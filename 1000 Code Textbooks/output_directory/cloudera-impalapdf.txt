ApacheImpalaGuide
ImportantNotice
Â©2010-2021 Cloudera,Inc.Allrightsreserved.
Cloudera,theClouderalogo,andanyotherproductor
servicenamesorsloganscontainedinthisdocumen taretrademarksofClouderaand
itssuppliersorlicensors,andmaynotbecopied,imitatedorused,inwholeorinpart,
withoutthepriorwrittenpermission ofClouderaortheapplicabletrademark holder.If
thisdocumen tationincludescode,including butnotlimitedto,codeexamples,Cloudera
makesthisavailabletoyouunderthetermsoftheApacheLicense,Version2.0,including
anyrequirednotices.AcopyoftheApacheLicenseVersion2.0,including anynotices,
isincludedherein.AcopyoftheApacheLicenseVersion2.0canalsobefoundhere:
https://opensour ce.org/licenses/ Apache-2.0
HadoopandtheHadoopelephantlogoaretrademarksoftheApacheSoftware
Foundation.Allothertrademarks,registeredtrademarks,productnamesandcompany
namesorlogosmentionedinthisdocumen tarethepropertyoftheirrespectiveowners.
Referencetoanyproducts,services,processesorotherinformation,bytradename,
trademark, manufacturer,supplierorotherwisedoesnotconstituteorimply
endorsement,sponsorshiporrecommenda tionthereofbyus.
Complying withallapplicablecopyrightlawsistheresponsibility oftheuser.Without
limitingtherightsundercopyright,nopartofthisdocumen tmaybereproduced,stored
inorintroducedintoaretrievalsystem,ortransmittedinanyformorbyanymeans
(electronic,mechanic al,photocopying,recording,orotherwise),orforanypurpose,
withouttheexpresswrittenpermission ofCloudera.
Clouderamayhavepatents,patentapplications,trademarks,copyrights,orother
intellectualpropertyrightscoveringsubjectmatterinthisdocumen t.Exceptasexpressly
providedinanywrittenlicenseagreementfromCloudera,thefurnishing ofthisdocument
doesnotgiveyouanylicensetothesepatents,trademarkscopyrights,orother
intellectualproperty.ForinformationaboutpatentscoveringClouderaproducts,see
http://tiny.cloudera.com/patents.
Theinformationinthisdocumen tissubjecttochangewithoutnotice.Clouderashall
notbeliableforanydamagesresultingfromtechnicalerrorsoromissions whichmay
bepresentinthisdocumen t,orfromuseofthisdocumen t.
Cloudera,Inc.
395PageMillRoad
PaloAlto,CA94306
info@clouder a.com
US:1-888-789-1488
Intl:1-650-362-0488
www.cloudera.com
ReleaseInformation
Version:CDH6.3.x
Date:September30,2021
TableofContents
IntroducingApacheImpala.................................................................................... 16
ImpalaBenefits.................................................................................................................................................. 16
HowImpalaWorkswithCDH............................................................................................................................. 16
PrimaryImpalaFeatures.................................................................................................................................... 17
ImpalaConceptsandArchitecture.......................................................................... 18
Componen tsoftheImpalaServer..................................................................................................................... 18
TheImpalaDaemon............................................................................................................................................................. 18
TheImpalaStatestore.......................................................................................................................................................... 18
TheImpalaCatalogService.................................................................................................................................................. 19
DevelopingImpalaApplications......................................................................................................................... 20
OverviewoftheImpalaSQLDialect..................................................................................................................................... 20
OverviewofImpalaProgramming Interfaces...................................................................................................................... 21
HowImpalaFitsIntotheHadoopEcosystem..................................................................................................... 21
HowImpalaWorkswithHive............................................................................................................................................... 21
OverviewofImpalaMetadataandtheMetastore.............................................................................................................. 22
HowImpalaUsesHDFS........................................................................................................................................................ 22
HowImpalaUsesHBase...................................................................................................................................................... 22
Planning forImpalaDeployment............................................................................ 23
ImpalaRequirements......................................................................................................................................... 23
ProductCompatibility Matrix............................................................................................................................................... 23
SupportedOperating Systems.............................................................................................................................................. 23
HiveMetastoreandRelatedConfiguration ......................................................................................................................... 23
JavaDependencies ............................................................................................................................................................... 23
Networking Configuration Requiremen ts............................................................................................................................ 24
Hardware Requiremen ts...................................................................................................................................................... 24
UserAccountRequiremen ts................................................................................................................................................. 25
Guidelines forDesigning ImpalaSchemas......................................................................................................... 25
SettingUpApacheImpalaUsingtheCommand Line............................................... 27
WhatisIncludedinanImpalaInstallation......................................................................................................... 27
InstallingImpalafromtheCommand Line......................................................................................................... 27
ModifyingImpalaStartupOptions..................................................................................................................... 29
Configuring ImpalaStartupOptionsthroughtheCommand Line....................................................................................... 29
Checking theValuesofImpalaConfiguration Options........................................................................................................ 32
StartupOptionsforimpaladDaemon.................................................................................................................................. 32
StartupOptionsforstatestoredDaemon............................................................................................................................. 32
StartupOptionsforcatalogdDaemon................................................................................................................................. 32
StartingImpala................................................................................................................................................... 32
StartingImpalafromtheCommand Line............................................................................................................................. 33
InstallingImpalawithClouderaManager.......................................................................................................... 33
InstallingImpalafromtheCommand Line......................................................................................................... 34
Managing Impala................................................................................................... 36
Post-InstallationConfigurationforImpala......................................................................................................... 36
ImpalaUpgradeConsiderations.............................................................................. 38
ConvertingLegacyUDFsDuringUpgradetoCDH5.12orHigher....................................................................... 38
Handling LargeRowsDuringUpgradetoCDH5.13/Impala2.10orHigher...................................................... 38
ChangeImpalacatalogdHeapwhenUpgradingfromCDH5.6orLower........................................................... 39
ListofReservedWordsUpdatedinCDH6.0/Impala3.0.................................................................................. 40
DecimalV2UsedbyDefaultinCDH6.0/Impala3.0......................................................................................... 40
BehaviorofColumnAliasesChangedinCDH6.0/Impala3.0........................................................................... 40
DefaultPARQUET_ARRA Y_RESOLUTIONChangedinCDH6.0/Impala3.0....................................................... 40
EnableClusteringHintforInserts....................................................................................................................... 40
DeprecatedQueryOptionsRemovedinCDH6.0/Impala3.0.......................................................................... 40
refresh_after_connectImpalaShellOptionRemovedinCDH6.0/Impala3.0................................................. 41
ReturnTypeChangedforEXTRACTandDATE_PARTFunctions inCDH6.0/Impala3.0.................................... 41
ImpalaRoleswithSELECTorINSERTPrivilegeReceiveREFRESHPrivilegeDuringtheUpgradetoCDH5.16
/CDH6.1....................................................................................................................................................... 41
PortChangeforSHUTDOWNCommand ............................................................................................................ 41
ChangeinClientConnection Timeout................................................................................................................ 41
DefaultSettingChanges..................................................................................................................................... 42
ImpalaTutorials..................................................................................................... 43
TutorialsforGettingStarted............................................................................................................................... 43
ExploreaNewImpalaInstance............................................................................................................................................ 43
LoadCSVDatafromLocalFiles............................................................................................................................................ 48
PointanImpalaTableatExistingDataFiles........................................................................................................................ 49
DescribetheImpalaTable.................................................................................................................................................... 51
QuerytheImpalaTable........................................................................................................................................................ 51
DataLoadingandQueryingExamples................................................................................................................................. 52
AdvancedTutorials............................................................................................................................................. 54
AttachinganExternalPartitioned TabletoanHDFSDirectoryStructure............................................................................ 54
SwitchingBackandForthBetweenImpalaandHive........................................................................................................... 56
CrossJoinsandCartesianProducts withtheCROSSJOINOperator.................................................................................... 57
DealingwithParquetFileswithUnknownSchema............................................................................................ 58
DownloadtheDataFilesintoHDFS..................................................................................................................................... 59
CreateDatabaseandTables................................................................................................................................................ 59
ExaminePhysicalandLogicalSchema................................................................................................................................. 60
AnalyzeData........................................................................................................................................................................ 61
ImpalaAdministration........................................................................................... 70
SettingTimeoutPeriodsforDaemons, Queries,andSessions........................................................................... 70
Increasing theStatestoreTimeout....................................................................................................................................... 70
SettingtheIdleQueryandIdleSessionTimeouts forimpalad............................................................................................. 70
SettingTimeoutandRetriesforThriftConnections totheBackendClient.......................................................................... 71
CancellingaQuery............................................................................................................................................................... 72
UsingImpalathroughaProxyforHighAvailability............................................................................................ 72
OverviewofProxyUsageandLoadBalancing forImpala................................................................................................... 72
Choosing theLoad-Balancing Algorithm ............................................................................................................................. 73
SpecialProxyConsiderations forClustersUsingKerberos................................................................................................... 74
SpecialProxyConsiderations forTLS/SSLEnabledClusters.................................................................................................. 75
ExampleofConfiguring HAProxyLoadBalancerforImpala................................................................................................ 75
Managing DiskSpaceforImpalaData................................................................................................................ 77
AuditingImpalaOperations............................................................................................................................... 78
Durability andPerformanceConsiderations forImpalaAuditing........................................................................................ 79
FormatoftheAuditLogFiles............................................................................................................................................... 79
WhichOperations AreAudited........................................................................................................................................... 80
ReviewingtheAuditLogs..................................................................................................................................................... 80
ViewingLineageInformationforImpalaData.................................................................................................... 80
ImpalaSecurity...................................................................................................... 82
SecurityGuidelines forImpala........................................................................................................................... 82
SecuringImpalaDataandLogFiles.................................................................................................................... 83
InstallationConsiderationsforImpalaSecurity.................................................................................................. 84
SecuringtheHiveMetastoreDatabase.............................................................................................................. 84
SecuringtheImpalaWebUserInterface............................................................................................................ 84
ConfiguringTLS/SSLforImpala.......................................................................................................................... 85
UsingCloudera Manager..................................................................................................................................................... 85
Configuring TLS/SSLCommunic ationfortheImpalaShell................................................................................................... 86
UsingTLS/SSLwithBusinessIntelligenceTools.................................................................................................................... 86
SpecifyingTLS/SSLMinimum AllowedVersionandCiphers................................................................................................. 87
EnablingSentryAuthorizationforImpala.......................................................................................................... 87
TheSentryPrivilegeModel.................................................................................................................................................. 87
StartingtheimpaladDaemonwithSentryAuthorizationEnabled...................................................................................... 90
EnablingSentryforImpalainCloudera Manager................................................................................................................ 91
UsingImpalawiththeSentryService(CDH5.1orhigheronly)........................................................................................... 91
SettingUpSchemaObjectsforaSecureImpalaDeployment.............................................................................................. 94
TheDEFAULTDatabaseinaSecureDeployment................................................................................................................. 94
ImpalaAuthentication........................................................................................................................................ 94
EnablingKerberosAuthenticationforImpala...................................................................................................................... 94
EnablingLDAPAuthenticationforImpala............................................................................................................................ 96
UsingMultipleAuthenticationMethodswithImpala.......................................................................................................... 98
Configuring ImpalaDelegation forHueandBITools........................................................................................................... 99
ImpalaSQLLanguageReference........................................................................... 101
Comments........................................................................................................................................................ 101
DataTypes........................................................................................................................................................ 101
ARRAYComplexType(CDH5.5orhigheronly).................................................................................................................. 102
BIGINTDataType............................................................................................................................................................... 105
BOOLEANDataType.......................................................................................................................................................... 106
CHARDataType(CDH5.2orhigheronly).......................................................................................................................... 107
DECIMALDataType(CDH6.0/Impala3.0orhigheronly)............................................................................................... 109
DOUBLEDataType............................................................................................................................................................. 114
FLOATDataType................................................................................................................................................................ 116
INTDataType.................................................................................................................................................................... 117
MAPComplexType(CDH5.5orhigheronly)..................................................................................................................... 118
REALDataType.................................................................................................................................................................. 121
SMALLINT DataType.......................................................................................................................................................... 122
STRINGDataType.............................................................................................................................................................. 123
STRUCTComplexType(CDH5.5orhigheronly)................................................................................................................ 124
TIMESTAMPDataType....................................................................................................................................................... 130
TINYINTDataType............................................................................................................................................................. 136
VARCHARDataType(CDH5.2orhigheronly)................................................................................................................... 137
ComplexTypes(CDH5.5orhigheronly)............................................................................................................................ 139
Literals.............................................................................................................................................................. 167
NumericLiterals................................................................................................................................................................. 167
StringLiterals..................................................................................................................................................................... 168
BooleanLiterals................................................................................................................................................................. 169
TimestampLiterals............................................................................................................................................................. 169
NULL................................................................................................................................................................................... 170
SQLOperators.................................................................................................................................................. 171
ArithmeticOperators......................................................................................................................................................... 171
BETWEEN Operator........................................................................................................................................................... 174
Comparison Operators....................................................................................................................................................... 175
EXISTSOperator................................................................................................................................................................. 176
ILIKEOperator.................................................................................................................................................................... 179
INOperator........................................................................................................................................................................ 180
IREGEXPOperator.............................................................................................................................................................. 182
ISDISTINCTFROMOperator.............................................................................................................................................. 183
ISNULLOperator............................................................................................................................................................... 185
ISTRUEOperator............................................................................................................................................................... 186
LIKEOperator..................................................................................................................................................................... 186
LogicalOperators............................................................................................................................................................... 187
REGEXPOperator............................................................................................................................................................... 189
RLIKEOperator................................................................................................................................................................... 191
ImpalaSchemaObjectsandObjectNames..................................................................................................... 191
OverviewofImpalaAliases................................................................................................................................................ 192
OverviewofImpalaDatabases.......................................................................................................................................... 193
OverviewofImpalaFunctions........................................................................................................................................... 194
OverviewofImpalaIdentifiers........................................................................................................................................... 195
OverviewofImpalaTables................................................................................................................................................. 196
OverviewofImpalaViews................................................................................................................................................. 199
ImpalaSQLStatements.................................................................................................................................... 202
DDLStatements................................................................................................................................................................. 203
DMLStatements................................................................................................................................................................ 204
ALTERDATABASEStatement.............................................................................................................................................. 204
ALTERTABLEStatement..................................................................................................................................................... 205
ALTERVIEWStatement...................................................................................................................................................... 218
COMMENT Statement........................................................................................................................................................ 219
COMPUTE STATSStatement............................................................................................................................................... 219
CREATEDATABASEStatement............................................................................................................................................ 226
CREATEFUNCTIONStatement........................................................................................................................................... 228
CREATEROLEStatement(CDH5.2orhigheronly)............................................................................................................. 234
CREATETABLEStatement................................................................................................................................................... 234
CREATEVIEWStatement.................................................................................................................................................... 248
DELETEStatement(CDH5.10orhigheronly).................................................................................................................... 249
DESCRIBEStatement.......................................................................................................................................................... 251
DROPDATABASEStatement............................................................................................................................................... 262
DROPFUNCTIONStatement.............................................................................................................................................. 263
DROPROLEStatement(CDH5.2orhigheronly)................................................................................................................ 265
DROPSTATSStatement...................................................................................................................................................... 265
DROPTABLEStatement...................................................................................................................................................... 268
DROPVIEWStatement....................................................................................................................................................... 270
EXPLAINStatement............................................................................................................................................................ 271
GRANTStatement(CDH5.2orhigheronly)....................................................................................................................... 273
INSERTStatement.............................................................................................................................................................. 277
INVALIDATEMETADATAStatement.................................................................................................................................... 286
LOADDATAStatement....................................................................................................................................................... 288
REFRESHStatement........................................................................................................................................................... 291
REFRESHAUTHORIZATIONStatement................................................................................................................................ 293
REFRESHFUNCTIONSStatement....................................................................................................................................... 293
REVOKEStatement(CDH5.2orhigheronly)..................................................................................................................... 293
SELECTStatement.............................................................................................................................................................. 295
SETStatement.................................................................................................................................................................... 321
SHOWStatement............................................................................................................................................................... 363
SHUTDOWNStatement...................................................................................................................................................... 379
TRUNCATETABLEStatement(CDH5.5orhigheronly)...................................................................................................... 381
UPDATEStatement(CDH5.10orhigheronly)................................................................................................................... 383
UPSERTStatement(CDH5.10orhigheronly).................................................................................................................... 384
USEStatement................................................................................................................................................................... 385
VALUESStatement............................................................................................................................................................. 386
OptimizerHintsinImpala.................................................................................................................................................. 387
ImpalaBuilt-InFunctions ................................................................................................................................. 391
ImpalaMathematic alFunctions........................................................................................................................................ 397
ImpalaBitFunctions.......................................................................................................................................................... 414
ImpalaTypeConversionFunctions..................................................................................................................................... 423
ImpalaDateandTimeFunctions....................................................................................................................................... 424
ImpalaConditional Functions............................................................................................................................................ 457
ImpalaStringFunctions..................................................................................................................................................... 462
ImpalaMiscellaneous Functions........................................................................................................................................ 477
ImpalaAggregat eFunctions.............................................................................................................................................. 479
ImpalaAnalyticFunctions.................................................................................................................................................. 506
User-DefinedFunctions (UDFs)........................................................................................................................ 525
UDFConcepts..................................................................................................................................................................... 525
RuntimeEnvironmen tforUDFs.......................................................................................................................................... 528
InstallingtheUDFDevelopmen tPackage.......................................................................................................................... 528
WritingUser-DefinedFunctions(UDFs)............................................................................................................................. 529
WritingUser-DefinedAggregat eFunctions(UDAFs)......................................................................................................... 532
BuildingandDeployingUDFs............................................................................................................................................. 533
PerformanceConsiderations forUDFs............................................................................................................................... 535
ExamplesofCreatingandUsingUDFs............................................................................................................................... 535
SecurityConsiderations forUser-DefinedFunctions.......................................................................................................... 540
LimitationsandRestrictionsforImpalaUDFs.................................................................................................................... 540
ConvertingLegacyUDFsDuringUpgrade toCDH5.12orHigher...................................................................................... 541
SQLDifferencesBetweenImpalaandHive...................................................................................................... 541
HiveQLFeaturesnotAvailableinImpala........................................................................................................................... 541
SemanticDifferencesBetweenImpalaandHiveQLFeatures............................................................................................ 542
PortingSQLfromOtherDatabaseSystemstoImpala...................................................................................... 543
PortingDDLandDMLStatements..................................................................................................................................... 543
PortingDataTypesfromOtherDatabaseSystems............................................................................................................ 543
SQLStatementstoRemoveorAdapt................................................................................................................................. 546
SQLConstructstoDouble-check ........................................................................................................................................ 547
NextPortingStepsafterVerifyingSyntaxandSemantics.................................................................................................. 548
ResourceManagement........................................................................................ 549
Admission ControlandQueryQueuing............................................................................................................ 549
Concurren tQueriesandAdmission Control....................................................................................................................... 549
MemoryLimitsandAdmission Control.............................................................................................................................. 550
HowImpalaAdmission ControlRelatestoOtherResourceManagemen tTools................................................................ 552
HowImpalaSchedules andEnforcesLimitsonConcurren tQueries.................................................................................. 552
HowAdmission ControlworkswithImpalaClients(JDBC,ODBC,HiveServer2)................................................................ 553
SQLandSchemaConsiderations forAdmission Control.................................................................................................... 553
Guidelines forUsingAdmission Control............................................................................................................................. 554
ConfiguringResourcePoolsandAdmission Control........................................................................................ 554
CreatingStaticServicePools.............................................................................................................................................. 555
UsingAdmission Control.................................................................................................................................................... 555
SettingPer-queryMemoryLimits...................................................................................................................................... 558
Configuring Admission ControlinCommand LineInterface............................................................................................... 559
Configuring Cluster-wideAdmission Control..................................................................................................................... 560
Admission ControlSampleScenario................................................................................................................ 562
TuningImpalaforPerformance............................................................................ 565
ImpalaPerformance Guidelines andBestPractices......................................................................................... 565
Performance ConsiderationsforJoinQueries.................................................................................................. 568
HowJoinsAreProcessedwhenStatisticsAreUnavailable ................................................................................................ 569
Overriding JoinReordering withSTRAIGHT_JOIN .............................................................................................................. 569
ExamplesofJoinOrderOptimization................................................................................................................................. 570
TableandColumnStatistics.............................................................................................................................. 575
OverviewofTableStatistics............................................................................................................................................... 575
OverviewofColumnStatistics............................................................................................................................................ 576
HowTableandColumnStatisticsWorkforPartitioned Tables.......................................................................................... 577
Generating TableandColumnStatistics............................................................................................................................ 578
DetectingMissingStatistics............................................................................................................................................... 582
Manually SettingTableandColumnStatisticswithALTERTABLE...................................................................................... 584
ExamplesofUsingTableandColumnStatisticswithImpala............................................................................................. 585
Benchmarking ImpalaQueries......................................................................................................................... 588
ControllingImpalaResourceUsage.................................................................................................................. 588
RuntimeFilteringforImpalaQueries(CDH5.7orhigheronly)....................................................................... 588
BackgroundInformation forRuntimeFiltering.................................................................................................................. 589
RuntimeFilteringInternals................................................................................................................................................. 590
FileFormatConsiderations forRuntimeFiltering.............................................................................................................. 590
WaitIntervalsforRuntimeFilters...................................................................................................................................... 590
QueryOptionsforRuntimeFiltering.................................................................................................................................. 591
RuntimeFilteringandQueryPlans.................................................................................................................................... 591
ExamplesofQueriesthatBenefitfromRuntimeFiltering.................................................................................................. 592
TuningandTroubleshooting QueriesthatUseRuntimeFiltering...................................................................................... 593
LimitationsandRestrictionsforRuntimeFiltering............................................................................................................. 593
UsingHDFSCachingwithImpala(CDH5.3orhigheronly).............................................................................. 593
OverviewofHDFSCachingforImpala............................................................................................................................... 594
SettingUpHDFSCachingforImpala.................................................................................................................................. 594
EnablingHDFSCachingforImpalaTablesandPartitions.................................................................................................. 595
LoadingandRemovingDatawithHDFSCachingEnabled................................................................................................. 596
AdministrationforHDFSCachingwithImpala................................................................................................................... 597
PerformanceConsiderations forHDFSCachingwithImpala............................................................................................. 598
DetectingandCorrectingHDFSBlockSkewConditions ................................................................................... 599
DataCacheforRemoteReads.......................................................................................................................... 600
TestingImpalaPerformance............................................................................................................................. 601
UnderstandingImpalaQueryPerformance -EXPLAINPlansandQueryProfiles............................................. 602
UsingtheEXPLAINPlanforPerformanceTuning............................................................................................................... 602
UsingtheSUMMAR YReportforPerformanceTuning....................................................................................................... 603
UsingtheQueryProfileforPerformanceTuning............................................................................................................... 604
ScalabilityConsiderationsforImpala.................................................................... 605
ImpactofManyTablesorPartitionsonImpalaCatalogPerformance andMemoryUsage............................. 605
ScalabilityConsiderationforLargeClusters..................................................................................................... 605
ScalabilityConsiderationsfortheImpalaStatestore........................................................................................ 606
EffectofBufferPoolonMemoryUsage(CDH5.13andhigher)....................................................................... 607
SQLOperationsthatSpilltoDisk...................................................................................................................... 607
LimitsonQuerySizeandComplexity............................................................................................................... 611
ScalabilityConsiderationsforImpalaI/O......................................................................................................... 611
ScalabilityConsiderationsforTableLayout...................................................................................................... 611
Kerberos-RelatedNetworkOverheadforLargeClusters................................................................................. 611
AvoidingCPUHotspots forHDFSCachedData................................................................................................ 612
ScalabilityConsiderationsforFileHandleCaching........................................................................................... 612
ScalingLimitsandGuidelines ........................................................................................................................... 613
DeploymentLimits............................................................................................................................................................. 613
DataStorageLimits........................................................................................................................................................... 614
SchemaDesignLimits........................................................................................................................................................ 614
SecurityLimits.................................................................................................................................................................... 614
QueryLimits-CompileTime.............................................................................................................................................. 614
QueryLimits-RuntimeTime.............................................................................................................................................. 614
HowtoConfigureImpalawithDedicatedCoordinators.................................................................................. 614
Determining theOptimalNumberofDedicatedCoordinat ors.......................................................................................... 615
DeployingDedicatedCoordinat orsandExecutorsinCloudera Manager.......................................................................... 618
DeployingDedicatedCoordinat orsandExecutorsfromCommand Line........................................................................... 619
MetadataManagement................................................................................................................................... 620
On-demand Metadata....................................................................................................................................................... 620
AutomaticInvalidation ofMetadataCache....................................................................................................................... 620
AutomaticInvalidation/R efreshofMetadata.................................................................................................................... 621
Partitioning forImpalaTables............................................................................... 625
WhentoUsePartitioned Tables....................................................................................................................... 625
SQLStatementsforPartitioned Tables............................................................................................................. 625
StaticandDynamic Partitioning Clauses.......................................................................................................... 626
RefreshingaSinglePartition............................................................................................................................ 626
Permissions forPartitionSubdirectories.......................................................................................................... 627
PartitionPruningforQueries........................................................................................................................... 627
Checking ifPartitionPruningHappens foraQuery........................................................................................................... 627
WhatSQLConstructsWorkwithPartitionPruning............................................................................................................ 628
Dynamic PartitionPruning................................................................................................................................................. 628
PartitionKeyColumns...................................................................................................................................... 630
SettingDifferentFileFormatsforPartitions..................................................................................................... 630
Managing Partitions......................................................................................................................................... 631
UsingPartitioning withKuduTables................................................................................................................. 631
KeepingStatisticsUptoDateforPartitioned Tables........................................................................................ 631
HowImpalaWorkswithHadoopFileFormats...................................................... 634
Choosing theFileFormatforaTable................................................................................................................ 635
UsingTextDataFileswithImpalaTables.......................................................................................................... 636
QueryPerformanceforImpalaTextTables........................................................................................................................ 636
CreatingTextTables........................................................................................................................................................... 637
DataFilesforTextTables................................................................................................................................................... 638
LoadingDataintoImpalaTextTables................................................................................................................................ 639
UsingLZO-Compressed TextFiles....................................................................................................................................... 640
Usinggzip,bzip2,orSnappy-Compressed TextFiles.......................................................................................................... 642
UsingtheParquetFileFormatwithImpalaTables........................................................................................... 643
CreatingParquetTablesinImpala..................................................................................................................................... 643
LoadingDataintoParquetTables...................................................................................................................................... 644
QueryPerformanceforImpalaParquetTables.................................................................................................................. 645
Compressions forParquetDataFiles................................................................................................................................. 647
ParquetTablesforImpalaComplexTypes......................................................................................................................... 649
Exchanging ParquetDataFileswithOtherHadoopComponen ts...................................................................................... 649
HowParquetDataFilesAreOrganized.............................................................................................................................. 652
Compacting DataFilesforParquetTables......................................................................................................................... 653
SchemaEvolutionforParquetTables................................................................................................................................. 654
DataTypeConsiderations forParquetTables.................................................................................................................... 655
UsingtheORCFileFormatwithImpalaTables................................................................................................. 656
CreatingORCTablesandLoadingData............................................................................................................................. 657
EnablingCompression forORCTables................................................................................................................................ 657
QueryPerformanceforImpalaORCTables........................................................................................................................ 658
DataTypeConsiderations forORCTables.......................................................................................................................... 659
UsingtheAvroFileFormatwithImpalaTables................................................................................................ 659
Creating AvroTables.......................................................................................................................................................... 660
UsingaHive-Creat edAvroTableinImpala........................................................................................................................ 662
SpecifyingtheAvroSchemathroughJSON........................................................................................................................ 662
LoadingDataintoanAvroTable........................................................................................................................................ 662
EnablingCompression forAvroTables............................................................................................................................... 663
HowImpalaHandlesAvroSchemaEvolution.................................................................................................................... 663
DataTypeConsiderations forAvroTables.......................................................................................................................... 664
QueryPerformanceforImpalaAvroTables....................................................................................................................... 664
UsingtheRCFileFileFormatwithImpalaTables.............................................................................................. 665
CreatingRCFileTablesandLoadingData.......................................................................................................................... 665
EnablingCompression forRCFileTables............................................................................................................................. 666
QueryPerformanceforImpalaRCFileTables..................................................................................................................... 667
UsingtheSequenceFile FileFormatwithImpalaTables.................................................................................. 667
CreatingSequenceFileTablesandLoadingData............................................................................................................... 667
EnablingCompression forSequenceFileTables.................................................................................................................. 668
QueryPerformanceforImpalaSequenceFileTables.......................................................................................................... 669
UsingImpalatoQueryKuduTables...................................................................... 670
BenefitsofUsingKuduTableswithImpala...................................................................................................... 670
ConfiguringImpalaforUsewithKudu............................................................................................................. 670
ClusterTopologyforKuduTables....................................................................................................................................... 670
KuduReplicationFactor................................................................................................................................... 671
ImpalaDDLEnhancemen tsforKuduTables(CREATETABLEandALTERTABLE)............................................... 671
PrimaryKeyColumnsforKuduTables................................................................................................................................ 671
Kudu-Specific ColumnAttributesforCREATETABLE........................................................................................................... 671
Partitioning forKuduTables............................................................................................................................................... 675
Handling Date,Time,orTimestampDatawithKudu........................................................................................................ 678
HowImpalaHandlesKuduMetadata................................................................................................................................ 680
WorkingwithKuduIntegratedwithHiveMetastore....................................................................................... 681
LoadingDataintoKuduTables......................................................................................................................... 681
ImpalaDMLSupportforKuduTables(INSERT,UPDATE,DELETE,UPSERT)...................................................... 681
ConsistencyConsiderationsforKuduTables.................................................................................................... 682
SecurityConsiderationsforKuduTables.......................................................................................................... 682
ImpalaQueryPerformance forKuduTables.................................................................................................... 683
UsingImpalatoQueryHBaseTables.................................................................... 684
OverviewofUsingHBasewithImpala............................................................................................................. 684
ConfiguringHBaseforUsewithImpala............................................................................................................ 684
SupportedDataTypesforHBaseColumns....................................................................................................... 685
Performance ConsiderationsfortheImpala-HBase Integration...................................................................... 685
UseCasesforQueryingHBasethroughImpala................................................................................................ 689
LoadingDataintoanHBaseTable.................................................................................................................... 689
LimitationsandRestrictionsoftheImpalaandHBaseIntegration.................................................................. 689
ExamplesofQueryingHBaseTablesfromImpala............................................................................................ 690
UsingImpalawiththeAmazonS3Filesystem....................................................... 692
HowImpalaSQLStatementsWorkwithS3...................................................................................................... 692
LoadingDataintoS3forImpalaQueries.......................................................................................................... 693
UsingImpalaDMLStatementsforS3Data........................................................................................................................ 693
Manually LoadingDataintoImpalaTablesonS3.............................................................................................................. 693
CreatingImpalaDatabases,Tables,andPartitionsforDataStoredonS3....................................................... 694
InternalandExternalTablesLocatedonS3...................................................................................................... 695
RunningandTuningImpalaQueriesforDataStoredonS3............................................................................. 697
UnderstandingandTuningImpalaQueryPerformanceforS3Data.................................................................................. 697
RestrictionsonImpalaSupportforS3.............................................................................................................. 698
BestPracticesforUsingImpalawithS3........................................................................................................... 698
SpecifyingImpalaCredentialstoAccessDatainS3withClouderaManager................................................... 699
SpecifyingImpalaCredentialsonClustersNotSecuredbySentryorKerberos.................................................................. 699
SpecifyingImpalaCredentialstoAccessDatainS3......................................................................................... 699
UsingImpalawiththeAzureDataLakeStore(ADLS)............................................ 701
Prerequisites.................................................................................................................................................... 701
HowImpalaSQLStatementsWorkwithADLS................................................................................................. 701
SpecifyingImpalaCredentialstoAccessDatainADLS..................................................................................... 702
LoadingDataintoADLSforImpalaQueries..................................................................................................... 703
UsingImpalaDMLStatementsforADLSData................................................................................................................... 703
Manually LoadingDataintoImpalaTablesonADLS......................................................................................................... 703
CreatingImpalaDatabases,Tables,andPartitionsforDataStoredonADLS................................................... 703
InternalandExternalTablesLocatedonADLS................................................................................................. 705
RunningandTuningImpalaQueriesforDataStoredonADLS......................................................................... 707
UnderstandingandTuningImpalaQueryPerformanceforADLSData............................................................................. 707
RestrictionsonImpalaSupportforADLS......................................................................................................... 708
BestPracticesforUsingImpalawithADLS....................................................................................................... 708
UsingImpalaLogging........................................................................................... 709
LocationsandNamesofImpalaLogFiles......................................................................................................... 709
Managing ImpalaLogsthroughClouderaManagerorManually ..................................................................... 710
RotatingImpalaLogs........................................................................................................................................ 710
ReviewingImpalaLogs..................................................................................................................................... 710
UnderstandingImpalaLogContents................................................................................................................ 711
SettingLoggingLevels...................................................................................................................................... 711
RedactingSensitiveInformationfromImpalaLogFiles................................................................................... 712
ImpalaClientAccess............................................................................................. 713
UsingtheImpalaShell(impala-shell Command) ............................................................................................. 713
impala-shell Configuration Options................................................................................................................................... 714
Connecting toimpaladthroughimpala-shell .................................................................................................................... 718
RunningCommands andSQLStatementsinimpala-shell ................................................................................................. 720
impala-shell Command Reference..................................................................................................................................... 721
ConfiguringImpalatoWorkwithODBC........................................................................................................... 723
Downloading theODBCDriver........................................................................................................................................... 723
Configuring theODBCPort................................................................................................................................................ 724
ExampleofSettingUpanODBCApplicationforImpala.................................................................................................... 724
NotesaboutJDBCandODBCInteractionwithImpalaSQLFeatures................................................................................. 725
ConfiguringImpalatoWorkwithJDBC............................................................................................................ 725
Configuring theJDBCPort.................................................................................................................................................. 726
Choosing theJDBCDriver................................................................................................................................................... 726
EnablingImpalaJDBCSupportonClientSystems.............................................................................................................. 726
Establishing JDBCConnections .......................................................................................................................................... 727
NotesaboutJDBCandODBCInteractionwithImpalaSQLFeatures................................................................................. 728
KuduConsiderations forDMLStatements......................................................................................................................... 729
Troubleshooting Impala....................................................................................... 730
Troubleshooting ImpalaSQLSyntaxIssues...................................................................................................... 730
Troubleshooting CrashesCausedbyMemoryResourceLimit......................................................................... 730
Troubleshooting I/OCapacityProblems........................................................................................................... 731
ImpalaTroubleshooting QuickReference........................................................................................................ 731
ImpalaWebUserInterfaceforDebugging....................................................................................................... 733
DebugWebUIforimpalad................................................................................................................................................ 733
DebugWebUIforstatestored........................................................................................................................................... 736
DebugWebUIforcatalogd................................................................................................................................................ 738
BreakpadMinidump sforImpala(CDH5.8orhigheronly).............................................................................. 739
EnablingorDisabling Minidump Generation ..................................................................................................................... 740
SpecifyingtheLocationforMinidump Files....................................................................................................................... 740
ControllingtheNumberofMinidump Files........................................................................................................................ 740
DetectingCrashEvents...................................................................................................................................................... 740
UsingtheMinidump FilesforProblemResolution............................................................................................................. 740
DemonstrationofBreakpad Feature................................................................................................................................. 741
PortsUsedbyImpala........................................................................................... 743
ImpalaReservedWords........................................................................................ 745
ListofCurrentReservedWords........................................................................................................................ 745
ImpalaFrequentlyAskedQuestions..................................................................... 761
TransitiontoApacheGovernance.................................................................................................................... 761
TryingImpala.................................................................................................................................................... 761
ImpalaSystemRequirements........................................................................................................................... 762
SupportedandUnsupport edFunctionality InImpala...................................................................................... 763
HowdoI?......................................................................................................................................................... 765
ImpalaPerformance......................................................................................................................................... 765
ImpalaUseCases............................................................................................................................................. 768
QuestionsaboutImpalaAndHive.................................................................................................................... 768
ImpalaAvailability............................................................................................................................................ 769
ImpalaInternals............................................................................................................................................... 770
SQL................................................................................................................................................................... 772
Partitioned Tables............................................................................................................................................. 773
HBase............................................................................................................................................................... 773
Appendix: ApacheLicense,Version2.0................................................................. 775
IntroducingApacheImpala
Impalaprovidesfast,interactiveSQLqueriesdirectlyonyourApacheHadoopdatastoredinHDFS,HBase,orthe
AmazonSimpleStorageService(S3).Inadditiontousingthesameunifiedstorageplatform,Impalaalsousesthesame
metadata,SQLsyntax(HiveSQL),ODBCdriver,anduserinterface(ImpalaqueryUIinHue)asApacheHive.Thisprovides
afamiliarandunifiedplatformforreal-timeorbatch-orientedqueries.
Impalaisanadditiontotoolsavailableforqueryingbigdata.Impaladoesnotreplacethebatchprocessingframeworks
builtonMapReducesuchasHive.HiveandotherframeworksbuiltonMapReducearebestsuitedforlongrunning
batchjobs,suchasthoseinvolvingbatchprocessingofExtract,Transform,andLoad(ETL)typejobs.
Note:ImpalagraduatedfromtheApacheIncubatoronNovember15,2017.Inplaceswherethe
documen tationformerlyreferredtoâClouderaImpalaâ,nowtheofficialnameisâApacheImpalaâ.
ImpalaBenefits
Impalaprovides:
â¢FamiliarSQLinterfacethatdatascientistsandanalystsalreadyknow.
â¢Abilitytoqueryhighvolumesofdata(âbigdataâ)inApacheHadoop.
â¢Distributedqueriesinaclusterenvironment,forconvenientscalingandtomakeuseofcost-effectivecommodity
hardware.
â¢Abilitytosharedatafilesbetweendifferentcomponen tswithnocopyorexport/import step;forexample,to
writewithPig,transformwithHiveandquerywithImpala.ImpalacanreadfromandwritetoHivetables,enabling
simpledatainterchangeusingImpalaforanalyticsonHive-produceddata.
â¢Singlesystemforbigdataprocessingandanalytics,socustomerscanavoidcostlymodeling andETLjustfor
analytics.
HowImpalaWorkswithCDH
ThefollowinggraphicillustrateshowImpalaispositioned inthebroaderClouderaenvironment:
TheImpalasolutioniscomposed ofthefollowingcomponen ts:
â¢Clients-Entitiesincluding Hue,ODBCclients,JDBCclients,andtheImpalaShellcanallinteractwithImpala.These
interfacesaretypicallyusedtoissuequeriesorcompleteadministrativetaskssuchasconnecting toImpala.
16|ApacheImpalaGuideIntroducingApacheImpala
â¢HiveMetastore-StoresinformationaboutthedataavailabletoImpala.Forexample,themetastoreletsImpala
knowwhatdatabasesareavailableandwhatthestructureofthosedatabasesis.Asyoucreate,drop,andalter
schemaobjects,loaddataintotables,andsoonthroughImpalaSQLstatements,therelevantmetadatachanges
areautomaticallybroadcasttoallImpalanodesbythededicatedcatalogserviceintroducedinImpala1.2.
â¢Impala-Thisprocess,whichrunsonDataNodes,coordinatesandexecutesqueries.EachinstanceofImpalacan
receive,plan,andcoordinatequeriesfromImpalaclients.QueriesaredistributedamongImpalanodes,andthese
nodesthenactasworkers,executingparallelqueryfragments.
â¢HBaseandHDFS-Storagefordatatobequeried.
QueriesexecutedusingImpalaarehandledasfollows:
1.UserapplicationssendSQLqueriestoImpalathroughODBCorJDBC,whichprovidestandardizedquerying
interfaces.Theuserapplicationmayconnecttoanyimpalad inthecluster.Thisimpalad becomesthecoordinator
forthequery.
2.Impalaparsesthequeryandanalyzesittodeterminewhattasksneedtobeperformedbyimpalad instances
acrossthecluster.Executionisplannedforoptimalefficiency.
3.ServicessuchasHDFSandHBaseareaccessed bylocalimpalad instancestoprovidedata.
4.Eachimpalad returnsdatatothecoordinatingimpalad ,whichsendstheseresultstotheclient.
PrimaryImpalaFeatures
Impalaprovidessupportfor:
â¢MostcommonSQL-92featuresofHiveQueryLanguage(HiveQL)including SELECT,joins,andaggregatefunctions .
â¢HDFS,HBase,andAmazonSimpleStorageSystem(S3)storage,including:
âHDFSfileformats:delimitedtextfiles,Parquet,Avro,SequenceFile, andRCFile.
âCompressioncodecs:Snappy,GZIP,Deflate,BZIP.
â¢Common dataaccessinterfacesincluding:
âJDBCdriver.
âODBCdriver.
âHueBeeswaxandtheImpalaQueryUI.
â¢impala-shell command-line interface.
â¢Kerberosauthentication.
ApacheImpalaGuide|17IntroducingApacheImpala
ImpalaConceptsandArchitecture
ThefollowingsectionsprovidebackgroundinformationtohelpyoubecomeproductiveusingImpalaanditsfeatures.
Whereappropriate,theexplanationsincludecontexttohelpunderstandhowaspectsofImpalarelatetoother
technologies youmightalreadybefamiliarwith,suchasrelationaldatabasemanagementsystemsanddatawarehouses,
orotherHadoopcomponen tssuchasHive,HDFS,andHBase.
Componen tsoftheImpalaServer
TheImpalaserverisadistributed,massivelyparallelprocessing(MPP)databaseengine.Itconsistsofdifferentdaemon
processesthatrunonspecifichostswithinyourCDHcluster.
TheImpalaDaemon
ThecoreImpalacomponen tistheImpaladaemon, physicallyrepresentedbytheimpalad process.Afewofthekey
functions thatanImpaladaemonperformsare:
â¢Readsandwritestodatafiles.
â¢Acceptsqueriestransmittedfromtheimpala-shell command, Hue,JDBC,orODBC.
â¢Parallelizesthequeriesanddistributesworkacrossthecluster.
â¢Transmitsintermediatequeryresultsbacktothecentralcoordinator.
Impaladaemons canbedeployedinoneofthefollowingways:
â¢HDFSandImpalaareco-located,andeachImpaladaemonrunsonthesamehostasaDataNode.
â¢ImpalaisdeployedseparatelyinacomputeclusterandreadsremotelyfromHDFS,S3,ADLS,etc.
TheImpaladaemons areinconstantcommunic ationwithStateStore,toconfirmwhichdaemons arehealthyandcan
acceptnewwork.
Theyalsoreceivebroadcastmessagesfromthecatalogd daemon(introducedinImpala1.2)wheneveranyImpala
daemonintheclustercreates,alters,ordropsanytypeofobject,orwhenanINSERTorLOAD DATA statementis
processedthroughImpala.ThisbackgroundcommunicationminimizestheneedforREFRESH orINVALIDATE METADATA
statementsthatwereneededtocoordinatemetadataacrossImpaladaemons priortoImpala1.2.
InCDH5.12/Impala2.9andhigher,youcancontrolwhichhostsactasquerycoordinatorsandwhichactasquery
executors,toimprovescalabilityforhighlyconcurrentworkloadsonlargeclusters.SeeHowtoConfigureImpalawith
DedicatedCoordinatorsonpage614fordetails.
Relatedinformation:SettingtheIdleQueryandIdleSessionTimeouts forimpaladonpage70,ModifyingImpala
StartupOptions,PortsUsedbyImpalaonpage743,UsingImpalathroughaProxyforHighAvailabilityonpage72
TheImpalaStatestore
TheImpalacomponen tknownastheStateStorechecksonthehealthofallImpaladaemons inacluster,andcontinuously
relaysitsfindingstoeachofthosedaemons. Itisphysicallyrepresentedbyadaemonprocessnamedstatestored .
Youonlyneedsuchaprocessononehostinacluster.IfanImpaladaemongoesofflineduetohardwarefailure,
networkerror,softwareissue,orotherreason,theStateStoreinformsalltheotherImpaladaemons sothatfuture
queriescanavoidmakingrequeststotheunreachable Impaladaemon.
BecausetheStateStore'spurposeistohelpwhenthingsgowrongandtobroadcastmetadatatocoordinators,itisnot
alwayscriticaltothenormaloperationofanImpalacluster.IftheStateStoreisnotrunningorbecomesunreachable,
theImpaladaemons continuerunninganddistributingworkamongthemselvesasusualwhenworkingwiththedata
knowntoImpala.TheclusterjustbecomeslessrobustifotherImpaladaemons fail,andmetadatabecomesless
consistentasitchangeswhiletheStateStoreisoffline.WhentheStateStorecomesbackonline,itre-establishes
communic ationwiththeImpaladaemons andresumesitsmonitoringandbroadcastingfunctions.
18|ApacheImpalaGuideImpalaConceptsandArchitecture
IfyouissueaDDLstatementwhiletheStateStoreisdown,thequeriesthataccessthenewobjecttheDDLcreatedwill
fail.
Mostconsiderationsforloadbalancing andhighavailabilityapplytotheimpalad daemon. Thestatestored and
catalogd daemons donothavespecialrequirementsforhighavailability,becauseproblemswiththosedaemons do
notresultindataloss.Ifthosedaemons becomeunavailableduetoanoutageonaparticular host,youcanstopthe
Impalaservice,deletetheImpalaStateStoreandImpalaCatalogServerroles,addtherolesonadifferenthost,and
restarttheImpalaservice.
Relatedinformation:
ScalabilityConsiderationsfortheImpalaStatestoreonpage606,ModifyingImpalaStartupOptions,Increasingthe
StatestoreTimeoutonpage70,PortsUsedbyImpalaonpage743
TheImpalaCatalogService
TheImpalacomponen tknownastheCatalogServicerelaysthemetadatachangesfromImpalaSQLstatementstoall
theImpaladaemons inacluster.Itisphysicallyrepresentedbyadaemonprocessnamedcatalogd .Youonlyneed
suchaprocessononehostinacluster.BecausetherequestsarepassedthroughtheStateStoredaemon, itmakes
sensetorunthestatestored andcatalogd servicesonthesamehost.
ThecatalogserviceavoidstheneedtoissueREFRESH andINVALIDATE METADATA statementswhenthemetadata
changesareperformedbystatementsissuedthroughImpala.Whenyoucreateatable,loaddata,andsoonthrough
Hive,youdoneedtoissueREFRESH orINVALIDATE METADATA onanImpalanodebeforeexecutingaquerythere.
ThisfeaturetouchesanumberofaspectsofImpala:
â¢SeeImpalaUpgradeConsiderationsonpage38andModifyingImpalaStartupOptionsforusageinformationfor
thecatalogd daemon.
â¢TheREFRESH andINVALIDATE METADATA statementsarenotneededwhentheCREATE TABLE ,INSERT,or
othertable-changing ordata-changing operationisperformedthroughImpala.Thesestatementsarestillneeded
ifsuchoperationsaredonethroughHiveorbymanipula tingdatafilesdirectlyinHDFS,butinthosecasesthe
statementsonlyneedtobeissuedononeImpaladaemonratherthanonalldaemons. SeeREFRESHStatement
onpage291andINVALIDATEMETADATAStatementonpage286forthelatestusageinformationforthose
statements.
Use--load_catalog_in_background optiontocontrolwhenthemetadataofatableisloaded.
â¢Ifsettofalse,themetadataofatableisloadedwhenitisreferencedforthefirsttime.Thismeansthatthefirst
runofaparticular querycanbeslowerthansubsequentruns.StartinginImpala2.2,thedefaultfor
load_catalog_in_background isfalse.
â¢Ifsettotrue,thecatalogserviceattemptstoloadmetadataforatableevenifnoqueryneededthatmetadata.
Sometadatawillpossiblybealreadyloadedwhenthefirstquerythatwouldneeditisrun.However,forthe
followingreasons,werecommend nottosettheoptiontotrue.
âBackgroundloadcaninterferewithquery-specific metadataloading.Thiscanhappenonstartuporafter
invalidatingmetadata,withadurationdepending ontheamountofmetadata,andcanleadtoaseemingly
randomlongrunningqueriesthataredifficulttodiagnose.
âImpalamayloadmetadatafortablesthatarepossiblyneverused,potentiallyincreasingcatalogsizeand
consequen tlymemoryusageforbothcatalogserviceandImpalaDaemon.
Mostconsiderationsforloadbalancing andhighavailabilityapplytotheimpalad daemon. Thestatestored and
catalogd daemons donothavespecialrequirementsforhighavailability,becauseproblemswiththosedaemons do
notresultindataloss.Ifthosedaemons becomeunavailableduetoanoutageonaparticular host,youcanstopthe
Impalaservice,deletetheImpalaStateStoreandImpalaCatalogServerroles,addtherolesonadifferenthost,and
restarttheImpalaservice.
ApacheImpalaGuide|19ImpalaConceptsandArchitecture
Note:
InImpala1.2.4andhigher,youcanspecifyatablenamewithINVALIDATE METADATA afterthetable
iscreatedinHive,allowingyoutomakeindividual tablesvisibletoImpalawithoutdoingafullreload
ofthecatalogmetadata.Impala1.2.4alsoincludesotherchangestomakethemetadatabroadcast
mechanism fasterandmoreresponsive,especially duringImpalastartup.
Relatedinformation:
ModifyingImpalaStartupOptions,PortsUsedbyImpalaonpage743
DevelopingImpalaApplications
ThecoredevelopmentlanguagewithImpalaisSQL.YoucanalsouseJavaorotherlanguagestointeractwithImpala
throughthestandardJDBCandODBCinterfacesusedbymanybusinessintelligencetools.Forspecializedkindsof
analysis,youcansupplemen ttheSQLbuilt-infunctions bywritinguser-definedfunctions (UDFs)inC++orJava.
OverviewoftheImpalaSQLDialect
TheImpalaSQLdialectishighlycompatiblewiththeSQLsyntaxusedintheApacheHivecomponen t(HiveQL).Assuch,
itisfamiliartouserswhoarealreadyfamiliarwithrunningSQLqueriesontheHadoopinfrastructure.Currently,Impala
SQLsupports asubsetofHiveQLstatements,datatypes,andbuilt-infunctions. Impalaalsoincludesadditional built-in
functions forcommonindustryfeatures,tosimplifyportingSQLfromnon-Hadoop systems.
ForuserscomingtoImpalafromtraditional databaseordatawarehousing backgrounds,thefollowingaspectsofthe
SQLdialectmightseemfamiliar:
â¢TheSELECTstatementincludesfamiliarclausessuchasWHERE,GROUP BY ,ORDER BY ,andWITH.Youwillfind
familiarnotionssuchasjoins,built-infunctions forprocessingstrings,numbers,anddates,aggregatefunctions ,
subqueries ,andcomparison operatorssuchasIN()andBETWEEN .TheSELECTstatementistheplacewhere
SQLstandardscompliance ismostimportant.
â¢Fromthedatawarehousing world,youwillrecognizethenotionofpartitioned tables.Oneormorecolumnsserve
aspartitionkeys,andthedataisphysicallyarrangedsothatqueriesthatrefertothepartitionkeycolumnsinthe
WHEREclausecanskippartitions thatdonotmatchthefilterconditions. Forexample,ifyouhave10yearsworth
ofdataanduseaclausesuchasWHERE year = 2015 ,WHERE year > 2010 ,orWHERE year IN (2014,
2015),Impalaskipsallthedatafornon-matchingyears,greatlyreducingtheamountofI/Oforthequery.
â¢InImpala1.2andhigher,UDFsletyouperformcustomcomparisons andtransformationlogicduringSELECTand
INSERT...SELECT statements.
ForuserscomingtoImpalafromtraditional databaseordatawarehousing backgrounds,thefollowingaspectsofthe
SQLdialectmightrequiresomelearningandpracticeforyoutobecomeproficientintheHadoopenvironment:
â¢ImpalaSQLisfocusedonqueriesandincludesrelativelylittleDML.ThereisnoUPDATEorDELETEstatement.
Staledataistypicallydiscarded(byDROP TABLE orALTER TABLE ... DROP PARTITION statements)or
replaced(byINSERT OVERWRITE statements).
â¢AlldatacreationisdonebyINSERTstatements,whichtypicallyinsertdatainbulkbyqueryingfromothertables.
Therearetwovariations,INSERT INTO whichappendstotheexistingdata,andINSERT OVERWRITE which
replacestheentirecontentsofatableorpartition (similartoTRUNCATE TABLE followedbyanewINSERT).
Although thereisanINSERT ... VALUES syntaxtocreateasmallnumberofvaluesinasinglestatement,itis
farmoreefficienttousetheINSERT ... SELECT tocopyandtransformlargeamountsofdatafromonetable
toanotherinasingleoperation.
â¢YouoftenconstructImpalatabledefinitionsanddatafilesinsomeotherenvironment,andthenattachImpalaso
thatitcanrunreal-timequeries.Thesamedatafilesandtablemetadataaresharedwithothercomponen tsof
theHadoopecosystem.Inparticular ,ImpalacanaccesstablescreatedbyHiveordatainsertedbyHive,andHive
20|ApacheImpalaGuideImpalaConceptsandArchitecture
canaccesstablesanddataproducedbyImpala.ManyotherHadoopcomponen tscanwritefilesinformatssuch
asParquetandAvro,thatcanthenbequeriedbyImpala.
â¢BecauseHadoopandImpalaarefocusedondatawarehouse-styleoperationsonlargedatasets,ImpalaSQL
includessomeidiomsthatyoumightfindintheimportutilitiesfortraditional databasesystems.Forexample,
youcancreateatablethatreadscomma-separ atedortab-separatedtextfiles,specifyingtheseparatorinthe
CREATE TABLE statement.Youcancreateexternaltablesthatreadexistingdatafilesbutdonotmoveortransform
them.
â¢BecauseImpalareadslargequantitiesofdatathatmightnotbeperfectlytidyandpredictable,itdoesnotrequire
lengthconstraintsonstringdatatypes.Forexample,youcandefineadatabasecolumnasSTRINGwithunlimited
length,ratherthanCHAR(1) orVARCHAR(64) .(Although inImpala2.0andlater,youcanalsouse
length-constrainedCHARandVARCHAR types.)
Relatedinformation:ImpalaSQLLanguageReferenceonpage101,especially ImpalaSQLStatementsonpage202and
ImpalaBuilt-InFunctions onpage391
OverviewofImpalaProgrammingInterfaces
YoucanconnectandsubmitrequeststotheImpaladaemons through:
â¢Theimpala-shell interactivecommand interpreter.
â¢TheHueweb-based userinterface.
â¢JDBC.
â¢ODBC.
Withtheseoptions,youcanuseImpalainheterogeneousenvironments,withJDBCorODBCapplicationsrunningon
non-Linux platforms.YoucanalsouseImpalaoncombinationwithvariousBusinessIntelligencetoolsthatusethe
JDBCandODBCinterfaces.
Eachimpalad daemonprocess,runningonseparatenodesinacluster,listenstoseveralportsforincomingrequests.
Requestsfromimpala-shell andHueareroutedtotheimpalad daemons throughthesameport.Theimpalad
daemons listenonseparateportsforJDBCandODBCrequests.
HowImpalaFitsIntotheHadoopEcosystem
Impalamakesuseofmanyfamiliarcomponen tswithintheHadoopecosystem.Impalacaninterchangedatawithother
Hadoopcomponen ts,asbothaconsumer andaproducer,soitcanfitinflexiblewaysintoyourETLandELTpipelines.
HowImpalaWorkswithHive
AmajorImpalagoalistomakeSQL-on-Hadoop operationsfastandefficientenoughtoappealtonewcategoriesof
usersandopenupHadooptonewtypesofusecases.Wherepractical,itmakesuseofexistingApacheHiveinfrastructure
thatmanyHadoopusersalreadyhaveinplacetoperformlong-running ,batch-orientedSQLqueries.
Inparticular ,ImpalakeepsitstabledefinitionsinatraditionalMySQLorPostgreSQLdatabaseknownasthemetastore,
thesamedatabasewhereHivekeepsthistypeofdata.Thus,ImpalacanaccesstablesdefinedorloadedbyHive,as
longasallcolumnsuseImpala-support eddatatypes,fileformats,andcompressioncodecs.
Theinitialfocusonqueryfeaturesandperformance meansthatImpalacanreadmoretypesofdatawiththeSELECT
statementthanitcanwritewiththeINSERTstatement.ToquerydatausingtheAvro,RCFile,orSequenceFile file
formats,youloadthedatausingHive.
TheImpalaqueryoptimizercanalsomakeuseoftablestatisticsandcolumnstatistics.Originally ,yougatheredthis
informationwiththeANALYZE TABLE statementinHive;inImpala1.2.2andhigher,usetheImpalaCOMPUTE STATS
statementinstead.COMPUTE STATS requireslesssetup,ismorereliable,anddoesnotrequireswitchingbackand
forthbetweenimpala-shell andtheHiveshell.
ApacheImpalaGuide|21ImpalaConceptsandArchitecture
OverviewofImpalaMetadataandtheMetastore
Asdiscussed inHowImpalaWorkswithHiveonpage21,Impalamaintainsinformationabouttabledefinitionsina
centraldatabaseknownasthemetastore.Impalaalsotracksothermetadataforthelow-levelcharacteristicsofdata
files:
â¢ThephysicallocationsofblockswithinHDFS.
Fortableswithalargevolumeofdataand/ormanypartitions, retrievingallthemetadataforatablecanbe
time-consuming ,takingminutesinsomecases.Thus,eachImpalanodecachesallofthismetadatatoreuseforfuture
queriesagainstthesametable.
Ifthetabledefinitionorthedatainthetableisupdated,allotherImpaladaemons intheclustermustreceivethe
latestmetadata,replacingtheobsoletecachedmetadata,beforeissuingaqueryagainstthattable.InImpala1.2and
higher,themetadataupdateisautomatic,coordinatedthroughthecatalogd daemon,forallDDLandDMLstatements
issuedthroughImpala.SeeTheImpalaCatalogServiceonpage19fordetails.
ForDDLandDMLissuedthroughHive,orchangesmademanually tofilesinHDFS,youstillusetheREFRESH statement
(whennewdatafilesareaddedtoexistingtables)ortheINVALIDATE METADATA statement(forentirelynewtables,
orafterdroppingatable,performinganHDFSrebalance operation,ordeletingdatafiles).IssuingINVALIDATE
METADATA byitselfretrievesmetadataforallthetablestrackedbythemetastore.Ifyouknowthatonlyspecifictables
havebeenchangedoutsideofImpala,youcanissueREFRESH table_name foreachaffectedtabletoonlyretrieve
thelatestmetadataforthosetables.
HowImpalaUsesHDFS
ImpalausesthedistributedfilesystemHDFSasitsprimarydatastoragemedium. Impalareliesontheredundancy
providedbyHDFStoguardagainsthardwareornetworkoutagesonindividual nodes.Impalatabledataisphysically
representedasdatafilesinHDFS,usingfamiliarHDFSfileformatsandcompressioncodecs.Whendatafilesarepresent
inthedirectoryforanewtable,Impalareadsthemall,regardlessoffilename.Newdataisaddedinfileswithnames
controlledbyImpala.
HowImpalaUsesHBase
HBaseisanalternativetoHDFSasastoragemediumforImpaladata.Itisadatabasestoragesystembuiltontopof
HDFS,withoutbuilt-inSQLsupport.ManyHadoopusersalreadyhaveitconfiguredandstorelarge(oftensparse)data
setsinit.BydefiningtablesinImpalaandmapping themtoequivalenttablesinHBase,youcanquerythecontentsof
theHBasetablesthroughImpala,andevenperformjoinqueriesincluding bothImpalaandHBasetables.SeeUsing
ImpalatoQueryHBaseTablesonpage684fordetails.
22|ApacheImpalaGuideImpalaConceptsandArchitecture
PlanningforImpalaDeployment
BeforeyousetupImpalainproduction, dosomeplanningtomakesurethatyourhardwaresetuphassufficientcapacity,
thatyourclustertopologyisoptimalforImpalaqueries,andthatyourschemadesignandETLprocessesfollowthe
bestpracticesforImpala.
ImpalaRequirements
Toperformasexpected,Impaladependsontheavailabilityofthesoftware,hardware,andconfigurationsdescribed
inthefollowingsections.
ProductCompatibilityMatrix
TheultimatesourceoftruthaboutcompatibilitybetweenvariousversionsofCDH,ClouderaManager,andvarious
CDHcomponen tsisthe.
SupportedOperatingSystems
TherelevantsupportedoperatingsystemsandversionsforImpalaarethesameasforthecorresponding CDHplatforms.
Fordetails,seetheSupportedOperating SystemspageforCDH.
HiveMetastoreandRelatedConfiguration
ImpalacaninteroperatewithdatastoredinHive,andusesthesameinfrastructureasHivefortrackingmetadataabout
schemaobjectssuchastablesandcolumns.Thefollowingcomponen tsareprerequisitesforImpala:
â¢MySQLorPostgreSQL,toactasametastoredatabaseforbothImpalaandHive.
AlwaysconfigureaHivemetastoreserviceratherthanconnecting directlytothemetastoredatabase.TheHive
metastoreserviceisrequiredtointeroperatebetweendifferentlevelsofmetastoreAPIsifthisisnecessaryfor
yourenvironment,andusingitavoidsknownissueswithconnecting directlytothemetastoredatabase.
Seebelowforasummaryofthemetastoreinstallationprocess.
â¢Hive(optional).Although onlytheHivemetastoredatabaseisrequiredforImpalatofunction, youmightinstall
Hiveonsomeclientmachines tocreateandloaddataintotablesthatusecertainfileformats.SeeHowImpala
WorkswithHadoopFileFormatsonpage634fordetails.HivedoesnotneedtobeinstalledonthesameDataNodes
asImpala;itjustneedsaccesstothesamemetastoredatabase.
Toinstallthemetastore:
1.InstallaMySQLorPostgreSQLdatabase.Startthedatabaseifitisnotstartedafterinstallation.
2.DownloadtheMySQLconnectororthePostgreSQLconnectorandplaceitinthe/usr/share/java/ directory.
3.Usetheappropriatecommand linetoolforyourdatabasetocreatethemetastoredatabase.
4.Usetheappropriatecommand linetoolforyourdatabasetograntprivilegesforthemetastoredatabasetothe
hiveuser.
5.Modifyhive-site.xml toincludeinformationmatchingyourparticular database:itsURL,username, and
password.Youwillcopythehive-site.xml filetotheImpalaConfigurationDirectorylaterintheImpala
installationprocess.
JavaDependencies
Although Impalaisprimarily writteninC++,itdoesuseJavatocommunic atewithvariousHadoopcomponen ts:
â¢TheofficiallysupportedJVMsforImpalaaretheOpenJDK JVMandOracleJVM.OtherJVMsmightcauseissues,
typicallyresultinginafailureatimpalad startup.Inparticular ,theJamVMusedbydefaultoncertainlevelsof
Ubuntusystemscancauseimpalad tofailtostart.
ApacheImpalaGuide|23PlanningforImpalaDeployment
â¢Internally,theimpalad daemonreliesontheJAVA_HOME environmentvariabletolocatethesystemJavalibraries.
Makesuretheimpalad serviceisnotrunfromanenvironmentwithanincorrectsettingforthisvariable.
â¢AllJavadependencies arepackagedintheimpala-dependencies.jar file,whichislocatedat
/usr/lib/impala/lib/ .Thesemaptoeverythingthatisbuiltunderfe/target/dependency .
NetworkingConfigurationRequirements
Aspartofensuringbestperformance, Impalaattemptstocompletetasksonlocaldata,asopposedtousingnetwork
connections toworkwithremotedata.Tosupportthisgoal,ImpalamatchesthehostnameprovidedtoeachImpala
daemonwiththeIPaddressofeachDataNodebyresolvingthehostnameflagtoanIPaddress.ForImpalatowork
withlocaldata,useasingleIPinterfacefortheDataNodeandtheImpaladaemononeachmachine. Ensurethatthe
Impaladaemon's hostnameflagresolvestotheIPaddressoftheDataNode.Forsingle-homed machines, thisisusually
automatic,butformulti-homed machines, ensurethattheImpaladaemon's hostnameresolvestothecorrectinterface.
Impalatriestodetectthecorrecthostnameatstart-up,andprintsthederivedhostnameatthestartofthelogina
messageoftheform:
Using hostname: impala-daemon-1.example.com
Inthemajorityofcases,thisautomaticdetectionworkscorrectly.Ifyouneedtoexplicitlysetthehostname,dosoby
settingthe--hostname flag.
HardwareRequirements
ThememoryallocationshouldbeconsistentacrossImpalaexecutornodes.AsingleImpalaexecutorwithalower
memorylimitthantherestcaneasilybecomeabottleneckandleadtosuboptimalperformance.
Thisguideline doesnotapplytocoordinator-onlynodes.
HardwareRequirementsforOptimalJoinPerformance
Duringjoinoperations,portionsofdatafromeachjoinedtableareloadedintomemory.Datasetscanbeverylarge,
soensureyourhardwarehassufficientmemorytoaccommodatethejoinsyouanticipatecompleting.
Whilerequirementsvaryaccordingtodatasetsize,thefollowingisgenerallyrecommended:
â¢CPU
Impalaversion2.2andhigherusestheSSSE3instructionset,whichisincludedinnewerprocessors.
Note:ThisrequiredlevelofprocessoristhesameasinImpalaversion1.x.TheImpala2.0and
2.1releaseshadastricterrequirementfortheSSE4.1instructionset,whichhasnowbeenrelaxed.
â¢Memory
128GBormorerecommended, ideally256GBormore.Iftheintermediateresultsduringqueryprocessingona
particular nodeexceedtheamountofmemoryavailabletoImpalaonthatnode,thequerywritestemporarywork
datatodisk,whichcanleadtolongquerytimes.Notethatbecausetheworkisparallelized,andintermediate
resultsforaggregatequeriesaretypicallysmallerthantheoriginaldata,Impalacanqueryandjointablesthatare
muchlargerthanthememoryavailableonanindividual node.
â¢JVMHeapSizeforCatalogServer
4GBormorerecommended, ideally8GBormore,toaccommodatethemaximumnumbersoftables,partitions,
anddatafilesyouareplanningtousewithImpala.
â¢Storage
DataNodeswith12ormorediskseach.I/Ospeedsareoftenthelimitingfactorfordiskperformance withImpala.
EnsurethatyouhavesufficientdiskspacetostorethedataImpalawillbequerying.
24|ApacheImpalaGuidePlanningforImpalaDeployment
UserAccountRequirements
Impalacreatesandusesauserandgroupnamedimpala.Donotdeletethisaccountorgroupanddonotmodifythe
account'sorgroup'spermissions andrights.Ensurenoexistingsystemsobstructthefunctioning oftheseaccountsand
groups.Forexample,ifyouhavescriptsthatdeleteuseraccountsnotinawhite-list,addtheseaccountstothelistof
permittedaccounts.
ForcorrectfiledeletionduringDROP TABLE operations,ImpalamustbeabletomovefilestotheHDFStrashcan.You
mightneedtocreateanHDFSdirectory/user/impala ,writeablebytheimpalauser,sothatthetrashcancanbe
created.Otherwise,datafilesmightremainbehindafteraDROP TABLE statement.
Impalashouldnotrunasroot.BestImpalaperformance isachievedusingdirectreads,butrootisnotpermittedto
usedirectreads.Therefore,runningImpalaasrootnegativelyaffectsperformance.
Bydefault,anyusercanconnecttoImpalaandaccessalltheassociateddatabasesandtables.Youcanenable
authorizationandauthenticationbasedontheLinuxOSuserwhoconnectstotheImpalaserver,andtheassociated
groupsforthatuser.ImpalaSecurityonpage82fordetails.Thesesecurityfeaturesdonotchangetheunderlying file
permission requirements;theimpalauserstillneedstobeabletoaccessthedatafiles.
Guidelines forDesigning ImpalaSchemas
Theguidelines inthistopichelpyoutoconstructanoptimizedandscalableschema,onethatintegrateswellwithyour
existingdatamanagementprocesses.Usetheseguidelines asachecklistwhendoinganyproof-of-conceptwork,
portingexercise,orbeforedeployingtoproduction.
IfyouareadaptinganexistingdatabaseorHiveschemaforusewithImpala,readtheguidelines inthissectionand
thenseePortingSQLfromOtherDatabaseSystemstoImpalaonpage543forspecificportingandcompatibilitytips.
Preferbinaryfileformatsovertext-basedformats.
Tosavespaceandimprovememoryusageandqueryperformance, usebinaryfileformatsforanylargeorintensively
queriedtables.Parquetfileformatisthemostefficientfordatawarehouse-styleanalyticqueries.Avroistheother
binaryfileformatthatImpalasupports, thatyoumightalreadyhaveaspartofaHadoopETLpipeline.
Although ImpalacancreateandquerytableswiththeRCFileandSequenceFile fileformats,suchtablesarerelatively
bulkyduetothetext-basednatureofthoseformats,andarenotoptimizedfordatawarehouse-stylequeriesdueto
theirrow-orientedlayout.ImpaladoesnotsupportINSERToperationsfortableswiththesefileformats.
Guidelines:
â¢Foranefficientandscalableformatforlarge,performance-critic altables,usetheParquetfileformat.
â¢TodeliverintermediatedataduringtheETLprocess,inaformatthatcanalsobeusedbyotherHadoopcomponen ts,
Avroisareasonable choice.
â¢Forconvenientimportofrawdata,useatexttableinsteadofRCFileorSequenceFile, andconverttoParquetin
alaterstageoftheETLprocess.
UseSnappycompressionwherepractical.
SnappycompressioninvolveslowCPUoverheadtodecompress,whilestillprovidingsubstantialspacesavings.Incases
whereyouhaveachoiceofcompressioncodecs,suchaswiththeParquetandAvrofileformats,useSnappycompression
unlessyoufindacompelling reasontouseadifferentcodec.
Prefernumerictypesoverstrings.
Ifyouhavenumericvaluesthatyoucouldtreataseitherstringsornumbers(suchasYEAR,MONTH,andDAYforpartition
keycolumns), definethemasthesmallestapplicableintegertypes.Forexample,YEARcanbeSMALLINT ,MONTHand
DAYcanbeTINYINT .Although youmightnotseeanydifferenceinthewaypartitioned tablesortextfilesarelaidout
ondisk,usingnumerictypeswillsavespaceinbinaryformatssuchasParquet,andinmemorywhendoingqueries,
particularly resource-intensivequeriessuchasjoins.
ApacheImpalaGuide|25PlanningforImpalaDeployment
Partition,butdonotover-partition.
Partitioning isanimportantaspectofperformance tuningforImpala.FollowtheproceduresinPartitioning forImpala
Tablesonpage625tosetuppartitioning foryourbiggest,mostintensivelyqueriedtables.
IfyouaremovingtoImpalafromatraditional databasesystem,orjustgettingstartedintheBigDatafield,youmight
nothaveenoughdatavolumetotakeadvantageofImpalaparallelquerieswithyourexistingpartitioning scheme.For
example,ifyouhaveonlyafewtensofmegabytesofdataperday,partitioning byYEAR,MONTH,andDAYcolumns
mightbetoogranular.Mostofyourclustermightbesittingidleduringqueriesthattargetasingleday,oreachnode
mighthaveverylittleworktodo.Considerreducingthenumberofpartitionkeycolumnssothateachpartitiondirectory
containsseveralgigabytesworthofdata.
Forexample,consideraParquettablewhereeachdatafileis1HDFSblock,withamaximumblocksizeof1GB.(In
Impala2.0andlater,thedefaultParquetblocksizeisreducedto256MB.Forthisexercise,let'sassumeyouhave
bumpedthesizebackupto1GBbysettingthequeryoptionPARQUET_FILE_SIZE=1g .)ifyouhavea10-nodecluster,
youneed10datafiles(upto10GB)togiveeachnodesomeworktodoforaquery.Buteachcoreoneachmachine
canprocessaseparatedatablockinparallel.With16-coremachines ona10-nodecluster,aquerycouldprocessup
to160GBfullyinparallel.Ifthereareonlyafewdatafilesperpartition, notonlyaremostclusternodessittingidle
duringqueries,soaremostcoresonthosemachines.
YoucanreducetheParquetblocksizetoaslowas128MBor64MBtoincreasethenumberoffilesperpartition and
improveparallelism.Butalsoconsiderreducingthelevelofpartitioning sothatanalyticquerieshaveenoughdatato
workwith.
Alwayscomputestatsafterloadingdata.
Impalamakesextensiveuseofstatisticsaboutdataintheoveralltableandineachcolumn,tohelpplan
resource-intensiveoperationssuchasjoinqueriesandinsertingintopartitioned Parquettables.Becausethisinformation
isonlyavailableafterdataisloaded,runtheCOMPUTE STATS statementonatableafterloadingorreplacingdatain
atableorpartition.
Havingaccuratestatisticscanmakethedifferencebetweenasuccessfuloperation,oronethatfailsduetoan
out-of-memor yerrororatimeout.Whenyouencounterperformance orcapacityissues,alwaysusetheSHOW STATS
statementtocheckifthestatisticsarepresentandup-to-dateforalltablesinthequery.
Whendoingajoinquery,Impalaconsultsthestatisticsforeachjoinedtabletodeterminetheirrelativesizesandto
estimatethenumberofrowsproducedineachjoinstage.WhendoinganINSERTintoaParquettable,Impalaconsults
thestatisticsforthesourcetabletodeterminehowtodistributetheworkofconstructingthedatafilesforeach
partition.
SeeCOMPUTE STATSStatementonpage219forthesyntaxoftheCOMPUTE STATS statement,andTableandColumn
Statisticsonpage575foralltheperformance considerationsfortableandcolumnstatistics.
VerifysensibleexecutionplanswithEXPLAINandSUMMAR Y.
Beforeexecutingaresource-intensivequery,usetheEXPLAIN statementtogetanoverviewofhowImpalaintends
toparallelizethequeryanddistributethework.Ifyouseethatthequeryplanisinefficient,youcantaketuningsteps
suchaschanging fileformats,usingpartitioned tables,runningtheCOMPUTE STATS statement,oraddingqueryhints.
Forinformationaboutallofthesetechniques, seeTuningImpalaforPerformance onpage565.
Afteryourunaquery,youcanseeperformance-r elatedinformationabouthowitactuallyranbyissuingtheSUMMARY
command inimpala-shell .PriortoImpala1.4,youwouldusethePROFILE command, butitshighlytechnicaloutput
wasonlyusefulforthemostexperienced users.SUMMARY ,newinImpala1.4,summariz esthemostusefulinformation
forallstagesofexecution,forallnodesratherthansplittingoutfiguresforeachnode.
26|ApacheImpalaGuidePlanningforImpalaDeployment
SettingUpApacheImpalaUsingtheCommand Line
Impalaisanopen-sour ceadd-ontotheClouderaEnterpriseCorethatreturnsrapidresponses toqueries.
Note:
UnderCDH5andCDH6,ImpalaisincludedaspartoftheCDHinstallationandnoseparatestepsare
needed.Therefore,theinstructionstepsinthissectionapplytoCDH4only.
WhatisIncludedinanImpalaInstallation
Impalaismadeupofasetofcomponen tsthatcanbeinstalledonmultiplenodesthroughoutyourcluster.Thekey
installationstepforperformance istoinstalltheimpalad daemon(whichdoesmostofthequeryprocessingwork)
onallDataNodesinthecluster.
TheImpalapackageinstallsthesebinaries:
â¢impalad -TheImpaladaemon. PlansandexecutesqueriesagainstHDFS,HBase,andAmazonS3data.Runone
impaladprocessoneachnodeintheclusterthathasaDataNode.
â¢statestored -Nameservicethattrackslocationandstatusofallimpalad instancesinthecluster.Runone
instanceofthisdaemononanodeinyourcluster.Mostproductiondeploymentsrunthisdaemononthenamenode.
â¢catalogd -MetadatacoordinationservicethatbroadcastschangesfromImpalaDDLandDMLstatementstoall
affectedImpalanodes,sothatnewtables,newlyloadeddata,andsoonareimmediatelyvisibletoqueries
submittedthroughanyImpalanode.(PriortoImpala1.2,youhadtoruntheREFRESH orINVALIDATE METADATA
statementoneachnodetosynchronizechangedmetadata.Nowthosestatementsareonlyrequiredifyouperform
theDDLorDMLthroughanexternalmechanism suchasHiveorbyuploading datatotheAmazonS3filesystem.)
Runoneinstanceofthisdaemononanodeinyourcluster,preferablyonthesamehostasthestatestored
daemon.
â¢impala-shell -Command-line interfaceforissuingqueriestotheImpaladaemon. Youinstallthisononeor
morehostsanywhereonyournetwork,notnecessarily DataNodesorevenwithinthesameclusterasImpala.It
canconnectremotelytoanyinstanceoftheImpaladaemon.
Beforedoingtheinstallation,ensurethatyouhaveallnecessaryprerequisites.SeeImpalaRequirementsonpage23
fordetails.
InstallingImpalafromtheCommand Line
BeforeinstallingImpalamanually,makesureallapplicablenodeshavetheappropriatehardwareconfiguration,levels
ofoperatingsystemandCDH,andanyothersoftwareprerequisites.SeeImpalaRequirementsonpage23fordetails.
YoucaninstallImpalaacrossmanyhostsorononehost:
â¢InstallingImpalaacrossmultiplemachines createsadistributedconfiguration.Forbestperformance, installImpala
onallDataNodes.
â¢InstallingImpalaonasinglemachineproducesapseudo-dis tributedcluster.
ToinstallImpalaonahost:
1.InstallCDH,including Hive,asdescribed inInstallingandDeployingUnmanag edCDHUsingtheCommand Line.
2.ConfiguretheHivemetastoretouseanexternaldatabaseasametastore.Impalausesthissamedatabaseforits
owntablemetadata.YoucanchooseeitheraMySQLorPostgreSQLdatabaseasthemetastore.Theprocessfor
configuringeachtypeofdatabaseisdescribed intheCDHInstallationGuide).
ApacheImpalaGuide|27SettingUpApacheImpalaUsingtheCommand Line
Clouderarecommends settingupaHivemetastoreserviceratherthanconnecting directlytothemetastore
database;thisconfigurationisrequiredwhenrunningImpalaunderCDH4.1.Makesurethe
/etc/impala/conf/hive-site.xml filecontainsthefollowingsetting,substitutingtheappropriatehostname
formetastore_server_host:
<property>
<name>hive.metastore.uris</name>
<value>thrift:// metastore_server_host :9083</value>
</property>
<property>
<name>hive.metastore.client.socket.timeout</name>
<value>3600</value>
<description>MetaStore Client socket timeout in seconds</description>
</property>
3.(Optional)IfyouinstalledthefullHivecomponen tonanyhost,youcanverifythatthemetastoreisconfigured
properlybystartingtheHiveconsoleandqueryingforthelistofavailabletables.Onceyouconfirmthattheconsole
starts,exittheconsoletocontinuetheinstallation:
$ hive
Hive history file=/tmp/root/hive_job_log_root_201207272011_678722950.txt
hive> show tables;
table1
table2
hive> quit;
$
4.Confirmthatyourpackagemanagementcommand isawareoftheImpalarepositorysettings,asdescribed in
ImpalaRequirementsonpage23.(ForCDH4,thisisadifferentrepositorythanforCDH.)Youmightneedto
downloadarepoorlistfileintoasystemdirectoryundernea th/etc.
5.Useoneofthefollowingsetsofcommands toinstalltheImpalapackage:
ForRHEL,OracleLinux,orCentOSsystems:
$ sudo yum install impala             # Binaries for daemons
$ sudo yum install impala-server      # Service start/stop script
$ sudo yum install impala-state-store # Service start/stop script
$ sudo yum install impala-catalog     # Service start/stop script
ForSUSEsystems:
$ sudo zypper install impala             # Binaries for daemons
$ sudo zypper install impala-server      # Service start/stop script
$ sudo zypper install impala-state-store # Service start/stop script
$ sudo zypper install impala-catalog     # Service start/stop script
ForDebianorUbuntusystems:
$ sudo apt-get install impala             # Binaries for daemons
$ sudo apt-get install impala-server      # Service start/stop script
$ sudo apt-get install impala-state-store # Service start/stop script
$ sudo apt-get install impala-catalog     # Service start/stop script
Note:Clouderarecommends thatyounotinstallImpalaonanyHDFSNameNode. Installing
ImpalaonNameNodes providesnoadditional datalocality,andexecutingquerieswithsucha
configurationmightcausememorycontentionandnegativelyimpacttheHDFSNameNode.
6.Copytheclienthive-site.xml ,core-site.xml ,hdfs-site.xml ,andhbase-site.xml configurationfiles
totheImpalaconfigurationdirectory,whichdefaultsto/etc/impala/conf .Createthisdirectoryifitdoesnot
alreadyexist.
28|ApacheImpalaGuideSettingUpApacheImpalaUsingtheCommand Line
7.Useoneofthefollowingcommands toinstallimpala-shell onthemachines fromwhichyouwanttoissue
queries.Youcaninstallimpala-shell onanysupportedmachinethatcanconnecttoDataNodesthatarerunning
impalad .
ForRHEL/Cen tOSsystems:
$ sudo yum install impala-shell
ForSUSEsystems:
$ sudo zypper install impala-shell
ForDebian/Ubun tusystems:
$ sudo apt-get install impala-shell
8.Completeanyrequiredorrecommended configuration,asdescribed inPost-InstallationConfigurationforImpala
onpage36.Someoftheseconfigurationchangesaremandatory.
Onceinstallationandconfigurationarecomplete,seeStartingImpalaonpage32forhowtoactivatethesoftwareon
theappropriatenodesinyourcluster.
IfthisisyourfirsttimesettingupandusingImpalainthiscluster,runthroughsomeoftheexercisesinImpalaTutorials
onpage43toverifythatyoucandobasicoperationssuchascreatingtablesandqueryingthem.
ModifyingImpalaStartupOptions
TheconfigurationoptionsfortheImpala-relateddaemons letyouchoosewhichhostsandportstousefortheservices
thatrunonasinglehost,specifydirectoriesforlogging,controlresourceusageandsecurity,andspecifyotheraspects
oftheImpalasoftware.
ConfiguringImpalaStartupOptionsthroughtheCommand Line
WhenyourunImpalainanon-Clouder aManagerenvironment,theImpalaserver,statestore,andcatalogservices
startupusingvaluesprovidedinadefaultsfile,/etc/default/impala .
ThisfileincludesinformationaboutmanyresourcesusedbyImpala.Mostofthedefaultsincludedinthisfileshould
beeffectiveinmostcases.Forexample,typicallyyouwouldnotchangethedefinitionoftheCLASSPATH variable,but
youwouldalwayssettheaddressusedbythestatestoreserver.Someofthecontentyoumightmodifyincludes:
IMPALA_STATE_STORE_HOST=127.0.0.1
IMPALA_STATE_STORE_PORT=24000
IMPALA_BACKEND_PORT=22000
IMPALA_LOG_DIR=/var/log/impala
IMPALA_CATALOG_SERVICE_HOST=...
IMPALA_STATE_STORE_HOST=...
export IMPALA_STATE_STORE_ARGS=${IMPALA_STATE_STORE_ARGS:- \
    -log_dir=${IMPALA_LOG_DIR} -state_store_port=${IMPALA_STATE_STORE_PORT}}
IMPALA_SERVER_ARGS=" \
-log_dir=${IMPALA_LOG_DIR} \
-catalog_service_host=${IMPALA_CATALOG_SERVICE_HOST} \
-state_store_port=${IMPALA_STATE_STORE_PORT} \
-state_store_host=${IMPALA_STATE_STORE_HOST} \
-be_port=${IMPALA_BACKEND_PORT}"
export ENABLE_CORE_DUMPS=${ENABLE_COREDUMPS:-false}
ApacheImpalaGuide|29SettingUpApacheImpalaUsingtheCommand Line
Tousealternatevalues,editthedefaultsfile,thenrestartalltheImpala-relatedservicessothatthechangestake
effect.RestarttheImpalaserverusingthefollowingcommands:
$ sudo service impala-server restart
Stopping Impala Server:                                    [  OK  ]
Starting Impala Server:                                    [  OK  ]
RestarttheImpalastatestoreusingthefollowingcommands:
$ sudo service impala-state-store restart
Stopping Impala State Store Server:                        [  OK  ]
Starting Impala State Store Server:                        [  OK  ]
RestarttheImpalacatalogserviceusingthefollowingcommands:
$ sudo service impala-catalog restart
Stopping Impala Catalog Server:                            [  OK  ]
Starting Impala Catalog Server:                            [  OK  ]
Somecommonsettingstochangeinclude:
â¢Statestoreaddress.Wherepractical,putthestatestoreonaseparatehostnotrunningtheimpalad daemon. In
thatrecommended configuration,theimpalad daemoncannotrefertothestatestoreserverusingtheloopback
address.IfthestatestoreishostedonamachinewithanIPaddressof192.168.0.27, change:
IMPALA_STATE_STORE_HOST=127.0.0.1
to:
IMPALA_STATE_STORE_HOST=192.168.0.27
â¢Catalogserveraddress(including boththehostnameandtheportnumber). Updatethevalueofthe
IMPALA_CATALOG_SERVICE_HOST variable.Clouderarecommends thecatalogserverbeonthesamehostas
thestatestore.Inthatrecommended configuration,theimpalad daemoncannotrefertothecatalogserverusing
theloopback address.IfthecatalogserviceishostedonamachinewithanIPaddressof192.168.0.27, addthe
followingline:
IMPALA_CATALOG_SERVICE_HOST=192.168.0.27:26000
The/etc/default/impala defaultsfilecurrentlydoesnotdefineanIMPALA_CATALOG_ARGS environment
variable,butifyouaddoneitwillberecognizedbytheservicestartup/shutdownscript.Addadefinitionforthis
variableto/etc/default/impala andaddtheoption-catalog_service_host= hostname .Iftheportis
differentthanthedefault26000,alsoaddtheoption-catalog_service_port= port.
â¢Memorylimits.YoucanlimittheamountofmemoryavailabletoImpala.Forexample,toallowImpalatouseno
morethan70%ofsystemmemory,change:
export IMPALA_SERVER_ARGS=${IMPALA_SERVER_ARGS:- \
    -log_dir=${IMPALA_LOG_DIR} \
    -state_store_port=${IMPALA_STATE_STORE_PORT} \
    -state_store_host=${IMPALA_STATE_STORE_HOST} \
    -be_port=${IMPALA_BACKEND_PORT}}
to:
export IMPALA_SERVER_ARGS=${IMPALA_SERVER_ARGS:- \
    -log_dir=${IMPALA_LOG_DIR} -state_store_port=${IMPALA_STATE_STORE_PORT} \
    -state_store_host=${IMPALA_STATE_STORE_HOST} \
    -be_port=${IMPALA_BACKEND_PORT} -mem_limit=70%}
30|ApacheImpalaGuideSettingUpApacheImpalaUsingtheCommand Line
Youcanspecifythememorylimitusingabsolutenotationsuchas500mor2G,orasapercentageofphysical
memorysuchas60%.
Note:Queriesthatexceedthespecified memorylimitareaborted.Percentagelimitsarebased
onthephysicalmemoryofthemachineanddonotconsidercgroups.
â¢Coredumpenablemen t.ToenablecoredumpsonsystemsnotmanagedbyClouderaManager,change:
export ENABLE_CORE_DUMPS=${ENABLE_COREDUMPS:-false}
to:
export ENABLE_CORE_DUMPS=${ENABLE_COREDUMPS:-true}
OnsystemsmanagedbyClouderaManager,enabletheEnableCoreDumpsettingfortheImpalaservice.
Note:
â¢Thelocationofcoredumpfilesmayvaryaccordingtoyouroperatingsystemconfiguration.
â¢OthersecuritysettingsmaypreventImpalafromwritingcoredumpsevenwhenthisoption
isenabled.
â¢Thedefaultlocationforcoredumpsisonatemporaryfilesystem,whichcanleadto
out-of-space issuesifthecoredumpsarelarge,frequent,ornotremovedpromptly.To
specifyanalternativelocationforthecoredumps,filtertheImpalaconfigurationsettings
tofindthecore_dump_dir option.Thisoptionletsyouspecifyadifferentdirectoryforcore
dumpsforeachoftheImpala-relateddaemons.
â¢AuthorizationusingtheopensourceSentryplugin.Specifythe-server_name and
-authorization_policy_file optionsaspartoftheIMPALA_SERVER_ARGS andIMPALA_STATE_STORE_ARGS
settingstoenablethecoreImpalasupportforauthentication.SeeEnablingSentryAuthorizationforImpalaon
page87fordetails.
â¢AuditingforsuccessfulorblockedImpalaqueries,anotheraspectofsecurity.Specifythe
-audit_event_log_dir= directory_path optionandoptionallythe
-max_audit_event_log_file_size= number_of_queries and-abort_on_failed_audit_event options
aspartoftheIMPALA_SERVER_ARGS settings,foreachImpalanode,toenableandcustomizeauditing. See
AuditingImpalaOperationsonpage78fordetails.
â¢PasswordprotectionfortheImpalawebUI,whichlistensonport25000bydefault.Thisfeatureinvolvesadding
someorallofthe--webserver_password_file ,--webserver_authentication_domain ,and
--webserver_certificate_file optionstotheIMPALA_SERVER_ARGS andIMPALA_STATE_STORE_ARGS
settings.SeeSecurityGuidelines forImpalaonpage82fordetails.
â¢AnothersettingyoumightaddtoIMPALA_SERVER_ARGS isacomma-separ atedlistofqueryoptionsandvalues:
-default_query_options=' option=value,option=value,...'
Theseoptionscontrolthebehaviorofqueriesperformedbythisimpalad instance.Theoptionvaluesyouspecify
hereoverridethedefaultvaluesforImpalaqueryoptions,asshownbytheSETstatementinimpala-shell .
â¢Duringtroubleshooting ,ClouderaSupportmightdirectyoutochangeothervalues,particularly for
IMPALA_SERVER_ARGS ,toworkaroundissuesorgatherdebugginginformation.
ApacheImpalaGuide|31SettingUpApacheImpalaUsingtheCommand Line
Note:
Thesestartupoptionsfortheimpalad daemonaredifferentfromthecommand-line optionsforthe
impala-shell command. Fortheimpala-shell options,seeimpala-shell ConfigurationOptions
onpage714.
Checking theValuesofImpalaConfigurationOptions
YoucancheckthecurrentruntimevalueofallthesesettingsthroughtheImpalawebinterface,availablebydefault
athttp://impala_hostname :25000/varz fortheimpalad daemon,http://impala_hostname :25010/varz
forthestatestored daemon, orhttp://impala_hostname :25020/varz forthecatalogd daemon. Inthe
ClouderaManagerinterface,youcanseethelinktotheappropriateservice_nameWebUIpagewhenyoulookatthe
statuspageforaspecificdaemononaspecifichost.
StartupOptionsforimpaladDaemon
Theimpalad daemonimplemen tsthemainImpalaservice,whichperformsqueryprocessingandreadsandwrites
thedatafiles.Someofthenoteworthyoptionsare:
â¢Thefe_service_threads optionspecifiesthemaximumnumberofconcurrentclientconnections allowed.The
defaultvalueis64withwhich64queriescanrunsimultaneously.
IfyouhavemoreclientstryingtoconnecttoImpalathanthevalueofthissetting,thelaterarrivingclientshave
towaituntilpreviousclientsdisconnect.Youcanincreasethisvaluetoallowmoreclientconnections. However,
alargevaluemeansmorethreadstobemaintainedevenifmostoftheconnections areidle,anditcouldnegatively
impactquerylatency.Clientapplicationsshouldusetheconnection pooltoavoidtheneedforlargenumberof
sessions.
StartupOptionsforstatestoredDaemon
Thestatestored daemonimplemen tstheImpalastatestoreservice,whichmonitorstheavailabilityofImpalaservices
acrossthecluster,andhandlessituationssuchasnodesbecomingunavailableorbecomingavailableagain.
StartupOptionsforcatalogdDaemon
Thecatalogd daemonimplemen tstheImpalacatalogservice,whichbroadcastsmetadatachangestoalltheImpala
nodeswhenImpalacreatesatable,insertsdata,orperformsotherkindsofDDLandDMLoperations.
Use--load_catalog_in_background optiontocontrolwhenthemetadataofatableisloaded.
â¢Ifsettofalse,themetadataofatableisloadedwhenitisreferencedforthefirsttime.Thismeansthatthefirst
runofaparticular querycanbeslowerthansubsequentruns.StartinginImpala2.2,thedefaultfor
load_catalog_in_background isfalse.
â¢Ifsettotrue,thecatalogserviceattemptstoloadmetadataforatableevenifnoqueryneededthatmetadata.
Sometadatawillpossiblybealreadyloadedwhenthefirstquerythatwouldneeditisrun.However,forthe
followingreasons,werecommend nottosettheoptiontotrue.
âBackgroundloadcaninterferewithquery-specific metadataloading.Thiscanhappenonstartuporafter
invalidatingmetadata,withadurationdepending ontheamountofmetadata,andcanleadtoaseemingly
randomlongrunningqueriesthataredifficulttodiagnose.
âImpalamayloadmetadatafortablesthatarepossiblyneverused,potentiallyincreasingcatalogsizeand
consequen tlymemoryusageforbothcatalogserviceandImpalaDaemon.
StartingImpala
ToactivateImpalaifitisinstalledbutnotyetstarted:
32|ApacheImpalaGuideSettingUpApacheImpalaUsingtheCommand Line
1.SetanynecessaryconfigurationoptionsfortheImpalaservices.SeeModifyingImpalaStartupOptionsfordetails.
2.StartoneinstanceoftheImpalastatestore.ThestatestorehelpsImpalatodistributeworkefficiently,andto
continuerunningintheeventofavailabilityproblemsforotherImpalanodes.Ifthestatestorebecomesunavailable,
Impalacontinuestofunction.
3.StartoneinstanceoftheImpalacatalogservice.
4.StartthemainImpalaserviceononeormoreDataNodes,ideallyonallDataNodestomaximizelocalprocessing
andavoidnetworktrafficduetoremotereads.
OnceImpalaisrunning,youcanconductinteractiveexperimen tsusingtheinstructions inImpalaTutorialsonpage43
andtryUsingtheImpalaShell(impala-shell Command) onpage713.
StartingImpalafromtheCommand Line
TostarttheImpalastatestoreandImpalafromthecommand lineorascript,youcaneitherusetheservice command
oryoucanstartthedaemons directlythroughtheimpalad ,statestored ,andcatalogd executables.
StarttheImpalastatestoreandthenstartimpalad instances.Youcanmodifythevaluestheserviceinitialization
scriptsusewhenstartingthestatestoreandImpalabyediting/etc/default/impala .
Startthestatestoreserviceusingacommand similartothefollowing:
$ sudo service impala-state-store start
Startthecatalogserviceusingacommand similartothefollowing:
$ sudo service impala-catalog start
StarttheImpalaserviceoneachDataNodeusingacommand similartothefollowing:
$ sudo service impala-server start
Note:
InCDH5.7/Impala2.5andhigher,ImpalaUDFsandUDAswritteninC++arepersistedinthemetastore
database.JavaUDFsarealsopersisted,iftheywerecreatedwiththenewCREATE FUNCTION syntax
forJavaUDFs,wheretheJavafunctionargumentandreturntypesareomitted.Java-basedUDFs
createdwiththeoldCREATE FUNCTION syntaxdonotpersistacrossrestartsbecausetheyareheld
inthememoryofthecatalogd daemon. Untilyoure-createsuchJavaUDFsusingthenewCREATE
FUNCTION syntax,youmustreloadthoseJava-basedUDFsbyrunningtheoriginalCREATE FUNCTION
statementsagaineachtimeyourestartthecatalogd daemon. PriortoCDH5.7/Impala2.5the
requirementtoreloadfunctions afterarestartappliedtobothC++andJavafunctions.
Ifanyoftheservicesfailtostart,review:
â¢ReviewingImpalaLogsonpage710
â¢Troubleshooting Impalaonpage730
InstallingImpalawithClouderaManager
BeforeinstallingImpalathroughtheClouderaManagerinterface,makesureallapplicablenodeshavetheappropriate
hardwareconfigurationandlevelsofoperatingsystemandCDH.SeeImpalaRequirementsonpage23fordetails.
ForinformationoninstallingImpalainaClouderaManager-manag edenvironment,see
http://www.cloudera.com/documen tation/enterprise/la test/topics/cm_ig_ins tall_impala.h tml
Managing yourImpalainstallationthroughClouderaManagerhasanumberofadvantages.Forexample,whenyou
makeconfigurationchangestoCDHcomponen tsusingClouderaManager,itautomaticallyapplieschangestothe
ApacheImpalaGuide|33SettingUpApacheImpalaUsingtheCommand Line
copiesofconfigurationfiles,suchashive-site.xml ,thatImpalakeepsunder/etc/impala/conf .Italsosetsup
theHiveMetastoreservicethatisrequiredforImpala.
Insomecases,depending onthelevelofImpala,CDH,andClouderaManager,youmightneedtoaddparticular
componen tconfigurationdetailsinsomeofthefree-formoptionfieldsontheImpalaconfigurationpageswithin
ClouderaManager.InClouderaManager4,thesefieldsarelabelledSafetyValve;inClouderaManager5,theyare
calledAdvancedConfigurationSnippet.
InstallingImpalafromtheCommand Line
BeforeinstallingImpalamanually,makesureallapplicablenodeshavetheappropriatehardwareconfiguration,levels
ofoperatingsystemandCDH,andanyothersoftwareprerequisites.SeeImpalaRequirementsonpage23fordetails.
YoucaninstallImpalaacrossmanyhostsorononehost:
â¢InstallingImpalaacrossmultiplemachines createsadistributedconfiguration.Forbestperformance, installImpala
onallDataNodes.
â¢InstallingImpalaonasinglemachineproducesapseudo-dis tributedcluster.
ToinstallImpalaonahost:
1.InstallCDH,including Hive,asdescribed inInstallingandDeployingUnmanag edCDHUsingtheCommand Line.
2.ConfiguretheHivemetastoretouseanexternaldatabaseasametastore.Impalausesthissamedatabaseforits
owntablemetadata.YoucanchooseeitheraMySQLorPostgreSQLdatabaseasthemetastore.Theprocessfor
configuringeachtypeofdatabaseisdescribed intheCDHInstallationGuide).
Clouderarecommends settingupaHivemetastoreserviceratherthanconnecting directlytothemetastore
database;thisconfigurationisrequiredwhenrunningImpalaunderCDH4.1.Makesurethe
/etc/impala/conf/hive-site.xml filecontainsthefollowingsetting,substitutingtheappropriatehostname
formetastore_server_host:
<property>
<name>hive.metastore.uris</name>
<value>thrift:// metastore_server_host :9083</value>
</property>
<property>
<name>hive.metastore.client.socket.timeout</name>
<value>3600</value>
<description>MetaStore Client socket timeout in seconds</description>
</property>
3.(Optional)IfyouinstalledthefullHivecomponen tonanyhost,youcanverifythatthemetastoreisconfigured
properlybystartingtheHiveconsoleandqueryingforthelistofavailabletables.Onceyouconfirmthattheconsole
starts,exittheconsoletocontinuetheinstallation:
$ hive
Hive history file=/tmp/root/hive_job_log_root_201207272011_678722950.txt
hive> show tables;
table1
table2
hive> quit;
$
4.Confirmthatyourpackagemanagementcommand isawareoftheImpalarepositorysettings,asdescribed in
ImpalaRequirementsonpage23.(ForCDH4,thisisadifferentrepositorythanforCDH.)Youmightneedto
downloadarepoorlistfileintoasystemdirectoryundernea th/etc.
5.Useoneofthefollowingsetsofcommands toinstalltheImpalapackage:
ForRHEL,OracleLinux,orCentOSsystems:
$ sudo yum install impala             # Binaries for daemons
$ sudo yum install impala-server      # Service start/stop script
34|ApacheImpalaGuideSettingUpApacheImpalaUsingtheCommand Line
$ sudo yum install impala-state-store # Service start/stop script
$ sudo yum install impala-catalog     # Service start/stop script
ForSUSEsystems:
$ sudo zypper install impala             # Binaries for daemons
$ sudo zypper install impala-server      # Service start/stop script
$ sudo zypper install impala-state-store # Service start/stop script
$ sudo zypper install impala-catalog     # Service start/stop script
ForDebianorUbuntusystems:
$ sudo apt-get install impala             # Binaries for daemons
$ sudo apt-get install impala-server      # Service start/stop script
$ sudo apt-get install impala-state-store # Service start/stop script
$ sudo apt-get install impala-catalog     # Service start/stop script
Note:Clouderarecommends thatyounotinstallImpalaonanyHDFSNameNode. Installing
ImpalaonNameNodes providesnoadditional datalocality,andexecutingquerieswithsucha
configurationmightcausememorycontentionandnegativelyimpacttheHDFSNameNode.
6.Copytheclienthive-site.xml ,core-site.xml ,hdfs-site.xml ,andhbase-site.xml configurationfiles
totheImpalaconfigurationdirectory,whichdefaultsto/etc/impala/conf .Createthisdirectoryifitdoesnot
alreadyexist.
7.Useoneofthefollowingcommands toinstallimpala-shell onthemachines fromwhichyouwanttoissue
queries.Youcaninstallimpala-shell onanysupportedmachinethatcanconnecttoDataNodesthatarerunning
impalad .
ForRHEL/Cen tOSsystems:
$ sudo yum install impala-shell
ForSUSEsystems:
$ sudo zypper install impala-shell
ForDebian/Ubun tusystems:
$ sudo apt-get install impala-shell
8.Completeanyrequiredorrecommended configuration,asdescribed inPost-InstallationConfigurationforImpala
onpage36.Someoftheseconfigurationchangesaremandatory.
Onceinstallationandconfigurationarecomplete,seeStartingImpalaonpage32forhowtoactivatethesoftwareon
theappropriatenodesinyourcluster.
IfthisisyourfirsttimesettingupandusingImpalainthiscluster,runthroughsomeoftheexercisesinImpalaTutorials
onpage43toverifythatyoucandobasicoperationssuchascreatingtablesandqueryingthem.
ApacheImpalaGuide|35SettingUpApacheImpalaUsingtheCommand Line
Managing Impala
Thefirstpartofthissectiondescribes thefollowingImpalaconfigurationtopics:
â¢TheImpalaService
â¢Post-InstallationConfigurationforImpalaonpage36
â¢ImpalaSecurityonpage82
â¢ModifyingImpalaStartupOptions
Therestofthissectiondescribes howtoconfigureImpalatoacceptconnections fromapplicationsthatusepopular
programmingAPIs:
â¢ConfiguringImpalatoWorkwithODBConpage723
â¢ConfiguringImpalatoWorkwithJDBConpage725
Thistypeofconfigurationisespecially usefulwhenusingImpalaincombinationwithBusinessIntelligencetools,which
usethesestandardinterfacestoquerydifferentkindsofdatabaseandBigDatasystems.
Post-InstallationConfigurationforImpala
Thissectiondescribes themandatoryandrecommended configurationsettingsforImpala.IfImpalaisinstalledusing
ClouderaManager,someoftheseconfigurationsarecompletedautomatically;youmuststillconfigureshort-circuit
readsmanually.IfyouinstalledImpalawithoutClouderaManager,orifyouwanttocustomizeyourenvironment,
considermakingthechangesdescribed inthistopic.
Insomecases,depending onthelevelofImpala,CDH,andClouderaManager,youmightneedtoaddparticular
componen tconfigurationdetailsinoneofthefree-formfieldsontheImpalaconfigurationpageswithinCloudera
Manager.InClouderaManager4,thesefieldsarelabelledSafetyValve;inClouderaManager5,theyarecalled
AdvancedConfigurationSnippet.
â¢Youmustenableshort-circuitreads,whetherornotImpalawasinstalledthroughClouderaManager.Thissetting
goesintheImpalaconfigurationsettings,nottheHadoop-wide settings.
â¢IfyouinstalledImpalainanenvironmentthatisnotmanagedbyClouderaManager,youmustenableblocklocation
tracking,andyoucanoptionallyenablenativechecksumming foroptimalperformance.
â¢IfyoudeployedImpalausingClouderaManagerseeTestingImpalaPerformance onpage601toconfirmproper
configuration.
Mandatory:Short-CircuitReads
Enablingshort-circuitreadsallowsImpalatoreadlocaldatadirectlyfromthefilesystem.Thisremovestheneedto
communic atethroughtheDataNodes,improvingperformance. Thissettingalsominimizesthenumberofadditional
copiesofdata.Short-circuitreadsrequireslibhadoop.so (theHadoopNativeLibrary)tobeaccessible toboththe
serverandtheclient.Youmustinstallitfroman.rpm,.deb,orparceltouseshort-circuitlocalreads.
Note:IfyouuseClouderaManager,youcanenableshort-circuitreadsthroughacheckboxinthe
userinterfaceandthatsettingtakeseffectforImpalaaswell.
ToconfigureDataNodesforshort-circuitreads:
1.Copytheclientcore-site.xml andhdfs-site.xml configurationfilesfromtheHadoopconfigurationdirectory
totheImpalaconfigurationdirectory.ThedefaultImpalaconfigurationlocationis/etc/impala/conf .
2.OnallImpalanodes,configurethefollowingpropertiesinImpala'scopyofhdfs-site.xml asshown:
<property>
    <name>dfs.client.read.shortcircuit</name>
36|ApacheImpalaGuideManaging Impala
    <value>true</value>
</property>
<property>
    <name>dfs.domain.socket.path</name>
    <value>/var/run/hdfs-sockets/dn</value>
</property>
<property>
    <name>dfs.client.file-block-storage-locations.timeout.millis</name>
    <value>10000</value>
</property>
3.If/var/run/hadoop-hdfs/ isgroup-writable,makesureitsgroupisroot.
Note:Ifyouarealsogoingtoenableblocklocationtracking,youcanskipcopyingconfiguration
filesandrestartingDataNodesandgostraighttoOptional:BlockLocationTracking.Configuring
short-circuitreadsandblocklocationtrackingrequirethesameprocessofcopyingfilesand
restartingservices,soyoucancompletethatprocessoncewhenyouhavecompletedall
configurationchanges.Whetheryoucopyfilesandrestartservicesnoworduringconfiguring
blocklocationtracking,short-circuitreadsarenotenableduntilyoucompletethosefinalsteps.
4.Afterapplyingthesechanges,restartallDataNodes.
Mandatory:BlockLocationTracking
EnablingblocklocationmetadataallowsImpalatoknowwhichdiskdatablocksarelocatedon,allowingbetterutilization
oftheunderlying disks.Impalawillnotstartunlessthissettingisenabled.
Toenableblocklocationtracking:
1.ForeachDataNode,addingthefollowingtothehdfs-site.xml file:
<property>
  <name>dfs.datanode.hdfs-blocks-metadata.enabled</name>
  <value>true</value>
</property> 
2.Copytheclientcore-site.xml andhdfs-site.xml configurationfilesfromtheHadoopconfigurationdirectory
totheImpalaconfigurationdirectory.ThedefaultImpalaconfigurationlocationis/etc/impala/conf .
3.Afterapplyingthesechanges,restartallDataNodes.
Optional:NativeChecksumming
Enablingnativechecksumming causesImpalatouseanoptimizednativelibraryforcomputing checksums,ifthatlibrary
isavailable.
Toenablenativechecksumming:
IfyouinstalledCDHfrompackages,thenativechecksumming libraryisinstalledandsetupcorrectly.Insuchacase,
noadditional stepsarerequired.Conversely,ifyouinstalledbyothermeans,nativechecksumming maynotbeavailable
duetomissingsharedobjects.Findingthemessage"Unable to load native-hadoop library for your
platform... using builtin-java classes where applicable "intheImpalalogsindicatesnative
checksumming maybeunavailable.Toenablenativechecksumming,youmustbuildandinstalllibhadoop.so (the
HadoopNativeLibrary).
ApacheImpalaGuide|37Managing Impala
ImpalaUpgradeConsiderations
ConvertingLegacyUDFsDuringUpgradetoCDH5.12orHigher
InCDH5.7/Impala2.5andhigher,theCREATEFUNCTIONStatementonpage228isavailableforcreatingJava-based
UDFs.UDFscreatedwiththenewsyntaxpersistacrossImpalarestarts,andaremorecompatiblewithHiveUDFs.
BecausethereplicationfeaturesinCDH5.12andhigheronlyworkwiththenew-stylesyntax,convertanyolderJava
UDFstousethenewsyntaxatthesametimeyouupgradetoCDH5.12orhigher.
Followthesestepstoconvertold-styleJavaUDFstothenewpersistentkind:
â¢UseSHOW FUNCTIONS toidentifyallUDFsandUDAs.
â¢Foreachfunction, useSHOW CREATE FUNCTION andsavethestatementinascriptfile.
â¢ForJavaUDFs,changetheoutputofSHOW CREATE FUNCTION tousethenewCREATE FUNCTION syntax(without
argumenttypes),whichmakestheUDFpersistent.
â¢Foreachfunction, dropitandre-createit,usingthenewCREATE FUNCTION syntaxforallJavaUDFs.
Handling LargeRowsDuringUpgradetoCDH5.13/Impala2.10orHigher
InCDH5.13/Impala2.10andhigher,thehandlingofmemorymanagementforlargecolumnvaluesisdifferentthan
inpreviousreleases.Somequeriesthatsucceeded previouslymightnowfailimmediatelywithanerrormessage.The
--read_size optionnolongerneedstobeincreasedfromitsdefaultof8MBforqueriesagainsttableswithhuge
columnvalues.Instead,thequeryoptionMAX_ROW_SIZE letsyoufine-tune thisvalueatthelevelofindividual queries
orsessions. ThedefaultforMAX_ROW_SIZE is512KB.Ifyourqueriesprocessrowswithcolumnvaluestotallingmore
than512KB,youmightneedtotakeactiontoavoidproblemsafterupgrading.
Followthesestepstoverifyifyourdeploymentneedsanyspecialsetuptodealwiththenewwayofdealingwithlarge
rows:
1.Checkifyourimpalad daemons arealreadyrunningwithalarger-than-normal valueforthe--read_size
configurationsetting.
2.ExaminealltablestofindifanyhaveSTRINGvaluesthatarehundredsofkilobytesormoreinlength.This
informationisavailableundertheMax Size columnintheoutputfromtheSHOW TABLE STATS statement,
aftertheCOMPUTE STATS statementhasbeenrunonthetable.Inthefollowingexample,theS1columnwitha
maximumlengthof700006couldcauseanissuebyitself,orifacombinationofvaluesfromtheS1,S2,andS3
columnsexceededthe512KBMAX_ROW_SIZE value.
show column stats big_strings;
+--------+--------+------------------+--------+----------+-------------------+
| Column | Type   | #Distinct Values | #Nulls | Max Size | Avg Size          |
+--------+--------+------------------+--------+----------+-------------------+
| x      | BIGINT | 30000            | -1     | 8        | 8                 |
| s1     | STRING | 30000            | -1     | 700006   | 392625            |
| s2     | STRING | 30000            | -1     | 10532    | 9232.6669921875   |
| s3     | STRING | 30000            | -1     | 103      | 87.66670227050781 |
+--------+--------+------------------+--------+----------+-------------------+
3.Foreachcandidatetable,runaquerytomaterializethelargeststringvaluesfromthelargestcolumnsallatonce.
CheckifthequeryfailswithamessagesuggestingtosettheMAX_ROW_SIZE queryoption.
select count(distinct s1, s2, s3) from little_strings;
+----------------------------+
| count(distinct s1, s2, s3) |
+----------------------------+
| 30000                      |
38|ApacheImpalaGuideImpalaUpgradeConsiderations
+----------------------------+
select count(distinct s1, s2, s3) from big_strings;
WARNINGS: Row of size 692.13 KB could not be materialized in plan node with id 1.
  Increase the max_row_size query option (currently 512.00 KB) to process larger rows.
Ifanyofyourtablesareaffected,makesuretheMAX_ROW_SIZE issetlargeenoughtoallowallqueriesagainstthe
affectedtablestodealwiththelargecolumnvalues:
â¢InSQLscriptsrunbyimpala-shell withthe-qor-foptions,orininteractiveimpala-shell sessions, issue
astatementSET MAX_ROW_SIZE= large_enough_size beforetherelevantqueries:
$ impala-shell -i localhost -q \
  'set max_row_size=1mb; select count(distinct s1, s2, s3) from big_strings'
â¢IflargecolumnvaluesarecommontomanyofyourtablesanditisnotpracticaltosetMAX_ROW_SIZE onlyfora
limitednumberofqueriesorscripts,usethe--default_query_options configurationsettingforallyour
impalad daemons, andincludethelargerMAX_ROW_SIZE settingaspartoftheargumenttothatsetting.For
example:
impalad --default_query_options='max_row_size=1gb;appx_count_distinct=true'
â¢Ifyourdeploymentusesanon-defaultvalueforthe--read_size configurationsetting,removethatsettingand
letImpalausethedefault.Ahighvaluefor--read_size couldcausehighermemoryconsumptioninCDH5.13
/Impala2.10andhigherthaninpreviousversions.The--read_size settingstillcontrolstheHDFSI/Oreadsize
(whichisrarelyifevernecessarytochange),butnolongeraffectsthespill-to-diskbuffersize.
ChangeImpalacatalogdHeapwhenUpgradingfromCDH5.6orLower
ThedefaultheapsizeforImpalacatalogd haschangedinCDH5.7/Impala2.5andhigher:
â¢Before5.7,bydefaultcatalogd wasusingtheJVM'sdefaultheapsize,whichisthesmallerof1/4thofthephysical
memoryor32GB.
â¢StartingwithCDH5.7.0,thedefaultcatalogd heapsizeis4GB.
Forexample,onahostwith128GBphysicalmemorythiswillresultincatalogd heapdecreasingfrom32GBto4
GB.
Forschemaswithlargenumbersoftables,partitions, anddatafiles,thecatalogd daemonmightencounteran
out-of-memor yerror.Topreventtheerror,increasethememorylimitforthecatalogd daemon:
1.Checkcurrentmemoryusageforthecatalogd daemonbyrunningthefollowingcommands onthehostwhere
thatdaemonrunsonyourcluster:
  jcmd catalogd_pid  VM.flags
  jmap -heap catalogd_pid
2.Decideonalargeenoughvalueforthecatalogd heap.
â¢OnsystemsmanagedbyClouderaManager,includethisvalueintheconfigurationfieldJavaHeapSizeof
CatalogServerinBytes(ClouderaManager5.7andhigher),orImpalaCatalogServerEnvironmentAdvanced
ConfigurationSnippet(SafetyValve)(priortoClouderaManager5.7).ThenrestarttheImpalaservice.
â¢OnsystemsnotmanagedbyClouderaManager,puttheJAVA_TOOL_OPTIONS environmentvariablesetting
intothestartupscriptforthecatalogd daemon, thenrestartthecatalogd daemon.
ApacheImpalaGuide|39ImpalaUpgradeConsiderations
Forexample,thefollowingenvironmentvariablesettingspecifiesthemaximumheapsizeof8GB.
  JAVA_TOOL_OPTIONS="-Xmx8g"
3.Usethesamejcmdandjmapcommands asearliertoverifythatthenewsettingsareineffect.
ListofReservedWordsUpdatedinCDH6.0/Impala3.0
ThelistofImpalaReservedWordsonpage745inImpalawasupdatedinCDH6.0/Impala3.0.Ifyouneedtousea
reservedwordasanidentifier,e.g.atablename,enclosethewordinback-ticks.
IfyouneedtousethereservedwordsfrompreviousversionsofCDH,settheimpaladandcatalogdstartupoption,
--reserved_words_version ,to"2.11.0" .
DecimalV2UsedbyDefaultinCDH6.0/Impala3.0
InImpala,twodifferentbehaviorsofDECIMAL typesaresupported.InCDH6.0/Impala3.0,DECIMAL V2isusedby
default.SeeDECIMALDataTypefordetailinformation.
IfyouneedtocontinueusingthefirstversionoftheDECIMAL typeforthebackwardcompatibilityofyourqueries,set
theDECIMAL_V2 queryoptiontoFALSE:
SET DECIMAL_V2=FALSE;
BehaviorofColumnAliasesChangedinCDH6.0/Impala3.0
ToconformtotheSQLstandard,ImpalanolongerperformsaliassubstitutioninthesubexpressionsofGROUP BY ,
HAVING,andORDER BY .SeeOverviewofImpalaAliasesonpage192forexamplesofsupportedandunsupport ed
aliasessyntax.
DefaultPARQUET_ARRA Y_RESOLUTIONChangedinCDH6.0/Impala3.0
ThedefaultvalueforthePARQUET_ARRAY_RESOLUTION waschangedtoTHREE_LEVEL inCDH6.0/Impala3.0,to
matchtheParquetstandard3-levelencoding.
SeePARQUET_RE SOLUTIONQueryoptionfortheinformationaboutthequeryoption.
EnableClusteringHintforInserts
InCDH6.0/Impala3.0,theclusteredhintisenabledbydefault.Thehintaddsalocalsortbythepartitioning columns
toaqueryplan.
Theclustered hintisonlyeffectiveforHDFSandKudutables.
Asinpreviousversions,thenoclustered hintpreventsclustering.Ifatablehasorderingcolumnsdefined,the
noclustered hintisignoredwithawarning.
DeprecatedQueryOptionsRemovedinCDH6.0/Impala3.0
Thefollowingqueryoptionshavebeendeprecatedforseveralreleasesandremoved:
40|ApacheImpalaGuideImpalaUpgradeConsiderations
â¢DEFAULT_ORDER_BY_LIMIT
â¢ABORT_ON_DEFAULT_LIMIT_EXCEEDED
â¢V_CPU_CORES
â¢RESERVATION_REQUEST_TIMEOUT
â¢RM_INITIAL_MEM
â¢SCAN_NODE_CODEGEN_THRESHOLD
â¢MAX_IO_BUFFERS
â¢RM_INITIAL_MEM
â¢DISABLE_CACHED_READS
refresh_after_connectImpalaShellOptionRemovedinCDH6.0/Impala3.0
Thedeprecatedrefresh_after_connect optionwasremovedfromImpalaShellinCDH6.0/Impala3.0
ReturnTypeChangedforEXTRACTandDATE_PARTFunctions inCDH6.0/Impala3.0
ThefollowingchangesweremadetotheEXTRACT andDATE_PART functions:
â¢TheoutputtypeoftheEXTRACT andDATE_PART functions waschangedtoBIGINT.
â¢ExtractingthemillisecondpartfromaTIMESTAMP returnsthesecondscomponen tandthemillisecondscomponen t.
Forexample,EXTRACT (CAST('2006-05-12 18:27:28.123456789' AS TIMESTAMP), 'MILLISECOND')
willreturn28123.
ImpalaRoleswithSELECTorINSERTPrivilegeReceiveREFRESHPrivilegeDuringtheUpgrade
toCDH5.16/CDH6.1
DuetotheSentryandImpalafinegrainedprivilegesfeatureinCDH5.16/CDH6.1,ifarolehastheSELECTorINSERT
privilegeonanobjectinImpalabeforeupgradingtoCDH5.16/CDH6.1,thatrolewillautomaticallygettheREFRESH
privilegeduringtheupgrade.
PortChangeforSHUTDOWNCommand
IfyouusedtheSHUTDOWN command inCDH6.1,andspecified aportexplicitly,changetheportnumberparameter,
inCDH6.2,tousetheKRPCport.
ChangeinClientConnection Timeout
Thedefaultbehaviorofclientconnection timeoutchanged.
InCDH6.2andlower,clientwaitedindefinitelytoopenthenewsessionifthemaximumnumberofthreadsspecified
by--fe_service_threads hasbeenallocated.
InCDH6.3andhigher,anewstartupflag,--accepted_client_cnxn_timeout ,wasaddedtocontrolhowthe
servershouldtreatnewconnection requestsifwehaverunoutoftheconfigurednumberofserverthreads.
If--accepted_client_cnxn_timeout > 0 ,newconnection requestsarerejectedafterthespecified timeout.
If--accepted_client_cnxn_timeout=0 ,clientswaitsindefinitelytoconnecttoImpala.Youcanusethissetting
torestorethepre-CDH6.3behavior.
Thedefaulttimeoutis5minutes.
ApacheImpalaGuide|41ImpalaUpgradeConsiderations
DefaultSettingChanges
DefaultValue Setting ReleaseChanged
true --compact_catalog_topic impalad flag CDH5.15&CDH6.1/Impala2.12
20000 --max_cached_file_handles impalad flag CDH6.1/Impala2.12
THREE_LEVEL PARQUET_ARRAY_RESOLUTION queryoption CDH6.0/Impala3.0
TRUE DECIMAL_V2 queryoption CDH6.0/Impala3.0
42|ApacheImpalaGuideImpalaUpgradeConsiderations
ImpalaTutorials
Thissectionincludestutorialscenarios thatdemonstratehowtobeginusingImpalaoncethesoftwareisinstalled.It
focusesontechniques forloadingdata,becauseonceyouhavesomedataintablesandcanquerythatdata,youcan
quicklyprogresstomoreadvancedImpalafeatures.
Note:
Wherepractical,thetutorialstakeyoufromâgroundzeroâtohavingthedesiredImpalatablesand
data.Insomecases,youmightneedtodownloadadditional filesfromoutsidesources,setupadditional
softwarecomponen ts,modifycommands orscriptstofityourownconfiguration,orsubstituteyour
ownsampledata.
Beforetryingthesetutoriallessons,installImpalausingoneoftheseprocedures:
â¢IfyoualreadyhavesomeCDHenvironmentsetupandjustneedtoaddImpalatoit,addtheImpalaserviceusing
theinstructions inAddingaService.MakesuretoalsoinstalltheHivemetastoreserviceifyoudonotalready
haveHiveconfigured.
â¢TosetupImpalaandallitsprerequisitesatonce,inaminimalconfigurationthatyoucanuseforsmall-scale
experimen ts,setuptheClouderaQuickStartVM,whichincludesCDHandImpalaonCentOS.Usethissingle-node
VMtotryoutbasicSQLfunctionality ,notanythingrelatedtoperformance andscalability.Formoreinformation,
seetheClouderaQuickStartVM.
TutorialsforGettingStarted
ThesetutorialsdemonstratethebasicsofusingImpala.Theyareintendedforfirst-timeusers,andfortryingoutImpala
onanynewclustertomakesurethemajorcomponen tsareworkingcorrectly.
ExploreaNewImpalaInstance
Thistutorialdemonstratestechniques forfindingyourwayaroundthetablesanddatabasesofanunfamiliar(possibly
empty)Impalainstance.
WhenyouconnecttoanImpalainstanceforthefirsttime,youusetheSHOW DATABASES andSHOW TABLES statements
toviewthemostcommontypesofobjects.Also,calltheversion() functiontoconfirmwhichversionofImpalayou
arerunning;theversionnumberisimportantwhenconsulting documen tationanddealingwithsupportissues.
AcompletelyemptyImpalainstancecontainsnotables,butstillhastwodatabases:
â¢default ,wherenewtablesarecreatedwhenyoudonotspecifyanyotherdatabase.
â¢_impala_builtins ,asystemdatabaseusedtoholdallthebuilt-infunctions.
Thefollowingexampleshowshowtoseetheavailabledatabases,andthetablesineach.Ifthelistofdatabasesor
tablesislong,youcanusewildcardnotationtolocatespecificdatabasesortablesbasedontheirnames.
$ impala-shell -i localhost --quiet
Starting Impala Shell without Kerberos authentication
Welcome to the Impala shell. Press TAB twice to see a list of available commands.
Copyright (c) 2012 Cloudera, Inc. All rights reserved.
(Shell build version: Impala Shell v...
[localhost:21000] > select version();
+-------------------------------------------
| version()
+-------------------------------------------
| impalad version ...
| Built on ...
ApacheImpalaGuide|43ImpalaTutorials
+-------------------------------------------
[localhost:21000] > show databases;
+--------------------------+
| name                     |
+--------------------------+
| _impala_builtins         |
| ctas                     |
| d1                       |
| d2                       |
| d3                       |
| default                  |
| explain_plans            |
| external_table           |
| file_formats             |
| tpc                      |
+--------------------------+
[localhost:21000] > select current_database();
+--------------------+
| current_database() |
+--------------------+
| default            |
+--------------------+
[localhost:21000] > show tables;
+-------+
| name  |
+-------+
| ex_t  |
| t1    |
+-------+
[localhost:21000] > show tables in d3;
[localhost:21000] > show tables in tpc;
+------------------------+
| name                   |
+------------------------+
| city                   |
| customer               |
| customer_address       |
| customer_demographics  |
| household_demographics |
| item                   |
| promotion              |
| store                  |
| store2                 |
| store_sales            |
| ticket_view            |
| time_dim               |
| tpc_tables             |
+------------------------+
[localhost:21000] > show tables in tpc like 'customer*';
+-----------------------+
| name                  |
+-----------------------+
| customer              |
| customer_address      |
| customer_demographics |
+-----------------------+
Onceyouknowwhattablesanddatabasesareavailable,youdescendintoadatabasewiththeUSEstatement.To
understandthestructureofeachtable,youusetheDESCRIBE command. Onceinsideadatabase,youcanissue
statementssuchasINSERTandSELECTthatoperateonparticular tables.
ThefollowingexampleexploresadatabasenamedTPCwhosenamewelearnedinthepreviousexample.Itshows
howtofilterthetablenameswithinadatabasebasedonasearchstring,examinethecolumnsofatable,andrun
queriestoexaminethecharacteristicsofthetabledata.Forexample,foranunfamiliartableyoumightwanttoknow
thenumberofrows,thenumberofdifferentvaluesforacolumn,andotherpropertiessuchaswhetherthecolumn
44|ApacheImpalaGuideImpalaTutorials
containsanyNULLvalues.Whensampling theactualdatavaluesfromatable,useaLIMITclausetoavoidexcessive
outputifthetablecontainsmorerowsordistinctvaluesthanyouexpect.
[localhost:21000] > use tpc;
[localhost:21000] > show tables like '*view*';
+-------------+
| name        |
+-------------+
| ticket_view |
+-------------+
[localhost:21000] > describe city;
+-------------+--------+---------+
| name        | type   | comment |
+-------------+--------+---------+
| id          | int    |         |
| name        | string |         |
| countrycode | string |         |
| district    | string |         |
| population  | int    |         |
+-------------+--------+---------+
[localhost:21000] > select count(*) from city;
+----------+
| count(*) |
+----------+
| 0        |
+----------+
[localhost:21000] > desc customer;
+------------------------+--------+---------+
| name                   | type   | comment |
+------------------------+--------+---------+
| c_customer_sk          | int    |         |
| c_customer_id          | string |         |
| c_current_cdemo_sk     | int    |         |
| c_current_hdemo_sk     | int    |         |
| c_current_addr_sk      | int    |         |
| c_first_shipto_date_sk | int    |         |
| c_first_sales_date_sk  | int    |         |
| c_salutation           | string |         |
| c_first_name           | string |         |
| c_last_name            | string |         |
| c_preferred_cust_flag  | string |         |
| c_birth_day            | int    |         |
| c_birth_month          | int    |         |
| c_birth_year           | int    |         |
| c_birth_country        | string |         |
| c_login                | string |         |
| c_email_address        | string |         |
| c_last_review_date     | string |         |
+------------------------+--------+---------+
[localhost:21000] > select count(*) from customer;
+----------+
| count(*) |
+----------+
| 100000   |
+----------+
[localhost:21000] > select count(distinct c_birth_month) from customer;
+-------------------------------+
| count(distinct c_birth_month) |
+-------------------------------+
| 12                            |
+-------------------------------+
[localhost:21000] > select count(*) from customer where c_email_address is null;
+----------+
| count(*) |
+----------+
| 0        |
+----------+
[localhost:21000] > select distinct c_salutation from customer limit 10;
+--------------+
| c_salutation |
+--------------+
| Mr.          |
| Ms.          |
ApacheImpalaGuide|45ImpalaTutorials
| Dr.          |
|              |
| Miss         |
| Sir          |
| Mrs.         |
+--------------+
Whenyougraduatefromread-only exploration,youusestatementssuchasCREATE DATABASE andCREATE TABLE
tosetupyourowndatabaseobjects.
Thefollowingexampledemonstratescreatinganewdatabaseholdinganewtable.Although thelastexampleended
insidetheTPCdatabase,thenewEXPERIMENTS databaseisnotnestedinsideTPC;alldatabasesarearrangedina
singletop-levellist.
[localhost:21000] > create database experiments;
[localhost:21000] > show databases;
+--------------------------+
| name                     |
+--------------------------+
| _impala_builtins         |
| ctas                     |
| d1                       |
| d2                       |
| d3                       |
| default                  |
| experiments              |
| explain_plans            |
| external_table           |
| file_formats             |
| tpc                      |
+--------------------------+
[localhost:21000] > show databases like 'exp*';
+---------------+
| name          |
+---------------+
| experiments   |
| explain_plans |
+---------------+
Thefollowingexamplecreatesanewtable,T1.Toillustrateacommonmistake,itcreatesthistableinsidethewrong
database,theTPCdatabasewherethepreviousexampleended.TheALTER TABLE statementletsyoumovethetable
totheintendeddatabase,EXPERIMENTS ,aspartofarenameoperation.TheUSEstatementisalwaysneededtoswitch
toanewdatabase,andthecurrent_database() functionconfirmswhichdatabasethesessionisin,toavoidthese
kindsofmistakes.
[localhost:21000] > create table t1 (x int);
[localhost:21000] > show tables;
+------------------------+
| name                   |
+------------------------+
| city                   |
| customer               |
| customer_address       |
| customer_demographics  |
| household_demographics |
| item                   |
| promotion              |
| store                  |
| store2                 |
| store_sales            |
| t1                     |
| ticket_view            |
| time_dim               |
| tpc_tables             |
+------------------------+
[localhost:21000] > select current_database();
+--------------------+
| current_database() |
46|ApacheImpalaGuideImpalaTutorials
+--------------------+
| tpc                |
+--------------------+
[localhost:21000] > alter table t1 rename to experiments.t1;
[localhost:21000] > use experiments;
[localhost:21000] > show tables;
+------+
| name |
+------+
| t1   |
+------+
[localhost:21000] > select current_database();
+--------------------+
| current_database() |
+--------------------+
| experiments        |
+--------------------+
Foryourinitialexperimen tswithtables,youcanuseoneswithjustafewcolumnsandafewrows,andtext-format
datafiles.
Note:Asyougraduatetomorerealisticscenarios, youwillusemoreelaboratetableswithmany
columns,featuressuchaspartitioning ,andfileformatssuchasParquet.Whendealingwithrealistic
datavolumes,youwillbringindatausingLOAD DATA orINSERT ... SELECT statementstooperate
onmillionsorbillionsofrowsatonce.
Thefollowingexamplesetsupacoupleofsimpletableswithafewrows,andperformsqueriesinvolvingsorting,
aggregatefunctions andjoins.
[localhost:21000] > insert into t1 values (1), (3), (2), (4);
[localhost:21000] > select x from t1 order by x desc;
+---+
| x |
+---+
| 4 |
| 3 |
| 2 |
| 1 |
+---+
[localhost:21000] > select min(x), max(x), sum(x), avg(x) from t1;
+--------+--------+--------+--------+
| min(x) | max(x) | sum(x) | avg(x) |
+--------+--------+--------+--------+
| 1      | 4      | 10     | 2.5    |
+--------+--------+--------+--------+
[localhost:21000] > create table t2 (id int, word string);
[localhost:21000] > insert into t2 values (1, "one"), (3, "three"), (5, 'five');
[localhost:21000] > select word from t1 join t2 on (t1.x = t2.id);
+-------+
| word  |
+-------+
| one   |
| three |
+-------+
Aftercompletingthistutorial,youshouldnowknow:
â¢HowtotellwhichversionofImpalaisrunningonyoursystem.
â¢HowtofindthenamesofdatabasesinanImpalainstance,eitherdisplayingthefulllistorsearchingforspecific
names.
â¢HowtofindthenamesoftablesinanImpaladatabase,eitherdisplayingthefulllistorsearchingforspecificnames.
â¢Howtoswitchbetweendatabasesandcheckwhichdatabaseyouarecurrentlyin.
â¢Howtolearnthecolumnnamesandtypesofatable.
â¢Howtocreatedatabasesandtables,insertsmallamountsoftestdata,andrunsimplequeries.
ApacheImpalaGuide|47ImpalaTutorials
LoadCSVDatafromLocalFiles
Thisscenarioillustrateshowtocreatesomeverysmalltables,suitableforfirst-timeuserstoexperimen twithImpala
SQLfeatures.TAB1andTAB2areloadedwithdatafromfilesinHDFS.AsubsetofdataiscopiedfromTAB1intoTAB3.
PopulateHDFSwiththedatayouwanttoquery.Tobeginthisprocess,createoneormorenewsubdirectoriesundernea th
youruserdirectoryinHDFS.Thedataforeachtableresidesinaseparatesubdirectory.Substituteyourownusername
forusername whereappropriate.Thisexampleusesthe-poptionwiththemkdiroperationtocreateanynecessary
parentdirectoriesiftheydonotalreadyexist.
$ whoami
username
$ hdfs dfs -ls /user
Found 3 items
drwxr-xr-x   - username username            0 2013-04-22 18:54 /user/username
drwxrwx---   - mapred   mapred              0 2013-03-15 20:11 /user/history
drwxr-xr-x   - hue      supergroup          0 2013-03-15 20:10 /user/hive
$ hdfs dfs -mkdir -p /user/username/sample_data/tab1 /user/username/sample_data/tab2
Hereissomesampledata,fortwotablesnamedTAB1andTAB2.
Copythefollowingcontentto.csvfilesinyourlocalfilesystem:
tab1.csv :
1,true,123.123,2012-10-24 08:55:00
2,false,1243.5,2012-10-25 13:40:00
3,false,24453.325,2008-08-22 09:33:21.123
4,false,243423.325,2007-05-12 22:32:21.33454
5,true,243.325,1953-04-22 09:11:33
tab2.csv :
1,true,12789.123
2,false,1243.5
3,false,24453.325
4,false,2423.3254
5,true,243.325
60,false,243565423.325
70,true,243.325
80,false,243423.325
90,true,243.325
Puteach.csvfileintoaseparateHDFSdirectoryusingcommands likethefollowing,whichusepathsavailableinthe
ImpalaDemoVM:
$ hdfs dfs -put tab1.csv /user/username/sample_data/tab1
$ hdfs dfs -ls /user/username/sample_data/tab1
Found 1 items
-rw-r--r--   1 username username        192 2013-04-02 20:08 
/user/username/sample_data/tab1/tab1.csv
$ hdfs dfs -put tab2.csv /user/username/sample_data/tab2
$ hdfs dfs -ls /user/username/sample_data/tab2
Found 1 items
-rw-r--r--   1 username username        158 2013-04-02 20:09 
/user/username/sample_data/tab2/tab2.csv
Thenameofeachdatafileisnotsignificant.Infact,whenImpalaexaminesthecontentsofthedatadirectoryforthe
firsttime,itconsidersallfilesinthedirectorytomakeupthedataofthetable,regardlessofhowmanyfilesthereare
orwhatthefilesarenamed.
TounderstandwhatpathsareavailablewithinyourownHDFSfilesystemandwhatthepermissions areforthevarious
directoriesandfiles,issuehdfs dfs -ls / andworkyourwaydownthetreedoing-lsoperationsforthevarious
directories.
48|ApacheImpalaGuideImpalaTutorials
Usetheimpala-shell command tocreatetables,eitherinteractivelyorthroughaSQLscript.
Thefollowingexampleshowscreatingthreetables.Foreachtable,theexampleshowscreatingcolumnswithvarious
attributessuchasBooleanorintegertypes.Theexamplealsoincludescommands thatprovideinformationabouthow
thedataisformatted,suchasrowsterminatingwithcommas,whichmakessenseinthecaseofimporting datafrom
a.csvfile.Wherewealreadyhave.csvfilescontainingdataintheHDFSdirectorytree,wespecifythelocationof
thedirectorycontainingtheappropriate.csvfile.Impalaconsidersallthedatafromallthefilesinthatdirectoryto
representthedataforthetable.
DROP TABLE IF EXISTS tab1;
-- The EXTERNAL clause means the data is located outside the central location
-- for Impala data files and is preserved when the associated Impala table is dropped.
-- We expect the data to already exist in the directory specified by the LOCATION clause.
CREATE EXTERNAL TABLE tab1
(
   id INT,
   col_1 BOOLEAN,
   col_2 DOUBLE,
   col_3 TIMESTAMP
)
ROW FORMAT DELIMITED FIELDS TERMINATED BY ','
LOCATION '/user/username/sample_data/tab1';
DROP TABLE IF EXISTS tab2;
-- TAB2 is an external table, similar to TAB1.
CREATE EXTERNAL TABLE tab2
(
   id INT,
   col_1 BOOLEAN,
   col_2 DOUBLE
)
ROW FORMAT DELIMITED FIELDS TERMINATED BY ','
LOCATION '/user/username/sample_data/tab2';
DROP TABLE IF EXISTS tab3;
-- Leaving out the EXTERNAL clause means the data will be managed
-- in the central Impala data directory tree. Rather than reading
-- existing data files when the table is created, we load the
-- data after creating the table.
CREATE TABLE tab3
(
   id INT,
   col_1 BOOLEAN,
   col_2 DOUBLE,
   month INT,
   day INT
)
ROW FORMAT DELIMITED FIELDS TERMINATED BY ',';
Note:GettingthroughtheseCREATE TABLE statementssuccessfullyisanimportantvalidationstep
toconfirmeverythingisconfiguredcorrectlywiththeHivemetastoreandHDFSpermissions. Ifyou
receiveanyerrorsduringtheCREATE TABLE statements:
â¢Makesurethehive.metastore.warehouse.dir propertypointstoadirectorythatImpala
canwriteto.Theownershipshouldbehive:hive ,andtheimpalausershouldalsobeamember
ofthehivegroup.
â¢Ifthevalueofhive.metastore.warehouse.dir isdifferentintheClouderaManagerdialogs
andintheHiveshell,youmightneedtodesignatethehostsrunningimpalad withtheâgatewayâ
roleforHive,anddeploytheclientconfigurationfilestothosehosts.
PointanImpalaTableatExistingDataFiles
AconvenientwaytosetupdataforImpalatoaccessistouseanexternaltable,wherethedataalreadyexistsinaset
ofHDFSfilesandyoujustpointtheImpalatableatthedirectorycontainingthosefiles.Forexample,youmightrunin
ApacheImpalaGuide|49ImpalaTutorials
impala-shell a*.sqlfilewithcontentssimilartothefollowing,tocreateanImpalatablethataccessesanexisting
datafileusedbyHive.
Thefollowingexamplessetup2tables,referencingthepathsandsampledatafromthesampleTPC-DSkitforImpala.
Forhistoricalreasons,thedataphysicallyresidesinanHDFSdirectorytreeunder/user/hive ,although thisparticular
dataisentirelymanagedbyImpalaratherthanHive.Whenwecreateanexternaltable,wespecifythedirectory
containingoneormoredatafiles,andImpalaqueriesthecombined contentofallthefilesinsidethatdirectory.Here
ishowweexaminethedirectoriesandfileswithintheHDFSfilesystem:
$ cd ~/username/datasets
$ ./tpcds-setup.sh
... Downloads and unzips the kit, builds the data and loads it into HDFS ...
$ hdfs dfs -ls /user/hive/tpcds/customer
Found 1 items
-rw-r--r--   1 username supergroup   13209372 2013-03-22 18:09 
/user/hive/tpcds/customer/customer.dat
$ hdfs dfs -cat /user/hive/tpcds/customer/customer.dat | more
1|AAAAAAAABAAAAAAA|980124|7135|32946|2452238|2452208|Mr.|Javier|Lewis|Y|9|12|1936|CHILE||Javie
r.Lewis@VFAxlnZEvOx.org|2452508|
2|AAAAAAAACAAAAAAA|819667|1461|31655|2452318|2452288|Dr.|Amy|Moses|Y|9|4|1966|TOGO||Amy.Moses@
Ovk9KjHH.com|2452318|
3|AAAAAAAADAAAAAAA|1473522|6247|48572|2449130|2449100|Miss|Latisha|Hamilton|N|18|9|1979|NIUE||
Latisha.Hamilton@V.com|2452313|
4|AAAAAAAAEAAAAAAA|1703214|3986|39558|2450030|2450000|Dr.|Michael|White|N|7|6|1983|MEXICO||Mic
hael.White@i.org|2452361|
5|AAAAAAAAFAAAAAAA|953372|4470|36368|2449438|2449408|Sir|Robert|Moran|N|8|5|1956|FIJI||Robert.
Moran@Hh.edu|2452469|
...
HereisaSQLscripttosetupImpalatablespointingtosomeofthesedatafilesinHDFS.(ThescriptintheVMsetsup
tableslikethisthroughHive;ignorethosetablesforpurposes ofthisdemonstration.)Savethefollowingas
customer_setup.sql :
--
-- store_sales fact table and surrounding dimension tables only
--
create database tpcds;
use tpcds;
drop table if exists customer;
create external table customer
(
    c_customer_sk             int,
    c_customer_id             string,
    c_current_cdemo_sk        int,
    c_current_hdemo_sk        int,
    c_current_addr_sk         int,
    c_first_shipto_date_sk    int,
    c_first_sales_date_sk     int,
    c_salutation              string,
    c_first_name              string,
    c_last_name               string,
    c_preferred_cust_flag     string,
    c_birth_day               int,
    c_birth_month             int,
    c_birth_year              int,
    c_birth_country           string,
    c_login                   string,
    c_email_address           string,
    c_last_review_date        string
)
row format delimited fields terminated by '|'
location '/user/hive/tpcds/customer';
drop table if exists customer_address;
create external table customer_address
(
    ca_address_sk             int,
    ca_address_id             string,
    ca_street_number          string,
50|ApacheImpalaGuideImpalaTutorials
    ca_street_name            string,
    ca_street_type            string,
    ca_suite_number           string,
    ca_city                   string,
    ca_county                 string,
    ca_state                  string,
    ca_zip                    string,
    ca_country                string,
    ca_gmt_offset             float,
    ca_location_type          string
)
row format delimited fields terminated by '|'
location '/user/hive/tpcds/customer_address';
Wewouldrunthisscriptwithacommand suchas:
impala-shell -i localhost -f customer_setup.sql
DescribetheImpalaTable
NowthatyouhaveupdatedthedatabasemetadatathatImpalacaches,youcanconfirmthattheexpectedtablesare
accessible byImpalaandexaminetheattributesofoneofthetables.Wecreatedthesetablesinthedatabasenamed
default .Ifthetableswereinadatabaseotherthanthedefault,wewouldissueacommanduse db_name toswitch
tothatdatabasebeforeexaminingorqueryingitstables.Wecouldalsoqualifythenameofatablebyprepending the
databasename,forexampledefault.customer anddefault.customer_name .
[impala-host:21000] > show databases
Query finished, fetching results ...
default
Returned 1 row(s) in 0.00s
[impala-host:21000] > show tables
Query finished, fetching results ...
customer
customer_address
Returned 2 row(s) in 0.00s
[impala-host:21000] > describe customer_address
+------------------+--------+---------+
| name             | type   | comment |
+------------------+--------+---------+
| ca_address_sk    | int    |         |
| ca_address_id    | string |         |
| ca_street_number | string |         |
| ca_street_name   | string |         |
| ca_street_type   | string |         |
| ca_suite_number  | string |         |
| ca_city          | string |         |
| ca_county        | string |         |
| ca_state         | string |         |
| ca_zip           | string |         |
| ca_country       | string |         |
| ca_gmt_offset    | float  |         |
| ca_location_type | string |         |
+------------------+--------+---------+
Returned 13 row(s) in 0.01
QuerytheImpalaTable
Youcanquerydatacontainedinthetables.Impalacoordinatesthequeryexecutionacrossasinglenodeormultiple
nodesdepending onyourconfiguration,withouttheoverheadofrunningMapReducejobstoperformtheintermediate
processing.
ThereareavarietyofwaystoexecutequeriesonImpala:
â¢Usingtheimpala-shell command ininteractivemode:
$ impala-shell -i impala-host
Connected to localhost:21000
ApacheImpalaGuide|51ImpalaTutorials
[impala-host:21000] > select count(*) from customer_address;
50000
Returned 1 row(s) in 0.37s
â¢Passingasetofcommands containedinafile:
$ impala-shell -i impala-host -f myquery.sql
Connected to localhost:21000
50000
Returned 1 row(s) in 0.19s
â¢Passingasinglecommand totheimpala-shell command. Thequeryisexecuted,theresultsarereturned,and
theshellexits.Makesuretoquotethecommand, preferablywithsinglequotationmarkstoavoidshellexpansion
ofcharacterssuchas*.
$ impala-shell -i impala-host -q 'select count(*) from customer_address'
Connected to localhost:21000
50000
Returned 1 row(s) in 0.29s
DataLoadingandQueryingExamples
Thissectiondescribes howtocreatesomesampletablesandloaddataintothem.Thesetablescanthenbequeried
usingtheImpalashell.
LoadingData
Loadingdatainvolves:
â¢Establishing adataset.Theexamplebelowuses.csvfiles.
â¢Creatingtablestowhichtoloaddata.
â¢Loadingthedataintothetablesyoucreated.
SampleQueries
Torunthesesamplequeries,createaSQLqueryfilequery.sql ,copyandpasteeachqueryintothequeryfile,and
thenrunthequeryfileusingtheshell.Forexample,torunquery.sql onimpala-host ,youmightusethecommand:
impala-shell.sh -i impala-host -f query.sql
Theexamplesandresultsbelowassumeyouhaveloadedthesampledataintothetablesasdescribed above.
Example:ExaminingContentsofTables
Let'sstartbyverifyingthatthetablesdocontainthedataweexpect.BecauseImpalaoftendealswithtablescontaining
millionsorbillionsofrows,whenexaminingtablesofunknownsize,includetheLIMITclausetoavoidhugeamounts
ofunnecessar youtput,asinthefinalquery.(Ifyourinteractivequerystartsdisplayinganunexpectedvolumeofdata,
pressCtrl-Cinimpala-shell tocancelthequery.)
SELECT * FROM tab1;
SELECT * FROM tab2;
SELECT * FROM tab2 LIMIT 5;
Results:
+----+-------+------------+-------------------------------+
| id | col_1 | col_2      | col_3                         |
+----+-------+------------+-------------------------------+
| 1  | true  | 123.123    | 2012-10-24 08:55:00           |
| 2  | false | 1243.5     | 2012-10-25 13:40:00           |
| 3  | false | 24453.325  | 2008-08-22 09:33:21.123000000 |
| 4  | false | 243423.325 | 2007-05-12 22:32:21.334540000 |
52|ApacheImpalaGuideImpalaTutorials
| 5  | true  | 243.325    | 1953-04-22 09:11:33           |
+----+-------+------------+-------------------------------+
+----+-------+---------------+
| id | col_1 | col_2         |
+----+-------+---------------+
| 1  | true  | 12789.123     |
| 2  | false | 1243.5        |
| 3  | false | 24453.325     |
| 4  | false | 2423.3254     |
| 5  | true  | 243.325       |
| 60 | false | 243565423.325 |
| 70 | true  | 243.325       |
| 80 | false | 243423.325    |
| 90 | true  | 243.325       |
+----+-------+---------------+
+----+-------+-----------+
| id | col_1 | col_2     |
+----+-------+-----------+
| 1  | true  | 12789.123 |
| 2  | false | 1243.5    |
| 3  | false | 24453.325 |
| 4  | false | 2423.3254 |
| 5  | true  | 243.325   |
+----+-------+-----------+
Example:AggregateandJoin
SELECT tab1.col_1, MAX(tab2.col_2), MIN(tab2.col_2)
FROM tab2 JOIN tab1 USING (id)
GROUP BY col_1 ORDER BY 1 LIMIT 5;
Results:
+-------+-----------------+-----------------+
| col_1 | max(tab2.col_2) | min(tab2.col_2) |
+-------+-----------------+-----------------+
| false | 24453.325       | 1243.5          |
| true  | 12789.123       | 243.325         |
+-------+-----------------+-----------------+
Example:Subquery,AggregateandJoins
SELECT tab2.*
FROM tab2,
(SELECT tab1.col_1, MAX(tab2.col_2) AS max_col2
 FROM tab2, tab1
 WHERE tab1.id = tab2.id
 GROUP BY col_1) subquery1
WHERE subquery1.max_col2 = tab2.col_2;
Results:
+----+-------+-----------+
| id | col_1 | col_2     |
+----+-------+-----------+
| 1  | true  | 12789.123 |
| 3  | false | 24453.325 |
+----+-------+-----------+
Example:INSERTQuery
INSERT OVERWRITE TABLE tab3
SELECT id, col_1, col_2, MONTH(col_3), DAYOFMONTH(col_3)
FROM tab1 WHERE YEAR(col_3) = 2012;
ApacheImpalaGuide|53ImpalaTutorials
QueryTAB3tochecktheresult:
SELECT * FROM tab3;
Results:
+----+-------+---------+-------+-----+
| id | col_1 | col_2   | month | day |
+----+-------+---------+-------+-----+
| 1  | true  | 123.123 | 10    | 24  |
| 2  | false | 1243.5  | 10    | 25  |
+----+-------+---------+-------+-----+
AdvancedTutorials
Thesetutorialswalkyouthroughadvancedscenarios orspecializedfeatures.
AttachinganExternalPartitioned TabletoanHDFSDirectoryStructure
ThistutorialshowshowyoumightsetupadirectorytreeinHDFS,putdatafilesintothelowest-levelsubdirectories,
andthenuseanImpalaexternaltabletoquerythedatafilesfromtheiroriginallocations.
Thetutorialusesatablewithweblogdata,withseparatesubdirectoriesfortheyear,month,day,andhost.For
simplicity ,weuseatinyamountofCSVdata,loadingthesamedataintoeachpartition.
First,wemakeanImpalapartitioned tableforCSVdata,andlookattheunderlying HDFSdirectorystructureto
understandthedirectorystructuretore-createelsewhereinHDFS.Thecolumnsfield1,field2,andfield3
correspondtothecontentsoftheCSVdatafiles.Theyear,month,day,andhostcolumnsareallrepresentedas
subdirectorieswithinthetablestructure,andarenotpartoftheCSVfiles.WeuseSTRINGforeachofthesecolumns
sothatwecanproduceconsistentsubdirectorynames,withleadingzerosforaconsistentlength.
create database external_partitions;
use external_partitions;
create table logs (field1 string, field2 string, field3 string)
  partitioned by (year string, month string , day string, host string)
  row format delimited fields terminated by ',';
insert into logs partition (year="2013", month="07", day="28", host="host1") values 
("foo","foo","foo");
insert into logs partition (year="2013", month="07", day="28", host="host2") values 
("foo","foo","foo");
insert into logs partition (year="2013", month="07", day="29", host="host1") values 
("foo","foo","foo");
insert into logs partition (year="2013", month="07", day="29", host="host2") values 
("foo","foo","foo");
insert into logs partition (year="2013", month="08", day="01", host="host1") values 
("foo","foo","foo");
BackintheLinuxshell,weexaminetheHDFSdirectorystructure.(YourImpaladatadirectorymightbeinadifferent
location;forhistoricalreasons,itissometimesundertheHDFSpath/user/hive/warehouse .)Weusethehdfs
dfs -ls command toexaminethenestedsubdirectoriescorresponding toeachpartitioning column,withseparate
subdirectoriesateachlevel(with=intheirnames)representingthedifferentvaluesforeachpartitioning column.
Whenwegettothelowestlevelofsubdirectory,weusethehdfs dfs -cat command toexaminethedatafileand
seeCSV-formatteddataproducedbytheINSERTstatementinImpala.
$ hdfs dfs -ls /user/impala/warehouse/external_partitions.db
Found 1 items
drwxrwxrwt   - impala hive          0 2013-08-07 12:24 
/user/impala/warehouse/external_partitions.db/logs
$ hdfs dfs -ls /user/impala/warehouse/external_partitions.db/logs
Found 1 items
drwxr-xr-x   - impala hive          0 2013-08-07 12:24 
/user/impala/warehouse/external_partitions.db/logs/year=2013
$ hdfs dfs -ls /user/impala/warehouse/external_partitions.db/logs/year=2013
54|ApacheImpalaGuideImpalaTutorials
Found 2 items
drwxr-xr-x   - impala hive          0 2013-08-07 12:23 
/user/impala/warehouse/external_partitions.db/logs/year=2013/month=07
drwxr-xr-x   - impala hive          0 2013-08-07 12:24 
/user/impala/warehouse/external_partitions.db/logs/year=2013/month=08
$ hdfs dfs -ls /user/impala/warehouse/external_partitions.db/logs/year=2013/month=07
Found 2 items
drwxr-xr-x   - impala hive          0 2013-08-07 12:22 
/user/impala/warehouse/external_partitions.db/logs/year=2013/month=07/day=28
drwxr-xr-x   - impala hive          0 2013-08-07 12:23 
/user/impala/warehouse/external_partitions.db/logs/year=2013/month=07/day=29
$ hdfs dfs -ls 
/user/impala/warehouse/external_partitions.db/logs/year=2013/month=07/day=28
Found 2 items
drwxr-xr-x   - impala hive          0 2013-08-07 12:21 
/user/impala/warehouse/external_partitions.db/logs/year=2013/month=07/day=28/host=host1
drwxr-xr-x   - impala hive          0 2013-08-07 12:22 
/user/impala/warehouse/external_partitions.db/logs/year=2013/month=07/day=28/host=host2
$ hdfs dfs -ls 
/user/impala/warehouse/external_partitions.db/logs/year=2013/month=07/day=28/host=host1
Found 1 items
-rw-r--r--   3 impala hive         12 2013-08-07 12:21 
/user/impala/warehouse/external_partiti
ons.db/logs/year=2013/month=07/day=28/host=host1/3981726974111751120--8907184999369517436_822630111_data.0
$ hdfs dfs -cat 
/user/impala/warehouse/external_partitions.db/logs/year=2013/month=07/day=28/\
host=host1/3981726974111751120--8 907184999369517436_822630111_data.0
foo,foo,foo
StillintheLinuxshell,weusehdfs dfs -mkdir tocreateseveraldatadirectoriesoutsidetheHDFSdirectorytree
thatImpalacontrols(/user/impala/warehouse inthisexample,maybedifferentinyourcase).Depending onyour
configuration,youmightneedtologinasauserwithpermission towriteintothisHDFSdirectorytree;forexample,
thecommands shownherewererunwhileloggedinasthehdfsuser.
hdfs dfs -mkdir -p /user/impala/data/logs/year=2013/month=07/day=28/host=host1
hdfs dfs -mkdir -p /user/impala/data/logs/year=2013/month=07/day=28/host=host2
hdfs dfs -mkdir -p /user/impala/data/logs/year=2013/month=07/day=28/host=host1
hdfs dfs -mkdir -p /user/impala/data/logs/year=2013/month=07/day=29/host=host1
hdfs dfs -mkdir -p /user/impala/data/logs/year=2013/month=08/day=01/host=host1
WemakeatinyCSVfile,withvaluesdifferentthanintheINSERTstatementsusedearlier,andputacopywithineach
subdirectorythatwewilluseasanImpalapartition.
$ cat >dummy_log_data
bar,baz,bletch
hdfs dfs -mkdir -p 
/user/impala/data/external_partitions/year=2013/month=08/day=01/host=host1
hdfs dfs -mkdir -p 
/user/impala/data/external_partitions/year=2013/month=07/day=28/host=host1
hdfs dfs -mkdir -p 
/user/impala/data/external_partitions/year=2013/month=07/day=28/host=host2
hdfs dfs -mkdir -p 
/user/impala/data/external_partitions/year=2013/month=07/day=29/host=host1
hdfs dfs -put dummy_log_data /user/impala/data/logs/year=2013/month=07/day=28/host=host1
$ hdfs dfs -put dummy_log_data /user/impala/data/logs/year=2013/month=07/day=28/host=host2
hdfs dfs -put dummy_log_data /user/impala/data/logs/year=2013/month=07/day=29/host=host1
$ hdfs dfs -put dummy_log_data /user/impala/data/logs/year=2013/month=08/day=01/host=host1
Backintheimpala-shell interpreter,wemovetheoriginalImpala-manag edtableaside,andcreateanewexternal
tablewithaLOCATION clausepointingtothedirectoryunderwhichwehavesetupallthepartition subdirectories
anddatafiles.
use external_partitions;
alter table logs rename to logs_original;
create external table logs (field1 string, field2 string, field3 string)
  partitioned by (year string, month string, day string, host string)
ApacheImpalaGuide|55ImpalaTutorials
  row format delimited fields terminated by ','
  location '/user/impala/data/logs';
Becausepartition subdirectoriesanddatafilescomeandgoduringthedatalifecycle,youmustidentifyeachofthe
partitions throughanALTER TABLE statementbeforeImpalarecognizesthedatafilestheycontain.
alter table logs add partition (year="2013",month="07",day="28",host="host1")
alter table log_type add partition (year="2013",month="07",day="28",host="host2");
alter table log_type add partition (year="2013",month="07",day="29",host="host1");
alter table log_type add partition (year="2013",month="08",day="01",host="host1");
WeissueaREFRESH statementforthetable,alwaysasafepracticewhendatafileshavebeenmanually added,removed,
orchanged.Thenthedataisreadytobequeried.TheSELECT * statementillustratesthatthedatafromourtrivial
CSVfilewasrecognizedineachofthepartitions wherewecopiedit.Although inthiscasethereareonlyafewrows,
weincludeaLIMITclauseonthistestqueryjustincasethereismoredatathanweexpect.
refresh log_type;
select * from log_type limit 100;
+--------+--------+--------+------+-------+-----+-------+
| field1 | field2 | field3 | year | month | day | host  |
+--------+--------+--------+------+-------+-----+-------+
| bar    | baz    | bletch | 2013 | 07    | 28  | host1 |
| bar    | baz    | bletch | 2013 | 08    | 01  | host1 |
| bar    | baz    | bletch | 2013 | 07    | 29  | host1 |
| bar    | baz    | bletch | 2013 | 07    | 28  | host2 |
+--------+--------+--------+------+-------+-----+-------+
SwitchingBackandForthBetweenImpalaandHive
Sometimes,youmightfinditconvenienttoswitchtotheHiveshelltoperformsomedataloadingortransformation
operation,particularly onfileformatssuchasRCFile,SequenceFile, andAvrothatImpalacurrentlycanquerybutnot
writeto.
Wheneveryoucreate,drop,oralteratableorotherkindofobjectthroughHive,thenexttimeyouswitchbacktothe
impala-shell interpreter,issueaone-timeINVALIDATE METADATA statementsothatImpalarecognizesthenew
orchangedobject.
Wheneveryouload,insert,orchangedatainanexistingtablethroughHive(oreventhroughmanualHDFSoperations
suchasthehdfscommand), thenexttimeyouswitchbacktotheimpala-shell interpreter,issueaone-time
REFRESH table_name statementsothatImpalarecognizestheneworchangeddata.
ForexamplesshowinghowthisprocessworksfortheREFRESH statement,lookattheexamplesofcreatingRCFileand
SequenceFile tablesinImpala,loadingdatathroughHive,andthenqueryingthedatathroughImpala.SeeUsingthe
RCFileFileFormatwithImpalaTablesonpage665andUsingtheSequenceFile FileFormatwithImpalaTablesonpage
667forthoseexamples.
ForexamplesshowinghowthisprocessworksfortheINVALIDATE METADATA statement,lookattheexampleof
creatingandloadinganAvrotableinHive,andthenqueryingthedatathroughImpala.SeeUsingtheAvroFileFormat
withImpalaTablesonpage659forthatexample.
Note:
Originally ,ImpaladidnotsupportUDFs,butthisfeatureisavailableinImpalastartinginImpala1.2.
SomeINSERT ... SELECT transformationsthatyouoriginally didthroughHivecannowbedone
throughImpala.SeeUser-DefinedFunctions (UDFs)onpage525fordetails.
PriortoImpala1.2,theREFRESH andINVALIDATE METADATA statementsneededtobeissuedon
eachImpalanodetowhichyouconnectedandissuedqueries.InImpala1.2andhigher,whenyou
issueeitherofthosestatementsonanyImpalanode,theresultsarebroadcasttoalltheImpalanodes
inthecluster,makingittrulyaone-stepoperationaftereachroundofDDLorETLoperationsinHive.
56|ApacheImpalaGuideImpalaTutorials
CrossJoinsandCartesianProductswiththeCROSSJOINOperator
Originally ,Impalarestrictedjoinqueriessothattheyhadtoincludeatleastoneequalitycomparison betweenthe
columnsofthetablesoneachsideofthejoinoperator.WiththehugetablestypicallyprocessedbyImpala,any
miscodedquerythatproducedafullCartesianproductasaresultsetcouldconsumeahugeamountofclusterresources.
InImpala1.2.2andhigher,thisrestrictionisliftedwhenyouusetheCROSS JOIN operatorinthequery.Youstill
cannotremoveallWHEREclausesfromaquerylikeSELECT * FROM t1 JOIN t2 toproduceallcombinationsof
rowsfrombothtables.ButyoucanusetheCROSS JOIN operatortoexplicitlyrequestsuchaCartesianproduct.
Typically,thisoperationisapplicableforsmallertables,wheretheresultsetstillfitswithinthememoryofasingle
Impalanode.
Thefollowingexamplesetsupdataforuseinaseriesofcomicbookswherecharactersbattleeachother.Atfirst,we
useanequijoinquery,whichonlyallowscharactersfromthesametimeperiodandthesameplanettomeet.
[localhost:21000] > create table heroes (name string, era string, planet string);
[localhost:21000] > create table villains (name string, era string, planet string);
[localhost:21000] > insert into heroes values
                  > ('Tesla','20th century','Earth'),
                  > ('Pythagoras','Antiquity','Earth'),
                  > ('Zopzar','Far Future','Mars');
Inserted 3 rows in 2.28s
[localhost:21000] > insert into villains values
                  > ('Caligula','Antiquity','Earth'),
                  > ('John Dillinger','20th century','Earth'),
                  > ('Xibulor','Far Future','Venus');
Inserted 3 rows in 1.93s
[localhost:21000] > select concat(heroes.name,' vs. ',villains.name) as battle
                  > from heroes join villains
                  > where heroes.era = villains.era and heroes.planet = villains.planet;
+--------------------------+
| battle                   |
+--------------------------+
| Tesla vs. John Dillinger |
| Pythagoras vs. Caligula  |
+--------------------------+
Returned 2 row(s) in 0.47s
Readersdemanded moreaction,soweaddedelementsoftimetravelandspacetravelsothatanyherocouldface
anyvillain.PriortoImpala1.2.2,thistypeofquerywasimpossible becausealljoinshadtoreferencematchingvalues
betweenthetwotables:
[localhost:21000] > -- Cartesian product not possible in Impala 1.1.
                  > select concat(heroes.name,' vs. ',villains.name) as battle from 
heroes join villains;
ERROR: NotImplementedException: Join between 'heroes' and 'villains' requires at least
 one conjunctive equality predicate between the two tables
WithImpala1.2.2,werewritethequeryslightlytouseCROSS JOIN ratherthanJOIN,andnowtheresultsetincludes
allcombinations:
[localhost:21000] > -- Cartesian product available in Impala 1.2.2 with the CROSS JOIN
 syntax.
                  > select concat(heroes.name,' vs. ',villains.name) as battle from 
heroes cross join villains;
+-------------------------------+
| battle                        |
+-------------------------------+
| Tesla vs. Caligula            |
| Tesla vs. John Dillinger      |
| Tesla vs. Xibulor             |
| Pythagoras vs. Caligula       |
| Pythagoras vs. John Dillinger |
| Pythagoras vs. Xibulor        |
| Zopzar vs. Caligula           |
| Zopzar vs. John Dillinger     |
| Zopzar vs. Xibulor            |
ApacheImpalaGuide|57ImpalaTutorials
+-------------------------------+
Returned 9 row(s) in 0.33s
ThefullcombinationofrowsfrombothtablesisknownastheCartesianproduct.Thistypeofresultsetisoftenused
forcreatinggriddatastructures.YoucanalsofiltertheresultsetbyincludingWHEREclausesthatdonotexplicitly
comparecolumnsbetweenthetwotables.Thefollowingexampleshowshowyoumightproducealistofcombinations
ofyearandquarterforuseinachart,andthenashorterlistwithonlyselectedquarters.
[localhost:21000] > create table x_axis (x int);
[localhost:21000] > create table y_axis (y int);
[localhost:21000] > insert into x_axis values (1),(2),(3),(4);
Inserted 4 rows in 2.14s
[localhost:21000] > insert into y_axis values (2010),(2011),(2012),(2013),(2014);
Inserted 5 rows in 1.32s
[localhost:21000] > select y as year, x as quarter from x_axis cross join y_axis;
+------+---------+
| year | quarter |
+------+---------+
| 2010 | 1       |
| 2011 | 1       |
| 2012 | 1       |
| 2013 | 1       |
| 2014 | 1       |
| 2010 | 2       |
| 2011 | 2       |
| 2012 | 2       |
| 2013 | 2       |
| 2014 | 2       |
| 2010 | 3       |
| 2011 | 3       |
| 2012 | 3       |
| 2013 | 3       |
| 2014 | 3       |
| 2010 | 4       |
| 2011 | 4       |
| 2012 | 4       |
| 2013 | 4       |
| 2014 | 4       |
+------+---------+
Returned 20 row(s) in 0.38s
[localhost:21000] > select y as year, x as quarter from x_axis cross join y_axis where
 x in (1,3);
+------+---------+
| year | quarter |
+------+---------+
| 2010 | 1       |
| 2011 | 1       |
| 2012 | 1       |
| 2013 | 1       |
| 2014 | 1       |
| 2010 | 3       |
| 2011 | 3       |
| 2012 | 3       |
| 2013 | 3       |
| 2014 | 3       |
+------+---------+
Returned 10 row(s) in 0.39s
DealingwithParquetFileswithUnknownSchema
Asdatapipelines starttoincludemoreaspectssuchasNoSQLorlooselyspecified schemas, youmightencounter
situationswhereyouhavedatafiles(particularly inParquetformat)whereyoudonotknowtheprecisetabledefinition.
ThistutorialshowshowyoucanbuildanImpalatablearounddatathatcomesfromnon-Impala orevennon-SQL
sources,whereyoudonothavecontrolofthetablelayoutandmightnotbefamiliarwiththecharacteristicsofthe
data.
58|ApacheImpalaGuideImpalaTutorials
Thedatausedinthistutorialrepresentsairlineon-timearrivalstatistics,fromOctober1987throughApril2008.See
thedetailsonthe2009ASADataExpowebsite.Youcanalsoseetheexplanationsofthecolumns;forpurposes ofthis
exercise,waituntilafterfollowingthetutorialbeforeexaminingtheschema,tobettersimulateareal-lifesituation
whereyoucannotrelyonassumptionsandassertions abouttherangesandrepresentationsofdatavalues.
DownloadtheDataFilesintoHDFS
First,wedownloadandunpackthedatafiles.Thereare8filestotalling1.4GB.
$ wget -O airlines_parquet.tar.gz https://home.apache.org/~arodoni/airlines_parquet.tar.gz
$ wget https://home.apache.org/~arodoni/airlines_parquet.tar.gz.sha512
$ shasum -a 512 -c airlines_parquet.tar.gz.sha512
airlines_parquet.tar.gz: OK
$ tar xvzf airlines_parquet.tar.gz
$ cd airlines_parquet/
$ du -kch *.parq
253M   4345e5eef217aa1b-c8f16177f35fd983_1150363067_data.0.parq
14M    4345e5eef217aa1b-c8f16177f35fd983_1150363067_data.1.parq
253M   4345e5eef217aa1b-c8f16177f35fd984_501176748_data.0.parq
64M    4345e5eef217aa1b-c8f16177f35fd984_501176748_data.1.parq
184M   4345e5eef217aa1b-c8f16177f35fd985_1199995767_data.0.parq
241M   4345e5eef217aa1b-c8f16177f35fd986_2086627597_data.0.parq
212M   4345e5eef217aa1b-c8f16177f35fd987_1048668565_data.0.parq
152M   4345e5eef217aa1b-c8f16177f35fd988_1432111844_data.0.parq
1.4G   total
Next,weputtheParquetdatafilesinHDFS,alltogetherinasingledirectory,withpermissions onthedirectoryand
thefilessothattheimpalauserwillbeabletoreadthem.
Afterunpacking ,wesawthelargestParquetfilewas253MB.WhencopyingParquetfilesintoHDFSforImpalatouse,
formaximumqueryperformance, makesurethateachfileresidesinasingleHDFSdatablock.Therefore,wepicka
sizelargerthananysinglefileandspecifythatastheblocksize,usingtheargument-Ddfs.block.size=253m on
thehdfs dfs -put command.
$ sudo -u hdfs hdfs dfs -mkdir -p /user/impala/staging/airlines
$ sudo -u hdfs hdfs dfs -Ddfs.block.size=253m -put *.parq /user/impala/staging/airlines
$ sudo -u hdfs hdfs dfs -ls /user/impala/staging
Found 1 items
$ sudo -u hdfs hdfs dfs -ls /user/impala/staging/airlines
Found 8 items
CreateDatabaseandTables
Withthefilesinanaccessible locationinHDFS,youcreateadatabasetablethatusesthedatainthosefiles:
â¢TheCREATE EXTERNAL syntaxandtheLOCATION attributepointImpalaattheappropriateHDFSdirectory.
â¢TheLIKE PARQUET ' path_to_any_parquet_file 'clausemeansweskipthelistofcolumnnamesandtypes;
Impalaautomaticallygetsthecolumnnamesanddatatypesstraightfromthedatafiles.(Currently,thistechnique
onlyworksforParquetfiles.)
â¢IgnorethewarningaboutlackofREAD_WRITE accesstothefilesinHDFS;theimpalausercanreadthefiles,
whichwillbesufficientforustoexperimen twithqueriesandperformsomecopyandtransformoperationsinto
othertables.
$ impala-shell
> CREATE DATABASE airlines_data;
  USE airlines_data;
  CREATE EXTERNAL TABLE airlines_external
  LIKE PARQUET 
'hdfs:staging/airlines/4345e5eef217aa1b-c8f16177f35fd983_1150363067_data.0.parq'
  STORED AS PARQUET LOCATION 'hdfs:staging/airlines';
ApacheImpalaGuide|59ImpalaTutorials
WARNINGS: Impala does not have READ_WRITE access to path 
'hdfs://myhost.com:8020/user/impala/staging'
ExaminePhysicalandLogicalSchema
Withthetablecreated,weexamineitsphysicalandlogicalcharacteristicstoconfirmthatthedataisreallythereand
inaformatandshapethatwecanworkwith.
â¢TheSHOW TABLE STATS statementgivesaveryhigh-levelsummaryofthetable,showinghowmanyfilesand
howmuchtotaldataitcontains.Also,itconfirmsthatthetableisexpectingalltheassociateddatafilestobein
Parquetformat.(TheabilitytoworkwithallkindsofHDFSdatafilesindifferentformatsmeansthatitispossible
tohaveamismatchbetweentheformatofthedatafiles,andtheformatthatthetableexpectsthedatafilesto
bein.)
â¢TheSHOW FILES statementconfirmsthatthedatainthetablehastheexpectednumber,names,andsizesof
theoriginalParquetfiles.
â¢TheDESCRIBE statement(oritsabbreviationDESC)confirmsthenamesandtypesofthecolumnsthatImpala
automaticallycreatedafterreadingthatmetadatafromtheParquetfile.
â¢TheDESCRIBE FORMATTED statementprintsoutsomeextradetailalongwiththecolumndefinitions.Thepieces
wecareaboutforthisexerciseare:
âThecontainingdatabaseforthetable.
âThelocationoftheassociateddatafilesinHDFS.
âThetableisanexternaltablesoImpalawillnotdeletetheHDFSfileswhenwefinishtheexperimen tsand
dropthetable.
âThetableissetuptoworkexclusivelywithfilesintheParquetformat.
> SHOW TABLE STATS airlines_external;
+-------+--------+--------+--------------+-------------------+---------+-------------------+
| #Rows | #Files | Size   | Bytes Cached | Cache Replication | Format  | Incremental 
stats |
+-------+--------+--------+--------------+-------------------+---------+-------------------+
| -1    | 8      | 1.34GB | NOT CACHED   | NOT CACHED        | PARQUET | false        
     |
+-------+--------+--------+--------------+-------------------+---------+-------------------+
> SHOW FILES IN airlines_external;
+----------------------------------------------------------------------------------------+----------+-----------+
| path                                                                                
   | size     | partition |
+----------------------------------------------------------------------------------------+----------+-----------+
| /user/impala/staging/airlines/4345e5eef217aa1b-c8f16177f35fd983_1150363067_data.0.parq
 | 252.99MB |           |
| /user/impala/staging/airlines/4345e5eef217aa1b-c8f16177f35fd983_1150363067_data.1.parq
 | 13.43MB  |           |
| /user/impala/staging/airlines/4345e5eef217aa1b-c8f16177f35fd984_501176748_data.0.parq
  | 252.84MB |           |
| /user/impala/staging/airlines/4345e5eef217aa1b-c8f16177f35fd984_501176748_data.1.parq
  | 63.92MB  |           |
| /user/impala/staging/airlines/4345e5eef217aa1b-c8f16177f35fd985_1199995767_data.0.parq
 | 183.64MB |           |
| /user/impala/staging/airlines/4345e5eef217aa1b-c8f16177f35fd986_2086627597_data.0.parq
 | 240.04MB |           |
| /user/impala/staging/airlines/4345e5eef217aa1b-c8f16177f35fd987_1048668565_data.0.parq
 | 211.35MB |           |
| /user/impala/staging/airlines/4345e5eef217aa1b-c8f16177f35fd988_1432111844_data.0.parq
 | 151.46MB |           |
+----------------------------------------------------------------------------------------+----------+-----------+
> DESCRIBE airlines_external;
+---------------------+--------+---------------------------------------------------+
| name                | type   | comment                                           |
+---------------------+--------+---------------------------------------------------+
| year                | int    | Inferred from Parquet file.                       |
| month               | int    | Inferred from Parquet file.                       |
| day                 | int    | Inferred from Parquet file.                       |
60|ApacheImpalaGuideImpalaTutorials
| dayofweek           | int    | Inferred from Parquet file.                       |
| dep_time            | int    | Inferred from Parquet file.                        |
| crs_dep_time        | int    | Inferred from Parquet file.                       |
| arr_time            | int    | Inferred from Parquet file.                       |
| crs_arr_time        | int    | Inferred from Parquet file.                       |
| carrier             | string | Inferred from Parquet file.                       |
| flight_num          | int    | Inferred from Parquet file.                       |
| tail_num            | int    | Inferred from Parquet file.                       |
| actual_elapsed_time | int    | Inferred from Parquet file.                       |
| crs_elapsed_time    | int    | Inferred from Parquet file.                       |
| airtime             | int    | Inferred from Parquet file.                       |
| arrdelay            | int    | Inferred from Parquet file.                       |
| depdelay            | int    | Inferred from Parquet file.                       |
| origin              | string | Inferred from Parquet file.                       |
| dest                | string | Inferred from Parquet file.                       |
| distance            | int    | Inferred from Parquet file.                       |
| taxi_in             | int    | Inferred from Parquet file.                       |
| taxi_out            | int    | Inferred from Parquet file.                       |
| cancelled           | int    | Inferred from Parquet file.                       |
| cancellation_code   | string | Inferred from Parquet file.                       |
| diverted            | int    | Inferred from Parquet file.                       |
| carrier_delay       | int    | Inferred from Parquet file.                       |
| weather_delay       | int    | Inferred from Parquet file.                       |
| nas_delay           | int    | Inferred from Parquet file.                       |
| security_delay      | int    | Inferred from Parquet file.                       |
| late_aircraft_delay | int    | Inferred from Parquet file.                       |
+---------------------+--------+---------------------------------------------------+
> DESCRIBE FORMATTED airlines_external;
+------------------------------+-------------------------------
| name                         | type
+------------------------------+-------------------------------
...
| # Detailed Table Information | NULL
| Database:                    | airlines_data
| Owner:                       | impala
...
| Location:                    | /user/impala/staging/airlines
| Table Type:                  | EXTERNAL_TABLE
...
| # Storage Information        | NULL
| SerDe Library:               | 
org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe
| InputFormat:                 | 
org.apache.hadoop.hive.ql.io.parquet.MapredParquetInputForma
| OutputFormat:                | 
org.apache.hadoop.hive.ql.io.parquet.MapredParquetOutputFormat
...
AnalyzeData
Nowthatweareconfidentthattheconnections aresolidbetweentheImpalatableandtheunderlying Parquetfiles,
werunsomeinitialqueriestounderstandthecharacteristicsofthedata:theoverallnumberofrows,andtheranges
andhowmanydifferentvaluesareincertaincolumns.
> SELECT COUNT(*) FROM airlines_external;
+-----------+
| count(*)  |
+-----------+
| 123534969 |
+-----------+
TheNDV()functionreturnsanumberofdistinctvalues,which,forperformance reasons,isanestimatewhenthere
arelotsofdifferentvaluesinthecolumn,butisprecisewhenthecardinalityislessthan16K.UseNDV()functionfor
thiskindofexplorationratherthanCOUNT(DISTINCT colname),becauseImpalacanevaluatemultipleNDV()
functions inasinglequery,butonlyasingleinstanceofCOUNT DISTINCT .
> SElECT NDV(carrier), NDV(flight_num), NDV(tail_num),
  NDV(origin), NDV(dest) FROM airlines_external;
ApacheImpalaGuide|61ImpalaTutorials
+--------------+-----------------+---------------+-------------+-----------+
| ndv(carrier) | ndv(flight_num) | ndv(tail_num) | ndv(origin) | ndv(dest) |
+--------------+-----------------+---------------+-------------+-----------+
| 29           | 8463            | 3             | 342         | 349       |
+--------------+-----------------+---------------+-------------+-----------+
> SELECT tail_num, COUNT(*) AS howmany FROM airlines_external
  GROUP BY tail_num;
+----------+-----------+
| tail_num | howmany   |
+----------+-----------+
| NULL     | 123122001 |
| 715      | 1         |
| 0        | 406405    |
| 112      | 6562      |
+----------+-----------+
> SELECT DISTINCT dest FROM airlines_external
  WHERE dest NOT IN (SELECT origin FROM airlines_external);
+------+
| dest |
+------+
| CBM  |
| SKA  |
| LAR  |
| RCA  |
| LBF  |
+------+
> SELECT DISTINCT dest FROM airlines_external
  WHERE dest NOT IN (SELECT DISTINCT origin FROM airlines_external);
+------+
| dest |
+------+
| CBM  |
| SKA  |
| LAR  |
| RCA  |
| LBF  |
+------+
> SELECT DISTINCT origin FROM airlines_external
  WHERE origin NOT IN (SELECT DISTINCT dest FROM airlines_external);
Fetched 0 row(s) in 2.63
Withtheabovequeries,weseethattherearemodestnumbersofdifferentairlines,flightnumbers,andoriginand
destinationairports.Twothingsjumpoutfromthisquery:thenumberoftail_num valuesismuchsmallerthanwe
mighthaveexpected,andtherearemoredestinationairportsthanoriginairports.Let'sdigfurther.Whatwefindis
thatmosttail_num valuesareNULL.Itlookslikethiswasanexperimen talcolumnthatwasn'tfilledinaccurately.
Wemakeamentalnotethatifweusethisdataasastartingpoint,we'llignorethiscolumn.Wealsofindthatcertain
airportsarerepresentedintheORIGINcolumnbutnottheDESTcolumn;nowweknowthatwecannotrelyonthe
assumptionthatthosesetsofairportcodesareidentical.
Note:ThefirstSELECT DISTINCT DEST querytakesalmost40seconds.Weexpectallquerieson
suchasmalldataset,lessthan2GB,totakeafewsecondsatmost.Thereasonisbecausethe
expressionNOT IN (SELECT origin FROM airlines_external) producesanintermediate
resultsetof123millionrows,thenruns123millioncomparisons oneachdatanodeagainstthetiny
setofdestinationairports.ThewaytheNOT INoperatorworksinternallymeansthatthisintermediate
resultsetwith123millionrowsmightbetransmittedacrossthenetworktoeachdatanodeinthe
cluster.ApplyinganotherDISTINCT insidetheNOT INsubquerymeansthattheintermediateresult
setisonly340items,resultinginmuchlessnetworktrafficandfewercomparison operations.The
moreefficientquerywiththeaddedDISTINCT isapproximately7timesasfast.
Next,wetrydoingasimplecalculation,withresultsbrokendownbyyear.Thisrevealsthatsomeyearshavenodata
intheairtime column.Thatmeanswemightbeabletousethatcolumninqueriesinvolvingcertaindateranges,but
wecannotcountonittoalwaysbereliable.ThequestionofwhetheracolumncontainsanyNULLvalues,andifso
62|ApacheImpalaGuideImpalaTutorials
whatistheirnumber,proportion, anddistribution, comesupagainandagainwhendoinginitialexplorationofadata
set.
> SELECT year, SUM(airtime) FROM airlines_external
  GROUP BY year ORDER BY year DESC;
+------+--------------+
| year | sum(airtime) |
+------+--------------+
| 2008 | 713050445    |
| 2007 | 748015545    |
| 2006 | 720372850    |
| 2005 | 708204026    |
| 2004 | 714276973    |
| 2003 | 665706940    |
| 2002 | 549761849    |
| 2001 | 590867745    |
| 2000 | 583537683    |
| 1999 | 561219227    |
| 1998 | 538050663    |
| 1997 | 536991229    |
| 1996 | 519440044    |
| 1995 | 513364265    |
| 1994 | NULL         |
| 1993 | NULL         |
| 1992 | NULL         |
| 1991 | NULL         |
| 1990 | NULL         |
| 1989 | NULL         |
| 1988 | NULL         |
| 1987 | NULL         |
+------+--------------+
WiththenotionofNULLvaluesinmind,let'scomebacktothetail_num columnthatwediscoveredhadalotof
NULLs.Let'squantifytheNULLandnon-NULLvaluesinthatcolumnforbetterunderstanding.First,wejustcountthe
overallnumberofrowsversusthenon-NULLvaluesinthatcolumn.Thatinitialresultgivestheappearanceofrelatively
fewnon-NULLvalues,butwecanbreakitdownmoreclearlyinasinglequery.OncewehavetheCOUNT(*) andthe
COUNT(colname)numbers,wecanencodethatinitialqueryinaWITHclause,thenrunafollow-onquerythatperforms
multiplearithmeticoperationsonthosevalues.Seeingthatonlyone-thirdofonepercentofallrowshavenon-NULL
valuesforthetail_num columnclearlyillustratesthatcolumnisnotofmuchuse.
> SELECT COUNT(*) AS 'rows', COUNT(tail_num) AS 'non-null tail numbers'
  FROM airlines_external;
+-----------+-----------------------+
| rows      | non-null tail numbers |
+-----------+-----------------------+
| 123534969 | 412968                |
+-----------+-----------------------+
> WITH t1 AS
  (SELECT COUNT(*) AS 'rows', COUNT(tail_num) AS 'nonnull'
  FROM airlines_external)
SELECT `rows`, `nonnull`, `rows` - `nonnull` AS 'nulls',
  (`nonnull` / `rows`) * 100 AS 'percentage non-null'
FROM t1;
+-----------+---------+-----------+---------------------+
| rows      | nonnull | nulls     | percentage non-null |
+-----------+---------+-----------+---------------------+
| 123534969 | 412968  | 123122001 | 0.3342923897119365  |
+-----------+---------+-----------+---------------------+
Byexaminingothercolumnsusingthesetechniques, wecanformamentalpictureofthewaydataisdistributed
throughoutthetable,andwhichcolumnsaremostsignificantforquerypurposes. Forthistutorial,wefocusmostly
onthefieldslikelytoholddiscretevalues,ratherthancolumnssuchasactual_elapsed_time whosenamessuggest
theyholdmeasurements.Wewoulddigdeeperintothosecolumnsoncewehadaclearpictureofwhichquestions
wereworthwhiletoask,andwhatkindsoftrendswemightlookfor.Forthefinalpieceofinitialexploration,let'slook
ApacheImpalaGuide|63ImpalaTutorials
attheyearcolumn.AsimpleGROUP BY queryshowsthatithasawell-definedrange,amanageablenumberofdistinct
values,andrelativelyevendistribution ofrowsacrossthedifferentyears.
> SELECT MIN(year), MAX(year), NDV(year) FROM airlines_external;
+-----------+-----------+-----------+
| min(year) | max(year) | ndv(year) |
+-----------+-----------+-----------+
| 1987      | 2008      | 22        |
+-----------+-----------+-----------+
> SELECT year, COUNT(*) howmany FROM airlines_external
  GROUP BY year ORDER BY year DESC;
+------+---------+
| year | howmany |
+------+---------+
| 2008 | 7009728 |
| 2007 | 7453215 |
| 2006 | 7141922 |
| 2005 | 7140596 |
| 2004 | 7129270 |
| 2003 | 6488540 |
| 2002 | 5271359 |
| 2001 | 5967780 |
| 2000 | 5683047 |
| 1999 | 5527884 |
| 1998 | 5384721 |
| 1997 | 5411843 |
| 1996 | 5351983 |
| 1995 | 5327435 |
| 1994 | 5180048 |
| 1993 | 5070501 |
| 1992 | 5092157 |
| 1991 | 5076925 |
| 1990 | 5270893 |
| 1989 | 5041200 |
| 1988 | 5202096 |
| 1987 | 1311826 |
+------+---------+
Wecouldgoquitefarwiththedatainthisinitialrawformat,justaswedownloaded itfromtheweb.Ifthedataset
provedtobeusefulandworthpersistinginImpalaforextensivequeries,wemightwanttocopyittoaninternaltable,
lettingImpalamanagethedatafilesandperhapsreorganizingalittleforhigherefficiency.Inthisnextstageofthe
tutorial,wecopytheoriginaldataintoapartitioned table,stillinParquetformat.Partitioning basedontheyear
columnletsusrunquerieswithclausessuchasWHERE year = 2001 orWHERE year BETWEEN 1989 AND 1999 ,
whichcandramaticallycutdownonI/Obyignoringallthedatafromyearsoutsidethedesiredrange.Ratherthan
readingallthedataandthendecidingwhichrowsareinthematchingyears,Impalacanzeroinononlythedatafiles
fromspecificyearpartitions. Todothis,Impalaphysicallyreorganizesthedatafiles,puttingtherowsfromeachyear
intodatafilesinaseparateHDFSdirectoryforeachyearvalue.Alongtheway,we'llalsogetridofthetail_num
columnthatprovedtobealmostentirelyNULL.
Thefirststepistocreateanewtablewithalayoutverysimilartotheoriginalairlines_external table.We'lldo
thatbyreverse-engineering aCREATE TABLE statementforthefirsttable,thentweakingitslightlytoincludea
PARTITION BY clauseforyear,andexcludingthetail_num column.TheSHOW CREATE TABLE statementgivesus
thestartingpoint.
Although wecouldeditthatoutputintoanewSQLstatement,alltheASCIIboxcharactersmakesuchediting
inconvenient.Togetamorestripped-do wnCREATE TABLE tostartwith,werestarttheimpala-shell command
withthe-Boption,whichturnsoffthebox-drawingbehavior.
$ impala-shell -i localhost -B -d airlines_data;
> SHOW CREATE TABLE airlines_external;
"CREATE EXTERNAL TABLE airlines_data.airlines_external (
  year INT COMMENT 'inferred from: optional int32 year',
  month INT COMMENT 'inferred from: optional int32 month',
  day INT COMMENT 'inferred from: optional int32 day',
  dayofweek INT COMMENT 'inferred from: optional int32 dayofweek',
64|ApacheImpalaGuideImpalaTutorials
  dep_time INT COMMENT 'inferred from: optional int32 dep_time',
  crs_dep_time INT COMMENT 'inferred from: optional int32 crs_dep_time',
  arr_time INT COMMENT 'inferred from: optional int32 arr_time',
  crs_arr_time INT COMMENT 'inferred from: optional int32 crs_arr_time',
  carrier STRING COMMENT 'inferred from: optional binary carrier',
  flight_num INT COMMENT 'inferred from: optional int32 flight_num',
  tail_num INT COMMENT 'inferred from: optional int32 tail_num',
  actual_elapsed_time INT COMMENT 'inferred from: optional int32 actual_elapsed_time',
  crs_elapsed_time INT COMMENT 'inferred from: optional int32 crs_elapsed_time',
  airtime INT COMMENT 'inferred from: optional int32 airtime',
  arrdelay INT COMMENT 'inferred from: optional int32 arrdelay',
  depdelay INT COMMENT 'inferred from: optional int32 depdelay',
  origin STRING COMMENT 'inferred from: optional binary origin',
  dest STRING COMMENT 'inferred from: optional binary dest',
  distance INT COMMENT 'inferred from: optional int32 distance',
  taxi_in INT COMMENT 'inferred from: optional int32 taxi_in',
  taxi_out INT COMMENT 'inferred from: optional int32 taxi_out',
  cancelled INT COMMENT 'inferred from: optional int32 cancelled',
  cancellation_code STRING COMMENT 'inferred from: optional binary cancellation_code',
  diverted INT COMMENT 'inferred from: optional int32 diverted',
  carrier_delay INT COMMENT 'inferred from: optional int32 carrier_delay',
  weather_delay INT COMMENT 'inferred from: optional int32 weather_delay',
  nas_delay INT COMMENT 'inferred from: optional int32 nas_delay',
  security_delay INT COMMENT 'inferred from: optional int32 security_delay',
  late_aircraft_delay INT COMMENT 'inferred from: optional int32 late_aircraft_delay'
)
STORED AS PARQUET
LOCATION 'hdfs://a1730.example.com:8020/user/impala/staging/airlines'
TBLPROPERTIES ('numFiles'='0', 'COLUMN_STATS_ACCURATE'='false',
  'transient_lastDdlTime'='1439425228', 'numRows'='-1', 'totalSize'='0',
  'rawDataSize'='-1')"
AftercopyingandpastingtheCREATE TABLE statementintoatexteditorforfine-tuning ,wequitandrestart
impala-shell withoutthe-Boption,toswitchbacktoregularoutput.
NextweruntheCREATE TABLE statementthatweadaptedfromtheSHOW CREATE TABLE output.Wekeptthe
STORED AS PARQUET clausebecausewewanttorearrangethedatasomewhatbutstillkeepitinthehigh-performance
Parquetformat.TheLOCATION andTBLPROPERTIES clausesarenotrelevantforthisnewtable,soweeditthoseout.
Becausewearegoingtopartitionthenewtablebasedontheyearcolumn,wemovethatcolumnname(anditstype)
intoanewPARTITIONED BY clause.
> CREATE TABLE airlines_data.airlines
 (month INT,
  day INT,
  dayofweek INT,
  dep_time INT,
  crs_dep_time INT,
  arr_time INT,
  crs_arr_time INT,
  carrier STRING,
  flight_num INT,
  actual_elapsed_time INT,
  crs_elapsed_time INT,
  airtime INT,
  arrdelay INT,
  depdelay INT,
  origin STRING,
  dest STRING,
  distance INT,
  taxi_in INT,
  taxi_out INT,
  cancelled INT,
  cancellation_code STRING,
  diverted INT,
  carrier_delay INT,
  weather_delay INT,
  nas_delay INT,
  security_delay INT,
  late_aircraft_delay INT)
PARTITIONED BY (year INT)
ApacheImpalaGuide|65ImpalaTutorials
STORED AS PARQUET
;
Next,wecopyalltherowsfromtheoriginaltableintothisnewonewithanINSERTstatement.(WeeditedtheCREATE
TABLEstatementtomakeanINSERTstatementwiththecolumnnamesinthesameorder.)Theonlychangeistoadd
aPARTITION(year) clause,andmovetheyearcolumntotheveryendoftheSELECTlistoftheINSERTstatement.
SpecifyingPARTITION(year) ,ratherthanafixedvaluesuchasPARTITION(year=2000) ,meansthatImpalafigures
outthepartition valueforeachrowbasedonthevalueoftheverylastcolumnintheSELECTlist.ThisisthefirstSQL
statementthatlegitimatelytakesanysubstantialtime,becausetherowsfromdifferentyearsareshuffledaroundthe
cluster;therowsthatgointoeachpartition arecollectedononenode,beforebeingwrittentooneormorenewdata
files.
> INSERT INTO airlines_data.airlines
  PARTITION (year)
  SELECT
    month,
    day,
    dayofweek,
    dep_time,
    crs_dep_time,
    arr_time,
    crs_arr_time,
    carrier,
    flight_num,
    actual_elapsed_time,
    crs_elapsed_time,
    airtime,
    arrdelay,
    depdelay,
    origin,
    dest,
    distance,
    taxi_in,
    taxi_out,
    cancelled,
    cancellation_code,
    diverted,
    carrier_delay,
    weather_delay,
    nas_delay,
    security_delay,
    late_aircraft_delay,
    year
  FROM airlines_data.airlines_external;
Oncepartitioning orjoinqueriescomeintoplay,it'simportanttohavestatisticsthatImpalacanusetooptimizequeries
onthecorresponding tables.TheCOMPUTE INCREMENTAL STATS statementisthewaytocollectstatisticsfor
partitioned tables.ThentheSHOW TABLE STATS statementconfirmsthatthestatisticsareinplaceforeachpartition,
andalsoillustrateshowmanyfilesandhowmuchrawdataisineachpartition.
> COMPUTE INCREMENTAL STATS airlines;
+-------------------------------------------+
| summary                                   |
+-------------------------------------------+
| Updated 22 partition(s) and 27 column(s). |
+-------------------------------------------+
> SHOW TABLE STATS airlines;
+-------+-----------+--------+----------+--------------+-------------------+---------+-------------------+----------------------------------------------------------------------------------------------------------+
| year  | #Rows     | #Files | Size     | Bytes Cached | Cache Replication | Format  |
 Incremental stats | Location                                                         
                                        |
+-------+-----------+--------+----------+--------------+-------------------+---------+-------------------+----------------------------------------------------------------------------------------------------------+
| 1987  | 1311826   | 1      | 11.75MB  | NOT CACHED   | NOT CACHED        | PARQUET |
 true              | 
hdfs://myhost.com:8020/user/hive/warehouse/airline_data.db/airlines/year=1987 |
| 1988  | 5202096   | 1      | 44.04MB  | NOT CACHED   | NOT CACHED        | PARQUET |
 true              | 
66|ApacheImpalaGuideImpalaTutorials
hdfs://myhost.com:8020/user/hive/warehouse/airline_data.db/airlines/year=1988 |
| 1989  | 5041200   | 1      | 46.07MB  | NOT CACHED   | NOT CACHED        | PARQUET |
 true              | 
hdfs://myhost.com:8020/user/hive/warehouse/airline_data.db/airlines/year=1989 |
| 1990  | 5270893   | 1      | 46.25MB  | NOT CACHED   | NOT CACHED        | PARQUET |
 true              | 
hdfs://myhost.com:8020/user/hive/warehouse/airline_data.db/airlines/year=1990 |
| 1991  | 5076925   | 1      | 46.77MB  | NOT CACHED   | NOT CACHED        | PARQUET |
 true              | 
hdfs://myhost.com:8020/user/hive/warehouse/airline_data.db/airlines/year=1991 |
| 1992  | 5092157   | 1      | 48.21MB  | NOT CACHED   | NOT CACHED        | PARQUET |
 true              | 
hdfs://myhost.com:8020/user/hive/warehouse/airline_data.db/airlines/year=1992 |
| 1993  | 5070501   | 1      | 47.46MB  | NOT CACHED   | NOT CACHED        | PARQUET |
 true              | 
hdfs://myhost.com:8020/user/hive/warehouse/airline_data.db/airlines/year=1993 |
| 1994  | 5180048   | 1      | 47.47MB  | NOT CACHED   | NOT CACHED        | PARQUET |
 true              | 
hdfs://myhost.com:8020/user/hive/warehouse/airline_data.db/airlines/year=1994 |
| 1995  | 5327435   | 1      | 62.40MB  | NOT CACHED   | NOT CACHED        | PARQUET |
 true              | 
hdfs://myhost.com:8020/user/hive/warehouse/airline_data.db/airlines/year=1995 |
| 1996  | 5351983   | 1      | 62.93MB  | NOT CACHED   | NOT CACHED        | PARQUET |
 true              | 
hdfs://myhost.com:8020/user/hive/warehouse/airline_data.db/airlines/year=1996 |
| 1997  | 5411843   | 1      | 65.05MB  | NOT CACHED   | NOT CACHED        | PARQUET |
 true              | 
hdfs://myhost.com:8020/user/hive/warehouse/airline_data.db/airlines/year=1997 |
| 1998  | 5384721   | 1      | 62.21MB  | NOT CACHED   | NOT CACHED        | PARQUET |
 true              | 
hdfs://myhost.com:8020/user/hive/warehouse/airline_data.db/airlines/year=1998 |
| 1999  | 5527884   | 1      | 65.10MB  | NOT CACHED   | NOT CACHED        | PARQUET |
 true              | 
hdfs://myhost.com:8020/user/hive/warehouse/airline_data.db/airlines/year=1999 |
| 2000  | 5683047   | 1      | 67.68MB  | NOT CACHED   | NOT CACHED        | PARQUET |
 true              | 
hdfs://myhost.com:8020/user/hive/warehouse/airline_data.db/airlines/year=2000 |
| 2001  | 5967780   | 1      | 74.03MB  | NOT CACHED   | NOT CACHED        | PARQUET |
 true              | 
hdfs://myhost.com:8020/user/hive/warehouse/airline_data.db/airlines/year=2001 |
| 2002  | 5271359   | 1      | 74.00MB  | NOT CACHED   | NOT CACHED        | PARQUET |
 true              | 
hdfs://myhost.com:8020/user/hive/warehouse/airline_data.db/airlines/year=2002 |
| 2003  | 6488540   | 1      | 99.35MB  | NOT CACHED   | NOT CACHED        | PARQUET |
 true              | 
hdfs://myhost.com:8020/user/hive/warehouse/airline_data.db/airlines/year=2003 |
| 2004  | 7129270   | 1      | 123.29MB | NOT CACHED   | NOT CACHED        | PARQUET |
 true              | 
hdfs://myhost.com:8020/user/hive/warehouse/airline_data.db/airlines/year=2004 |
| 2005  | 7140596   | 1      | 120.72MB | NOT CACHED   | NOT CACHED        | PARQUET |
 true              | 
hdfs://myhost.com:8020/user/hive/warehouse/airline_data.db/airlines/year=2005 |
| 2006  | 7141922   | 1      | 121.88MB | NOT CACHED   | NOT CACHED        | PARQUET |
 true              | 
hdfs://myhost.com:8020/user/hive/warehouse/airline_data.db/airlines/year=2006 |
| 2007  | 7453215   | 1      | 130.87MB | NOT CACHED   | NOT CACHED        | PARQUET |
 true              | 
hdfs://myhost.com:8020/user/hive/warehouse/airline_data.db/airlines/year=2007 |
| 2008  | 7009728   | 1      | 123.14MB | NOT CACHED   | NOT CACHED        | PARQUET |
 true              | 
hdfs://myhost.com:8020/user/hive/warehouse/airline_data.db/airlines/year=2008 |
| Total | 123534969 | 22     | 1.55GB   | 0B           |                   |         |
                   |                                                                  
                                        |
+-------+-----------+--------+----------+--------------+-------------------+---------+-------------------+----------------------------------------------------------------------------------------------------------+
Atthispoint,wesanitycheckthepartitioning wedid.Allthepartitions haveexactlyonefile,whichisonthelowside.
AquerythatincludesaclauseWHERE year=2004 willonlyreadasingledatablock;thatdatablockwillbereadand
processedbyasingledatanode;therefore,foraquerytargetingasingleyear,alltheothernodesintheclusterwill
sitidlewhilealltheworkhappensonasinglemachine. It'sevenpossiblethatbychance(depending onHDFSreplication
factorandthewaydatablocksaredistributedacrossthecluster),thatmultipleyearpartitions selectedbyafiltersuch
ApacheImpalaGuide|67ImpalaTutorials
asWHERE year BETWEEN 1999 AND 2001 couldallbereadandprocessedbythesamedatanode.Themoredata
fileseachpartitionhas,themoreparallelismyoucangetandthelessprobabilityofâhotspotsâ occurring onparticular
nodes,thereforeabiggerperformance boostbyhavingabigcluster.
However,themoredatafiles,thelessdatagoesineachone.Theoverheadofdividingtheworkinaparallelquery
mightnotbeworthitifeachnodeisonlyreadingafewmegabytes.50or100megabytesisadecentsizeforaParquet
datablock;9or37megabytesisonthesmallside.Whichistosay,thedatadistribution weendedupwithbasedon
thispartitioning schemeisontheborderlinebetweensensible(reasonably largefiles)andsuboptimal(fewfilesin
eachpartition). Thewaytoseehowwellitworksinpracticeistorunthesamequeriesagainsttheoriginalflattable
andthenewpartitioned table,andcomparetimes.
Spoiler:inthiscase,withmyparticular 4-nodeclusterwithitsspecificdistribution ofdatablocksandmyparticular
exploratoryqueries,queriesagainstthepartitioned tabledoconsistentlyrunfasterthanthesamequeriesagainstthe
unpartitioned table.ButIcouldnotbesurethatwouldbethecasewithoutsomerealmeasurements.Herearesome
queriesIrantodrawthatconclusion, firstagainstairlines_external (nopartitioning), thenagainstAIRLINES
(partitioned byyear).TheAIRLINES queriesareconsistentlyfaster.Changing thevolumeofdata,changing thesize
ofthecluster,runningqueriesthatdidordidn'trefertothepartition keycolumns,orotherfactorscouldchangethe
resultstofavoronetablelayoutortheother.
Note:Ifyoufindthevolumeofeachpartitionisonlyinthelowtensofmegabytes,considerlowering
thegranularity ofpartitioning. Forexample,insteadofpartitioning byyear,month,andday,partition
byyearandmonthorevenjustbyyear.Theideallayouttodistributeworkefficientlyinaparallel
queryismanytensorevenhundredsofmegabytesperParquetfile,andthenumberofParquetfiles
ineachpartition somewhathigherthanthenumberofdatanodes.
> SELECT SUM(airtime) FROM airlines_external;
+--------------+
| 8662859484   |
+--------------+
> SELECT SUM(airtime) FROM airlines;
+--------------+
| 8662859484   |
+--------------+
> SELECT SUM(airtime) FROM airlines_external WHERE year = 2005;
+--------------+
| 708204026    |
+--------------+
> SELECT SUM(airtime) FROM airlines WHERE year = 2005;
+--------------+
| 708204026    |
+--------------+
Nowwecanfinallyanalyzethisdatasetthatfromtherawdatafilesandwedidn'tknowwhatcolumnstheycontained.
Let'sseewhethertheairtime ofaflighttendstobedifferentdepending onthedayoftheweek.Wecanseethat
theaverageisalittlehigherondaynumber6;perhapsSaturdayisabusyflyingdayandplaneshavetocircleforlonger
atthedestinationairportbeforelanding.
> SELECT dayofweek, AVG(airtime) FROM airlines
  GROUP BY dayofweek ORDER BY dayofweek;
+-----------+-------------------+
| dayofweek | avg(airtime)      |
+-----------+-------------------+
| 1         | 102.1560425016671 |
| 2         | 102.1582931538807 |
| 3         | 102.2170009256653 |
| 4         | 102.37477661846   |
| 5         | 102.2697358763511 |
| 6         | 105.3627448363705 |
| 7         | 103.4144351202054 |
+-----------+-------------------+
68|ApacheImpalaGuideImpalaTutorials
Toseeiftheapparenttrendholdsupovertime,let'sdothesamebreakdownbydayofweek,butalsosplitupbyyear.
Nowwecanseethatdaynumber6consistentlyhasahigheraverageairtimeineachyear.Wecanalsoseethatthe
averageairtimeincreasedovertimeacrosstheboard.AndthepresenceofNULLforthiscolumninyears1987to1994
showsthatqueriesinvolvingthiscolumnneedtoberestrictedtoadaterangeof1995andhigher.
> SELECT year, dayofweek, AVG(airtime) FROM airlines
  GROUP BY year, dayofweek ORDER BY year DESC, dayofweek;
+------+-----------+-------------------+
| year | dayofweek | avg(airtime)      |
+------+-----------+-------------------+
| 2008 | 1         | 103.1821651651355 |
| 2008 | 2         | 103.2149301386094 |
| 2008 | 3         | 103.0585076622796 |
| 2008 | 4         | 103.4671383539038 |
| 2008 | 5         | 103.5575385182659 |
| 2008 | 6         | 107.4006306562128 |
| 2008 | 7         | 104.8648851041755 |
| 2007 | 1         | 102.2196114337825 |
| 2007 | 2         | 101.9317791906348 |
| 2007 | 3         | 102.0964767689043 |
| 2007 | 4         | 102.6215927201686 |
| 2007 | 5         | 102.4289399000661 |
| 2007 | 6         | 105.1477448215756 |
| 2007 | 7         | 103.6305945644095 |
...
| 1996 | 1         | 99.33860750862108 |
| 1996 | 2         | 99.54225446396656 |
| 1996 | 3         | 99.41129336113134 |
| 1996 | 4         | 99.5110373340348  |
| 1996 | 5         | 99.22120745027595 |
| 1996 | 6         | 101.1717447111921 |
| 1996 | 7         | 99.95410136133704 |
| 1995 | 1         | 96.93779698300494 |
| 1995 | 2         | 96.93458674589712 |
| 1995 | 3         | 97.00972311337051 |
| 1995 | 4         | 96.90843832024412 |
| 1995 | 5         | 96.78382115425562 |
| 1995 | 6         | 98.70872826057003 |
| 1995 | 7         | 97.85570478374616 |
| 1994 | 1         | NULL              |
| 1994 | 2         | NULL              |
| 1994 | 3         | NULL              |
...
| 1987 | 5         | NULL              |
| 1987 | 6         | NULL              |
| 1987 | 7         | NULL              |
+------+-----------+-------------------+
ApacheImpalaGuide|69ImpalaTutorials
ImpalaAdministration
Asanadministrator,youmonitorImpala'suseofresourcesandtakeactionwhennecessarytokeepImpalarunning
smoothly andavoidconflictswithotherHadoopcomponen tsrunningonthesamecluster.Whenyoudetectthatan
issuehashappened orcouldhappeninthefuture,youreconfigureImpalaorothercomponen tssuchasHDFSoreven
thehardwareoftheclusteritselftoresolveoravoidproblems.
Relatedtasks:
Asanadministrator,youcanexpecttoperforminstallation,upgrade,andconfigurationtasksforImpalaonallmachines
inacluster.SeeImpalaUpgradeConsiderationsonpage38,andManaging Impalaonpage36fordetails.
Forsecuritytaskstypicallyperformedbyadministrators,seeImpalaSecurityonpage82.
AdministratorsalsodecidehowtoallocateclusterresourcessothatallHadoopcomponen tscanrunsmoothly together.
ForImpala,thistaskprimarily involves:
â¢DecidinghowmanyImpalaqueriescanrunconcurrentlyandwithhowmuchmemory,throughtheadmission
controlfeature.SeeAdmission ControlandQueryQueuingonpage549fordetails.
â¢DividingclusterresourcessuchasmemorybetweenImpalaandothercomponen ts,usingYARNforoverallresource
management,andLlamatomediateresourcerequestsfromImpalatoYARN.SeeResourceManagementonpage
549fordetails.
SettingTimeoutPeriodsforDaemons, Queries,andSessions
Depending onhowbusyyourCDHclusteris,youmightincreaseordecreasevarioustimeoutvalues.Increasetimeouts
ifImpalaiscancelling operationsprematurely,whenthesystemisresponding slowerthanusualbuttheoperations
arestillsuccessfulifgivenextratime.Decreasetimeouts ifoperationsareidleorhangingforlongperiods,andtheidle
orhungoperationsareconsuming resourcesandreducingconcurrency.
IncreasingtheStatestoreTimeout
IfyouhaveanextensiveImpalaschema,forexamplewithhundredsofdatabases,tensofthousands oftables,andso
on,youmightencountertimeouterrorsduringstartupastheImpalacatalogservicebroadcastsmetadatatoallthe
Impalanodesusingthestatestoreservice.Toavoidsuchtimeouterrorsonstartup,increasethestatestoretimeout
valuefromitsdefaultof10seconds.Specifythetimeoutvalueusingthe
-statestore_subscriber_timeout_seconds optionforthestatestoreservice,usingtheconfigurationinstructions
inModifyingImpalaStartupOptions.Thesymptomofthisproblemismessagesintheimpalad logsuchas:
Connection with state-store lost
Trying to re-register with state-store
SeeScalabilityConsiderationsfortheImpalaStatestoreonpage606formoredetailsaboutstatestoreoperationand
settingsonclusterswithalargenumberofImpala-relatedobjectssuchastablesandpartitions.
SettingtheIdleQueryandIdleSessionTimeouts forimpalad
Tokeeplong-running queriesoridlesessionsfromtyingupclusterresources,youcansettimeoutintervalsforboth
individual queries,andentiresessions.
70|ApacheImpalaGuideImpalaAdministration
Note:
Thetimeoutclockforqueriesandsessionsonlystartstickingwhenthequeryorsessionisidle.
Forqueries,thismeansthequeryhasresultsreadybutiswaitingforaclienttofetchthedata.Aquery
canrunforanarbitrarytimewithouttriggeringatimeout,becausethequeryiscomputing results
ratherthansittingidlewaitingfortheresultstobefetched.Thetimeoutperiodisintendedtoprevent
unclosed queriesfromconsuming resourcesandtakingupslotsintheadmission countofrunning
queries,potentiallypreventingotherqueriesfromstarting.
Forsessions, thismeansthatnoqueryhasbeensubmittedforsomeperiodoftime.
Usethefollowingstartupoptionsfortheimpalad daemontospecifytimeoutvalues:
â¢--idle_query_timeout
Specifies thetimeinsecondsafterwhichanidlequeryiscancelled. Thiscouldbeaquerywhoseresultswereall
fetchedbutwasneverclosed,oronewhoseresultswerepartiallyfetchedandthentheclientprogramstopped
requestingfurtherresults.ThisconditionismostlikelytooccurinaclientprogramusingtheJDBCorODBC
interfaces,ratherthanintheinteractiveimpala-shell interpreter.Onceaqueryiscancelled, theclientprogram
cannotretrieveanyfurtherresultsfromthequery.
YoucanreducetheidlequerytimeoutbyusingtheQUERY_TIMEOUT_S queryoption.Anynon-zerovaluespecified
forthe--idle_query_timeout startupoptionservesasanupperlimitfortheQUERY_TIMEOUT_S queryoption.
SeeQUERY_TIMEOUT_SQueryOption(CDH5.2orhigheronly)onpage355aboutthequeryoption.
Azerovaluefor--idle_query_timeout disablesquerytimeouts.
Cancelled queriesremainintheopenstatebutuseonlytheminimalresources.
â¢--idle_session_timeout
Specifies thetimeinsecondsafterwhichanidlesessionexpires.Asessionisidlewhennoactivityisoccurring for
anyofthequeriesinthatsession,andthesessionhasnotstartedanynewqueries.Onceasessionisexpired,you
cannotissueanynewqueryrequeststoit.Thesessionremainsopen,buttheonlyoperationyoucanperformis
tocloseit.
Thedefaultvalueof0specifiessessionsneverexpire.
Youcanoverridethe--idle_session_timeout valuewiththeIDLE_SESSION_TIME OUTQueryOption(CDH
5.15/Impala2.12orhigheronly)onpage335atthesessionlevel.
Forinstructions onchangingimpalad startupoptions,seeModifyingImpalaStartupOptions.
Note:
Impalachecksperiodicallyforidlesessionsandqueriestocancel.Theactualidletimebefore
cancellationmightbeupto50%greaterthanthespecified configurationsetting.Forexample,ifthe
timeoutsettingwas60,thesessionorquerymightbecancelledafterbeingidlebetween60and90
seconds.
SettingTimeoutandRetriesforThriftConnections totheBackendClient
Impalaconnections tothebackendclientaresubjecttofailureincaseswhenthenetworkismomentarilyoverloaded.
Toavoidfailedqueriesduetotransientnetworkproblems,youcanconfigurethenumberofThriftconnection retries
usingthefollowingoption:
â¢The--backend_client_connection_num_retries optionspecifiesthenumberoftimesImpalawilltry
connecting tothebackendclientafterthefirstconnection attemptfails.Bydefault,impalad willattemptthree
re-connections beforeitreturnsafailure.
ApacheImpalaGuide|71ImpalaAdministration
Youcanconfiguretimeouts forsendingandreceivingdatafromthebackendclient.Therefore,ifforsomereasona
queryhangs,insteadofwaitingindefinitelyforaresponse, Impalawillterminatetheconnection afteraconfigurable
timeout.
â¢The--backend_client_rpc_timeout_ms optioncanbeusedtospecifythenumberofmillisecondsImpala
shouldwaitforaresponsefromthebackendclientbeforeitterminatestheconnection andsignalsafailure.The
defaultvalueforthispropertyis300000milliseconds,or5minutes.
Cancelling aQuery
Occasionally,anImpalaquerymightrunforanunexpectedlylongtime,tyingupresourcesinthecluster.Thissection
describes theoptionstoterminatesuchrunawayqueries.
SettingaTimeLimitonQueryExecution
AnImpalaadministratorcansetadefaultvalueoftheEXEC_TIME_LIMIT_S queryoptionforaresourcepool.Ifa
useraccidentallyrunsalargequerythatexecutesforlongerthanthelimit,itwillbeautomaticallyterminatedafter
thetimelimitexpirestofreeupresources.
YoucanoverridethedefaultvalueperqueryorpersessionifyoudonotwanttoapplythedefaultEXEC_TIME_LIMIT_S
valuetoaspecificqueryorasession.SeeEXEC_TIME_LIMIT_S QueryOption(CDH5.15/Impala2.12orhigheronly)
onpage331forthedetailsofthequeryoption.
InteractivelyCancelling aQuery
Youcanmanually cancelaqueryintheImpalaWebUIfortheimpalad host(onport25000bydefault):
1.Click/queries.
2.ClickCancelforaqueryinthequeriesinflightlist.
Variousclientapplicationsletyouinteractivelycancelqueriessubmittedormonitoredthroughthoseapplications.For
example:
â¢Press^Cinimpala-shell .
â¢ClickCancelfromtheWatchpageinHue.
UsingImpalathroughaProxyforHighAvailability
Formostclustersthathavemultipleusersandproduction availabilityrequirements,youmightwanttosetupa
load-balancing proxyservertorelayrequeststoandfromImpala.
Setupasoftwarepackageofyourchoicetoperformthesefunctions.
Note:
Mostconsiderationsforloadbalancing andhighavailabilityapplytotheimpalad daemon. The
statestored andcatalogd daemons donothavespecialrequirementsforhighavailability,because
problemswiththosedaemons donotresultindataloss.Ifthosedaemons becomeunavailabledue
toanoutageonaparticular host,youcanstoptheImpalaservice,deletetheImpalaStateStoreand
ImpalaCatalogServerroles,addtherolesonadifferenthost,andrestarttheImpalaservice.
OverviewofProxyUsageandLoadBalancing forImpala
Usingaload-balancing proxyserverforImpalaoffersthefollowingadvantages:
â¢Applicationsconnecttoasinglewell-knownhostandport,ratherthankeepingtrackofthehostswherethe
impalad daemons arerunning.
â¢Ifanyhostrunninganimpalad becomesunavailable,applicationconnection requestsstillsucceedbecauseyou
alwaysconnecttotheproxyserverratherthanaspecifichostrunningtheimpalad daemon.
72|ApacheImpalaGuideImpalaAdministration
â¢ThecoordinatornodeforeachImpalaquerypotentiallyrequiresmorememoryandCPUcyclesthantheother
nodesthatprocessthequery.Theproxyservercanschedule queriessothateachconnection usesadifferent
coordinatornode.Thisload-balancing technique letstheimpalad nodessharethisadditional work,ratherthan
directingitonasinglemachine.
Thefollowingarethegeneralsetupstepsthatapplytoanyload-balancing proxysoftware:
1.Selectanddownloadaload-balancing proxysoftwareorotherload-balancing hardwareappliance. Itshouldonly
needtobeinstalledandconfiguredonasinglehost,typicallyonanedgenode.
2.Configuretheloadbalancer(typicallybyeditingaconfigurationfile).Inparticular:
â¢TorelayImpalarequestsbackandforth,setupaportthattheloadbalancerwilllistenon.
â¢Selectaloadbalancing algorithm.SeeChoosing theLoad-Balancing Algorithmonpage73forloadbalancing
algorithmoptions.
â¢ForKerberizedclusters,followtheinstructions inSpecialProxyConsiderationsforClustersUsingKerberos
onpage74.
3.IfyouareusingHueorJDBC-based applications,youtypicallysetuploadbalancing forbothports21000and
21050,becausetheseclientapplicationsconnectthroughport21050whiletheimpala-shell command connects
throughport21000.SeePortsUsedbyImpalaonpage743forwhentouseport21000,21050,oranothervalue
depending onwhattypeofconnections youareloadbalancing.
4.Runtheload-balancing proxyserver,pointingitattheconfigurationfilethatyousetup.
5.OnsystemsmanagedbyClouderaManager:
a.NavigatetoImpala>Configuration>ImpalaDaemonDefaultGroup.
b.IntheImpalaDaemons LoadBalancer field,specifytheaddressoftheloadbalancerinthehost:port
format.
ThissettingletsClouderaManagerrouteallappropriateImpala-relatedoperationsthroughtheload-balancing
proxyserver.
6.Foranyscripts,jobs,orconfigurationsettingsforapplicationsthatformerlyconnectedtoaspecificimpalad to
runImpalaSQLstatements,changetheconnection information(suchasthe-ioptioninimpala-shell )topoint
totheloadbalancerinstead.
Note:ThefollowingsectionsusetheHAProxysoftwareasarepresentativeexampleofaloadbalancer
thatyoucanusewithImpala.ForinformationspecificallyaboutusingImpalawiththeF5BIG-IPload
balancer,seeImpalaHAwithF5BIG-IP.
Choosing theLoad-Balancing Algorithm
Load-balancing softwareoffersanumberofalgorithmstodistributerequests.Eachalgorithmhasitsowncharacteristics
thatmakeitsuitableinsomesituationsbutnotothers.
Leastconn
Connects sessionstothecoordinatorwiththefewestconnections, tobalancetheloadevenly.Typicallyusedfor
workloadsconsistingofmanyindependen t,short-running queries.Inconfigurationswithonlyafewclientmachines,
thissettingcanavoidhavingallrequestsgotoonlyasmallsetofcoordinators.
Recommended forImpalawithF5.
SourceIPPersistence
SessionsfromthesameIPaddressalwaysgotothesamecoordinator.AgoodchoiceforImpalaworkloadscontaining
amixofqueriesandDDLstatements,suchasCREATE TABLE andALTER TABLE .Becausethemetadatachanges
fromaDDLstatementtaketimetopropagateacrossthecluster,prefertousetheSourceIPPersistencealgorithm
inthiscase.IfyouareunabletochooseSourceIPPersistence,runtheDDLandsubsequentqueriesthatdepend
ontheresultsoftheDDLthroughthesamesession,forexamplebyrunningimpala-shell -f script_file
tosubmitseveralstatementsthroughasinglesession.
ApacheImpalaGuide|73ImpalaAdministration
RequiredforsettinguphighavailabilitywithHue.SeeConfigureHiveandImpalaforHighAvailabilityforconfiguring
highavailabilitywithHue.
Round-robin
Distributesconnections toallcoordinatornodes.Typicallynotrecommended forImpala.
Youmightneedtoperformbenchmark sandloadtestingtodeterminewhichsettingisoptimalforyourusecase.
Alwayssetupusingtwoload-balancing algorithms:SourceIPPersistenceforHueandLeastconnforothers.
SpecialProxyConsiderationsforClustersUsingKerberos
InaclusterusingKerberos,applicationscheckhostcredentialstoverifythatthehosttheyareconnecting toisthe
sameonethatisactuallyprocessingtherequest.
InImpala2.11andlowerversions,onceyouenableaproxyserverinaKerberizedcluster,userswillnotbeableto
connecttoindividual impaladaemons directlyfromimpala-shell.
InImpala2.12andhigher,whenyouenableaproxyserverinaKerberizedcluster,usershaveanoptiontoconnectto
Impaladaemons directlyfromimpala-shell usingthe-b/--kerberos_host_fqdn impala-shell flag.This
optioncanbeusedfortestingortroubleshooting purposes, butnotrecommended forliveproduction environments
asitdefeatsthepurposeofaloadbalancer/pr oxy.
Example:
impala-shell -i impalad-1.mydomain.com -k -b loadbalancer-1.mydomain.com
Alternatively,withthefullyqualified configurations:
impala-shell --impalad=impalad-1.mydomain.com:21000 --kerberos 
--kerberos_host_fqdn=loadbalancer-1.mydomain.com
Seeimpala-shell ConfigurationOptionsonpage714forinformationabouttheoption.
Tovalidatetheload-balancing proxyserver,performtheseextraKerberossetupsteps:
1.ThissectionassumesyouarestartingwithaKerberos-enabled cluster.SeeEnablingKerberosAuthenticationfor
Impalaonpage94forinstructions forsettingupImpalawithKerberos.SeeEnablingKerberosAuthenticationfor
CDHforgeneralstepstosetupKerberos.
2.Choosethehostyouwillusefortheproxyserver.BasedontheKerberossetupprocedure,itshouldalreadyhave
anentryimpala/proxy_host @realminitskeytab.
3.InClouderaManager,navigatetoImpala>Configuration>ImpalaDaemonDefaultGroup.
4.IntheImpalaDaemons LoadBalancer field,specifytheaddressoftheloadbalancerinthehost:portformat.
Whenthisfieldisspecified andKerberosisenabled, ClouderaManageraddsaprincipalfor
impala/proxy_host @realmtothekeytabforallImpaladaemons.
5.RestarttheImpalaservice.
ClientConnection toProxyServerinKerberizedClusters
WhenaclientconnecttoImpala,theserviceprincipalspecified bytheclientmustmatchthe-principal setting,
impala/proxy_host @realm,oftheImpalaproxyserverasspecified initskeytab.Andtheclientshouldconnect
totheproxyserverport.
Inhue.ini ,setthefollowingtoconfigureHuetoautomaticallyconnecttotheproxyserver:
[impala]
server_host= proxy_host
impala_principal=impala/ proxy_host
74|ApacheImpalaGuideImpalaAdministration
ThefollowingaretheJDBCconnection stringformatswhenconnecting throughtheloadbalancerwiththeload
balancer's hostnameintheprincipal:
jdbc:hive2:// proxy_host :load_balancer_port /;principal=impala/_HOST@ realm
jdbc:hive2:// proxy_host :load_balancer_port /;principal=impala/ proxy_host @realm
Whenstartingimpala-shell ,specifytheserviceprincipalviathe-bor--kerberos_host_fqdn flag.
SpecialProxyConsiderationsforTLS/SSLEnabledClusters
WhenTLS/SSLisenabledforImpala,theclientapplication,whetherimpala-shell, Hue,orsomethingelse,expectsthe
certificatecommonname(CN)tomatchthehostnamethatitisconnectedto.Withnoloadbalancing proxyserver,
thehostnameandcertificateCNareboththatoftheimpalad instance.However,withaproxyserver,thecertificate
presentedbytheimpalad instancedoesnotmatchtheloadbalancing proxyserverhostname.Ifyoutrytoload-balance
aTLS/SSL-enabled Impalainstallationwithoutadditional configuration,youseeacertificatemismatcherrorwhena
clientattemptstoconnecttotheloadbalancing proxyhost.
YoucanconfigureaproxyserverinseveralwaystoloadbalanceTLS/SSLenabledImpala:
TLS/SSLBridging
Inthisconfiguration,theproxyserverpresentsaTLS/SSLcertificatetotheclient,decryptstheclientrequest,then
re-encryptstherequestbeforesendingittothebackendimpalad .Theclientandservercertificatescanbemanaged
separately.Therequestorresultingpayloadisencryptedintransitatalltimes.
TLS/SSLPassthrough
Inthisconfiguration,trafficpassesthroughtothebackendimpalad instancewithnointeractionfromtheload
balancing proxyserver.Trafficisstillencryptedend-to-end.
Thesameservercertificate,utilizingeitherwildcardorSubjectAlternateName(SAN),mustbeinstalledoneach
impalad instance.
TLS/SSLOffload
Inthisconfiguration,alltrafficisdecryptedontheloadbalancing proxyserver,andtrafficbetweenthebackend
impalad instancesisunencrypted.Thisconfigurationpresumesthatclusterhostsresideonatrustednetworkand
onlyexternalclient-facingcommunic ationneedtobeencryptedin-transit.
IfyouplantouseAuto-TLS,yourloadbalancermustperformTLS/SSLbridgingorTLS/SSLoffload.
Refertoyourloadbalancerdocumen tationforthestepstosetupImpalaandtheloadbalancerusingoneoftheoptions
above.
ForinformationspecificallyaboutusingImpalawiththeF5BIG-IPloadbalancerwithTLS/SSLenabled, seeImpalaHA
withF5BIG-IP.
ExampleofConfiguringHAProxyLoadBalancerforImpala
Ifyouarenotalreadyusingaload-balancing proxy,youcanexperimen twithHAProxyafree,opensourceloadbalancer.
ThisexampleshowshowyoumightinstallandconfigurethatloadbalanceronaRedHatEnterpriseLinuxsystem.
â¢Installtheloadbalancer:
yum install haproxy 
â¢Setuptheconfigurationfile:/etc/haproxy/haproxy.cfg .Seethefollowingsectionforasampleconfiguration
file.
â¢Runtheloadbalancer(onasinglehost,preferablyonenotrunningimpalad ):
/usr/sbin/haproxy âf /etc/haproxy/haproxy.cfg
ApacheImpalaGuide|75ImpalaAdministration
â¢Inimpala-shell ,JDBCapplications,orODBCapplications,connecttothelistenerportoftheproxyhost,rather
thanport21000or21050onahostactuallyrunningimpalad .Thesampleconfigurationfilesetshaproxytolisten
onport25003,thereforeyouwouldsendallrequeststohaproxy_host :25003.
Thisisthesamplehaproxy.cfg usedinthisexample:
global
    # To have these messages end up in /var/log/haproxy.log you will
    # need to:
    #
    # 1) configure syslog to accept network log events.  This is done
    #    by adding the '-r' option to the SYSLOGD_OPTIONS in
    #    /etc/sysconfig/syslog
    #
    # 2) configure local2 events to go to the /var/log/haproxy.log
    #   file. A line like the following can be added to
    #   /etc/sysconfig/syslog
    #
    #    local2.*                       /var/log/haproxy.log
    #
    log         127.0.0.1 local0
    log         127.0.0.1 local1 notice
    chroot      /var/lib/haproxy
    pidfile     /var/run/haproxy.pid
    maxconn     4000
    user        haproxy
    group       haproxy
    daemon
    # turn on stats unix socket
    #stats socket /var/lib/haproxy/stats
#---------------------------------------------------------------------
# common defaults that all the 'listen' and 'backend' sections will
# use if not designated in their block
#
# You might need to adjust timing values to prevent timeouts.
#
# The timeout values should be dependant on how you use the cluster
# and how long your queries run.
#---------------------------------------------------------------------
defaults
    mode                    http
    log                     global
    option                  httplog
    option                  dontlognull
    option http-server-close
    option forwardfor       except 127.0.0.0/8
    option                  redispatch
    retries                 3
    maxconn                 3000
    timeout connect 5000
    timeout client 3600s
    timeout server 3600s
#
# This sets up the admin page for HA Proxy at port 25002.
#
listen stats :25002
    balance
    mode http
    stats enable
    stats auth username :password
# This is the setup for Impala. Impala client connect to load_balancer_host:25003.
# HAProxy will balance connections among the list of servers listed below.
# The list of Impalad is listening at port 21000 for beeswax (impala-shell) or original
 ODBC driver.
# For JDBC or ODBC version 2.x driver, use port 21050 instead of 21000.
listen impala :25003
    mode tcp
    option tcplog
76|ApacheImpalaGuideImpalaAdministration
    balance leastconn
    server symbolic_name_1  impala-host-1.example.com:21000 check
    server symbolic_name_2  impala-host-2.example.com:21000 check
    server symbolic_name_3  impala-host-3.example.com:21000 check
    server symbolic_name_4  impala-host-4.example.com:21000 check
# Setup for Hue or other JDBC-enabled applications.
# In particular, Hue requires sticky sessions.
# The application connects to load_balancer_host:21051, and HAProxy balances
# connections to the associated hosts, where Impala listens for JDBC
# requests on port 21050.
listen impalajdbc :21051
    mode tcp
    option tcplog
    balance source
    server symbolic_name_5  impala-host-1.example.com:21050 check
    server symbolic_name_6  impala-host-2.example.com:21050 check
    server symbolic_name_7  impala-host-3.example.com:21050 check
    server symbolic_name_8  impala-host-4.example.com:21050 check
Important:HuerequiresthecheckoptionattheendofeachlineintheabovefiletoensureHAProxy
candetectanyunreachableimpalad server,andfailovercanbesuccessful.WithouttheTCPcheck,
youcanhitanerrorwhentheimpalad daemontowhichHuetriestoconnectisdown.
Note:IfyourJDBCorODBCapplicationconnectstoImpalathroughaloadbalancersuchashaproxy ,
becautiousaboutreusingtheconnections. Iftheloadbalancerhassetupconnection timeoutvalues,
eitherchecktheconnection frequentlysothatitneversitsidlelongerthantheloadbalancertimeout
value,orchecktheconnection validitybeforeusingitandcreateanewoneiftheconnection has
beenclosed.
Managing DiskSpaceforImpalaData
Although ImpalatypicallyworkswithmanylargefilesinanHDFSstoragesystemwithplentyofcapacity,thereare
timeswhenyoumightperformsomefilecleanuptoreclaimspace,oradvisedevelopersontechniques tominimize
spaceconsumptionandfileduplication.
â¢Usecompactbinaryfileformatswherepractical.Numericandtime-based datainparticular canbestoredinmore
compactforminbinarydatafiles.Depending onthefileformat,variouscompressionandencodingfeaturescan
reducefilesizeevenfurther.YoucanspecifytheSTORED AS clauseaspartoftheCREATE TABLE statement,or
ALTER TABLE withtheSET FILEFORMAT clauseforanexistingtableorpartitionwithinapartitioned table.See
HowImpalaWorkswithHadoopFileFormatsonpage634fordetailsaboutfileformats,especially UsingtheParquet
FileFormatwithImpalaTablesonpage643.SeeCREATETABLEStatementonpage234andALTERTABLEStatement
onpage205forsyntaxdetails.
â¢Youmanageunderlying datafilesdifferentlydepending onwhetherthecorresponding Impalatableisdefinedas
aninternalorexternaltable:
âUsetheDESCRIBE FORMATTED statementtocheckifaparticular tableisinternal(managedbyImpala)or
external,andtoseethephysicallocationofthedatafilesinHDFS.SeeDESCRIBEStatementonpage251for
details.
âForImpala-manag ed(âinternalâ)tables,useDROP TABLE statementstoremovedatafiles.SeeDROPTABLE
Statementonpage268fordetails.
âFortablesnotmanagedbyImpala(âexternalâtables),useappropriateHDFS-relatedcommands suchas
hadoop fs ,hdfs dfs ,ordistcp,tocreate,move,copy,ordeletefileswithinHDFSdirectoriesthatare
accessible bytheimpalauser.IssueaREFRESH table_name statementafteraddingorremovinganyfiles
fromthedatadirectoryofanexternaltable.SeeREFRESHStatementonpage291fordetails.
ApacheImpalaGuide|77ImpalaAdministration
âUseexternaltablestoreferenceHDFSdatafilesintheiroriginallocation.Withthistechnique, youavoid
copyingthefiles,andyoucanmapmorethanoneImpalatabletothesamesetofdatafiles.Whenyoudrop
theImpalatable,thedatafilesareleftundisturbed.SeeExternalTablesonpage197fordetails.
âUsetheLOAD DATA statementtomoveHDFSfilesintothedatadirectoryforanImpalatablefrominside
Impala,withouttheneedtospecifytheHDFSpathofthedestinationdirectory.Thistechnique worksforboth
internalandexternaltables.SeeLOADDATAStatementonpage288fordetails.
â¢MakesurethattheHDFStrashcanisconfiguredcorrectly.WhenyouremovefilesfromHDFS,thespacemightnot
bereclaimed forusebyotherfilesuntilsometimelater,whenthetrashcanisemptied.SeeDROPTABLEStatement
onpage268andtheFAQentryWhyisspacenotfreedupwhenIissueDROPTABLE?onpage772fordetails.See
UserAccountRequirementsonpage25forpermissions neededfortheHDFStrashcantooperatecorrectly.
â¢Dropalltablesinadatabasebeforedroppingthedatabaseitself.SeeDROPDATABASEStatementonpage262for
details.
â¢CleanuptemporaryfilesafterfailedINSERTstatements.IfanINSERTstatementencountersanerror,andyou
seeadirectorynamed.impala_insert_staging or_impala_insert_staging leftbehindinthedata
directoryforthetable,itmightcontaintemporarydatafilestakingupspaceinHDFS.Youmightbeabletosalvage
thesedatafiles,forexampleiftheyarecompletebutcouldnotbemovedintoplaceduetoapermission error.
Or,youmightdeletethosefilesthroughcommands suchashadoop fs orhdfs dfs ,toreclaimspacebefore
re-tryingtheINSERT.IssueDESCRIBE FORMATTED table_name toseetheHDFSpathwhereyoucancheckfor
temporaryfiles.
â¢Bydefault,intermediatefilesusedduringlargesort,join,aggregation,oranalyticfunctionoperationsarestored
inthedirectory/tmp/impala-scratch .Thesefilesareremovedwhentheoperationfinishes.(Multiple concurrent
queriescanperformoperationsthatusetheâspilltodiskâtechnique, withoutanynameconflictsforthese
temporaryfiles.)Youcanspecifyadifferentlocationbystartingtheimpalad daemonwiththe
--scratch_dirs=" path_to_directory "configurationoptionortheequivalentconfigurationoptioninthe
ClouderaManageruserinterface.Youcanspecifyasingledirectory,oracomma-separ atedlistofdirectories.The
scratchdirectoriesmustbeonthelocalfilesystem,notinHDFS.Youmightspecifydifferentdirectorypathsfor
differenthosts,depending onthecapacityandspeedoftheavailablestoragedevices.InCDH5.5/Impala2.3or
higher,Impalasuccessfullystarts(withawarningwrittentothelog)ifitcannotcreateorreadandwritefilesin
oneofthescratchdirectories.Ifthereislessthan1GBfreeonthefilesystemwherethatdirectoryresides,Impala
stillruns,butwritesawarningmessagetoitslog.IfImpalaencountersanerrorreadingorwritingfilesinascratch
directoryduringaquery,Impalalogstheerrorandthequeryfails.
â¢IfyouusetheAmazonSimpleStorageService(S3)asaplacetooffloaddatatoreducethevolumeoflocalstorage,
Impala2.2.0andhighercanquerythedatadirectlyfromS3.SeeUsingImpalawiththeAmazonS3Filesystemon
page692fordetails.
AuditingImpalaOperations
TomonitorhowImpaladataisbeingusedwithinyourorganization,ensurethatyourImpalaauthorizationand
authenticationpoliciesareeffective,anddetectattemptsatintrusionorunauthoriz edaccesstoImpaladata,youcan
usetheauditingfeatureinImpala1.2.1andhigher:
â¢Enableauditingbyincluding theoption--audit_event_log_dir= directory_path inyourimpalad startup
optionsforaclusternotmanagedbyClouderaManager,orconfiguringImpalaDaemonlogginginCloudera
Manager.Thelogdirectorymustbealocaldirectoryontheserver,notanHDFSdirectory.
â¢Decidehowmanyquerieswillberepresentedineachlogfiles.Bydefault,Impalastartsanewlogfileevery5000
queries.Tospecifyadifferentnumber,includetheoption
--max_audit_event_log_file_size= number_of_queries intheimpalad startupoptions.
â¢ConfigureClouderaNavigatortocollectandconsolidatetheauditlogsfromallthehostsinthecluster.
â¢InCDH5.12/Impala2.9andhigher,youcancontrolhowmanyauditeventlogfilesarekeptoneachhost.Specify
theoption--max_audit_event_log_files= number_of_log_files intheimpalad startupoptions.Once
thelimitisreached,olderfilesarerotatedoutusingthesamemechanism asforotherImpalalogfiles.Thedefault
valueforthissettingis0,representinganunlimitednumberofauditeventlogfiles.
78|ApacheImpalaGuideImpalaAdministration
â¢UseClouderaNavigatororClouderaManagertofilter,visualize,andproducereportsbasedontheauditdata.
(TheImpalaauditingfeatureworkswithClouderaManager4.7to5.1andClouderaNavigator2.1andhigher.)
Checktheauditdatatoensurethatallactivityisauthorizedanddetectattemptsatunauthoriz edaccess.
DurabilityandPerformance ConsiderationsforImpalaAuditing
Theauditingfeatureonlyimposesperformance overheadwhileauditingisenabled.
BecauseanyImpalahostcanprocessaquery,enableauditingonallhostswheretheimpalad daemonruns.Each
hoststoresitsownlogfiles,inadirectoryinthelocalfilesystem.Thelogdataisperiodicallyflushedtodisk(through
anfsync() systemcall)toavoidlossofauditdataincaseofacrash.
Theruntimeoverheadofauditingappliestowhicheverhostservesasthecoordinatorforthequery,thatis,thehost
youconnecttowhenyouissuethequery.Thismightbethesamehostforallqueries,ordifferentapplicationsorusers
mightconnecttoandissuequeriesthroughdifferenthosts.
ToavoidexcessiveI/Ooverheadonbusycoordinatorhosts,Impalasyncstheauditlogdata(usingthefsync() system
call)periodicallyratherthanaftereveryquery.Currently,thefsync() callsareissuedatafixedinterval,every5
seconds.
Bydefault,Impalaavoidslosinganyauditlogdatainthecaseofanerrorduringaloggingoperation(suchasadiskfull
error),byimmediatelyshuttingdownimpalad onthehostwheretheauditingproblemoccurred.Youcanoverride
thissettingbyspecifyingtheoption--abort_on_failed_audit_event=false intheimpalad startupoptions.
FormatoftheAuditLogFiles
TheauditlogfilesrepresentthequeryinformationinJSONformat,onequeryperline.Typically,ratherthanlooking
atthelogfilesthemselves,youusetheClouderaNavigatorproducttoconsolidatethelogdatafromallImpalahosts
andfilterandvisualizetheresultsinusefulways.(Ifyoudoexaminetherawlogdata,youmightrunthefilesthrough
aJSONpretty-printerfirst.)
Alltheinformationaboutschemaobjectsaccessed bythequeryisencodedinasinglenestedrecordonthesameline.
Forexample,theauditlogforanINSERT ... SELECT statementrecordsthataselectoperationoccursonthesource
tableandaninsertoperationoccursonthedestinationtable.Theauditlogforaqueryagainstaviewrecordsthebase
tableaccessed bytheview,ormultiplebasetablesinthecaseofaviewthatincludesajoinquery.EveryImpala
operationthatcorrespondstoaSQLstatementisrecordedintheauditlogs,whethertheoperationsucceeds orfails.
Impalarecordsmoreinformationforasuccessfuloperationthanforafailedone,becauseanunauthoriz edqueryis
stoppedimmediately,beforeallthequeryplanningiscompleted.
Theinformationloggedforeachqueryincludes:
â¢Clientsessionstate:
âSessionID
âUsername
âNetworkaddressoftheclientconnection
â¢SQLstatementdetails:
âQueryID
âStatementType-DML,DDL,andsoon
âSQLstatementtext
âExecutionstarttime,inlocaltime
âExecutionStatus-Detailsonanyerrorsthatwereencountered
âTargetCatalogObjects:
âObjectType-Table,View,orDatabase
âFullyqualified objectname
âPrivilege-Howtheobjectisbeingused(SELECT,INSERT,CREATE,andsoon)
ApacheImpalaGuide|79ImpalaAdministration
WhichOperationsAreAudited
ThekindsofSQLqueriesrepresentedintheauditlogare:
â¢Queriesthatcausedatatobereturnedorchanged.
Thisincludesqueriesthatfailwhilerunningbutstillstreampartialresultstotheuser.
â¢Queriesthatarepreventedduetolackofauthorization,evenifnothingisreturnedorchanged.
â¢QueriesthatImpalacananalyzeandparsetodeterminethattheyareauthorized.
TheauditdataisrecordedimmediatelyafterImpalafinishesitsanalysisandbeforethequeryisactuallyexecuted.
Otherthanauditsforlackofauthorization,theauditlogdoesnotcontainentriesforqueriesthatcouldnotbeparsed
andanalyzed,suchaserrors,cancelledqueries,andtimedoutqueries.Forexample,aquerythatfailsduetoasyntax
errorisnotrecordedintheauditlog.CertainstatementsintheImpala-shell interpreter,suchasCONNECT ,SUMMARY ,
PROFILE ,SET,andQUIT,donotcorrespondtoactualSQLqueries;thesestatementsarenotreflectedintheaudit
log.
ReviewingtheAuditLogs
Youtypicallydonotreviewtheauditlogsinrawform.TheClouderaManagerAgentperiodicallytransfersthelog
informationintoaback-end databasewhereitcanbeexaminedinconsolidatedform.SeetheClouderaNavigator
documen tationfordetails.
ViewingLineageInformationforImpalaData
LineageisafeatureintheClouderaNavigatordatamanagementcomponen tthathelpsyoutrackwheredataoriginated,
andhowdatapropagatesthroughthesystemthroughSQLstatementssuchasSELECT,INSERT,andCREATE TABLE
AS SELECT .ImpalaiscoveredbytheClouderaNavigatorlineagefeaturesinCDH5.4/Impala2.2andhigher.
Thistypeoftrackingisimportantinhigh-security configurations,especially inhighlyregulatedindustriessuchas
healthcare,pharmaceutic als,financialservicesandintelligence.Forsuchkindsofsensitivedata,itisimportanttoknow
alltheplacesinthesystemthatcontainthatdataorotherdataderivedfromit;toverifywhohasaccessed thatdata;
andtobeabletodoublecheck thatthedatausedtomakeadecisionwasprocessedcorrectlyandnottamperedwith.
Youinteractwiththisfeaturethroughlineagediagrams showingrelationshipsbetweentablesandcolumns.For
instructions aboutinterpretinglineagediagrams,see
http://www.cloudera.com/documen tation/enterprise/la test/topics/cn_iu_lineag e.html.
ColumnLineage
Columnlineagetracksinformationinfinedetail,atthelevelofparticular columnsratherthanentiretables.
Forexample,ifyouhaveatablewithinformationderivedfromweblogs,youmightcopythatdataintoothertables
aspartoftheETLprocess.TheETLoperationsmightinvolvetransformationsthroughexpressionsandfunctioncalls,
andrearrangingthecolumnsintomoreorfewertables(normalizing ordenormalizing thedata).Thenforreporting,
youmightissuequeriesagainstmultipletablesandviews.Inthisexample,columnlineagehelpsyoudeterminethat
datathatenteredthesystemasRAW_LOGS.FIELD1 wasthenturnedintoWEBSITE_REPORTS.IP_ADDRESS through
anINSERT ... SELECT statement.Or,conversely,youcouldstartwithareportingqueryagainstaview,andtrace
theoriginofthedatainafieldsuchasTOP_10_VISITORS.USER_ID backtotheunderlying tableandevenfurther
backtothepointwherethedatawasfirstloadedintoImpala.
Whenyouhavetableswhereyouneedtotrackorcontrolaccesstosensitiveinformationatthecolumnlevel,see
EnablingSentryAuthorizationforImpalaonpage87forhowtoimplemen tcolumn-levelsecurity.Yousetup
authorizationusingtheSentryframework,createviewsthatrefertospecificsetsofcolumns,andthenassign
authorizationprivilegestothoseviewsratherthantheunderlying tables.
80|ApacheImpalaGuideImpalaAdministration
LineageDataforImpala
Thelineagefeatureisenabledbydefault.Whenlineageloggingisenabled, theserializedcolumnlineagegraphis
computedforeachqueryandstoredinaspecializedlogfileinJSONformat.
Impalarecordsqueriesinthelineagelogiftheycompletesuccessfully,orfailduetoauthorizationerrors.Forwrite
operationssuchasINSERTandCREATE TABLE AS SELECT ,thestatementisrecordedinthelineagelogonlyifit
successfullycompletes.Therefore,thelineagefeaturetracksdatathatwasaccessed bysuccessfulqueries,orthatwas
attemptedtobeaccessed byunsuccess fulqueriesthatwereblockedduetoauthorizationfailure.Thesekindsofqueries
representdatathatreallywasaccessed, orwheretheattemptedaccesscouldrepresentmalicious activity.
Impaladoesnotrecordinthelineagelogqueriesthatfailduetosyntaxerrorsorthatfailorarecancelledbeforethey
reachthestageofrequestingrowsfromtheresultset.
ToenableordisablethisfeatureonasystemnotmanagedbyClouderaManager,setorremovethe
-lineage_event_log_dir configurationoptionfortheimpalad daemon. Forinformationaboutturningthelineage
featureonandoffthroughClouderaManager,see
http://www.cloudera.com/documen tation/enterprise/la test/topics/datamgmt_impala_lineag e_log.html.
ApacheImpalaGuide|81ImpalaAdministration
ImpalaSecurity
Impalaincludesafine-grainedauthorizationframeworkforHadoop,basedontheSentryopensourceproject.Sentry
authorizationwasaddedinImpala1.1.0.TogetherwiththeKerberosauthenticationframework,SentrytakesHadoop
securitytoanewlevelneededfortherequirementsofhighlyregulatedindustriessuchashealthcare,financialservices,
andgovernment.Impalaalsoincludesanauditingcapability; Impalageneratestheauditdata,theClouderaNavigator
productconsolidatestheauditdatafromallnodesinthecluster,andClouderaManagerletsyoufilter,visualize,and
producereports.TheauditingfeaturewasaddedinImpala1.1.1.
TheImpalasecurityfeatureshaveseveralobjectives.Atthemostbasiclevel,securitypreventsaccidentsormistakes
thatcoulddisruptapplicationprocessing,deleteorcorruptdata,orrevealdatatounauthoriz edusers.Moreadvanced
securityfeaturesandpracticescanhardenthesystemagainstmalicious userstryingtogainunauthoriz edaccessor
performotherdisallowedoperations.Theauditingfeatureprovidesawaytoconfirmthatnounauthoriz edaccess
occurred,anddetectwhetheranysuchattemptsweremade.Thisisacriticalsetoffeaturesforproduction deployments
inlargeorganizationsthathandleimportantorsensitivedata.Itsetsthestageformulti-tenancy,wheremultiple
applicationsrunconcurrentlyandarepreventedfrominterferingwitheachother.
ThematerialinthissectionpresumesthatyouarealreadyfamiliarwithadministeringsecureLinuxsystems.Thatis,
youshouldknowthegeneralsecuritypracticesforLinuxandHadoop,andtheirassociatedcommands andconfiguration
files.Forexample,youshouldknowhowtocreateLinuxusersandgroups,manageLinuxgroupmembership,setLinux
andHDFSfilepermissions andownership,anddesignatethedefaultpermissions andownershipfornewfiles.You
shouldbefamiliarwiththeconfigurationofthenodesinyourHadoopcluster,andknowhowtoapplyconfiguration
changesorrunasetofcommands acrossallthenodes.
Thesecurityfeaturesaredividedintothesebroadcategories:
authorization
Whichusersareallowedtoaccesswhichresources,andwhatoperationsaretheyallowedtoperform?Impalarelies
ontheopensourceSentryprojectforauthorization.Bydefault(whenauthorizationisnotenabled), Impaladoes
allreadandwriteoperationswiththeprivilegesoftheimpalauser,whichissuitableforadevelopment/test
environmentbutnotforasecureproduction environment.Whenauthorizationisenabled,ImpalausestheOSuser
IDoftheuserwhorunsimpala-shell orotherclientprogram,andassociatesvariousprivilegeswitheachuser.
SeeEnablingSentryAuthorizationforImpalaonpage87fordetailsaboutsettingupandmanaging authorization.
authentication
HowdoesImpalaverifytheidentityoftheusertoconfirmthattheyreallyareallowedtoexercisetheprivileges
assignedtothatuser?ImpalareliesontheKerberossubsystemforauthentication.SeeEnablingKerberos
AuthenticationforImpalaonpage94fordetailsaboutsettingupandmanaging authentication.
auditing
Whatoperationswereattempted,anddidtheysucceedornot?Thisfeatureprovidesawaytolookbackand
diagnose whetherattemptsweremadetoperformunauthoriz edoperations.Youusethisinformationtotrack
downsuspicious activity,andtoseewherechangesareneededinauthorizationpolicies.Theauditdataproduced
bythisfeatureiscollectedbytheClouderaManagerproductandthenpresentedinauser-friendly formbythe
ClouderaManagerproduct.SeeAuditingImpalaOperationsonpage78fordetailsaboutsettingupandmanaging
auditing.
SecurityGuidelines forImpala
ThefollowingarethemajorstepstohardenaclusterrunningImpalaagainstaccidentsandmistakes,ormalicious
attackerstryingtoaccesssensitivedata:
â¢Securetherootaccount.Therootusercantamperwiththeimpalad daemon, readandwritethedatafilesin
HDFS,logintootheruseraccounts,andaccessothersystemservicesthatarebeyondthecontrolofImpala.
82|ApacheImpalaGuideImpalaSecurity
â¢Restrictmembershipinthesudoers list(inthe/etc/sudoers file).Theuserswhocanrunthesudocommand
candomanyofthesamethingsastherootuser.
â¢EnsuretheHadoopownershipandpermissions forImpaladatafilesarerestricted.
â¢EnsuretheHadoopownershipandpermissions forImpalalogfilesarerestricted.
â¢EnsurethattheImpalawebUI(availablebydefaultonport25000oneachImpalanode)ispassword-protected.
SeeImpalaWebUserInterfaceforDebuggingonpage733fordetails.
â¢CreateapolicyfilethatspecifieswhichImpalaprivilegesareavailabletousersinparticular Hadoopgroups(which
bydefaultmaptoLinuxOSgroups).CreatetheassociatedLinuxgroupsusingthegroupadd command ifnecessary.
â¢TheImpalaauthorizationfeaturemakesuseoftheHDFSfileownershipandpermissions mechanism; forbackground
information,seetheHDFSPermissions Guide.SetupusersandassignthemtogroupsattheOSlevel,corresponding
tothedifferentcategoriesofuserswithdifferentaccesslevelsforvariousdatabases,tables,andHDFSlocations
(URIs).CreatetheassociatedLinuxusersusingtheuseradd command ifnecessary,andaddthemtotheappropriate
groupswiththeusermod command.
â¢Designyourdatabases,tables,andviewswithdatabaseandtablestructuretoallowpolicyrulestospecifysimple,
consistentrules.Forexample,ifalltablesrelatedtoanapplicationareinsideasingledatabase,youcanassign
privilegesforthatdatabaseandusethe*wildcardforthetablename.Ifyouarecreatingviewswithdifferent
privilegesthantheunderlying basetables,youmightputtheviewsinaseparatedatabasesothatyoucanuse
the*wildcardforthedatabasecontainingthebasetables,whilespecifyingtheprecisenamesoftheindividual
views.(Forspecifyingtableordatabasenames,youeitherspecifytheexactnameor*tomeanallthedatabases
onaserver,orallthetablesandviewsinadatabase.)
â¢Enableauthorizationbyrunningtheimpalad daemons withthe-server_name and
-authorization_policy_file optionsonallnodes.(Theauthorizationfeaturedoesnotapplytothe
statestored daemon, whichhasnoaccesstoschemaobjectsordatafiles.)
â¢SetupauthenticationusingKerberos,tomakesureusersreallyarewhotheysaytheyare.
SecuringImpalaDataandLogFiles
Oneaspectofsecurityistoprotectfilesfromunauthoriz edaccessatthefilesystemlevel.Forexample,ifyoustore
sensitivedatainHDFS,youspecifypermissions ontheassociatedfilesanddirectoriesinHDFStorestrictreadandwrite
permissions totheappropriateusersandgroups.
IfyouissuequeriescontainingsensitivevaluesintheWHEREclause,suchasfinancialaccountnumbers,thosevalues
arestoredinImpalalogfilesintheLinuxfilesystemandyoumustsecurethosefilesalso.ForthelocationsofImpala
logfiles,seeUsingImpalaLoggingonpage709.
AllImpalareadandwriteoperationsareperformedunderthefilesystemprivilegesoftheimpalauser.Theimpala
usermustbeabletoreadalldirectoriesanddatafilesthatyouquery,andwriteintoallthedirectoriesanddatafiles
forINSERTandLOAD DATA statements.Ataminimum, makesuretheimpalauserisinthehivegroupsothatit
canaccessfilesanddirectoriessharedbetweenImpalaandHive.SeeUserAccountRequirementsonpage25formore
details.
Settingfilepermissions isnecessaryforImpalatofunctioncorrectly,butisnotaneffectivesecuritypracticebyitself:
â¢Thewaytoensurethatonlyauthorizeduserscansubmitrequestsfordatabasesandtablestheyareallowedto
accessistosetupSentryauthorization,asexplainedinEnablingSentryAuthorizationforImpalaonpage87.With
authorizationenabled,thecheckingoftheuserIDandgroupisdonebyImpala,andunauthoriz edaccessisblocked
byImpalaitself.Theactuallow-levelreadandwriterequestsarestilldonebytheimpalauser,soyoumusthave
appropriatefileanddirectorypermissions forthatuserID.
â¢YoumustalsosetupKerberosauthentication,asdescribed inEnablingKerberosAuthenticationforImpalaon
page94,sothatuserscanonlyconnectfromtrustedhosts.WithKerberosenabled, ifsomeone connectsanew
ApacheImpalaGuide|83ImpalaSecurity
hosttothenetworkandcreatesuserIDsthatmatchyourprivilegedIDs,theywillbeblockedfromconnecting to
Impalaatallfromthathost.
InstallationConsiderationsforImpalaSecurity
Impala1.1comessetupwithallthesoftwareandsettingsneededtoenablesecuritywhenyouruntheimpalad
daemonwiththenewsecurity-r elatedoptions(-server_name and-authorization_policy_file ).Youdonot
needtochangeanyenvironmentvariablesorinstallanyadditional JARfiles.InaclustermanagedbyClouderaManager,
youdonotneedtochangeanysettingsinClouderaManager.
SecuringtheHiveMetastoreDatabase
ItisimportanttosecuretheHivemetastore,sothatuserscannotaccessthenamesorotherinformationaboutdatabases
andtablesthethroughtheHiveclientorbyqueryingthemetastoredatabase.DothisbyturningonHivemetastore
security,usingtheinstructions intheCDHSecurityGuideforsecuringdifferentHivecomponen ts:
â¢SecuretheHiveMetastore.
â¢Inaddition, allowaccesstothemetastoreonlyfromtheHiveServer2server,andthendisablelocalaccesstothe
HiveServer2server.
SecuringtheImpalaWebUserInterface
Theinstructions inthissectionpresumeyouarefamiliarwiththe.htpasswd mechanism commonly usedto
password-protectpagesonwebservers.
Password-protecttheImpalawebUIthatlistensonport25000bydefault.Setupa.htpasswd fileinthe$IMPALA_HOME
directory,orstartboththeimpalad andstatestored daemons withthe--webserver_password_file option
tospecifyadifferentlocation(including thefilename).
ThisfileshouldonlybereadablebytheImpalaprocessandmachineadministrators,becauseitcontains(hashed)
versionsofpasswords.Theusername /passwordpairsarenotderivedfromUnixusernames, Kerberosusers,orany
othersystem.ThedomainfieldinthepasswordfilemustmatchthedomainsuppliedtoImpalabythenewcommand-line
option--webserver_authentication_domain .Thedefaultismydomain.com .
Impalaalsosupports usingHTTPSforsecurewebtraffic.Todoso,set--webserver_certificate_file torefer
toavalid.pemTLS/SSLcertificatefile.ImpalawillautomaticallystartusingHTTPSoncetheTLS/SSLcertificatehas
beenreadandvalidated.A.pemfileisbasicallyaprivatekey,followedbyasignedTLS/SSLcertificate;makesureto
concatenatebothpartswhenconstructingthe.pemfile.
IfImpalacannotfindorparsethe.pemfile,itprintsanerrormessageandquits.
Note:
Iftheprivatekeyisencryptedusingapassphrase,Impalawillaskforthatpassphraseonstartup,which
isnotusefulforalargecluster.Inthatcase,removethepassphraseandmakethe.pemfilereadable
onlybyImpalaandadministrators.
WhenyouturnonTLS/SSLfortheImpalawebUI,theassociatedURLschangefromhttp:// prefixes
tohttps:// .Adjustanybookmark sorapplicationcodethatreferstothoseURLs.
ConfiguringSecureAccessforImpalaWebServers
ClouderaManagersupports password-basedauthenticationforsecureaccesstotheImpalaCatalogServer,Daemon,
andStateStorewebservers.
Authenticationforthethreetypesofdaemons canbeconfiguredindependen tly.
84|ApacheImpalaGuideImpalaSecurity
ConfiguringPasswordAuthentication
1.NavigatetoClusters>ImpalaService>Configuration.
2.Searchfor"password"usingtheSearchboxintheConfigurationtab.Thisshoulddisplaythepassword-related
properties(Username andPasswordproperties) fortheImpalaDaemon, StateStore,andCatalogServer.Ifthere
aremultiplerolegroupsconfiguredforImpalaDaemoninstances,thesearchshoulddisplayallofthem.
3.Enterausername andpasswordintothesefields.
4.ClickSaveChanges,andrestarttheImpalaservice.
NowwhenyouaccesstheWebUIfortheImpalaDaemon, StateStore,orCatalogServer,youareaskedtologinbefore
accessisgranted.
ConfiguringTLS/SSLforImpalaWebUI
1.CreateorobtainanTLS/SSLcertificate.
2.Placethecertificate,in.pemformat,onthehostswheretheImpalaCatalogServerandStateStorearerunning,
andoneachhostwhereanImpalaDaemonisrunning.Itcanbeplacedinanylocation(path)youchoose.Ifall
theImpalaDaemons aremembersofthesamerolegroup,thenthe.pemfilemusthavethesamepathonevery
host.
3.NavigatetoClusters>ImpalaService>Configuration.
4.Searchfor"certificate"usingtheSearchboxintheConfigurationtab.Thisshoulddisplaythecertificatefilelocation
propertiesfortheImpalaCatalogServer,ImpalaDaemon, andStateStore.Iftherearemultiplerolegroups
configuredforImpalaDaemoninstances,thesearchshoulddisplayallofthem.
5.Inthepropertyfields,enterthefullpathnametothecertificatefile,fillouttheprivatekeyfilepath,andthe
passwordfortheprivatekeyfile..
6.ClickSaveChanges,andrestarttheImpalaservice.
Important:IfClouderaManagercannotfindthe.pemfileonthehostforaspecificroleinstance,
thatrolewillfailtostart.
WhenyouaccesstheWebUIfortheImpalaCatalogServer,ImpalaDaemon, andStateStore,httpswillbeused.
ConfiguringTLS/SSLforImpala
Impalasupports TLS/SSLnetworkencryption,betweenImpalaandclientprograms,andbetweentheImpala-related
daemons runningondifferentnodesinthecluster.Thisfeatureisimportantwhenyoualsouseotherfeaturessuch
asKerberosauthenticationorSentryauthorization,wherecredentialsarebeingtransmittedbackandforth.
Important:
â¢YoucanuseeitherClouderaManagerorthefollowingcommand-line instructions tocomplete
thisconfiguration.
â¢ThisinformationappliesspecificallytotheversionofImpalashownintheHTMLpageheaderor
onthePDFtitlepage.IfyouuseanearlierversionofCDH,seethedocumen tationforthatversion
locatedatClouderaDocumen tation.
UsingClouderaManager
ToconfigureImpalatolistenforBeeswaxandHiveServer2requestsonTLS/SSL-secur edports:
1.OpentheClouderaManagerAdminConsoleandgototheImpalaservice.
2.ClicktheConfigurationtab.
3.SelectScope>Impala(Service-Wide) .
4.SelectCategory>Security.
ApacheImpalaGuide|85ImpalaSecurity
5.Editthefollowingproperties:
Table1:ImpalaSSLProperties
Description Property
Encryptcommunic ationbetweenclients(likeODBC,JDBC,andtheImpalashell)
andtheImpaladaemonusingTransportLayerSecurity(TLS)(formerlyknown
asSecureSocketLayer(SSL)).EnableTLS/SSLforImpala
LocalpathtotheX509certificatethatidentifiestheImpaladaemontoclients
duringTLS/SSLconnections. ThisfilemustbeinPEMformat.ImpalaTLS/SSLServer
CertificateFile(PEMFormat)
Localpathtotheprivatekeythatmatchesthecertificatespecified inthe
CertificateforClients.ThisfilemustbeinPEMformat.ImpalaTLS/SSLServerPrivate
KeyFile(PEMFormat)
ThepasswordfortheprivatekeyintheImpalaTLS/SSLServerCertificateand
PrivateKeyfile.Ifleftblank,theprivatekeyisnotprotectedbyapassword.ImpalaTLS/SSLPrivateKey
Password
Thelocationondiskofthecertificate,inPEMformat,usedtoconfirmthe
authenticityofSSL/TLSserversthattheImpaladaemons mightconnectto.ImpalaTLS/SSLCACertificate
BecausetheImpaladaemons connecttoeachother,thisshouldalsoinclude
theCAcertificateusedtosignalltheSSL/TLSCertificates.Withoutthisparameter,
SSL/TLSbetweenImpaladaemons willnotbeenabled.
6.ClickSaveChangestocommitthechanges.
7.Selecteachscope,oneeachforâImpalaDaemonâ ,âCatalogServerâ,andâStatestoreâ,andrepeattheabovesteps.
EachoftheseImpalacomponen tshasitsowninternalwebserverthatpowerstheassociatedwebUIwithdiagnostic
information.TheconfigurationsettingrepresentsthelocalpathtotheX509certificatethatidentifiestheweb
servertoclientsduringTLS/SSLconnections.
8.RestarttheImpalaservice.
ConfiguringTLS/SSLCommunic ationfortheImpalaShell
Typically,aclientprogramhascorresponding configurationpropertiesinClouderaManagertoverifythatitisconnecting
totherightserver.Forexample,withTLS/SSLenabledforImpala,youusethefollowingoptionswhenstarting
impala-shell :
â¢--ssl:enablesTLS/SSLforimpala-shell .
â¢--ca_cert :thelocalpathnamepointingtothethird-partyCAcertificate,ortoacopyoftheservercertificate
forself-signed servercertificates.
If--ca_cert isnotset,impala-shell enablesTLS/SSL,butdoesnotvalidatetheservercertificate.Thisisuseful
forconnecting toaknown-goodImpalathatisonlyrunningoverTLS/SSL,whenacopyofthecertificateisnotavailable
(suchaswhendebuggingcustomerinstallations).
Forimpala-shell tosuccessfullyconnecttoanImpalaclusterthathastheminimum allowedTLS/SSLversionsetto
1.2(--ssl_minimum_version=tlsv1.2 ),thePythonversionontheclusterthatimpala-shell runsonmustbe
2.7.9orhigher(oravendor-providedPythonversionwiththerequiredsupport.SomevendorspatchedPython2.7.5
versionsonRedHatEnterpriseLinux7andderivatives).
UsingTLS/SSLwithBusinessIntelligenceTools
YoucanuseKerberosauthentication,TLS/SSLencryption,orbothtosecureconnections fromJDBCandODBCapplications
toImpala.SeeConfiguringImpalatoWorkwithJDBConpage725andConfiguringImpalatoWorkwithODBConpage
723fordetails.
PriortoCDH5.7/Impala2.5,theHiveJDBCdriverdidnotsupportconnections thatusebothKerberosauthentication
andSSLencryption.Ifyourclusterisrunninganolderreleasethathasthisrestriction,tousebothofthesesecurity
featureswithImpalathroughaJDBCapplication,usetheClouderaJDBCConnectorastheJDBCdriver.
86|ApacheImpalaGuideImpalaSecurity
SpecifyingTLS/SSLMinimum AllowedVersionandCiphers
Depending onyourclusterconfigurationandthesecuritypracticesinyourorganization,youmightneedtorestrictthe
allowedversionsofTLS/SSLusedbyImpala.OlderTLS/SSLversionsmighthavevulnerabilitiesorlackcertainfeatures.
InCDH5.13/Impala2.10,youcanusestartupoptionsfortheimpalad ,catalogd ,andstatestored daemons to
specifyaminimum allowedversionofTLS/SSL.
Specifyoneofthefollowingvaluesforthe--ssl_minimum_version configurationsetting:
â¢tlsv1:AllowanyTLSversionof1.0orhigher.ThissettingisthedefaultwhenTLS/SSLisenabled.
â¢tlsv1.1 :AllowanyTLSversionof1.1orhigher.
â¢tlsv1.2 :AllowanyTLSversionof1.2orhigher.
Alongwithspecifyingtheversion,youcanalsospecifytheallowedsetofTLSciphersbyusingthe--ssl_cipher_list
configurationsetting.Theargumenttothisoptionisalistofkeywords,separatedbycolons,commas,orspaces,and
optionallyincluding othernotation.Forexample:
--ssl_cipher_list="RC4-SHA,RC4-MD5"
Bydefault,thecipherlistisempty,andImpalausesthedefaultcipherlistfortheunderlying platform.Seetheoutput
ofman ciphers forthefullsetofkeywordsandnotationallowedintheargumentstring.
EnablingSentryAuthorizationforImpala
Authorizationdetermineswhichusersareallowedtoaccesswhichresources,andwhatoperationstheyareallowed
toperform.InImpala1.1andhigher,youuseApacheSentryforauthorization.Sentryaddsafine-grainedauthorization
frameworkforHadoop.Bydefault(whenauthorizationisnotenabled), Impaladoesallreadandwriteoperationswith
theprivilegesoftheimpalauser,whichissuitableforadevelopment/testenvironmentbutnotforasecureproduction
environment.Whenauthorizationisenabled,ImpalausestheOSuserIDoftheuserwhorunsimpala-shell orother
clientprogram,andassociatesvariousprivilegeswitheachuser.
Note:Sentryistypicallyusedinconjunction withKerberosauthenticationthatdefineswhichhosts
areallowedtoconnecttoeachserver.UsingthecombinationofSentryandKerberospreventsmalicious
usersfrombeingabletoconnectbycreatinganamedaccountonanuntrustedmachine. SeeEnabling
KerberosAuthenticationforImpalaonpage94fordetailsaboutKerberosauthentication.
TheSentryPrivilegeModel
Privilegescanbegrantedondifferentobjectsintheschemaandareassociatedwithalevelintheobjecthierarchy.If
aprivilegeisgrantedonaparentobjectinthehierarchy,thechildobjectautomaticallyinheritsit.Thisisthesame
privilegemodelasHiveandotherdatabasesystems.
TheobjectsintheImpalaschemahierarchyare:
Server
    URI
    Database
        Table
            Column
Thetable-levelprivilegesapplytoviewsaswell.Anywhereyouspecifyatablename,youcanspecifyaviewname
instead.
InCDH5.5/Impala2.3andhigher,youcanspecifyprivilegesforindividual columns.
Thetablebelowliststheminimum levelofprivilegesandthescoperequiredtoexecuteSQLstatementsinCDH6.1/
CDH5.16andhigher.Thefollowingnotationsareused:
ApacheImpalaGuide|87ImpalaSecurity
â¢ANYdenotestheSELECT,INSERT,CREATE,orREFRESH privilege.
â¢ALLprivilegedenotestheSELECT,INSERT,CREATE,andREFRESH privileges.
â¢TheownerofanobjecteffectivelyhastheALLprivilegeontheobject.
â¢Theparentlevelsofthespecified scopeareimplicitly supported.Forexample,ifaprivilegeislistedwiththeTABLE
scope,thesameprivilegegrantedonDATABASEandSERVERwillallowtheusertoexecutethatspecificSQL
statementonTABLE.
Scope Privileges SQLStatement
TABLE SELECT SELECT
TABLE SELECT WITHSELECT
TABLE SELECT EXPLAINSELECT
TABLE INSERT INSERT
TABLE INSERT EXPLAININSERT
TABLE INSERT TRUNCATE
TABLE INSERT LOAD
URI ALL
SERVER CREATE CREATEDATABASE
SERVER CREATE CREATEDATABASELOCATION
URI ALL
DATABASE CREATE CREATETABLE
DATABASE CREATE CREATETABLELIKE
TABLE SELECT,INSERT,orREFRESH
DATABASE CREATE CREATETABLEASSELECT
DATABASE INSERT
TABLE SELECT
DATABASE CREATE EXPLAINCREATETABLEASSELECT
DATABASE INSERT
TABLE SELECT
TABLE CREATE CREATETABLELOCATION
URI ALL
DATABASE CREATE CREATEVIEW
TABLE SELECT
DATABASE ALLWITHGRANT ALTERDATABASESETOWNER
TABLE ALL ALTERTABLE
TABLE ALL ALTERTABLESETLOCATION
URI ALL
DATABASE CREATE ALTERTABLERENAME
TABLE ALL
TABLE ALLWITHGRANT ALTERTABLESETOWNER
88|ApacheImpalaGuideImpalaSecurity
TABLE ALL ALTERVIEW
TABLE SELECT
DATABASE CREATE ALTERVIEWRENAME
TABLE ALL
VIEW ALLWITHGRANT ALTERVIEWSETOWNER
DATABASE ALL DROPDATABASE
TABLE ALL DROPTABLE
TABLE ALL DROPVIEW
DATABASE CREATE CREATEFUNCTION
URI ALL
DATABASE ALL DROPFUNCTION
TABLE ALL COMPUTE STATS
TABLE ALL DROPSTATS
SERVER REFRESH INVALIDATEMETADATA
TABLE REFRESH INVALIDATEMETADATA<table>
TABLE REFRESH REFRESH<table>
SERVER REFRESH REFRESHAUTHORIZATION
DATABASE REFRESH REFRESHFUNCTIONS
DATABASE ALL COMMENT ONDATABASE
TABLE ALL COMMENT ONTABLE
TABLE ALL COMMENT ONVIEW
TABLE ALL COMMENT ONCOLUMN
DATABASE SELECT,INSERT,orREFRESH DESCRIBEDATABASE
TABLE SELECT,INSERT,orREFRESH DESCRIBE<table/view>
COLUMN SELECT IftheuserhastheSELECTprivilegeat
theCOLUMNlevel,onlythecolumns
theuserhasaccesswillshow.
TABLE ANY USE
TABLE ANY SHOWDATABASES
TABLE ANY SHOWTABLES
DATABASE SELECT,INSERT,orREFRESH SHOWFUNCTIONS
TABLE SELECT,INSERT,orREFRESH SHOWPARTITIONS
TABLE SELECT,INSERT,orREFRESH SHOWTABLESTATS
TABLE SELECT,INSERT,orREFRESH SHOWCOLUMNSTATS
TABLE SELECT,INSERT,orREFRESH SHOWFILES
TABLE SELECT,INSERT,orREFRESH SHOWCREATETABLE
TABLE SELECT,INSERT,orREFRESH SHOWCREATEVIEW
ApacheImpalaGuide|89ImpalaSecurity
DATABASE SELECT,INSERT,orREFRESH SHOWCREATEFUNCTION
TABLE SELECT,INSERT,orREFRESH SHOWRANGEPARTITIONS(Kuduonly)
TABLE ALL UPDATE(Kuduonly)
TABLE ALL EXPLAINUPDATE(Kuduonly)
TABLE ALL UPSERT(Kuduonly)
TABLE ALL WITHUPSERT(Kuduonly)
TABLE ALL EXPLAINUPSERT(Kuduonly)
TABLE ALL DELETE(Kuduonly)
TABLE ALL EXPLAINDELETE(Kuduonly)
Note:IfaspecificprivilegeisnotenabledinSentry,theALLprivilegeisrequiredinImpala.
PrivilegesaremanagedviatheGRANTandREVOKESQLstatementsthatrequirestheSentryserviceenabled.TheSentry
servicestores,retrieves,andmanipula tesprivilegeinformationstoredinsidetheSentrydatabase.
IfyouchangeprivilegesoutsideofImpala,e.g.addingauser,removingauser,modifyingprivileges,youmustclear
theImpalaCatalogservercachebyrunningtheREFRESH AUTHORIZATION statement.REFRESH AUTHORIZATION
isnotrequiredifyoumakethechangestoprivilegeswithinImpala.
ObjectOwnershipinSentry
StartinginCDH5.16andCDH6.1,Impalasupports theownershipondatabases,tables,andviews.TheCREATE
statementsimplicitly maketheuserrunningthestatementtheowneroftheobject.AnownerhastheOWNERprivilege
ifenabledinSentry.Forexample,ifUserAcreatesadatabase,foo,viatheCREATE DATABASE statement,UserAnow
ownsthefoodatabaseandisauthorizedtoperformanyoperationonthefoodatabase.
TheOWNERprivilegeisnotagrantableorrevokableprivilegewhereastheALLprivilegeisexplicitlygrantedviathe
GRANTstatement.
TheobjectownershipfeatureiscontrolledbyaSentryconfiguration.TheOWNERprivilegeisonlygrantedwhenthe
featureisenabledinSentry.Whenenabledtheygettheownerprivilege,withorwithouttheGRANT OPTION ,which
isalsocontrolledbytheSentryconfiguration.
AnownershipcanbetransferredtoanotheruserorroleviatheALTER DATABASE ,ALTER TABLE ,orALTER VIEW
withtheSET OWNER clause.
StartingtheimpaladDaemonwithSentryAuthorizationEnabled
Toruntheimpalad daemonwithauthorizationenabled,youaddthefollowingoptionstotheIMPALA_SERVER_ARGS
declarationinthe/etc/default/impala configurationfile:
â¢-server_name :TurnsonSentryauthorizationforImpala.Theauthorizationrulesrefertoasymbolicservername,
andyouspecifythenametouseastheargumenttothe-server_name option.
â¢--sentry_config :Specifies thelocalpathtothesentry-site.xml configurationfile.Thissettingisrequired
toenableauthorization.
Forexample,youmightadaptyour/etc/default/impala configurationtocontainlineslikethefollowing.Touse
theSentryservice:
IMPALA_SERVER_ARGS=" \
-server_name=server1 \
...
90|ApacheImpalaGuideImpalaSecurity
Theprecedingexamplessetupasymbolicnameofserver1 torefertothecurrentinstanceofImpala.Thissymbolic
nameisusedinthefollowingways:
â¢InanenvironmentmanagedbyClouderaManager,seeEnablingSentryforImpalainClouderaManageronpage
91forsettingupSentryforImpalainCloudManager.Thevaluesmustbethesameforboth,sothatImpalaand
Hivecansharetheprivilegerules.RestarttheImpalaandHiveservicesaftersettingorchanging thisvalue.
â¢InanenvironmentnotmanagedbyClouderaManager,youspecifythisvalueforthesentry.hive.server
propertyinthesentry-site.xml configurationfileforHive,aswellasinthe-server_name optionforimpalad.
Nowrestarttheimpalad daemons onallthenodes.
EnablingSentryforImpalainClouderaManager
ToenabletheSentryserviceforImpalaandHive:
1.NavigatetotheHivecluster.
2.IntheConfigurationtab,selectHive(Service-Wide) underSCOPEandAdvancedunderCATEGORY.
3.IntheSentryServicefield,typetheSentryserviceyouspecified intheImpalaconfiguration.Thisistheserver
nametousewhengrantingserverlevelprivileges
4.WhenusingSentrywiththeHiveMetastore,youcanspecifythelistofusersthatareallowedtobypassSentry
AuthorizationinHiveMetastore.SelectSecurityforCATEGORYintheConfigurationtab,andspecifytheusersin
theBypassSentryAuthorizationUsersfield.Theseareusuallyserviceusersthatalreadyensureallactivityhas
beenauthorized.
5.IfinCDH5,navigatetotheImpalacluster,andperformthenexttwostepstodisablethepolicyfile-based
authorization.
6.IntheConfigurationtab,selectImpala(Service-Wide) underSCOPEandPolicyFileBasedSentryunderCATEGORY.
7.DeselecttheEnableSentryAuthorizationusingPolicyFilesparameterwhenusingtheSentryservice.Cloudera
ManagerthrowsavalidationerrorinCDH5ifyouattempttoconfiguretheSentryserviceandpolicyfileatthe
sametime.
8.RestartImpalaandHive.
UsingImpalawiththeSentryService(CDH5.1orhigheronly)
WhenyouusetheSentryservice,setupprivilegesthroughtheGRANTandREVOKEstatementsineitherImpalaorHive.
Sentryprivilegesareautomaticallypropagatedtobothservices.ImpalaaddedtheGRANTandREVOKEstatementsin
CDH5.2/Impala2.0.
ForinformationaboutusingtheImpalaGRANTandREVOKEstatements,seeGRANTStatement(CDH5.2orhigheronly)
onpage273andREVOKEStatement(CDH5.2orhigheronly)onpage293.
Changing Privileges
IfyoumakeachangetoprivilegesinSentryfromoutsideofImpala,e.g.addingauser,removingauser,modifying
privileges,therearetwooptionstopropagatethechange:
â¢Usethecatalogd flag,--sentry_catalog_polling_frequency_s tospecifyhowoftentodoaSentry
refresh.Theflagissetto60secondsbydefault.
â¢RuntheINVALIDATE METADATA statementtoforceaSentryrefresh.INVALIDATE METADATA forcesaSentry
refreshregardlessofthe--sentry_catalog_polling_fequency_s flag.
IfyoumakeachangetoprivilegeswithinImpala,INVALIDATE METADATA isnotrequired.
Warning:AsINVALIDATE METADATA isanexpensiveoperation,youshoulduseitjudiciously .
ApacheImpalaGuide|91ImpalaSecurity
GrantingPrivilegesonURI
URIsrepresentthefilepathsyouspecifyaspartofstatementssuchasCREATE EXTERNAL TABLE andLOAD DATA .
Typically,youspecifywhatlooklikeUNIXpaths,buttheselocationscanalsobeprefixedwithhdfs:// tomakeclear
thattheyarereallyURIs.TosetprivilegesforaURI,specifythenameofadirectory,andtheprivilegeappliestoallthe
filesinthatdirectoryandanydirectoriesundernea thit.
URIsmuststartwithhdfs:// ,s3a://,adl://,orfile:// .IfaURIstartswithanabsolutepath,thepathwillbe
appended tothedefaultfilesystemprefix.Forexample,ifyouspecify:
GRANT ALL ON URI '/tmp';
TheabovestatementeffectivelybecomesthefollowingwherethedefaultfilesystemisHDFS.
GRANT ALL ON URI 'hdfs://localhost:20500/tmp';
WhendefiningURIsforHDFS,youmustalsospecifytheNameNode. Forexample:
GRANT ALL ON URI file:///path/to/dir TO <role>
GRANT ALL ON URI hdfs://namenode:port/path/to/dir TO <role>
Warning:BecausetheNameNode hostandportmustbespecified, itisstronglyrecommended that
youuseHighAvailability(HA).ThisensuresthattheURIwillremainconstanteveniftheNameNode
changes.Forexample:
GRANT ALL ON URI hdfs://ha-nn-uri/path/to/dir TO <role>
ExamplesofSettingupAuthorizationforSecurityScenarios
Thefollowingexamplesshowhowtosetupauthorizationtodealwithvariousscenarios.
AUserwithNoPrivileges
Ifauserhasnoprivilegesatall,thatusercannotaccessanyschemaobjectsinthesystem.Theerrormessagesdonot
disclosethenamesorexistenceofobjectsthattheuserisnotauthorizedtoread.
Thisistheexperience youwantausertohaveiftheysomehowlogintoasystemwheretheyarenotanauthorized
Impalauser.Orinarealdeployment,ausermighthavenoprivilegesbecausetheyarenotamemberofanyofthe
authorizedgroups.
ExamplesofPrivilegesforAdministrativeUsers
Inthisexample,theSQLstatementsgranttheentire_server roleallprivilegesonboththedatabasesandURIs
withintheserver.
CREATE ROLE entire_server;
GRANT ROLE entire_server TO GROUP admin_group;
GRANT ALL ON SERVER server1 TO ROLE entire_server;
AUserwithPrivilegesforSpecificDatabasesandTables
Ifauserhasprivilegesforspecifictablesinspecificdatabases,theusercanaccessthosethingsbutnothingelse.They
canseethetablesandtheirparentdatabasesintheoutputofSHOW TABLES andSHOW DATABASES ,USEtheappropriate
databases,andperformtherelevantactions(SELECTand/orINSERT)basedonthetableprivileges.Toactuallycreate
atablerequirestheALLprivilegeatthedatabaselevel,soyoumightdefineseparaterolesfortheuserthatsetsupa
schemaandotherusersorapplicationsthatperformday-to-dayoperationsonthetables.
CREATE ROLE one_database;
92|ApacheImpalaGuideImpalaSecurity
GRANT ROLE one_database TO GROUP admin_group;
GRANT ALL ON DATABASE db1 TO ROLE one_database;
CREATE ROLE instructor;
GRANT ROLE instructor TO GROUP trainers;
GRANT ALL ON TABLE db1.lesson TO ROLE instructor;
# This particular course is all about queries, so the students can SELECT but not INSERT
 or CREATE/DROP.
CREATE ROLE student;
GRANT ROLE student TO GROUP visitors;
GRANT SELECT ON TABLE db1.training TO ROLE student;
PrivilegesforWorkingwithExternalDataFiles
WhendataisbeinginsertedthroughtheLOAD DATA statement,orisreferencedfromanHDFSlocationoutsidethe
normalImpaladatabasedirectories,theuseralsoneedsappropriatepermissions ontheURIscorresponding tothose
HDFSlocations.
Inthisexample:
â¢Theexternal_table rolecaninsertintoandquerytheImpalatable,external_table.sample .
â¢Thestaging_dir rolecanspecifytheHDFSpath/user/cloudera/external_data withtheLOAD DATA
statement.WhenImpalaqueriesorloadsdatafiles,itoperatesonallthefilesinthatdirectory,notjustasingle
file,soanyImpalaLOCATION parametersrefertoadirectoryratherthananindividual file.
CREATE ROLE external_table;
GRANT ROLE external_table TO GROUP cloudera;
GRANT ALL ON TABLE external_table.sample TO ROLE external_table;
CREATE ROLE staging_dir;
GRANT ROLE staging TO GROUP cloudera;
GRANT ALL ON URI 'hdfs://127.0.0.1:8020/user/cloudera/external_data' TO ROLE staging_dir;
SeparatingAdministratorResponsibility fromReadandWritePrivileges
Tocreateadatabase,youneedthefullprivilegeonthatdatabasewhileday-to-dayoperationsontableswithinthat
databasecanbeperformedwithlowerlevelsofprivilegeonspecifictable.Thus,youmightsetupseparaterolesfor
eachdatabaseorapplication:anadministrativeonethatcouldcreateordropthedatabase,andauser-levelonethat
canaccessonlytherelevanttables.
Inthisexample,theresponsibilities aredividedbetweenusersin3differentgroups:
â¢Membersofthesupergroup grouphavethetraining_sysadmin roleandsocansetupadatabasenamed
training .
â¢Membersofthecloudera grouphavetheinstructor roleandsocancreate,insertinto,andqueryanytables
inthetraining database,butcannotcreateordropthedatabaseitself.
â¢Membersofthevisitor grouphavethestudent roleandsocanquerythosetablesinthetraining database.
CREATE ROLE training_sysadmin;
GRANT ROLE training_sysadmin TO GROUP supergroup;
GRANT ALL ON DATABASE training1 TO ROLE training_sysadmin;
CREATE ROLE instructor;
GRANT ROLE instructor TO GROUP cloudera;
GRANT ALL ON TABLE training1.course1 TO ROLE instructor;
CREATE ROLE visitor;
GRANT ROLE student TO GROUP visitor;
GRANT SELECT ON TABLE training1.course1 TO ROLE student;
ApacheImpalaGuide|93ImpalaSecurity
SettingUpSchemaObjectsforaSecureImpalaDeployment
Inyourroledefinitions, youmustspecifyprivilegesatthelevelofindividual databasesandtables,oralldatabasesor
alltableswithinadatabase.Tosimplifythestructureoftheserules,planaheadoftimehowtonameyourschema
objectssothatdatawithdifferentauthorizationrequirementsisdividedintoseparatedatabases.
IfyouareaddingsecurityontopofanexistingImpaladeployment,youcanrenametablesorevenmovethembetween
databasesusingtheALTER TABLE statement.
TheDEFAULTDatabaseinaSecureDeployment
Becauseoftheextraemphasis ongranularaccesscontrolsinasecuredeployment,youshouldmoveanyimportant
orsensitiveinformationoutoftheDEFAULT databaseintoanameddatabase.Sometimesyoumightneedtogive
privilegesontheDEFAULT databaseforadministrativereasons,forexample,asaplaceyoucanreliablyspecifywith
aUSEstatementwhenpreparingtodropadatabase.
ImpalaAuthentication
Authenticationisthemechanism toensurethatonlyspecified hostsanduserscanconnecttoImpala.Italsoverifies
thatwhenclientsconnecttoImpala,theyareconnectedtoalegitimateserver.Thisfeaturepreventsspoofingsuchas
impersonation (settingupaphonyclientsystemwiththesameaccountandgroupnamesasalegitimateuser)and
man-in-the-middle attacks(interceptingapplicationrequestsbeforetheyreachImpalaandeavesdroppingonsensitive
informationintherequestsortheresults).
Impalasupports authenticationusingeitherKerberosorLDAP.
Note:Regardlessoftheauthenticationmechanism used,ImpalaalwayscreatesHDFSdirectoriesand
datafilesownedbythesameuser(typicallyimpala).Toimplemen tuser-levelaccesstodifferent
databases,tables,columns,partitions, andsoon,usetheSentryauthorizationfeature,asexplained
inEnablingSentryAuthorizationforImpalaonpage87.
Onceyouarefinishedsettingupauthentication,moveontoauthorization,whichinvolvesspecifyingwhatdatabases,
tables,HDFSdirectories,andsooncanbeaccessed byparticular userswhentheyconnectthroughImpala.SeeEnabling
SentryAuthorizationforImpalaonpage87fordetails.
EnablingKerberosAuthenticationforImpala
Impalasupports Kerberosauthentication.ForbackgroundinformationonenablingKerberosauthentication,see
EnablingKerberosAuthenticationforCDH.
WhenusingImpalainamanagedenvironment,ClouderaManagerautomaticallycompletesKerberosconfiguration.
InImpala2.0andlater,user()returnsthefullKerberosprincipalstring,suchasuser@example.com ,inaKerberized
environment.
Note:Regardlessoftheauthenticationmechanism used,ImpalaalwayscreatesHDFSdirectoriesand
datafilesownedbythesameuser(typicallyimpala).Toimplemen tuser-levelaccesstodifferent
databases,tables,columns,partitions, andsoon,usetheSentryauthorizationfeature,asexplained
inEnablingSentryAuthorizationforImpalaonpage87.
AnalternativeformofauthenticationyoucanuseisLDAP,described inEnablingLDAPAuthenticationforImpalaon
page96.
94|ApacheImpalaGuideImpalaSecurity
RequirementsforUsingImpalawithKerberos
Important:
â¢IfyouplantouseImpalainyourcluster,youmustconfigureyourKDCtoallowticketstobe
renewed,andyoumustconfigurekrb5.conf torequestrenewabletickets.Typically,youcan
dothisbyaddingthemax_renewable_life settingtoyourrealminkdc.conf ,andbyadding
therenew_lifetime parametertothelibdefaults sectionofkrb5.conf .
Formoreinformationaboutrenewabletickets,seetheKerberosdocumen tation.
â¢TheImpalaWebUIdoesnotsupportKerberosauthentication.
â¢YoucannotusetheImpalaresourcemanagementfeatureonaclusterthathasKerberos
authenticationenabled.
Impalasupports theClouderaODBCdriverandtheKerberosinterfaceprovided.TouseKerberosthroughtheODBC
driver,thehosttypemustbesetdepending ontheleveloftheODBDdriver:
â¢SecImpala fortheODBC1.0driver.
â¢SecBeeswax fortheODBC1.2driver.
â¢BlankfortheODBC2.0driverorhigher,whenconnecting toasecurecluster.
â¢HS2NoSasl fortheODBC2.0driverorhigher,whenconnecting toanon-secur ecluster.
ToenableKerberosintheImpalashell,starttheimpala-shell command usingthe-kflag.
ConfiguringImpalatoSupportKerberosSecurity
EnablingKerberosauthenticationforImpalainvolvesstepsthatcanbesummariz edasfollows:
â¢Creatingserviceprincipals forImpalaandtheHTTPservice.Principalnamestaketheform:
serviceName /fully.qualified.domain.name @KERBEROS.REALM
â¢Creating,merging,anddistributingkeytabfilesfortheseprincipals.
â¢Editing/etc/default/impala (inclusternotmanagedbyClouderaManager),oreditingtheSecuritysettings
intheClouderaManagerinterface,toaccommodateKerberosauthentication.
EnablingKerberosforImpalawithaProxyServer
AcommonconfigurationforImpalawithHighAvailabilityistouseaproxyservertosubmitrequeststotheactual
impalad daemons ondifferenthostsinthecluster.Thisconfigurationavoidsconnection problemsincaseofmachine
failure,becausetheproxyservercanroutenewrequeststhroughoneoftheremaining hostsinthecluster.This
configurationalsohelpswithloadbalancing ,becausetheadditional overheadofbeingtheâcoordinatornodeâfor
eachqueryisspreadacrossmultiplehosts.
Although youcansetupaproxyserverwithorwithoutKerberosauthentication,typicallyuserssetupasecureKerberized
configuration.ForinformationaboutsettingupaproxyserverforImpala,including Kerberos-specific steps,seeUsing
ImpalathroughaProxyforHighAvailabilityonpage72.
EnablingImpalaDelegationforKerberosUsers
SeeConfiguringImpalaDelegationforHueandBIToolsonpage99fordetailsaboutthedelegationfeaturethatlets
certainuserssubmitqueriesusingthecredentialsofotherusers.
UsingTLS/SSLwithBusinessIntelligenceTools
YoucanuseKerberosauthentication,TLS/SSLencryption,orbothtosecureconnections fromJDBCandODBCapplications
toImpala.SeeConfiguringImpalatoWorkwithJDBConpage725andConfiguringImpalatoWorkwithODBConpage
723fordetails.
ApacheImpalaGuide|95ImpalaSecurity
PriortoCDH5.7/Impala2.5,theHiveJDBCdriverdidnotsupportconnections thatusebothKerberosauthentication
andSSLencryption.Ifyourclusterisrunninganolderreleasethathasthisrestriction,tousebothofthesesecurity
featureswithImpalathroughaJDBCapplication,usetheClouderaJDBCConnectorastheJDBCdriver.
EnablingAccesstoInternalImpalaAPIsforKerberosUsers
ForapplicationsthatneeddirectaccesstoImpalaAPIs,withoutgoingthroughtheHiveServer2orBeeswaxinterfaces,
youcanspecifyalistofKerberosuserswhoareallowedtocallthoseAPIs.Bydefault,theimpalaandhdfsusersare
theonlyonesauthorizedforthiskindofaccess.Anyusersnotexplicitlyauthorizedthroughthe
internal_principals_whitelist configurationsettingareblockedfromaccessing theAPIs.Thissettingapplies
toalltheImpala-relateddaemons, although currentlyitisprimarily usedforHDFStocontrolthebehaviorofthecatalog
server.
Mapping KerberosPrincipals toShortNamesforImpala
InCDH5.8/Impala2.6andhigher,Impalarecognizestheauth_to_local setting,specified throughtheCloudera
ManagersettingAdditional RulestoMapKerberosPrincipals toShortNames.Thisfeatureisdisabledbydefault,to
avoidanunexpectedchangeinsecurity-r elatedbehavior.Toenableit,selecttheUseHDFSRulestoMapKerberos
Principals toShortNamescheckboxtoenabletheservice-wide --load_auth_to_local_rules configuration
setting.ThenrestarttheImpalaservice.SeeUsingAuth-to-LocalRulestoIsolateClusterUsersforgeneralinformation
aboutthisfeature.
EnablingLDAPAuthenticationforImpala
Authenticationistheprocessofallowingonlyspecified nameduserstoaccesstheserver(inthiscase,theImpala
server).Thisfeatureiscrucialforanyproduction deployment,topreventmisuse,tampering ,orexcessiveloadonthe
server.ImpalausesLDAPforauthentication,verifyingthecredentialsofeachuserwhoconnectsthroughimpala-shell ,
Hue,aBusinessIntelligencetool,JDBCorODBCapplication,etc.
Note:Regardlessoftheauthenticationmechanism used,ImpalaalwayscreatesHDFSdirectoriesand
datafilesownedbythesameuser(typicallyimpala).Toimplemen tuser-levelaccesstodifferent
databases,tables,columns,partitions, andsoon,usetheSentryauthorizationfeature,asexplained
inEnablingSentryAuthorizationforImpalaonpage87.
AnalternativeformofauthenticationyoucanuseisKerberos,described inEnablingKerberosAuthenticationforImpala
onpage94.
RequirementsforUsingImpalawithLDAP
AuthenticationagainstLDAPserversisavailableinImpala1.2.2andhigher.Impala1.4.0addedthesupportforsecure
LDAPauthenticationthroughSSLandTLS.
TheImpalaLDAPsupportletsyouuseImpalawithsystemssuchasActiveDirectorythatuseLDAPbehindthescenes.
ConsiderationforConnections BetweenImpalaComponen ts
Onlytheconnections betweenclientsandImpalacanbeauthenticatedbyLDAP.
YoumustusetheKerberosauthenticationmechanism forconnections betweeninternalImpalacomponen ts,suchas
betweentheimpalad ,statestored ,andcatalogd daemons. SeeEnablingKerberosAuthenticationforImpalaon
page94onhowtosetupKerberosforImpala.
EnablingLDAPinCommand LineInterface
ToenableLDAPauthenticationviaacommand lineinterface,starttheimpalad withthefollowingstartupoptions
for:
--enable_ldap_auth
EnablesLDAP-based authenticationbetweentheclientandImpala.
96|ApacheImpalaGuideImpalaSecurity
--ldap_uri
SetstheURIoftheLDAPservertouse.Typically,theURIisprefixedwithldap:// .YoucanspecifysecureSSL-based
LDAPtransportbyusingtheprefixldaps:// .TheURIcanoptionallyspecifytheport,forexample:
ldap://ldap_server.example.com:389 orldaps://ldap_server.example.com:636 .(389and636are
thedefaultportsfornon-SSLandSSLLDAPconnections, respectively.)
SupportforCustomBindStrings
WhenImpalaconnectstoLDAPitissuesabindcalltotheLDAPservertoauthenticateastheconnecteduser.Impala
clients,including theImpalashell,providetheshortnameoftheusertoImpala.ThisisnecessarysothatImpalacan
useSentryforrole-based access,whichusesshortnames.
However,LDAPserversoftenrequiremorecomplex,structuredusernames forauthentication.Impalasupports three
waysoftransformingtheshortname(forexample,'henry' )toamorecomplicatedstring.Ifnecessary,specifyone
ofthefollowingconfigurationoptionswhenstartingtheimpalad daemon.
--ldap_domain
Replacestheusername withastringusername @ldap_domain .
--ldap_baseDN
Replacestheusername withaâdistinguished nameâ(DN)oftheform:uid=userid,ldap_baseDN .(Thisis
equivalenttoaHiveoption).
--ldap_bind_pattern
Thisisthemostgeneraloption,andreplacestheusername withthestringldap_bind_pat ternwhereallinstances
ofthestring#UIDarereplacedwithuserid.Forexample,anldap_bind_pattern of
"user=#UID,OU=foo,CN=bar" withausername ofhenrywillconstructabindnameof
"user=henry,OU=foo,CN=bar" .
Theaboveoptionsaremutually exclusive,andImpaladoesnotstartifmorethanoneoftheseoptionsarespecified.
SecureLDAPConnections
Toavoidsendingcredentialsoverthewireincleartext,youmustconfigureasecureconnection betweenboththe
clientandImpala,andbetweenImpalaandtheLDAPserver.Thesecureconnection coulduseSSLorTLS.
SecureLDAPconnections throughSSL:
ForSSL-enabled LDAPconnections, specifyaprefixofldaps:// insteadofldap:// .Also,thedefaultportfor
SSL-enabled LDAPconnections is636insteadof389.
SecureLDAPconnections throughTLS:
TLS,thesuccessor totheSSLprotocol,issupportedbymostmodernLDAPservers.UnlikeSSLconnections, TLS
connections canbemadeonthesameserverportasnon-TLSconnections. Tosecureallconnections usingTLS,specify
thefollowingflagsasstartupoptionstotheimpalad daemon:
--ldap_tls
TellsImpalatostartaTLSconnection totheLDAPserver,andtofailauthenticationifitcannotbedone.
--ldap_ca_certificate=" /path/to/certificate/pem "
Specifies thelocationofthecertificateinstandard.PEMformat.Storethiscertificateonthelocalfilesystem,ina
locationthatonlytheimpalauserandothertrusteduserscanread.
EnablingLDAPinClouderaManager
ToenableLDAPauthenticationinClouderaManager:
1.IntheImpalaservice,clicktheConfigurationtab.
2.Inthesearchbox,typeldap.
ApacheImpalaGuide|97ImpalaSecurity
3.Specifythevaluesfortheoptionfields.Eachfieldliststhecorresponding Impalastartupflag.Seethesections
aboveforthecorresponding flagifyouneedmoreinformationonaparticular field.
4.ClickSaveChanges.
5.RestarttheImpalaservice.
LDAPAuthenticationforimpala-shell
ToconnecttoImpalausingLDAPauthentication,youspecifycommand-line optionstotheimpala-shell command
interpreterandenterthepasswordwhenprompted.
-l
EnablesLDAPauthentication.
-u
Setstheuser.PerActiveDirectory,theuseristheshortusername, notthefullLDAPdistinguished name.Ifyour
LDAPsettingsincludeasearchbase,usethe--ldap_bind_pattern ontheimpalad daemontotranslatethe
shortusernamefromimpala-shell automaticallytothefullyqualified name.
impala-shell automaticallypromptsforthepassword.
SeeConfiguringImpalatoWorkwithJDBConpage725fortheformattousewiththeJDBCconnection stringforservers
usingLDAPauthentication.
EnablingLDAPforImpalainHue
1.GototheHueservice.
2.ClicktheConfigurationtab.
3.SelectScope>HueServer.
4.SelectCategory>Advanced.
5.AddthefollowingpropertiestotheHueServerAdvancedConfigurationSnippet(SafetyValve)for
hue_safety_valve_server.iniproperty.
[impala]
auth_username=<LDAP username of Hue user to be authenticated>
auth_password=<LDAP password of Hue user to be authenticated>
6.ClickSaveChanges.
EnablingImpalaDelegationforLDAPUsers
SeeConfiguringImpalaDelegationforHueandBIToolsonpage99fordetailsaboutthedelegationfeaturethatlets
certainuserssubmitqueriesusingthecredentialsofotherusers.
LDAPRestrictionsforImpala
TheLDAPsupportispreliminary.ItcurrentlyhasonlybeentestedagainstActiveDirectory.
UsingMultipleAuthenticationMethodswithImpala
Impala2.0andlaterautomaticallyhandlesbothKerberosandLDAPauthentication.Eachimpalad daemoncanaccept
bothKerberosandLDAPrequeststhroughthesameport.Nospecialactionsneedtobetakenifsomeusersauthenticate
throughKerberosandsomethroughLDAP.
PriortoImpala2.0,youhadtoconfigureeachimpalad tolistenonaspecificportdepending onthekindof
authentication,thenconfigureyournetworkloadbalancertoforwardeachkindofrequesttoaDataNodethatwas
setupwiththeappropriateauthenticationtype.OncetheinitialrequestwasmadeusingeitherKerberosorLDAP
authentication,Impalaautomaticallyhandledtheprocessofcoordinatingtheworkacrossmultiplenodesandtransmitting
intermediateresultsbacktothecoordinatornode.
98|ApacheImpalaGuideImpalaSecurity
ConfiguringImpalaDelegationforHueandBITools
WhenuserssubmitImpalaqueriesthroughaseparateapplication,suchasHueorabusinessintelligencetool,typically
allrequestsaretreatedascomingfromthesameuser.InImpala1.2andhigher,Impalasupports âdelegationâwhere
userswhosenamesyouspecifycandelegatetheexecutionofaquerytoanotheruser.Thequeryrunswiththeprivileges
ofthedelegateduser,nottheoriginalauthenticateduser.
StartinginImpala3.1andhigher,youcandelegateusinggroups.Insteadoflistingalargenumberofdelegatedusers,
youcancreateagroupofthoseusersandspecifythedelegatedgroupnameintheImpaladstartupoption.Theclient
sendsthedelegatedusername,andImpalaperformsanauthorizationtoseeifthedelegateduserbelongstoadelegated
group.
ThenameofthedelegateduserispassedusingtheHiveServer2protocolconfigurationpropertyimpala.doas.user
whentheclientconnectstoImpala.
Currently,thedelegationfeatureisavailableonlyforImpalaqueriessubmittedthroughapplicationinterfacessuchas
HueandBItools.Forexample,ImpalacannotissuequeriesusingtheprivilegesoftheHDFSuser.
Thedelegationfeatureisenabledbythestartupoptionsforimpalad :--authorized_proxy_user_config and
--authorized_proxy_group_config .SeeEnablingDelegationinClouderaManageronpage100forenabling
delegationinClouderaManager.
â¢Thelistofauthorizedusers/groupsaredelimitedwith;
â¢Thelistofdelegatedusers/groupsaredelimitedwith,bydefault.
â¢Usethe--authorized_proxy_user_config_delimiter startupoptiontooverridethedefaultuserdelimiter
(thecommacharacter)toanothercharacter.
â¢Usethe--authorized_proxy_group_config_delimiter startupoptiontooverridethedefaultgroup
delimiter(thecommacharacter)toanothercharacter.
â¢Awildcard(*)issupportedtodelegatedtoanyusersoranygroups,e.g.
--authorized_proxy_group_config=hue=* .Makesuretousesinglequotesorescapecharacterstoensure
thatany*charactersdonotundergowildcardexpansion whenspecified incommand-line arguments.
WhenyoustartImpalawiththe--authorized_proxy_user_config= authenticated_user =delegated_user
or--authorized_proxy_group_config= authenticated_user =delegated_group option:
â¢Authenticationisbasedontheuseronthelefthandside(authenticated_user).
â¢Authorizationisbasedontherighthandsideuser(s)orgroup(s)(delegated_user,delegated_group ).
â¢Whenopeningaclientconnection, theclientmustprovideadelegatedusername viatheHiveServer2protocol
property,impala.doas.user orDelegationUID .
â¢Itisnotnecessaryforauthenticated_usertohavethepermission toaccess/editfiles.
â¢ItisnotnecessaryforthedelegateduserstohaveaccesstotheserviceviaKerberos.
â¢delegated_useranddelegated_group mustexistintheOS.
â¢Forgroupdelegation,usetheJNI-based mapping providersforgroupdelegation,suchas
JniBasedUnixGr oupsMappingWithF allbackandJniBasedUnixGr oupsNetgroupMappingWithF allback.
â¢ShellBasedUnixGr oupsNetgroupMapping andShellBasedUnixGr oupsMapping Hadoopgroupmapping providers
arenotsupportedinImpalagroupdelegation.
â¢InImpala,user()returnsauthenticated_userandeffective_user() returnsthedelegateduserthattheclient
specified.
Theuserorgroupdelegationprocessworksasfollows:
1.TheImpaladdaemonstartswithoneorbothofthefollowingoptions:
â¢--authorized_proxy_user_config= authenticated_user =delegated_user
â¢--authorized_proxy_group_config= authenticated_user =delegated_group
2.AclientconnectstoImpalaviatheHiveServer2protocolwiththeimpala.doas.user configurationproperty,
e.g.connecteduserisauthenticated_userwithimpala.doas.user= delegated_user .
3.Theclientuserauthenticated_user sendsarequesttoImpalaasthedelegateduserdelegated_user.
4.Impalachecksauthorization:
ApacheImpalaGuide|99ImpalaSecurity
Inuserdelegation,Impalachecksifdelegated_user isinthelistofauthorizeddelegateusersfortheuser
authenticated_user .â¢
â¢Ingroupdelegate,Impalachecksifdelegated_user belongstooneofthedelegatedgroupsfortheuser
authenticated_user ,delegated_group inthisexample.
5.Iftheuserisanauthorizeddelegateduserforauthenticated_user ,therequestisexecutedasthedelegate
userdelegated_user .
SeeModifyingImpalaStartupOptionsfordetailsaboutaddingorchangingimpalad startupoptions.
SeethisblogpostforbackgroundinformationaboutthedelegationcapabilityinHiveServer2.
Tosetupauthenticationforthedelegatedusers:
â¢Ontheserverside,configureeitheruser/pass wordauthenticationthroughLDAP,orKerberosauthentication,for
allthedelegatedusers.SeeEnablingLDAPAuthenticationforImpalaonpage96orEnablingKerberosAuthentication
forImpalaonpage94fordetails.
â¢Ontheclientside,tolearnhowtoenabledelegation,consultthedocumen tationfortheODBCdriveryouare
using.
EnablingDelegationinClouderaManager
ToenabledelegationinClouderaManager:
1.NavigatetoClusters>Impala>Configuration>PolicyFile-Based Sentry.
2.IntheProxyUserConfigurationfield,typetheasemicolon-separ atedlistofkey=valuepairsofauthorizedproxy
userstotheuser(s)theycanimpersonate.Thelistofdelegatedshortusernamesaredelimitedwithacomma,
e.g.hue=user1, user2.
Theshortusernamesshouldbespecified. Theusernamesarecase-sensitiv e.
3.IntheProxyGroupConfigurationfield,typetheasemicolon-separ atedlistofkey=valuepairsofauthorizedproxy
userstothegroup(s)theycanimpersonate.Thelistofdelegatedgroupsaredelimitedwithacomma,e.g.
hue=group1,group2.
Thegroupnamesarecase-sensitiv e.
4.ClickSaveChangesandrestarttheImpalaservice.
100|ApacheImpalaGuideImpalaSecurity
ImpalaSQLLanguageReference
ImpalausesSQLasitsquerylanguage.Toprotectuserinvestmentinskillsdevelopmentandquerydesign,Impala
providesahighdegreeofcompatibilitywiththeHiveQueryLanguage(HiveQL):
â¢BecauseImpalausesthesamemetadatastoreasHivetorecordinformationabouttablestructureandproperties,
ImpalacanaccesstablesdefinedthroughthenativeImpalaCREATE TABLE command, ortablescreatedusing
theHivedatadefinitionlanguage(DDL).
â¢Impalasupports datamanipula tion(DML)statementssimilartotheDMLcomponen tofHiveQL.
â¢Impalaprovidesmanybuilt-infunctions withthesamenamesandparametertypesastheirHiveQLequivalents.
Impalasupports mostofthesamestatementsandclausesasHiveQL,including,butnotlimitedtoJOIN,AGGREGATE ,
DISTINCT ,UNION ALL ,ORDER BY ,LIMITand(uncorrelated)subqueryintheFROMclause.Impalaalsosupports
INSERT INTO andINSERT OVERWRITE .
Impalasupports datatypeswiththesamenamesandsemanticsastheequivalentHivedatatypes:STRING,TINYINT ,
SMALLINT ,INT,BIGINT,FLOAT,DOUBLE,BOOLEAN ,STRING,TIMESTAMP .
ForfulldetailsaboutImpalaSQLsyntaxandsemantics,seeImpalaSQLStatementsonpage202.
MostHiveQLSELECTandINSERTstatementsrununmodified withImpala.ForinformationaboutHivesyntaxnot
availableinImpala,seeSQLDifferencesBetweenImpalaandHiveonpage541.
Foralistofthebuilt-infunctions availableinImpalaqueries,seeImpalaBuilt-InFunctions onpage391.
Comments
Impalasupports thefamiliarstylesofSQLcomments:
â¢Alltextfroma--sequence totheendofthelineisconsideredacommentandignored.Thistypeofcomment
canoccuronasinglelinebyitself,orafterallorpartofastatement.
â¢Alltextfroma/*sequence tothenext*/sequence isconsideredacommentandignored.Thistypeofcomment
canstretchovermultiplelines.Thistypeofcommentcanoccurononeormorelinesbyitself,inthemiddleofa
statement,orbeforeorafterastatement.
Forexample:
-- This line is a comment about a table.
create table ...;
/*
This is a multi-line comment about a query.
*/
select ...;
select * from t /* This is an embedded comment about a query. */ where ...;
select * from t -- This is a trailing comment within a multi-line command.
where ...;
DataTypes
Impalasupports asetofdatatypesthatyoucanusefortablecolumns,expressionvalues,andfunctionargumentsand
returnvalues.
Note:Currently,Impalasupports onlyscalartypes,notcompositeornestedtypes.Accessing atable
containinganycolumnswithunsupport edtypescausesanerror.
ApacheImpalaGuide|101ImpalaSQLLanguageReference
Forthenotationtowriteliteralsofeachofthesedatatypes,seeLiteralsonpage167.
Impalasupports alimitedsetofimplicitcaststoavoidundesiredresultsfromunexpectedcastingbehavior.
â¢Impaladoesnotimplicitly castbetweenstringandnumericorBooleantypes.AlwaysuseCAST()forthese
conversions.
â¢Impaladoesperformimplicitcastsamongthenumerictypes,whengoingfromasmallerorlessprecisetypetoa
largerormorepreciseone.Forexample,Impalawillimplicitly convertaSMALLINT toaBIGINTorFLOAT,butto
convertfromDOUBLEtoFLOATorINTtoTINYINT requiresacalltoCAST()inthequery.
â¢ImpaladoesperformimplicitcastsfromSTRINGtoTIMESTAMP .Impalahasarestrictedsetofliteralformatsfor
theTIMESTAMP datatypeandtheFROM_UNIXTIME() formatstring;seeTIMESTAMPDataTypeonpage130for
details.
Seethetopicsunderthissectionforfulldetailsonimplicitandexplicitcastingforeachdatatype,andseeImpalaType
ConversionFunctions onpage423fordetailsabouttheCAST()function.
ARRAYComplexType(CDH5.5orhigheronly)
Acomplexdatatypethatcanrepresentanarbitrarynumberoforderedelements.Theelementscanbescalarsor
anothercomplextype(ARRAY,STRUCT,orMAP).
Syntax:
column_name  ARRAY < type >
type ::= primitive_type  | complex_type
Usagenotes:
Becausecomplextypesareoftenusedincombination,forexampleanARRAYofSTRUCTelements,ifyouareunfamiliar
withtheImpalacomplextypes,startwithComplexTypes(CDH5.5orhigheronly)onpage139forbackgroundinformation
andusageexamples.
Theelementsofthearrayhavenonames.YourefertothevalueofthearrayitemusingtheITEMpseudocolumn,or
itspositioninthearraywiththePOSpseudocolumn.SeeITEMandPOSPseudocolumnsonpage153forinformation
aboutthesepseudocolumns.
Eachrowcanhaveadifferentnumberofelements(including none)inthearrayforthatrow.
Whenanarraycontainsitemsofscalartypes,youcanuseaggregationfunctions onthearrayelementswithoutusing
joinnotation.Forexample,youcanfindtheCOUNT() ,AVG(),SUM(),andsoonofnumericarrayelements,orthe
MAX()andMIN()ofanyscalararrayelementsbyreferringtotable_name .array_column intheFROMclauseof
thequery.Whenyouneedtocross-referencevaluesfromthearraywithscalarvaluesfromthesamerow,suchasby
including aGROUP BY clausetoproduceaseparateaggregatedresultforeachrow,thenthejoinclauseisrequired.
Acommonusagepatternwithcomplextypesistohaveanarrayasthetop-leveltypeforthecolumn:anarrayof
structs,anarrayofmaps,oranarrayofarrays.Forexample,youcanmodeladenormaliz edtablebycreatingacolumn
thatisanARRAYofSTRUCTelements;eachiteminthearrayrepresentsarowfromatablethatwouldnormally be
usedinajoinquery.Thiskindofdatastructureletsyouessentiallydenormaliz etablesbyassociatingmultiplerows
fromonetablewiththematchingrowinanothertable.
Youtypicallydonotcreatemorethanonetop-levelARRAYcolumn,becauseifthereissomerelationshipbetweenthe
elementsofmultiplearrays,itisconvenienttomodelthedataasanarrayofanothercomplextypeelement(either
STRUCTorMAP).
Youcanpassamulti-part qualified nametoDESCRIBE tospecifyanARRAY,STRUCT,orMAPcolumnandvisualizeits
structureasifitwereatable.Forexample,iftableT1containsanARRAYcolumnA1,youcouldissuethestatement
DESCRIBE t1.a1 .IftableT1containedaSTRUCTcolumnS1,andafieldF1withintheSTRUCTwasaMAP,youcould
issuethestatementDESCRIBE t1.s1.f1 .AnARRAYisshownasatwo-columntable,withITEMandPOScolumns.
ASTRUCTisshownasatablewitheachfieldrepresentingacolumninthetable.AMAPisshownasatwo-columntable,
withKEYandVALUEcolumns.
Addedin:CDH5.5.0/Impala2.3.0
102|ApacheImpalaGuideImpalaSQLLanguageReference
Restrictions:
â¢Columns withthisdatatypecanonlybeusedintablesorpartitions withtheParquetfileformat.
â¢Columns withthisdatatypecannotbeusedaspartition keycolumnsinapartitioned table.
â¢TheCOMPUTE STATS statementdoesnotproduceanystatisticsforcolumnsofthisdatatype.
â¢Themaximumlengthofthecolumndefinitionforanycomplextype,including declarationsforanynestedtypes,
is4000characters.
â¢SeeLimitationsandRestrictionsforComplexTypesonpage143forafulllistoflimitationsandassociatedguidelines
aboutcomplextypecolumns.
Kuduconsiderations:
Currently,thedatatypesCHAR,VARCHAR ,ARRAY,MAP,andSTRUCTcannotbeusedwithKudutables.
Examples:
Note:ManyofthecomplextypeexamplesrefertotablessuchasCUSTOMER andREGIONadapted
fromthetablesusedintheTPC-Hbenchmark. SeeSampleSchemaandDataforExperimen tingwith
ImpalaComplexTypesonpage160forthetabledefinitions.
ThefollowingexampleshowshowtoconstructatablewithvariouskindsofARRAYcolumns,bothatthetopleveland
nestedwithinothercomplextypes.WhenevertheARRAYconsistsofascalarvalue,suchasinthePETScolumnorthe
CHILDREN field,youcanseethatfutureexpansion islimited.Forexample,youcouldnoteasilyevolvetheschemato
recordthekindofpetorthechild'sbirthdayalongside thename.Therefore,itismorecommontouseanARRAYwhose
elementsareofSTRUCTtype,toassociatemultiplefieldswitheacharrayelement.
Note:PracticetheCREATE TABLE andquerynotationforcomplextypecolumnsusingemptytables,
untilyoucanvisualizeacomplexdatastructureandconstructcorresponding SQLstatementsreliably.
CREATE TABLE array_demo
(
  id BIGINT,
  name STRING,
-- An ARRAY of scalar type as a top-level column.
  pets ARRAY <STRING>,
-- An ARRAY with elements of complex type (STRUCT).
  places_lived ARRAY < STRUCT <
    place: STRING,
    start_year: INT
  >>,
-- An ARRAY as a field (CHILDREN) within a STRUCT.
-- (The STRUCT is inside another ARRAY, because it is rare
-- for a STRUCT to be a top-level column.)
  marriages ARRAY < STRUCT <
    spouse: STRING,
    children: ARRAY <STRING>
  >>,
-- An ARRAY as the value part of a MAP.
-- The first MAP field (the key) would be a value such as
-- 'Parent' or 'Grandparent', and the corresponding array would
-- represent 2 parents, 4 grandparents, and so on.
  ancestors MAP < STRING, ARRAY <STRING> >
)
STORED AS PARQUET;
ApacheImpalaGuide|103ImpalaSQLLanguageReference
ThefollowingexampleshowshowtoexaminethestructureofatablecontainingoneormoreARRAYcolumnsbyusing
theDESCRIBE statement.YoucanvisualizeeachARRAYasitsowntwo-columntable,withcolumnsITEMandPOS.
DESCRIBE array_demo;
+--------------+---------------------------+
| name         | type                      |
+--------------+---------------------------+
| id           | bigint                    |
| name         | string                    |
| pets         | array<string>             |
| marriages    | array<struct<             |
|              |   spouse:string,          |
|              |   children:array<string>  |
|              | >>                        |
| places_lived | array<struct<             |
|              |   place:string,           |
|              |   start_year:int          |
|              | >>                        |
| ancestors    | map<string,array<string>> |
+--------------+---------------------------+
DESCRIBE array_demo.pets;
+------+--------+
| name | type   |
+------+--------+
| item | string |
| pos  | bigint |
+------+--------+
DESCRIBE array_demo.marriages;
+------+--------------------------+
| name | type                     |
+------+--------------------------+
| item | struct<                  |
|      |   spouse:string,         |
|      |   children:array<string> |
|      | >                        |
| pos  | bigint                   |
+------+--------------------------+
DESCRIBE array_demo.places_lived;
+------+------------------+
| name | type             |
+------+------------------+
| item | struct<          |
|      |   place:string,  |
|      |   start_year:int |
|      | >                |
| pos  | bigint           |
+------+------------------+
DESCRIBE array_demo.ancestors;
+-------+---------------+
| name  | type          |
+-------+---------------+
| key   | string        |
| value | array<string> |
+-------+---------------+
ThefollowingexampleshowsqueriesinvolvingARRAYcolumnscontainingelementsofscalarorcomplextypes.You
âunpackâ eachARRAYcolumnbyreferringtoitinajoinquery,asifitwereaseparatetablewithITEMandPOScolumns.
Ifthearrayelementisascalartype,yourefertoitsvalueusingtheITEMpseudocolumn.Ifthearrayelementisa
STRUCT,yourefertotheSTRUCTfieldsusingdotnotationandthefieldnames.IfthearrayelementisanotherARRAY
oraMAP,youuseanotherlevelofjointounpackthenestedcollectionelements.
-- Array of scalar values.
-- Each array element represents a single string, plus we know its position in the array.
SELECT id, name, pets.pos, pets.item FROM array_demo, array_demo.pets;
-- Array of structs.
104|ApacheImpalaGuideImpalaSQLLanguageReference
-- Now each array element has named fields, possibly of different types.
-- You can consider an ARRAY of STRUCT to represent a table inside another table.
SELECT id, name, places_lived.pos, places_lived.item.place, places_lived.item.start_year
FROM array_demo, array_demo.places_lived;
-- The .ITEM name is optional for array elements that are structs.
-- The following query is equivalent to the previous one, with .ITEM
-- removed from the column references.
SELECT id, name, places_lived.pos, places_lived.place, places_lived.start_year
  FROM array_demo, array_demo.places_lived;
-- To filter specific items from the array, do comparisons against the .POS or .ITEM
-- pseudocolumns, or names of struct fields, in the WHERE clause.
SELECT id, name, pets.item FROM array_demo, array_demo.pets
  WHERE pets.pos in (0, 1, 3);
SELECT id, name, pets.item FROM array_demo, array_demo.pets
  WHERE pets.item LIKE 'Mr. %';
SELECT id, name, places_lived.pos, places_lived.place, places_lived.start_year
  FROM array_demo, array_demo.places_lived
WHERE places_lived.place like '%California%';
Relatedinformation:
ComplexTypes(CDH5.5orhigheronly)onpage139,STRUCTComplexType(CDH5.5orhigheronly)onpage124,MAP
ComplexType(CDH5.5orhigheronly)onpage118
BIGINTDataType
An8-byteintegerdatatypeusedinCREATE TABLE andALTER TABLE statements.
Syntax:
InthecolumndefinitionofaCREATE TABLE statement:
column_name  BIGINT
Range:-9223372036854775808 ..9223372036854775807. ThereisnoUNSIGNED subtype.
Conversions:Impalaautomaticallyconvertstoafloating-pointtype(FLOATorDOUBLE)automatically.UseCAST()to
converttoTINYINT,SMALLINT ,INT,STRING,orTIMESTAMP .Castinganintegerorfloating-pointvalueNtoTIMESTAMP
producesavaluethatisNsecondspastthestartoftheepochdate(January1,1970).Bydefault,theresultvalue
representsadateandtimeintheUTCtimezone.Ifthesetting
--use_local_tz_for_unix_timestamp_conversions=true isineffect,theresultingTIMESTAMP representsa
dateandtimeinthelocaltimezone.
Examples:
CREATE TABLE t1 (x BIGINT);
SELECT CAST(1000 AS BIGINT);
Usagenotes:
BIGINTisaconvenienttypetouseforcolumndeclarationsbecauseyoucanuseanykindofintegervaluesinINSERT
statementsandtheyarepromotedtoBIGINTwherenecessary.However,BIGINTalsorequiresthemostbytesof
anyintegertypeondiskandinmemory,meaningyourqueriesarenotasefficientandscalableaspossibleifyou
overusethistype.Therefore,prefertousethesmallestintegertypewithsufficientrangetoholdallinputvalues,and
CAST()whennecessarytotheappropriatetype.
ForaconvenientandautomatedwaytochecktheboundsoftheBIGINTtype,callthefunctionsMIN_BIGINT() and
MAX_BIGINT() .
IfanintegervalueistoolargetoberepresentedasaBIGINT,useaDECIMAL insteadwithsufficientdigitsofprecision.
NULLconsiderations:Castinganynon-numeric valuetothistypeproducesaNULLvalue.
ApacheImpalaGuide|105ImpalaSQLLanguageReference
Partitioning: Prefertousethistypeforapartition keycolumn.Impalacanprocessthenumerictypemoreefficiently
thanaSTRINGrepresentationofthevalue.
HBaseconsiderations:ThisdatatypeisfullycompatiblewithHBasetables.
Texttableconsiderations:ValuesofthistypearepotentiallylargerintexttablesthanintablesusingParquetorother
binaryformats.
Internaldetails:Representedinmemoryasan8-bytevalue.
Addedin:AvailableinallversionsofImpala.
Columnstatisticsconsiderations:Becausethistypehasafixedsize,themaximumandaveragesizefieldsarealways
filledinforcolumnstatistics,evenbeforeyouruntheCOMPUTE STATS statement.
Relatedinformation:
NumericLiteralsonpage167,TINYINTDataTypeonpage136,SMALLINT DataTypeonpage122,INTDataTypeonpage
117,BIGINTDataTypeonpage105,DECIMALDataType(CDH6.0/Impala3.0orhigheronly)onpage109,Impala
MathematicalFunctions onpage397
BOOLEANDataType
AdatatypeusedinCREATE TABLE andALTER TABLE statements,representingasingletrue/falsechoice.
Syntax:
InthecolumndefinitionofaCREATE TABLE statement:
column_name  BOOLEAN
Range:TRUEorFALSE.DonotusequotationmarksaroundtheTRUEandFALSEliteralvalues.Youcanwritetheliteral
valuesinuppercase,lowercase,ormixedcase.Thevaluesqueriedfromatablearealwaysreturnedinlowercase,true
orfalse.
Conversions:ImpaladoesnotautomaticallyconvertanyothertypetoBOOLEAN .Allconversionsmustuseanexplicit
calltotheCAST()function.
YoucanuseCAST()toconvertanyintegerorfloating-pointtypetoBOOLEAN :avalueof0representsfalse,andany
non-zerovalueisconvertedtotrue.
SELECT CAST(42 AS BOOLEAN) AS nonzero_int, CAST(99.44 AS BOOLEAN) AS nonzero_decimal,
  CAST(000 AS BOOLEAN) AS zero_int, CAST(0.0 AS BOOLEAN) AS zero_decimal;
+-------------+-----------------+----------+--------------+
| nonzero_int | nonzero_decimal | zero_int | zero_decimal |
+-------------+-----------------+----------+--------------+
| true        | true            | false    | false        |
+-------------+-----------------+----------+--------------+
Whenyoucasttheoppositeway,fromBOOLEAN toanumerictype,theresultbecomeseither1or0:
SELECT CAST(true AS INT) AS true_int, CAST(true AS DOUBLE) AS true_double,
  CAST(false AS INT) AS false_int, CAST(false AS DOUBLE) AS false_double;
+----------+-------------+-----------+--------------+
| true_int | true_double | false_int | false_double |
+----------+-------------+-----------+--------------+
| 1        | 1           | 0         | 0            |
+----------+-------------+-----------+--------------+
YoucancastDECIMAL valuestoBOOLEAN ,withthesametreatmentofzeroandnon-zerovaluesastheothernumeric
types.YoucannotcastaBOOLEAN toaDECIMAL .
YoucannotcastaSTRINGvaluetoBOOLEAN ,although youcancastaBOOLEAN valuetoSTRING,returning'1'for
truevaluesand'0'forfalsevalues.
106|ApacheImpalaGuideImpalaSQLLanguageReference
Although youcancastaTIMESTAMP toaBOOLEAN oraBOOLEAN toaTIMESTAMP ,theresultsareunlikelytobeuseful.
Anynon-zeroTIMESTAMP (thatis,anyvalueotherthan1970-01-01 00:00:00 )becomesTRUEwhenconvertedto
BOOLEAN ,while1970-01-01 00:00:00 becomesFALSE.AvalueofFALSEbecomes1970-01-01 00:00:00 when
convertedtoBOOLEAN ,andTRUEbecomesonesecondpastthisepochdate,thatis,1970-01-01 00:00:01 .
NULLconsiderations:AnexpressionofthistypeproducesaNULLvalueifanyargumentoftheexpressionisNULL.
Partitioning:
DonotuseaBOOLEAN columnasapartitionkey.Although youcancreatesuchatable,subsequentoperationsproduce
errors:
[localhost:21000] > create table truth_table (assertion string) partitioned by (truth 
boolean);
[localhost:21000] > insert into truth_table values ('Pigs can fly',false);
ERROR: AnalysisException: INSERT into table with BOOLEAN partition column (truth) is 
not supported: partitioning.truth_table
Examples:
SELECT 1 < 2;
SELECT 2 = 5;
SELECT 100 < NULL, 100 > NULL;
CREATE TABLE assertions (claim STRING, really BOOLEAN);
INSERT INTO assertions VALUES
  ("1 is less than 2", 1 < 2),
  ("2 is the same as 5", 2 = 5),
  ("Grass is green", true),
  ("The moon is made of green cheese", false);
SELECT claim FROM assertions WHERE really = TRUE;
HBaseconsiderations:ThisdatatypeisfullycompatiblewithHBasetables.
Parquetconsiderations:ThistypeisfullycompatiblewithParquettables.
Texttableconsiderations:ValuesofthistypearepotentiallylargerintexttablesthanintablesusingParquetorother
binaryformats.
Columnstatisticsconsiderations:Becausethistypehasafixedsize,themaximumandaveragesizefieldsarealways
filledinforcolumnstatistics,evenbeforeyouruntheCOMPUTE STATS statement.
Kuduconsiderations:
Currently,thedatatypesBOOLEAN ,FLOAT,andDOUBLEcannotbeusedforprimarykeycolumnsinKudutables.
Relatedinformation:BooleanLiteralsonpage169,SQLOperatorsonpage171,ImpalaConditional Functions onpage
457
CHARDataType(CDH5.2orhigheronly)
Afixed-lengthcharactertype,paddedwithtrailingspacesifnecessarytoachievethespecified length.Ifvaluesare
longerthanthespecified length,Impalatruncatesanytrailingcharacters.
Syntax:
InthecolumndefinitionofaCREATE TABLE statement:
column_name  CHAR(length)
Themaximumlengthyoucanspecifyis255.
Semanticsoftrailingspaces:
â¢WhenyoustoreaCHARvalueshorterthanthespecified lengthinatable,queriesreturnthevaluepaddedwith
trailingspacesifnecessary;theresultingvaluehasthesamelengthasspecified inthecolumndefinition.
â¢LeadingspacesinCHARarepreservedwithinthedatafile.
ApacheImpalaGuide|107ImpalaSQLLanguageReference
â¢IfyoustoreaCHARvaluecontainingtrailingspacesinatable,thosetrailingspacesarenotstoredinthedatafile.
Whenthevalueisretrievedbyaquery,theresultcouldhaveadifferentnumberoftrailingspaces.Thatis,the
valueincludeshowevermanyspacesareneededtopadittothespecified lengthofthecolumn.
â¢IfyoucomparetwoCHARvaluesthatdifferonlyinthenumberoftrailingspaces,thosevaluesareconsidered
identical.
â¢Whencomparing orprocessingCHARvalues:
âCAST()truncatesanylongerstringtofitwithinthedefinedlength.Forexample:
SELECT CAST('x' AS CHAR(4)) = CAST('x        ' AS CHAR(4)); -- Returns TRUE.
âIfaCHARvalueisshorterthanthespecified length,itispaddedontherightwithspacesuntilitmatchesthe
specified length.
âCHAR_LENGTH() returnsthelengthincluding anytrailingspaces.
âLENGTH() returnsthelengthexcludingtrailingspaces.
âCONCAT() returnsthelengthincluding trailingspaces.
Partitioning: Thistypecanbeusedforpartition keycolumns.Becauseoftheefficiencyadvantageofnumericvalues
overcharacter-based values,ifthepartition keyisastringrepresentationofanumber,prefertouseanintegertype
withsufficientrange(INT,BIGINT,andsoon)wherepractical.
HBaseconsiderations:ThisdatatypecannotbeusedwithHBasetables.
Parquetconsiderations:
â¢ThistypecanbereadfromandwrittentoParquetfiles.
â¢Thereisnorequirementforaparticular levelofParquet.
â¢ParquetfilesgeneratedbyImpalaandcontainingthistypecanbefreelyinterchangedwithothercomponen ts
suchasHiveandMapReduce.
â¢Anytrailingspaces,whetherimplicitly orexplicitlyspecified, arenotwrittentotheParquetdatafiles.
â¢ParquetdatafilesmightcontainvaluesthatarelongerthanallowedbytheCHAR(n)lengthlimit.Impalaignores
anyextratrailingcharacterswhenitprocessesthosevaluesduringaquery.
Texttableconsiderations:
Textdatafilesmightcontainvaluesthatarelongerthanallowedforaparticular CHAR(n)column.Anyextratrailing
charactersareignoredwhenImpalaprocessesthosevaluesduringaquery.Textdatafilescanalsocontainvaluesthat
areshorterthanthedefinedlengthlimit,andImpalapadsthemwithtrailingspacesuptothespecified length.Any
textdatafilesproducedbyImpalaINSERTstatementsdonotincludeanytrailingblanksforCHARcolumns.
Avroconsiderations:
TheAvrospecificationallowsstringvaluesupto2**64bytesinlength.ImpalaqueriesforAvrotablesuse32-bitintegers
toholdstringlengths.InCDH5.7/Impala2.5andhigher,ImpalatruncatesCHARandVARCHAR valuesinAvrotables
to(2**31)-1 bytes.IfaqueryencountersaSTRINGvaluelongerthan(2**31)-1 bytesinanAvrotable,thequeryfails.
Inearlierreleases,encounteringsuchlongvaluesinanAvrotablecouldcauseacrash.
Compatibility:
ThistypeisavailableusingCDH5.2/Impala2.0orhigher.
Someotherdatabasesystemsmakethelengthspecificationoptional.ForImpala,thelengthisrequired.
Internaldetails:Representedinmemoryasabytearraywiththesamesizeasthelengthspecification.Valuesthatare
shorterthanthespecified lengtharepaddedontherightwithtrailingspaces.
Addedin:CDH5.2.0/Impala2.0.0
Columnstatisticsconsiderations:Becausethistypehasafixedsize,themaximumandaveragesizefieldsarealways
filledinforcolumnstatistics,evenbeforeyouruntheCOMPUTE STATS statement.
UDFconsiderations:Thistypecannotbeusedfortheargumentorreturntypeofauser-definedfunction(UDF)or
user-definedaggregatefunction(UDA).
108|ApacheImpalaGuideImpalaSQLLanguageReference
Kuduconsiderations:
Currently,thedatatypesCHAR,VARCHAR ,ARRAY,MAP,andSTRUCTcannotbeusedwithKudutables.
Performance consideration:
TheCHARtypecurrentlydoesnothavetheImpalaCodegensupport,andwerecommend usingVARCHAR orSTRING
overCHARastheperformance gainofCodegenoutweighsthebenefitsoffixedwidthCHAR.
Restrictions:
Becausetheblank-padding behaviorrequiresallocatingthemaximumlengthforeachvalueinmemory,forscalability
reasons,youshouldavoiddeclaringCHARcolumnsthataremuchlongerthantypicalvaluesinthatcolumn.
AlldatainCHARandVARCHAR columnsmustbeinacharacterencodingthatiscompatiblewithUTF-8.Ifyouhave
binarydatafromanotherdatabasesystem(thatis,aBLOBtype),useaSTRINGcolumntoholdit.
WhenanexpressioncomparesaCHARwithaSTRINGorVARCHAR ,theCHARvalueisimplicitly convertedtoSTRING
first,withtrailingspacespreserved.
Thisbehaviordiffersfromotherpopulardatabasesystems.TogettheexpectedresultofTRUE,casttheexpressions
onbothsidestoCHARvaluesoftheappropriatelength.Forexample:
SELECT CAST("foo  " AS CHAR(5)) = CAST('foo' AS CHAR(3)); -- Returns TRUE.
Thisbehaviorissubjecttochangeinfuturereleases.
Relatedinformation:
STRINGDataTypeonpage123,VARCHARDataType(CDH5.2orhigheronly)onpage137,StringLiteralsonpage168,
ImpalaStringFunctions onpage462
DECIMALDataType(CDH6.0/Impala3.0orhigheronly)
TheDECIMAL datatypeisanumericdatatypewithfixedscaleandprecision.
Thedatatypeisusefulforstoringanddoingoperationsonprecisedecimalvalues.
Syntax:
DECIMAL[( precision [, scale])]
Precision:
precision representsthetotalnumberofdigitsthatcanberepresentedregardlessofthelocationofthedecimalpoint.
Thisvaluemustbebetween1and38,specified asanintegerliteral.
Thedefaultprecisionis9.
Scale:
scalerepresentsthenumberoffractionaldigits.
Thisvaluemustbelessthanorequaltotheprecision,specified asanintegerliteral.
Thedefaultscaleis0.
Whentheprecisionandthescaleareomitted,aDECIMAL istreatedasDECIMAL(9, 0) .
Range:
TherangeofDECIMAL typeis-10^38+1through10^38â1.
ThelargestvalueisrepresentedbyDECIMAL(38, 0) .
Themostprecisefractionalvalue(between0and1,or0and-1)isrepresentedbyDECIMAL(38, 38) ,with38digits
totherightofthedecimalpoint.Thevalueclosestto0wouldbe.0000...1 (37zerosandthefinal1).Thevalueclosest
to1wouldbe.999...(9repeated38times).
ApacheImpalaGuide|109ImpalaSQLLanguageReference
Memoryanddiskstorage:
OnlytheprecisiondeterminesthestoragesizeforDECIMAL values,andthescalesettinghasnoeffectonthestorage
size.Thefollowingtabledescribes thein-memor ystorageoncethevaluesareloadedintomemory.
In-memor yStorage Precision
4bytes 1-9
8bytes 10-18
16bytes 19-38
Theon-diskrepresentationvariesdepending onthefileformatofthetable.
Text,RCFile,andSequenceFile tablesuseASCII-based formatsasbelow:
â¢Leadingzerosarenotstored.
â¢Trailingzerosarestored.
â¢EachDECIMAL valuetakesupasmanybytesastheprecisionofthevalue,plus:
âOneextrabyteifthedecimalpointispresent.
âOneextrabytefornegativevalues.
ParquetandAvrotablesusebinaryformatsandoffermorecompactstorageforDECIMAL values.Inthesetables,
Impalastoreseachvalueinfewerbyteswherepossibledepending ontheprecisionspecified fortheDECIMAL column.
Toconservespaceinlargetables,usethesmallest-precisionDECIMAL type.
Precisionandscaleinarithmeticoperations:
Forallarithmeticoperations,theresultingprecisionisatmost38.
Iftheresultingprecisionwouldbegreaterthan38,Impalatruncatestheresultfromtheback,butkeepsatleast6
fractionaldigitsinscaleandrounds.
Forexample,DECIMAL(38, 20) * DECIMAL(38, 20) returnsDECIMAL(38, 6) .Accordingtothetablebelow,
theresultingprecisionandscalewouldbe(77, 40) ,buttheyarehigherthanthemaximumprecisionandscalefor
DECIMAL .So,Impalasetstheprecisiontothemaximumallowed38,andtruncatesthescaleto6.
WhenyouuseDECIMAL valuesinarithmeticoperations,theprecisionandscaleoftheresultvaluearedeterminedas
follows.Forbetterreadability ,thefollowingtermsareusedinthetablebelow:
â¢P1,P2:Inputprecisions
â¢S1,S2:Inputscales
â¢L1,L2:LeadingdigitsininputDECIMAL s,i.e.,L1=P1-S1andL2=P2-S2
ResultingScale ResultingPrecision Operation
max(S1,S2) max(L1,L2)+max(S1,S2)+1 AdditionandSubtraction
1isforcarry-over.
S1+S2 P1+P2+1 Multiplication
max(S1+P2+1,6) L1+S2+max(S1+P2+1,6) Division
max(S1,S2) min(L1,L2)+max(S1,S2) Modulo
Precisionandscaleinfunctions:
WhenyouuseDECIMAL valuesinbuilt-infunctions, theprecisionandscaleoftheresultvaluearedeterminedas
follows:
110|ApacheImpalaGuideImpalaSQLLanguageReference
â¢TheresultoftheSUMaggregatefunctiononaDECIMAL valueis:
âPrecision:38
âScale:Thesamescaleastheinputcolumn
â¢TheresultofAVGaggregatefunctiononaDECIMAL valueis:
âPrecision:38
âScale:max(Scaleofinputcolumn,6)
ImplicitconversionsinDECIMALassignmen ts:
Impalaenforcesstrictconversionrulesindecimalassignmen tslikeinINSERTandUNIONstatements,orinfunctions
likeCOALESCE .
Ifthereisnotenoughprecisionandscaleinthedestination,Impalafailswithanerror.
ImpalaperformsimplicitconversionsbetweenDECIMAL andothernumerictypesasbelow:
â¢DECIMAL isimplicitly convertedtoDOUBLEorFLOATwhennecessaryevenwithalossofprecision.Itcanbe
necessary,forexamplewheninserting aDECIMAL valueintoaDOUBLEcolumn.Forexample:
CREATE TABLE flt(c FLOAT);
INSERT INTO flt SELECT CAST(1e37 AS DECIMAL(38, 0));
SELECT CAST(c AS DECIMAL(38, 0)) FROM flt;
Result: 9999999933815812510711506376257961984
Theresulthasalossofinformationduetoimplicitcasting.ThisiswhywediscourageusingtheDOUBLEandFLOAT
typesingeneral.
â¢DOUBLEandFLOATcannotbeimplicitly convertedtoDECIMAL .Anerrorisreturned.
â¢DECIMAL isimplicitly convertedtoDECIMAL ifalldigitsfitintheresultingDECIMAL .
Forexample,thefollowingqueryreturnsanerrorbecausetheresultingtypethatguaranteesthatalldigitsfit
cannotbedetermined.
SELECT GREATEST (CAST(1 AS DECIMAL(38, 0)), CAST(2 AS DECIMAL(38, 37)));
â¢Integervaluescanbeimplicitly convertedtoDECIMAL whenthereisenoughroomintheDECIMAL toguarantee
thatalldigitsfit.Theintegertypesrequirethefollowingnumbersofdigitstotheleftofthedecimalpointwhen
convertedtoDECIMAL :
âBIGINT:19digits
âINT:10digits
âSMALLINT :5digits
âTINYINT :3digits
Forexample:
CREATE TABLE decimals_10_8 (x DECIMAL(10, 8));
INSERT INTO decimals_10_8 VALUES (CAST(1 AS TINYINT));
TheaboveINSERTstatementfailsbecauseTINYINT requiresroomfor3digitstotheleftofthedecimalpointin
theDECIMAL .
CREATE TABLE decimals_11_8(x DECIMAL(11, 8));
INSERT INTO decimals_11_8 VALUES (CAST(1 AS TINYINT));
ApacheImpalaGuide|111ImpalaSQLLanguageReference
TheaboveINSERTstatementsucceeds becausethereisenoughroomfor3digitstotheleftofthedecimalpoint
thatTINYINT requires.
InUNION,theresultingprecisionandscalesaredeterminedasfollows.
â¢Precision:max(L1,L2)+max(S1,S2)
IftheresultingtypedoesnotfitintheDECIMAL type,anerrorisreturned.Seethefirstexamplebelow.
â¢Scale:max(S1,S2)
ExamplesforUNION:
â¢DECIMAL(20, 0) UNION DECIMAL(20, 20) wouldrequireaDECIMAL(40, 20) tofitallthedigits.Sincethis
islargerthanthemaxprecisionforDECIMAL ,Impalareturnsanerror.Onewaytofixtheerroristocastboth
operandstothedesiredtype,forexampleDECIMAL(38, 18) .
â¢DECIMAL(20, 2) UNION DECIMAL(8, 6) returnsDECIMAL(24, 6) .
â¢INT UNION DECIMAL(9, 4) returnsDECIMAL(14, 4) .
INThastheprecision10andthescale0,soitistreatedasDECIMAL(10, 0) UNION DECIMAL(9. 4) .
CastingbetweenDECIMALandotherdatatypes:
Toavoidpotentialconversionerrors,useCASTtoexplicitlyconvertbetweenDECIMAL andothertypesindecimal
assignmen tslikeinINSERTandUNIONstatements,orinfunctions likeCOALESCE :
â¢YoucancastthefollowingtypestoDECIMAL :FLOAT,TINYINT ,SMALLINT ,INT,BIGINT,STRING
â¢YoucancastDECIMAL tothefollowingtypes:FLOAT,TINYINT ,SMALLINT ,INT,BIGINT,STRING,BOOLEAN ,
TIMESTAMP
ImpalaperformsCASTbetweenDECIMAL andothernumerictypesasbelow:
â¢Precision:Ifyoucastavaluewithbiggerprecisionthantheprecisionofthedestinationtype,Impalareturnsan
error.Forexample,CAST(123456 AS DECIMAL(3,0)) returnsanerrorbecausealldigitsdonotfitinto
DECIMAL(3, 0)
â¢Scale:Ifyoucastavaluewithmorefractionaldigitsthanthescaleofthedestinationtype,thefractionaldigitsare
rounded.Forexample,CAST(1.239 AS DECIMAL(3, 2)) returns1.24.
CastingSTRINGtoDECIMAL:
YoucancastSTRINGofnumericcharactersincolumns,literals,orexpressionstoDECIMAL aslongasnumberfits
withinthespecified targetDECIMAL typewithoutoverflow.
â¢IfscaleinSTRING>scaleinDECIMAL ,thefractionaldigitsareroundedtotheDECIMAL scale.
Forexample,CAST('98.678912' AS DECIMAL(15, 1)) returns98.7.
â¢If#leadingdigitsinSTRING>#leadingdigitsinDECIMAL ,anerrorisreturned.
Forexample,CAST('123.45' AS DECIMAL(2, 2)) returnsanerror.
ExponentialnotationissupportedwhencastingfromSTRING.
Forexample,CAST('1.0e6' AS DECIMAL(32, 0)) returns1000000 .
Castinganynon-numeric value,suchas'ABC'totheDECIMAL typereturnsanerror.
CastingDECIMALtoTIMESTAMP:
CastingaDECIMAL valueNtoTIMESTAMP producesavaluethatisNsecondspastthestartoftheepochdate(January
1,1970).
DECIMALvsFLOATconsideration:
112|ApacheImpalaGuideImpalaSQLLanguageReference
TheFLOATandDOUBLEtypescancauseproblemsorunexpectedbehaviorduetoinabilitytopreciselyrepresentcertain
fractionalvalues,forexampledollarandcentsvaluesforcurrency.Youmightfindoutputvaluesslightlydifferentthan
youinserted,equalityteststhatdonotmatchprecisely,orunexpectedvaluesforGROUP BY columns.TheDECIMAL
typecanhelpreduceunexpectedbehaviorandroundingerrors,butattheexpenseofsomeperformance overhead
forassignmen tsandcomparisons.
Literalsandexpressions:
â¢Numericliteralswithoutadecimalpoint
âTheliteralsaretreatedasthesmallestintegerthatwouldfittheliteral.Forexample,111isaTINYINT ,and
1111isaSMALLINT .
âLargeliteralsthatdonotfitintoanyintegertypearetreatedasDECIMAL .
âTheliteralstoolargetofitintoaDECIMAL(38, 0) aretreatedasDOUBLE.
â¢Numericliteralswithadecimalpoint
âTheliteralwithlessthan38digitsaretreatedasDECIMAL .
âTheliteralswith38ormoredigitsaretreatedasaDOUBLE.
â¢ExponentialnotationissupportedinDECIMAL literals.
â¢TorepresentaverylargeorpreciseDECIMAL valueasaliteral,forexampleonethatcontainsmoredigitsthan
canberepresentedbyaBIGINTliteral,useaquotedstringorafloating-pointvalueforthenumberandCAST
thestringtothedesiredDECIMAL type.
Forexample:CAST('999999999999999999999999999999' AS DECIMAL(38, 5)))
Fileformatconsiderations:
TheDECIMAL datatypecanbestoredinanyofthefileformatssupportedbyImpala:
â¢ImpalacanqueryAvro,RCFile,orSequenceFile tablesthatcontainDECIMAL columns,createdbyotherHadoop
componen ts.
â¢ImpalacanqueryandinsertintoKudutablesthatcontainDECIMAL columns.Kudusupports theDECIMAL type
inCDH6.1andhigher.
â¢TheDECIMAL datatypeisfullycompatiblewithHBasetables.
â¢TheDECIMAL datatypeisfullycompatiblewithParquettables.
â¢ValuesoftheDECIMAL datatypearepotentiallylargerintexttablesthanintablesusingParquetorotherbinary
formats.
UDFconsideration:
WhenwritingaC++UDF,usetheDecimalVal datatypedefinedin/usr/include/impala_udf/udf.h .
Changing precisionandscale:
YoucanissueanALTER TABLE ... REPLACE COLUMNS statementtochangetheprecisionandscaleofanexisting
DECIMAL column.
â¢Fortext-basedformats(text,RCFile,andSequenceFile tables)
âIfthevaluesinthecolumnfitwithinthenewprecisionandscale,theyarereturnedcorrectlybyaquery.
âIfanyvaluesthatdonotfitwithinthenewprecisionandscale:
â¢ImpalareturnsanerrorifthequeryoptionABORT_ON_ERROR issettotrue.
â¢ImpalareturnsaNULLandwarningthatconversionfailedifthequeryoptionABORT_ON_ERROR isset
tofalse.
âLeadingzerosdonotcountagainsttheprecisionvalue,buttrailingzerosafterthedecimalpointdo.
ApacheImpalaGuide|113ImpalaSQLLanguageReference
â¢Forbinaryformats(ParquetandAvrotables)
âAlthough anALTER TABLE ... REPLACE COLUMNS statementthatchangestheprecisionorscaleofa
DECIMAL columnsucceeds, anysubsequentattempttoquerythechangedcolumnresultsinafatalerror.
Thisisbecausethemetadataaboutthecolumnsisstoredinthedatafilesthemselves,andALTER TABLE
doesnotactuallymakeanyupdatestothedatafiles.Theotherunalteredcolumnscanstillbequeried
successfully.
âIfthemetadatainthedatafilesdisagreeswiththemetadatainthemetastoredatabase,Impalacancelsthe
query.
Partitioning:
UsingaDECIMAL columnasapartitionkeyprovidesyouabettermatchbetweenthepartitionkeyvaluesandtheHDFS
directorynamesthanusingaDOUBLEorFLOATpartitioning column.
Columnstatisticsconsiderations:
BecausetheDECIMAL typehasafixedsize,themaximumandaveragesizefieldsarealwaysfilledinforcolumnstatistics,
evenbeforeyouruntheCOMPUTE STATS statement.
CompatibilitywitholderversionofDECIMAL:
ThisversionofDECIMAL typeisthedefaultinCDH6.0/Impala3.0andhigher.Thekeydifferencesbetweenthisversion
ofDECIMAL andthepreviousDECIMAL V1inImpala2.xincludethefollowing.
DECIMALinCDH5.15/Impala2.12
orlowerDECIMALinCDH6.0/Impala3.0or
higher
ReturnseithertheresultorNULLwith
awarning.Returnseithertheresultoranerror. Overallbehavior
IssuesawarningandreturnsNULL. Abortswithanerror. Overflowbehavior
Truncatesdigitsfromthefront. Truncatesandroundsdigitsfromthe
back.Truncation/roundingbehaviorin
arithmetic
Truncatesfromtheback. Truncatesfromthebackandrounds. Stringcast
IfyouneedtocontinueusingthefirstversionoftheDECIMAL typeforthebackwardcompatibilityofyourqueries,set
theDECIMAL_V2 queryoptiontoFALSE:
SET DECIMAL_V2=FALSE;
Compatibilitywithotherdatabases:
UsetheDECIMAL datatypeinImpalaforapplicationswhereyouusedtheNUMBERdatatypeinOracle.
TheImpalaDECIMAL typedoesnotsupporttheOracleidiomsof*forscale.
TheImpalaDECIMAL typedoesnotsupportnegativevaluesforprecision.
DOUBLEDataType
Adoubleprecisionfloating-pointdatatypeusedinCREATE TABLE andALTER TABLE statements.
Syntax:
InthecolumndefinitionofaCREATE TABLE statement:
column_name  DOUBLE
Range:4.94065645841246544e-324d ..1.79769313486231570e+308, positiveornegative
114|ApacheImpalaGuideImpalaSQLLanguageReference
Precision:15to17significantdigits,depending onusage.Thenumberofsignificantdigitsdoesnotdependonthe
positionofthedecimalpoint.
Representation:Thevaluesarestoredin8bytes,usingIEEE754DoublePrecisionBinaryFloatingPointformat.
Conversions:ImpaladoesnotautomaticallyconvertDOUBLEtoanyothertype.YoucanuseCAST()toconvertDOUBLE
valuestoFLOAT,TINYINT ,SMALLINT ,INT,BIGINT,STRING,TIMESTAMP ,orBOOLEAN .Youcanuseexponential
notationinDOUBLEliteralsorwhencastingfromSTRING,forexample1.0e6torepresentonemillion.Castingan
integerorfloating-pointvalueNtoTIMESTAMP producesavaluethatisNsecondspastthestartoftheepochdate
(January1,1970).Bydefault,theresultvaluerepresentsadateandtimeintheUTCtimezone.Ifthesetting
--use_local_tz_for_unix_timestamp_conversions=true isineffect,theresultingTIMESTAMP representsa
dateandtimeinthelocaltimezone.
Usagenotes:
ThedatatypeREALisanaliasforDOUBLE.
ImpaladoesnotevaluateNaN(notanumber)asequaltoanyothernumericvalues,including otherNaNvalues.For
example,thefollowingstatement,whichevaluatesequalitybetweentwoNaNvalues,returnsfalse:
SELECT CAST('nan' AS DOUBLE)=CAST('nan' AS DOUBLE);
Examples:
CREATE TABLE t1 (x DOUBLE);
SELECT CAST(1000.5 AS DOUBLE);
Partitioning: Becausefractionalvaluesofthistypearenotalwaysrepresentedprecisely,whenthistypeisusedfora
partition keycolumn,theunderlying HDFSdirectoriesmightnotbenamedexactlyasyouexpect.Prefertopartition
onaDECIMAL columninstead.
HBaseconsiderations:ThisdatatypeisfullycompatiblewithHBasetables.
Parquetconsiderations:ThistypeisfullycompatiblewithParquettables.
Texttableconsiderations:ValuesofthistypearepotentiallylargerintexttablesthanintablesusingParquetorother
binaryformats.
Internaldetails:Representedinmemoryasan8-bytevalue.
Columnstatisticsconsiderations:Becausethistypehasafixedsize,themaximumandaveragesizefieldsarealways
filledinforcolumnstatistics,evenbeforeyouruntheCOMPUTE STATS statement.
Restrictions:
DuetothewayarithmeticonFLOATandDOUBLEcolumnsuseshigh-performancehardwareinstructions, anddistributed
queriescanperformtheseoperationsindifferentorderforeachquery,resultscanvaryslightlyforaggregatefunction
callssuchasSUM()andAVG()forFLOATandDOUBLEcolumns,particularly onlargedatasetswheremillionsorbillions
ofvaluesaresummed oraveraged.Forperfectconsistencyandrepeatability,usetheDECIMAL datatypeforsuch
operationsinsteadofFLOATorDOUBLE.
Theinabilitytoexactlyrepresentcertainfloating-pointvaluesmeansthatDECIMAL issometimesabetterchoicethan
DOUBLEorFLOATwhenprecisioniscritical,particularly whentransferringdatafromotherdatabasesystemsthatuse
differentrepresentationsorfileformats.
Kuduconsiderations:
Currently,thedatatypesBOOLEAN ,FLOAT,andDOUBLEcannotbeusedforprimarykeycolumnsinKudutables.
Relatedinformation:
NumericLiteralsonpage167,ImpalaMathematicalFunctions onpage397,FLOATDataTypeonpage116
ApacheImpalaGuide|115ImpalaSQLLanguageReference
FLOATDataType
Asingleprecisionfloating-pointdatatypeusedinCREATE TABLE andALTER TABLE statements.
Syntax:
InthecolumndefinitionofaCREATE TABLE statement:
column_name  FLOAT
Range:1.40129846432481707e-45 ..3.40282346638528860e+38, positiveornegative
Precision:6to9significantdigits,depending onusage.Thenumberofsignificantdigitsdoesnotdependontheposition
ofthedecimalpoint.
Representation:Thevaluesarestoredin4bytes,usingIEEE754SinglePrecisionBinaryFloatingPointformat.
Conversions:ImpalaautomaticallyconvertsFLOATtomorepreciseDOUBLEvalues,butnottheotherwayaround.
YoucanuseCAST()toconvertFLOATvaluestoTINYINT ,SMALLINT ,INT,BIGINT,STRING,TIMESTAMP ,orBOOLEAN .
YoucanuseexponentialnotationinFLOATliteralsorwhencastingfromSTRING,forexample1.0e6torepresentone
million.Castinganintegerorfloating-pointvalueNtoTIMESTAMP producesavaluethatisNsecondspastthestartof
theepochdate(January1,1970).Bydefault,theresultvaluerepresentsadateandtimeintheUTCtimezone.Ifthe
setting--use_local_tz_for_unix_timestamp_conversions=true isineffect,theresultingTIMESTAMP
representsadateandtimeinthelocaltimezone.
Usagenotes:
ImpaladoesnotevaluateNaN(notanumber)asequaltoanyothernumericvalues,including otherNaNvalues.For
example,thefollowingstatement,whichevaluatesequalitybetweentwoNaNvalues,returnsfalse:
SELECT CAST('nan' AS FLOAT)=CAST('nan' AS FLOAT);
Examples:
CREATE TABLE t1 (x FLOAT);
SELECT CAST(1000.5 AS FLOAT);
Partitioning: Becausefractionalvaluesofthistypearenotalwaysrepresentedprecisely,whenthistypeisusedfora
partition keycolumn,theunderlying HDFSdirectoriesmightnotbenamedexactlyasyouexpect.Prefertopartition
onaDECIMAL columninstead.
HBaseconsiderations:ThisdatatypeisfullycompatiblewithHBasetables.
Parquetconsiderations:ThistypeisfullycompatiblewithParquettables.
Texttableconsiderations:ValuesofthistypearepotentiallylargerintexttablesthanintablesusingParquetorother
binaryformats.
Internaldetails:Representedinmemoryasa4-bytevalue.
Columnstatisticsconsiderations:Becausethistypehasafixedsize,themaximumandaveragesizefieldsarealways
filledinforcolumnstatistics,evenbeforeyouruntheCOMPUTE STATS statement.
Restrictions:
DuetothewayarithmeticonFLOATandDOUBLEcolumnsuseshigh-performancehardwareinstructions, anddistributed
queriescanperformtheseoperationsindifferentorderforeachquery,resultscanvaryslightlyforaggregatefunction
callssuchasSUM()andAVG()forFLOATandDOUBLEcolumns,particularly onlargedatasetswheremillionsorbillions
ofvaluesaresummed oraveraged.Forperfectconsistencyandrepeatability,usetheDECIMAL datatypeforsuch
operationsinsteadofFLOATorDOUBLE.
Theinabilitytoexactlyrepresentcertainfloating-pointvaluesmeansthatDECIMAL issometimesabetterchoicethan
DOUBLEorFLOATwhenprecisioniscritical,particularly whentransferringdatafromotherdatabasesystemsthatuse
differentrepresentationsorfileformats.
116|ApacheImpalaGuideImpalaSQLLanguageReference
Kuduconsiderations:
Currently,thedatatypesBOOLEAN ,FLOAT,andDOUBLEcannotbeusedforprimarykeycolumnsinKudutables.
Relatedinformation:
NumericLiteralsonpage167,ImpalaMathematicalFunctions onpage397,DOUBLEDataTypeonpage114
INTDataType
A4-byteintegerdatatypeusedinCREATE TABLE andALTER TABLE statements.
Syntax:
InthecolumndefinitionofaCREATE TABLE statement:
column_name  INT
Range:-2147483648 ..2147483647. ThereisnoUNSIGNED subtype.
Conversions:Impalaautomaticallyconvertstoalargerintegertype(BIGINT)orafloating-pointtype(FLOATorDOUBLE)
automatically.UseCAST()toconverttoTINYINT ,SMALLINT ,STRING,orTIMESTAMP .Castinganintegeror
floating-pointvalueNtoTIMESTAMP producesavaluethatisNsecondspastthestartoftheepochdate(January1,
1970).Bydefault,theresultvaluerepresentsadateandtimeintheUTCtimezone.Ifthesetting
--use_local_tz_for_unix_timestamp_conversions=true isineffect,theresultingTIMESTAMP representsa
dateandtimeinthelocaltimezone.
Usagenotes:
ThedatatypeINTEGER isanaliasforINT.
ForaconvenientandautomatedwaytochecktheboundsoftheINTtype,callthefunctionsMIN_INT() and
MAX_INT() .
IfanintegervalueistoolargetoberepresentedasaINT,useaBIGINTinstead.
NULLconsiderations:Castinganynon-numeric valuetothistypeproducesaNULLvalue.
Examples:
CREATE TABLE t1 (x INT);
SELECT CAST(1000 AS INT);
Partitioning: Prefertousethistypeforapartition keycolumn.Impalacanprocessthenumerictypemoreefficiently
thanaSTRINGrepresentationofthevalue.
HBaseconsiderations:ThisdatatypeisfullycompatiblewithHBasetables.
Parquetconsiderations:
Texttableconsiderations:ValuesofthistypearepotentiallylargerintexttablesthanintablesusingParquetorother
binaryformats.
Internaldetails:Representedinmemoryasa4-bytevalue.
Addedin:AvailableinallversionsofImpala.
Columnstatisticsconsiderations:Becausethistypehasafixedsize,themaximumandaveragesizefieldsarealways
filledinforcolumnstatistics,evenbeforeyouruntheCOMPUTE STATS statement.
Relatedinformation:
NumericLiteralsonpage167,TINYINTDataTypeonpage136,SMALLINT DataTypeonpage122,INTDataTypeonpage
117,BIGINTDataTypeonpage105,DECIMALDataType(CDH6.0/Impala3.0orhigheronly)onpage109,Impala
MathematicalFunctions onpage397
ApacheImpalaGuide|117ImpalaSQLLanguageReference
MAPComplexType(CDH5.5orhigheronly)
Acomplexdatatyperepresentinganarbitrarysetofkey-valuepairs.Thekeypartisascalartype,whilethevaluepart
canbeascalaroranothercomplextype(ARRAY,STRUCT,orMAP).
Syntax:
column_name  MAP < primitive_type , type >
type ::= primitive_type  | complex_type
Usagenotes:
Becausecomplextypesareoftenusedincombination,forexampleanARRAYofSTRUCTelements,ifyouareunfamiliar
withtheImpalacomplextypes,startwithComplexTypes(CDH5.5orhigheronly)onpage139forbackgroundinformation
andusageexamples.
TheMAPcomplexdatatyperepresentsasetofkey-valuepairs.Eachelementofthemapisindexedbyaprimitivetype
suchasBIGINTorSTRING,lettingyoudefinesequences thatarenotcontinuousorcategorieswitharbitrarynames.
Youmightfinditconvenientformodelling dataproducedinotherlanguages,suchasaPythondictionaryorJava
HashMap, whereasinglescalarvalueservesasthelookupkey.
Inabigdatacontext,thekeysinamapcolumnmightrepresentanumericsequence ofeventsduringamanufacturing
process,orTIMESTAMP valuescorresponding tosensorobservations.Themapitselfisinherentlyunordered,soyou
choosewhethertomakethekeyvaluessignificant(suchasarecordedTIMESTAMP )orsynthetic(suchasarandom
globaluniversalID).
Note:Behindthescenes,theMAPtypeisimplemen tedinasimilarwayastheARRAYtype.Impala
doesnotenforceanyuniqueness constraintontheKEYvalues,andtheKEYvaluesareprocessedby
loopingthroughtheelementsoftheMAPratherthanbyaconstant-timelookup.Therefore,thistype
isprimarily foreaseofunderstandingwhenimporting dataandalgorithmsfromnon-SQLcontexts,
ratherthanoptimizingtheperformance ofkeylookups.
Youcanpassamulti-part qualified nametoDESCRIBE tospecifyanARRAY,STRUCT,orMAPcolumnandvisualizeits
structureasifitwereatable.Forexample,iftableT1containsanARRAYcolumnA1,youcouldissuethestatement
DESCRIBE t1.a1 .IftableT1containedaSTRUCTcolumnS1,andafieldF1withintheSTRUCTwasaMAP,youcould
issuethestatementDESCRIBE t1.s1.f1 .AnARRAYisshownasatwo-columntable,withITEMandPOScolumns.
ASTRUCTisshownasatablewitheachfieldrepresentingacolumninthetable.AMAPisshownasatwo-columntable,
withKEYandVALUEcolumns.
Addedin:CDH5.5.0/Impala2.3.0
Restrictions:
â¢Columns withthisdatatypecanonlybeusedintablesorpartitions withtheParquetfileformat.
â¢Columns withthisdatatypecannotbeusedaspartition keycolumnsinapartitioned table.
â¢TheCOMPUTE STATS statementdoesnotproduceanystatisticsforcolumnsofthisdatatype.
â¢Themaximumlengthofthecolumndefinitionforanycomplextype,including declarationsforanynestedtypes,
is4000characters.
â¢SeeLimitationsandRestrictionsforComplexTypesonpage143forafulllistoflimitationsandassociatedguidelines
aboutcomplextypecolumns.
Kuduconsiderations:
Currently,thedatatypesCHAR,VARCHAR ,ARRAY,MAP,andSTRUCTcannotbeusedwithKudutables.
Examples:
118|ApacheImpalaGuideImpalaSQLLanguageReference
Note:ManyofthecomplextypeexamplesrefertotablessuchasCUSTOMER andREGIONadapted
fromthetablesusedintheTPC-Hbenchmark. SeeSampleSchemaandDataforExperimen tingwith
ImpalaComplexTypesonpage160forthetabledefinitions.
ThefollowingexampleshowsatablewithvariouskindsofMAPcolumns,bothatthetoplevelandnestedwithinother
complextypes.Eachrowrepresentsinformationaboutaspecificcountry,withcomplextypefieldsofvariouslevels
ofnestingtorepresentdifferentinformationassociatedwiththecountry:factualmeasurementssuchasareaand
population,notablepeopleindifferentcategories,geographicfeaturessuchascities,pointsofinterestwithineach
city,andmountainswithassociatedfacts.PracticetheCREATE TABLE andquerynotationforcomplextypecolumns
usingemptytables,untilyoucanvisualizeacomplexdatastructureandconstructcorresponding SQLstatements
reliably.
create TABLE map_demo
(
  country_id BIGINT,
-- Numeric facts about each country, looked up by name.
-- For example, 'Area':1000, 'Population':999999.
-- Using a MAP instead of a STRUCT because there could be
-- a different set of facts for each country.
  metrics MAP <STRING, BIGINT>,
-- MAP whose value part is an ARRAY.
-- For example, the key 'Famous Politicians' could represent an array of 10 elements,
-- while the key 'Famous Actors' could represent an array of 20 elements.
  notables MAP <STRING, ARRAY <STRING>>,
-- MAP that is a field within a STRUCT.
-- (The STRUCT is inside another ARRAY, because it is rare
-- for a STRUCT to be a top-level column.)
-- For example, city #1 might have points of interest with key 'Zoo',
-- representing an array of 3 different zoos.
-- City #2 might have completely different kinds of points of interest.
-- Because the set of field names is potentially large, and most entries could be blank,
-- a MAP makes more sense than a STRUCT to represent such a sparse data structure.
  cities ARRAY < STRUCT <
    name: STRING,
    points_of_interest: MAP <STRING, ARRAY <STRING>>
  >>,
-- MAP that is an element within an ARRAY. The MAP is inside a STRUCT field to associate
-- the mountain name with all the facts about the mountain.
-- The "key" of the map (the first STRING field) represents the name of some fact whose
 value
-- can be expressed as an integer, such as 'Height', 'Year First Climbed', and so on.
  mountains ARRAY < STRUCT < name: STRING, facts: MAP <STRING, INT > > >
)
STORED AS PARQUET;
DESCRIBE map_demo;
+------------+------------------------------------------------+
| name       | type                                           |
+------------+------------------------------------------------+
| country_id | bigint                                         |
| metrics    | map<string,bigint>                             |
| notables   | map<string,array<string>>                      |
| cities     | array<struct<                                  |
|            |   name:string,                                 |
|            |   points_of_interest:map<string,array<string>> |
|            | >>                                             |
| mountains  | array<struct<                                  |
|            |   name:string,                                 |
|            |   facts:map<string,int>                        |
|            | >>                                             |
+------------+------------------------------------------------+
DESCRIBE map_demo.metrics;
ApacheImpalaGuide|119ImpalaSQLLanguageReference
+-------+--------+
| name  | type   |
+-------+--------+
| key   | string |
| value | bigint |
+-------+--------+
DESCRIBE map_demo.notables;
+-------+---------------+
| name  | type          |
+-------+---------------+
| key   | string        |
| value | array<string> |
+-------+---------------+
DESCRIBE map_demo.notables.value;
+------+--------+
| name | type   |
+------+--------+
| item | string |
| pos  | bigint |
+------+--------+
DESCRIBE map_demo.cities;
+------+------------------------------------------------+
| name | type                                           |
+------+------------------------------------------------+
| item | struct<                                        |
|      |   name:string,                                 |
|      |   points_of_interest:map<string,array<string>> |
|      | >                                              |
| pos  | bigint                                         |
+------+------------------------------------------------+
DESCRIBE map_demo.cities.item.points_of_interest;
+-------+---------------+
| name  | type          |
+-------+---------------+
| key   | string        |
| value | array<string> |
+-------+---------------+
DESCRIBE map_demo.cities.item.points_of_interest.value;
+------+--------+
| name | type   |
+------+--------+
| item | string |
| pos  | bigint |
+------+--------+
DESCRIBE map_demo.mountains;
+------+-------------------------+
| name | type                    |
+------+-------------------------+
| item | struct<                 |
|      |   name:string,          |
|      |   facts:map<string,int> |
|      | >                       |
| pos  | bigint                  |
+------+-------------------------+
DESCRIBE map_demo.mountains.item.facts;
+-------+--------+
| name  | type   |
+-------+--------+
| key   | string |
| value | int    |
+-------+--------+
120|ApacheImpalaGuideImpalaSQLLanguageReference
ThefollowingexampleshowsatablethatusesavarietyofdatatypesfortheMAPâkeyâfield.Typically,youuseBIGINT
orSTRINGtousenumericorcharacter-based keyswithoutworryingaboutexceedinganysizeorlengthconstraints.
CREATE TABLE map_demo_obscure
(
  id BIGINT,
  m1 MAP <INT, INT>,
  m2 MAP <SMALLINT, INT>,
  m3 MAP <TINYINT, INT>,
  m4 MAP <TIMESTAMP, INT>,
  m5 MAP <BOOLEAN, INT>,
  m6 MAP <CHAR(5), INT>,
  m7 MAP <VARCHAR(25), INT>,
  m8 MAP <FLOAT, INT>,
  m9 MAP <DOUBLE, INT>,
  m10 MAP <DECIMAL(12,2), INT>
)
STORED AS PARQUET;
CREATE TABLE celebrities (name STRING, birth_year MAP < STRING, SMALLINT >) STORED AS 
PARQUET;
-- A typical row might represent values with 2 different birth years, such as:
-- ("Joe Movie Star", { "real": 1972, "claimed": 1977 })
CREATE TABLE countries (name STRING, famous_leaders MAP < INT, STRING >) STORED AS 
PARQUET;
-- A typical row might represent values with different leaders, with key values 
corresponding to their numeric sequence, such as:
-- ("United States", { 1: "George Washington", 3: "Thomas Jefferson", 16: "Abraham 
Lincoln" })
CREATE TABLE airlines (name STRING, special_meals MAP < STRING, MAP < STRING, STRING >
 >) STORED AS PARQUET;
-- A typical row might represent values with multiple kinds of meals, each with several
 components:
-- ("Elegant Airlines",
--   {
--     "vegetarian": { "breakfast": "pancakes", "snack": "cookies", "dinner": "rice 
pilaf" },
--     "gluten free": { "breakfast": "oatmeal", "snack": "fruit", "dinner": "chicken" 
}
--   } )
Relatedinformation:
ComplexTypes(CDH5.5orhigheronly)onpage139,ARRAYComplexType(CDH5.5orhigheronly)onpage102,STRUCT
ComplexType(CDH5.5orhigheronly)onpage124
REALDataType
AnaliasfortheDOUBLEdatatype.SeeDOUBLEDataTypeonpage114fordetails.
Examples:
TheseexamplesshowhowyoucanusethetypenamesREALandDOUBLEinterchangeably,andbehindthescenes
ImpalatreatsthemalwaysasDOUBLE.
[localhost:21000] > create table r1 (x real);
[localhost:21000] > describe r1;
+------+--------+---------+
| name | type   | comment |
+------+--------+---------+
| x    | double |         |
+------+--------+---------+
[localhost:21000] > insert into r1 values (1.5), (cast (2.2 as double));
[localhost:21000] > select cast (1e6 as real);
+---------------------------+
| cast(1000000.0 as double) |
ApacheImpalaGuide|121ImpalaSQLLanguageReference
+---------------------------+
| 1000000                   |
+---------------------------+
SMALLINT DataType
A2-byteintegerdatatypeusedinCREATE TABLE andALTER TABLE statements.
Syntax:
InthecolumndefinitionofaCREATE TABLE statement:
column_name  SMALLINT
Range:-32768..32767.ThereisnoUNSIGNED subtype.
Conversions:Impalaautomaticallyconvertstoalargerintegertype(INTorBIGINT)orafloating-pointtype(FLOAT
orDOUBLE)automatically.UseCAST()toconverttoTINYINT ,STRING,orTIMESTAMP .Castinganintegeror
floating-pointvalueNtoTIMESTAMP producesavaluethatisNsecondspastthestartoftheepochdate(January1,
1970).Bydefault,theresultvaluerepresentsadateandtimeintheUTCtimezone.Ifthesetting
--use_local_tz_for_unix_timestamp_conversions=true isineffect,theresultingTIMESTAMP representsa
dateandtimeinthelocaltimezone.
Usagenotes:
ForaconvenientandautomatedwaytochecktheboundsoftheSMALLINT type,callthefunctionsMIN_SMALLINT()
andMAX_SMALLINT() .
IfanintegervalueistoolargetoberepresentedasaSMALLINT ,useanINTinstead.
NULLconsiderations:Castinganynon-numeric valuetothistypeproducesaNULLvalue.
Examples:
CREATE TABLE t1 (x SMALLINT);
SELECT CAST(1000 AS SMALLINT);
Parquetconsiderations:
Physically,ParquetfilesrepresentTINYINT andSMALLINT valuesas32-bitintegers.Although Impalarejectsattempts
toinsertout-of-rangevaluesintosuchcolumns,ifyoucreateanewtablewiththeCREATE TABLE ... LIKE PARQUET
syntax,anyTINYINT orSMALLINT columnsintheoriginaltableturnintoINTcolumnsinthenewtable.
Partitioning: Prefertousethistypeforapartition keycolumn.Impalacanprocessthenumerictypemoreefficiently
thanaSTRINGrepresentationofthevalue.
HBaseconsiderations:ThisdatatypeisfullycompatiblewithHBasetables.
Texttableconsiderations:ValuesofthistypearepotentiallylargerintexttablesthanintablesusingParquetorother
binaryformats.
Internaldetails:Representedinmemoryasa2-bytevalue.
Addedin:AvailableinallversionsofImpala.
Columnstatisticsconsiderations:Becausethistypehasafixedsize,themaximumandaveragesizefieldsarealways
filledinforcolumnstatistics,evenbeforeyouruntheCOMPUTE STATS statement.
Relatedinformation:
NumericLiteralsonpage167,TINYINTDataTypeonpage136,SMALLINT DataTypeonpage122,INTDataTypeonpage
117,BIGINTDataTypeonpage105,DECIMALDataType(CDH6.0/Impala3.0orhigheronly)onpage109,Impala
MathematicalFunctions onpage397
122|ApacheImpalaGuideImpalaSQLLanguageReference
STRINGDataType
AdatatypeusedinCREATE TABLE andALTER TABLE statements.
Syntax:
InthecolumndefinitionofaCREATE TABLE andALTER TABLE statements:
column_name  STRING
Length:
Ifyouneedtomanipula testringvalueswithpreciseormaximumlengths,inImpala2.0andhigheryoucandeclare
columnsasVARCHAR( max_length )orCHAR(length),butforbestperformance useSTRINGwherepractical.
TakethefollowingconsiderationsforSTRINGlengths:
â¢ThehardlimitonthesizeofaSTRINGandthetotalsizeofarowis2GB.
Ifaquerytriestoprocessorcreateastringlargerthanthislimit,itwillreturnanerrortotheuser.
â¢Thelimitis1GBonSTRINGwhenwritingtoParquetfiles.
â¢Queriesoperatingonstringswith32KBorlesswillworkreliablyandwillnothitsignificantperformanceormemory
problems(unlessyouhaveverycomplexqueries,verymanycolumns,etc.)
â¢Performance andmemoryconsumptionmaydegradewithstringslargerthan32KB.
â¢Therowsize,i.e.thetotalsizeofallstringandothercolumns,issubjecttolowerlimitsatvariouspointsinquery
executionthatsupportspill-to-disk.Afewexamplesforlowerrowsizelimitsare:
âRowscomingfromtherightsideofanyhashjoin
âRowscomingfromeithersideofahashjointhatspillstodisk
âRowsbeingsortedbytheSORToperatorwithoutalimit
âRowsinagroupingaggregation
InCDH5.12andlower,thedefaultlimitoftherowsizeintheabovecasesis8MB.
InCDH5.13andhigher,themaxrowsizeisconfigurableonaper-querybasiswiththeMAX_ROW_SIZE query
option.RowsuptoMAX_ROW_SIZE (whichdefaultsto512KB)canalwaysbeprocessedintheabovecases.Rows
largerthanMAX_ROW_SIZE areprocessedonabest-effortbasis.SeeMAX_ROW_SIZEformoredetails.
Charactersets:
ForfullsupportinallImpalasubsystems,restrictstringvaluestotheASCIIcharacterset.Although someUTF-8character
datacanbestoredinImpalaandretrievedthroughqueries,UTF-8stringscontainingnon-ASCII charactersarenot
guaranteedtoworkproperlyincombinationwithmanySQLaspects,including butnotlimitedto:
â¢Stringmanipula tionfunctions.
â¢Comparison operators.
â¢TheORDER BY clause.
â¢Valuesinpartition keycolumns.
ForanynationallanguageaspectssuchascollationorderorinterpretingextendedASCIIvariantssuchasISO-8859-1
orISO-8859-2 encodings,Impaladoesnotincludesuchmetadatawiththetabledefinition.Ifyouneedtosort,manipulate,
ordisplaydatadepending onthosenationallanguagecharacteristicsofstringdata,uselogicontheapplicationside.
Conversions:
â¢ImpaladoesnotautomaticallyconvertSTRINGtoanynumerictype.ImpaladoesautomaticallyconvertSTRING
toTIMESTAMP ifthevaluematchesoneoftheacceptedTIMESTAMP formats;seeTIMESTAMPDataTypeonpage
130fordetails.
â¢YoucanuseCAST()toconvertSTRINGvaluestoTINYINT ,SMALLINT ,INT,BIGINT,FLOAT,DOUBLE,or
TIMESTAMP .
ApacheImpalaGuide|123ImpalaSQLLanguageReference
â¢YoucannotdirectlycastaSTRINGvaluetoBOOLEAN .YoucanuseaCASEexpressiontoevaluatestringvalues
suchas'T','true',andsoonandreturnBooleantrueandfalsevaluesasappropriate.
â¢YoucancastaBOOLEAN valuetoSTRING,returning'1'fortruevaluesand'0'forfalsevalues.
Partitioning:
Although itmightbeconvenienttouseSTRINGcolumnsforpartitionkeys,evenwhenthosecolumnscontainnumbers,
forperformance andscalabilityitismuchbettertousenumericcolumnsaspartitionkeyswheneverpractical.Although
theunderlying HDFSdirectorynamemightbethesameineithercase,thein-memor ystorageforthepartition key
columnsismorecompact,andcomputationsarefaster,ifpartition keycolumnssuchasYEAR,MONTH,DAYandsoon
aredeclaredasINT,SMALLINT ,andsoon.
Zero-lengthstrings:Forpurposes ofclausessuchasDISTINCT andGROUP BY ,Impalaconsiderszero-lengthstrings
(""),NULL,andspacetoallbedifferentvalues.
Texttableconsiderations:ValuesofthistypearepotentiallylargerintexttablesthanintablesusingParquetorother
binaryformats.
Avroconsiderations:
TheAvrospecificationallowsstringvaluesupto2**64bytesinlength.ImpalaqueriesforAvrotablesuse32-bitintegers
toholdstringlengths.InCDH5.7/Impala2.5andhigher,ImpalatruncatesCHARandVARCHAR valuesinAvrotables
to(2**31)-1 bytes.IfaqueryencountersaSTRINGvaluelongerthan(2**31)-1 bytesinanAvrotable,thequeryfails.
Inearlierreleases,encounteringsuchlongvaluesinanAvrotablecouldcauseacrash.
Columnstatisticsconsiderations:Becausethevaluesofthistypehavevariablesize,noneofthecolumnstatisticsfields
arefilledinuntilyouruntheCOMPUTE STATS statement.
Examples:
Thefollowingexamplesdemonstratedouble-quot edandsingle-quot edstringliterals,andrequiredescapingfor
quotationmarkswithinstringliterals:
SELECT 'I am a single-quoted string';
SELECT "I am a double-quoted string";
SELECT 'I\'m a single-quoted string with an apostrophe';
SELECT "I\'m a double-quoted string with an apostrophe";
SELECT 'I am a "short" single-quoted string containing quotes';
SELECT "I am a \"short\" double-quoted string containing quotes";
Thefollowingexamplesdemonstratecallstostringmanipula tionfunctions toconcatenatestrings,convertnumbers
tostrings,orpulloutsubstrings:
SELECT CONCAT("Once upon a time, there were ", CAST(3 AS STRING), ' little pigs.');
SELECT SUBSTR("hello world",7,5);
ThefollowingexamplesshowhowtoperformoperationsonSTRINGcolumnswithinatable:
CREATE TABLE t1 (s1 STRING, s2 STRING);
INSERT INTO t1 VALUES ("hello", 'world'), (CAST(7 AS STRING), "wonders");
SELECT s1, s2, length(s1) FROM t1 WHERE s2 LIKE 'w%';
Relatedinformation:
StringLiteralsonpage168,CHARDataType(CDH5.2orhigheronly)onpage107,VARCHARDataType(CDH5.2or
higheronly)onpage137,ImpalaStringFunctions onpage462,ImpalaDateandTimeFunctions onpage424
STRUCTComplexType(CDH5.5orhigheronly)
Acomplexdatatype,representingmultiplefieldsofasingleitem.FrequentlyusedastheelementtypeofanARRAY
ortheVALUEpartofaMAP.
124|ApacheImpalaGuideImpalaSQLLanguageReference
Syntax:
column_name  STRUCT < name : type [COMMENT ' comment_string '], ... >
type ::= primitive_type  | complex_type
ThenamesandnumberoffieldswithintheSTRUCTarefixed.Eachfieldcanbeadifferenttype.AfieldwithinaSTRUCT
canalsobeanotherSTRUCT,oranARRAYoraMAP,allowingyoutocreatenesteddatastructureswithamaximum
nestingdepthof100.
ASTRUCTcanbethetop-leveltypeforacolumn,orcanitselfbeanitemwithinanARRAYorthevaluepartofthe
key-valuepairinaMAP.
WhenaSTRUCTisusedasanARRAYelementoraMAPvalue,youuseajoinclausetobringtheARRAYorMAPelements
intotheresultset,andthenrefertoarray_name .ITEM.fieldormap_name .VALUE.field.InthecaseofaSTRUCT
directlyinsideanARRAYorMAP,youcanomitthe.ITEMand.VALUEpseudocolumnsandreferdirectlyto
array_name .fieldormap_name .field.
Usagenotes:
Becausecomplextypesareoftenusedincombination,forexampleanARRAYofSTRUCTelements,ifyouareunfamiliar
withtheImpalacomplextypes,startwithComplexTypes(CDH5.5orhigheronly)onpage139forbackgroundinformation
andusageexamples.
ASTRUCTissimilarconceptuallytoatablerow:itcontainsafixednumberofnamedfields,eachwithapredefined
type.Tocombinetworelatedtables,whileusingcomplextypestominimizerepetition,thetypicalwaytorepresent
thatdataisasanARRAYofSTRUCTelements.
BecauseaSTRUCThasafixednumberofnamedfields,ittypicallydoesnotmakesensetohaveaSTRUCTasthetype
ofatablecolumn.Insuchacase,youcouldjustmakeeachfieldoftheSTRUCTintoaseparatecolumnofthetable.
TheSTRUCTtypeismostusefulasanitemofanARRAYorthevaluepartofthekey-valuepairinaMAP.Anestedtype
columnwithaSTRUCTatthelowestlevelletsyouassociateavariablenumberofrow-likeobjectswitheachrowof
thetable.
TheSTRUCTtypeisstraightforwardtoreferencewithinaquery.YoudonotneedtoincludetheSTRUCTcolumnina
joinclauseorgiveitatablealias,asisrequiredfortheARRAYandMAPtypes.Yourefertotheindividual fieldsusing
dotnotation,suchasstruct_column_name .field_name ,withoutanypseudocolumnsuchasITEMorVALUE.
Youcanpassamulti-part qualified nametoDESCRIBE tospecifyanARRAY,STRUCT,orMAPcolumnandvisualizeits
structureasifitwereatable.Forexample,iftableT1containsanARRAYcolumnA1,youcouldissuethestatement
DESCRIBE t1.a1 .IftableT1containedaSTRUCTcolumnS1,andafieldF1withintheSTRUCTwasaMAP,youcould
issuethestatementDESCRIBE t1.s1.f1 .AnARRAYisshownasatwo-columntable,withITEMandPOScolumns.
ASTRUCTisshownasatablewitheachfieldrepresentingacolumninthetable.AMAPisshownasatwo-columntable,
withKEYandVALUEcolumns.
Internaldetails:
WithintheParquetdatafile,thevaluesforeachSTRUCTfieldarestoredadjacenttoeachother,sothattheycanbe
encodedandcompressedusingalltheParquettechniques forstoringsetsofsimilarorrepeatedvalues.Theadjacency
appliesevenwhentheSTRUCTvaluesarepartofanARRAYorMAP.Duringaquery,Impalaavoidsunnecessar yI/Oby
readingonlytheportionsoftheParquetdatafilecontainingtherequestedSTRUCTfields.
Addedin:CDH5.5.0/Impala2.3.0
Restrictions:
â¢Columns withthisdatatypecanonlybeusedintablesorpartitions withtheParquetfileformat.
â¢Columns withthisdatatypecannotbeusedaspartition keycolumnsinapartitioned table.
â¢TheCOMPUTE STATS statementdoesnotproduceanystatisticsforcolumnsofthisdatatype.
â¢Themaximumlengthofthecolumndefinitionforanycomplextype,including declarationsforanynestedtypes,
is4000characters.
ApacheImpalaGuide|125ImpalaSQLLanguageReference
â¢SeeLimitationsandRestrictionsforComplexTypesonpage143forafulllistoflimitationsandassociatedguidelines
aboutcomplextypecolumns.
Kuduconsiderations:
Currently,thedatatypesCHAR,VARCHAR ,ARRAY,MAP,andSTRUCTcannotbeusedwithKudutables.
Examples:
Note:ManyofthecomplextypeexamplesrefertotablessuchasCUSTOMER andREGIONadapted
fromthetablesusedintheTPC-Hbenchmark. SeeSampleSchemaandDataforExperimen tingwith
ImpalaComplexTypesonpage160forthetabledefinitions.
ThefollowingexampleshowsatablewithvariouskindsofSTRUCTcolumns,bothatthetoplevelandnestedwithin
othercomplextypes.PracticetheCREATE TABLE andquerynotationforcomplextypecolumnsusingemptytables,
untilyoucanvisualizeacomplexdatastructureandconstructcorresponding SQLstatementsreliably.
CREATE TABLE struct_demo
(
  id BIGINT,
  name STRING,
-- A STRUCT as a top-level column. Demonstrates how the table ID column
-- and the ID field within the STRUCT can coexist without a name conflict.
  employee_info STRUCT < employer: STRING, id: BIGINT, address: STRING >,
-- A STRUCT as the element type of an ARRAY.
  places_lived ARRAY < STRUCT <street: STRING, city: STRING, country: STRING >>,
-- A STRUCT as the value portion of the key-value pairs in a MAP.
  memorable_moments MAP < STRING, STRUCT < year: INT, place: STRING, details: STRING 
>>,
-- A STRUCT where one of the fields is another STRUCT.
  current_address STRUCT < street_address: STRUCT <street_number: INT, street_name: 
STRING, street_type: STRING>, country: STRING, postal_code: STRING >
)
STORED AS PARQUET;
ThefollowingexampleshowshowtoexaminethestructureofatablecontainingoneormoreSTRUCTcolumnsby
usingtheDESCRIBE statement.YoucanvisualizeeachSTRUCTasitsowntable,withcolumnsnamedthesameas
eachfieldoftheSTRUCT.IftheSTRUCTisnestedinsideanothercomplextype,suchasARRAY,youcanextendthe
qualified namepassedtoDESCRIBE untiltheoutputshowsjusttheSTRUCTfields.
DESCRIBE struct_demo;
+-------------------+--------------------------+
| name              | type                     |
+-------------------+--------------------------+
| id                | bigint                   |
| name              | string                   |
| employee_info     | struct<                  |
|                   |   employer:string,       |
|                   |   id:bigint,             |
|                   |   address:string         |
|                   | >                        |
| places_lived      | array<struct<            |
|                   |   street:string,         |
|                   |   city:string,           |
|                   |   country:string         |
|                   | >>                       |
| memorable_moments | map<string,struct<       |
|                   |   year:int,              |
|                   |   place:string,          |
|                   |   details:string         |
|                   | >>                       |
| current_address   | struct<                  |
126|ApacheImpalaGuideImpalaSQLLanguageReference
|                   |   street_address:struct< |
|                   |     street_number:int,   |
|                   |     street_name:string,  |
|                   |     street_type:string   |
|                   |   >,                     |
|                   |   country:string,        |
|                   |   postal_code:string     |
|                   | >                        |
+-------------------+--------------------------+
Thetop-levelcolumnEMPLOYEE_INFO isaSTRUCT.Describing table_name .struct_name displaysthefieldsofthe
STRUCTasiftheywerecolumnsofatable:
DESCRIBE struct_demo.employee_info;
+----------+--------+
| name     | type   |
+----------+--------+
| employer | string |
| id       | bigint |
| address  | string |
+----------+--------+
BecausePLACES_LIVED isaSTRUCTinsideanARRAY,theinitialDESCRIBE showsthestructureoftheARRAY:
DESCRIBE struct_demo.places_lived;
+------+------------------+
| name | type             |
+------+------------------+
| item | struct<          |
|      |   street:string, |
|      |   city:string,   |
|      |   country:string |
|      | >                |
| pos  | bigint           |
+------+------------------+
AskforthedetailsoftheITEMfieldoftheARRAYtoseejustthelayoutoftheSTRUCT:
DESCRIBE struct_demo.places_lived.item;
+---------+--------+
| name    | type   |
+---------+--------+
| street  | string |
| city    | string |
| country | string |
+---------+--------+
Likewise,MEMORABLE_MOMENTS hasaSTRUCTinsideaMAP,whichrequiresanextralevelofqualifiednametoseejust
theSTRUCTpart:
DESCRIBE struct_demo.memorable_moments;
+-------+------------------+
| name  | type             |
+-------+------------------+
| key   | string           |
| value | struct<          |
|       |   year:int,      |
|       |   place:string,  |
|       |   details:string |
|       | >                |
+-------+------------------+
ApacheImpalaGuide|127ImpalaSQLLanguageReference
ForaMAP,asktoseetheVALUEfieldtoseethecorresponding STRUCTfieldsinatable-likestructure:
DESCRIBE struct_demo.memorable_moments.value;
+---------+--------+
| name    | type   |
+---------+--------+
| year    | int    |
| place   | string |
| details | string |
+---------+--------+
ForaSTRUCTinsideaSTRUCT,wecanseethefieldsoftheouterSTRUCT:
DESCRIBE struct_demo.current_address;
+----------------+-----------------------+
| name           | type                  |
+----------------+-----------------------+
| street_address | struct<               |
|                |   street_number:int,  |
|                |   street_name:string, |
|                |   street_type:string  |
|                | >                     |
| country        | string                |
| postal_code    | string                |
+----------------+-----------------------+
Thenwecanuseafurtherqualified nametoseejustthefieldsoftheinnerSTRUCT:
DESCRIBE struct_demo.current_address.street_address;
+---------------+--------+
| name          | type   |
+---------------+--------+
| street_number | int    |
| street_name   | string |
| street_type   | string |
+---------------+--------+
ThefollowingexampleshowshowtoexaminethestructureofatablecontainingoneormoreSTRUCTcolumnsby
usingtheDESCRIBE statement.YoucanvisualizeeachSTRUCTasitsowntable,withcolumnsnamedthesameas
eachfieldoftheSTRUCT.IftheSTRUCTisnestedinsideanothercomplextype,suchasARRAY,youcanextendthe
qualified namepassedtoDESCRIBE untiltheoutputshowsjusttheSTRUCTfields.
DESCRIBE struct_demo;
+-------------------+--------------------------+---------+
| name              | type                     | comment |
+-------------------+--------------------------+---------+
| id                | bigint                   |         |
| name              | string                   |         |
| employee_info     | struct<                  |         |
|                   |   employer:string,       |         |
|                   |   id:bigint,             |         |
|                   |   address:string         |         |
|                   | >                        |         |
| places_lived      | array<struct<            |         |
|                   |   street:string,         |         |
|                   |   city:string,           |         |
|                   |   country:string         |         |
|                   | >>                       |         |
| memorable_moments | map<string,struct<       |         |
|                   |   year:int,              |         |
|                   |   place:string,          |         |
|                   |   details:string         |         |
|                   | >>                       |         |
| current_address   | struct<                  |         |
|                   |   street_address:struct< |         |
|                   |     street_number:int,   |         |
128|ApacheImpalaGuideImpalaSQLLanguageReference
|                   |     street_name:string,  |         |
|                   |     street_type:string   |         |
|                   |   >,                     |         |
|                   |   country:string,        |         |
|                   |   postal_code:string     |         |
|                   | >                        |         |
+-------------------+--------------------------+---------+
SELECT id, employee_info.id FROM struct_demo;
SELECT id, employee_info.id AS employee_id FROM struct_demo;
SELECT id, employee_info.id AS employee_id, employee_info.employer
  FROM struct_demo;
SELECT id, name, street, city, country
  FROM struct_demo, struct_demo.places_lived;
SELECT id, name, places_lived.pos, places_lived.street, places_lived.city, 
places_lived.country
  FROM struct_demo, struct_demo.places_lived;
SELECT id, name, pl.pos, pl.street, pl.city, pl.country
  FROM struct_demo, struct_demo.places_lived AS pl;
SELECT id, name, places_lived.pos, places_lived.street, places_lived.city, 
places_lived.country
  FROM struct_demo, struct_demo.places_lived;
SELECT id, name, pos, street, city, country
  FROM struct_demo, struct_demo.places_lived;
SELECT id, name, memorable_moments.key,
  memorable_moments.value.year,
  memorable_moments.value.place,
  memorable_moments.value.details
FROM struct_demo, struct_demo.memorable_moments
WHERE memorable_moments.key IN ('Birthday','Anniversary','Graduation');
SELECT id, name, mm.key, mm.value.year, mm.value.place, mm.value.details
  FROM struct_demo, struct_demo.memorable_moments AS mm
WHERE mm.key IN ('Birthday','Anniversary','Graduation');
SELECT id, name, memorable_moments.key, memorable_moments.value.year,
  memorable_moments.value.place, memorable_moments.value.details
FROM struct_demo, struct_demo.memorable_moments
WHERE key IN ('Birthday','Anniversary','Graduation');
SELECT id, name, key, value.year, value.place, value.details
  FROM struct_demo, struct_demo.memorable_moments
WHERE key IN ('Birthday','Anniversary','Graduation');
SELECT id, name, key, year, place, details
  FROM struct_demo, struct_demo.memorable_moments
WHERE key IN ('Birthday','Anniversary','Graduation');
SELECT id, name,
  current_address.street_address.street_number,
  current_address.street_address.street_name,
  current_address.street_address.street_type,
  current_address.country,
  current_address.postal_code
FROM struct_demo;
Forexample,thistableusesastructthatencodesseveraldatavaluesforeachphonenumberassociatedwithaperson.
Eachpersoncanhaveavariable-leng tharrayofassociatedphonenumbers,andqueriescanrefertothecategoryfield
tolocatespecifichome,work,mobile,andsoonkindsofphonenumbers.
CREATE TABLE contact_info_many_structs
(
  id BIGINT, name STRING,
ApacheImpalaGuide|129ImpalaSQLLanguageReference
  phone_numbers ARRAY < STRUCT <category:STRING, country_code:STRING, area_code:SMALLINT,
 full_number:STRING, mobile:BOOLEAN, carrier:STRING > >
) STORED AS PARQUET;
Becausestructsarenaturallysuitedtocompositevalueswherethefieldshavedifferentdatatypes,youmightuse
themtodecomposethingssuchasaddresses:
CREATE TABLE contact_info_detailed_address
(
  id BIGINT, name STRING,
  address STRUCT < house_number:INT, street:STRING, street_type:STRING, apartment:STRING,
 city:STRING, region:STRING, country:STRING >
);
Inabigdatacontext,splittingoutdatafieldssuchasthenumberpartoftheaddressandthestreetnamecouldlet
youdoanalysisoneachfieldindependen tly.Forexample,whichstreetshavethelargestnumberrangeofaddresses,
whatarethestatisticalpropertiesofthestreetnames,whichareashaveahigherproportion ofâRoadsâ,âCourtsâor
âBoulevardsâ,andsoon.
Relatedinformation:
ComplexTypes(CDH5.5orhigheronly)onpage139,ARRAYComplexType(CDH5.5orhigheronly)onpage102,MAP
ComplexType(CDH5.5orhigheronly)onpage118
TIMESTAMPDataType
InImpala,theTIMESTAMP datatypeholdsavalueofdateandtime.Itcanbedecomposed intoyear,month,day,hour,
minuteandsecondsfields,butwithnotimezoneinformationavailable,itdoesnotcorrespondtoanyspecificpoint
intime.
Internally,theresolution ofthetimeportionofaTIMESTAMP valueisinnanoseconds.
Syntax:
InthecolumndefinitionofaCREATE TABLE statement:
column_name  TIMESTAMP
timestamp  [+ | -] INTERVAL interval
DATE_ADD ( timestamp , INTERVAL interval time_unit )
Range:1400-01-01 to9999-12-31
OutofrangeTIMESTAMP valuesareconvertedtoNULL.
TherangeofImpalaTIMESTAMP isdifferentfromtheHiveTIMESTAMP type.RefertoHivedocumen tationfordetail.
INTERVALexpressions:
Youcanperformdatearithmeticbyaddingorsubtractingaspecified numberoftimeunits,usingtheINTERVAL
keywordandthe+operator,the-operator,date_add() ordate_sub() .
Thefollowingunitsaresupportedfortime_unit intheINTERVAL clause:
â¢YEAR[S]
â¢MONTH[S]
â¢WEEK[S]
â¢DAY[S]
â¢HOUR[S]
â¢MINUTE[S]
â¢SECOND[S]
130|ApacheImpalaGuideImpalaSQLLanguageReference
â¢MILLISECOND[S]
â¢MICROSECOND[S]
â¢NANOSECOND[S]
Youcanonlyspecifyonetimeunitineachintervalexpression,forexampleINTERVAL 3 DAYS orINTERVAL 25
HOURS,butyoucanproduceanygranularitybyaddingtogethersuccessiveINTERVAL values,suchastimestamp_value
+ INTERVAL 3 WEEKS - INTERVAL 1 DAY + INTERVAL 10 MICROSECONDS .
Internaldetails:Representedinmemoryasa16-bytevalue.
Timezones:
Bydefault,ImpalastoresandinterpretsTIMESTAMP valuesinUTCtimezonewhenwritingtodatafiles,readingfrom
datafiles,orconvertingtoandfromsystemtimevaluesthroughfunctions.
Whenyousetthe--use_local_tz_for_unix_timestamp_conversions startupflagtoTRUE,Impalatreatsthe
TIMESTAMP valuesspecified inthelocaltimezone.Thelocaltimezoneisdeterminedinthefollowingorderwiththe
TIMESTAMP queryoptiontakesthehighestprecedence:
1.TheTIMESTAMP queryoption
2.$TZenvironmentvariable
3.Systemtimezonewheretheimpaladcoordinatorruns
The--use_local_tz_for_unix_timestamp_conversions settingcanbeusedtofixdiscrepancyinINTERVAL
operations.Forexample,aTIMESTAMP + INTERVAL n-hours canbeaffectedbyDaylightSavingTime,whichImpala
doesnotconsiderbydefaultastheseoperationsareappliedasifthetimestampwasinUTC.Youcanusethe
--use_local_tz_for_unix_timestamp_conversions settingtofixtheissue.
SeeCustomizingTimeZonesonpage135forconfiguringtousecustomtimezonedatabaseandaliases.
SeeImpalaDateandTimeFunctions forthelistoffunctions affectedbythe
--use_local_tz_for_unix_timestamp_conversions setting.
Timezonehandling betweenImpalaandHive:
InteroperabilitybetweenHiveandImpalaisdifferentdepending onthefileformat.
â¢Text
Fortexttables,TIMESTAMP valuescanbewrittenandreadinterchangeablybyImpalaandHiveasHivereadsand
writesTIMESTAMP valueswithoutconvertingwithrespecttotimezones.
â¢Parquet
Note:ThissectiononlyappliestoINT96 TIMESTAMP .SeeDataTypeConsiderationsforParquet
Tablesonpage655forinformationaboutParquetdatatypes.
WhenHivewritestoParquetdatafiles,theTIMESTAMP valuesarenormalizedtoUTCfromthelocaltimezone
ofthehostwherethedatawaswritten.Ontheotherhand,Impaladoesnotmakeanytimezoneadjustment
whenitwritesorreadsINT96 TIMESTAMP valuestoParquetfiles.Thisdifferenceintimezonehandlingcancause
potentiallyinconsistentresultswhenImpalaprocessesTIMESTAMP valuesintheParquetfileswrittenbyHive.
Toavoidincompatibilityproblemsorhavingtocodeworkarounds,youcanspecifyoneorbothoftheseimpalad
startupflags:
â¢--use_local_tz_for_unix_timestamp_conversions=true
â¢--convert_legacy_hive_parquet_utc_timestamps=true
Whenthe--convert_legacy_hive_parquet_utc_timestamps settingisenabled, Impalarecognizesthe
ParquetdatafileswrittenbyHive,andappliesthesameUTC-to-local-timezoneconversionlogicduringthequery
asHivedoes.
InCDH6.0/Impala3.0andlower,the--convert_legacy_hive_parquet_utc_timestamps settinghada
severeimpactonmulti-threadedperformance. Thenewtimezoneimplemen tationinCDH6.1eliminatedmost
ApacheImpalaGuide|131ImpalaSQLLanguageReference
oftheperformance overheadandmadeImpalascalewelltomultiplethreads.The
--convert_legacy_hive_parquet_utc_timestamps settingisturnedoffbydefaultforaperformance
reason.Toavoidunexpectedincompatibilityproblems,youshouldturnontheoptionwhenprocessingTIMESTAMP
columnsinParquetfileswrittenbyHive.
HivecurrentlycannotwriteINT64TIMESTAMP values.
InCDH6.2andhigher,INT64 TIMESTAMP valuesannotatedwiththeTIMESTAMP_MILLIS orTIMESTAMP_MICROS
OriginalType areassumed tobealwaysUTCnormalized,sotheUTCtolocalconversionwillbealwaysdone.
INT64 TIMESTAMP annotatedwiththeTIMESTAMP LogicalType specifieswhetherUTCtolocalconversionis
necessarydepending ontheParquetmetadata.
Conversions:
ImpalaautomaticallyconvertsSTRINGliteralsofthecorrectformatintoTIMESTAMP values.Timestampvaluesare
acceptedintheformat'yyyy-MM-dd HH:mm:ss.SSSSSS' ,andcanconsistofjustthedate,orjustthetime,with
orwithoutthefractionalsecondportion.Forexample,youcanspecifyTIMESTAMP valuessuchas'1966-07-30' ,
'08:30:00' ,or'1985-09-25 17:45:30.005' .
Leadingzeroesarenotrequiredinthenumbersrepresentingthedatecomponen t,suchasmonthanddate,orthe
timecomponen t,suchashour,minute,andsecond.Forexample,Impalaacceptsboth'2018-1-1 01:02:03' and
'2018-01-01 1:2:3' asvalid.
InSTRINGtoTIMESTAMP conversions,leadingandtrailingwhitespaces,suchasaspace,atab,anewline,oracarriage
return,areignored.Forexample,Impalatreatsthefollowingasequivalent:'1999-12-01 01:02:03','1999-12-01 01:02:03',
'1999-12-01 01:02:03\r\n\t'.
WhenyouconvertorcastaSTRINGliteraltoTIMESTAMP ,youcanusethefollowingseparatorsbetweenthedatepart
andthetimepart:
â¢Oneormorespacecharacters
Example:CAST('2001-01-09 01:05:01' AS TIMESTAMP)
â¢ThecharacterâTâ
Example:CAST('2001-01-09T01:05:01' AS TIMESTAMP)
Castinganintegerorfloating-pointvalueNtoTIMESTAMP producesavaluethatisNsecondspastthestartofthe
epochdate(January1,1970).Bydefault,theresultvaluerepresentsadateandtimeintheUTCtimezone.Ifthesetting
--use_local_tz_for_unix_timestamp_conversions=true isineffect,theresultingTIMESTAMP representsa
dateandtimeinthelocaltimezone.
InImpala1.3andhigher,theFROM_UNIXTIME() andUNIX_TIMESTAMP() functions allowawiderrangeofformat
strings,withmoreflexibilityinelementorder,repetitionofletterplaceholder s,andseparatorcharacters.InCDH5.5
/Impala2.3andhigher,theUNIX_TIMESTAMP() functionalsoallowsanumerictimezoneoffsettobespecified as
partoftheinputstring.SeeImpalaDateandTimeFunctions onpage424fordetails.
InImpala2.2.0andhigher,built-infunctions thatacceptorreturnintegersrepresentingTIMESTAMP valuesusethe
BIGINTtypeforparametersandreturnvalues,ratherthanINT.Thischangeletsthedateandtimefunctions avoid
anoverflowerrorthatwouldotherwiseoccuronJanuary19th,2038(knownastheâYear2038problemâorâY2K38
problemâ).ThischangeaffectstheFROM_UNIXTIME() andUNIX_TIMESTAMP() functions. Youmightneedtochange
applicationcodethatinteractswiththesefunctions, changethetypesofcolumnsthatstorethereturnvalues,oradd
CAST()callstoSQLstatementsthatcallthesefunctions.
Partitioning:
Although youcannotuseaTIMESTAMP columnasapartition key,youcanextracttheindividual years,months,days,
hours,andsoonandpartition basedonthosecolumns.Becausethepartition keycolumnvaluesarerepresentedin
HDFSdirectorynames,ratherthanasfieldsinthedatafilesthemselves,youcanalsokeeptheoriginalTIMESTAMP
132|ApacheImpalaGuideImpalaSQLLanguageReference
valuesifdesired,withoutduplicatingdataorwastingstoragespace.SeePartitionKeyColumns onpage630formore
detailsonpartitioning withdateandtimevalues.
[localhost:21000] > create table timeline (event string) partitioned by (happened 
timestamp);
ERROR: AnalysisException: Type 'TIMESTAMP' is not supported as partition-column type in
 column: happened
NULLconsiderations:CastinganyunrecognizedSTRINGvaluetothistypeproducesaNULLvalue.
HBaseconsiderations:ThisdatatypeisfullycompatiblewithHBasetables.
Parquetconsideration:INT96encodedParquettimestampsaresupportedinImpala.INT64timestampsaresupported
inCDH6.2andhigher.
Parquetconsiderations:ThistypeisfullycompatiblewithParquettables.
Texttableconsiderations:ValuesofthistypearepotentiallylargerintexttablesthanintablesusingParquetorother
binaryformats.
Columnstatisticsconsiderations:Becausethistypehasafixedsize,themaximumandaveragesizefieldsarealways
filledinforcolumnstatistics,evenbeforeyouruntheCOMPUTE STATS statement.
Kuduconsiderations:
InCDH5.12/Impala2.9andhigher,youcanincludeTIMESTAMP columnsinKudutables,insteadofrepresentingthe
dateandtimeasaBIGINTvalue.ThebehaviorofTIMESTAMP forKudutableshassomespecialconsiderations:
â¢Anynanosecondsintheoriginal96-bitvalueproducedbyImpalaarenotstored,becauseKudurepresentsdate/time
columnsusing64-bitvalues.Thenanosecondportionofthevalueisrounded,nottruncated.Therefore,a
TIMESTAMP valuethatyoustoreinaKudutablemightnotbebit-for-bitidenticaltothevaluereturnedbyaquery.
â¢TheconversionbetweentheImpala96-bitrepresentationandtheKudu64-bitrepresentationintroducessome
performance overheadwhenreadingorwritingTIMESTAMP columns.Youcanminimizetheoverheadduring
writesbyperforminginsertsthroughtheKuduAPI.Becausetheoverheadduringreadsappliestoeachquery,you
mightcontinuetouseaBIGINTcolumntorepresentdate/timevaluesinperformance-critic alapplications.
â¢TheImpalaTIMESTAMP typehasanarrowerrangeforyearsthantheunderlying Kududatatype.Impalacan
representyears1400-9999. IfyearvaluesoutsidethisrangearewrittentoaKudutablebyanon-Impala client,
ImpalareturnsNULLbydefaultwhenreadingthoseTIMESTAMP valuesduringaquery.Or,iftheABORT_ON_ERROR
queryoptionisenabled, thequeryfailswhenitencountersavaluewithanout-of-rangeyear.
Restrictions:
IfyoucastaSTRINGwithanunrecognizedformattoaTIMESTAMP ,theresultisNULLratherthananerror.Makesure
totestyourdatapipelinetobesureanytextualdateandtimevaluesareinaformatthatImpalaTIMESTAMP can
recognize.
Currently,AvrotablescannotcontainTIMESTAMP columns.IfyouneedtostoredateandtimevaluesinAvrotables,
asaworkaroundyoucanuseaSTRINGrepresentationofthevalues,convertthevaluestoBIGINTwiththe
UNIX_TIMESTAMP() function, orcreateseparatenumericcolumnsforindividual dateandtimefieldsusingthe
EXTRACT() function.
Examples:
ThefollowingexamplesdemonstrateusingTIMESTAMP valueswithbuilt-infunctions:
select cast('1966-07-30' as timestamp);
select cast('1985-09-25 17:45:30.005' as timestamp);
select cast('08:30:00' as timestamp);
select hour('1970-01-01 15:30:00');         -- Succeeds, returns 15.
select hour('1970-01-01 15:30');            -- Returns NULL because seconds field 
required.
select hour('1970-01-01 27:30:00');         -- Returns NULL because hour value out of 
range.
ApacheImpalaGuide|133ImpalaSQLLanguageReference
select dayofweek('2004-06-13');             -- Returns 1, representing Sunday.
select dayname('2004-06-13');               -- Returns 'Sunday'.
select date_add('2004-06-13', 365);         -- Returns 2005-06-13 with zeros for hh:mm:ss
 fields.
select day('2004-06-13');                   -- Returns 13.
select datediff('1989-12-31','1984-09-01'); -- How many days between these 2 dates?
select now();                               -- Returns current date and time in local 
timezone.
ThefollowingexamplesdemonstrateusingTIMESTAMP valueswithHDFS-backedtables:
create table dates_and_times (t timestamp);
insert into dates_and_times values
  ('1966-07-30'), ('1985-09-25 17:45:30.005'), ('08:30:00'), (now());
ThefollowingexamplesdemonstrateusingTIMESTAMP valueswithKudutables:
create table timestamp_t (x int primary key, s string, t timestamp, b bigint)
  partition by hash (x) partitions 16
  stored as kudu;
-- The default value of now() has microsecond precision, so the final 3 digits
-- representing nanoseconds are all zero.
insert into timestamp_t values (1, cast(now() as string), now(), unix_timestamp(now()));
-- Values with 1-499 nanoseconds are rounded down in the Kudu TIMESTAMP column.
insert into timestamp_t values (2, cast(now() + interval 100 nanoseconds as string), 
now() + interval 100 nanoseconds, unix_timestamp(now() + interval 100 nanoseconds));
insert into timestamp_t values (3, cast(now() + interval 499 nanoseconds as string), 
now() + interval 499 nanoseconds, unix_timestamp(now() + interval 499 nanoseconds));
-- Values with 500-999 nanoseconds are rounded up in the Kudu TIMESTAMP column.
insert into timestamp_t values (4, cast(now() + interval 500 nanoseconds as string), 
now() + interval 500 nanoseconds, unix_timestamp(now() + interval 500 nanoseconds));
insert into timestamp_t values (5, cast(now() + interval 501 nanoseconds as string), 
now() + interval 501 nanoseconds, unix_timestamp(now() + interval 501 nanoseconds));
-- The string representation shows how underlying Impala TIMESTAMP can have nanosecond
 precision.
-- The TIMESTAMP column shows how timestamps in a Kudu table are rounded to microsecond
 precision.
-- The BIGINT column represents seconds past the epoch and so if not affected much by 
nanoseconds.
select s, t, b from timestamp_t order by t;
+-------------------------------+-------------------------------+------------+
| s                             | t                             | b          |
+-------------------------------+-------------------------------+------------+
| 2017-05-31 15:30:05.107157000 | 2017-05-31 15:30:05.107157000 | 1496244605 |
| 2017-05-31 15:30:28.868151100 | 2017-05-31 15:30:28.868151000 | 1496244628 |
| 2017-05-31 15:34:33.674692499 | 2017-05-31 15:34:33.674692000 | 1496244873 |
| 2017-05-31 15:35:04.769166500 | 2017-05-31 15:35:04.769167000 | 1496244904 |
| 2017-05-31 15:35:33.033082501 | 2017-05-31 15:35:33.033083000 | 1496244933 |
+-------------------------------+-------------------------------+------------+
Addedin:AvailableinallversionsofImpala.
Relatedinformation:
â¢TimestampLiteralsonpage169.
â¢Toconverttoorfromdifferentdateformats,orperformdatearithmetic,usethedateandtimefunctions described
inImpalaDateandTimeFunctions onpage424.Inparticular ,thefrom_unixtime() functionrequiresa
case-sensitiv eformatstringsuchas"yyyy-MM-dd HH:mm:ss.SSSS" ,matchingoneoftheallowedvariations
ofaTIMESTAMP value(dateplustime,onlydate,onlytime,optionalfractionalseconds).
â¢SeeSQLDifferencesBetweenImpalaandHiveonpage541fordetailsaboutdifferencesinTIMESTAMP handling
betweenImpalaandHive.
134|ApacheImpalaGuideImpalaSQLLanguageReference
CustomizingTimeZones
StartinginCDH6.1/Impala3.1,youcancustomizethetimezonedefinitionsusedinImpala.
â¢Bydefault,ImpalausestheOSâstimezonedatabaselocatedin/usr/share/zoneinfo .Thisdirectorycontains
theIANAtimezonedatabaseinacompiledbinaryformat.Thecontentsofthezoneinfo directoryiscontrolled
bytheOSâspackagemanager.
â¢Usethefollowingstart-upflagsmanagedasimpalad safetyvalvesinClouderaManager.
â--hdfs_zone_info_zip :ThisflagallowsImpalaadministratorstospecifyacustomtimezonedatabase.
Theflagshouldbesettoashared(notnecessarily HDFS)paththatpointstoaziparchiveofacustomIANA
timezonedatabase.Thetimezonedatabaseisexpectedtobeinacompiledbinaryformat.Ifthestartupflag
isset,Impalawillusethespecified timezonedatabaseinsteadofthedefault/usr/share/zoneinfo
database.Thetimezonedbupgradeprocessisdescribed indetailbelow.
â--hdfs_zone_alias_conf :ThisflagallowsImpalaadministratorstospecifydefinitionsforcustomtimezone
aliases.Theflagshouldbesettoashared(notnecessarily HDFS)paththatspecifiesaconfigfilecontaining
customtimezonealiasdefinitions. Thisconfigfilecanbeusedasaworkaroundforuserswhowanttokeep
usingtheirlegacytimezonenames.Configuringcustomaliasesisdescribed indetailbelow.
UpgradingcustomIANAtimezonedatabase:
1.DownloadlatestIANAtimezonedatabasedistribution:
git clone https://github.com/eggert/tz
Alternatively,downloadaspecifictzdbversionfrom:
 https://www.iana.org/time-zones/repository
2.Buildtimezonetools:
cd tz
make TOPDIR=tzdata install
3.Generatethecompiledbinarytimezonedatabase:
./zic -d ./tzdata/etc/zoneinfo africa antarctica asia australasia backward backzone 
etcetera europe factory northamerica pacificnew southamerica systemv
4.Createziparchive:
pushd ./tzdata/etc
zip -r zoneinfo.zip zoneinfo
popd
5.CopythetimezonedatabasetoHDFS:
hdfs dfs -mkdir -p /tzdb/latest
hdfs dfs -copyFromLocal ./tzdata/etc/zoneinfo.zip /tzdb/latest
6.Setthe--hdfs_zone_info_zip startupflagto/tzdb/latest/zoneinfo.zip asanimpalad safetyvalve.
7.PerformafullrestartofImpalaservice.
Configuringcustomtimezonealiases:
1.Createatzalias.conf configfilethatcontainstimezonealiasdefinitionsformattedasALIAS = DEFINITION .
Forexample:
#
# Define aliases for existing timezone names:
ApacheImpalaGuide|135ImpalaSQLLanguageReference
#
Universal Coordinated Time = UTC
Mideast/Riyadh89 = Asia/Riyadh
PDT = America/Los_Angeles
#
# Define aliases as UTC offsets in seconds:
#
GMT-01:00 = 3600
GMT+01:00 = -3600
2.CopytheconfigfiletoHDFS:
hdfs dfs -mkdir -p /tzdb
hdfs dfs -copyFromLocal tzalias.conf /tzdb
3.Setthe--hdfs_zone_alias_conf startupflagto/tzdb/tzalias.conf asanimpalad safetyvalve.
4.PerformafullrestartofImpalaservice.
Addedin:CDH6.1/Impala3.1
TINYINTDataType
A1-byteintegerdatatypeusedinCREATE TABLE andALTER TABLE statements.
Syntax:
InthecolumndefinitionofaCREATE TABLE statement:
column_name  TINYINT
Range:-128..127.ThereisnoUNSIGNED subtype.
Conversions:Impalaautomaticallyconvertstoalargerintegertype(SMALLINT ,INT,orBIGINT)orafloating-point
type(FLOATorDOUBLE)automatically.UseCAST()toconverttoSTRINGorTIMESTAMP .Castinganintegeror
floating-pointvalueNtoTIMESTAMP producesavaluethatisNsecondspastthestartoftheepochdate(January1,
1970).Bydefault,theresultvaluerepresentsadateandtimeintheUTCtimezone.Ifthesetting
--use_local_tz_for_unix_timestamp_conversions=true isineffect,theresultingTIMESTAMP representsa
dateandtimeinthelocaltimezone.
ImpaladoesnotreturncolumnoverflowsasNULL,sothatcustomerscandistinguishbetweenNULLdataandoverflow
conditions similartohowtheydosowithtraditional databasesystems.Impalareturnsthelargestorsmallestvaluein
therangeforthetype.Forexample,validvaluesforatinyint rangefrom-128to127.InImpala,atinyint witha
valueof-200returns-128ratherthanNULL.Atinyint withavalueof200returns127.
Usagenotes:
ForaconvenientandautomatedwaytochecktheboundsoftheTINYINT type,callthefunctionsMIN_TINYINT()
andMAX_TINYINT() .
IfanintegervalueistoolargetoberepresentedasaTINYINT ,useaSMALLINT instead.
NULLconsiderations:Castinganynon-numeric valuetothistypeproducesaNULLvalue.
Examples:
CREATE TABLE t1 (x TINYINT);
SELECT CAST(100 AS TINYINT);
Parquetconsiderations:
Physically,ParquetfilesrepresentTINYINT andSMALLINT valuesas32-bitintegers.Although Impalarejectsattempts
toinsertout-of-rangevaluesintosuchcolumns,ifyoucreateanewtablewiththeCREATE TABLE ... LIKE PARQUET
syntax,anyTINYINT orSMALLINT columnsintheoriginaltableturnintoINTcolumnsinthenewtable.
HBaseconsiderations:ThisdatatypeisfullycompatiblewithHBasetables.
136|ApacheImpalaGuideImpalaSQLLanguageReference
Texttableconsiderations:ValuesofthistypearepotentiallylargerintexttablesthanintablesusingParquetorother
binaryformats.
Internaldetails:Representedinmemoryasa1-bytevalue.
Addedin:AvailableinallversionsofImpala.
Columnstatisticsconsiderations:Becausethistypehasafixedsize,themaximumandaveragesizefieldsarealways
filledinforcolumnstatistics,evenbeforeyouruntheCOMPUTE STATS statement.
Relatedinformation:
NumericLiteralsonpage167,TINYINTDataTypeonpage136,SMALLINT DataTypeonpage122,INTDataTypeonpage
117,BIGINTDataTypeonpage105,DECIMALDataType(CDH6.0/Impala3.0orhigheronly)onpage109,Impala
MathematicalFunctions onpage397
VARCHARDataType(CDH5.2orhigheronly)
Avariable-leng thcharactertype,truncatedduringprocessingifnecessarytofitwithinthespecified length.
Syntax:
InthecolumndefinitionofaCREATE TABLE statement:
column_name  VARCHAR( max_length )
Themaximumlengthyoucanspecifyis65,535.
Partitioning: Thistypecanbeusedforpartition keycolumns.Becauseoftheefficiencyadvantageofnumericvalues
overcharacter-based values,ifthepartition keyisastringrepresentationofanumber,prefertouseanintegertype
withsufficientrange(INT,BIGINT,andsoon)wherepractical.
HBaseconsiderations:ThisdatatypecannotbeusedwithHBasetables.
Parquetconsiderations:
â¢ThistypecanbereadfromandwrittentoParquetfiles.
â¢Thereisnorequirementforaparticular levelofParquet.
â¢ParquetfilesgeneratedbyImpalaandcontainingthistypecanbefreelyinterchangedwithothercomponen ts
suchasHiveandMapReduce.
â¢ParquetdatafilescancontainvaluesthatarelongerthanallowedbytheVARCHAR( n)lengthlimit.Impalaignores
anyextratrailingcharacterswhenitprocessesthosevaluesduringaquery.
Texttableconsiderations:
TextdatafilescancontainvaluesthatarelongerthanallowedbytheVARCHAR( n)lengthlimit.Anyextratrailing
charactersareignoredwhenImpalaprocessesthosevaluesduringaquery.
Avroconsiderations:
TheAvrospecificationallowsstringvaluesupto2**64bytesinlength.ImpalaqueriesforAvrotablesuse32-bitintegers
toholdstringlengths.InCDH5.7/Impala2.5andhigher,ImpalatruncatesCHARandVARCHAR valuesinAvrotables
to(2**31)-1 bytes.IfaqueryencountersaSTRINGvaluelongerthan(2**31)-1 bytesinanAvrotable,thequeryfails.
Inearlierreleases,encounteringsuchlongvaluesinanAvrotablecouldcauseacrash.
Schemaevolutionconsiderations:
YoucanuseALTER TABLE ... CHANGE toswitchcolumndatatypestoandfromVARCHAR .Youcanconvertfrom
STRINGtoVARCHAR( n),orfromVARCHAR( n)toSTRING,orfromCHAR(n)toVARCHAR( n),orfromVARCHAR( n)
toCHAR(n).WhenswitchingbackandforthbetweenVARCHAR andCHAR,youcanalsochangethelengthvalue.This
schemaevolutionworksthesamefortablesusinganyfileformat.Ifatablecontainsvalueslongerthanthemaximum
lengthdefinedforaVARCHAR column,Impaladoesnotreturnanerror.Anyextratrailingcharactersareignoredwhen
Impalaprocessesthosevaluesduringaquery.
Compatibility:
ApacheImpalaGuide|137ImpalaSQLLanguageReference
ThistypeisavailableinCDH5.2/Impala2.0orhigher.
Internaldetails:Representedinmemoryasabytearraywiththeminimum sizeneededtorepresenteachvalue.
Addedin:CDH5.2.0/Impala2.0.0
Columnstatisticsconsiderations:Becausethevaluesofthistypehavevariablesize,noneofthecolumnstatisticsfields
arefilledinuntilyouruntheCOMPUTE STATS statement.
Kuduconsiderations:
Currently,thedatatypesCHAR,VARCHAR ,ARRAY,MAP,andSTRUCTcannotbeusedwithKudutables.
Restrictions:
AlldatainCHARandVARCHAR columnsmustbeinacharacterencodingthatiscompatiblewithUTF-8.Ifyouhave
binarydatafromanotherdatabasesystem(thatis,aBLOBtype),useaSTRINGcolumntoholdit.
Examples:
ThefollowingexamplesshowhowlongandshortVARCHAR valuesaretreated.Valueslongerthanthemaximum
specified lengtharetruncatedbyCAST(),orwhenqueriedfromexistingdatafiles.Valuesshorterthanthemaximum
specified lengtharerepresentedastheactuallengthofthevalue,withnoextrapaddingasseenwithCHARvalues.
create table varchar_1 (s varchar(1));
create table varchar_4 (s varchar(4));
create table varchar_20 (s varchar(20));
insert into varchar_1 values (cast('a' as varchar(1))), (cast('b' as varchar(1))), 
(cast('hello' as varchar(1))), (cast('world' as varchar(1)));
insert into varchar_4 values (cast('a' as varchar(4))), (cast('b' as varchar(4))), 
(cast('hello' as varchar(4))), (cast('world' as varchar(4)));
insert into varchar_20 values (cast('a' as varchar(20))), (cast('b' as varchar(20))), 
(cast('hello' as varchar(20))), (cast('world' as varchar(20)));
select * from varchar_1;
+---+
| s |
+---+
| a |
| b |
| h |
| w |
+---+
select * from varchar_4;
+------+
| s    |
+------+
| a    |
| b    |
| hell |
| worl |
+------+
[localhost:21000] > select * from varchar_20;
+-------+
| s     |
+-------+
| a     |
| b     |
| hello |
| world |
+-------+
select concat('[',s,']') as s from varchar_20;
+---------+
| s       |
+---------+
| [a]     |
| [b]     |
| [hello] |
| [world] |
+---------+
138|ApacheImpalaGuideImpalaSQLLanguageReference
ThefollowingexampleshowshowidenticalVARCHAR valuescompareasequal,evenifthecolumnsaredefinedwith
differentmaximumlengths.Bothtablescontain'a'and'b'values.Thelonger'hello' and'world' valuesfrom
theVARCHAR_20 tableweretruncatedwheninsertedintotheVARCHAR_1 table.
select s from varchar_1 join varchar_20 using (s);
+-------+
| s     |
+-------+
| a     |
| b     |
+-------+
ThefollowingexamplesshowhowVARCHAR valuesarefreelyinterchangeablewithSTRINGvaluesincontextssuch
ascomparison operatorsandbuilt-infunctions:
select length(cast('foo' as varchar(100))) as length;
+--------+
| length |
+--------+
| 3      |
+--------+
select cast('xyz' as varchar(5)) > cast('abc' as varchar(10)) as greater;
+---------+
| greater |
+---------+
| true    |
+---------+
UDFconsiderations:Thistypecannotbeusedfortheargumentorreturntypeofauser-definedfunction(UDF)or
user-definedaggregatefunction(UDA).
Relatedinformation:
STRINGDataTypeonpage123,CHARDataType(CDH5.2orhigheronly)onpage107,StringLiteralsonpage168,Impala
StringFunctions onpage462
ComplexTypes(CDH5.5orhigheronly)
Complextypes(alsoreferredtoasnestedtypes)letyourepresentmultipledatavalueswithinasinglerow/column
position. TheydifferfromthefamiliarcolumntypessuchasBIGINTandSTRING,knownasscalartypesorprimitive
types,whichrepresentasingledatavaluewithinagivenrow/columnposition. Impalasupports thecomplextypes
ARRAY,MAP,andSTRUCTinCDH5.5/Impala2.3andhigher.TheHiveUNIONtypeisnotcurrentlysupported.
Onceyouunderstandthebasicsofcomplextypes,refertotheindividual typetopicswhenyouneedtorefreshyour
memoryaboutsyntaxandexamples:
â¢ARRAYComplexType(CDH5.5orhigheronly)onpage102
â¢STRUCTComplexType(CDH5.5orhigheronly)onpage124
â¢MAPComplexType(CDH5.5orhigheronly)onpage118
BenefitsofImpalaComplexTypes
ThereasonsforusingImpalacomplextypesincludethefollowing:
â¢YoualreadyhavedataproducedbyHiveorothernon-Impala componen tthatusesthecomplextypecolumn
names.Youmightneedtoconverttheunderlying datatoParquettouseitwithImpala.
â¢Yourdatamodeloriginateswithanon-SQLprogramminglanguageoraNoSQLdatamanagementsystem.For
example,ifyouarerepresentingPythondataexpressedasnestedlists,dictionaries, andtuples,thosedata
structurescorrespondcloselytoImpalaARRAY,MAP,andSTRUCTtypes.
â¢Youranalyticqueriesinvolvingmultipletablescouldbenefitfromgreaterlocalityduringjoinprocessing. Bypacking
morerelateddataitemswithineachHDFSdatablock,complextypesletjoinqueriesavoidthenetworkoverhead
ofthetraditional Hadoopshuffleorbroadcastjointechniques.
ApacheImpalaGuide|139ImpalaSQLLanguageReference
TheImpalacomplextypesupportproducesresultsetswithallscalarvalues,andthescalarcomponen tsofcomplex
typescanbeusedwithallSQLclauses,suchasGROUP BY ,ORDER BY ,allkindsofjoins,subqueries, andinlineviews.
TheabilitytoprocesscomplextypedataentirelyinSQLreducestheneedtowriteapplication-specific codeinJavaor
otherprogramminglanguagestodeconstructtheunderlying datastructures.
OverviewofImpalaComplexTypes
TheARRAYandMAPtypesarecloselyrelated:theyrepresentcollections witharbitrarynumbersofelements,where
eachelementisthesametype.Incontrast,STRUCTgroupstogetherafixednumberofitemsintoasingleelement.
ThepartsofaSTRUCTelement(thefields)canbeofdifferenttypes,andeachfieldhasaname.
TheelementsofanARRAYorMAP,orthefieldsofaSTRUCT,canalsobeothercomplextypes.Youcanconstruct
elaboratedatastructureswithupto100levelsofnesting.Forexample,youcanmakeanARRAYwhoseelementsare
STRUCTs.WithineachSTRUCT,youcanhavesomefieldsthatareARRAY,MAP,oranotherkindofSTRUCT.TheImpala
documen tationusesthetermscomplexandnestedtypesinterchangeably;forsimplicity ,itprimarily usestheterm
complextypes,toencompassallthepropertiesofthesetypes.
Whenvisualizing yourdatamodelinfamiliarSQLterms,youcanthinkofeachARRAYorMAPasaminiaturetable,and
eachSTRUCTasarowwithinsuchatable.Bydefault,thetablerepresentedbyanARRAYhastwocolumns,POSto
representorderingofelements,andITEMrepresentingthevalueofeachelement.Likewise,bydefault,thetable
representedbyaMAPencodeskey-valuepairs,andthereforehastwocolumns,KEYandVALUE.
TheITEMandVALUEnamesareonlyrequiredfortheverysimplestkindsofARRAYandMAPcolumns,onesthathold
onlyscalarvalues.WhentheelementswithintheARRAYorMAPareoftypeSTRUCTratherthanascalartype,thenthe
resultsetcontainscolumnswithnamescorresponding totheSTRUCTfieldsratherthanITEMorVALUE.
Youwritemostqueriesthatprocesscomplextypecolumnsusingfamiliarjoinsyntax,eventhoughthedataforboth
sidesofthejoinresidesinasingletable.Thejoinnotationbringstogetherthescalarvaluesfromarowwiththevalues
fromthecomplextypecolumnsforthatsamerow.Thefinalresultsetcontainsallscalarvalues,allowingyoutodoall
thefamiliarfiltering,aggregation,ordering,andsoonforthecomplexdataentirelyinSQLorusingbusinessintelligence
toolsthatissueSQLqueries.
Behindthescenes,Impalaensuresthattheprocessingforeachrowisdoneefficientlyonasinglehost,withoutthe
networktrafficinvolvedinbroadcastorshufflejoins.Themostcommontypeofjoinqueryfortableswithcomplex
typecolumnsisINNER JOIN ,whichreturnsresultsonlyinthosecaseswherethecomplextypecontainssomeelements.
Therefore,mostqueryexamplesinthissectionuseeithertheINNER JOIN clauseortheequivalentcommanotation.
Note:
Although ImpalacanquerycomplextypesthatarepresentinParquetfiles,Impalacurrentlycannot
createnewParquetfilescontainingcomplextypes.Therefore,thediscussion andexamplespresume
thatyouareworkingwithexistingParquetdataproducedthroughHive,Spark,orsomeothersource.
SeeConstructingParquetFileswithComplexColumns UsingHiveonpage162forexamplesof
constructingParquetdatafileswithcomplextypecolumns.
Forlearningpurposes, youcancreateemptytableswithcomplextypecolumnsandpracticequery
syntax,evenifyoudonothavesampledatawiththerequiredstructure.
DesignConsiderationsforComplexTypes
WhenplanningtouseImpalacomplextypes,anddesigning theImpalaschema,firstlearnhowthiskindofschema
differsfromtraditional tablelayoutsfromtherelationaldatabaseanddatawarehousing fields.Becauseyoumight
havealreadyencounteredcomplextypesinaHadoopcontextwhileusingHiveforETL,alsolearnhowtowrite
high-performance analyticqueriesforcomplextypedatausingImpalaSQLsyntax.
HowComplexTypesDifferfromTraditional DataWarehouseSchemas
Complextypesletyouassociatearbitrarydatastructureswithaparticular row.Ifyouarefamiliarwithschemadesign
forrelationaldatabasemanagementsystemsordatawarehouses, aschemawithcomplextypeshasthefollowing
differences:
140|ApacheImpalaGuideImpalaSQLLanguageReference
â¢Logically,relatedvaluescannowbegroupedtightlytogetherinthesametable.
Intraditional datawarehousing,relatedvaluesweretypicallyarrangedinoneoftwoways:
âSplitacrossmultiplenormalizedtables.Foreignkeycolumnsspecified whichrowsfromeachtablewere
associatedwitheachother.Thisarrangementavoidedduplicatedataandthereforethedatawascompact,
butjoinqueriescouldbeexpensivebecausetherelateddatahadtoberetrievedfromseparatelocations.
(InthecaseofdistributedHadoopqueries,thejoinedtablesmightevenbetransmittedbetweendifferent
hostsinacluster.)
âFlattenedintoasingledenormaliz edtable.Although thislayouteliminatedsomepotentialperformance
issuesbyremovingtheneedforjoinqueries,thetabletypicallybecamelargerbecausevalueswererepeated.
Theextradatavolumecouldcauseperformance issuesinotherpartsoftheworkflow,suchaslongerETL
cyclesormoreexpensivefull-tablescansduringqueries.
Complextypesrepresentamiddlegroundthataddressestheseperformance andvolumeconcerns.Byphysically
locatingrelateddatawithinthesamedatafiles,complextypesincreaselocalityandreducetheexpenseofjoin
queries.Byassociatinganarbitraryamountofdatawithasinglerow,complextypesavoidtheneedtorepeat
lengthyvaluessuchasstrings.BecauseImpalaknowswhichcomplextypevaluesareassociatedwitheachrow,
youcansavestoragebyavoidingartificialforeignkeyvaluesthatareonlyusedforjoins.Theflexibilityofthe
STRUCT,ARRAY,andMAPtypesletsyoumodelfamiliarconstructssuchasfactanddimension tablesfromadata
warehouse,andwidetablesrepresentingsparsematrixes.
PhysicalStorageforComplexTypes
Physically,thescalarandcomplexcolumnsineachrowarelocatedadjacenttoeachotherinthesameParquetdata
file,ensuringthattheyareprocessedonthesamehostratherthanbeingbroadcastacrossthenetworkwhen
cross-referencedwithinaquery.Thisco-locationsimplifies theprocessofcopying,converting,andbackingallthe
columnsupatonce.Becauseofthecolumn-orien tedlayoutofParquetfiles,youcanstillqueryonlythescalarcolumns
ofatablewithoutimposing theI/Openaltyofreadingthe(possibly large)valuesofthecompositecolumns.
WithineachParquetdatafile,theconstituentpartsofcomplextypecolumnsarestoredincolumn-orien tedformat:
â¢EachfieldofaSTRUCTtypeisstoredlikeacolumn,withallthescalarvaluesadjacenttoeachotherandencoded,
compressed,andsoonusingtheParquetspace-savingtechniques.
â¢ForanARRAYcontainingscalarvalues,allthosevalues(representedbytheITEMpseudocolumn)arestored
adjacenttoeachother.
â¢ForaMAP,thevaluesoftheKEYpseudocolumnarestoredadjacenttoeachother.IftheVALUEpseudocolumnis
ascalartype,itsvaluesarealsostoredadjacenttoeachother.
â¢IfanARRAYelement,STRUCTfield,orMAPVALUEpartisanothercomplextype,thecolumn-orien tedstorage
appliestothenextleveldown(orthenextlevelafterthat,andsoonfordeeplynestedtypes)wherethefinal
elements,fields,orvaluesareofscalartypes.
ThenumbersrepresentedbythePOSpseudocolumnofanARRAYarenotphysicallystoredinthedatafiles.Theyare
synthesizedatquerytimebasedontheorderoftheARRAYelementsassociatedwitheachrow.
FileFormatSupportforImpalaComplexTypes
Currently,ImpalaqueriessupportcomplextypedataonlyintheParquetfileformat.SeeUsingtheParquetFileFormat
withImpalaTablesonpage643fordetailsabouttheperformance benefitsandphysicallayoutofthisfileformat.
BecauseImpaladoesnotparsethedatastructurescontainingnestedtypesforunsupport edformatssuchastext,Avro,
SequenceFile, orRCFile,youcannotusedatafilesintheseformatswithImpala,evenifthequerydoesnotrefertothe
nestedtypecolumns.Also,ifatableusinganunsupport edformatoriginally containednestedtypecolumns,andthen
thosecolumnsweredroppedfromthetableusingALTER TABLE ... DROP COLUMN ,anyexistingdatafilesinthe
tablestillcontainthenestedtypedataandImpalaqueriesonthattablewillgenerateerrors.
TheoneexceptiontotheprecedingruleisCOUNT(*) queriesonRCFiletablesthatincludecomplextypes.Suchqueries
areallowedinCDH5.8/Impala2.6andhigher.
ApacheImpalaGuide|141ImpalaSQLLanguageReference
YoucanperformDDLoperationsfortablesinvolvingcomplextypesinmostfileformatsotherthanParquet.Youcannot
createtablesinImpalawithcomplextypesusingtextfiles.
Youcanhaveapartitioned tablewithcomplextypecolumnsthatusesanon-Parquetformat,anduseALTER TABLE
tochangethefileformattoParquetforindividual partitions. WhenyouputParquetdatafilesintothosepartitions,
Impalacanexecutequeriesagainstthatdataaslongasthequerydoesnotinvolveanyofthenon-Parquetpartitions.
Ifyouusetheparquet-tools command toexaminethestructureofaParquetdatafilethatincludescomplextypes,
youseethatbothARRAYandMAParerepresentedasaBaginParquetterminology ,withallfieldsmarkedOptional
becauseImpalaallowsanycolumntobenullable.
Impalasupports either2-leveland3-levelencodingwithineachParquetdatafile.WhenconstructingParquetdata
filesoutsideImpala,useeitherencodingstylebutdonotmix2-leveland3-levelencodingwithinthesamedatafile.
Choosing BetweenComplexTypesandNormalizedTables
Choosing betweenmultiplenormalizedfactanddimension tables,orasingletablecontainingcomplextypes,isan
importantdesigndecision.
â¢Ifyouarecomingfromatraditional databaseordatawarehousing background,youmightbefamiliarwithhow
tosplitupdatabetweentables.Yourbusinessintelligencetoolsmightalreadybeoptimizedfordealingwiththis
kindofmulti-tablescenariothroughjoinqueries.
â¢IfyouarepullingdatafromImpalaintoanapplicationwritteninaprogramminglanguagethathasdatastructures
analogoustothecomplextypes,suchasPythonorJava,complextypesinImpalacouldsimplifydatainterchange
andimproveunderstandability andreliabilityofyourprogramlogic.
â¢Youmightalreadybefacedwithexistinginfrastructureorreceivehighvolumesofdatathatassumeonelayout
ortheother.Forexample,complextypesarepopularwithweb-orientedapplications,forexampletokeep
informationaboutanonlineuserallinoneplaceforconvenientlookupandanalysis,ortodealwithsparseor
constantlyevolvingdatafields.
â¢Ifsomepartsofthedatachangeovertimewhilerelateddataremainsconstant,usingmultiplenormalizedtables
letsyoureplacecertainpartsofthedatawithoutreloadingtheentiredataset.Conversely,ifyoureceiverelated
dataallbundledtogether,suchasinJSONfiles,usingcomplextypescansavetheoverheadofsplittingtherelated
itemsacrossmultipletables.
â¢Fromaperformance perspective:
âInParquettables,Impalacanskipcolumnsthatarenotreferencedinaquery,avoidingtheI/Openaltyof
readingtheembedded data.Whencomplextypesarenestedwithinacolumn,thedataisphysicallydivided
ataverygranularlevel;forexample,aqueryreferringtodatanestedmultiplelevelsdeepinacomplextype
columndoesnothavetoreadallthedatafromthatcolumn,onlythedatafortherelevantpartsofthecolumn
typehierarchy.
âComplextypesavoidthepossibility ofexpensivejoinquerieswhendatafromfactanddimension tablesis
processedinparallelacrossmultiplehosts.Alltheinformationforarowcontainingcomplextypesistypically
tobeinthesamedatablock,andthereforedoesnotneedtobetransmittedacrossthenetworkwhenjoining
fieldsthatareallpartofthesamerow.
âThetradeoffwithcomplextypesisthatfewerrowsfitineachdatablock.Whetheritisbettertohavemore
datablockswithfewerrows,orfewerdatablockswithmanyrows,dependsonthedistribution ofyourdata
andthecharacteristicsofyourqueryworkload.Ifthecomplexcolumnsarerarelyreferenced,usingthem
mightlowerefficiency.Ifyouareseeinglowparallelismduetoasmallvolumeofdata(relativelyfewdata
blocks)ineachtablepartition, increasingtherowsizebyincluding complexcolumnsmightproducemore
datablocksandthusspreadtheworkmoreevenlyacrossthecluster.SeeScalabilityConsiderationsforImpala
onpage605formoreonthisadvancedtopic.
DifferencesBetweenImpalaandHiveComplexTypes
ImpalacanqueryParquettablescontainingARRAY,STRUCT,andMAPcolumnsproducedbyHive.Therearesome
differencestobeawareofbetweentheImpalaSQLandHiveQLsyntaxforcomplextypes,primarily forqueries.
142|ApacheImpalaGuideImpalaSQLLanguageReference
Impalasupports asubsetofthesyntaxthatHivesupports forspecifyingARRAY,STRUCT,andMAPtypesintheCREATE
TABLEstatements.
BecauseImpalaSTRUCTcolumnsincludeuser-specified fieldnames,youusetheNAMED_STRUCT() constructorin
HiveratherthantheSTRUCT() constructorwhenyoupopulateanImpalaSTRUCTcolumnusingaHiveINSERT
statement.
TheHiveUNIONtypeisnotcurrentlysupportedinImpala.
WhileImpalausuallyaimsforahighdegreeofcompatibilitywithHiveQLquerysyntax,ImpalasyntaxdiffersfromHive
forqueriesinvolvingcomplextypes.Thedifferencesareintendedtoprovideextraflexibilityforqueriesinvolvingthese
kindsoftables.
â¢Impalausesdotnotationforreferringtoelementnamesorelementswithincomplextypes,andjoinnotationfor
cross-referencingscalarcolumnswiththeelementsofcomplextypeswithinthesamerow,ratherthantheLATERAL
VIEWclauseandEXPLODE() functionofHiveQL.
â¢Usingjoinnotationletsyouuseallthekindsofjoinquerieswithcomplextypecolumns.Forexample,youcanuse
aLEFT OUTER JOIN ,LEFT ANTI JOIN ,orLEFT SEMI JOIN querytoevaluatedifferentscenarios wherethe
complexcolumnsdoordonotcontainanyelements.
â¢Youcanincludereferencestocollectiontypesinsidesubqueries andinlineviews.Forexample,youcanconstruct
aFROMclausewhereoneoftheâtablesâisasubqueryagainstacomplextypecolumn,oruseasubqueryagainst
acomplextypecolumnastheargumenttoanINorEXISTSclause.
â¢TheImpalapseudocolumnPOSletsyouretrievethepositionofelementsinanarrayalongwiththeelements
themselves,equivalenttothePOSEXPLODE() functionofHiveQL.Youdonotuseindexnotationtoretrievea
singlearrayelementinaquery;thejoinqueryloopsthroughthearrayelementsandyouuseWHEREclausesto
specifywhichelementstoreturn.
â¢JoinclausesinvolvingcomplextypecolumnsdonotrequireanONorUSINGclause.Impalaimplicitly appliesthe
joinkeysothatthecorrectarrayentriesormapelementsareassociatedwiththecorrectrowfromthetable.
â¢ImpaladoesnotcurrentlysupporttheUNIONcomplextype.
LimitationsandRestrictionsforComplexTypes
Complextypecolumnscanonlybeusedintablesorpartitions withtheParquetfileformat.
Complextypecolumnscannotbeusedaspartition keycolumnsinapartitioned table.
WhenyouusecomplextypeswiththeORDER BY ,GROUP BY ,HAVING,orWHEREclauses,youcannotrefertothe
columnnamebyitself.Instead,yourefertothenamesofthescalarvalueswithinthecomplextype,suchastheITEM,
POS,KEY,orVALUEpseudocolumns,orthefieldnamesfromaSTRUCT.
Themaximumdepthofnestingforcomplextypesis100levels.
Themaximumlengthofthecolumndefinitionforanycomplextype,including declarationsforanynestedtypes,is
4000characters.
Foridealperformance andscalability,usesmallormedium-siz edcollections, whereallthecomplexcolumnscontain
atmostafewhundredmegabytesperrow.Remember ,allthecolumnsofarowarestoredinthesameHDFSdata
block,whosesizeinParquetfilestypicallyrangesfrom256MBto1GB.
Including complextypecolumnsinatableintroducessomeoverheadthatmightmakequeriesthatdonotreference
thosecolumnssomewhatslowerthanImpalaqueriesagainsttableswithoutanycomplextypecolumns.Expectat
mosta2xslowdowncomparedtotablesthatdonothaveanycomplextypecolumns.
Currently,theCOMPUTE STATS statementdoesnotcollectanystatisticsforcolumnscontainingcomplextypes.Impala
usesheuristicstoconstructexecutionplansinvolvingcomplextypecolumns.
Currently,Impalabuilt-infunctions anduser-definedfunctions cannotacceptcomplextypesasparametersorproduce
themasfunctionreturnvalues.(WhenthecomplextypevaluesarematerializedinanImpalaresultset,theresultset
containsthescalarcomponen tsofthevalues,suchasthePOSorITEMforanARRAY,theKEYorVALUEforaMAP,or
thefieldsofaSTRUCT;thesescalardataitemscanbeusedwithbuilt-infunctions andUDFsasusual.)
ApacheImpalaGuide|143ImpalaSQLLanguageReference
Impalacurrentlycannotwritenewdatafilescontainingcomplextypecolumns.Therefore,although theSELECT
statementworksforqueriesinvolvingcomplextypecolumns,youcannotuseastatementformthatwritesdatato
complextypecolumns,suchasCREATE TABLE AS SELECT orINSERT ... SELECT .Tocreatedatafilescontaining
complextypedata,usetheHiveINSERTstatement,oranotherETLmechanism suchasMapReducejobs,Sparkjobs,
Pig,andsoon.
Currently,ImpalacanquerycomplextypecolumnsonlyfromParquettablesorParquetpartitions withinpartitioned
tables.Although youcanusecomplextypesintableswithAvro,text,andotherfileformatsaspartofyourETLpipeline,
forexampleasintermediatetablespopulatedthroughHive,doinganalyticsthroughImpalarequiresthatthedata
eventuallyendsupinaParquettable.TherequirementforParquetdatafilesmeansthatyoucanusecomplextypes
withImpalatableshostedonotherkindsoffilestoragesystemssuchasIsilonandAmazonS3,butyoucannotuse
ImpalatoquerycomplextypesfromHBasetables.SeeFileFormatSupportforImpalaComplexTypesonpage141for
moredetails.
UsingComplexTypesinSQL
WhenusingcomplextypesthroughSQLinImpala,youlearnthenotationfor< >delimitersforthecomplextype
columnsinCREATE TABLE statements,andhowtoconstructjoinqueriestoâunpackâ thescalarvaluesnestedinside
thecomplexdatastructures.Youmightneedtocondenseatraditional RDBMSordatawarehouseschemaintoa
smallernumberofParquettables,anduseHive,Spark,Pig,orothermechanism outsideImpalatopopulatethetables
withdata.
ComplexTypeSyntaxforDDLStatements
Thedefinitionofdata_type,asseenintheCREATE TABLE andALTER TABLE statements,nowincludescomplextypes
inadditiontoprimitivetypes:
  primitive_type
| array_type
| map_type
| struct_type
Unionsarenotcurrentlysupported.
Array,struct,andmapcolumntypedeclarationsarespecified intheCREATE TABLE statement.Youcanalsoadd
orchangethetypeofcomplexcolumnsthroughtheALTER TABLE statement.
Currently,ImpalaqueriesallowcomplextypesonlyintablesthatusetheParquetformat.IfanImpalaqueryencounters
complextypesinatableorpartition usinganotherfileformat,thequeryreturnsaruntimeerror.
YoucanuseALTER TABLE ... SET FILEFORMAT PARQUET tochangethefileformatofanexistingtablecontaining
complextypestoParquet,afterwhichImpalacanqueryit.MakesuretoloadParquetfilesintothetableafterchanging
thefileformat,becausetheALTER TABLE ... SET FILEFORMAT statementdoesnotconvertexistingdatatothe
newfileformat.
Partitioned tablescancontaincomplextypecolumns.Allthepartition keycolumnsmustbescalartypes.
BecauseusecasesforImpalacomplextypesrequirethatyoualreadyhaveParquetdatafilesproducedoutsideof
Impala,youcanusetheImpalaCREATE TABLE LIKE PARQUET syntaxtoproduceatablewithcolumnsthatmatch
thestructureofanexistingParquetfile,including complextypecolumnsfornesteddatastructures.Remember to
includetheSTORED AS PARQUET clauseinthiscase,becauseevenwithCREATE TABLE LIKE PARQUET ,thedefault
fileformatoftheresultingtableisstilltext.
YoucannotusetheCREATE TABLE AS SELECT syntaxtocreateatablewithnestedtypecolumnsbecausethe
complexcolumnsareomittedfromtheresultsetofanImpalaSELECT * orSELECT col_name query,andbecause
ImpalacurrentlydoesnotsupportwritingParquetfileswithcomplextypecolumns,
144|ApacheImpalaGuideImpalaSQLLanguageReference
Note:
Onceyouhaveatablesetupwithcomplextypecolumns,usetheDESCRIBE andSHOW CREATE
TABLEstatementstoseethecorrectnotationwith<and>delimitersandcommaandcolonseparators
withinthecomplextypedefinitions.Ifyoudonothaveexistingdatawiththesamelayoutasthetable,
youcanquerytheemptytabletopracticewiththenotationfortheSELECTstatement.IntheSELECT
list,youusedotnotationandpseudocolumnssuchasITEM,KEY,andVALUEforreferringtoitems
withinthecomplextypecolumns.IntheFROMclause,youusejoinnotationtoconstructtablealiases
foranyreferencedARRAYandMAPcolumns.
Forexample,whendefiningatablethatholdscontactinformation,youmightrepresentphonenumbersdifferently
depending ontheexpectedlayoutandrelationshipsofthedata,andhowwellyoucanpredictthosepropertiesin
advance.
Herearedifferentwaysthatyoumightrepresentphonenumbersinatraditional relationalschema,withequivalent
representationsusingcomplextypes.
Thetraditional, simplestwaytorepresentphonenumbersinarelationaltableistostoreallcontactinfoinasingle
table,withallcolumnshavingscalartypes,andeachpotentialphonenumberrepresentedasaseparatecolumn.In
thisexample,eachpersoncanonlyhavethese3typesofphonenumbers.Ifthepersondoesnothaveaparticular kind
ofphonenumber,thecorresponding columnisNULLforthatrow.
CREATE TABLE contacts_fixed_phones
(
    id BIGINT
  , name STRING
  , address STRING
  , home_phone STRING
  , work_phone STRING
  , mobile_phone STRING
) STORED AS PARQUET;
Figure1:Traditional RelationalRepresentationofPhoneNumbers:SingleTable
Usingacomplextypecolumntorepresentthephonenumbersaddssomeextraflexibility.Nowtherecouldbean
unlimitednumberofphonenumbers.Becausethearrayelementshaveanorderbutnotsymbolicnames,youcould
decideinadvancethatphone_number[0] isthehomenumber,[1]istheworknumber,[2]isthemobilenumber,and
soon.(Insubsequentexamples,youwillseehowtocreateamoreflexiblenamingschemeusingothercomplextype
variations,suchasaMAPoranARRAYwhereeachelementisaSTRUCT.)
CREATE TABLE contacts_array_of_phones
(
    id BIGINT
  , name STRING
  , address STRING
  , phone_number ARRAY < STRING >
) STORED AS PARQUET;
Figure2:AnArrayofPhoneNumbers
AnotherwaytorepresentanarbitrarysetofphonenumbersiswithaMAPcolumn.WithaMAP,eachelementis
associatedwithakeyvaluethatyouspecify,whichcouldbeanumeric, string,orotherscalartype.Thisexampleuses
aSTRINGkeytogiveeachphonenumberaname,suchas'home'or'mobile' .Aquerycouldfilterthedatabased
onthekeyvalues,ordisplaythekeyvaluesinreports.
CREATE TABLE contacts_unlimited_phones
(
  id BIGINT, name STRING, address STRING, phone_number MAP < STRING,STRING >
ApacheImpalaGuide|145ImpalaSQLLanguageReference
) STORED AS PARQUET;
Figure3:AMapofPhoneNumbers
Ifyouareanexperienced databasedesigner,youalreadyknowhowtoworkaroundthelimitationsofthesingle-table
schemafromFigure1:TraditionalRelationalRepresentationofPhoneNumbers:SingleTableonpage145.Bynormalizing
theschema,withthephonenumbersintheirowntable,youcanassociateanarbitrarysetofphonenumberswith
eachperson,andassociateadditional detailswitheachphonenumber,suchaswhetheritisahome,work,ormobile
phone.
Theflexibilityofthisapproachcomeswithsomedrawbacks.Reconstructingallthedataforaparticular personrequires
ajoinquery,whichmightrequireperformancetuningonHadoopbecausethedatafromeachtablemightbetransmitted
fromadifferenthost.Datamanagementtaskssuchasbackupsandrefreshingthedatarequiredealingwithmultiple
tablesinsteadofasingletable.
Thisexampleillustratesatraditional databaseschematostorecontactinfonormalizedacross2tables.Thefacttable
establishestheidentityandbasicinformationaboutperson.Adimension tablestoresinformationonlyaboutphone
numbers,usinganIDvaluetoassociateeachphonenumberwithapersonIDfromthefacttable.Eachpersoncan
have0,1,ormanyphones;thecategoriesarenotrestrictedtoafewpredefinedones;andthephonetablecancontain
asmanycolumnsasdesired,torepresentallsortsofdetailsabouteachphonenumber.
CREATE TABLE fact_contacts (id BIGINT, name STRING, address STRING) STORED AS PARQUET;
CREATE TABLE dim_phones
(
    contact_id BIGINT
  , category STRING
  , international_code STRING
  , area_code STRING
  , exchange STRING
  , extension STRING
  , mobile BOOLEAN
  , carrier STRING
  , current BOOLEAN
  , service_start_date TIMESTAMP
  , service_end_date TIMESTAMP
)
STORED AS PARQUET;
Figure4:Traditional RelationalRepresentationofPhoneNumbers:NormalizedTables
TorepresentaschemaequivalenttotheonefromFigure4:Traditional RelationalRepresentationofPhoneNumbers:
NormalizedTablesonpage146usingcomplextypes,thisexampleusesanARRAYwhereeacharrayelementisaSTRUCT.
Aswiththeearliercomplextypeexamples,eachpersoncanhaveanarbitrarysetofassociatedphonenumbers.Making
eacharrayelementintoaSTRUCTletsusassociatemultipledataitemswitheachphonenumber,andgiveaseparate
nameandtypetoeachdataitem.TheSTRUCTfieldsoftheARRAYelementsreproducethecolumnsofthedimension
tablefromthepreviousexample.
Youcandoallthesamekindsofquerieswiththecomplextypeschemaaswiththenormalizedschemafromthe
previousexample.Theadvantagesofthecomplextypedesignareintheareasofconvenienceandperformance. Now
yourbackupandETLprocessesonlydealwithasingletable.Whenaqueryusesajointocross-referencetheinformation
aboutapersonwiththeirassociatedphonenumbers,alltherelevantdataforeachrowresidesinthesameHDFSdata
block,meaningeachrowcanbeprocessedonasinglehostwithoutrequiringnetworktransmission.
CREATE TABLE contacts_detailed_phones
(
  id BIGINT, name STRING, address STRING
    , phone ARRAY < STRUCT <
        category: STRING
      , international_code: STRING
      , area_code: STRING
      , exchange: STRING
146|ApacheImpalaGuideImpalaSQLLanguageReference
      , extension: STRING
      , mobile: BOOLEAN
      , carrier: STRING
      , current: BOOLEAN
      , service_start_date: TIMESTAMP
      , service_end_date: TIMESTAMP
    >>
) STORED AS PARQUET;
Figure5:PhoneNumbersRepresentedasanArrayofStructs
SQLStatementsthatSupportComplexTypes
TheImpalaSQLstatementsthatsupportcomplextypesarecurrentlyCREATE TABLE ,ALTER TABLE ,DESCRIBE ,
LOAD DATA ,andSELECT.Thatis,currentlyImpalacancreateoraltertablescontainingcomplextypecolumns,examine
thestructureofatablecontainingcomplextypecolumns,importexistingdatafilescontainingcomplextypecolumns
intoatable,andqueryParquettablescontainingcomplextypes.
Impalacurrentlycannotwritenewdatafilescontainingcomplextypecolumns.Therefore,although theSELECT
statementworksforqueriesinvolvingcomplextypecolumns,youcannotuseastatementformthatwritesdatato
complextypecolumns,suchasCREATE TABLE AS SELECT orINSERT ... SELECT .Tocreatedatafilescontaining
complextypedata,usetheHiveINSERTstatement,oranotherETLmechanism suchasMapReducejobs,Sparkjobs,
Pig,andsoon.
DDLStatementsandComplexTypes
Columnspecificationsforcomplexornestedtypesuse<and>delimiters:
-- What goes inside the < > for an ARRAY is a single type, either a scalar or another
-- complex type (ARRAY, STRUCT, or MAP).
CREATE TABLE array_t
(
  id BIGINT,
  a1 ARRAY <STRING>,
  a2 ARRAY <BIGINT>,
  a3 ARRAY <TIMESTAMP>,
  a4 ARRAY <STRUCT <f1: STRING, f2: INT, f3: BOOLEAN>>
)
STORED AS PARQUET;
-- What goes inside the < > for a MAP is two comma-separated types specifying the types
 of the key-value pair:
-- a scalar type representing the key, and a scalar or complex type representing the 
value.
CREATE TABLE map_t
(
  id BIGINT,
  m1 MAP <STRING, STRING>,
  m2 MAP <STRING, BIGINT>,
  m3 MAP <BIGINT, STRING>,
  m4 MAP <BIGINT, BIGINT>,
  m5 MAP <STRING, ARRAY <STRING>>
)
STORED AS PARQUET;
-- What goes inside the < > for a STRUCT is a comma-separated list of fields, each field
 defined as
-- name:type. The type can be a scalar or a complex type. The field names for each STRUCT
 do not clash
-- with the names of table columns or fields in other STRUCTs. A STRUCT is most often 
used inside
-- an ARRAY or a MAP rather than as a top-level column.
CREATE TABLE struct_t
(
  id BIGINT,
  s1 STRUCT <f1: STRING, f2: BIGINT>,
  s2 ARRAY <STRUCT <f1: INT, f2: TIMESTAMP>>,
  s3 MAP <BIGINT, STRUCT <name: STRING, birthday: TIMESTAMP>>
)
ApacheImpalaGuide|147ImpalaSQLLanguageReference
STORED AS PARQUET;
QueriesandComplexTypes
TheresultsetofanImpalaqueryalwayscontainsallscalartypes;theelementsandfieldswithinanycomplextype
queriesmustbeâunpackedâusingjoinqueries.Aquerycannotdirectlyretrievetheentirevalueforacomplextype
column.Impalareturnsanerrorinthiscase.QueriesusingSELECT * areallowedfortableswithcomplextypes,but
thecolumnswithcomplextypesareskipped.
Thefollowingexampleshowshowreferringdirectlytoacomplextypecolumnreturnsanerror,whileSELECT * on
thesametablesucceeds, butonlyretrievesthescalarcolumns.
Note:ManyofthecomplextypeexamplesrefertotablessuchasCUSTOMER andREGIONadapted
fromthetablesusedintheTPC-Hbenchmark. SeeSampleSchemaandDataforExperimen tingwith
ImpalaComplexTypesonpage160forthetabledefinitions.
SELECT c_orders FROM customer LIMIT 1;
ERROR: AnalysisException: Expr 'c_orders' in select list returns a complex type 
'ARRAY<STRUCT<o_orderkey:BIGINT,o_orderstatus:STRING, ... 
l_receiptdate:STRING,l_shipinstruct:STRING,l_shipmode:STRING,l_comment:STRING>>>>'.
Only scalar types are allowed in the select list.
-- Original column has several scalar and one complex column.
DESCRIBE customer;
+--------------+------------------------------------+
| name         | type                               |
+--------------+------------------------------------+
| c_custkey    | bigint                             |
| c_name       | string                             |
...
| c_orders     | array<struct<                      |
|              |   o_orderkey:bigint,               |
|              |   o_orderstatus:string,            |
|              |   o_totalprice:decimal(12,2),      |
...
|              | >>                                 |
+--------------+------------------------------------+
-- When we SELECT * from that table, only the scalar columns come back in the result 
set.
CREATE TABLE select_star_customer STORED AS PARQUET AS SELECT * FROM customer;
+------------------------+
| summary                |
+------------------------+
| Inserted 150000 row(s) |
+------------------------+
-- The c_orders column, being of complex type, was not included in the SELECT * result
 set.
DESC select_star_customer;
+--------------+---------------+
| name         | type          |
+--------------+---------------+
| c_custkey    | bigint        |
| c_name       | string        |
| c_address    | string        |
| c_nationkey  | smallint      |
| c_phone      | string        |
| c_acctbal    | decimal(12,2) |
| c_mktsegment | string        |
| c_comment    | string        |
+--------------+---------------+
148|ApacheImpalaGuideImpalaSQLLanguageReference
ReferencestofieldswithinSTRUCTcolumnsusedotnotation.Ifthefieldnameisunambiguous, youcanomitqualifiers
suchastablename,columnname,oreventheITEMorVALUEpseudocolumnnamesforSTRUCTelementsinsidean
ARRAYoraMAP.
SELECT id, address.city FROM customers WHERE address.zip = 94305;
ReferencestoelementswithinARRAYcolumnsusetheITEMpseudocolumn:
select r_name, r_nations.item.n_name from region, region.r_nations limit 7;
+--------+----------------+
| r_name | item.n_name    |
+--------+----------------+
| EUROPE | UNITED KINGDOM |
| EUROPE | RUSSIA         |
| EUROPE | ROMANIA        |
| EUROPE | GERMANY        |
| EUROPE | FRANCE         |
| ASIA   | VIETNAM        |
| ASIA   | CHINA          |
+--------+----------------+
ReferencestofieldswithinMAPcolumnsusetheKEYandVALUEpseudocolumns.Inthisexample,oncethequery
establishesthealiasMAP_FIELD foraMAPcolumnwithaSTRINGkeyandanINTvalue,thequerycanreferto
MAP_FIELD.KEY andMAP_FIELD.VALUE ,whichhavezero,one,ormanyinstancesforeachrowfromthecontaining
table.
DESCRIBE table_0;
+---------+-----------------------+
| name    | type                  |
+---------+-----------------------+
| field_0 | string                |
| field_1 | map<string,int>       |
...
SELECT field_0, map_field.key, map_field.value
  FROM table_0, table_0.field_1 AS map_field
WHERE length(field_0) = 1
LIMIT 10;
+---------+-----------+-------+
| field_0 | key       | value |
+---------+-----------+-------+
| b       | gshsgkvd  | NULL  |
| b       | twrtcxj6  | 18    |
| b       | 2vp5      | 39    |
| b       | fh0s      | 13    |
| v       | 2         | 41    |
| v       | 8b58mz    | 20    |
| v       | hw        | 16    |
| v       | 65l388pyt | 29    |
| v       | 03k68g91z | 30    |
| v       | r2hlg5b   | NULL  |
+---------+-----------+-------+
Whencomplextypesarenestedinsideeachother,youuseacombinationofjoins,pseudocolumnnames,anddot
notationtorefertospecificfieldsattheappropriatelevel.Thisisthemostfrequentformofquerysyntaxforcomplex
columns,becausethetypicalusecaseinvolvestwolevelsofcomplextypes,suchasanARRAYofSTRUCTelements.
SELECT id, phone_numbers.area_code FROM contact_info_many_structs INNER JOIN 
contact_info_many_structs.phone_numbers phone_numbers LIMIT 3;
YoucanexpressrelationshipsbetweenARRAYandMAPcolumnsatdifferentlevelsasjoins.Youincludecomparison
operatorsbetweenfieldsatthetoplevelandwithinthenestedtypecolumnssothatImpalacandotheappropriate
joinoperation.
ApacheImpalaGuide|149ImpalaSQLLanguageReference
Note:ManyofthecomplextypeexamplesrefertotablessuchasCUSTOMER andREGIONadapted
fromthetablesusedintheTPC-Hbenchmark. SeeSampleSchemaandDataforExperimen tingwith
ImpalaComplexTypesonpage160forthetabledefinitions.
Forexample,thefollowingqueriesworkequivalently.Theyeachreturncustomerandorderdataforcustomersthat
haveatleastoneorder.
SELECT c.c_name, o.o_orderkey FROM customer c, c.c_orders o LIMIT 5;
+--------------------+------------+
| c_name             | o_orderkey |
+--------------------+------------+
| Customer#000072578 | 558821     |
| Customer#000072578 | 2079810    |
| Customer#000072578 | 5768068    |
| Customer#000072578 | 1805604    |
| Customer#000072578 | 3436389    |
+--------------------+------------+
SELECT c.c_name, o.o_orderkey FROM customer c INNER JOIN c.c_orders o LIMIT 5;
+--------------------+------------+
| c_name             | o_orderkey |
+--------------------+------------+
| Customer#000072578 | 558821     |
| Customer#000072578 | 2079810    |
| Customer#000072578 | 5768068    |
| Customer#000072578 | 1805604    |
| Customer#000072578 | 3436389    |
+--------------------+------------+
Thefollowingqueryusinganouterjoinreturnscustomersthathaveorders,pluscustomerswithnoorders(noentries
intheC_ORDERS array):
SELECT c.c_custkey, o.o_orderkey
  FROM customer c LEFT OUTER JOIN c.c_orders o
LIMIT 5;
+-----------+------------+
| c_custkey | o_orderkey |
+-----------+------------+
| 60210     | NULL       |
| 147873    | NULL       |
| 72578     | 558821     |
| 72578     | 2079810    |
| 72578     | 5768068    |
+-----------+------------+
Thefollowingqueryreturnsonlycustomersthathavenoorders.(WithLEFT ANTI JOIN orLEFT SEMI JOIN ,the
querycanonlyrefertocolumnsfromtheleft-handtable,becausebydefinitionthereisnomatchinginformationin
theright-handtable.)
SELECT c.c_custkey, c.c_name
  FROM customer c LEFT ANTI JOIN c.c_orders o
LIMIT 5;
+-----------+--------------------+
| c_custkey | c_name             |
+-----------+--------------------+
| 60210     | Customer#000060210 |
| 147873    | Customer#000147873 |
| 141576    | Customer#000141576 |
| 85365     | Customer#000085365 |
| 70998     | Customer#000070998 |
+-----------+--------------------+
Youcanalsoperformcorrelatedsubqueries toexaminethepropertiesofcomplextypecolumnsforeachrowinthe
resultset.
150|ApacheImpalaGuideImpalaSQLLanguageReference
Countthenumberoforderspercustomer.NotethecorrelatedreferencetothetablealiasC.TheCOUNT(*) operation
appliestoalltheelementsoftheC_ORDERS arrayforthecorresponding row,avoidingtheneedforaGROUP BY clause.
select c_name, howmany FROM customer c, (SELECT COUNT(*) howmany FROM c.c_orders) v 
limit 5;
+--------------------+---------+
| c_name             | howmany |
+--------------------+---------+
| Customer#000030065 | 15      |
| Customer#000065455 | 18      |
| Customer#000113644 | 21      |
| Customer#000111078 | 0       |
| Customer#000024621 | 0       |
+--------------------+---------+
Countthenumberoforderspercustomer,ignoringanycustomersthathavenotplacedanyorders:
SELECT c_name, howmany_orders
FROM
  customer c,
  (SELECT COUNT(*) howmany_orders FROM c.c_orders) subq1
WHERE howmany_orders > 0
LIMIT 5;
+--------------------+----------------+
| c_name             | howmany_orders |
+--------------------+----------------+
| Customer#000072578 | 7              |
| Customer#000046378 | 26             |
| Customer#000069815 | 11             |
| Customer#000079058 | 12             |
| Customer#000092239 | 26             |
+--------------------+----------------+
Countthenumberoflineitemsineachorder.ThereferencetoC.C_ORDERS intheFROMclauseisneededbecause
theO_ORDERKEY fieldisamemberoftheelementsintheC_ORDERS array.ThesubquerylabelledSUBQ1iscorrelated:
itisre-evaluatedfortheC_ORDERS.O_LINEITEMS arrayfromeachrowoftheCUSTOMERS table.
SELECT c_name, o_orderkey, howmany_line_items
FROM
  customer c,
  c.c_orders t2,
  (SELECT COUNT(*) howmany_line_items FROM c.c_orders.o_lineitems) subq1
WHERE howmany_line_items > 0
LIMIT 5;
+--------------------+------------+--------------------+
| c_name             | o_orderkey | howmany_line_items |
+--------------------+------------+--------------------+
| Customer#000020890 | 1884930    | 95                 |
| Customer#000020890 | 4570754    | 95                 |
| Customer#000020890 | 3771072    | 95                 |
| Customer#000020890 | 2555489    | 95                 |
| Customer#000020890 | 919171     | 95                 |
+--------------------+------------+--------------------+
Getthenumberoforders,theaverageorderprice,andthemaximumitemsinanyorderpercustomer.Forthisexample,
thesubqueries labelledSUBQ1andSUBQ2arecorrelated:theyarere-evaluatedforeachrowfromtheoriginalCUSTOMER
table,andonlyapplytothecomplexcolumnsassociatedwiththatrow.
SELECT c_name, howmany, average_price, most_items
FROM
  customer c,
  (SELECT COUNT(*) howmany, AVG(o_totalprice) average_price FROM c.c_orders) subq1,
  (SELECT MAX(l_quantity) most_items FROM c.c_orders.o_lineitems ) subq2
LIMIT 5;
+--------------------+---------+---------------+------------+
| c_name             | howmany | average_price | most_items |
+--------------------+---------+---------------+------------+
| Customer#000030065 | 15      | 128908.34     | 50.00      |
ApacheImpalaGuide|151ImpalaSQLLanguageReference
| Customer#000088191 | 0       | NULL          | NULL       |
| Customer#000101555 | 10      | 164250.31     | 50.00      |
| Customer#000022092 | 0       | NULL          | NULL       |
| Customer#000036277 | 27      | 166040.06     | 50.00      |
+--------------------+---------+---------------+------------+
Forexample,thesequeriesshowhowtoaccessinformationabouttheARRAYelementswithintheCUSTOMER table
fromtheânestedTPC-Hâschema,startingwiththeinitialARRAYelementsandprogressingtoexaminetheSTRUCT
fieldsoftheARRAY,andthentheelementsnestedwithinanotherARRAYofSTRUCT:
-- How many orders does each customer have?
-- The type of the ARRAY column doesn't matter, this is just counting the elements.
SELECT c_custkey, count(*)
  FROM customer, customer.c_orders
GROUP BY c_custkey
LIMIT 5;
+-----------+----------+
| c_custkey | count(*) |
+-----------+----------+
| 61081     | 21       |
| 115987    | 15       |
| 69685     | 19       |
| 109124    | 15       |
| 50491     | 12       |
+-----------+----------+
-- How many line items are part of each customer order?
-- Now we examine a field from a STRUCT nested inside the ARRAY.
SELECT c_custkey, c_orders.o_orderkey, count(*)
  FROM customer, customer.c_orders c_orders, c_orders.o_lineitems
GROUP BY c_custkey, c_orders.o_orderkey
LIMIT 5;
+-----------+------------+----------+
| c_custkey | o_orderkey | count(*) |
+-----------+------------+----------+
| 63367     | 4985959    | 7        |
| 53989     | 1972230    | 2        |
| 143513    | 5750498    | 5        |
| 17849     | 4857989    | 1        |
| 89881     | 1046437    | 1        |
+-----------+------------+----------+
-- What are the line items in each customer order?
-- One of the STRUCT fields inside the ARRAY is another
-- ARRAY containing STRUCT elements. The join finds
-- all the related items from both levels of ARRAY.
SELECT c_custkey, o_orderkey, l_partkey
  FROM customer, customer.c_orders, c_orders.o_lineitems
LIMIT 5;
+-----------+------------+-----------+
| c_custkey | o_orderkey | l_partkey |
+-----------+------------+-----------+
| 113644    | 2738497    | 175846    |
| 113644    | 2738497    | 27309     |
| 113644    | 2738497    | 175873    |
| 113644    | 2738497    | 88559     |
| 113644    | 2738497    | 8032      |
+-----------+------------+-----------+
PseudocolumnsforARRAYandMAPTypes
EachelementinanARRAYtypehasaposition, indexedstartingfromzero,andavalue.EachelementinaMAPtype
representsakey-valuepair.Impalaprovidespseudocolumnsthatletyouretrievethismetadataaspartofaquery,or
filterqueryresultsbyincluding suchthingsinaWHEREclause.Yourefertothepseudocolumnsaspartofqualified
columnnamesinqueries:
â¢ITEM:Thevalueofanarrayelement.IftheARRAYcontainsSTRUCTelements,youcanrefertoeither
array_name .ITEM.field_name orusetheshorthand array_name .field_name .
â¢POS:Thepositionofanelementwithinanarray.
152|ApacheImpalaGuideImpalaSQLLanguageReference
â¢KEY:Thevalueformingthefirstpartofakey-valuepairinamap.Itisnotnecessarily unique.
â¢VALUE:Thedataitemformingthesecondpartofakey-valuepairinamap.IftheVALUEpartoftheMAPelement
isaSTRUCT,youcanrefertoeithermap_name .VALUE.field_name orusetheshorthand map_name .field_name .
ITEMandPOSPseudocolumns
WhenanARRAYcolumncontainsSTRUCTelements,youcanrefertoafieldwithintheSTRUCTusingaqualified name
oftheformarray_column .field_name .IftheARRAYcontainsscalarvalues,Impalarecognizesthespecialname
array_column .ITEMtorepresentthevalueofeachscalararrayelement.Forexample,ifacolumncontainedan
ARRAYwhereeachelementwasaSTRING,youwouldusearray_name .ITEMtorefertoeachscalarvalueinthe
SELECTlist,ortheWHEREorotherclauses.
ThisexampleshowsatablewithtwoARRAYcolumnswhoseelementsareofthescalartypeSTRING.Whenreferring
tothevaluesofthearrayelementsintheSELECTlist,WHEREclause,orORDER BY clause,youusetheITEM
pseudocolumnbecausewithinthearray,theindividual elementshavenodefinednames.
create TABLE persons_of_interest
(
person_id BIGINT,
aliases ARRAY <STRING>,
associates ARRAY <STRING>,
real_name STRING
)
STORED AS PARQUET;
-- Get all the aliases of each person.
SELECT real_name, aliases.ITEM
  FROM persons_of_interest, persons_of_interest.aliases
ORDER BY real_name, aliases.item;
-- Search for particular associates of each person.
SELECT real_name, associates.ITEM
  FROM persons_of_interest, persons_of_interest.associates
WHERE associates.item LIKE '% MacGuffin';
Becauseanarrayisinherentlyanordereddatastructure,Impalarecognizesthespecialnamearray_column .POSto
representthenumericpositionofeachelementwithinthearray.ThePOSpseudocolumnletsyoufilterorreorderthe
resultsetbasedonthesequence ofarrayelements.
ThefollowingexampleusesatablefromaflattenedversionoftheTPC-Hschema.TheREGIONtableonlyhasafew
rows,suchasonerowforEuropeandoneforAsia.Therowforeachregionrepresentsallthecountriesinthatregion
asanARRAYofSTRUCTelements:
[localhost:21000] > desc region;
+-------------+--------------------------------------------------------------------+
| name        | type                                                               |
+-------------+--------------------------------------------------------------------+
| r_regionkey | smallint                                                           |
| r_name      | string                                                             |
| r_comment   | string                                                             |
| r_nations   | array<struct<n_nationkey:smallint,n_name:string,n_comment:string>> |
+-------------+--------------------------------------------------------------------+
Tofindthecountrieswithinaspecificregion,youuseajoinquery.Tofindouttheorderofelementsinthearray,you
alsorefertothePOSpseudocolumnintheselectlist:
[localhost:21000] > SELECT r1.r_name, r2.n_name, r2.POS
                  > FROM region r1 INNER JOIN r1.r_nations r2
                  > WHERE r1.r_name = 'ASIA';
+--------+-----------+-----+
| r_name | n_name    | pos |
+--------+-----------+-----+
| ASIA   | VIETNAM   | 0   |
| ASIA   | CHINA     | 1   |
| ASIA   | JAPAN     | 2   |
ApacheImpalaGuide|153ImpalaSQLLanguageReference
| ASIA   | INDONESIA | 3   |
| ASIA   | INDIA     | 4   |
+--------+-----------+-----+
Onceyouknowthepositions oftheelements,youcanusethatinformationinsubsequentqueries,forexampleto
changetheorderingofresultsfromthecomplextypecolumnortofiltercertainelementsfromthearray:
[localhost:21000] > SELECT r1.r_name, r2.n_name, r2.POS
                  > FROM region r1 INNER JOIN r1.r_nations r2
                  > WHERE r1.r_name = 'ASIA'
                  > ORDER BY r2.POS DESC ;
+--------+-----------+-----+
| r_name | n_name    | pos |
+--------+-----------+-----+
| ASIA   | INDIA     | 4   |
| ASIA   | INDONESIA | 3   |
| ASIA   | JAPAN     | 2   |
| ASIA   | CHINA     | 1   |
| ASIA   | VIETNAM   | 0   |
+--------+-----------+-----+
[localhost:21000] > SELECT r1.r_name, r2.n_name, r2.POS
                  > FROM region r1 INNER JOIN r1.r_nations r2
                  > WHERE r1.r_name = 'ASIA' AND r2.POS BETWEEN 1 and 3 ;
+--------+-----------+-----+
| r_name | n_name    | pos |
+--------+-----------+-----+
| ASIA   | CHINA     | 1   |
| ASIA   | JAPAN     | 2   |
| ASIA   | INDONESIA | 3   |
+--------+-----------+-----+
KEYandVALUEPseudocolumns
TheMAPdatatypeissuitableforrepresentingsparseorwidedatastructures,whereeachrowmightonlyhaveentries
forasmallsubsetofnamedfields.Becausetheelementnames(themapkeys)varydepending ontherow,aquery
mustbeabletorefertoboththekeyandthevaluepartsofeachkey-valuepair.TheKEYandVALUEpseudocolumns
letyourefertothepartsofthekey-valuepairindependen tlywithinthequery,asmap_column .KEYand
map_column .VALUE.
TheKEYmustalwaysbeascalartype,suchasSTRING,BIGINT,orTIMESTAMP .ItcanbeNULL.ValuesoftheKEYfield
arenotnecessarily uniquewithinthesameMAP.YouapplyanyrequiredDISTINCT ,GROUP BY ,andotherclausesin
thequery,andloopthroughtheresultsettoprocessallthevaluesmatchinganyspecified keys.
TheVALUEcanbeeitherascalartypeoranothercomplextype.IftheVALUEisaSTRUCT,youcanconstructaqualified
namemap_column .VALUE.struct_field torefertotheindividual fieldsinsidethevaluepart.IftheVALUEisan
ARRAYoranotherMAP,youmustincludeanotherjoinconditionthatestablishesatablealiasformap_column .VALUE,
andthenconstructanotherqualified nameusingthatalias,forexampletable_alias .ITEMortable_alias .KEY
andtable_alias .VALUE
ThefollowingexampleshowsdifferentwaystoaccessaMAPcolumnusingtheKEYandVALUEpseudocolumns.The
DETAILS columnhasaSTRINGfirstpartwithshort,standardizedvaluessuchas'Recurring' ,'Lucid' ,or
'Anxiety' .Thisistheâkeyâthatisusedtolookupparticular kindsofelementsfromtheMAP.Thesecondpart,also
aSTRING,isalongerfree-formexplanation.ImpalagivesyouthestandardpseudocolumnnamesKEYandVALUEfor
thetwoparts,andyouapplyyourownconventionsandinterpretationstotheunderlying values.
Note:Ifyoufindthatthesingle-itemnatureoftheVALUEmakesitdifficulttomodelyourdata
accurately,thesolutionistypicallytoaddsomenestingtothecomplextype.Forexample,tohave
severalsetsofkey-valuepairs,makethecolumnanARRAYwhoseelementsareMAP.Tomakeaset
ofkey-valuepairsthatholdsmoreelaborateinformation,makeaMAPcolumnwhoseVALUEpart
containsanARRAYoraSTRUCT.
CREATE TABLE dream_journal
(
154|ApacheImpalaGuideImpalaSQLLanguageReference
  dream_id BIGINT,
  details MAP <STRING,STRING>
)
STORED AS PARQUET;
-- What are all the types of dreams that are recorded?
SELECT DISTINCT details.KEY FROM dream_journal, dream_journal.details;
-- How many lucid dreams were recorded?
-- Because there is no GROUP BY, we count the 'Lucid' keys across all rows.
SELECT COUNT(details.KEY)
  FROM dream_journal, dream_journal.details
WHERE details.KEY = 'Lucid' ;
-- Print a report of a subset of dreams, filtering based on both the lookup key
-- and the detailed value.
SELECT dream_id, details.KEY AS "Dream Type" , details.VALUE AS "Dream Summary"
  FROM dream_journal, dream_journal.details
WHERE
details.KEY IN ('Happy', 'Pleasant', 'Joyous')
  AND details.VALUE LIKE '%childhood%' ;
Thefollowingexampleshowsamoreelaborateversionoftheprevioustable,wheretheVALUEpartoftheMAPentry
isaSTRUCTratherthanascalartype.NowinsteadofreferringtotheVALUEpseudocolumndirectly,youusedot
notationtorefertotheSTRUCTfieldsinsideit.
CREATE TABLE better_dream_journal
(
  dream_id BIGINT,
  details MAP <STRING,STRUCT <summary: STRING, when_happened: TIMESTAMP, duration: 
DECIMAL(5,2), woke_up: BOOLEAN> >
)
STORED AS PARQUET;
-- Do more elaborate reporting and filtering by examining multiple attributes within 
the same dream.
SELECT dream_id, details.KEY AS "Dream Type" , details.VALUE.summary AS "Dream Summary" ,
details.VALUE.duration AS "Duration"
  FROM better_dream_journal, better_dream_journal.details
WHERE
details.KEY IN ('Anxiety', 'Nightmare')
  AND details.VALUE.duration > 60
  AND details.VALUE.woke_up = TRUE ;
-- Remember that if the ITEM or VALUE contains a STRUCT, you can reference
-- the STRUCT fields directly without the .ITEM or .VALUE qualifier.
SELECT dream_id, details.KEY AS "Dream Type" , details.summary AS "Dream Summary" , 
details.duration AS "Duration"
  FROM better_dream_journal, better_dream_journal.details
WHERE
details.KEY IN ('Anxiety', 'Nightmare')
  AND details.duration > 60
  AND details.woke_up = TRUE ;
LoadingDataContainingComplexTypes
BecausetheImpalaINSERTstatementdoesnotcurrentlysupportcreatingnewdatawithcomplextypecolumns,or
copyingexistingcomplextypevaluesfromonetabletoanother,youprimarily useImpalatoqueryParquettableswith
complextypeswherethedatawasinsertedthroughHive,orcreatetableswithcomplextypeswhereyoualreadyhave
existingParquetdatafiles.
IfyouhavecreatedaHivetablewiththeParquetfileformatandcontainingcomplextypes,usethesametablefor
Impalaquerieswithnochanges.IfyouhavesuchaHivetableinsomeotherformat,useaHiveCREATE TABLE AS
SELECT ... STORED AS PARQUET orINSERT ... SELECT statementtoproduceanequivalentParquettablethat
Impalacanquery.
ApacheImpalaGuide|155ImpalaSQLLanguageReference
IfyouhaveexistingParquetdatafilescontainingcomplextypes,locatedoutsideofanyImpalaorHivetable,suchas
datafilescreatedbySparkjobs,youcanuseanImpalaCREATE TABLE ... STORED AS PARQUET statement,
followedbyanImpalaLOAD DATA statementtomovethedatafilesintothetable.Asanalternative,youcanusean
ImpalaCREATE EXTERNAL TABLE statementtocreateatablepointingtotheHDFSdirectorythatalreadycontains
thedatafiles.
Perhapsthesimplestwaytogetstartedwithcomplextypedataistotakeadenormaliz edtablecontainingduplicated
values,anduseanINSERT ... SELECT statementtocopythedataintoaParquettableandcondensetherepeated
valuesintocomplextypes.WiththeHiveINSERTstatement,youusetheCOLLECT_LIST() ,NAMED_STRUCT() ,and
MAP()constructorfunctions withinaGROUP BY querytoproducethecomplextypevalues.COLLECT_LIST() turns
asequence ofvaluesintoanARRAY.NAMED_STRUCT() usesthefirst,third,andsoonargumentsasthefieldnames
foraSTRUCT,tomatchthefieldnamesfromtheCREATE TABLE statement.
Note:BecauseHivecurrentlycannotconstructindividual rowsusingcomplextypesthroughthe
INSERT ... VALUES syntax,youpreparethedatainflatforminaseparatetable,thencopyitto
thetablewithcomplexcolumnsusingINSERT ... SELECT andthecomplextypeconstructors.See
ConstructingParquetFileswithComplexColumns UsingHiveonpage162forexamples.
UsingComplexTypesasNestedTypes
TheARRAY,STRUCT,andMAPtypescanbethetop-leveltypesforânestedtypeâcolumns.Thatis,eachofthesetypes
cancontainothercomplexorscalartypes,withmultiplelevelsofnestingtoamaximumdepthof100.Forexample,
youcanhaveanarrayofstructures,amapcontainingothermaps,astructurecontaininganarrayofotherstructures,
andsoon.Atthelowestlevel,therearealwaysscalartypesmakingupthefieldsofaSTRUCT,elementsofanARRAY,
andkeysandvaluesofaMAP.
Schemas involvingcomplextypestypicallyusesomelevelofnestingforthecomplextypecolumns.
Forexample,tomodelarelationshiplikeadimension tableandafacttable,youtypicallyuseanARRAYwhereeach
arrayelementisaSTRUCT.TheSTRUCTfieldsrepresentwhatwouldtraditionally becolumnsinaseparatejoined
table.ItmakeslittlesensetouseaSTRUCTasthetop-leveltypeforacolumn,becauseyoucouldjustmakethefields
oftheSTRUCTintoregulartablecolumns.
Perhapstheonlyusecaseforatop-levelSTRUCTwouldbetotoallowSTRUCTfieldswiththesamenameascolumns
tocoexistinthesametable.ThefollowingexampleshowshowatablecouldhaveacolumnnamedID,andtwoseparate
STRUCTfieldsalsonamedID.BecausetheSTRUCTfieldsarealwaysreferencedusingqualified names,theidentical
IDnamesdonotcauseaconflict.
CREATE TABLE struct_namespaces
(
  id BIGINT
  , s1 STRUCT < id: BIGINT, field1: STRING >
  , s2 STRUCT < id: BIGINT, when_happened: TIMESTAMP >
)
STORED AS PARQUET;
select id, s1.id, s2.id from struct_namespaces;
Itiscommontomakethevalueportionofeachkey-valuepairinaMAPaSTRUCT,ARRAYofSTRUCT,orothercomplex
typevariation.Thatway,eachkeyintheMAPcanbeassociatedwithaflexibleandextensibledatastructure.Thekey
valuesarenotpredefinedaheadoftime(otherthanbyspecifyingtheirdatatype).Therefore,theMAPcanaccommodate
arapidlyevolvingschema,orsparsedatastructureswhereeachrowcontainsonlyafewdatavaluesdrawnfroma
largesetofpossiblechoices.
Although youcanuseanARRAYofscalarvaluesasthetop-levelcolumninatable,suchasimplearrayistypicallyof
limiteduseforanalyticqueries.Theonlypropertyofthearrayelements,asidefromtheelementvalue,istheordering
sequence availablethroughthePOSpseudocolumn.Torecordanyadditional itemabouteacharrayelement,suchas
aTIMESTAMP orasymbolicname,youuseanARRAYofSTRUCTratherthanofscalarvalues.
Ifyouareconsidering havingmultipleARRAYorMAPcolumns,withrelateditemsunderthesamepositionineach
ARRAYorthesamekeyineachMAP,prefertouseaSTRUCTtogroupalltherelateditemsintoasingleARRAYorMAP.
156|ApacheImpalaGuideImpalaSQLLanguageReference
Doingsoavoidstheadditional storageoverheadandpotentialduplicationofkeyvaluesfromhavinganextracomplex
typecolumn.Also,becauseeachARRAYorMAPthatyoureferenceinthequerySELECTlistrequiresanadditional join
clause,minimizing thenumberofcomplextypecolumnsalsomakesthequeryeasiertoreadandmaintain,relying
moreondotnotationtorefertotherelevantfieldsratherthanasequence ofjoinclauses.
Forexample,hereisatablewithseveralcomplextypecolumnsallatthetoplevelandcontainingonlyscalartypes.
ToretrieveeverydataitemfortherowrequiresaseparatejoinforeachARRAYorMAPcolumn.ThefieldsoftheSTRUCT
canbereferencedusingdotnotation,butthereisnorealadvantagetousingtheSTRUCTatthetoplevelratherthan
justmakingseparatecolumnsFIELD1andFIELD2.
CREATE TABLE complex_types_top_level
(
  id BIGINT,
  a1 ARRAY<INT>,
  a2 ARRAY<STRING>,
  s STRUCT<field1: INT, field2: STRING>,
-- Numeric lookup key for a string value.
  m1 MAP<INT,STRING>,
-- String lookup key for a numeric value.
  m2 MAP<STRING,INT>
)
STORED AS PARQUET;
describe complex_types_top_level;
+------+-----------------+
| name | type            |
+------+-----------------+
| id   | bigint          |
| a1   | array<int>      |
| a2   | array<string>   |
| s    | struct<         |
|      |   field1:int,   |
|      |   field2:string |
|      | >               |
| m1   | map<int,string> |
| m2   | map<string,int> |
+------+-----------------+
select
  id,
  a1.item,
  a2.item,
  s.field1,
  s.field2,
  m1.key,
  m1.value,
  m2.key,
  m2.value
from
  complex_types_top_level,
  complex_types_top_level.a1,
  complex_types_top_level.a2,
  complex_types_top_level.m1,
  complex_types_top_level.m2;
Forexample,hereisatablewithcolumnscontaininganARRAYofSTRUCT,aMAPwhereeachkeyvalueisaSTRUCT,
andaMAPwhereeachkeyvalueisanARRAYofSTRUCT.
CREATE TABLE nesting_demo
(
  user_id BIGINT,
  family_members ARRAY < STRUCT < name: STRING, email: STRING, date_joined: TIMESTAMP 
>>,
  foo map < STRING, STRUCT < f1: INT, f2: INT, f3: TIMESTAMP, f4: BOOLEAN >>,
  gameplay MAP < STRING , ARRAY < STRUCT <
    name: STRING, highest: BIGINT, lives_used: INT, total_spent: DECIMAL(16,2)
  >>>
)
ApacheImpalaGuide|157ImpalaSQLLanguageReference
STORED AS PARQUET;
TheDESCRIBE statementrearrangesthe<and>separatorsandthefieldnameswithineachSTRUCTforeasyreadability:
DESCRIBE nesting_demo;
+----------------+-----------------------------+
| name           | type                        |
+----------------+-----------------------------+
| user_id        | bigint                      |
| family_members | array<struct<               |
|                |   name:string,              |
|                |   email:string,             |
|                |   date_joined:timestamp     |
|                | >>                          |
| foo            | map<string,struct<          |
|                |   f1:int,                   |
|                |   f2:int,                   |
|                |   f3:timestamp,             |
|                |   f4:boolean                |
|                | >>                          |
| gameplay       | map<string,array<struct<    |
|                |   name:string,              |
|                |   highest:bigint,           |
|                |   lives_used:int,           |
|                |   total_spent:decimal(16,2) |
|                | >>>                         |
+----------------+-----------------------------+
Toquerythecomplextypecolumns,youusejoinnotationtorefertothelowest-levelscalarvalues.Ifthevalueisan
ARRAYelement,thefullyqualifiednameincludestheITEMpseudocolumn.IfthevalueisinsideaMAP,thefullyqualified
nameincludestheKEYorVALUEpseudocolumn.EachreferencetoadifferentARRAYorMAP(evenifnestedinside
anothercomplextype)requiresanadditional joinclause.
SELECT
-- The lone scalar field doesn't require any dot notation or join clauses.
    user_id
-- Retrieve the fields of a STRUCT inside an ARRAY.
-- The FAMILY_MEMBERS name refers to the FAMILY_MEMBERS table alias defined later in 
the FROM clause.
  , family_members.item.name
  , family_members.item.email
  , family_members.item.date_joined
-- Retrieve the KEY and VALUE fields of a MAP, with the value being a STRUCT consisting
 of more fields.
-- The FOO name refers to the FOO table alias defined later in the FROM clause.
  , foo.key
  , foo.value.f1
  , foo.value.f2
  , foo.value.f3
  , foo.value.f4
-- Retrieve the KEY fields of a MAP, and expand the VALUE part into ARRAY items consisting
 of STRUCT fields.
-- The GAMEPLAY name refers to the GAMEPLAY table alias defined later in the FROM clause
 (referring to the MAP item).
-- The GAME_N name refers to the GAME_N table alias defined later in the FROM clause 
(referring to the ARRAY
-- inside the MAP item's VALUE part.)
  , gameplay.key
  , game_n.name
  , game_n.highest
  , game_n.lives_used
  , game_n.total_spent
FROM
    nesting_demo
  , nesting_demo.family_members AS family_members
  , nesting_demo.foo AS foo
  , nesting_demo.gameplay AS gameplay
158|ApacheImpalaGuideImpalaSQLLanguageReference
  , nesting_demo.gameplay.value AS game_n;
Onceyouunderstandthenotationtorefertoaparticular dataitemintheSELECTlist,youcanusethesamequalified
nametorefertothatdataiteminotherpartsofthequery,suchastheWHEREclause,ORDER BY orGROUP BY clauses,
orcallstobuilt-infunctions. Forexample,youmightfrequentlyretrievetheVALUEpartofeachMAPitemintheSELECT
list,whilechoosing thespecificMAPitemsbyrunningcomparisons againsttheKEYpartintheWHEREclause.
Accessing ComplexTypeDatainFlattenedFormUsingViews
Thelayoutofcomplexandnestedtypesislargelyaphysicalconsideration.Thecomplextypecolumnsresideinthe
samedatafilesratherthaninseparatenormalizedtables,foryourconvenienceinmanaging relateddatasetsand
performance inqueryingrelateddatasets.Youcanuseviewstotreattableswithcomplextypesasiftheywere
flattened.Byputtingthejoinlogicandreferencestothecomplextypecolumnsintheviewdefinition,youcanquery
thesametablesusingexistingqueriesintendedfortablescontainingonlyscalarcolumns.Thistechnique alsoletsyou
usetableswithcomplextypeswithBItoolsthatarenotawareofthedatatypesandquerynotationforaccessing
complextypecolumns.
Forexample,thevariationoftheTPC-HschemacontainingcomplextypeshasatableREGION.Thistablehas5rows,
corresponding to5regionssuchasNORTH AMERICA andAFRICA.EachrowhasanARRAYcolumn,whereeacharray
itemisaSTRUCTcontainingdetailsaboutacountryinthatregion.
DESCRIBE region;
+-------------+-------------------------+
| name        | type                    |
+-------------+-------------------------+
| r_regionkey | smallint                |
| r_name      | string                  |
| r_comment   | string                  |
| r_nations   | array<struct<           |
|             |   n_nationkey:smallint, |
|             |   n_name:string,        |
|             |   n_comment:string      |
|             | >>                      |
+-------------+-------------------------+
Thesamedatacouldberepresentedintraditional denormaliz edform,asasingletablewheretheinformationabout
eachregionisrepeatedoverandover,alongside theinformationabouteachcountry.Thenestedcomplextypeslet
usavoidtherepetition,whilestillkeepingthedatainasingletableratherthannormalizing acrossmultipletables.
TousethistablewithaJDBCorODBCapplicationthatexpectedscalarcolumns,wecouldcreateaviewthatrepresented
theresultsetasasetofscalarcolumns(threecolumnsfromtheoriginaltable,plusthreemorefromtheSTRUCTfields
ofthearrayelements).Inthefollowingexamples,anycolumnwithanR_*prefixistakenunchangedfromtheoriginal
table,whileanycolumnwithanN_*prefixisextractedfromtheSTRUCTinsidetheARRAY.
CREATE VIEW region_view AS
  SELECT
    r_regionkey,
    r_name,
    r_comment,
    array_field.item.n_nationkey AS n_nationkey,
    array_field.item.n_name AS n_name,
    array_field.n_comment AS n_comment
FROM
  region, region.r_nations AS array_field;
Thenwepointtheapplicationqueriesattheviewratherthantheoriginaltable.Fromtheperspectiveoftheview,
thereare25rowsintheresultset,oneforeachnationineachregion,andqueriescanreferfreelytofieldsrelatedto
theregionorthenation.
-- Retrieve info such as the nation name from the original R_NATIONS array elements.
select n_name from region_view where r_name in ('EUROPE', 'ASIA');
+----------------+
ApacheImpalaGuide|159ImpalaSQLLanguageReference
| n_name         |
+----------------+
| UNITED KINGDOM |
| RUSSIA         |
| ROMANIA        |
| GERMANY        |
| FRANCE         |
| VIETNAM        |
| CHINA          |
| JAPAN          |
| INDONESIA      |
| INDIA          |
+----------------+
-- UNITED STATES in AMERICA and UNITED KINGDOM in EUROPE.
SELECT DISTINCT r_name FROM region_view WHERE n_name LIKE 'UNITED%';
+---------+
| r_name  |
+---------+
| AMERICA |
| EUROPE  |
+---------+
-- For conciseness, we only list some view columns in the SELECT list.
-- SELECT * would bring back all the data, unlike SELECT *
-- queries on the original table with complex type columns.
SELECT r_regionkey, r_name, n_nationkey, n_name FROM region_view LIMIT 7;
+-------------+--------+-------------+----------------+
| r_regionkey | r_name | n_nationkey | n_name         |
+-------------+--------+-------------+----------------+
| 3           | EUROPE | 23          | UNITED KINGDOM |
| 3           | EUROPE | 22          | RUSSIA         |
| 3           | EUROPE | 19          | ROMANIA        |
| 3           | EUROPE | 7           | GERMANY        |
| 3           | EUROPE | 6           | FRANCE         |
| 2           | ASIA   | 21          | VIETNAM        |
| 2           | ASIA   | 18          | CHINA          |
+-------------+--------+-------------+----------------+
TutorialsandExamplesforComplexTypes
Thefollowingexamplesillustratethequerysyntaxforsomecommonusecasesinvolvingcomplextypecolumns.
SampleSchemaandDataforExperimen tingwithImpalaComplexTypes
Thetablesusedforearlierexamplesofcomplextypesyntaxaretrivialoneswithnoactualdata.Themoresubstantial
examplesofthecomplextypefeatureusethesetables,adaptedfromtheschemausedforTPC-Htesting:
SHOW TABLES;
+----------+
| name     |
+----------+
| customer |
| part     |
| region   |
| supplier |
+----------+
DESCRIBE customer;
+--------------+------------------------------------+
| name         | type                               |
+--------------+------------------------------------+
| c_custkey    | bigint                             |
| c_name       | string                             |
| c_address    | string                             |
| c_nationkey  | smallint                           |
| c_phone      | string                             |
| c_acctbal    | decimal(12,2)                      |
| c_mktsegment | string                             |
| c_comment    | string                             |
| c_orders     | array<struct<                      |
|              |   o_orderkey:bigint,               |
160|ApacheImpalaGuideImpalaSQLLanguageReference
|              |   o_orderstatus:string,            |
|              |   o_totalprice:decimal(12,2),      |
|              |   o_orderdate:string,              |
|              |   o_orderpriority:string,          |
|              |   o_clerk:string,                  |
|              |   o_shippriority:int,              |
|              |   o_comment:string,                |
|              |   o_lineitems:array<struct<        |
|              |     l_partkey:bigint,              |
|              |     l_suppkey:bigint,              |
|              |     l_linenumber:int,              |
|              |     l_quantity:decimal(12,2),      |
|              |     l_extendedprice:decimal(12,2), |
|              |     l_discount:decimal(12,2),      |
|              |     l_tax:decimal(12,2),           |
|              |     l_returnflag:string,           |
|              |     l_linestatus:string,           |
|              |     l_shipdate:string,             |
|              |     l_commitdate:string,           |
|              |     l_receiptdate:string,          |
|              |     l_shipinstruct:string,         |
|              |     l_shipmode:string,             |
|              |     l_comment:string               |
|              |   >>                               |
|              | >>                                 |
+--------------+------------------------------------+
DESCRIBE part;
+---------------+---------------+
| name          | type          |
+---------------+---------------+
| p_partkey     | bigint        |
| p_name        | string        |
| p_mfgr        | string        |
| p_brand       | string        |
| p_type        | string        |
| p_size        | int           |
| p_container   | string        |
| p_retailprice | decimal(12,2) |
| p_comment     | string        |
+---------------+---------------+
DESCRIBE region;
+-------------+--------------------------------------------------------------------+
| name        | type                                                               |
+-------------+--------------------------------------------------------------------+
| r_regionkey | smallint                                                           |
| r_name      | string                                                             |
| r_comment   | string                                                             |
| r_nations   | array<struct<n_nationkey:smallint,n_name:string,n_comment:string>> |
+-------------+--------------------------------------------------------------------+
DESCRIBE supplier;
+-------------+----------------------------------------------+
| name        | type                                         |
+-------------+----------------------------------------------+
| s_suppkey   | bigint                                       |
| s_name      | string                                       |
| s_address   | string                                       |
| s_nationkey | smallint                                     |
| s_phone     | string                                       |
| s_acctbal   | decimal(12,2)                                |
| s_comment   | string                                       |
| s_partsupps | array<struct<ps_partkey:bigint,              |
|             | ps_availqty:int,ps_supplycost:decimal(12,2), |
|             | ps_comment:string>>                          |
+-------------+----------------------------------------------+
ApacheImpalaGuide|161ImpalaSQLLanguageReference
Thevolumeofdatausedinthefollowingexamplesis:
SELECT count(*) FROM customer;
+----------+
| count(*) |
+----------+
| 150000   |
+----------+
SELECT count(*) FROM part;
+----------+
| count(*) |
+----------+
| 200000   |
+----------+
SELECT count(*) FROM region;
+----------+
| count(*) |
+----------+
| 5        |
+----------+
SELECT count(*) FROM supplier;
+----------+
| count(*) |
+----------+
| 10000    |
+----------+
ConstructingParquetFileswithComplexColumns UsingHive
ThefollowingexamplesdemonstratetheHivesyntaxtotransformflatdata(tableswithallscalarcolumns)intoParquet
tableswhereImpalacanquerythecomplextypecolumns.Eachexampleshowsthefullsequence ofsteps,including
switchingbackandforthbetweenImpalaandHive.Although thesourcetablecanuseanyfileformat,thedestination
tablemustusetheParquetfileformat.
CreatetablewithARRAYinImpala,loaddatainHive,queryinImpala:
ThisexampleshowsthecycleofcreatingthetablesandqueryingthecomplexdatainImpala,andusingHive(either
thehiveshellorbeeline )forthedataloadingstep.Thedatastartsinflattened,denormaliz edforminatexttable.
Hivewritesthecorresponding Parquetdata,including anARRAYcolumn.ThenImpalacanrunanalyticqueriesonthe
Parquettable,usingjoinnotationtounpacktheARRAYcolumn.
/* Initial DDL and loading of flat, denormalized data happens in impala-shell */CREATE
 TABLE flat_array (country STRING, city STRING);INSERT INTO flat_array VALUES
    ('Canada', 'Toronto') , ('Canada', 'Vancouver') , ('Canada', "St. John\'s")
  , ('Canada', 'Saint John') , ('Canada', 'Montreal') , ('Canada', 'Halifax')
  , ('Canada', 'Winnipeg') , ('Canada', 'Calgary') , ('Canada', 'Saskatoon')
  , ('Canada', 'Ottawa') , ('Canada', 'Yellowknife') , ('France', 'Paris')
  , ('France', 'Nice') , ('France', 'Marseilles') , ('France', 'Cannes')
  , ('Greece', 'Athens') , ('Greece', 'Piraeus') , ('Greece', 'Hania')
  , ('Greece', 'Heraklion') , ('Greece', 'Rethymnon') , ('Greece', 'Fira');
CREATE TABLE complex_array (country STRING, city ARRAY <STRING>) STORED AS PARQUET;
/* Conversion to Parquet and complex and/or nested columns happens in Hive */
INSERT INTO complex_array SELECT country, collect_list(city) FROM flat_array GROUP BY 
country;
Query ID = dev_20151108160808_84477ff2-82bd-4ba4-9a77-554fa7b8c0cb
Total jobs = 1
Launching Job 1 out of 1
162|ApacheImpalaGuideImpalaSQLLanguageReference
...
/* Back to impala-shell again for analytic queries */
REFRESH complex_array;
SELECT country, city.item FROM complex_array, complex_array.city
+---------+-------------+
| country | item        |
+---------+-------------+
| Canada  | Toronto     |
| Canada  | Vancouver   |
| Canada  | St. John's  |
| Canada  | Saint John  |
| Canada  | Montreal    |
| Canada  | Halifax     |
| Canada  | Winnipeg    |
| Canada  | Calgary     |
| Canada  | Saskatoon   |
| Canada  | Ottawa      |
| Canada  | Yellowknife |
| France  | Paris       |
| France  | Nice        |
| France  | Marseilles  |
| France  | Cannes      |
| Greece  | Athens      |
| Greece  | Piraeus     |
| Greece  | Hania       |
| Greece  | Heraklion   |
| Greece  | Rethymnon   |
| Greece  | Fira        |
+---------+-------------+
CreatetablewithSTRUCTandARRAYinImpala,loaddatainHive,queryinImpala:
ThisexampleshowsthecycleofcreatingthetablesandqueryingthecomplexdatainImpala,andusingHive(either
thehiveshellorbeeline )forthedataloadingstep.Thedatastartsinflattened,denormaliz edforminatexttable.
Hivewritesthecorresponding Parquetdata,including aSTRUCTcolumnwithanARRAYfield.ThenImpalacanrun
analyticqueriesontheParquettable,usingjoinnotationtounpacktheARRAYfieldfromtheSTRUCTcolumn.
/* Initial DDL and loading of flat, denormalized data happens in impala-shell */
CREATE TABLE flat_struct_array (continent STRING, country STRING, city STRING);
INSERT INTO flat_struct_array VALUES
    ('North America', 'Canada', 'Toronto') , ('North America', 'Canada', 'Vancouver')
  , ('North America', 'Canada', "St. John\'s") , ('North America', 'Canada', 'Saint 
John')
  , ('North America', 'Canada', 'Montreal') , ('North America', 'Canada', 'Halifax')
  , ('North America', 'Canada', 'Winnipeg') , ('North America', 'Canada', 'Calgary')
  , ('North America', 'Canada', 'Saskatoon') , ('North America', 'Canada', 'Ottawa')
  , ('North America', 'Canada', 'Yellowknife') , ('Europe', 'France', 'Paris')
  , ('Europe', 'France', 'Nice') , ('Europe', 'France', 'Marseilles')
  , ('Europe', 'France', 'Cannes') , ('Europe', 'Greece', 'Athens')
  , ('Europe', 'Greece', 'Piraeus') , ('Europe', 'Greece', 'Hania')
  , ('Europe', 'Greece', 'Heraklion') , ('Europe', 'Greece', 'Rethymnon')
  , ('Europe', 'Greece', 'Fira');
CREATE TABLE complex_struct_array (continent STRING, country STRUCT <name: STRING, city:
 ARRAY <STRING> >) STORED AS PARQUET;
/* Conversion to Parquet and complex and/or nested columns happens in Hive */
INSERT INTO complex_struct_array SELECT continent, named_struct('name', country, 'city',
 collect_list(city)) FROM flat_array_array GROUP BY continent, country;
Query ID = dev_20151108163535_11a4fa53-0003-4638-97e6-ef13cdb8e09e
Total jobs = 1
Launching Job 1 out of 1
ApacheImpalaGuide|163ImpalaSQLLanguageReference
...
/* Back to impala-shell again for analytic queries */
REFRESH complex_struct_array;
SELECT t1.continent, t1.country.name, t2.item
  FROM complex_struct_array t1, t1.country.city t2
+---------------+--------------+-------------+
| continent     | country.name | item        |
+---------------+--------------+-------------+
| Europe        | France       | Paris       |
| Europe        | France       | Nice        |
| Europe        | France       | Marseilles  |
| Europe        | France       | Cannes      |
| Europe        | Greece       | Athens      |
| Europe        | Greece       | Piraeus     |
| Europe        | Greece       | Hania       |
| Europe        | Greece       | Heraklion   |
| Europe        | Greece       | Rethymnon   |
| Europe        | Greece       | Fira        |
| North America | Canada       | Toronto     |
| North America | Canada       | Vancouver   |
| North America | Canada       | St. John's  |
| North America | Canada       | Saint John  |
| North America | Canada       | Montreal    |
| North America | Canada       | Halifax     |
| North America | Canada       | Winnipeg    |
| North America | Canada       | Calgary     |
| North America | Canada       | Saskatoon   |
| North America | Canada       | Ottawa      |
| North America | Canada       | Yellowknife |
+---------------+--------------+-------------+
FlatteningNormalizedTablesintoaSingleTablewithComplexTypes
Onecommonuseforcomplextypesistoembedthecontentsofonetableintoanother.Thetraditional technique of
denormalizing resultsinahugenumberofrowswithsomecolumnvaluesrepeatedoverandover.Withcomplextypes,
youcankeepthesamenumberofrowsasintheoriginalnormalizedtable,andputalltheassociateddatafromthe
othertableinasinglenewcolumn.
Inthisflatteningscenario,youmightfrequentlyuseacolumnthatisanARRAYconsistingofSTRUCTelements,where
eachfieldwithintheSTRUCTcorrespondstoacolumnnamefromthetablethatyouarecombining.
Thefollowingexampleshowsatraditional normalizedlayoutusingtwotables,andthenanequivalentlayoutusing
complextypesinasingletable.
/* Traditional relational design */
-- This table just stores numbers, allowing us to look up details about the employee
-- and details about their vacation time using a three-table join query.
CREATE table employee_vacations
(
  employee_id BIGINT,
  vacation_id BIGINT
)
STORED AS PARQUET;
-- Each kind of information to track gets its own "fact table".
CREATE table vacation_details
(
  vacation_id BIGINT,
  vacation_start TIMESTAMP,
  duration INT
)
STORED AS PARQUET;
-- Any time we print a human-readable report, we join with this table to
-- display info about employee #1234.
164|ApacheImpalaGuideImpalaSQLLanguageReference
CREATE TABLE employee_contact
(
  employee_id BIGINT,
  name STRING,
  address STRING,
  phone STRING,
  email STRING,
  address_type STRING /* 'home', 'work', 'remote', etc. */
)
STORED AS PARQUET;
/* Equivalent flattened schema using complex types */
-- For analytic queries using complex types, we can bundle the dimension table
-- and multiple fact tables into a single table.
CREATE TABLE employee_vacations_nested_types
(
-- We might still use the employee_id for other join queries.
-- The table needs at least one scalar column to serve as an identifier
-- for the complex type columns.
  employee_id BIGINT,
-- Columns of the VACATION_DETAILS table are folded into a STRUCT.
-- We drop the VACATION_ID column because Impala doesn't need
-- synthetic IDs to join a complex type column.
-- Each row from the VACATION_DETAILS table becomes an array element.
  vacation ARRAY < STRUCT <
    vacation_start: TIMESTAMP,
    duration: INT
  >>,
-- The ADDRESS_TYPE column, with a small number of predefined values that are distinct
-- for each employee, makes the EMPLOYEE_CONTACT table a good candidate to turn into a
 MAP,
-- with each row represented as a STRUCT. The string value from ADDRESS_TYPE becomes 
the
-- "key" (the anonymous first field) of the MAP.
  contact MAP < STRING, STRUCT <
    address: STRING,
    phone: STRING,
    email: STRING
  >>
)
STORED AS PARQUET;
Interchanging ComplexTypeTablesandDataFileswithHiveandOtherComponen ts
YoucanproduceParquetdatafilesthroughseveralHadoopcomponen tsandAPIs,asexplainedin
http://www.cloudera.com/documen tation/enterprise/la test/topics/cdh_ig_par quet.html.
IfyouhaveaHive-createdParquettablethatincludesARRAY,STRUCT,orMAPcolumns,Impalacanquerythatsame
tableinCDH5.5/Impala2.3andhigher,subjecttotheusualrestrictionthatallothercolumnsareofdatatypes
supportedbyImpala,andalsothatthefiletypeofthetablemustbeParquet.
IfyouhaveaParquetdatafileproducedoutsideofImpala,Impalacanautomaticallydeducetheappropriatetable
structureusingthesyntaxCREATE TABLE ... LIKE PARQUET ' hdfs_path_of_parquet_file '.InCDH5.5/
Impala2.3andhigher,thisfeatureworksforParquetfilesthatincludeARRAY,STRUCT,orMAPtypes.
/* In impala-shell, find the HDFS data directory of the original table.
DESCRIBE FORMATTED tpch_nested_parquet.customer;
...
| Location: | hdfs://localhost:20500/test-warehouse/tpch_nested_parquet.db/customer   
| NULL |
...
# In the Unix shell, find the path of any Parquet data file in that HDFS directory.
$ hdfs dfs -ls hdfs://localhost:20500/test-warehouse/tpch_nested_parquet.db/customer
Found 4 items
-rwxr-xr-x   3 dev supergroup  171298918 2015-09-22 23:30 
hdfs://localhost:20500/blah/tpch_nested_parquet.db/customer/000000_0
ApacheImpalaGuide|165ImpalaSQLLanguageReference
...
/* Back in impala-shell, use the HDFS path in a CREATE TABLE LIKE PARQUET statement. */
CREATE TABLE customer_ctlp
  LIKE PARQUET 'hdfs://localhost:20500/blah/tpch_nested_parquet.db/customer/000000_0'
  STORED AS PARQUET;
/* Confirm that old and new tables have the same column layout, including complex types.
 */
DESCRIBE tpch_nested_parquet.customer
+--------------+------------------------------------+---------+
| name         | type                               | comment |
+--------------+------------------------------------+---------+
| c_custkey    | bigint                             |         |
| c_name       | string                             |         |
| c_address    | string                             |         |
| c_nationkey  | smallint                           |         |
| c_phone      | string                             |         |
| c_acctbal    | decimal(12,2)                      |         |
| c_mktsegment | string                             |         |
| c_comment    | string                             |         |
| c_orders     | array<struct<                      |         |
|              |   o_orderkey:bigint,               |         |
|              |   o_orderstatus:string,            |         |
|              |   o_totalprice:decimal(12,2),      |         |
|              |   o_orderdate:string,              |         |
|              |   o_orderpriority:string,          |         |
|              |   o_clerk:string,                  |         |
|              |   o_shippriority:int,              |         |
|              |   o_comment:string,                |         |
|              |   o_lineitems:array<struct<        |         |
|              |     l_partkey:bigint,              |         |
|              |     l_suppkey:bigint,              |         |
|              |     l_linenumber:int,              |         |
|              |     l_quantity:decimal(12,2),      |         |
|              |     l_extendedprice:decimal(12,2), |         |
|              |     l_discount:decimal(12,2),      |         |
|              |     l_tax:decimal(12,2),           |         |
|              |     l_returnflag:string,           |         |
|              |     l_linestatus:string,           |         |
|              |     l_shipdate:string,             |         |
|              |     l_commitdate:string,           |         |
|              |     l_receiptdate:string,          |         |
|              |     l_shipinstruct:string,         |         |
|              |     l_shipmode:string,             |         |
|              |     l_comment:string               |         |
|              |   >>                               |         |
|              | >>                                 |         |
+--------------+------------------------------------+---------+
describe customer_ctlp;
+--------------+------------------------------------+-----------------------------+
| name         | type                               | comment                     |
+--------------+------------------------------------+-----------------------------+
| c_custkey    | bigint                             | Inferred from Parquet file. |
| c_name       | string                             | Inferred from Parquet file. |
| c_address    | string                             | Inferred from Parquet file. |
| c_nationkey  | int                                | Inferred from Parquet file. |
| c_phone      | string                             | Inferred from Parquet file. |
| c_acctbal    | decimal(12,2)                      | Inferred from Parquet file. |
| c_mktsegment | string                             | Inferred from Parquet file. |
| c_comment    | string                             | Inferred from Parquet file. |
| c_orders     | array<struct<                      | Inferred from Parquet file. |
|              |   o_orderkey:bigint,               |                             |
|              |   o_orderstatus:string,            |                             |
|              |   o_totalprice:decimal(12,2),      |                             |
|              |   o_orderdate:string,              |                             |
|              |   o_orderpriority:string,          |                             |
|              |   o_clerk:string,                  |                             |
|              |   o_shippriority:int,              |                             |
|              |   o_comment:string,                |                             |
|              |   o_lineitems:array<struct<        |                             |
|              |     l_partkey:bigint,              |                             |
166|ApacheImpalaGuideImpalaSQLLanguageReference
|              |     l_suppkey:bigint,              |                             |
|              |     l_linenumber:int,              |                             |
|              |     l_quantity:decimal(12,2),      |                             |
|              |     l_extendedprice:decimal(12,2), |                             |
|              |     l_discount:decimal(12,2),      |                             |
|              |     l_tax:decimal(12,2),           |                             |
|              |     l_returnflag:string,           |                             |
|              |     l_linestatus:string,           |                             |
|              |     l_shipdate:string,             |                             |
|              |     l_commitdate:string,           |                             |
|              |     l_receiptdate:string,          |                             |
|              |     l_shipinstruct:string,         |                             |
|              |     l_shipmode:string,             |                             |
|              |     l_comment:string               |                             |
|              |   >>                               |                             |
|              | >>                                 |                             |
+--------------+------------------------------------+-----------------------------+
Literals
EachoftheImpaladatatypeshascorresponding notationforliteralvaluesofthattype.Youspecifyliteralvaluesin
SQLstatements,suchasintheSELECTlistorWHEREclauseofaquery,orasanargumenttoafunctioncall.SeeData
Typesonpage101foracompletelistoftypes,ranges,andconversionrules.
NumericLiterals
Towriteliteralsfortheintegertypes(TINYINT ,SMALLINT ,INT,andBIGINT),useasequence ofdigitswithoptional
leadingzeros.
Towriteliteralsforthefloating-pointtypes(DECIMAL ,FLOAT,andDOUBLE),useasequence ofdigitswithanoptional
decimalpoint(.character).Topreserveaccuracyduringarithmeticexpressions,Impalainterpretsfloating-pointliterals
astheDECIMAL typewiththesmallestappropriateprecisionandscale,untilrequiredbythecontexttoconvertthe
resulttoFLOATorDOUBLE.
Integervaluesarepromotedtofloating-pointwhennecessary,basedonthecontext.
Youcanalsouseexponentialnotationbyincluding anecharacter.Forexample,1e6is1times10tothepowerof6
(1million).Anumberinexponentialnotationisalwaysinterpretedasfloating-point.
WhenImpalaencountersanumericliteral,itconsidersthetypetobetheâsmallestâthatcanaccuratelyrepresentthe
value.Thetypeispromotedtolargerormoreaccuratetypesifnecessary,basedonsubsequentpartsofanexpression.
Forexample,youcanseebythetypesImpaladefinesforthefollowingtablecolumnshowitinterpretsthecorresponding
numericliterals:
[localhost:21000] > create table ten as select 10 as x;
+-------------------+
| summary           |
+-------------------+
| Inserted 1 row(s) |
+-------------------+
[localhost:21000] > desc ten;
+------+---------+---------+
| name | type    | comment |
+------+---------+---------+
| x    | tinyint |         |
+------+---------+---------+
[localhost:21000] > create table four_k as select 4096 as x;
+-------------------+
| summary           |
+-------------------+
| Inserted 1 row(s) |
+-------------------+
[localhost:21000] > desc four_k;
ApacheImpalaGuide|167ImpalaSQLLanguageReference
+------+----------+---------+
| name | type     | comment |
+------+----------+---------+
| x    | smallint |         |
+------+----------+---------+
[localhost:21000] > create table one_point_five as select 1.5 as x;
+-------------------+
| summary           |
+-------------------+
| Inserted 1 row(s) |
+-------------------+
[localhost:21000] > desc one_point_five;
+------+--------------+---------+
| name | type         | comment |
+------+--------------+---------+
| x    | decimal(2,1) |         |
+------+--------------+---------+
[localhost:21000] > create table one_point_three_three_three as select 1.333 as x;
+-------------------+
| summary           |
+-------------------+
| Inserted 1 row(s) |
+-------------------+
[localhost:21000] > desc one_point_three_three_three;
+------+--------------+---------+
| name | type         | comment |
+------+--------------+---------+
| x    | decimal(4,3) |         |
+------+--------------+---------+
StringLiterals
Stringliteralsarequotedusingeithersingleordoublequotationmarks.Youcanuseeitherkindofquotesforstring
literals,evenbothkindsfordifferentliteralswithinthesamestatement.
QuotedliteralsareconsideredtobeoftypeSTRING.TousequotedliteralsincontextsrequiringaCHARorVARCHAR
value,CAST()theliteraltoaCHARorVARCHAR oftheappropriatelength.
Escapingspecialcharacters:
Toencodespecialcharacterswithinastringliteral,precedethemwiththebackslash(\)escapecharacter:
â¢\trepresentsatab.
â¢\nrepresentsanewlineorlinefeed.Thismightcauseextralinebreaksinimpala-shell output.
â¢\rrepresentsacarriagereturn.Thismightcauseunusualformatting(makingitappearthatsomecontentis
overwritten)inimpala-shell output.
â¢\brepresentsabackspace.Thismightcauseunusualformatting(makingitappearthatsomecontentisoverwritten)
inimpala-shell output.
â¢\0representsanASCIInulcharacter(notthesameasaSQLNULL).Thismightnotbevisibleinimpala-shell
output.
â¢\ZrepresentsaDOSend-of-file character.Thismightnotbevisibleinimpala-shell output.
â¢\%and\_canbeusedtoescapewildcardcharacterswithinthestringpassedtotheLIKEoperator.
â¢\followedby3octaldigitsrepresentstheASCIIcodeofasinglecharacter;forexample,\101isASCII65,the
characterA.
â¢Usetwoconsecutiv ebackslashes(\\)topreventthebackslashfrombeinginterpretedasanescapecharacter.
â¢Usethebackslashtoescapesingleordoublequotationmarkcharacterswithinastringliteral,iftheliteralis
enclosed bythesametypeofquotationmark.
â¢Ifthecharacterfollowingthe\doesnotrepresentthestartofarecognizedescapesequence, thecharacteris
passedthroughunchanged.
Quoteswithinquotes:
168|ApacheImpalaGuideImpalaSQLLanguageReference
Toincludeasinglequotationcharacterwithinastringvalue,enclosetheliteralwitheithersingleordoublequotation
marks,andoptionallyescapethesinglequoteasa\'sequence. Earlierreleasesrequiredescapingasinglequoteinside
doublequotes.Continueusingescapesequences inthiscaseifyoualsoneedtorunyourSQLcodeonolderversions
ofImpala.
Toincludeadoublequotationcharacterwithinastringvalue,enclosetheliteralwithsinglequotationmarks,no
escapingisnecessaryinthiscase.Or,enclosetheliteralwithdoublequotationmarksandescapethedoublequoteas
a\"sequence.
[localhost:21000] > select "What\'s happening?" as single_within_double,
                  >        'I\'m not sure.' as single_within_single,
                  >        "Homer wrote \"The Iliad\"." as double_within_double,
                  >        'Homer also wrote "The Odyssey".' as double_within_single;
+----------------------+----------------------+--------------------------+---------------------------------+
| single_within_double | single_within_single | double_within_double     | 
double_within_single            |
+----------------------+----------------------+--------------------------+---------------------------------+
| What's happening?    | I'm not sure.        | Homer wrote "The Iliad". | Homer also 
wrote "The Odyssey". |
+----------------------+----------------------+--------------------------+---------------------------------+
FieldterminatorcharacterinCREATETABLE:
Note:TheCREATE TABLE clausesFIELDS TERMINATED BY ,ESCAPED BY ,andLINES TERMINATED
BYhavespecialrulesforthestringliteralusedfortheirargument,becausetheyallrequireasingle
character.Youcanusearegularcharactersurroundedbysingleordoublequotationmarks,anoctal
sequence suchas'\054'(representingacomma),oranintegerintherange'-127'..'128' (with
quotationmarksbutnobackslash),whichisinterpretedasasingle-byteASCIIcharacter.Negative
valuesaresubtractedfrom256;forexample,FIELDS TERMINATED BY '-2' setsthefielddelimiter
toASCIIcode254,theâIcelandic Thornâcharacterusedasadelimiterbysomedataformats.
impala-shell considerations:
Whendealingwithoutputthatincludesnon-ASCII ornon-printablecharacterssuchaslinefeedsandbackspaces,use
theimpala-shell optionstosavetoafile,turnoffprettyprinting,orbothratherthanrelyingonhowtheoutput
appearsvisually.Seeimpala-shell ConfigurationOptionsonpage714foralistofimpala-shell options.
BooleanLiterals
ForBOOLEAN values,theliteralsareTRUEandFALSE,withnoquotationmarksandcase-insensitiv e.
Examples:
select true;
select * from t1 where assertion = false;
select case bool_col when true then 'yes' when false 'no' else 'null' end from t1;
TimestampLiterals
ImpalaautomaticallyconvertsSTRINGliteralsofthecorrectformatintoTIMESTAMP values.Timestampvaluesare
acceptedintheformat'yyyy-MM-dd HH:mm:ss.SSSSSS' ,andcanconsistofjustthedate,orjustthetime,with
orwithoutthefractionalsecondportion.Forexample,youcanspecifyTIMESTAMP valuessuchas'1966-07-30' ,
'08:30:00' ,or'1985-09-25 17:45:30.005' .
Leadingzeroesarenotrequiredinthenumbersrepresentingthedatecomponen t,suchasmonthanddate,orthe
timecomponen t,suchashour,minute,andsecond.Forexample,Impalaacceptsboth'2018-1-1 01:02:03' and
'2018-01-01 1:2:3' asvalid.
InSTRINGtoTIMESTAMP conversions,leadingandtrailingwhitespaces,suchasaspace,atab,anewline,oracarriage
return,areignored.Forexample,Impalatreatsthefollowingasequivalent:'1999-12-01 01:02:03','1999-12-01 01:02:03',
'1999-12-01 01:02:03\r\n\t'.
ApacheImpalaGuide|169ImpalaSQLLanguageReference
WhenyouconvertorcastaSTRINGliteraltoTIMESTAMP ,youcanusethefollowingseparatorsbetweenthedatepart
andthetimepart:
â¢Oneormorespacecharacters
Example:CAST('2001-01-09 01:05:01' AS TIMESTAMP)
â¢ThecharacterâTâ
Example:CAST('2001-01-09T01:05:01' AS TIMESTAMP)
YoucanalsouseINTERVAL expressionstoaddorsubtractfromtimestampliteralvalues,suchas
CAST('1966-07-30' AS TIMESTAMP) + INTERVAL 5 YEARS + INTERVAL 3 DAYS .SeeTIMESTAMPDataType
onpage130fordetails.
Depending onyourdatapipeline,youmightreceivedateandtimedataastext,innotationthatdoesnotexactlymatch
theformatforImpalaTIMESTAMP literals.SeeImpalaDateandTimeFunctions onpage424forfunctions thatcan
convertbetweenavarietyofstringliterals(including differentfieldorder,separators,andtimezonenotation)and
equivalentTIMESTAMP ornumericvalues.
NULL
ThenotionofNULLvaluesisfamiliarfromallkindsofdatabasesystems,buteachSQLdialectcanhaveitsownbehavior
andrestrictionsonNULLvalues.ForBigDataprocessing,theprecisesemanticsofNULLvaluesaresignificant:any
misunder standingcouldleadtoinaccurateresultsormisformatteddata,thatcouldbetime-consuming tocorrectfor
largedatasets.
â¢NULLisadifferentvaluethananemptystring.Theemptystringisrepresentedbyastringliteralwithnothing
inside,""or''.
â¢Inadelimitedtextfile,theNULLvalueisrepresentedbythespecialtoken\N.
â¢WhenImpalainsertsdataintoapartitioned table,andthevalueofoneofthepartitioning columnsisNULLorthe
emptystring,thedataisplacedinaspecialpartitionthatholdsonlythesetwokindsofvalues.Whenthesevalues
arereturnedinaquery,theresultisNULLwhetherthevaluewasoriginallyNULLoranemptystring.Thisbehavior
iscompatiblewiththewayHivetreatsNULLvaluesinpartitioned tables.Hivedoesnotallowemptystringsas
partitionkeys,anditreturnsastringvaluesuchas__HIVE_DEFAULT_PARTITION__ insteadofNULLwhensuch
valuesarereturnedfromaquery.Forexample:
create table t1 (i int) partitioned by (x int, y string);
-- Select an INT column from another table, with all rows going into a special HDFS 
subdirectory
-- named __HIVE_DEFAULT_PARTITION__. Depending on whether one or both of the partitioning
 keys
-- are null, this special directory name occurs at different levels of the physical data
 directory
-- for the table.
insert into t1 partition(x=NULL, y=NULL) select c1 from some_other_table;
insert into t1 partition(x, y=NULL) select c1, c2 from some_other_table;
insert into t1 partition(x=NULL, y) select c1, c3  from some_other_table;
â¢ThereisnoNOT NULL clausewhendefiningacolumntopreventNULLvaluesinthatcolumn.
â¢ThereisnoDEFAULT clausetospecifyanon-NULLdefaultvalue.
â¢IfanINSERToperationmentionssomecolumnsbutnotothers,theunmentionedcolumnscontainNULLforall
insertedrows.
â¢InImpala1.2.1andhigher,allNULLvaluescomeattheendoftheresultsetforORDER BY ... ASC queries,and
atthebeginning oftheresultsetforORDER BY ... DESC queries.Ineffect,NULLisconsideredgreaterthanall
othervaluesforsortingpurposes. TheoriginalImpalabehavioralwaysputNULLvaluesattheend,evenforORDER
BY ... DESC queries.ThenewbehaviorinImpala1.2.1makesImpalamorecompatiblewithotherpopular
databasesystems.InImpala1.2.1andhigher,youcanoverrideorspecifythesortingbehaviorforNULLbyadding
theclauseNULLS FIRST orNULLS LAST attheendoftheORDER BY clause.
170|ApacheImpalaGuideImpalaSQLLanguageReference
Note:BecausetheNULLS FIRST andNULLS LAST keywordsarenotcurrentlyavailableinHive
queries,anyviewsyoucreateusingthosekeywordswillnotbeavailablethroughHive.
â¢InallothercontextsbesidessortingwithORDER BY ,comparing aNULLtoanythingelsereturnsNULL,making
thecomparison meaningless. Forexample,10 > NULL producesNULL,10 < NULL alsoproducesNULL,5
BETWEEN 1 AND NULL producesNULL,andsoon.
Severalbuilt-infunctions serveasshorthand forevaluatingexpressionsandreturningNULL,0,orsomeothersubstitution
valuedepending ontheexpressionresult:ifnull() ,isnull() ,nvl(),nullif() ,nullifzero() ,and
zeroifnull() .SeeImpalaConditional Functions onpage457fordetails.
Kuduconsiderations:
Columns inKudutableshaveanattributethatspecifieswhetherornottheycancontainNULLvalues.Acolumnwith
aNULLattributecancontainnulls.AcolumnwithaNOT NULL attributecannotcontainanynulls,andanINSERT,
UPDATE,orUPSERTstatementwillskipanyrowthatattemptstostoreanullinacolumndesignatedasNOT NULL .
KudutablesdefaulttotheNULLsettingforeachcolumn,exceptcolumnsthatarepartoftheprimarykey.
InadditiontocolumnswiththeNOT NULL attribute,KudutablesalsohaverestrictionsonNULLvaluesincolumnsthat
arepartoftheprimarykeyforatable.NocolumnthatispartoftheprimarykeyinaKudutablecancontainanyNULL
values.
SQLOperators
SQLoperatorsareaclassofcomparison functions thatarewidelyusedwithintheWHEREclausesofSELECTstatements.
ArithmeticOperators
Thearithmeticoperatorsuseexpressionswithaleft-handargument,theoperator,andthen(inmostcases)aright-hand
argument.
Syntax:
left_hand_arg binary_operator right_hand_arg
unary_operator single_arg
â¢+and-:Canbeusedeitherasunaryorbinaryoperators.
âWithunarynotation,suchas+5,-2.5,or-col_name ,theymultiplytheirsinglenumericargumentby+1
or-1.Therefore,unary+returnsitsargumentunchanged,whileunary-flipsthesignofitsargument.
Although youcandoubleuptheseoperatorsinexpressionssuchas++5(alwayspositive)or-+2or+-2(both
alwaysnegative),youcannotdoubletheunaryminusoperatorbecause--isinterpretedasthestartofa
comment.(Youcanuseadoubleunaryminusoperatorifyouseparatethe-characters,forexamplewitha
spaceorparentheses.)
âWithbinarynotation,suchas2+2,5-2.5,orcol1 + col2,theyaddorsubtractrespectivelytheright-hand
argumentto(orfrom)theleft-handargument.Bothargumentsmustbeofnumerictypes.
â¢*and/:Multiplicationanddivisionrespectively.Bothargumentsmustbeofnumerictypes.
Whenmultiplying ,theshorterargumentispromotedifnecessary(suchasSMALLINT toINTorBIGINT,orFLOAT
toDOUBLE),andthentheresultispromotedagaintothenextlargertype.Thus,multiplying aTINYINT andan
INTproducesaBIGINTresult.Multiplying aFLOATandaFLOATproducesaDOUBLEresult.Multiplying aFLOAT
andaDOUBLEoraDOUBLEandaDOUBLEproducesaDECIMAL(38,17) ,becauseDECIMAL valuescanrepresent
muchlargerandmoreprecisevaluesthanDOUBLE.
Whendividing,ImpalaalwaystreatstheargumentsandresultasDOUBLEvaluestoavoidlosingprecision.Ifyou
needtoinserttheresultsofadivisionoperationintoaFLOATcolumn,usetheCAST()functiontoconvertthe
resulttothecorrecttype.
ApacheImpalaGuide|171ImpalaSQLLanguageReference
â¢DIV:Integerdivision.Argumentsarenotpromotedtoafloating-pointtype,andanyfractionalresultisdiscarded.
Forexample,13 DIV 7 returns1,14 DIV 7 returns2,and15 DIV 7 returns2.Thisoperatoristhesameas
theQUOTIENT() function.
â¢%:Modulooperator.Returnstheremainder oftheleft-handargumentdividedbytheright-handargument.Both
argumentsmustbeofoneoftheintegertypes.
â¢&,|,~,and^:BitwiseoperatorsthatreturnthelogicalAND,logicalOR,NOT,orlogicalXOR(exclusiveOR)oftheir
argumentvalues.Bothargumentsmustbeofoneoftheintegertypes.Iftheargumentsareofdifferenttype,the
argumentwiththesmallertypeisimplicitly extendedtomatchtheargumentwiththelongertype.
Youcanchainasequence ofarithmeticexpressions,optionallygroupingthemwithparentheses.
Thearithmeticoperatorsgenerallydonothaveequivalentcallingconventionsusingfunctional notation.Forexample,
priortoCDH5.4/Impala2.2,thereisnoMOD()functionequivalenttothe%modulooperator.Conversely,thereare
somearithmeticfunctions thatdonothaveacorresponding operator.Forexample,forexponentiationyouusethe
POW()function, butthereisno**exponentiationoperator.SeeImpalaMathematicalFunctions onpage397forthe
arithmeticfunctions youcanuse.
Complextypeconsiderations:
Toaccessacolumnwithacomplextype(ARRAY,STRUCT,orMAP)inanaggregationfunction, youunpacktheindividual
elementsusingjoinnotationinthequery,andthenapplythefunctiontothefinalscalaritem,field,key,orvalueat
thebottomofanynestedtypehierarchyinthecolumn.SeeComplexTypes(CDH5.5orhigheronly)onpage139for
detailsaboutusingcomplextypesinImpala.
Thefollowingexampledemonstratescallstoseveralaggregationfunctions usingvaluesfromacolumncontaining
nestedcomplextypes(anARRAYofSTRUCTitems).Thearrayisunpackedinsidethequeryusingjoinnotation.The
arrayelementsarereferencedusingtheITEMpseudocolumn,andthestructurefieldsinsidethearrayelementsare
referencedusingdotnotation.NumericvaluessuchasSUM()andAVG()arecomputedusingthenumericR_NATIONKEY
field,andthegeneral-purpose MAX()andMIN()valuesarecomputedfromthestringN_NAMEfield.
describe region;
+-------------+-------------------------+---------+
| name        | type                    | comment |
+-------------+-------------------------+---------+
| r_regionkey | smallint                |         |
| r_name      | string                  |         |
| r_comment   | string                  |         |
| r_nations   | array<struct<           |         |
|             |   n_nationkey:smallint, |         |
|             |   n_name:string,        |         |
|             |   n_comment:string      |         |
|             | >>                      |         |
+-------------+-------------------------+---------+
select r_name, r_nations.item.n_nationkey
  from region, region.r_nations as r_nations
order by r_name, r_nations.item.n_nationkey;
+-------------+------------------+
| r_name      | item.n_nationkey |
+-------------+------------------+
| AFRICA      | 0                |
| AFRICA      | 5                |
| AFRICA      | 14               |
| AFRICA      | 15               |
| AFRICA      | 16               |
| AMERICA     | 1                |
| AMERICA     | 2                |
| AMERICA     | 3                |
| AMERICA     | 17               |
| AMERICA     | 24               |
| ASIA        | 8                |
| ASIA        | 9                |
| ASIA        | 12               |
| ASIA        | 18               |
| ASIA        | 21               |
172|ApacheImpalaGuideImpalaSQLLanguageReference
| EUROPE      | 6                |
| EUROPE      | 7                |
| EUROPE      | 19               |
| EUROPE      | 22               |
| EUROPE      | 23               |
| MIDDLE EAST | 4                |
| MIDDLE EAST | 10               |
| MIDDLE EAST | 11               |
| MIDDLE EAST | 13               |
| MIDDLE EAST | 20               |
+-------------+------------------+
select
  r_name,
  count(r_nations.item.n_nationkey) as count,
  sum(r_nations.item.n_nationkey) as sum,
  avg(r_nations.item.n_nationkey) as avg,
  min(r_nations.item.n_name) as minimum,
  max(r_nations.item.n_name) as maximum,
  ndv(r_nations.item.n_nationkey) as distinct_vals
from
  region, region.r_nations as r_nations
group by r_name
order by r_name;
+-------------+-------+-----+------+-----------+----------------+---------------+
| r_name      | count | sum | avg  | minimum   | maximum        | distinct_vals |
+-------------+-------+-----+------+-----------+----------------+---------------+
| AFRICA      | 5     | 50  | 10   | ALGERIA   | MOZAMBIQUE     | 5             |
| AMERICA     | 5     | 47  | 9.4  | ARGENTINA | UNITED STATES  | 5             |
| ASIA        | 5     | 68  | 13.6 | CHINA     | VIETNAM        | 5             |
| EUROPE      | 5     | 77  | 15.4 | FRANCE    | UNITED KINGDOM | 5             |
| MIDDLE EAST | 5     | 58  | 11.6 | EGYPT     | SAUDI ARABIA   | 5             |
+-------------+-------+-----+------+-----------+----------------+---------------+
Youcannotrefertoacolumnwithacomplexdatatype(ARRAY,STRUCT,orMAP)directlyinanoperator.Youcanapply
operatorsonlytoscalarvaluesthatmakeupacomplextype(thefieldsofaSTRUCT,theitemsofanARRAY,orthekey
orvalueportionofaMAP)aspartofajoinquerythatreferstothescalarvalueusingtheappropriatedotnotationor
ITEM,KEY,orVALUEpseudocolumnnames.
ThefollowingexampleshowshowtodoanarithmeticoperationusinganumericfieldofaSTRUCTtypethatisanitem
withinanARRAYcolumn.OncethescalarnumericvalueR_NATIONKEY isextracted,itcanbeusedinanarithmetic
expression,suchasmultiplying by10:
-- The SMALLINT is a field within an array of structs.
describe region;
+-------------+-------------------------+---------+
| name        | type                    | comment |
+-------------+-------------------------+---------+
| r_regionkey | smallint                |         |
| r_name      | string                  |         |
| r_comment   | string                  |         |
| r_nations   | array<struct<           |         |
|             |   n_nationkey:smallint, |         |
|             |   n_name:string,        |         |
|             |   n_comment:string      |         |
|             | >>                      |         |
+-------------+-------------------------+---------+
-- When we refer to the scalar value using dot notation,
-- we can use arithmetic and comparison operators on it
-- like any other number.
select r_name, nation.item.n_name, nation.item.n_nationkey * 10
  from region, region.r_nations as nation
where nation.item.n_nationkey < 5;
+-------------+-------------+------------------------------+
| r_name      | item.n_name | nation.item.n_nationkey * 10 |
+-------------+-------------+------------------------------+
| AMERICA     | CANADA      | 30                           |
| AMERICA     | BRAZIL      | 20                           |
| AMERICA     | ARGENTINA   | 10                           |
ApacheImpalaGuide|173ImpalaSQLLanguageReference
| MIDDLE EAST | EGYPT       | 40                           |
| AFRICA      | ALGERIA     | 0                            |
+-------------+-------------+------------------------------+
BETWEEN Operator
InaWHEREclause,comparesanexpressiontobothalowerandupperbound.Thecomparison issuccessfulisthe
expressionisgreaterthanorequaltothelowerbound,andlessthanorequaltotheupperbound.Iftheboundvalues
areswitched,sothelowerboundisgreaterthantheupperbound,doesnotmatchanyvalues.
Syntax:
expression  BETWEEN lower_bound  AND upper_bound
Datatypes:Typicallyusedwithnumericdatatypes.Workswithanydatatype,although notverypracticalforBOOLEAN
values.(BETWEEN false AND true willmatchallBOOLEAN values.)UseCAST()ifnecessarytoensurethelower
andupperboundvaluesarecompatibletypes.Callstringordate/timefunctions ifnecessarytoextractortransform
therelevantportiontocompare,especially ifthevaluecanbetransformedintoanumber.
Usagenotes:
Becarefulwhenusingshortstringoperands.Alongerstringthatstartswiththeupperboundvaluewillnotbeincluded,
becauseitisconsideredgreaterthantheupperbound.Forexample,BETWEEN 'A' and 'M' wouldnotmatchthe
stringvalue'Midway' .Usefunctions suchasupper() ,lower() ,substr() ,trim(),andsoonifnecessarytoensure
thecomparison worksasexpected.
Complextypeconsiderations:
Youcannotrefertoacolumnwithacomplexdatatype(ARRAY,STRUCT,orMAP)directlyinanoperator.Youcanapply
operatorsonlytoscalarvaluesthatmakeupacomplextype(thefieldsofaSTRUCT,theitemsofanARRAY,orthekey
orvalueportionofaMAP)aspartofajoinquerythatreferstothescalarvalueusingtheappropriatedotnotationor
ITEM,KEY,orVALUEpseudocolumnnames.
Examples:
-- Retrieve data for January through June, inclusive.
select c1 from t1 where month between 1 and 6 ;
-- Retrieve data for names beginning with 'A' through 'M' inclusive.
-- Only test the first letter to ensure all the values starting with 'M' are matched.
-- Do a case-insensitive comparison to match names with various capitalization 
conventions.
select last_name from customers where upper(substr(last_name,1,1)) between 'A' and 'M' ;
-- Retrieve data for only the first week of each month.
select count(distinct visitor_id)) from web_traffic where dayofmonth(when_viewed) between
 1 and 7 ;
ThefollowingexampleshowshowtodoaBETWEEN comparison usinganumericfieldofaSTRUCTtypethatisanitem
withinanARRAYcolumn.OncethescalarnumericvalueR_NATIONKEY isextracted,itcanbeusedinacomparison
operator:
-- The SMALLINT is a field within an array of structs.
describe region;
+-------------+-------------------------+---------+
| name        | type                    | comment |
+-------------+-------------------------+---------+
| r_regionkey | smallint                |         |
| r_name      | string                  |         |
| r_comment   | string                  |         |
| r_nations   | array<struct<           |         |
|             |   n_nationkey:smallint, |         |
|             |   n_name:string,        |         |
|             |   n_comment:string      |         |
174|ApacheImpalaGuideImpalaSQLLanguageReference
|             | >>                      |         |
+-------------+-------------------------+---------+
-- When we refer to the scalar value using dot notation,
-- we can use arithmetic and comparison operators on it
-- like any other number.
select r_name, nation.item.n_name, nation.item.n_nationkey
from region, region.r_nations as nation
where nation.item.n_nationkey between 3 and 5
+-------------+-------------+------------------+
| r_name      | item.n_name | item.n_nationkey |
+-------------+-------------+------------------+
| AMERICA     | CANADA      | 3                |
| MIDDLE EAST | EGYPT       | 4                |
| AFRICA      | ETHIOPIA    | 5                |
+-------------+-------------+------------------+
Comparison Operators
Impalasupports thefamiliarcomparison operatorsforchecking equalityandsortorderforthecolumndatatypes:
Syntax:
left_hand_expression comparison_operator right_hand_expression
â¢=,!=,<>:applytoallscalartypes.
â¢<,<=,>,>=:applytoallscalartypes;forBOOLEAN ,TRUEisconsideredgreaterthanFALSE.
Alternatives:
TheINandBETWEEN operatorsprovideshorthand notationforexpressingcombinationsofequality,lessthan,and
greaterthancomparisons withasingleoperator.
Becausecomparing anyvaluetoNULLproducesNULLratherthanTRUEorFALSE,usetheIS NULL andIS NOT
NULLoperatorstocheckifavalueisNULLornot.
Complextypeconsiderations:
Youcannotrefertoacolumnwithacomplexdatatype(ARRAY,STRUCT,orMAP)directlyinanoperator.Youcanapply
operatorsonlytoscalarvaluesthatmakeupacomplextype(thefieldsofaSTRUCT,theitemsofanARRAY,orthekey
orvalueportionofaMAP)aspartofajoinquerythatreferstothescalarvalueusingtheappropriatedotnotationor
ITEM,KEY,orVALUEpseudocolumnnames.
ThefollowingexampleshowshowtodoanarithmeticoperationusinganumericfieldofaSTRUCTtypethatisanitem
withinanARRAYcolumn.OncethescalarnumericvalueR_NATIONKEY isextracted,itcanbeusedwithacomparison
operatorsuchas<:
-- The SMALLINT is a field within an array of structs.
describe region;
+-------------+-------------------------+---------+
| name        | type                    | comment |
+-------------+-------------------------+---------+
| r_regionkey | smallint                |         |
| r_name      | string                  |         |
| r_comment   | string                  |         |
| r_nations   | array<struct<           |         |
|             |   n_nationkey:smallint, |         |
|             |   n_name:string,        |         |
|             |   n_comment:string      |         |
|             | >>                      |         |
+-------------+-------------------------+---------+
-- When we refer to the scalar value using dot notation,
-- we can use arithmetic and comparison operators on it
-- like any other number.
select r_name, nation.item.n_name, nation.item.n_nationkey
from region, region.r_nations as nation
ApacheImpalaGuide|175ImpalaSQLLanguageReference
where nation.item.n_nationkey < 5
+-------------+-------------+------------------+
| r_name      | item.n_name | item.n_nationkey |
+-------------+-------------+------------------+
| AMERICA     | CANADA      | 3                |
| AMERICA     | BRAZIL      | 2                |
| AMERICA     | ARGENTINA   | 1                |
| MIDDLE EAST | EGYPT       | 4                |
| AFRICA      | ALGERIA     | 0                |
+-------------+-------------+------------------+
EXISTSOperator
TheEXISTSoperatortestswhetherasubqueryreturnsanyresults.Youtypicallyuseittofindvaluesfromonetable
thathavecorresponding valuesinanothertable.
Theconverse,NOT EXISTS ,helpstofindallthevaluesfromonetablethatdonothaveanycorresponding valuesin
anothertable.
Syntax:
EXISTS ( subquery )
NOT EXISTS ( subquery )
Usagenotes:
Thesubquerycanrefertoadifferenttablethantheouterqueryblock,orthesametable.Forexample,youmightuse
EXISTSorNOT EXISTS tochecktheexistenceofparent/childrelationshipsbetweentwocolumnsofthesametable.
Youcanalsouseoperatorsandfunctioncallswithinthesubquerytotestforotherkindsofrelationshipsotherthan
strictequality.Forexample,youmightuseacalltoCOUNT() inthesubquerytocheckwhetherthenumberofmatching
valuesishigherorlowerthansomelimit.YoumightcallaUDFinthesubquerytocheckwhethervaluesinonetable
matchesahashedrepresentationofthosesamevaluesinadifferenttable.
NULLconsiderations:
Ifthesubqueryreturnsanyvalueatall(evenNULL),EXISTSreturnsTRUEandNOT EXISTS returnsfalse.
ThefollowingexampleshowshowevenwhenthesubqueryreturnsonlyNULLvalues,EXISTSstillreturnsTRUEand
thusmatchesalltherowsfromthetableintheouterqueryblock.
[localhost:21000] > create table all_nulls (x int);
[localhost:21000] > insert into all_nulls values (null), (null), (null);
[localhost:21000] > select y from t2 where exists (select x from all_nulls);
+---+
| y |
+---+
| 2 |
| 4 |
| 6 |
+---+
However,ifthetableinthesubqueryisemptyandsothesubqueryreturnsanemptyresultset,EXISTSreturnsFALSE:
[localhost:21000] > create table empty (x int);
[localhost:21000] > select y from t2 where exists (select x from empty);
[localhost:21000] >
Addedin:CDH5.2.0/Impala2.0.0
Restrictions:
Correlatedsubqueries usedinEXISTSandINoperatorscannotincludeaLIMITclause.
PriortoCDH5.8/Impala2.6,theNOT EXISTS operatorrequiredacorrelatedsubquery.InCDH5.8/Impala2.6and
higher,NOT EXISTS workswithuncorrelatedqueriesalso.
176|ApacheImpalaGuideImpalaSQLLanguageReference
Complextypeconsiderations:
Youcannotrefertoacolumnwithacomplexdatatype(ARRAY,STRUCT,orMAP)directlyinanoperator.Youcanapply
operatorsonlytoscalarvaluesthatmakeupacomplextype(thefieldsofaSTRUCT,theitemsofanARRAY,orthekey
orvalueportionofaMAP)aspartofajoinquerythatreferstothescalarvalueusingtheappropriatedotnotationor
ITEM,KEY,orVALUEpseudocolumnnames.
Examples:
Thefollowingexamplesrefertothesesimpletablescontainingsmallsetsofintegersorstrings:
[localhost:21000] > create table t1 (x int);
[localhost:21000] > insert into t1 values (1), (2), (3), (4), (5), (6);
[localhost:21000] > create table t2 (y int);
[localhost:21000] > insert into t2 values (2), (4), (6);
[localhost:21000] > create table t3 (z int);
[localhost:21000] > insert into t3 values (1), (3), (5);
[localhost:21000] > create table month_names (m string);
[localhost:21000] > insert into month_names values
                  > ('January'), ('February'), ('March'),
                  > ('April'), ('May'), ('June'), ('July'),
                  > ('August'), ('September'), ('October'),
                  > ('November'), ('December');
Thefollowingexampleshowsacorrelatedsubquerythatfindsallthevaluesinonetablethatexistinanothertable.
ForeachvalueXfromT1,thequerychecksiftheYcolumnofT2containsanidenticalvalue,andtheEXISTSoperator
returnsTRUEorFALSEasappropriateineachcase.
localhost:21000] > select x from t1 where exists (select y from t2 where t1.x = y);
+---+
| x |
+---+
| 2 |
| 4 |
| 6 |
+---+
Anuncorrelatedqueryislessinterestinginthiscase.BecausethesubqueryalwaysreturnsTRUE,allrowsfromT1are
returned.Ifthetablecontentswherechangedsothatthesubquerydidnotmatchanyrows,noneoftherowsfrom
T1wouldbereturned.
[localhost:21000] > select x from t1 where exists (select y from t2 where y > 5);
+---+
| x |
+---+
| 1 |
| 2 |
| 3 |
| 4 |
| 5 |
| 6 |
+---+
Thefollowingexampleshowshowanuncorrelatedsubquerycantestfortheexistenceofsomeconditionwithina
table.ByusingLIMIT 1 oranaggregatefunction, thequeryreturnsasingleresultornoresultbasedonwhetherthe
subquerymatchesanyrows.Here,weknowthatT1andT2containsomeevennumbers,butT3doesnot.
[localhost:21000] > select "contains an even number" from t1 where exists (select x from
 t1 where x % 2 = 0) limit 1;
+---------------------------+
| 'contains an even number' |
+---------------------------+
| contains an even number   |
+---------------------------+
ApacheImpalaGuide|177ImpalaSQLLanguageReference
[localhost:21000] > select "contains an even number" as assertion from t1 where exists
 (select x from t1 where x % 2 = 0) limit 1;
+-------------------------+
| assertion               |
+-------------------------+
| contains an even number |
+-------------------------+
[localhost:21000] > select "contains an even number" as assertion from t2 where exists
 (select x from t2 where y % 2 = 0) limit 1;
ERROR: AnalysisException: couldn't resolve column reference: 'x'
[localhost:21000] > select "contains an even number" as assertion from t2 where exists
 (select y from t2 where y % 2 = 0) limit 1;
+-------------------------+
| assertion               |
+-------------------------+
| contains an even number |
+-------------------------+
[localhost:21000] > select "contains an even number" as assertion from t3 where exists
 (select z from t3 where z % 2 = 0) limit 1;
[localhost:21000] >
Thefollowingexamplefindsnumbersinonetablethatare1greaterthannumbersfromanothertable.TheEXISTS
notationissimplerthananequivalentCROSS JOIN betweenthetables.(Theexamplethenalsoillustrateshowthe
sametestcouldbeperformedusinganINoperator.)
[localhost:21000] > select x from t1 where exists (select y from t2 where x = y + 1);
+---+
| x |
+---+
| 3 |
| 5 |
+---+
[localhost:21000] > select x from t1 where x in (select y + 1 from t2);
+---+
| x |
+---+
| 3 |
| 5 |
+---+
Thefollowingexamplefindsvaluesfromonetablethatdonotexistinanothertable.
[localhost:21000] > select x from t1 where not exists (select y from t2 where x = y);
+---+
| x |
+---+
| 1 |
| 3 |
| 5 |
+---+
ThefollowingexampleusestheNOT EXISTS operatortofindalltheleafnodesintree-structureddata.Thissimplified
âtreeoflifeâhasmultiplelevels(class,order,family,andsoon),witheachitempointingupwardthroughaPARENT
pointer.Theexamplerunsanouterqueryandasubqueryonthesametable,returningonlythoseitemswhoseID
valueisnotreferencedbythePARENTofanyotheritem.
[localhost:21000] > create table tree (id int, parent int, name string);
[localhost:21000] > insert overwrite tree values
                  > (0, null, "animals"),
                  > (1, 0, "placentals"),
                  > (2, 0, "marsupials"),
                  > (3, 1, "bats"),
                  > (4, 1, "cats"),
                  > (5, 2, "kangaroos"),
                  > (6, 4, "lions"),
                  > (7, 4, "tigers"),
                  > (8, 5, "red kangaroo"),
                  > (9, 2, "wallabies");
178|ApacheImpalaGuideImpalaSQLLanguageReference
[localhost:21000] > select name as "leaf node" from tree one
                  > where not exists (select parent from tree two where one.id = 
two.parent);
+--------------+
| leaf node    |
+--------------+
| bats         |
| lions        |
| tigers       |
| red kangaroo |
| wallabies    |
+--------------+
Relatedinformation:
Subqueries inImpalaSELECTStatementsonpage312
ILIKEOperator
Acase-insensitiv ecomparison operatorforSTRINGdata,withbasicwildcardcapabilityusing_tomatchasingle
characterand%tomatchmultiplecharacters.Theargumentexpressionmustmatchtheentirestringvalue.Typically,
itismoreefficienttoputany%wildcardmatchattheendofthestring.
Thisoperator,availableinCDH5.7/Impala2.5andhigher,istheequivalentoftheLIKEoperator,butwith
case-insensitiv ecomparisons.
Syntax:
string_expression  ILIKE wildcard_expression
string_expression  NOT ILIKE wildcard_expression
Complextypeconsiderations:
Youcannotrefertoacolumnwithacomplexdatatype(ARRAY,STRUCT,orMAP)directlyinanoperator.Youcanapply
operatorsonlytoscalarvaluesthatmakeupacomplextype(thefieldsofaSTRUCT,theitemsofanARRAY,orthekey
orvalueportionofaMAP)aspartofajoinquerythatreferstothescalarvalueusingtheappropriatedotnotationor
ITEM,KEY,orVALUEpseudocolumnnames.
Examples:
Inthefollowingexamples,stringsthatarethesameexceptfordifferencesinuppercaseandlowercasematchsuccessfully
withILIKE,butdonotmatchwithLIKE:
select 'fooBar' ilike 'FOOBAR';
+-------------------------+
| 'foobar' ilike 'foobar' |
+-------------------------+
| true                    |
+-------------------------+
select 'fooBar' like 'FOOBAR';
+------------------------+
| 'foobar' like 'foobar' |
+------------------------+
| false                  |
+------------------------+
select 'FOOBAR' ilike 'f%';
+---------------------+
| 'foobar' ilike 'f%' |
+---------------------+
| true                |
+---------------------+
select 'FOOBAR' like 'f%';
+--------------------+
| 'foobar' like 'f%' |
+--------------------+
ApacheImpalaGuide|179ImpalaSQLLanguageReference
| false              |
+--------------------+
select 'ABCXYZ' not ilike 'ab_xyz';
+-----------------------------+
| not 'abcxyz' ilike 'ab_xyz' |
+-----------------------------+
| false                       |
+-----------------------------+
select 'ABCXYZ' not like 'ab_xyz';
+----------------------------+
| not 'abcxyz' like 'ab_xyz' |
+----------------------------+
| true                       |
+----------------------------+
Relatedinformation:
Forcase-sensitiv ecomparisons, seeLIKEOperatoronpage186.Foramoregeneralkindofsearchoperatorusingregular
expressions,seeREGEXPOperatoronpage189oritscase-insensitiv ecounterpartIREGEXPOperatoronpage182.
INOperator
TheINoperatorcomparesanargumentvaluetoasetofvalues,andreturnsTRUEiftheargumentmatchesanyvalue
intheset.TheNOT INoperatorreversesthecomparison, andchecksiftheargumentvalueisnotpartofasetof
values.
Syntax:
expression  IN (expression  [, expression ])
expression  IN (subquery )
expression  NOT IN ( expression  [, expression ])
expression  NOT IN ( subquery )
Theleft-handexpressionandthesetofcomparison valuesmustbeofcompatibletypes.
Theleft-handexpressionmustconsistonlyofasinglevalue,notatuple.Although theleft-handexpressionistypically
acolumnname,itcouldalsobesomeothervalue.Forexample,theWHEREclausesWHERE id IN (5) andWHERE
5 IN (id) producethesameresults.
Thesetofvaluestocheckagainstcanbespecified asconstants,functioncalls,columnnames,orotherexpressionsin
thequerytext.ThemaximumnumberofexpressionsintheINlistis9999.(Themaximumnumberofelementsofa
singleexpressionis10,000items,andtheINoperatoritselfcountsasone.)
InImpala2.0andhigher,thesetofvaluescanalsobegeneratedbyasubquery.INcanevaluateanunlimitednumber
ofresultsusingasubquery.
Usagenotes:
AnyexpressionusingtheINoperatorcouldberewrittenasaseriesofequalitytestsconnectedwithOR,buttheIN
syntaxisoftenclearer,moreconcise,andeasierforImpalatooptimize.Forexample,withpartitioned tables,queries
frequentlyuseINclausestofilterdatabycomparing thepartition keycolumnstospecificvalues.
NULLconsiderations:
Iftherereallyisamatchingnon-nullvalue,INreturnsTRUE:
[localhost:21000] > select 1 in (1,null,2,3);
+----------------------+
| 1 in (1, null, 2, 3) |
+----------------------+
| true                 |
+----------------------+
[localhost:21000] > select 1 not in (1,null,2,3);
+--------------------------+
180|ApacheImpalaGuideImpalaSQLLanguageReference
| 1 not in (1, null, 2, 3) |
+--------------------------+
| false                    |
+--------------------------+
Ifthesearchedvalueisnotfoundinthecomparison values,andthecomparison valuesincludeNULL,theresultis
NULL:
[localhost:21000] > select 5 in (1,null,2,3);
+----------------------+
| 5 in (1, null, 2, 3) |
+----------------------+
| NULL                 |
+----------------------+
[localhost:21000] > select 5 not in (1,null,2,3);
+--------------------------+
| 5 not in (1, null, 2, 3) |
+--------------------------+
| NULL                     |
+--------------------------+
[localhost:21000] > select 1 in (null);
+-------------+
| 1 in (null) |
+-------------+
| NULL        |
+-------------+
[localhost:21000] > select 1 not in (null);
+-----------------+
| 1 not in (null) |
+-----------------+
| NULL            |
+-----------------+
Iftheleft-handargumentisNULL,INalwaysreturnsNULL.Thisruleappliesevenifthecomparison valuesinclude
NULL.
[localhost:21000] > select null in (1,2,3);
+-------------------+
| null in (1, 2, 3) |
+-------------------+
| NULL              |
+-------------------+
[localhost:21000] > select null not in (1,2,3);
+-----------------------+
| null not in (1, 2, 3) |
+-----------------------+
| NULL                  |
+-----------------------+
[localhost:21000] > select null in (null);
+----------------+
| null in (null) |
+----------------+
| NULL           |
+----------------+
[localhost:21000] > select null not in (null);
+--------------------+
| null not in (null) |
+--------------------+
| NULL               |
+--------------------+
Addedin:AvailableinearlierImpalareleases,butnewcapabilities wereaddedinCDH5.2.0/Impala2.0.0
Complextypeconsiderations:
Youcannotrefertoacolumnwithacomplexdatatype(ARRAY,STRUCT,orMAP)directlyinanoperator.Youcanapply
operatorsonlytoscalarvaluesthatmakeupacomplextype(thefieldsofaSTRUCT,theitemsofanARRAY,orthekey
orvalueportionofaMAP)aspartofajoinquerythatreferstothescalarvalueusingtheappropriatedotnotationor
ITEM,KEY,orVALUEpseudocolumnnames.
ApacheImpalaGuide|181ImpalaSQLLanguageReference
ThefollowingexampleshowshowtodoanarithmeticoperationusinganumericfieldofaSTRUCTtypethatisanitem
withinanARRAYcolumn.OncethescalarnumericvalueR_NATIONKEY isextracted,itcanbeusedinanarithmetic
expression,suchasmultiplying by10:
-- The SMALLINT is a field within an array of structs.
describe region;
+-------------+-------------------------+---------+
| name        | type                    | comment |
+-------------+-------------------------+---------+
| r_regionkey | smallint                |         |
| r_name      | string                  |         |
| r_comment   | string                  |         |
| r_nations   | array<struct<           |         |
|             |   n_nationkey:smallint, |         |
|             |   n_name:string,        |         |
|             |   n_comment:string      |         |
|             | >>                      |         |
+-------------+-------------------------+---------+
-- When we refer to the scalar value using dot notation,
-- we can use arithmetic and comparison operators on it
-- like any other number.
select r_name, nation.item.n_name, nation.item.n_nationkey
from region, region.r_nations as nation
where nation.item.n_nationkey in (1,3,5)
+---------+-------------+------------------+
| r_name  | item.n_name | item.n_nationkey |
+---------+-------------+------------------+
| AMERICA | CANADA      | 3                |
| AMERICA | ARGENTINA   | 1                |
| AFRICA  | ETHIOPIA    | 5                |
+---------+-------------+------------------+
Restrictions:
Correlatedsubqueries usedinEXISTSandINoperatorscannotincludeaLIMITclause.
Examples:
-- Using IN is concise and self-documenting.
SELECT * FROM t1 WHERE c1 IN (1,2,10);
-- Equivalent to series of = comparisons ORed together.
SELECT * FROM t1 WHERE c1 = 1 OR c1 = 2 OR c1 = 10;
SELECT c1 AS "starts with vowel" FROM t2 WHERE upper(substr(c1,1,1)) IN 
('A','E','I','O','U');
SELECT COUNT(DISTINCT(visitor_id)) FROM web_traffic WHERE month IN 
('January','June','July');
Relatedinformation:
Subqueries inImpalaSELECTStatementsonpage312
IREGEXPOperator
Testswhetheravaluematchesaregularexpression,usingcase-insensitiv estringcomparisons. UsesthePOSIXregular
expressionsyntaxwhere^and$matchthebeginning andendofthestring,.representsanysinglecharacter,*
representsasequence ofzeroormoreitems,+representsasequence ofoneormoreitems,?producesanon-greedy
match,andsoon.
Thisoperator,availableinCDH5.7/Impala2.5andhigher,istheequivalentoftheREGEXPoperator,butwith
case-insensitiv ecomparisons.
Syntax:
string_expression  IREGEXP regular_expression
182|ApacheImpalaGuideImpalaSQLLanguageReference
Usagenotes:
The|symbolisthealternationoperator,typicallyusedwithin()tomatchdifferentsequences. The()groupsdonot
allowbackreferences.Toretrievethepartofavaluematchedwithina()section,usetheregexp_extract() built-in
function. (Currently,thereisnotanycase-insensitiv eequivalentfortheregexp_extract() function.)
InImpala1.3.1andhigher,theREGEXPandRLIKEoperatorsnowmatcharegularexpressionstringthatoccurs
anywhereinsidethetargetstring,thesameasiftheregularexpressionwasenclosed oneachsideby.*.SeeREGEXP
Operatoronpage189forexamples.Previously,theseoperatorsonlysucceeded whentheregularexpressionmatched
theentiretargetstring.Thischangeimprovescompatibilitywiththeregularexpressionsupportforpopulardatabase
systems.Thereisnochangetothebehavioroftheregexp_extract() andregexp_replace() built-infunctions.
InImpala2.0andlater,theImpalaregularexpressionsyntaxconformstothePOSIXExtendedRegularExpressionsyntax
usedbytheGoogleRE2library.Fordetails,seetheRE2documen tation.Ithasmostidiomsfamiliarfromregular
expressionsinPerl,Python,andsoon,including.*?fornon-greedymatches.
InImpala2.0andlater,achangeintheunderlying regularexpressionlibrarycouldcausechangesinthewayregular
expressionsareinterpretedbythisfunction. Testanyqueriesthatuseregularexpressionsandadjusttheexpression
patternsifnecessary.
Complextypeconsiderations:
Youcannotrefertoacolumnwithacomplexdatatype(ARRAY,STRUCT,orMAP)directlyinanoperator.Youcanapply
operatorsonlytoscalarvaluesthatmakeupacomplextype(thefieldsofaSTRUCT,theitemsofanARRAY,orthekey
orvalueportionofaMAP)aspartofajoinquerythatreferstothescalarvalueusingtheappropriatedotnotationor
ITEM,KEY,orVALUEpseudocolumnnames.
Examples:
ThefollowingexamplesdemonstratethesyntaxfortheIREGEXP operator.
select 'abcABCaabbcc' iregexp '^[a-c]+$';
+---------------------------------+
| 'abcabcaabbcc' iregexp '[a-c]+' |
+---------------------------------+
| true                            |
+---------------------------------+
Relatedinformation:
REGEXPOperatoronpage189
ISDISTINCTFROMOperator
TheIS DISTINCT FROM operator,anditsconversetheIS NOT DISTINCT FROM operator,testwhetherornot
valuesareidentical.IS NOT DISTINCT FROM issimilartothe=operator,andIS DISTINCT FROM issimilartothe
!=operator,exceptthatNULLvaluesaretreatedasidentical.Therefore,IS NOT DISTINCT FROM returnstrue
ratherthanNULL,andIS DISTINCT FROM returnsfalseratherthanNULL,whencomparing twoNULLvalues.If
oneofthevaluesbeingcomparedisNULLandtheotherisnot,IS DISTINCT FROM returnstrueandIS NOT
DISTINCT FROM returnsfalse,againinsteadofreturningNULLinbothcases.
Syntax:
expression1  IS DISTINCT FROM expression2
expression1  IS NOT DISTINCT FROM expression2
expression1  <=> expression2
Theoperator<=>isanaliasforIS NOT DISTINCT FROM .ItistypicallyusedasaNULL-safeequalityoperatorinjoin
queries.Thatis,A <=> B istrueifAequalsBorifbothAandBareNULL.
Usagenotes:
ApacheImpalaGuide|183ImpalaSQLLanguageReference
Thisoperatorprovidesconcisenotationforcomparing twovaluesandalwaysproducingatrueorfalseresult,
withouttreatingNULLasaspecialcase.Otherwise,tounambiguously distinguishbetweentwovaluesrequiresa
compound expressioninvolvingIS [NOT] NULL testsofbothoperandsinadditiontothe=or!=operator.
The<=>operator,usedlikeanequalityoperatorinajoinquery,ismoreefficientthantheequivalentclause:A = B
OR (A IS NULL AND B IS NULL) .The<=>operatorcanuseahashjoin,whiletheORexpressioncannot.
Examples:
ThefollowingexamplesshowhowIS DISTINCT FROM givesoutputsimilartothe!=operator,andIS NOT DISTINCT
FROMgivesoutputsimilartothe=operator.TheexceptioniswhentheexpressioninvolvesaNULLvalueononeside
orbothsides,where!=and=returnNULLbuttheIS [NOT] DISTINCT FROM operatorsstillreturntrueorfalse.
select 1 is distinct from 0, 1 != 0;
+----------------------+--------+
| 1 is distinct from 0 | 1 != 0 |
+----------------------+--------+
| true                 | true   |
+----------------------+--------+
select 1 is distinct from 1, 1 != 1;
+----------------------+--------+
| 1 is distinct from 1 | 1 != 1 |
+----------------------+--------+
| false                | false  |
+----------------------+--------+
select 1 is distinct from null, 1 != null;
+-------------------------+-----------+
| 1 is distinct from null | 1 != null |
+-------------------------+-----------+
| true                    | NULL      |
+-------------------------+-----------+
select null is distinct from null, null != null;
+----------------------------+--------------+
| null is distinct from null | null != null |
+----------------------------+--------------+
| false                      | NULL         |
+----------------------------+--------------+
select 1 is not distinct from 0, 1 = 0;
+--------------------------+-------+
| 1 is not distinct from 0 | 1 = 0 |
+--------------------------+-------+
| false                    | false |
+--------------------------+-------+
select 1 is not distinct from 1, 1 = 1;
+--------------------------+-------+
| 1 is not distinct from 1 | 1 = 1 |
+--------------------------+-------+
| true                     | true  |
+--------------------------+-------+
select 1 is not distinct from null, 1 = null;
+-----------------------------+----------+
| 1 is not distinct from null | 1 = null |
+-----------------------------+----------+
| false                       | NULL     |
+-----------------------------+----------+
select null is not distinct from null, null = null;
+--------------------------------+-------------+
| null is not distinct from null | null = null |
+--------------------------------+-------------+
| true                           | NULL        |
+--------------------------------+-------------+
184|ApacheImpalaGuideImpalaSQLLanguageReference
ThefollowingexampleshowshowIS DISTINCT FROM considersCHARvaluestobethesame(notdistinctfromeach
other)iftheyonlydifferinthenumberoftrailingspaces.Therefore,sometimestheresultofanIS [NOT] DISTINCT
FROMoperatordiffersdepending onwhetherthevaluesareSTRING/VARCHAR orCHAR.
select
  'x' is distinct from 'x ' as string_with_trailing_spaces,
  cast('x' as char(5)) is distinct from cast('x ' as char(5)) as 
char_with_trailing_spaces;
+-----------------------------+---------------------------+
| string_with_trailing_spaces | char_with_trailing_spaces |
+-----------------------------+---------------------------+
| true                        | false                     |
+-----------------------------+---------------------------+
ISNULLOperator
TheIS NULL operator,anditsconversetheIS NOT NULL operator,testwhetheraspecified valueisNULL.Because
usingNULLwithanyoftheothercomparison operatorssuchas=or!=alsoreturnsNULLratherthanTRUEorFALSE,
youuseaspecial-purpose comparison operatortocheckforthisspecialcondition.
InCDH5.14/Impala2.11andhigher,youcanusetheoperatorsIS UNKNOWN andIS NOT UNKNOWN assynonymsfor
IS NULL andIS NOT NULL ,respectively.
Syntax:
expression  IS NULL
expression  IS NOT NULL
expression  IS UNKNOWN
expression  IS NOT UNKNOWN
Usagenotes:
Inmanycases,NULLvaluesindicatesomeincorrectorincompleteprocessingduringdataingestionorconversion.You
mightcheckwhetheranyvaluesinacolumnareNULL,andifsotakesomefollowupactiontofillthemin.
Withsparsedata,oftenrepresentedinâwideâtables,itiscommonformostvaluestobeNULLwithonlyanoccasional
non-NULLvalue.Inthosecases,youcanusetheIS NOT NULL operatortoidentifytherowscontaininganydataat
allforaparticular column,regardlessoftheactualvalue.
Withawell-designed databaseschema,effectiveuseofNULLvaluesandIS NULL andIS NOT NULL operatorscan
savehavingtodesigncustomlogicaroundspecialvaluessuchas0,-1,'N/A',emptystring,andsoon.NULLletsyou
distinguishbetweenavaluethatisknowntobe0,false,orempty,andatrulyunknownvalue.
Complextypeconsiderations:
TheIS [NOT] UNKNOWN operator,aswiththeIS [NOT] NULL operator,isnotapplicabletocomplextypecolumns
(STRUCT,ARRAY,orMAP).Usingacomplextypecolumnwiththisoperatorcausesaqueryerror.
Examples:
-- If this value is non-zero, something is wrong.
select count(*) from employees where employee_id is null;
-- With data from disparate sources, some fields might be blank.
-- Not necessarily an error condition.
select count(*) from census where household_income is null;
-- Sometimes we expect fields to be null, and followup action
-- is needed when they are not.
select count(*) from web_traffic where weird_http_code is not null;
ApacheImpalaGuide|185ImpalaSQLLanguageReference
ISTRUEOperator
ThisvariationoftheISoperatortestsfortruthorfalsity,withright-handarguments[NOT] TRUE ,[NOT] FALSE ,
and[NOT] UNKNOWN .
Syntax:
expression  IS TRUE
expression  IS NOT TRUE
expression  IS FALSE
expression  IS NOT FALSE
Usagenotes:
ThisIS TRUE andIS FALSE formsaresimilartodoingequalitycomparisons withtheBooleanvaluesTRUEandFALSE,
exceptthatIS TRUE andIS FALSE alwaysreturneitherTRUEorFALSE,eveniftheleft-handsideexpressionreturns
NULL
TheseoperatorsletyousimplifyBooleancomparisons thatmustalsocheckforNULL,forexampleX != 10 AND X
IS NOT NULL isequivalentto(X != 10) IS TRUE .
InCDH5.14/Impala2.11andhigher,youcanusetheoperatorsIS [NOT] TRUE andIS [NOT] FALSE asequivalents
forthebuilt-infunctionsISTRUE() ,ISNOTTRUE() ,ISFALSE() ,andISNOTFALSE() .
Complextypeconsiderations:
TheIS [NOT] TRUE andIS [NOT] FALSE operatorsarenotapplicabletocomplextypecolumns(STRUCT,ARRAY,
orMAP).Usingacomplextypecolumnwiththeseoperatorscausesaqueryerror.
Addedin:CDH5.14.0/Impala2.11.0
Examples:
select assertion, b, b is true, b is false, b is unknown
  from boolean_test;
+-------------+-------+-----------+------------+-----------+
| assertion   | b     | istrue(b) | isfalse(b) | b is null |
+-------------+-------+-----------+------------+-----------+
| 2 + 2 = 4   | true  | true      | false      | false     |
| 2 + 2 = 5   | false | false     | true       | false     |
| 1 = null    | NULL  | false     | false      | true      |
| null = null | NULL  | false     | false      | true      |
+-------------+-------+-----------+------------+-----------+
LIKEOperator
Acomparison operatorforSTRINGdata,withbasicwildcardcapabilityusingtheunderscore(_)tomatchasingle
characterandthepercentsign(%)tomatchmultiplecharacters.Theargumentexpressionmustmatchtheentirestring
value.Typically,itismoreefficienttoputany%wildcardmatchattheendofthestring.
Syntax:
string_expression  LIKE wildcard_expression
string_expression  NOT LIKE wildcard_expression
Complextypeconsiderations:
Youcannotrefertoacolumnwithacomplexdatatype(ARRAY,STRUCT,orMAP)directlyinanoperator.Youcanapply
operatorsonlytoscalarvaluesthatmakeupacomplextype(thefieldsofaSTRUCT,theitemsofanARRAY,orthekey
orvalueportionofaMAP)aspartofajoinquerythatreferstothescalarvalueusingtheappropriatedotnotationor
ITEM,KEY,orVALUEpseudocolumnnames.
186|ApacheImpalaGuideImpalaSQLLanguageReference
Examples:
select distinct c_last_name from customer where c_last_name like 'Mc%' or c_last_name 
like 'Mac%';
select count(c_last_name) from customer where c_last_name like 'M%';
select c_email_address from customer where c_email_address like '%.edu';
-- We can find 4-letter names beginning with 'M' by calling functions...
select distinct c_last_name from customer where length(c_last_name) = 4 and 
substr(c_last_name,1,1) = 'M';
-- ...or in a more readable way by matching M followed by exactly 3 characters.
select distinct c_last_name from customer where c_last_name like 'M___';
Forcase-insensitiv ecomparisons, seeILIKEOperatoronpage179.Foramoregeneralkindofsearchoperatorusing
regularexpressions,seeREGEXPOperatoronpage189oritscase-insensitiv ecounterpartIREGEXPOperatoronpage
182.
LogicalOperators
LogicaloperatorsreturnaBOOLEAN value,basedonabinaryorunarylogicaloperationbetweenargumentsthatare
alsoBooleans. Typically,theargumentexpressionsusecomparison operators.
Syntax:
boolean_expression binary_logical_operator boolean_expression
unary_logical_operator boolean_expression
TheImpalalogicaloperatorsare:
â¢AND:Abinaryoperatorthatreturnstrueifitsleft-handandright-handargumentsbothevaluatetotrue,NULL
ifeitherargumentisNULL,andfalseotherwise.
â¢OR:Abinaryoperatorthatreturnstrueifeitherofitsleft-handandright-handargumentsevaluatetotrue,NULL
ifoneargumentisNULLandtheotheriseitherNULLorfalse,andfalseotherwise.
â¢NOT:AunaryoperatorthatflipsthestateofaBooleanexpressionfromtruetofalse,orfalsetotrue.Ifthe
argumentexpressionisNULL,theresultremainsNULL.(WhenNOTisusedthiswayasaunarylogicaloperator,it
worksdifferentlythantheIS NOT NULL comparison operator,whichreturnstruewhenappliedtoaNULL.)
Complextypeconsiderations:
Youcannotrefertoacolumnwithacomplexdatatype(ARRAY,STRUCT,orMAP)directlyinanoperator.Youcanapply
operatorsonlytoscalarvaluesthatmakeupacomplextype(thefieldsofaSTRUCT,theitemsofanARRAY,orthekey
orvalueportionofaMAP)aspartofajoinquerythatreferstothescalarvalueusingtheappropriatedotnotationor
ITEM,KEY,orVALUEpseudocolumnnames.
ThefollowingexampleshowshowtodoanarithmeticoperationusinganumericfieldofaSTRUCTtypethatisanitem
withinanARRAYcolumn.OncethescalarnumericvalueR_NATIONKEY isextracted,itcanbeusedinanarithmetic
expression,suchasmultiplying by10:
-- The SMALLINT is a field within an array of structs.
describe region;
+-------------+-------------------------+---------+
| name        | type                    | comment |
+-------------+-------------------------+---------+
| r_regionkey | smallint                |         |
| r_name      | string                  |         |
| r_comment   | string                  |         |
| r_nations   | array<struct<           |         |
|             |   n_nationkey:smallint, |         |
|             |   n_name:string,        |         |
|             |   n_comment:string      |         |
|             | >>                      |         |
+-------------+-------------------------+---------+
-- When we refer to the scalar value using dot notation,
ApacheImpalaGuide|187ImpalaSQLLanguageReference
-- we can use arithmetic and comparison operators on it
-- like any other number.
select r_name, nation.item.n_name, nation.item.n_nationkey
  from region, region.r_nations as nation
where
  nation.item.n_nationkey between 3 and 5
  or nation.item.n_nationkey < 15;
+-------------+----------------+------------------+
| r_name      | item.n_name    | item.n_nationkey |
+-------------+----------------+------------------+
| EUROPE      | UNITED KINGDOM | 23               |
| EUROPE      | RUSSIA         | 22               |
| EUROPE      | ROMANIA        | 19               |
| ASIA        | VIETNAM        | 21               |
| ASIA        | CHINA          | 18               |
| AMERICA     | UNITED STATES  | 24               |
| AMERICA     | PERU           | 17               |
| AMERICA     | CANADA         | 3                |
| MIDDLE EAST | SAUDI ARABIA   | 20               |
| MIDDLE EAST | EGYPT          | 4                |
| AFRICA      | MOZAMBIQUE     | 16               |
| AFRICA      | ETHIOPIA       | 5                |
+-------------+----------------+------------------+
Examples:
TheseexamplesdemonstratetheANDoperator:
[localhost:21000] > select true and true;
+---------------+
| true and true |
+---------------+
| true          |
+---------------+
[localhost:21000] > select true and false;
+----------------+
| true and false |
+----------------+
| false          |
+----------------+
[localhost:21000] > select false and false;
+-----------------+
| false and false |
+-----------------+
| false           |
+-----------------+
[localhost:21000] > select true and null;
+---------------+
| true and null |
+---------------+
| NULL          |
+---------------+
[localhost:21000] > select (10 > 2) and (6 != 9);
+-----------------------+
| (10 > 2) and (6 != 9) |
+-----------------------+
| true                  |
+-----------------------+
TheseexamplesdemonstratetheORoperator:
[localhost:21000] > select true or true;
+--------------+
| true or true |
+--------------+
| true         |
+--------------+
[localhost:21000] > select true or false;
+---------------+
| true or false |
+---------------+
188|ApacheImpalaGuideImpalaSQLLanguageReference
| true          |
+---------------+
[localhost:21000] > select false or false;
+----------------+
| false or false |
+----------------+
| false          |
+----------------+
[localhost:21000] > select true or null;
+--------------+
| true or null |
+--------------+
| true         |
+--------------+
[localhost:21000] > select null or true;
+--------------+
| null or true |
+--------------+
| true         |
+--------------+
[localhost:21000] > select false or null;
+---------------+
| false or null |
+---------------+
| NULL          |
+---------------+
[localhost:21000] > select (1 = 1) or ('hello' = 'world');
+--------------------------------+
| (1 = 1) or ('hello' = 'world') |
+--------------------------------+
| true                           |
+--------------------------------+
[localhost:21000] > select (2 + 2 != 4) or (-1 > 0);
+--------------------------+
| (2 + 2 != 4) or (-1 > 0) |
+--------------------------+
| false                    |
+--------------------------+
TheseexamplesdemonstratetheNOToperator:
[localhost:21000] > select not true;
+----------+
| not true |
+----------+
| false    |
+----------+
[localhost:21000] > select not false;
+-----------+
| not false |
+-----------+
| true      |
+-----------+
[localhost:21000] > select not null;
+----------+
| not null |
+----------+
| NULL     |
+----------+
[localhost:21000] > select not (1=1);
+-------------+
| not (1 = 1) |
+-------------+
| false       |
+-------------+
REGEXPOperator
Testswhetheravaluematchesaregularexpression.UsesthePOSIXregularexpressionsyntaxwhere^and$match
thebeginning andendofthestring,.representsanysinglecharacter,*representsasequence ofzeroormoreitems,
+representsasequence ofoneormoreitems,?producesanon-greedymatch,andsoon.
ApacheImpalaGuide|189ImpalaSQLLanguageReference
Syntax:
string_expression  REGEXP regular_expression
Usagenotes:
TheRLIKEoperatorisasynonymforREGEXP.
The|symbolisthealternationoperator,typicallyusedwithin()tomatchdifferentsequences. The()groupsdonot
allowbackreferences.Toretrievethepartofavaluematchedwithina()section,usetheregexp_extract() built-in
function.
InImpala1.3.1andhigher,theREGEXPandRLIKEoperatorsnowmatcharegularexpressionstringthatoccurs
anywhereinsidethetargetstring,thesameasiftheregularexpressionwasenclosed oneachsideby.*.SeeREGEXP
Operatoronpage189forexamples.Previously,theseoperatorsonlysucceeded whentheregularexpressionmatched
theentiretargetstring.Thischangeimprovescompatibilitywiththeregularexpressionsupportforpopulardatabase
systems.Thereisnochangetothebehavioroftheregexp_extract() andregexp_replace() built-infunctions.
InImpala2.0andlater,theImpalaregularexpressionsyntaxconformstothePOSIXExtendedRegularExpressionsyntax
usedbytheGoogleRE2library.Fordetails,seetheRE2documen tation.Ithasmostidiomsfamiliarfromregular
expressionsinPerl,Python,andsoon,including.*?fornon-greedymatches.
InImpala2.0andlater,achangeintheunderlying regularexpressionlibrarycouldcausechangesinthewayregular
expressionsareinterpretedbythisfunction. Testanyqueriesthatuseregularexpressionsandadjusttheexpression
patternsifnecessary.
Complextypeconsiderations:
Youcannotrefertoacolumnwithacomplexdatatype(ARRAY,STRUCT,orMAP)directlyinanoperator.Youcanapply
operatorsonlytoscalarvaluesthatmakeupacomplextype(thefieldsofaSTRUCT,theitemsofanARRAY,orthekey
orvalueportionofaMAP)aspartofajoinquerythatreferstothescalarvalueusingtheappropriatedotnotationor
ITEM,KEY,orVALUEpseudocolumnnames.
Examples:
ThefollowingexamplesdemonstratetheidenticalsyntaxfortheREGEXPandRLIKEoperators.
-- Find all customers whose first name starts with 'J', followed by 0 or more of any 
character.
select c_first_name, c_last_name from customer where c_first_name regexp '^J.*';
select c_first_name, c_last_name from customer where c_first_name rlike '^J.*';
-- Find 'Macdonald', where the first 'a' is optional and the 'D' can be upper- or 
lowercase.
-- The ^...$ are required, to match the start and end of the value.
select c_first_name, c_last_name from customer where c_last_name regexp '^Ma?c[Dd]onald$';
select c_first_name, c_last_name from customer where c_last_name rlike '^Ma?c[Dd]onald$';
-- Match multiple character sequences, either 'Mac' or 'Mc'.
select c_first_name, c_last_name from customer where c_last_name regexp 
'^(Mac|Mc)donald$';
select c_first_name, c_last_name from customer where c_last_name rlike '^(Mac|Mc)donald$';
-- Find names starting with 'S', then one or more vowels, then 'r', then any other 
characters.
-- Matches 'Searcy', 'Sorenson', 'Sauer'.
select c_first_name, c_last_name from customer where c_last_name regexp '^S[aeiou]+r.*$';
select c_first_name, c_last_name from customer where c_last_name rlike '^S[aeiou]+r.*$';
-- Find names that end with 2 or more vowels: letters from the set a,e,i,o,u.
select c_first_name, c_last_name from customer where c_last_name regexp '.*[aeiou]{2,}$';
select c_first_name, c_last_name from customer where c_last_name rlike '.*[aeiou]{2,}$';
-- You can use letter ranges in the [] blocks, for example to find names starting with
 A, B, or C.
select c_first_name, c_last_name from customer where c_last_name regexp '^[A-C].*';
select c_first_name, c_last_name from customer where c_last_name rlike '^[A-C].*';
190|ApacheImpalaGuideImpalaSQLLanguageReference
-- If you are not sure about case, leading/trailing spaces, and so on, you can process
 the
-- column using string functions first.
select c_first_name, c_last_name from customer where lower(trim(c_last_name)) regexp 
'^de.*';
select c_first_name, c_last_name from customer where lower(trim(c_last_name)) rlike 
'^de.*';
Relatedinformation:
Forregularexpressionmatchingwithcase-insensitiv ecomparisons, seeIREGEXPOperatoronpage182.
RLIKEOperator
SynonymfortheREGEXPoperator.SeeREGEXPOperatoronpage189fordetails.
Examples:
ThefollowingexamplesdemonstratetheidenticalsyntaxfortheREGEXPandRLIKEoperators.
-- Find all customers whose first name starts with 'J', followed by 0 or more of any 
character.
select c_first_name, c_last_name from customer where c_first_name regexp '^J.*';
select c_first_name, c_last_name from customer where c_first_name rlike '^J.*';
-- Find 'Macdonald', where the first 'a' is optional and the 'D' can be upper- or 
lowercase.
-- The ^...$ are required, to match the start and end of the value.
select c_first_name, c_last_name from customer where c_last_name regexp '^Ma?c[Dd]onald$';
select c_first_name, c_last_name from customer where c_last_name rlike '^Ma?c[Dd]onald$';
-- Match multiple character sequences, either 'Mac' or 'Mc'.
select c_first_name, c_last_name from customer where c_last_name regexp 
'^(Mac|Mc)donald$';
select c_first_name, c_last_name from customer where c_last_name rlike '^(Mac|Mc)donald$';
-- Find names starting with 'S', then one or more vowels, then 'r', then any other 
characters.
-- Matches 'Searcy', 'Sorenson', 'Sauer'.
select c_first_name, c_last_name from customer where c_last_name regexp '^S[aeiou]+r.*$';
select c_first_name, c_last_name from customer where c_last_name rlike '^S[aeiou]+r.*$';
-- Find names that end with 2 or more vowels: letters from the set a,e,i,o,u.
select c_first_name, c_last_name from customer where c_last_name regexp '.*[aeiou]{2,}$';
select c_first_name, c_last_name from customer where c_last_name rlike '.*[aeiou]{2,}$';
-- You can use letter ranges in the [] blocks, for example to find names starting with
 A, B, or C.
select c_first_name, c_last_name from customer where c_last_name regexp '^[A-C].*';
select c_first_name, c_last_name from customer where c_last_name rlike '^[A-C].*';
-- If you are not sure about case, leading/trailing spaces, and so on, you can process
 the
-- column using string functions first.
select c_first_name, c_last_name from customer where lower(trim(c_last_name)) regexp 
'^de.*';
select c_first_name, c_last_name from customer where lower(trim(c_last_name)) rlike 
'^de.*';
ImpalaSchemaObjectsandObjectNames
WithImpala,youworkwithschemaobjectsthatarefamiliartodatabaseusers:primarily databases,tables,views,and
functions. TheSQLsyntaxtoworkwiththeseobjectsisexplainedinImpalaSQLStatementsonpage202.Thissection
explainstheconceptualknowledgeyouneedtoworkwiththeseobjectsandthevariouswaystospecifytheirnames.
Withinatable,partitions canalsobeconsideredakindofobject.Partitioning isanimportantsubjectforImpala,with
itsowndocumen tationsectioncoveringusecasesandperformance considerations.SeePartitioning forImpalaTables
onpage625fordetails.
ApacheImpalaGuide|191ImpalaSQLLanguageReference
Impaladoesnothaveacounterpartoftheâtablespaceâ notionfromsomedatabasesystems.Bydefault,allthedata
filesforadatabase,table,orpartition arelocatedwithinnestedfolderswithintheHDFSfilesystem.Youcanalso
specifyaparticular HDFSlocationforagivenImpalatableorpartition. Therawdatafortheseobjectsisrepresented
asacollectionofdatafiles,providingtheflexibilitytoloaddatabysimplymovingfilesintotheexpectedHDFSlocation.
Informationabouttheschemaobjectsisheldinthemetastoredatabase.ThisdatabaseissharedbetweenImpalaand
Hive,allowingeachtocreate,drop,andqueryeachother'sdatabases,tables,andsoon.WhenImpalamakesachange
toschemaobjectsthroughaCREATE,ALTER,DROP,INSERT,orLOAD DATA statement,itbroadcaststhosechanges
toallnodesintheclusterthroughthecatalogservice.WhenyoumakesuchchangesthroughHiveordirectlythrough
manipula tingHDFSfiles,youusetheREFRESHorINVALIDATEMETADATAstatementsontheImpalasidetorecognize
thenewlyloadeddata,newtables,andsoon.
OverviewofImpalaAliases
Whenyouwritethenamesoftables,columns,orcolumnexpressionsinaquery,youcanassignanaliasatthesame
time.Thenyoucanspecifythealiasratherthantheoriginalnamewhenmakingotherreferencestothetableorcolumn
inthesamestatement.Youtypicallyspecifyaliasesthatareshorter,easiertoremember ,orboththantheoriginal
names.Thealiasesareprintedinthequeryheader,makingthemusefulforself-documen tingoutput.
Tosetupanalias,addtheAS aliasclauseimmediatelyafteranytable,column,orexpressionnameintheSELECT
listorFROMlistofaquery.TheASkeywordisoptional;youcanalsospecifythealiasimmediatelyaftertheoriginal
name.
-- Make the column headers of the result set easier to understand.
SELECT c1 AS name, c2 AS address, c3 AS phone FROM table_with_terse_columns;
SELECT SUM(ss_xyz_dollars_net) AS total_sales FROM table_with_cryptic_columns;
-- The alias can be a quoted string for extra readability.
SELECT c1 AS "Employee ID", c2 AS "Date of hire" FROM t1;
-- The AS keyword is optional.
SELECT c1 "Employee ID", c2 "Date of hire" FROM t1;
-- The table aliases assigned in the FROM clause can be used both earlier
-- in the query (the SELECT list) and later (the WHERE clause).
SELECT one.name, two.address, three.phone
  FROM census one, building_directory two, phonebook three
WHERE one.id = two.id and two.id = three.id;
-- The aliases c1 and c2 let the query handle columns with the same names from 2 joined
 tables.
-- The aliases t1 and t2 let the query abbreviate references to long or cryptically 
named tables.
SELECT t1.column_n AS c1, t2.column_n AS c2 FROM long_name_table AS t1, 
very_long_name_table2 AS t2
  WHERE c1 = c2;
SELECT t1.column_n c1, t2.column_n c2 FROM table1 t1, table2 t2
  WHERE c1 = c2;
YoucanspecifycolumnaliaseswithorwithouttheASkeyword,andwithnoquotationmarks,singlequotationmarks,
ordoublequotationmarks.Somekindofquotationmarksarerequiredifthecolumnaliascontainsanyspacesorother
problematiccharacters.Thealiastextisdisplayedintheimpala-shell outputasall-lowercase.Forexample:
[localhost:21000] > select c1 First_Column from t;
[localhost:21000] > select c1 as First_Column from t;
+--------------+
| first_column |
+--------------+
...
[localhost:21000] > select c1 'First Column' from t;
[localhost:21000] > select c1 as 'First Column' from t;
+--------------+
| first column |
+--------------+
...
[localhost:21000] > select c1 "First Column" from t;
[localhost:21000] > select c1 as "First Column" from t;
192|ApacheImpalaGuideImpalaSQLLanguageReference
+--------------+
| first column |
+--------------+
...
FromImpala3.0,thealiassubstitutionlogicintheGROUP BY ,HAVING,andORDER BY clauseshasbecomemore
consistentwithstandardSQLbehavior,asfollows.Aliasesarenowonlylegalatthetoplevel,andnotinsubexpressions.
Thefollowingstatementsareallowed:
  SELECT int_col / 2 AS x
  FROM t
  GROUP BY x;
  SELECT int_col / 2 AS x
  FROM t
  ORDER BY x;
  SELECT NOT bool_col AS nb
  FROM t
  GROUP BY nb
  HAVING nb;
AndthefollowingstatementsareNOTallowed:
  SELECT int_col / 2 AS x
  FROM t
  GROUP BY x / 2;
  SELECT int_col / 2 AS x
  FROM t
  ORDER BY -x;
  SELECT int_col / 2 AS x
  FROM t
  GROUP BY x
  HAVING x > 3;
TouseanaliasnamethatmatchesoneoftheImpalareservedkeywords(listedinImpalaReservedWordsonpage
745),surroundtheidentifierwitheithersingleordoublequotationmarks,or``characters(backticks).
Aliasesfollowthesamerulesasidentifierswhenitcomestocaseinsensitivity .Aliasescanbelongerthanidentifiers
(uptothemaximumlengthofaJavastring)andcanincludeadditional characterssuchasspacesanddasheswhen
theyarequotedusingbacktickcharacters.
Complextypeconsiderations:
Queriesinvolvingthecomplextypes(ARRAY,STRUCT,andMAP),typicallymakeextensiveuseoftablealiases.These
queriesinvolvejoinclauseswherethecomplextypecolumnistreatedasajoinedtable.Toconstructtwo-partor
three-partqualified namesforthecomplexcolumnelementsintheFROMlist,sometimesitissyntacticallyrequiredto
constructatablealiasforthecomplexcolumnwhereitisreferencedinthejoinclause.SeeComplexTypes(CDH5.5
orhigheronly)onpage139fordetailsandexamples.
Alternatives:
Anotherwaytodefinedifferentnamesforthesametablesorcolumnsistocreateviews.SeeOverviewofImpalaViews
onpage199fordetails.
OverviewofImpalaDatabases
InImpala,adatabaseisalogicalcontainerforagroupoftables.Eachdatabasedefinesaseparatenamespace. Within
adatabase,youcanrefertothetablesinsideitusingtheirunqualified names.Differentdatabasescancontaintables
withidenticalnames.
ApacheImpalaGuide|193ImpalaSQLLanguageReference
Creatingadatabaseisalightweightoperation.Thereareminimaldatabase-specific propertiestoconfigure,suchas
LOCATION andCOMMENT .
YoucanchangetheownerofadatabasewiththeALTER DATABASE statement.
Typically,youcreateaseparatedatabaseforeachprojectorapplication,toavoidnamingconflictsbetweentablesand
tomakeclearwhichtablesarerelatedtoeachother.TheUSEstatementletsyouswitchbetweendatabases.Unqualified
referencestotables,views,andfunctions refertoobjectswithinthecurrentdatabase.Youcanalsorefertoobjects
inotherdatabasesbyusingqualified namesoftheformdbname.object_name .
EachdatabaseisphysicallyrepresentedbyadirectoryinHDFS.WhenyoudonotspecifyaLOCATION attribute,the
directoryislocatedintheImpaladatadirectorywiththeassociatedtablesmanagedbyImpala.Whenyoudospecify
aLOCATION attribute,anyreadandwriteoperationsfortablesinthatdatabasearerelativetothespecified HDFS
directory.
Thereisaspecialdatabase,nameddefault ,whereyoubeginwhenyouconnecttoImpala.Tablescreatedindefault
arephysicallylocatedonelevelhigherinHDFSthanalltheuser-createddatabases.
Impalaincludesanotherpredefineddatabase,_impala_builtins ,thatservesasthelocationforthebuilt-infunctions.
Toseethebuilt-infunctions, useastatementlikethefollowing:
show functions in _impala_builtins;
show functions in _impala_builtins like '* substring *';
Relatedstatements:
CREATEDATABASEStatementonpage226,DROPDATABASEStatementonpage262,USEStatementonpage385,SHOW
DATABASESonpage368
OverviewofImpalaFunctions
Functions letyouapplyarithmetic,string,orothercomputationsandtransformationstoImpaladata.Youtypically
usetheminSELECTlistsandWHEREclausestofilterandformatqueryresultssothattheresultsetisexactlywhatyou
want,withnofurtherprocessingneededontheapplicationside.
Scalarfunctions returnasingleresultforeachinputrow.SeeImpalaBuilt-InFunctions onpage391.
[localhost:21000] > select name, population from country where continent = 'North America'
 order by population desc limit 4;
[localhost:21000] > select upper(name), population from country where continent = 'North
 America' order by population desc limit 4;
+-------------+------------+
| upper(name) | population |
+-------------+------------+
| USA         | 320000000  |
| MEXICO      | 122000000  |
| CANADA      | 25000000   |
| GUATEMALA   | 16000000   |
+-------------+------------+
Aggregatefunctions combinetheresultsfrommultiplerows:eitherasingleresultfortheentiretable,oraseparate
resultforeachgroupofrows.Aggregatefunctions arefrequentlyusedincombinationwithGROUP BY andHAVING
clausesintheSELECTstatement.SeeImpalaAggregateFunctions onpage479.
[localhost:21000] > select continent, sum(population)  as howmany from country group by
 continent  order by howmany desc;
+---------------+------------+
| continent     | howmany    |
+---------------+------------+
| Asia          | 4298723000 |
| Africa        | 1110635000 |
| Europe        | 742452000  |
| North America | 565265000  |
| South America | 406740000  |
| Oceania       | 38304000   |
+---------------+------------+
194|ApacheImpalaGuideImpalaSQLLanguageReference
User-definedfunctions (UDFs)letyoucodeyourownlogic.Theycanbeeitherscalaroraggregatefunctions. UDFslet
youimplemen timportantbusinessorscientificlogicusinghigh-performancecodeforImpalatoautomaticallyparallelize.
YoucanalsouseUDFstoimplemen tconveniencefunctions tosimplifyreportingorportingSQLfromotherdatabase
systems.SeeUser-DefinedFunctions (UDFs)onpage525.
[localhost:21000] > select rot13('Hello world!')  as 'Weak obfuscation';
+------------------+
| weak obfuscation |
+------------------+
| Uryyb jbeyq!     |
+------------------+
[localhost:21000] > select likelihood_of_new_subatomic_particle(sensor1, sensor2, sensor3)
 as probability
                  > from experimental_results group by experiment;
Eachfunctionisassociatedwithaspecificdatabase.Forexample,ifyouissueaUSE somedb statementfollowedby
CREATE FUNCTION somefunc ,thenewfunctioniscreatedinthesomedbdatabase,andyoucouldrefertoitthrough
thefullyqualified namesomedb.somefunc .YoucouldthenissueanotherUSEstatementandcreateafunctionwith
thesamenameinadifferentdatabase.
Impalabuilt-infunctions areassociatedwithaspecialdatabasenamed_impala_builtins ,whichletsyoureferto
themfromanydatabasewithoutqualifyingthename.
[localhost:21000] > show databases;
+-------------------------+
| name                    |
+-------------------------+
| _impala_builtins         |
| analytic_functions      |
| avro_testing            |
| data_file_size          |
...
[localhost:21000] > show functions in _impala_builtins like '*subs*';
+-------------+-----------------------------------+
| return type | signature                         |
+-------------+-----------------------------------+
| STRING      | substr(STRING, BIGINT)            |
| STRING      | substr(STRING, BIGINT, BIGINT)    |
| STRING      | substring(STRING, BIGINT)         |
| STRING      | substring(STRING, BIGINT, BIGINT) |
+-------------+-----------------------------------+
Relatedstatements:CREATEFUNCTIONStatementonpage228,DROPFUNCTIONStatementonpage263
OverviewofImpalaIdentifiers
Identifiersarethenamesofdatabases,tables,orcolumnsthatyouspecifyinaSQLstatement.Therulesforidentifiers
governwhatnamesyoucangivetothingsyoucreate,thenotationforreferringtonamescontainingunusualcharacters,
andotheraspectssuchascasesensitivity .
â¢Theminimum lengthofanidentifieris1character.
â¢Themaximumlengthofanidentifieriscurrently128characters,enforcedbythemetastoredatabase.
â¢Anidentifiermuststartwithanalphanumeric orunderscorecharacter.Theremainder cancontainanycombination
ofalphanumeric charactersandunderscores.Quotingtheidentifierwithbacktickshasnoeffectontheallowed
charactersinthename.
â¢AnidentifiercancontainonlyASCIIcharacters.
â¢TouseanidentifiernamethatmatchesoneoftheImpalareservedkeywords(listedinImpalaReservedWords
onpage745),surroundtheidentifierwith``characters(backticks).Quotethereservedwordevenifitispartof
afullyqualified name.Thefollowingexampleshowshowareservedwordcanbeusedasacolumnnameifitis
ApacheImpalaGuide|195ImpalaSQLLanguageReference
quotedwithbackticksintheCREATE TABLE statement,andhowthecolumnnamemustalsobequotedwith
backticksinaquery:
[localhost:21000] > create table reserved (`data` string);
[localhost:21000] > select data from reserved;
ERROR: AnalysisException: Syntax error in line 1:
select data from reserved
       ^
Encountered: DATA
Expected: ALL, CASE, CAST, DISTINCT, EXISTS, FALSE, IF, INTERVAL, NOT, NULL, 
STRAIGHT_JOIN, TRUE, IDENTIFIER
CAUSED BY: Exception: Syntax error
[localhost:21000] > select reserved.data from reserved;
ERROR: AnalysisException: Syntax error in line 1:
select reserved.data from reserved
                ^
Encountered: DATA
Expected: IDENTIFIER
CAUSED BY: Exception: Syntax error
[localhost:21000] > select reserved.`data` from reserved;
[localhost:21000] >
Important:BecausethelistofreservedwordsgrowsovertimeasnewSQLsyntaxisadded,
consideradoptingcodingconventions(especially foranyautomatedscriptsorinpackaged
applications)toalwaysquoteallidentifierswithbackticks.Quotingallidentifiersprotectsyour
SQLfromcompatibilityissuesifnewreservedwordsareaddedinlaterreleases.
â¢Impalaidentifiersarealwayscase-insensitiv e.Thatis,tablesnamedt1andT1alwaysrefertothesametable,
regardlessofquotecharacters.Internally,Impalaalwaysfoldsallspecified tableandcolumnnamestolowercase.
Thisiswhythecolumnheadersinqueryoutputarealwaysdisplayedinlowercase.
SeeOverviewofImpalaAliasesonpage192forhowtodefineshorteroreasier-to-remember aliasesiftheoriginal
namesarelongorcrypticidentifiers.Aliasesfollowthesamerulesasidentifierswhenitcomestocaseinsensitivity .
Aliasescanbelongerthanidentifiers(uptothemaximumlengthofaJavastring)andcanincludeadditional characters
suchasspacesanddasheswhentheyarequotedusingbacktickcharacters.
Anotherwaytodefinedifferentnamesforthesametablesorcolumnsistocreateviews.SeeOverviewofImpalaViews
onpage199fordetails.
OverviewofImpalaTables
TablesaretheprimarycontainersfordatainImpala.Theyhavethefamiliarrowandcolumnlayoutsimilartoother
databasesystems,plussomefeaturessuchaspartitioning oftenassociatedwithhigher-end datawarehousesystems.
Logically,eachtablehasastructurebasedonthedefinitionofitscolumns,partitions, andotherproperties.
Physically,eachtablethatusesHDFSstorageisassociatedwithadirectoryinHDFS.Thetabledataconsistsofallthe
datafilesundernea ththatdirectory:
â¢InternaltablesaremanagedbyImpala,andusedirectoriesinsidethedesignatedImpalaworkarea.
â¢ExternaltablesusearbitraryHDFSdirectories,wherethedatafilesaretypicallysharedbetweendifferentHadoop
componen ts.
â¢Large-scaledataisusuallyhandledbypartitioned tables,wherethedatafilesaredividedamongdifferentHDFS
subdirectories.
ImpalatablescanalsorepresentdatathatisstoredinHBase,orintheAmazonS3filesystem(CDH5.4/Impala2.2or
higher).SeeUsingImpalatoQueryHBaseTablesonpage684andUsingImpalawiththeAmazonS3Filesystemonpage
692.
196|ApacheImpalaGuideImpalaSQLLanguageReference
Impalaqueriesignorefileswithextensionscommonly usedfortemporaryworkfilesbyHadooptools.Anyfileswith
extensions.tmpor.copying arenotconsideredpartoftheImpalatable.Thesuffixmatchingiscase-insensitiv e,so
forexampleImpalaignoresboth.copying and.COPYING suffixes.
InternalTables
ThedefaultkindoftableproducedbytheCREATE TABLE statementisknownasaninternaltable.(Itscounterpartis
theexternaltable,producedbytheCREATE EXTERNAL TABLE syntax.)
â¢ImpalacreatesadirectoryinHDFStoholdthedatafiles.
â¢YoucancreatedataininternaltablesbyissuingINSERTorLOAD DATA statements.
â¢IfyouaddorreplacedatausingHDFSoperations,issuetheREFRESH command inimpala-shell sothatImpala
recognizesthechangesindatafiles,blocklocations,andsoon.
â¢WhenyouissueaDROP TABLE statement,Impalaphysicallyremovesallthedatafilesfromthedirectory.
â¢Toseewhetheratableisinternalorexternal,anditsassociatedHDFSlocation,issuethestatementDESCRIBE
FORMATTED table_name .TheTable Type fielddisplaysMANAGED_TABLE forinternaltablesand
EXTERNAL_TABLE forexternaltables.TheLocation fielddisplaysthepathofthetabledirectoryasanHDFS
URI.
â¢WhenyouissueanALTER TABLE statementtorenameaninternaltable,alldatafilesaremovedintothenew
HDFSdirectoryforthetable.ThefilesaremovedeveniftheywereformerlyinadirectoryoutsidetheImpaladata
directory,forexampleinaninternaltablewithaLOCATION attributepointingtoanoutsideHDFSdirectory.
Examples:
Youcanswitchatablefrominternaltoexternal,orfromexternaltointernal,byusingtheALTER TABLE statement:
-- Switch a table from internal to external.
ALTER TABLE table_name  SET TBLPROPERTIES('EXTERNAL'='TRUE');
-- Switch a table from external to internal.
ALTER TABLE table_name  SET TBLPROPERTIES('EXTERNAL'='FALSE');
IftheKuduserviceisintegratedwiththeHiveMetastore,theaboveoperationsarenotsupported.
ExternalTables
ThesyntaxCREATE EXTERNAL TABLE setsupanImpalatablethatpointsatexistingdatafiles,potentiallyinHDFS
locationsoutsidethenormalImpaladatadirectories..Thisoperationsavestheexpenseofimporting thedataintoa
newtablewhenyoualreadyhavethedatafilesinaknownlocationinHDFS,inthedesiredfileformat.
â¢YoucanuseImpalatoquerythedatainthistable.
â¢YoucancreatedatainexternaltablesbyissuingINSERTorLOAD DATA statements.
â¢IfyouaddorreplacedatausingHDFSoperations,issuetheREFRESH command inimpala-shell sothatImpala
recognizesthechangesindatafiles,blocklocations,andsoon.
â¢WhenyouissueaDROP TABLE statementinImpala,thatremovestheconnection thatImpalahaswiththe
associateddatafiles,butdoesnotphysicallyremovetheunderlying data.Youcancontinuetousethedatafiles
withotherHadoopcomponen tsandHDFSoperations.
â¢Toseewhetheratableisinternalorexternal,anditsassociatedHDFSlocation,issuethestatementDESCRIBE
FORMATTED table_name .TheTable Type fielddisplaysMANAGED_TABLE forinternaltablesand
EXTERNAL_TABLE forexternaltables.TheLocation fielddisplaysthepathofthetabledirectoryasanHDFS
URI.
â¢WhenyouissueanALTER TABLE statementtorenameanexternaltable,alldatafilesareleftintheiroriginal
locations.
ApacheImpalaGuide|197ImpalaSQLLanguageReference
â¢YoucanpointmultipleexternaltablesatthesameHDFSdirectorybyusingthesameLOCATION attributeforeach
one.Thetablescouldhavedifferentcolumndefinitions,aslongasthenumberandtypesofcolumnsarecompatible
withtheschemaevolutionconsiderationsfortheunderlying filetype.Forexample,fortextdatafiles,onetable
mightdefineacertaincolumnasaSTRINGwhileanotherdefinesthesamecolumnasaBIGINT.
Examples:
Youcanswitchatablefrominternaltoexternal,orfromexternaltointernal,byusingtheALTER TABLE statement:
-- Switch a table from internal to external.
ALTER TABLE table_name  SET TBLPROPERTIES('EXTERNAL'='TRUE');
-- Switch a table from external to internal.
ALTER TABLE table_name  SET TBLPROPERTIES('EXTERNAL'='FALSE');
IftheKuduserviceisintegratedwiththeHiveMetastore,theaboveoperationsarenotsupported.
FileFormats
Eachtablehasanassociatedfileformat,whichdetermineshowImpalainterpretstheassociateddatafiles.SeeHow
ImpalaWorkswithHadoopFileFormatsonpage634fordetails.
YousetthefileformatduringtheCREATE TABLE statement,orchangeitlaterusingtheALTER TABLE statement.
Partitioned tablescanhaveadifferentfileformatforindividual partitions, allowingyoutochangethefileformatused
inyourETLprocessfornewdatawithoutgoingbackandreconvertingalltheexistingdatainthesametable.
AnyINSERTstatementsproducenewdatafileswiththecurrentfileformatofthetable.Forexistingdatafiles,changing
thefileformatofthetabledoesnotautomaticallydoanydataconversion.YoumustuseTRUNCATE TABLE orINSERT
OVERWRITE toremoveanypreviousdatafilesthatusetheoldfileformat.ThenyouusetheLOAD DATA statement,
INSERT ... SELECT ,orothermechanism toputdatafilesofthecorrectformatintothetable.
Thedefaultfileformat,text,isthemostflexibleandeasytoproducewhenyouarejustgettingstartedwithImpala.
TheParquetfileformatoffersthehighestqueryperformance andusescompressiontoreducestoragerequirements;
therefore,wherepractical,useParquetforImpalatableswithsubstantialamountsofdata.Also,thecomplextypes
(ARRAY,STRUCT,andMAP)availableinCDH5.5/Impala2.3andhigherarecurrentlyonlysupportedwiththeParquet
filetype.BasedonyourexistingETLworkflow,youmightuseotherfileformatssuchasAvro,possiblydoingafinal
conversionsteptoParquettotakeadvantageofitsperformance foranalyticqueries.
KuduTables
Bydefault,tablesstoredinApacheKuduaretreatedspecially,becauseKudumanagesitsdataindependen tlyofHDFS
files.
AllmetadatathatImpalaneedsisstoredintheHMS.
WhenKuduisnotintegratedwiththeHMS,whenyoucreateaKudutablethroughImpala,thetableisassignedan
internalKudutablenameoftheformimpala:: db_name.table_name .YoucanseetheKudu-assigned nameinthe
outputofDESCRIBE FORMATTED ,inthekudu.table_name fieldofthetableproperties.
ForImpala-Kudumanagedtables,ALTER TABLE ... RENAME renamesboththeImpalaandtheKudutable.
ForImpala-Kuduexternaltables,ALTER TABLE ... RENAME renamesjusttheImpalatable.TochangetheKudu
tablethatanImpalaexternaltablepointsto,useALTER TABLE impala_name  SET
TBLPROPERTIES('kudu.table_name' = ' different_kudu_table_name ').Theunderlying Kudutablemust
alreadyexist.
Inpractice,externaltablesaretypicallyusedtoaccessunderlying KudutablesthatwerecreatedoutsideofImpala,
thatis,throughtheKuduAPI.
TheSHOW TABLE STATS outputforaKudutableshowsKudu-specific detailsaboutthelayoutofthetable.Instead
ofinformationaboutthenumberandsizesoffiles,theinformationisdividedbytheKudutablets.Foreachtablet,the
outputincludesthefields# Rows(although thisnumberisnotcurrentlycomputed),Start Key ,Stop Key ,Leader
198|ApacheImpalaGuideImpalaSQLLanguageReference
Replica ,and# Replicas .TheoutputofSHOW COLUMN STATS ,illustratingthedistribution ofvalueswithineach
column,isthesameforKudutablesasforHDFS-backedtables.
IftheKuduserviceisnotintegratedwiththeHiveMetastore,thedistinctionbetweeninternalandexternaltableshas
somespecialdetailsforKudutables.TablescreatedentirelythroughImpalaareinternaltables.Thetablenameas
representedwithinKuduincludesnotationsuchasanimpala:: prefixandtheImpaladatabasename.ExternalKudu
tablesarethosecreatedbyanon-Impala mechanism, suchasauserapplicationcallingtheKuduAPIs.Forthesetables,
theCREATE EXTERNAL TABLE syntaxletsyouestablishamapping fromImpalatotheexistingKudutable:
CREATE EXTERNAL TABLE impala_name STORED AS KUDU
  TBLPROPERTIES('kudu.table_name' = 'original_kudu_name');
ExternalKudutablesdifferinoneimportantwayfromotherexternaltables:addingordroppingacolumnorrange
partition changesthedataintheunderlying Kudutable,incontrasttoanHDFS-backedexternaltablewhereexisting
datafilesareleftuntouched.
OverviewofImpalaViews
Viewsarelightweightlogicalconstructsthatactasaliasesforqueries.Youcanspecifyaviewnameinaquery(aSELECT
statementortheSELECTportionofanINSERTstatement)whereyouwouldusuallyspecifyatablename.
Aviewletsyou:
â¢Issuecomplicatedquerieswithcompactandsimplesyntax:
-- Take a complicated reporting query, plug it into a CREATE VIEW statement...
create view v1 as select c1, c2, avg(c3) from t1 group by c3 order by c1 desc limit 10;
-- ... and now you can produce the report with 1 line of code.
select * from v1;
â¢Reducemaintenance,byavoidingtheduplicationofcomplicatedqueriesacrossmultipleapplicationsinmultiple
languages:
create view v2 as select t1.c1, t1.c2, t2.c3 from t1 join t2 on (t1.id = t2.id);
-- This simple query is safer to embed in reporting applications than the longer query
 above.
-- The view definition can remain stable even if the structure of the underlying tables
 changes.
select c1, c2, c3 from v2;
â¢Buildanew,morerefinedqueryontopoftheoriginalquerybyaddingnewclauses,select-listexpressions,function
calls,andsoon:
create view average_price_by_category as select category, avg(price) as avg_price from
 products group by category;
create view expensive_categories as select category, avg_price from 
average_price_by_category order by avg_price desc limit 10000;
create view top_10_expensive_categories as select category, avg_price from 
expensive_categories limit 10;
Thistechnique letsyoubuildupseveralmoreorlessgranularvariationsofthesamequery,andswitchbetween
themwhenappropriate.
â¢Setupaliaseswithintuitivenamesfortables,columns,resultsetsfromjoins,andsoon:
-- The original tables might have cryptic names inherited from a legacy system.
create view action_items as select rrptsk as assignee, treq as due_date, dmisc as notes
 from vxy_t1_br;
-- You can leave original names for compatibility, build new applications using more 
intuitive ones.
select assignee, due_date, notes from action_items;
ApacheImpalaGuide|199ImpalaSQLLanguageReference
â¢Swaptableswithothersthatusedifferentfileformats,partitioning schemes, andsoonwithoutanydowntime
fordatacopyingorconversion:
create table slow (x int, s string) stored as textfile;
create view report as select s from slow where x between 20 and 30;
-- Query is kind of slow due to inefficient table definition, but it works.
select * from report;
create table fast (s string) partitioned by (x int) stored as parquet;
-- ...Copy data from SLOW to FAST. Queries against REPORT view continue to work...
-- After changing the view definition, queries will be faster due to partitioning,
-- binary format, and compression in the new table.
alter view report as select s from fast where x between 20 and 30;
select * from report;
â¢Avoidcodinglengthysubqueries andrepeatingthesamesubquerytextinmanyotherqueries.
â¢Setupfine-grainedsecuritywhereausercanquerysomecolumnsfromatablebutnotothercolumns.Because
CDH5.5/Impala2.3andhighersupportcolumn-levelauthorization,thistechnique isnolongerrequired.Ifyou
formerlyimplemen tedcolumn-levelsecuritythroughviews,seeHiveSQLSyntaxforUsewithSentryfordetails
aboutthecolumn-levelauthorizationfeature.
TheSQLstatementsthatconfigureviewsareCREATEVIEWStatementonpage248,ALTERVIEWStatementonpage
218,andDROPVIEWStatementonpage270.Youcanspecifyviewnameswhenqueryingdata(SELECTStatementon
page295)andcopyingdatafromonetabletoanother(INSERTStatementonpage277).TheWITHclausecreatesan
inlineview,thatonlyexistsforthedurationofasinglequery.
[localhost:21000] > create view trivial as select * from customer;
[localhost:21000] > create view some_columns as select c_first_name, c_last_name, c_login
 from customer;
[localhost:21000] > select * from some_columns limit 5;
Query finished, fetching results ...
+--------------+-------------+---------+
| c_first_name | c_last_name | c_login |
+--------------+-------------+---------+
| Javier       | Lewis       |         |
| Amy          | Moses       |         |
| Latisha      | Hamilton    |         |
| Michael      | White       |         |
| Robert       | Moran       |         |
+--------------+-------------+---------+
[localhost:21000] > create view ordered_results as select * from some_columns order by
 c_last_name desc, c_first_name desc limit 1000;
[localhost:21000] > select * from ordered_results limit 5;
Query: select * from ordered_results limit 5
Query finished, fetching results ...
+--------------+-------------+---------+
| c_first_name | c_last_name | c_login |
+--------------+-------------+---------+
| Thomas       | Zuniga      |         |
| Sarah        | Zuniga      |         |
| Norma        | Zuniga      |         |
| Lloyd        | Zuniga      |         |
| Lisa         | Zuniga      |         |
+--------------+-------------+---------+
Returned 5 row(s) in 0.48s
Thepreviousexampleusesdescending orderforORDERED_RESULTS becauseinthesampleTPCD-Hdata,thereare
somerowswithemptystringsforbothC_FIRST_NAME andC_LAST_NAME ,makingthelowest-orderednamesunuseful
inasamplequery.
create view visitors_by_day as select day, count(distinct visitors) as howmany from 
web_traffic group by day;
create view top_10_days as select day, howmany from visitors_by_day order by howmany 
limit 10;
select * from top_10_days;
Usagenotes:
200|ApacheImpalaGuideImpalaSQLLanguageReference
Toseethedefinitionofaview,issueaDESCRIBE FORMATTED statement,whichshowsthequeryfromtheoriginal
CREATE VIEW statement:
[localhost:21000] > create view v1 as select * from t1;
[localhost:21000] > describe formatted v1;
Query finished, fetching results ...
+------------------------------+------------------------------+------------+
| name                         | type                         | comment    |
+------------------------------+------------------------------+------------+
| # col_name                   | data_type                    | comment    |
|                              | NULL                         | NULL       |
| x                            | int                          | None       |
| y                            | int                          | None       |
| s                            | string                       | None       |
|                              | NULL                         | NULL       |
| # Detailed Table Information | NULL                         | NULL       |
| Database:                    | views                        | NULL       |
| Owner:                       | doc_demo                     | NULL       |
| CreateTime:                  | Mon Jul 08 15:56:27 EDT 2013 | NULL       |
| LastAccessTime:              | UNKNOWN                      | NULL       |
| Protect Mode:                | None                         | NULL       |
| Retention:                   | 0                            | NULL       |
| Table Type:                  | VIRTUAL_VIEW                 | NULL       |
| Table Parameters:            | NULL                         | NULL       |
|                              | transient_lastDdlTime        | 1373313387 |
|                              | NULL                         | NULL       |
| # Storage Information        | NULL                         | NULL       |
| SerDe Library:               | null                         | NULL       |
| InputFormat:                 | null                         | NULL       |
| OutputFormat:                | null                         | NULL       |
| Compressed:                  | No                           | NULL       |
| Num Buckets:                 | 0                            | NULL       |
| Bucket Columns:              | []                           | NULL       |
| Sort Columns:                | []                           | NULL       |
|                              | NULL                         | NULL       |
| # View Information           | NULL                         | NULL       |
| View Original Text:          | SELECT * FROM t1             | NULL       |
| View Expanded Text:          | SELECT * FROM t1             | NULL       |
+------------------------------+------------------------------+------------+
PriortoImpala1.4.0,itwasnotpossibletousetheCREATE TABLE LIKE view_name syntax.InImpala1.4.0and
higher,youcancreateatablewiththesamecolumndefinitionsasaviewusingtheCREATE TABLE LIKE technique.
AlthoughCREATE TABLE LIKE normally inheritsthefileformatoftheoriginaltable,aviewhasnounderlying file
format,soCREATE TABLE LIKE view_name producesatexttablebydefault.Tospecifyadifferentfileformat,
includeaSTORED AS file_format clauseattheendoftheCREATE TABLE LIKE statement.
Complextypeconsiderations:
Fortablescontainingcomplextypecolumns(ARRAY,STRUCT,orMAP),youtypicallyusejoinqueriestorefertothe
complexvalues.Youcanuseviewstohidethejoinnotation,makingsuchtablesseemliketraditional denormaliz ed
tables,andmakingthosetablesqueryablebybusinessintelligencetoolsthatdonothavebuilt-insupportforthose
complextypes.SeeAccessing ComplexTypeDatainFlattenedFormUsingViewsonpage159fordetails.
TheSTRAIGHT_JOIN hintaffectsthejoinorderoftablereferencesinthequeryblockcontainingthehint.Itdoesnot
affectthejoinorderofnestedqueries,suchasviews,inlineviews,orWHERE-clausesubqueries. Tousethishintfor
performance tuningofcomplexqueries,applythehinttoallqueryblocksthatneedafixedjoinorder.
Restrictions:
â¢YoucannotinsertintoanImpalaview.(Insomedatabasesystems,thisoperationisallowedandinsertsrowsinto
thebasetable.)Youcanuseaviewnameontheright-handsideofanINSERTstatement,intheSELECTpart.
â¢Ifaviewappliestoapartitioned table,anypartitionpruningconsiderstheclausesonboththeoriginalqueryand
anyadditional WHEREpredicatesinthequerythatreferstotheview.PriortoImpala1.4,onlytheWHEREclauses
ontheoriginalqueryfromtheCREATE VIEW statementwereusedforpartition pruning.
ApacheImpalaGuide|201ImpalaSQLLanguageReference
â¢AnORDER BY clausewithoutanadditional LIMITclauseisignoredinanyviewdefinition.Ifyouneedtosortthe
entireresultsetfromaview,useanORDER BY clauseintheSELECTstatementthatqueriestheview.Youcan
stillmakeasimpleâtop10âreportbycombining theORDER BY andLIMITclausesinthesameviewdefinition:
[localhost:21000] > create table unsorted (x bigint);
[localhost:21000] > insert into unsorted values (1), (9), (3), (7), (5), (8), (4), (6),
 (2);
[localhost:21000] > create view sorted_view as select x from unsorted order by x;
[localhost:21000] > select x from sorted_view; -- ORDER BY clause in view has no effect.
+---+
| x |
+---+
| 1 |
| 9 |
| 3 |
| 7 |
| 5 |
| 8 |
| 4 |
| 6 |
| 2 |
+---+
[localhost:21000] > select x from sorted_view order by x; -- View query requires ORDER
 BY at outermost level.
+---+
| x |
+---+
| 1 |
| 2 |
| 3 |
| 4 |
| 5 |
| 6 |
| 7 |
| 8 |
| 9 |
+---+
[localhost:21000] > create view top_3_view as select x from unsorted order by x limit 
3;
[localhost:21000] > select x from top_3_view; -- ORDER BY and LIMIT together in view 
definition are preserved.
+---+
| x |
+---+
| 1 |
| 2 |
| 3 |
+---+
â¢TheTABLESAMPLE clauseoftheSELECTstatementdoesnotapplytoatablereferencederivedfromaview,a
subquery,oranythingotherthanarealbasetable.ThisclauseonlyworksfortablesbackedbyHDFSorHDFS-like
datafiles,thereforeitdoesnotapplytoKuduorHBasetables.
Relatedstatements:CREATEVIEWStatementonpage248,ALTERVIEWStatementonpage218,DROPVIEWStatement
onpage270
ImpalaSQLStatements
TheImpalaSQLdialectsupports arangeofstandardelements,plussomeextensionsforBigDatausecasesrelatedto
dataloadinganddatawarehousing.
Note:
Intheimpala-shell interpreter,asemicolonattheendofeachstatementisrequired.Sincethe
semicolonisnotactuallypartoftheSQLsyntax,wedonotincludeitinthesyntaxdefinitionofeach
statement,butwedoshowitinexamplesintendedtoberuninimpala-shell .
202|ApacheImpalaGuideImpalaSQLLanguageReference
DDLStatements
DDLreferstoâDataDefinitionLanguageâ,asubsetofSQLstatementsthatchangethestructureofthedatabaseschema
insomeway,typicallybycreating,deleting,ormodifyingschemaobjectssuchasdatabases,tables,andviews.Most
ImpalaDDLstatementsstartwiththekeywordsCREATE,DROP,orALTER.
TheImpalaDDLstatementsare:
â¢ALTERTABLEStatementonpage205
â¢ALTERVIEWStatementonpage218
â¢COMPUTE STATSStatementonpage219
â¢CREATEDATABASEStatementonpage226
â¢CREATEFUNCTIONStatementonpage228
â¢CREATEROLEStatement(CDH5.2orhigheronly)onpage234
â¢CREATETABLEStatementonpage234
â¢CREATEVIEWStatementonpage248
â¢DROPDATABASEStatementonpage262
â¢DROPFUNCTIONStatementonpage263
â¢DROPROLEStatement(CDH5.2orhigheronly)onpage265
â¢DROPTABLEStatementonpage268
â¢DROPVIEWStatementonpage270
â¢GRANTStatement(CDH5.2orhigheronly)onpage273
â¢REVOKEStatement(CDH5.2orhigheronly)onpage293
AfterImpalaexecutesaDDLcommand, informationaboutavailabletables,columns,views,partitions, andsoonis
automaticallysynchronizedbetweenalltheImpalanodesinacluster.(PriortoImpala1.2,youhadtoissueaREFRESH
orINVALIDATE METADATA statementmanually ontheothernodestomakethemawareofthechanges.)
Ifthetimingofmetadataupdatesissignificant,forexampleifyouuseround-robinscheduling whereeachquerycould
beissuedthroughadifferentImpalanode,youcanenabletheSYNC_DDL queryoptiontomaketheDDLstatement
waituntilallnodeshavebeennotifiedaboutthemetadatachanges.
SeeUsingImpalawiththeAmazonS3Filesystemonpage692fordetailsabouthowImpalaDDLstatementsinteract
withtablesandpartitions storedintheAmazonS3filesystem.
Although theINSERTstatementisofficiallyclassified asaDML(datamanipula tionlanguage)statement,italsoinvolves
metadatachangesthatmustbebroadcasttoallImpalanodes,andsoisalsoaffectedbytheSYNC_DDL queryoption.
BecausetheSYNC_DDL queryoptionmakeseachDDLoperationtakelongerthannormal,youmightonlyenableit
beforethelastDDLoperationinasequence. Forexample,ifyouarerunningascriptthatissuesmultipleofDDL
operationstosetupanentirenewschema,addseveralnewpartitions, andsoon,youmightminimizetheperformance
overheadbyenablingthequeryoptiononlybeforethelastCREATE,DROP,ALTER,orINSERTstatement.Thescript
onlyfinisheswhenalltherelevantmetadatachangesarerecognizedbyalltheImpalanodes,soyoucouldconnectto
anynodeandissuequeriesthroughit.
TheclassificationofDDL,DML,andotherstatementsisnotnecessarily thesamebetweenImpalaandHive.Impala
organizesthesestatementsinawayintendedtobefamiliartopeoplefamiliarwithrelationaldatabasesordata
warehouseproducts.Statementsthatmodifythemetastoredatabase,suchasCOMPUTE STATS ,areclassified asDDL.
Statementsthatonlyquerythemetastoredatabase,suchasSHOWorDESCRIBE ,areputintoaseparatecategoryof
utilitystatements.
Note:ThequerytypesshownintheImpaladebugwebuserinterfacemightnotmatchexactlythe
categorieslistedhere.Forexample,currentlytheUSEstatementisshownasDDLinthedebugweb
UI.ThequerytypesshowninthedebugwebUIaresubjecttochange,forimprovedconsistency.
Relatedinformation:
TheothermajorclassificationsofSQLstatementsaredatamanipula tionlanguage(seeDMLStatementsonpage204)
andqueries(seeSELECTStatementonpage295).
ApacheImpalaGuide|203ImpalaSQLLanguageReference
DMLStatements
DMLreferstoâDataManipula tionLanguageâ,asubsetofSQLstatementsthatmodifythedatastoredintables.Because
Impalafocusesonqueryperformance andleveragestheappend-only natureofHDFSstorage,currentlyImpalaonly
supports asmallsetofDMLstatements:
â¢DELETEStatement(CDH5.10orhigheronly)onpage249.WorksforKudutablesonly.
â¢INSERTStatementonpage277.
â¢LOADDATAStatementonpage288.DoesnotapplyforHBaseorKudutables.
â¢UPDATEStatement(CDH5.10orhigheronly)onpage383.WorksforKudutablesonly.
â¢UPSERTStatement(CDH5.10orhigheronly)onpage384.WorksforKudutablesonly.
INSERTinImpalaisprimarily optimizedforinserting largevolumesofdatainasinglestatement,tomakeeffective
useofthemulti-meg abyteHDFSblocks.ThisisthewayinImpalatocreatenewdatafiles.Ifyouintendtoinsertone
orafewrowsatatime,suchasusingtheINSERT ... VALUES syntax,thattechnique ismuchmoreefficientfor
ImpalatablesstoredinHBase.SeeUsingImpalatoQueryHBaseTablesonpage684fordetails.
LOAD DATA movesexistingdatafilesintothedirectoryforanImpalatable,makingthemimmediatelyavailablefor
Impalaqueries.ThisisonewayinImpalatoworkwithdatafilesproducedbyotherHadoopcomponen ts.(CREATE
EXTERNAL TABLE istheotheralternative;withexternaltables,youcanqueryexistingdatafiles,whilethefilesremain
intheiroriginallocation.)
InCDH5.10/Impala2.8andhigher,ImpaladoessupporttheUPDATE,DELETE,andUPSERTstatementsforKudu
tables.ForHDFSorS3tables,tosimulatetheeffectsofanUPDATEorDELETEstatementinotherdatabasesystems,
typicallyyouuseINSERTorCREATE TABLE AS SELECT tocopydatafromonetabletoanother,filteringoutor
changing theappropriaterowsduringthecopyoperation.
YoucanalsoachievearesultsimilartoUPDATEbyusingImpalatablesstoredinHBase.Whenyouinsertarowintoan
HBasetable,andthetablealreadycontainsarowwiththesamevalueforthekeycolumn,theolderrowishidden,
effectivelythesameasasingle-rowUPDATE.
ImpalacanperformDMLoperationsfortablesorpartitions storedintheAmazonS3filesystemwithCDH5.8/Impala
2.6andhigher.SeeUsingImpalawiththeAmazonS3Filesystemonpage692fordetails.
Relatedinformation:
TheothermajorclassificationsofSQLstatementsaredatadefinitionlanguage(seeDDLStatementsonpage203)and
queries(seeSELECTStatementonpage295).
ALTERDATABASEStatement
TheALTER DATABASE statementchangesthecharacteristicsofadatabase.
UsetheSET OWNER clausetotransfertheownershipofthedatabasefromthecurrentownertoanotheruserora
role.
Thedatabaseownerisoriginally settotheuserwhocreatesthedatabase.WhenobjectownershipisenabledinSentry,
anownerofadatabasecanhavetheALLwithGRANTorALLwithoutGRANTprivilege.ThetermOWNERisusedto
differentiatebetweentheALLprivilegethatisexplicitlygrantedviatheGRANTstatementandaprivilegethatisimplicitly
grantedbytheCREATE DATABASE statement.
Syntax:
ALTER DATABASE database_name  SET OWNER USER user_name;
ALTER DATABASE database_name  SET OWNER ROLE role_name;
Statementtype:DDL
Cancellation:Cannotbecancelled.
Addedin:CDH6.1/Impala3.1
204|ApacheImpalaGuideImpalaSQLLanguageReference
ALTERTABLEStatement
TheALTER TABLE statementchangesthestructureorpropertiesofanexistingImpalatable.
InImpala,thisisprimarily alogicaloperationthatupdatesthetablemetadatainthemetastoredatabasethatImpala
shareswithHive.MostALTER TABLE operationsdonotactuallyrewrite,move,andsoontheactualdatafiles.(The
RENAME TO clauseistheoneexception;itcancauseHDFSfilestobemovedtodifferentpaths.)WhenyoudoanALTER
TABLEoperation,youtypicallyneedtoperformcorresponding physicalfilesystemoperations,suchasrewritingthe
datafilestoincludeextrafields,orconvertingthemtoadifferentfileformat.
Syntax:
ALTER TABLE [ old_db_name .]old_table_name  RENAME TO [ new_db_name .]new_table_name
ALTER TABLE name ADD [IF NOT EXISTS] COLUMNS ( col_spec [, col_spec  ...])
ALTER TABLE name REPLACE COLUMNS ( col_spec [, col_spec  ...])
ALTER TABLE name ADD COLUMN [IF NOT EXISTS] col_spec
ALTER TABLE name DROP [COLUMN] column_name
ALTER TABLE name CHANGE column_name col_spec
ALTER TABLE name SET OWNER USER user_name
ALTER TABLE name SET OWNER ROLE role_name
-- Kudu tables only.
ALTER TABLE name ALTER [COLUMN] column_name
  { SET kudu_storage_attr attr_value
    | DROP DEFAULT }
kudu_storage_attr ::= { DEFAULT | BLOCK_SIZE | ENCODING | COMPRESSION }
-- Non-Kudu tables only.
ALTER TABLE name ALTER [COLUMN] column_name
  SET COMMENT ' comment_text '
ALTER TABLE name ADD [IF NOT EXISTS] PARTITION ( partition_spec )
[location_spec ]
[cache_spec ]
ALTER TABLE name ADD [IF NOT EXISTS] RANGE PARTITION kudu_partition_spec
ALTER TABLE name DROP [IF EXISTS] PARTITION ( partition_spec )
[PURGE]
ALTER TABLE name DROP [IF EXISTS] RANGE PARTITION kudu_partition_spec
ALTER TABLE name RECOVER PARTITIONS
ALTER TABLE name [PARTITION ( partition_spec )]
  SET { FILEFORMAT file_format
  | ROW FORMAT row_format
  | LOCATION ' hdfs_path_of_directory '
  | TBLPROPERTIES ( table_properties )
  | SERDEPROPERTIES ( serde_properties ) }
ALTER TABLE namecolname
  ('statsKey '='val, ...)
statsKey ::= numDVs | numNulls | avgSize | maxSize
ALTER TABLE name [PARTITION ( partition_spec )] SET { CACHED IN ' pool_name ' [WITH 
REPLICATION = integer] | UNCACHED }
new_name  ::= [new_database .]new_table_name
col_spec  ::= col_name type_name  COMMENT ' column-comment ' [kudu_attributes ]
kudu_attributes  ::= { [NOT] NULL | ENCODING codec | COMPRESSION algorithm  |
  DEFAULT constant  | BLOCK_SIZE number }
partition_spec  ::= simple_partition_spec  | complex_partition_spec
simple_partition_spec  ::= partition_col =constant_value
ApacheImpalaGuide|205ImpalaSQLLanguageReference
complex_partition_spec  ::= comparison_expression_on_partition_col
kudu_partition_spec  ::= constant range_operator  VALUES range_operator constant  | VALUE
 = constant
cache_spec ::= CACHED IN ' pool_name ' [WITH REPLICATION = integer] | UNCACHED
location_spec ::= LOCATION ' hdfs_path_of_directory '
table_properties  ::= 'name'='value'[, 'name'='value' ...]
serde_properties  ::= 'name'='value'[, 'name'='value' ...]
file_format  ::= { PARQUET | TEXTFILE | RCFILE | SEQUENCEFILE | AVRO }
row_format  ::= DELIMITED
  [FIELDS TERMINATED BY ' char' [ESCAPED BY ' char']]
  [LINES TERMINATED BY ' char']
Statementtype:DDL
Complextypeconsiderations:
InCDH5.5/Impala2.3andhigher,theALTER TABLE statementcanchangethemetadatafortablescontaining
complextypes(ARRAY,STRUCT,andMAP).Forexample,youcanuseanADD COLUMNS ,DROP COLUMN ,orCHANGE
clausetomodifythetablelayoutforcomplextypecolumns.Although Impalaqueriesonlyworkforcomplextype
columnsinParquettables,thecomplextypesupportintheALTER TABLE statementappliestoallfileformats.For
example,youcanuseImpalatoupdatemetadataforastagingtableinanon-Parquetfileformatwherethedatais
populatedbyHive.OryoucanuseALTER TABLE SET FILEFORMAT tochangetheformatofanexistingtableto
ParquetsothatImpalacanqueryit.Remember thatchanging thefileformatforatabledoesnotconvertthedatafiles
withinthetable;youmustprepareanyParquetdatafilescontainingcomplextypesoutsideImpala,andbringthem
intothetableusingLOAD DATA orupdatingthetable'sLOCATION property.SeeComplexTypes(CDH5.5orhigher
only)onpage139fordetailsaboutusingcomplextypes.
Usagenotes:
Wheneveryouspecifypartitions inanALTER TABLE statement,throughthePARTITION ( partition_spec )clause,
youmustincludeallthepartitioning columnsinthespecification.
MostoftheALTER TABLE operationsworkthesameforinternaltables(managedbyImpala)asforexternaltables
(withdatafileslocatedinarbitrarylocations).Theexceptionisrenamingatable;foranexternaltable,theunderlying
datadirectoryisnotrenamedormoved.
Todroporaltermultiplepartitions:
InCDH5.10/Impala2.8andhigher,theexpressionforthepartition clausewithaDROPorSEToperationcaninclude
comparison operatorssuchas<,IN,orBETWEEN ,andBooleanoperatorssuchasANDandOR.
Forexample,youmightdropagroupofpartitions corresponding toaparticular daterangeafterthedataâagesoutâ:
alter table historical_data drop partition (year < 1995);
alter table historical_data drop partition (year = 1996 and month between 1 and 6);
Fortableswithmultiplepartition keyscolumns,youcanspecifymultipleconditions separatedbycommas,andthe
operationonlyappliestothepartitions thatmatchalltheconditions (similartousinganANDclause):
alter table historical_data drop partition (year < 1995, last_name like 'A%');
206|ApacheImpalaGuideImpalaSQLLanguageReference
Thistechnique canalsobeusedtochangethefileformatofgroupsofpartitions, aspartofanETLpipelinethat
periodicallyconsolidatesandrewritestheunderlying datafilesinadifferentfileformat:
alter table fast_growing_data partition (year = 2016, month in (10,11,12)) set fileformat
 parquet;
Note:
Theextendedsyntaxinvolvingcomparison operatorsandmultiplepartitions appliestotheSET
FILEFORMAT ,SET TBLPROPERTIES ,SET SERDEPROPERTIES ,andSET [UN]CACHED clauses.You
canalsousethissyntaxwiththePARTITION clauseintheCOMPUTE INCREMENTAL STATS statement,
andwiththePARTITION clauseoftheSHOW FILES statement.SomeformsofALTER TABLE still
onlyapplytoonepartitionatatime:theSET LOCATION andADD PARTITION clauses.ThePARTITION
clausesintheLOAD DATA andINSERTstatementsalsoonlyapplytoonepartition atatime.
ADDLstatementthatappliestomultiplepartitions isconsideredsuccessful(resultinginnochanges)
evenifnopartitions matchtheconditions. TheresultsarethesameasiftheIF EXISTS clausewas
specified.
Theperformance andscalabilityofthistechnique issimilartoissuingasequence ofsingle-partition
ALTER TABLE statementsinquicksuccession. Tominimizebottlenecksduetocommunic ationwith
themetastoredatabase,orcausingotherDDLoperationsonthesametabletowait,testtheeffects
ofperformingALTER TABLE statementsthataffectlargenumbersofpartitions.
AmazonS3considerations:
Youcanspecifyans3a://prefixontheLOCATION attributeofatableorpartition tomakeImpalaquerydatafrom
theAmazonS3filesystem.InCDH5.8/Impala2.6andhigher,Impalaautomaticallyhandlescreatingorremovingthe
associatedfolderswhenyouissueALTER TABLE statementswiththeADD PARTITION orDROP PARTITION clauses.
InCDH5.8/Impala2.6andhigher,ImpalaDDLstatementssuchasCREATE DATABASE ,CREATE TABLE ,DROP
DATABASE CASCADE ,DROP TABLE ,andALTER TABLE [ADD|DROP] PARTITION cancreateorremovefoldersas
neededintheAmazonS3system.PriortoCDH5.8/Impala2.6,youhadtocreatefoldersyourselfandpointImpala
database,tables,orpartitions atthem,andmanually removefolderswhennolongerneeded.SeeUsingImpalawith
theAmazonS3Filesystemonpage692fordetailsaboutreadingandwritingS3datawithImpala.
HDFScaching(CACHEDINclause):
IfyouspecifytheCACHED IN clause,anyexistingorfuturedatafilesinthetabledirectoryorthepartitionsubdirectories
aredesignatedtobeloadedintomemorywiththeHDFScachingmechanism. SeeUsingHDFSCachingwithImpala
(CDH5.3orhigheronly)onpage593fordetailsaboutusingtheHDFScachingfeature.
InCDH5.4/Impala2.2andhigher,theoptionalWITH REPLICATION clauseforCREATE TABLE andALTER TABLE
letsyouspecifyareplicationfactor,thenumberofhostsonwhichtocachethesamedatablocks.WhenImpala
processesacacheddatablock,wherethecachereplicationfactorisgreaterthan1,Impalarandomly selectsahost
thathasacachedcopyofthatdatablock.ThisoptimizationavoidsexcessiveCPUusageonasinglehostwhenthe
samecacheddatablockisprocessedmultipletimes.Clouderarecommends specifyingavaluegreaterthanorequal
totheHDFSblockreplicationfactor.
IfyouconnecttodifferentImpalanodeswithinanimpala-shell sessionforload-balancing purposes, youcanenable
theSYNC_DDL queryoptiontomakeeachDDLstatementwaitbeforereturning,untiltheneworchangedmetadata
hasbeenreceivedbyalltheImpalanodes.SeeSYNC_DDL QueryOptiononpage361fordetails.
ThefollowingsectionsshowexamplesoftheusecasesforvariousALTER TABLE clauses.
Torenameatable(RENAME TOclause):
TheRENAME TO clauseletsyouchangethenameofanexistingtable,andoptionallywhichdatabaseitislocatedin.
ApacheImpalaGuide|207ImpalaSQLLanguageReference
Forinternaltables,thisoperationphysicallyrenamesthedirectorywithinHDFSthatcontainsthedatafiles;theoriginal
directorynamenolongerexists.Byqualifyingthetablenameswithdatabasenames,youcanusethistechnique to
moveaninternaltable(anditsassociateddatadirectory)fromonedatabasetoanother.Forexample:
create database d1;
create database d2;
create database d3;
use d1;
create table mobile (x int);
use d2;
-- Move table from another database to the current one.
alter table d1.mobile rename to mobile;
use d1;
-- Move table from one database to another.
alter table d2.mobile rename to d3.mobile;
Tochangetheownerofatable:
ALTER TABLE name SET OWNER USER user_name;
ALTER TABLE name SET OWNER ROLE role_name;
Thetableownerisoriginally settotheuserwhocreatesthetable.WhenobjectownershipisenabledinSentry,an
ownerofatablecanhavetheALLwithGRANTorALLwithoutGRANTprivilege.ThetermOWNERisusedtodifferentiate
betweentheALLprivilegethatisexplicitlygrantedviatheGRANTstatementandaprivilegethatisimplicitly granted
bytheCREATE TABLE statement.
UsetheALTER TABLE SET OWNER totransfertheownershipfromthecurrentownertoanotheruserorarole.
TochangethephysicallocationwhereImpalalooksfordatafilesassociatedwithatableorpartition:
ALTER TABLE table_name  [PARTITION ( partition_spec )] SET LOCATION ' hdfs_path_of_directory ';
ThepathyouspecifyisthefullHDFSpathwherethedatafilesreside,orwillbecreated.Impaladoesnotcreateany
additional subdirectorynamedafterthetable.Impaladoesnotmoveanydatafilestothisnewlocationorchangeany
datafilesthatmightalreadyexistinthatdirectory.
Tosetthelocationforasinglepartition, includethePARTITION clause.Specifyallthesamepartitioning columnsfor
thetable,withaconstantvalueforeach,topreciselyidentifythesinglepartition affectedbythestatement:
create table p1 (s string) partitioned by (month int, day int);
-- Each ADD PARTITION clause creates a subdirectory in HDFS.
alter table p1 add partition (month=1, day=1);
alter table p1 add partition (month=1, day=2);
alter table p1 add partition (month=2, day=1);
alter table p1 add partition (month=2, day=2);
-- Redirect queries, INSERT, and LOAD DATA for one partition
-- to a specific different directory.
alter table p1 partition (month=1, day=1) set location '/usr/external_data/new_years_day';
Note:Ifyouarecreatingapartitionforthefirsttimeandspecifyingitslocation,formaximumefficiency,
useasingleALTER TABLE statementincluding boththeADD PARTITION andLOCATION clauses,
ratherthanseparatestatementswithADD PARTITION andSET LOCATION clauses.
Toautomaticallydetectnewpartition directoriesaddedthroughHiveorHDFSoperations:
InCDH5.5/Impala2.3andhigher,theRECOVER PARTITIONS clausescansapartitioned tabletodetectifanynew
partition directorieswereaddedoutsideofImpala,suchasbyHiveALTER TABLE statementsorbyhdfs dfs or
hadoop fs commands. TheRECOVER PARTITIONS clauseautomaticallyrecognizesanydatafilespresentinthese
newdirectories,thesameastheREFRESH statementdoes.
208|ApacheImpalaGuideImpalaSQLLanguageReference
Forexample,hereisasequence ofexamplesshowinghowyoumightcreateapartitioned tableinImpala,createnew
partitions throughHive,copydatafilesintothenewpartitions withthehdfscommand, andhaveImpalarecognize
thenewpartitions andnewdata:
InImpala,createthetable,andasinglepartition fordemonstrationpurposes:
create database recover_partitions;
use recover_partitions;
create table t1 (s string) partitioned by (yy int, mm int);
insert into t1 partition (yy = 2016, mm = 1) values ('Partition exists');
show files in t1;
+---------------------------------------------------------------------+------+--------------+
| Path                                                                | Size | Partition
    |
+---------------------------------------------------------------------+------+--------------+
| /user/hive/warehouse/recover_partitions.db/t1/yy=2016/mm=1/data.txt | 17B  | 
yy=2016/mm=1 |
+---------------------------------------------------------------------+------+--------------+
quit;
InHive,createsomenewpartitions. Inarealusecase,youmightcreatethepartitions andpopulatethemwithdata
asthefinalstagesofanETLpipeline.
hive> use recover_partitions;
OK
hive> alter table t1 add partition (yy = 2016, mm = 2);
OK
hive> alter table t1 add partition (yy = 2016, mm = 3);
OK
hive> quit;
Fordemonstrationpurposes, manually copydata(asinglerow)intothesenewpartitions, usingmanualHDFSoperations:
$ hdfs dfs -ls /user/hive/warehouse/recover_partitions.db/t1/yy=2016/
Found 3 items
drwxr-xr-x - impala   hive 0 2016-05-09 16:06 
/user/hive/warehouse/recover_partitions.db/t1/yy=2016/mm=1
drwxr-xr-x - jrussell hive 0 2016-05-09 16:14 
/user/hive/warehouse/recover_partitions.db/t1/yy=2016/mm=2
drwxr-xr-x - jrussell hive 0 2016-05-09 16:13 
/user/hive/warehouse/recover_partitions.db/t1/yy=2016/mm=3
$ hdfs dfs -cp /user/hive/warehouse/recover_partitions.db/t1/yy=2016/mm=1/data.txt \
  /user/hive/warehouse/recover_partitions.db/t1/yy=2016/mm=2/data.txt
$ hdfs dfs -cp /user/hive/warehouse/recover_partitions.db/t1/yy=2016/mm=1/data.txt \
  /user/hive/warehouse/recover_partitions.db/t1/yy=2016/mm=3/data.txt
hive> select * from t1;
OK
Partition exists  2016  1
Partition exists  2016  2
Partition exists  2016  3
hive> quit;
ApacheImpalaGuide|209ImpalaSQLLanguageReference
InImpala,initiallythepartitions anddataarenotvisible.RunningALTER TABLE withtheRECOVER PARTITIONS
clausescansthetabledatadirectorytofindanynewpartition directories,andthedatafilesinsidethem:
select * from t1;
+------------------+------+----+
| s                | yy   | mm |
+------------------+------+----+
| Partition exists | 2016 | 1  |
+------------------+------+----+
alter table t1 recover partitions;
select * from t1;
+------------------+------+----+
| s                | yy   | mm |
+------------------+------+----+
| Partition exists | 2016 | 1  |
| Partition exists | 2016 | 3  |
| Partition exists | 2016 | 2  |
+------------------+------+----+
Tochangethekey-valuepairsoftheTBLPROPERTIESandSERDEPROPERTIESfields:
ALTER TABLE table_name  SET TBLPROPERTIES (' key1'='value1', 'key2'='value2'[, ...]);
ALTER TABLE table_name  SET SERDEPROPERTIES (' key1'='value1', 'key2'='value2'[, ...]);
TheTBLPROPERTIES clauseisprimarily awaytoassociatearbitraryuser-specified dataitemswithaparticular table.
TheSERDEPROPERTIES clausesetsupmetadatadefininghowtablesarereadorwritten,neededinsomecasesby
HivebutnotusedextensivelybyImpala.Youwouldusethisclauseprimarily tochangethedelimiterinanexistingtext
tableorpartition, bysettingthe'serialization.format' and'field.delim' propertyvaluestothenewdelimiter
character.TheSERDEPROPERTIES clausedoesnotchangetheexistingdatainthetable.Thechangeonlyaffectsthe
futureinsertsintothetable.
UsetheDESCRIBE FORMATTED statementtoseethecurrentvaluesofthesepropertiesforanexistingtable.
SeeCREATETABLEStatementonpage234formoredetailsabouttheseclauses.
Tomanually setorupdatetableorcolumnstatistics:
Although formosttablestheCOMPUTE STATS orCOMPUTE INCREMENTAL STATS statementisallyouneedtokeep
tableandcolumnstatisticsuptodateforatable,sometimesforaverylargetableoronethatisupdatedfrequently,
thelengthoftimetorecomputeallthestatisticsmightmakeitimpracticaltorunthosestatementsasoftenasneeded.
Asaworkaround,youcanusetheALTER TABLE statementtosettablestatisticsattheleveloftheentiretableora
singlepartition, orcolumnstatisticsattheleveloftheentiretable.
Youcansetthenumrows valuefortablestatisticsbychanging theTBLPROPERTIES settingforatableorpartition.
Forexample:
create table analysis_data stored as parquet as select * from raw_data;
Inserted 1000000000 rows in 181.98s
compute stats analysis_data;
insert into analysis_data select * from smaller_table_we_forgot_before;
Inserted 1000000 rows in 15.32s
-- Now there are 1001000000 rows. We can update this single data point in the stats.
alter table analysis_data set tblproperties('numRows'='1001000000', 
'STATS_GENERATED_VIA_STATS_TASK'='true');
-- If the table originally contained 1 million rows, and we add another partition with
 30 thousand rows,
-- change the numRows property for the partition and the overall table.
alter table partitioned_data partition(year=2009, month=4) set tblproperties 
('numRows'='30000', 'STATS_GENERATED_VIA_STATS_TASK'='true');
alter table partitioned_data set tblproperties ('numRows'='1030000', 
'STATS_GENERATED_VIA_STATS_TASK'='true');
210|ApacheImpalaGuideImpalaSQLLanguageReference
SeeSettingTableStatisticsonpage584fordetails.
InCDH5.8/Impala2.6andhigher,youcanusetheSET COLUMN STATS clausetosetaspecificstatsvaluefora
particular column.
Youspecifyacase-insensitiv esymbolicnameforthekindofstatistics:numDVs,numNulls ,avgSize ,maxSize .The
keynamesandvaluesarebothquoted.Thisoperationappliestoanentiretable,notaspecificpartition. Forexample:
create table t1 (x int, s string);
insert into t1 values (1, 'one'), (2, 'two'), (2, 'deux');
show column stats t1;
+--------+--------+------------------+--------+----------+----------+
| Column | Type   | #Distinct Values | #Nulls | Max Size | Avg Size |
+--------+--------+------------------+--------+----------+----------+
| x      | INT    | -1               | -1     | 4        | 4        |
| s      | STRING | -1               | -1     | -1       | -1       |
+--------+--------+------------------+--------+----------+----------+
alter table t1 set column stats x ('numDVs'='2','numNulls'='0');
alter table t1 set column stats s ('numdvs'='3','maxsize'='4');
show column stats t1;
+--------+--------+------------------+--------+----------+----------+
| Column | Type   | #Distinct Values | #Nulls | Max Size | Avg Size |
+--------+--------+------------------+--------+----------+----------+
| x      | INT    | 2                | 0      | 4        | 4        |
| s      | STRING | 3                | -1     | 4        | -1       |
+--------+--------+------------------+--------+----------+----------+
Toreorganizecolumnsforatable:
YoucanaddmultiplecolumnsatatimeusingtheALTER TABLE statement.IfyouspecifytheIF NOT EXISTS clause,
ImpalasilentlyignorestheADDrequestanddoesnotreturnanerrorifacolumnwiththesamenameexistsinthe
table.
Whenyoureplacecolumns,alltheoriginalcolumndefinitionsarediscarded.
Youmightusethesestatementsifyoureceiveanewsetofdatafileswithdifferentdatatypesorcolumnsinadifferent
order.Thedatafilesareretained,soifthenewcolumnsareincompatiblewiththeoldones,useINSERT OVERWRITE
orLOAD DATA OVERWRITE toreplaceallthedatabeforeissuinganyfurtherqueries.
Forexample,hereishowyoumightaddcolumnstoanexistingtable.ThefirstALTER TABLE addstwonewcolumns,
andthesecondALTER TABLE addsonenewcolumn.AsingleImpalaqueryreadsboththeoldandnewdatafiles,
containingdifferentnumbersofcolumns.Foranycolumnsnotpresentinaparticular datafile,allthecolumnvalues
areconsideredtobeNULL.
create table t1 (x int);
insert into t1 values (1), (2);
alter table t1 add columns (s string, t timestamp);
insert into t1 values (3, 'three', now());
alter table t1 add columns (b boolean);
insert into t1 values (4, 'four', now(), true);
select * from t1 order by x;
+---+-------+-------------------------------+------+
| x | s     | t                             | b    |
+---+-------+-------------------------------+------+
| 1 | NULL  | NULL                          | NULL |
| 2 | NULL  | NULL                          | NULL |
| 3 | three | 2016-05-11 11:19:45.054457000 | NULL |
| 4 | four  | 2016-05-11 11:20:20.260733000 | true |
+---+-------+-------------------------------+------+
YoumightusetheCHANGEclausetorenameasinglecolumn,ortotreatanexistingcolumnasadifferenttypethan
before,suchastoswitchbetweentreatingacolumnasSTRINGandTIMESTAMP ,orbetweenINTandBIGINT.You
ApacheImpalaGuide|211ImpalaSQLLanguageReference
canonlydropasinglecolumnatatime;todropmultiplecolumns,issuemultipleALTER TABLE statements,ordefine
thenewsetofcolumnswithasingleALTER TABLE ... REPLACE COLUMNS statement.
Thefollowingexamplesshowsomesafeoperationstodroporchangecolumns.Droppingthefinalcolumninatable
letsImpalaignorethedatacausinganydisruptiontoexistingdatafiles.Changing thetypeofacolumnworksifexisting
datavaluescanbesafelyconvertedtothenewtype.Thetypeconversionrulesdependonthefileformatofthe
underlying table.Forexample,inatexttable,thesamevaluecanbeinterpretedasaSTRINGoranumericvalue,while
inabinaryformatsuchasParquet,therulesarestricterandtypeconversionsonlyworkbetweencertainsizesof
integers.
create table optional_columns (x int, y int, z int, a1 int, a2 int);
insert into optional_columns values (1,2,3,0,0), (2,3,4,100,100);
-- When the last column in the table is dropped, Impala ignores the
-- values that are no longer needed. (Dropping A1 but leaving A2
-- would cause problems, as we will see in a subsequent example.)
alter table optional_columns drop column a2;
alter table optional_columns drop column a1;
select * from optional_columns;
+---+---+---+
| x | y | z |
+---+---+---+
| 1 | 2 | 3 |
| 2 | 3 | 4 |
+---+---+---+
create table int_to_string (s string, x int);
insert into int_to_string values ('one', 1), ('two', 2);
-- What was an INT column will now be interpreted as STRING.
-- This technique works for text tables but not other file formats.
-- The second X represents the new name of the column, which we keep the same.
alter table int_to_string change x x string;
-- Once the type is changed, we can insert non-integer values into the X column
-- and treat that column as a string, for example by uppercasing or concatenating.
insert into int_to_string values ('three', 'trois');
select s, upper(x) from int_to_string;
+-------+----------+
| s     | upper(x) |
+-------+----------+
| one   | 1        |
| two   | 2        |
| three | TROIS    |
+-------+----------+
Remember thatImpaladoesnotactuallydoanyconversionfortheunderlying datafilesasaresultofALTER TABLE
statements.IfyouuseALTER TABLE tocreateatablelayoutthatdoesnotagreewiththecontentsoftheunderlying
files,youmustreplacethefilesyourself,suchasusingLOAD DATA toloadanewsetofdatafiles,orINSERT OVERWRITE
tocopyfromanothertableandreplacetheoriginaldata.
ThefollowingexampleshowswhathappensifyoudeletethemiddlecolumnfromaParquettablecontainingthree
columns.Theunderlying datafilesstillcontainthreecolumnsofdata.Becausethecolumnsareinterpretedbasedon
theirpositions inthedatafileinsteadofthespecificcolumnnames,aSELECT * querynowreadsthefirstandsecond
columnsfromthedatafile,potentiallyleadingtounexpectedresultsorconversionerrors.Forthisreason,ifyouexpect
tosomedaydropacolumn,declareitasthelastcolumninthetable,whereitsdatacanbeignoredbyqueriesafter
thecolumnisdropped.Or,re-runyourETLprocessandcreatenewdatafilesifyoudroporchangethetypeofacolumn
inawaythatcausesproblemswithexistingdatafiles.
-- Parquet table showing how dropping a column can produce unexpected results.
create table p1 (s1 string, s2 string, s3 string) stored as parquet;
212|ApacheImpalaGuideImpalaSQLLanguageReference
insert into p1 values ('one', 'un', 'uno'), ('two', 'deux', 'dos'),
  ('three', 'trois', 'tres');
select * from p1;
+-------+-------+------+
| s1    | s2    | s3   |
+-------+-------+------+
| one   | un    | uno  |
| two   | deux  | dos  |
| three | trois | tres |
+-------+-------+------+
alter table p1 drop column s2;
-- The S3 column contains unexpected results.
-- Because S2 and S3 have compatible types, the query reads
-- values from the dropped S2, because the existing data files
-- still contain those values as the second column.
select * from p1;
+-------+-------+
| s1    | s3    |
+-------+-------+
| one   | un    |
| two   | deux  |
| three | trois |
+-------+-------+
-- Parquet table showing how dropping a column can produce conversion errors.
create table p2 (s1 string, x int, s3 string) stored as parquet;
insert into p2 values ('one', 1, 'uno'), ('two', 2, 'dos'), ('three', 3, 'tres');
select * from p2;
+-------+---+------+
| s1    | x | s3   |
+-------+---+------+
| one   | 1 | uno  |
| two   | 2 | dos  |
| three | 3 | tres |
+-------+---+------+
alter table p2 drop column x;
select * from p2;
WARNINGS:
File 'hdfs_filename ' has an incompatible Parquet schema for column 'add_columns.p2.s3'.
Column type: STRING, Parquet schema:
optional int32 x [i:1 d:1 r:0]
File 'hdfs_filename ' has an incompatible Parquet schema for column 'add_columns.p2.s3'.
Column type: STRING, Parquet schema:
optional int32 x [i:1 d:1 r:0]
InCDH5.8/Impala2.6andhigher,ifanAvrotableiscreatedwithoutcolumndefinitionsintheCREATE TABLE
statement,andcolumnsarelateraddedthroughALTER TABLE ,theresultingtableisnowqueryable.Missingvalues
fromthenewlyaddedcolumnsnowdefaulttoNULL.
TochangethefileformatthatImpalaexpectsdatatobein,foratableorpartition:
UseanALTER TABLE ... SET FILEFORMAT clause.YoucanincludeanoptionalPARTITION ( col1=val1,
col2=val2, ...clausesothatthefileformatischangedforaspecificpartition ratherthantheentiretable.
Becausethisoperationonlychangesthetablemetadata,youmustdoanyconversionofexistingdatausingregular
Hadooptechniques outsideofImpala.AnynewdatacreatedbytheImpalaINSERTstatementwillbeinthenew
format.YoucannotspecifythedelimiterforTextfiles;thedatafilesmustbecomma-delimit ed.
Tosetthefileformatforasinglepartition, includethePARTITION clause.Specifyallthesamepartitioning columns
forthetable,withaconstantvalueforeach,topreciselyidentifythesinglepartition affectedbythestatement:
create table p1 (s string) partitioned by (month int, day int);
-- Each ADD PARTITION clause creates a subdirectory in HDFS.
alter table p1 add partition (month=1, day=1);
ApacheImpalaGuide|213ImpalaSQLLanguageReference
alter table p1 add partition (month=1, day=2);
alter table p1 add partition (month=2, day=1);
alter table p1 add partition (month=2, day=2);
-- Queries and INSERT statements will read and write files
-- in this format for this specific partition.
alter table p1 partition (month=2, day=2) set fileformat parquet;
Tochangetherowformatwithdifferentdelimitercharacters:
UsetheSET ROW FORMAT DELIMITED clausetoingestdatafilesthatuseadifferentdelimitercharacteroradifferent
lineendcharacter.WhenspecifyingdelimiterandlineendcharacterswiththeFIELDS TERMINATED BY ,ESCAPED
BY,andLINES TERMINATED BY clauses,youcanusethefollowing:
â¢AregularASCIIcharactersurroundedbysingleordoublequotationmarks.
â¢Anoctalsequence, suchas'\054'representingacommaor'\0'forASCIInull(hex00).
â¢Specialcharacters,suchas:
â'\t'fortab
â'\n'fornewlineorlinefeed
â'\r'forcarriagereturn
â¢Anintegerintherange'-127'..'128' (withquotationmarksbutnobackslash)
Negativevaluesaresubtractedfrom256.Forexample,FIELDS TERMINATED BY '-2' setsthefielddelimiter
toASCIIcode254.
Formoreexamplesoftexttables,seeUsingTextDataFileswithImpalaTablesonpage636.
FortheESCAPED BY clause,chooseanescapecharacterthatisnotusedanywhereelseinthefile.Thecharacter
followingtheescapecharacteristakenliterallyaspartofafieldvalue.
SurroundingfieldvalueswithquotationmarksdoesnothelpImpalatoparsefieldswithembedded delimitercharacters
asthequotationmarksareconsideredtobepartofthecolumnvalue.
Ifyouwanttouse\astheescapecharacter,specifytheclauseinimpala-shell asESCAPED BY '\\' .
Toaddordroppartitions foratable,thetablemustalreadybepartitioned (thatis,createdwithaPARTITIONED BY
clause).ThepartitionisaphysicaldirectoryinHDFS,withanamethatencodesaparticular columnvalue(thepartition
key).TheImpalaINSERTstatementalreadycreatesthepartition ifnecessary,sotheALTER TABLE ... ADD
PARTITION isprimarily usefulforimporting databymovingorcopyingexistingdatafilesintotheHDFSdirectory
corresponding toapartition. (YoucanusetheLOAD DATA statementtomovefilesintothepartition directory,or
ALTER TABLE ... PARTITION (...) SET LOCATION topointapartitionatadirectorythatalreadycontainsdata
files.
TheDROP PARTITION clauseisusedtoremovetheHDFSdirectoryandassociateddatafilesforaparticular setof
partitionkeyvalues;forexample,ifyoualwaysanalyzethelast3monthsworthofdata,atthebeginning ofeachmonth
youmightdroptheoldestpartition thatisnolongerneeded.Removingpartitions reducestheamountofmetadata
associatedwiththetableandthecomplexityofcalculatingtheoptimalqueryplan,whichcansimplifyandspeedup
queriesonpartitioned tables,particularly joinqueries.HereisanexampleshowingtheADD PARTITION andDROP
PARTITION clauses.
Toavoiderrorswhileaddingordroppingpartitions whoseexistenceisnotcertain,addtheoptionalIF [NOT] EXISTS
clausebetweentheADDorDROPkeywordandthePARTITION keyword.Thatis,theentireclausebecomesADD IF
NOT EXISTS PARTITION orDROP IF EXISTS PARTITION .Thefollowingexampleshowshowpartitions canbe
createdautomaticallythroughINSERTstatements,ormanually throughALTER TABLE statements.TheIF [NOT]
EXISTSclauseslettheALTER TABLE statementssucceedevenifanewrequestedpartitionalreadyexists,orapartition
tobedroppeddoesnotexist.
Inserting 2yearvaluescreates2partitions:
create table partition_t (s string) partitioned by (y int);
insert into partition_t (s,y) values ('two thousand',2000), ('nineteen ninety',1990);
214|ApacheImpalaGuideImpalaSQLLanguageReference
show partitions partition_t;
+-------+-------+--------+------+--------------+-------------------+--------+-------------------+
| y     | #Rows | #Files | Size | Bytes Cached | Cache Replication | Format | Incremental
 stats |
+-------+-------+--------+------+--------------+-------------------+--------+-------+
| 1990  | -1    | 1      | 16B  | NOT CACHED   | NOT CACHED        | TEXT   | false |
| 2000  | -1    | 1      | 13B  | NOT CACHED   | NOT CACHED        | TEXT   | false |
| Total | -1    | 2      | 29B  | 0B           |                   |        |       |
+-------+-------+--------+------+--------------+-------------------+--------+-------+
WithouttheIF NOT EXISTS clause,anattempttoaddanewpartition mightfail:
alter table partition_t add partition (y=2000);
ERROR: AnalysisException: Partition spec already exists: (y=2000).
TheIF NOT EXISTS clausemakesthestatementsucceedwhetherornottherewasalreadyapartition withthe
specified keyvalue:
alter table partition_t add if not exists partition (y=2000);
alter table partition_t add if not exists partition (y=2010);
show partitions partition_t;
+-------+-------+--------+------+--------------+-------------------+--------+-------------------+
| y     | #Rows | #Files | Size | Bytes Cached | Cache Replication | Format | Incremental
 stats |
+-------+-------+--------+------+--------------+-------------------+--------+-------+
| 1990  | -1    | 1      | 16B  | NOT CACHED   | NOT CACHED        | TEXT   | false |
| 2000  | -1    | 1      | 13B  | NOT CACHED   | NOT CACHED        | TEXT   | false |
| 2010  | -1    | 0      | 0B   | NOT CACHED   | NOT CACHED        | TEXT   | false |
| Total | -1    | 2      | 29B  | 0B           |                   |        |       |
+-------+-------+--------+------+--------------+-------------------+--------+-------+
Likewise,theIF EXISTS clauseletsDROP PARTITION succeedwhetherornotthepartition isalreadyinthetable:
alter table partition_t drop if exists partition (y=2000);
alter table partition_t drop if exists partition (y=1950);
show partitions partition_t;
+-------+-------+--------+------+--------------+-------------------+--------+-------------------+
| y     | #Rows | #Files | Size | Bytes Cached | Cache Replication | Format | Incremental
 stats |
+-------+-------+--------+------+--------------+-------------------+--------+-------+
| 1990  | -1    | 1      | 16B  | NOT CACHED   | NOT CACHED        | TEXT   | false |
| 2010  | -1    | 0      | 0B   | NOT CACHED   | NOT CACHED        | TEXT   | false |
| Total | -1    | 1      | 16B  | 0B           |                   |        |       |
+-------+-------+--------+------+--------------+-------------------+--------+-------+
TheoptionalPURGEkeyword,availableinCDH5.5/Impala2.3andhigher,isusedwiththeDROP PARTITION clause
toremoveassociatedHDFSdatafilesimmediatelyratherthangoingthroughtheHDFStrashcanmechanism. Usethis
keywordwhendroppingapartitionifitiscrucialtoremovethedataasquicklyaspossibletofreeupspace,orifthere
isaproblemwiththetrashcan,suchasthetrashcannotbeingconfiguredorbeinginadifferentHDFSencryptionzone
thanthedatafiles.
-- Create an empty table and define the partitioning scheme.
create table part_t (x int) partitioned by (month int);
-- Create an empty partition into which you could copy data files from some other source.
alter table part_t add partition (month=1);
-- After changing the underlying data, issue a REFRESH statement to make the data visible
 in Impala.
refresh part_t;
-- Later, do the same for the next month.
alter table part_t add partition (month=2);
-- Now you no longer need the older data.
alter table part_t drop partition (month=1);
-- If the table was partitioned by month and year, you would issue a statement like:
ApacheImpalaGuide|215ImpalaSQLLanguageReference
-- alter table part_t drop partition (year=2003,month=1);
-- which would require 12 ALTER TABLE statements to remove a year's worth of data.
-- If the data files for subsequent months were in a different file format,
-- you could set a different file format for the new partition as you create it.
alter table part_t add partition (month=3) set fileformat=parquet;
Thevaluespecified forapartitionkeycanbeanarbitraryconstantexpression,withoutanyreferencestocolumns.For
example:
alter table time_data add partition (month=concat('Decem','ber'));
alter table sales_data add partition (zipcode = cast(9021 * 10 as string));
Note:
AnalternativewaytoreorganizeatableanditsassociateddatafilesistouseCREATE TABLE tocreate
avariationoftheoriginaltable,thenuseINSERTtocopythetransformedorreordereddatatothe
newtable.TheadvantageofALTER TABLE isthatitavoidsmakingaduplicatecopyofthedatafiles,
allowingyoutoreorganizehugevolumesofdatainaspace-efficientwayusingfamiliarHadoop
techniques.
Toswitchatablebetweeninternalandexternal:
Youcanswitchatablefrominternaltoexternal,orfromexternaltointernal,byusingtheALTER TABLE statement:
-- Switch a table from internal to external.
ALTER TABLE table_name  SET TBLPROPERTIES('EXTERNAL'='TRUE');
-- Switch a table from external to internal.
ALTER TABLE table_name  SET TBLPROPERTIES('EXTERNAL'='FALSE');
IftheKuduserviceisintegratedwiththeHiveMetastore,theaboveoperationsarenotsupported.
Cancellation:Cannotbecancelled.
HDFSpermissions:
MostALTER TABLE clausesdonotactuallyreadorwriteanyHDFSfiles,andsodonotdependonspecificHDFS
permissions. Forexample,theSET FILEFORMAT clausedoesnotactuallycheckthefileformatexistingdatafilesor
convertthemtothenewformat,andtheSET LOCATION clausedoesnotrequireanyspecialpermissions onthenew
location.(Anypermission-r elatedfailureswouldcomelater,whenyouactuallyqueryorinsertintothetable.)
Ingeneral,ALTER TABLE clausesthatdotouchHDFSfilesanddirectoriesrequirethesameHDFSpermissions as
corresponding CREATE,INSERT,orSELECTstatements.Thepermissions allowtheuserIDthattheimpalad daemon
runsunder,typicallytheimpalauser,toreadorwritefilesordirectories,or(inthecaseoftheexecutebit)descend
intoadirectory.TheRENAME TO clauserequiresread,write,andexecutepermission inthesourceanddestination
databasedirectoriesandinthetabledatadirectory,andreadandwritepermission forthedatafileswithinthetable.
TheADD PARTITION andDROP PARTITION clausesrequirewriteandexecutepermissions fortheassociatedpartition
directory.
Kuduconsiderations:
BecauseoftheextraconstraintsandfeaturesofKudutables,suchastheNOT NULL andDEFAULT attributesfor
columns,ALTER TABLE hasspecificrequirementsrelatedtoKudutables:
â¢InanADD COLUMNS operation,youcanspecifytheNULL,NOT NULL ,andDEFAULT default_value column
attributes.
â¢InCDH5.12/Impala2.9andhigher,youcanalsospecifytheENCODING ,COMPRESSION ,andBLOCK_SIZE attributes
whenaddingacolumn.
216|ApacheImpalaGuideImpalaSQLLanguageReference
â¢IfyouaddacolumnwithaNOT NULL attribute,itmustalsohaveaDEFAULT attribute,sothedefaultvaluecan
beassignedtothatcolumnforallexistingrows.
â¢TheDROP COLUMN clauseworksthesameforaKudutableasforotherkindsoftables.
â¢Although youcanchangethenameofacolumnwiththeCHANGEclause,youcannotchangethetypeofacolumn
inaKudutable.
â¢Youcannotchangethenullability ofexistingcolumnsinaKudutable.
â¢InCDH5.13/Impala2.10,youcanchangethedefaultvalue,encoding,compression,orblocksizeofexisting
columnsinaKudutablebyusingtheSETclause.
â¢YoucannotusetheREPLACE COLUMNS clausewithaKudutable.
â¢TheRENAME TO clauseforaKudutableonlyaffectsthenamestoredinthemetastoredatabasethatImpalauses
torefertothetable.Tochangewhichunderlying KudutableisassociatedwithanImpalatablename,youmust
changetheTBLPROPERTIES propertyofthetable:SET
TBLPROPERTIES('kudu.table_name'=' kudu_tbl_name ).Youcanonlychangeunderlying Kudutablesfor
theexternaltables.
ThefollowingaresomeexamplesofusingtheADD COLUMNS clauseforaKudutable:
CREATE TABLE t1 ( x INT, PRIMARY KEY (x) )
  PARTITION BY HASH (x) PARTITIONS 16
  STORED AS KUDU
ALTER TABLE t1 ADD COLUMNS (y STRING ENCODING prefix_encoding);
ALTER TABLE t1 ADD COLUMNS (z INT DEFAULT 10);
ALTER TABLE t1 ADD COLUMNS (a STRING NOT NULL DEFAULT '', t TIMESTAMP COMPRESSION 
default_compression);
ThefollowingaresomeexamplesofmodifyingcolumndefaultsandstorageattributesforaKudutable:
create table kt (x bigint primary key, s string default 'yes', t timestamp)
  stored as kudu;
-- You can change the default value for a column, which affects any rows
-- inserted after this change is made.
alter table kt alter column s set default 'no';
-- You can remove the default value for a column, which affects any rows
-- inserted after this change is made. If the column is nullable, any
-- future inserts default to NULL for this column. If the column is marked
-- NOT NULL, any future inserts must specify a value for the column.
alter table kt alter column s drop default;
insert into kt values (1, 'foo', now());
-- Because of the DROP DEFAULT above, omitting S from the insert
-- gives it a value of NULL.
insert into kt (x, t) values (2, now());
select * from kt;
+---+------+-------------------------------+
| x | s    | t                             |
+---+------+-------------------------------+
| 2 | NULL | 2017-10-02 00:03:40.652156000 |
| 1 | foo  | 2017-10-02 00:03:04.346185000 |
+---+------+-------------------------------+
-- Other storage-related attributes can also be changed for columns.
-- These changes take effect for any newly inserted rows, or rows
-- rearranged due to compaction after deletes or updates.
alter table kt alter column s set encoding prefix_encoding;
-- The COLUMN keyword is optional in the syntax.
alter table kt alter x set block_size 2048;
alter table kt alter column t set compression zlib;
ApacheImpalaGuide|217ImpalaSQLLanguageReference
desc kt;
+------+-----------+---------+-------------+----------+---------------+-----------------+---------------------+------------+
| name | type      | comment | primary_key | nullable | default_value | encoding      
  | compression         | block_size |
+------+-----------+---------+-------------+----------+---------------+-----------------+---------------------+------------+
| x    | bigint    |         | true        | false    |               | AUTO_ENCODING 
  | DEFAULT_COMPRESSION | 2048       |
| s    | string    |         | false       | true     |               | PREFIX_ENCODING
 | DEFAULT_COMPRESSION | 0          |
| t    | timestamp |         | false       | true     |               | AUTO_ENCODING 
  | ZLIB                | 0          |
+------+-----------+---------+-------------+----------+---------------+-----------------+---------------------+------------+
Kudutablesalluseanunderlying partitioning mechanism. Thepartition syntaxisdifferentthanfornon-Kudutables.
YoucanusetheALTER TABLE statementtoaddanddroprangepartitions fromaKudutable.Anynewrangemust
notoverlapwithanyexistingranges.Droppingarangeremovesalltheassociatedrowsfromthetable.SeePartitioning
forKuduTablesonpage675fordetails.
Relatedinformation:
OverviewofImpalaTablesonpage196,CREATETABLEStatementonpage234,DROPTABLEStatementonpage268,
Partitioning forImpalaTablesonpage625,InternalTablesonpage197,ExternalTablesonpage197
ALTERVIEWStatement
TheALTER VIEW statementchangesthecharacteristicsofaview.
Becauseaviewisalogicalconstruct,analiasforaquery,withnophysicaldatabehindit,ALTER VIEW onlyinvolves
changestometadatainthemetastoredatabase,notanydatafilesinHDFS.
Toseethedefinitionoftheupdatedview,issueaDESCRIBE FORMATTED statement.
Syntax:
ALTER VIEW [ database_name .]view_name
   [(column_name  [COMMENT ' column_comment '][, ...])]
   AS select_statement ;
ALTER VIEW [ database_name .]view_name
   RENAME TO [ database_name .]view_name ;
ALTER VIEW [ database_name .]view_name  SET OWNER USER user_name;
ALTER VIEW [ database_name .]view_name  SET OWNER ROLE role_name;
â¢TheASclauseassociatestheviewwithadifferentquery.
Anoptionallistofcolumnnamescanbespecified withorwithoutthecolumn-levelcomments.
Forexample:
ALTER VIEW v1 AS SELECT x, UPPER(s) s FROM t2;
ALTER VIEW v1 (c1, c2) AS SELECT x, UPPER(s) s FROM t2;
ALTER VIEW v7 (c1 COMMENT 'Comment for c1', c2) AS SELECT t1.c1, t1.c2 FROM t1;
â¢TheRENAME TO clausechangesthenameoftheview,movestheviewtoadifferentdatabase,orboth.
Forexample:
ALTER VIEW db1.v1 RENAME TO db2.v2; -- Move the view to a different database with a new
 name.
ALTER VIEW db1.v1 RENAME TO db1.v2;  -- Rename the view in the same database.
ALTER VIEW db1.v1 RENAME TO db2.v1; -- Move the view to a difference database with the
 same view name.
218|ApacheImpalaGuideImpalaSQLLanguageReference
â¢TheSET OWNER clausetransferstheownershipoftheviewfromthecurrentownertoanotheruserorarole.
Theviewownerisoriginally settotheuserwhocreatestheview.WhenobjectownershipisenabledinSentry,
anownerofaviewcanhavetheALLwithGRANTorALLwithoutGRANTprivilege.ThetermOWNERisusedto
differentiatebetweentheALLprivilegethatisexplicitlygrantedviatheGRANTstatementandaprivilegethatis
implicitly grantedbytheCREATE VIEW statement.
Statementtype:DDL
IfyouconnecttodifferentImpalanodeswithinanimpala-shell sessionforload-balancing purposes, youcanenable
theSYNC_DDL queryoptiontomakeeachDDLstatementwaitbeforereturning,untiltheneworchangedmetadata
hasbeenreceivedbyalltheImpalanodes.SeeSYNC_DDL QueryOptiononpage361fordetails.
Securityconsiderations:
Ifthesestatementsinyourenvironmentcontainsensitiveliteralvaluessuchascreditcardnumbersortaxidentifiers,
Impalacanredactthissensitiveinformationwhendisplayingthestatementsinlogfilesandotheradministrative
contexts.Seehttp://www.cloudera.com/content/cloudera/en/documen tation/core/latest/topics/sg_redaction.h tml
fordetails.
Cancellation:Cannotbecancelled.
HDFSpermissions: ThisstatementdoesnottouchanyHDFSfilesordirectories,thereforenoHDFSpermissions are
required.
Relatedinformation:
OverviewofImpalaViewsonpage199,CREATEVIEWStatementonpage248,DROPVIEWStatementonpage270
COMMENT Statement
TheCOMMENT statementadds,changes,orremovesacommentaboutadatabase,atable,oracolumn.
YoucanalternativelyusetheCREATEandALTERstatementstoaddcommentstotheobjects.
Youcanviewthecommentonadatabase,atable,oracolumnusingtheSHOWorDESCRIBE statement.
Syntax:
COMMENT ON DATABASE db_name IS {'comment' | NULL}
COMMENT ON TABLE [ db_name.]table_name  IS {'comment' | NULL}
COMMENT ON COLUMN [ db_name.]table_name .column_name  IS {'comment' | NULL}
Parameters:
â¢db_name :Specifythedatabasenameifnotforthecurrentdatabase.
â¢NULL:Ifgivenforthecomment,removestheexistingcomment.
â¢Thecommentstringcanbeupto256characterslong.
Privilegesrequired:
Toaddacomment,theALTERprivilegeontheobjectisrequired.
Toviewacomment,theSELECT,INSERT,orREFRESH ontheobjectisrequired.
Usagenotes:
Addedin:CDH6.1
COMPUTE STATSStatement
TheCOMPUTE STATSstatementgathersinformationaboutvolumeanddistribution ofdatainatableandallassociated
columnsandpartitions. Theinformationisstoredinthemetastoredatabase,andusedbyImpalatohelpoptimize
ApacheImpalaGuide|219ImpalaSQLLanguageReference
queries.Forexample,ifImpalacandeterminethatatableislargeorsmall,orhasmanyorfewdistinctvaluesitcan
organizeandparallelizetheworkappropriatelyforajoinqueryorinsertoperation.Fordetailsaboutthekindsof
informationgatheredbythisstatement,seeTableandColumnStatisticsonpage575.
Syntax:
COMPUTE STATS [ db_name.]table_name   [ ( column_list  ) ] [TABLESAMPLE SYSTEM( percentage )
 [REPEATABLE( seed)]]
column_list  ::= column_name  [ , column_name , ... ]
COMPUTE INCREMENTAL STATS [ db_name.]table_name  [PARTITION ( partition_spec )]
partition_spec  ::= partition_col =constant_value
partition_spec  ::= simple_partition_spec  | complex_partition_spec
simple_partition_spec  ::= partition_col =constant_value
complex_partition_spec  ::= comparison_expression_on_partition_col
ThePARTITION clauseisonlyallowedincombinationwiththeINCREMENTAL clause.ItisoptionalforCOMPUTE
INCREMENTAL STATS ,andrequiredforDROP INCREMENTAL STATS .Wheneveryouspecifypartitions throughthe
PARTITION ( partition_spec )clauseinaCOMPUTE INCREMENTAL STATS orDROP INCREMENTAL STATS
statement,youmustincludeallthepartitioning columnsinthespecification,andspecifyconstantvaluesforallthe
partition keycolumns.
Usagenotes:
Originally ,ImpalareliedonuserstoruntheHiveANALYZE TABLE statement,butthatmethodofgatheringstatistics
provedunreliableanddifficulttouse.TheImpalaCOMPUTE STATS statementwasbuilttoimprovethereliabilityand
user-friendliness ofthisoperation.COMPUTE STATS doesnotrequireanysetupstepsorspecialconfiguration.You
onlyrunasingleImpalaCOMPUTE STATS statementtogatherbothtableandcolumnstatistics,ratherthanseparate
HiveANALYZE TABLE statementsforeachkindofstatistics.
Fornon-incrementalCOMPUTE STATS statement,thecolumnsforwhichstatisticsarecomputedcanbespecified with
anoptionalcomma-separ atelistofcolumns.
Ifnocolumnlistisgiven,theCOMPUTE STATS statementcomputescolumn-levelstatisticsforallcolumnsofthetable.
Thisaddspotentiallyunneeded workforcolumnswhosestatsarenotneededbyqueries.Itcanbeespecially costly
forverywidetablesandunneeded largestringfields.
COMPUTE STATS returnsanerrorwhenaspecified columncannotbeanalyzed,suchaswhenthecolumndoesnot
exist,thecolumnisofanunsupport edtypeforCOMPUTE STATS,e.g.columsofcomplextypes,orthecolumnisa
partitioning column.
Ifanemptycolumnlistisgiven,nocolumnisanalyzedbyCOMPUTE STATS .
InCDH5.15/Impala2.12andhigher,anoptionalTABLESAMPLE clauseimmediatelyafteratablereferencespecifies
thattheCOMPUTE STATS operationonlyprocessesaspecified percentageofthetabledata.Fortablesthatareso
largethatafullCOMPUTE STATS operationisimpractical,youcanuseCOMPUTE STATS withaTABLESAMPLE clause
toextrapolatestatisticsfromasampleofthetabledata.SeeTableandColumnStatisticsabouttheexperimen talstats
extrapolationandsampling features.
TheCOMPUTE INCREMENTAL STATS variationisashortcutforpartitioned tablesthatworksonasubsetofpartitions
ratherthantheentiretable.Theincrementalnaturemakesitsuitableforlargetableswithmanypartitions, wherea
fullCOMPUTE STATS operationtakestoolongtobepracticaleachtimeapartitionisaddedordropped.SeeGenerating
TableandColumnStatisticsonpage578forfullusagedetails.
220|ApacheImpalaGuideImpalaSQLLanguageReference
Important:
Foraparticular table,useeitherCOMPUTE STATS orCOMPUTE INCREMENTAL STATS .Thetwokinds
ofstatsdonotinteroperatewitheachotheratthetablelevel.Withoutdroppingthestats,ifyourun
COMPUTE INCREMENTAL STATS itwilloverwritethefullcomputestatsorifyourunCOMPUTE STATS
itwilldropallincrementalstatsforconsistency.
WhenyourunCOMPUTE INCREMENTAL STATS onatableforthefirsttime,thestatisticsarecomputed
againfromscratchregardlessofwhetherthetablealreadyhasstatistics.Therefore,expectaone-time
resource-intensiveoperationforscanningtheentiretablewhenrunningCOMPUTE INCREMENTAL
STATSforthefirsttimeonagiventable.
InImpala3.0andlower,approximately400bytesofmetadatapercolumnperpartition areneeded
forcaching.Tableswithabignumberofpartitions andmanycolumnscanadduptoasignificant
memoryoverheadasthemetadatamustbecachedonthecatalogd hostandoneveryimpalad
hostthatiseligibletobeacoordinator.Ifthismetadataforalltablesexceeds2GB,youmight
experience servicedowntime.InImpala3.1andhigher,theissuewasalleviatedwithanimproved
handlingofincrementalstats.
COMPUTE INCREMENTAL STATS onlyappliestopartitioned tables.IfyouusetheINCREMENTAL clauseforan
unpartitioned table,ImpalaautomaticallyusestheoriginalCOMPUTE STATS statement.Suchtablesdisplayfalse
undertheIncremental stats columnoftheSHOW TABLE STATS output.
Note:
Becausemanyofthemostperformance-critic alandresource-intensiveoperationsrelyontableand
columnstatisticstoconstructaccurateandefficientplans,COMPUTE STATS isanimportantstepat
theendofyourETLprocess.RunCOMPUTE STATS onalltablesasyourfirststepduringperformance
tuningforslowqueries,ortroubleshooting forout-of-memor yconditions:
â¢AccuratestatisticshelpImpalaconstructanefficientqueryplanforjoinqueries,improving
performance andreducingmemoryusage.
â¢AccuratestatisticshelpImpaladistributetheworkeffectivelyforinsertoperationsintoParquet
tables,improvingperformance andreducingmemoryusage.
â¢AccuratestatisticshelpImpalaestimatethememoryrequiredforeachquery,whichisimportant
whenyouuseresourcemanagementfeatures,suchasadmission controlandtheYARNresource
managementframework.ThestatisticshelpImpalatoachievehighconcurrency,fullutilization
ofavailablememory,andavoidcontentionwithworkloadsfromotherHadoopcomponen ts.
â¢InCDH5.10/Impala2.8andhigher,whenyouruntheCOMPUTE STATS orCOMPUTE
INCREMENTAL STATS statementagainstaParquettable,Impalaautomaticallyappliesthequery
optionsettingMT_DOP=4 toincreasetheamountofintra-nodeparallelismduringthis
CPU-intensiveoperation.SeeMT_DOP QueryOptiononpage345fordetailsaboutwhatthisquery
optiondoesandhowtouseitwithCPU-intensiveSELECTstatements.
Computing statsforgroupsofpartitions:
InCDH5.10/Impala2.8andhigher,youcanrunCOMPUTE INCREMENTAL STATS onmultiplepartitions, insteadof
theentiretableoronepartition atatime.Youincludecomparison operatorsotherthan=inthePARTITION clause,
andtheCOMPUTE INCREMENTAL STATS statementappliestoallpartitions thatmatchthecomparison expression.
Forexample,theINT_PARTITIONS tablecontains4partitions. ThefollowingCOMPUTE INCREMENTAL STATS
statementsaffectsomebutnotallpartitions, asindicatedbytheUpdated n partition(s) messages.Thepartitions
thatareaffecteddependonvaluesinthepartitionkeycolumnXthatmatchthecomparison expressioninthePARTITION
clause.
show partitions int_partitions;
ApacheImpalaGuide|221ImpalaSQLLanguageReference
+-------+-------+--------+------+--------------+-------------------+---------+...
| x     | #Rows | #Files | Size | Bytes Cached | Cache Replication | Format  |...
+-------+-------+--------+------+--------------+-------------------+---------+...
| 99    | -1    | 0      | 0B   | NOT CACHED   | NOT CACHED        | PARQUET |...
| 120   | -1    | 0      | 0B   | NOT CACHED   | NOT CACHED        | TEXT    |...
| 150   | -1    | 0      | 0B   | NOT CACHED   | NOT CACHED        | TEXT    |...
| 200   | -1    | 0      | 0B   | NOT CACHED   | NOT CACHED        | TEXT    |...
| Total | -1    | 0      | 0B   | 0B           |                   |         |...
+-------+-------+--------+------+--------------+-------------------+---------+...
compute incremental stats int_partitions partition (x < 100);
+-----------------------------------------+
| summary                                 |
+-----------------------------------------+
| Updated 1 partition(s) and 1 column(s). |
+-----------------------------------------+
compute incremental stats int_partitions partition (x in (100, 150, 200));
+-----------------------------------------+
| summary                                 |
+-----------------------------------------+
| Updated 2 partition(s) and 1 column(s). |
+-----------------------------------------+
compute incremental stats int_partitions partition (x between 100 and 175);
+-----------------------------------------+
| summary                                 |
+-----------------------------------------+
| Updated 2 partition(s) and 1 column(s). |
+-----------------------------------------+
compute incremental stats int_partitions partition (x in (100, 150, 200) or x < 100);
+-----------------------------------------+
| summary                                 |
+-----------------------------------------+
| Updated 3 partition(s) and 1 column(s). |
+-----------------------------------------+
compute incremental stats int_partitions partition (x != 150);
+-----------------------------------------+
| summary                                 |
+-----------------------------------------+
| Updated 3 partition(s) and 1 column(s). |
+-----------------------------------------+
Complextypeconsiderations:
Currently,thestatisticscreatedbytheCOMPUTE STATS statementdonotincludeinformationaboutcomplextype
columns.Thecolumnstatsmetricsforcomplexcolumnsarealwaysshownas-1.Forqueriesinvolvingcomplextype
columns,Impalausesheuristicstoestimatethedatadistribution withinsuchcolumns.
HBaseconsiderations:
COMPUTE STATS worksforHBasetablesalso.ThestatisticsgatheredforHBasetablesaresomewhatdifferentthan
forHDFS-backedtables,butthatmetadataisstillusedforoptimizationwhenHBasetablesareinvolvedinjoinqueries.
AmazonS3considerations:
COMPUTE STATS alsoworksfortableswheredataresidesintheAmazonSimpleStorageService(S3).SeeUsingImpala
withtheAmazonS3Filesystemonpage692fordetails.
Performance considerations:
ThestatisticscollectedbyCOMPUTE STATS areusedtooptimizejoinqueriesINSERToperationsintoParquettables,
andotherresource-intensivekindsofSQLstatements.SeeTableandColumnStatisticsonpage575fordetails.
Forlargetables,theCOMPUTE STATS statementitselfmighttakealongtimeandyoumightneedtotuneits
performance. TheCOMPUTE STATS statementdoesnotworkwiththeEXPLAIN statement,ortheSUMMARY command
inimpala-shell .YoucanusethePROFILE statementinimpala-shell toexaminetiminginformationforthe
222|ApacheImpalaGuideImpalaSQLLanguageReference
statementasawhole.IfabasicCOMPUTE STATS statementtakesalongtimeforapartitioned table,considerswitching
totheCOMPUTE INCREMENTAL STATS syntaxsothatonlynewlyaddedpartitions areanalyzedeachtime.
Examples:
Thisexampleshowstwotables,T1andT2,withasmallnumberdistinctvalueslinkedbyaparent-childrelationship
betweenT1.IDandT2.PARENT .T1istiny,whileT2hasapproximately100Krows.Initially,thestatisticsincludes
physicalmeasurementssuchasthenumberoffiles,thetotalsize,andsizemeasurementsforfixed-lengthcolumns
suchaswiththeINTtype.Unknownvaluesarerepresentedby-1.AfterrunningCOMPUTE STATS foreachtable,much
moreinformationisavailablethroughtheSHOW STATS statements.Ifyouwererunningajoinqueryinvolvingboth
ofthesetables,youwouldneedstatisticsforbothtablestogetthemosteffectiveoptimizationforthequery.
[localhost:21000] > show table stats t1;
Query: show table stats t1
+-------+--------+------+--------+
| #Rows | #Files | Size | Format |
+-------+--------+------+--------+
| -1    | 1      | 33B  | TEXT   |
+-------+--------+------+--------+
Returned 1 row(s) in 0.02s
[localhost:21000] > show table stats t2;
Query: show table stats t2
+-------+--------+----------+--------+
| #Rows | #Files | Size     | Format |
+-------+--------+----------+--------+
| -1    | 28     | 960.00KB | TEXT   |
+-------+--------+----------+--------+
Returned 1 row(s) in 0.01s
[localhost:21000] > show column stats t1;
Query: show column stats t1
+--------+--------+------------------+--------+----------+----------+
| Column | Type   | #Distinct Values | #Nulls | Max Size | Avg Size |
+--------+--------+------------------+--------+----------+----------+
| id     | INT    | -1               | -1     | 4        | 4        |
| s      | STRING | -1               | -1     | -1       | -1       |
+--------+--------+------------------+--------+----------+----------+
Returned 2 row(s) in 1.71s
[localhost:21000] > show column stats t2;
Query: show column stats t2
+--------+--------+------------------+--------+----------+----------+
| Column | Type   | #Distinct Values | #Nulls | Max Size | Avg Size |
+--------+--------+------------------+--------+----------+----------+
| parent | INT    | -1               | -1     | 4        | 4        |
| s      | STRING | -1               | -1     | -1       | -1       |
+--------+--------+------------------+--------+----------+----------+
Returned 2 row(s) in 0.01s
[localhost:21000] > compute stats t1;
Query: compute stats t1
+-----------------------------------------+
| summary                                 |
+-----------------------------------------+
| Updated 1 partition(s) and 2 column(s). |
+-----------------------------------------+
Returned 1 row(s) in 5.30s
[localhost:21000] > show table stats t1;
Query: show table stats t1
+-------+--------+------+--------+
| #Rows | #Files | Size | Format |
+-------+--------+------+--------+
| 3     | 1      | 33B  | TEXT   |
+-------+--------+------+--------+
Returned 1 row(s) in 0.01s
[localhost:21000] > show column stats t1;
Query: show column stats t1
+--------+--------+------------------+--------+----------+----------+
| Column | Type   | #Distinct Values | #Nulls | Max Size | Avg Size |
+--------+--------+------------------+--------+----------+----------+
| id     | INT    | 3                | -1     | 4        | 4        |
| s      | STRING | 3                | -1     | -1       | -1       |
+--------+--------+------------------+--------+----------+----------+
Returned 2 row(s) in 0.02s
ApacheImpalaGuide|223ImpalaSQLLanguageReference
[localhost:21000] > compute stats t2;
Query: compute stats t2
+-----------------------------------------+
| summary                                 |
+-----------------------------------------+
| Updated 1 partition(s) and 2 column(s). |
+-----------------------------------------+
Returned 1 row(s) in 5.70s
[localhost:21000] > show table stats t2;
Query: show table stats t2
+-------+--------+----------+--------+
| #Rows | #Files | Size     | Format |
+-------+--------+----------+--------+
| 98304 | 1      | 960.00KB | TEXT   |
+-------+--------+----------+--------+
Returned 1 row(s) in 0.03s
[localhost:21000] > show column stats t2;
Query: show column stats t2
+--------+--------+------------------+--------+----------+----------+
| Column | Type   | #Distinct Values | #Nulls | Max Size | Avg Size |
+--------+--------+------------------+--------+----------+----------+
| parent | INT    | 3                | -1     | 4        | 4        |
| s      | STRING | 6                | -1     | 14       | 9.3      |
+--------+--------+------------------+--------+----------+----------+
Returned 2 row(s) in 0.01s
ThefollowingexampleshowshowtousetheINCREMENTAL clause,availableinImpala2.1.0andhigher.TheCOMPUTE
INCREMENTAL STATS syntaxletsyoucollectstatisticsfornewlyaddedorchangedpartitions, withoutrescanningthe
entiretable.
-- Initially the table has no incremental stats, as indicated
-- 'false' under Incremental stats.
show table stats item_partitioned;
+-------------+-------+--------+----------+--------------+---------+------------------
| i_category  | #Rows | #Files | Size     | Bytes Cached | Format  | Incremental stats
+-------------+-------+--------+----------+--------------+---------+------------------
| Books       | -1    | 1      | 223.74KB | NOT CACHED   | PARQUET | false
| Children    | -1    | 1      | 230.05KB | NOT CACHED   | PARQUET | false
| Electronics | -1    | 1      | 232.67KB | NOT CACHED   | PARQUET | false
| Home        | -1    | 1      | 232.56KB | NOT CACHED   | PARQUET | false
| Jewelry     | -1    | 1      | 223.72KB | NOT CACHED   | PARQUET | false
| Men         | -1    | 1      | 231.25KB | NOT CACHED   | PARQUET | false
| Music       | -1    | 1      | 237.90KB | NOT CACHED   | PARQUET | false
| Shoes       | -1    | 1      | 234.90KB | NOT CACHED   | PARQUET | false
| Sports      | -1    | 1      | 227.97KB | NOT CACHED   | PARQUET | false
| Women       | -1    | 1      | 226.27KB | NOT CACHED   | PARQUET | false
| Total       | -1    | 10     | 2.25MB   | 0B           |         |
+-------------+-------+--------+----------+--------------+---------+------------------
-- After the first COMPUTE INCREMENTAL STATS,
-- all partitions have stats. The first
-- COMPUTE INCREMENTAL STATS scans the whole
-- table, discarding any previous stats from
-- a traditional COMPUTE STATS statement.
compute incremental stats item_partitioned;
+-------------------------------------------+
| summary                                   |
+-------------------------------------------+
| Updated 10 partition(s) and 21 column(s). |
+-------------------------------------------+
show table stats item_partitioned;
+-------------+-------+--------+----------+--------------+---------+------------------
| i_category  | #Rows | #Files | Size     | Bytes Cached | Format  | Incremental stats
+-------------+-------+--------+----------+--------------+---------+------------------
| Books       | 1733  | 1      | 223.74KB | NOT CACHED   | PARQUET | true
| Children    | 1786  | 1      | 230.05KB | NOT CACHED   | PARQUET | true
| Electronics | 1812  | 1      | 232.67KB | NOT CACHED   | PARQUET | true
| Home        | 1807  | 1      | 232.56KB | NOT CACHED   | PARQUET | true
| Jewelry     | 1740  | 1      | 223.72KB | NOT CACHED   | PARQUET | true
| Men         | 1811  | 1      | 231.25KB | NOT CACHED   | PARQUET | true
| Music       | 1860  | 1      | 237.90KB | NOT CACHED   | PARQUET | true
| Shoes       | 1835  | 1      | 234.90KB | NOT CACHED   | PARQUET | true
224|ApacheImpalaGuideImpalaSQLLanguageReference
| Sports      | 1783  | 1      | 227.97KB | NOT CACHED   | PARQUET | true
| Women       | 1790  | 1      | 226.27KB | NOT CACHED   | PARQUET | true
| Total       | 17957 | 10     | 2.25MB   | 0B           |         |
+-------------+-------+--------+----------+--------------+---------+------------------
-- Add a new partition...
alter table item_partitioned add partition (i_category='Camping');
-- Add or replace files in HDFS outside of Impala,
-- rendering the stats for a partition obsolete.
!import_data_into_sports_partition.sh
refresh item_partitioned;
drop incremental stats item_partitioned partition (i_category='Sports');
-- Now some partitions have incremental stats
-- and some do not.
show table stats item_partitioned;
+-------------+-------+--------+----------+--------------+---------+------------------
| i_category  | #Rows | #Files | Size     | Bytes Cached | Format  | Incremental stats
+-------------+-------+--------+----------+--------------+---------+------------------
| Books       | 1733  | 1      | 223.74KB | NOT CACHED   | PARQUET | true
| Camping     | -1    | 1      | 408.02KB | NOT CACHED   | PARQUET | false
| Children    | 1786  | 1      | 230.05KB | NOT CACHED   | PARQUET | true
| Electronics | 1812  | 1      | 232.67KB | NOT CACHED   | PARQUET | true
| Home        | 1807  | 1      | 232.56KB | NOT CACHED   | PARQUET | true
| Jewelry     | 1740  | 1      | 223.72KB | NOT CACHED   | PARQUET | true
| Men         | 1811  | 1      | 231.25KB | NOT CACHED   | PARQUET | true
| Music       | 1860  | 1      | 237.90KB | NOT CACHED   | PARQUET | true
| Shoes       | 1835  | 1      | 234.90KB | NOT CACHED   | PARQUET | true
| Sports      | -1    | 1      | 227.97KB | NOT CACHED   | PARQUET | false
| Women       | 1790  | 1      | 226.27KB | NOT CACHED   | PARQUET | true
| Total       | 17957 | 11     | 2.65MB   | 0B           |         |
+-------------+-------+--------+----------+--------------+---------+------------------
-- After another COMPUTE INCREMENTAL STATS,
-- all partitions have incremental stats, and only the 2
-- partitions without incremental stats were scanned.
compute incremental stats item_partitioned;
+------------------------------------------+
| summary                                  |
+------------------------------------------+
| Updated 2 partition(s) and 21 column(s). |
+------------------------------------------+
show table stats item_partitioned;
+-------------+-------+--------+----------+--------------+---------+------------------
| i_category  | #Rows | #Files | Size     | Bytes Cached | Format  | Incremental stats
+-------------+-------+--------+----------+--------------+---------+------------------
| Books       | 1733  | 1      | 223.74KB | NOT CACHED   | PARQUET | true
| Camping     | 5328  | 1      | 408.02KB | NOT CACHED   | PARQUET | true
| Children    | 1786  | 1      | 230.05KB | NOT CACHED   | PARQUET | true
| Electronics | 1812  | 1      | 232.67KB | NOT CACHED   | PARQUET | true
| Home        | 1807  | 1      | 232.56KB | NOT CACHED   | PARQUET | true
| Jewelry     | 1740  | 1      | 223.72KB | NOT CACHED   | PARQUET | true
| Men         | 1811  | 1      | 231.25KB | NOT CACHED   | PARQUET | true
| Music       | 1860  | 1      | 237.90KB | NOT CACHED   | PARQUET | true
| Shoes       | 1835  | 1      | 234.90KB | NOT CACHED   | PARQUET | true
| Sports      | 1783  | 1      | 227.97KB | NOT CACHED   | PARQUET | true
| Women       | 1790  | 1      | 226.27KB | NOT CACHED   | PARQUET | true
| Total       | 17957 | 11     | 2.65MB   | 0B           |         |
+-------------+-------+--------+----------+--------------+---------+------------------
Fileformatconsiderations:
TheCOMPUTE STATS statementworkswithtablescreatedwithanyofthefileformatssupportedbyImpala.SeeHow
ImpalaWorkswithHadoopFileFormatsonpage634fordetailsaboutworkingwiththedifferentfileformats.The
followingconsiderationsapplytoCOMPUTE STATS depending onthefileformatofthetable.
TheCOMPUTE STATS statementworkswithtexttableswithnorestrictions. Thesetablescanbecreatedthrougheither
ImpalaorHive.
TheCOMPUTE STATS statementworkswithParquettables.ThesetablescanbecreatedthrougheitherImpalaorHive.
ApacheImpalaGuide|225ImpalaSQLLanguageReference
TheCOMPUTE STATS statementworkswithAvrotableswithoutrestrictioninCDH5.4/Impala2.2andhigher.In
earlierreleases,COMPUTE STATS workedonlyforAvrotablescreatedthroughHive,andrequiredtheCREATE TABLE
statementtouseSQL-stylecolumnnamesandtypesratherthananAvro-styleschemaspecification.
TheCOMPUTE STATS statementworkswithRCFiletableswithnorestrictions. Thesetablescanbecreatedthrough
eitherImpalaorHive.
TheCOMPUTE STATS statementworkswithSequenceFile tableswithnorestrictions. Thesetablescanbecreated
througheitherImpalaorHive.
TheCOMPUTE STATS statementworkswithpartitioned tables,whetherallthepartitions usethesamefileformat,or
somepartitions aredefinedthroughALTER TABLE tousedifferentfileformats.
Statementtype:DDL
Cancellation:Certainmulti-stagestatements(CREATE TABLE AS SELECT andCOMPUTE STATS )canbecancelled
duringsomestages,whenrunningINSERTorSELECToperationsinternally.Tocancelthisstatement,useCtrl-Cfrom
theimpala-shell interpreter,theCancelbuttonfromtheWatchpageinHue,Actions>CancelfromtheQueries
listinClouderaManager,orCancelfromthelistofin-flightqueries(foraparticular node)ontheQueriestabinthe
ImpalawebUI(port25000).
Restrictions:
Note:PriortoImpala1.4.0,COMPUTE STATS countedthenumberofNULLvaluesineachcolumn
andrecordedthatfigureinthemetastoredatabase.BecauseImpaladoesnotcurrentlyusetheNULL
countduringqueryplanning,Impala1.4.0andhigherspeedsuptheCOMPUTE STATS statementby
skippingthisNULLcounting.
Internaldetails:
Behindthescenes,theCOMPUTE STATS statementexecutestwostatements:onetocounttherowsofeachpartition
inthetable(ortheentiretableifunpartitioned) throughtheCOUNT(*) function, andanothertocounttheapproximate
numberofdistinctvaluesineachcolumnthroughtheNDV()function. Youmightseethesequeriesinyourmonitoring
anddiagnosticdisplays.Thesamefactorsthataffecttheperformance, scalability,andexecutionofotherqueries(such
asparallelexecution,memoryusage,admission control,andtimeouts) alsoapplytothequeriesrunbytheCOMPUTE
STATSstatement.
HDFSpermissions:
TheuserIDthattheimpalad daemonrunsunder,typicallytheimpalauser,musthavereadpermission forallaffected
filesinthesourcedirectory:allfilesinthecaseofanunpartitioned tableorapartitioned tableinthecaseofCOMPUTE
STATS;orallthefilesinpartitions withoutincrementalstatsinthecaseofCOMPUTE INCREMENTAL STATS .Itmust
alsohavereadandexecutepermissions forallrelevantdirectoriesholdingthedatafiles.(Essentially,COMPUTE STATS
requiresthesamepermissions astheunderlying SELECTqueriesitrunsagainstthetable.)
Kuduconsiderations:
TheCOMPUTE STATS statementappliestoKudutables.Impaladoesnotcomputethenumberofrowsforeachpartition
forKudutables.Therefore,youdonotneedtore-runtheoperationwhenyousee-1inthe# Rowscolumnofthe
outputfromSHOW TABLE STATS .Thatcolumnalwaysshows-1forallKudutables.
Relatedinformation:
DROPSTATSStatementonpage265,SHOWTABLESTATSStatementonpage373,SHOWCOLUMNSTATSStatement
onpage375,TableandColumnStatisticsonpage575
CREATEDATABASEStatement
Createsanewdatabase.
InImpala,adatabaseisboth:
â¢Alogicalconstructforgroupingtogetherrelatedtables,views,andfunctions withintheirownnamespace. You
mightuseaseparatedatabaseforeachapplication,setofrelatedtables,orroundofexperimen tation.
226|ApacheImpalaGuideImpalaSQLLanguageReference
â¢AphysicalconstructrepresentedbyadirectorytreeinHDFS.Tables(internaltables),partitions, anddatafilesare
alllocatedunderthisdirectory.YoucanperformHDFS-leveloperationssuchasbackingitupandmeasuring space
usage,orremoveitwithaDROP DATABASE statement.
Syntax:
CREATE (DATABASE|SCHEMA) [IF NOT EXISTS] database_name [COMMENT ' database_comment ']
  [LOCATION hdfs_path ];
Statementtype:DDL
Usagenotes:
AdatabaseisphysicallyrepresentedasadirectoryinHDFS,withafilename extension.db,underthemainImpala
datadirectory.IftheassociatedHDFSdirectorydoesnotexist,itiscreatedforyou.Alldatabasesandtheirassociated
directoriesaretop-levelobjects,withnophysicalorlogicalnesting.
Aftercreatingadatabase,tomakeitthecurrentdatabasewithinanimpala-shell session,usetheUSEstatement.
Youcanrefertotablesinthecurrentdatabasewithoutprepending anyqualifiertotheirnames.
WhenyoufirstconnecttoImpalathroughimpala-shell ,thedatabaseyoustartin(beforeissuinganyCREATE
DATABASE orUSEstatements)isnameddefault .
Impalaincludesanotherpredefineddatabase,_impala_builtins ,thatservesasthelocationforthebuilt-infunctions.
Toseethebuilt-infunctions, useastatementlikethefollowing:
show functions in _impala_builtins;
show functions in _impala_builtins like '* substring *';
Aftercreatingadatabase,yourimpala-shell sessionoranotherimpala-shell connectedtothesamenodecan
immediatelyaccessthatdatabase.ToaccessthedatabasethroughtheImpaladaemononadifferentnode,issuethe
INVALIDATE METADATA statementfirstwhileconnectedtothatothernode.
SettingtheLOCATION attributeforanewdatabaseisawaytoworkwithsetsoffilesinanHDFSdirectorystructure
outsidethedefaultImpaladatadirectory,asopposedtosettingtheLOCATION attributeforeachindividual table.
IfyouconnecttodifferentImpalanodeswithinanimpala-shell sessionforload-balancing purposes, youcanenable
theSYNC_DDL queryoptiontomakeeachDDLstatementwaitbeforereturning,untiltheneworchangedmetadata
hasbeenreceivedbyalltheImpalanodes.SeeSYNC_DDL QueryOptiononpage361fordetails.
Hiveconsiderations:
WhenyoucreateadatabaseinImpala,thedatabasecanalsobeusedbyHive.WhenyoucreateadatabaseinHive,
issueanINVALIDATE METADATA statementinImpalatomakeImpalapermanen tlyawareofthenewdatabase.
TheSHOW DATABASES statementlistsalldatabases,orthedatabaseswhosenamematchesawildcardpattern.In
CDH5.7/Impala2.5andhigher,theSHOW DATABASES outputincludesasecondcolumnthatdisplaystheassociated
comment,ifany,foreachdatabase.
AmazonS3considerations:
TospecifythatanytablescreatedwithinadatabaseresideontheAmazonS3system,youcanincludeans3a://prefix
ontheLOCATION attribute.InCDH5.8/Impala2.6andhigher,Impalaautomaticallycreatesanyrequiredfoldersas
thedatabases,tables,andpartitions arecreated,andremovesthemwhentheyaredropped.
InCDH5.8/Impala2.6andhigher,ImpalaDDLstatementssuchasCREATE DATABASE ,CREATE TABLE ,DROP
DATABASE CASCADE ,DROP TABLE ,andALTER TABLE [ADD|DROP] PARTITION cancreateorremovefoldersas
neededintheAmazonS3system.PriortoCDH5.8/Impala2.6,youhadtocreatefoldersyourselfandpointImpala
database,tables,orpartitions atthem,andmanually removefolderswhennolongerneeded.SeeUsingImpalawith
theAmazonS3Filesystemonpage692fordetailsaboutreadingandwritingS3datawithImpala.
Cancellation:Cannotbecancelled.
HDFSpermissions:
ApacheImpalaGuide|227ImpalaSQLLanguageReference
TheuserIDthattheimpalad daemonrunsunder,typicallytheimpalauser,musthavewritepermission forthe
parentHDFSdirectoryunderwhichthedatabaseislocated.
Examples:
create database first_db;
use first_db;
create table t1 (x int);
create database second_db;
use second_db;
-- Each database has its own namespace for tables.
-- You can reuse the same table names in each database.
create table t1 (s string);
create database temp;
-- You can either USE a database after creating it,
-- or qualify all references to the table name with the name of the database.
-- Here, tables T2 and T3 are both created in the TEMP database.
create table temp.t2 (x int, y int);
use database temp;
create table t3 (s string);
-- You cannot drop a database while it is selected by the USE statement.
drop database temp;
ERROR: AnalysisException: Cannot drop current default database: temp
-- The always-available database 'default' is a convenient one to USE
-- before dropping a database you created.
use default;
-- Before dropping a database, first drop all the tables inside it,
-- or in CDH 5.5 / Impala 2.3  and higher use the CASCADE clause.
drop database temp;
ERROR: ImpalaRuntimeException: Error making 'dropDatabase' RPC to Hive Metastore:
CAUSED BY: InvalidOperationException: Database temp is not empty
show tables in temp;
+------+
| name |
+------+
| t3   |
+------+
-- CDH 5.5 / Impala 2.3  and higher:
drop database temp cascade;
-- Earlier releases:
drop table temp.t3;
drop database temp;
Relatedinformation:
OverviewofImpalaDatabasesonpage193,DROPDATABASEStatementonpage262,USEStatementonpage385,SHOW
DATABASESonpage368,OverviewofImpalaTablesonpage196
CREATEFUNCTIONStatement
Createsauser-definedfunction(UDF),whichyoucanusetoimplemen tcustomlogicduringSELECTorINSERT
operations.
Syntax:
Thesyntaxisdifferentdepending onwhetheryoucreateascalarUDF,whichiscalledonceforeachrowandimplemen ted
byasinglefunction, orauser-definedaggregatefunction(UDA),whichisimplemen tedbymultiplefunctions that
computeintermediateresultsacrosssetsofrows.
InCDH5.7/Impala2.5andhigher,thesyntaxisalsodifferentforcreatingordroppingscalarJava-basedUDFs.The
statementsforJavaUDFsuseanewsyntax,withoutanyargumenttypesorreturntypespecified. Java-basedUDFs
228|ApacheImpalaGuideImpalaSQLLanguageReference
createdusingthenewsyntaxpersistacrossrestartsoftheImpalacatalogserver,andcanbesharedtransparently
betweenImpalaandHive.
TocreateapersistentscalarC++UDFwithCREATE FUNCTION :
CREATE FUNCTION [IF NOT EXISTS] [ db_name.]function_name ([arg_type [, arg_type ...])
  RETURNS return_type
  LOCATION ' hdfs_path_to_dot_so '
  SYMBOL=' symbol_name '
TocreateapersistentJavaUDFwithCREATE FUNCTION :
CREATE FUNCTION [IF NOT EXISTS] [ db_name.]function_name
  LOCATION ' hdfs_path_to_jar '
  SYMBOL=' class_name '
TocreateapersistentUDA,whichmustbewritteninC++,issueaCREATE AGGREGATE FUNCTION statement:
CREATE [AGGREGATE] FUNCTION [IF NOT EXISTS] [ db_name.]function_name ([arg_type [, 
arg_type ...])
  RETURNS return_type
[INTERMEDIATE type_spec ]
  LOCATION ' hdfs_path '
  [INIT_FN=' function ]
  UPDATE_FN=' function
  MERGE_FN=' function
  [PREPARE_FN=' function ]
  [CLOSEFN=' function ]
[SERIALIZE_FN=' function ]
  [FINALIZE_FN=' function ]
Statementtype:DDL
Varargsnotation:
Note:
Variable-leng thargumentlistsaresupportedforC++UDFs,butcurrentlynotforJavaUDFs.
Iftheunderlying implemen tationofyourfunctionacceptsavariablenumberofarguments:
â¢Thevariableargumentsmustgolastintheargumentlist.
â¢Thevariableargumentsmustallbeofthesametype.
â¢YoumustincludeatleastoneinstanceofthevariableargumentsineveryfunctioncallinvokedfromSQL.
â¢YoudesignatethevariableportionoftheargumentlistintheCREATE FUNCTION statementbyincluding...
immediatelyafterthetypenameofthefirstvariableargument.Forexample,tocreateafunctionthatacceptsan
INTargument,followedbyaBOOLEAN ,followedbyoneormoreSTRINGarguments,yourCREATE FUNCTION
statementwouldlooklike:
CREATE FUNCTION func_name  (INT, BOOLEAN, STRING ...)
  RETURNS type LOCATION ' path' SYMBOL=' entry_point ';
SeeVariable-Leng thArgumentListsonpage531forhowtocodeaC++UDFtoacceptvariable-leng thargumentlists.
Scalarandaggregatefunctions:
Thesimplestkindofuser-definedfunctionreturnsasinglescalarvalueeachtimeitiscalled,typicallyonceforeach
rowintheresultset.ThisgeneralkindoffunctioniswhatisusuallymeantbyUDF.User-definedaggregatefunctions
(UDAs)areaspecializedkindofUDFthatproduceasinglevaluebasedonthecontentsofmultiplerows.Youusually
useUDAsincombinationwithaGROUP BY clausetocondensealargeresultsetintoasmallerone,orevenasingle
rowsummarizing columnvaluesacrossanentiretable.
ApacheImpalaGuide|229ImpalaSQLLanguageReference
YoucreateUDAsbyusingtheCREATE AGGREGATE FUNCTION syntax.TheclausesINIT_FN ,UPDATE_FN ,MERGE_FN ,
SERIALIZE_FN ,FINALIZE_FN ,andINTERMEDIATE onlyapplywhenyoucreateaUDAratherthanascalarUDF.
The*_FNclausesspecifyfunctions tocallatdifferentphasesoffunctionprocessing.
â¢Initialize:ThefunctionyouspecifywiththeINIT_FN clausedoesanyinitialsetup,suchasinitializing member
variablesininternaldatastructures.ThisfunctionisoftenastubforsimpleUDAs.Youcanomitthisclauseanda
default(no-op)functionwillbeused.
â¢Update:ThefunctionyouspecifywiththeUPDATE_FN clauseiscalledonceforeachrowintheoriginalresultset,
thatis,beforeanyGROUP BY clauseisapplied.Aseparateinstanceofthefunctioniscalledforeachdifferent
valuereturnedbytheGROUP BY clause.Thefinalargumentpassedtothisfunctionisapointer,towhichyou
writeanupdatedvaluebasedonitsoriginalvalueandthevalueofthefirstargument.
â¢Merge:ThefunctionyouspecifywiththeMERGE_FN clauseiscalledanarbitrarynumberoftimes,tocombine
intermediatevaluesproducedbydifferentnodesordifferentthreadsasImpalareadsandprocessesdatafilesin
parallel.Thefinalargumentpassedtothisfunctionisapointer,towhichyouwriteanupdatedvaluebasedonits
originalvalueandthevalueofthefirstargument.
â¢Serialize:ThefunctionyouspecifywiththeSERIALIZE_FN clausefreesmemoryallocatedtointermediateresults.
ItisrequiredifanymemorywasallocatedbytheAllocatefunctionintheInit,Update,orMergefunctions, orif
theintermediatetypecontainsanypointers.SeetheUDAcodesamplesfordetails.
â¢Finalize:ThefunctionyouspecifywiththeFINALIZE_FN clausedoesanyrequiredteardownforresourcesacquired
byyourUDF,suchasfreeingmemory,closingfilehandlesifyouexplicitlyopenedanyfiles,andsoon.Thisfunction
isoftenastubforsimpleUDAs.Youcanomitthisclauseandadefault(no-op)functionwillbeused.Itisrequired
inUDAswherethefinalreturntypeisdifferentthantheintermediatetype.orifanymemorywasallocatedby
theAllocatefunctionintheInit,Update,orMergefunctions. SeetheUDAcodesamplesfordetails.
Ifyouuseaconsistentnamingconventionforeachoftheunderlying functions, Impalacanautomaticallydetermine
thenamesbasedonthefirstsuchclause,sotheothersareoptional.
Forend-to-endexamplesofUDAs,seeUser-DefinedFunctions (UDFs)onpage525.
Complextypeconsiderations:
Currently,ImpalaUDFscannotacceptargumentsorreturnvaluesoftheImpalacomplextypes(STRUCT,ARRAY,or
MAP).
Usagenotes:
â¢Whenauthorizationisenabled, theCREATE FUNCTION statementrequires:
âTheCREATEprivilegeonthedatabase.
âTheALLprivilegeontwoURIswheretheURIsare:
âTheJARfileonthefilesystem.Forexample:
GRANT ALL ON URI 'file: ///path_to_my.jar ' TO ROLE my_role;
âTheJARonHDFS.Forexample:
GRANT ALL ON URI 'hdfs: ///path/to/jar ' TO ROLE my_role
â¢YoucanwriteImpalaUDFsineitherC++orJava.C++UDFsarenewtoImpala,andaretherecommended format
forhighperformance utilizingnativecode.Java-basedUDFsarecompatiblebetweenImpalaandHive,andare
mostsuitedtoreusingexistingHiveUDFs.(ImpalacanrunJava-basedHiveUDFsbutnotHiveUDAs.)
â¢CDH5.7/Impala2.5introducesUDFimprovementstopersistenceforbothC++andJavaUDFs,andbetter
compatibilitybetweenImpalaandHiveforJavaUDFs.SeeUser-DefinedFunctions (UDFs)onpage525fordetails.
â¢ThebodyoftheUDFisrepresentedbya.soor.jarfile,whichyoustoreinHDFSandtheCREATE FUNCTION
statementdistributestoeachImpalanode.
230|ApacheImpalaGuideImpalaSQLLanguageReference
â¢Impalacallstheunderlying codeduringSQLstatementevaluation,asmanytimesasneededtoprocessallthe
rowsfromtheresultset.AllUDFsareassumed tobedeterministic,thatis,toalwaysreturnthesameresultwhen
passedthesameargumentvalues.ImpalamightormightnotskipsomeinvocationsofaUDFiftheresultvalue
isalreadyknownfromapreviouscall.Therefore,donotrelyontheUDFbeingcalledaspecificnumberoftimes,
anddonotreturndifferentresultvaluesbasedonsomeexternalfactorsuchasthecurrenttime,arandomnumber
function, oranexternaldatasourcethatcouldbeupdatedwhileanImpalaqueryisinprogress.
â¢ThenamesofthefunctionargumentsintheUDFarenotsignificant,onlytheirnumber,positions, anddatatypes.
â¢Youcanoverloadthesamefunctionnamebycreatingmultipleversionsofthefunction, eachwithadifferent
argumentsignature.Forsecurityreasons,youcannotmakeaUDFwiththesamenameasanybuilt-infunction.
â¢IntheUDFcode,yourepresentthefunctionreturnresultasastruct.Thisstructcontains2fields.Thefirst
fieldisaboolean representingwhetherthevalueisNULLornot.(Whenthisfieldistrue,thereturnvalueis
interpretedasNULL.)Thesecondfieldisthesametypeasthespecified functionreturntype,andholdsthereturn
valuewhenthefunctionreturnssomethingotherthanNULL.
â¢IntheUDFcode,yourepresentthefunctionargumentsasaninitialpointertoaUDFcontextstructure,followed
byreferencestozeroormorestructs,corresponding toeachofthearguments.Eachstructhasthesame2
fieldsaswiththereturnvalue,aboolean fieldrepresentingwhethertheargumentisNULL,andafieldofthe
appropriatetypeholdinganynon-NULLargumentvalue.
â¢Forsamplecodeandbuildinstructions forUDFs,seethesampleUDFsintheImpalagithubrepo.
â¢BecausethefilerepresentingthebodyoftheUDFisstoredinHDFS,itisautomaticallyavailabletoalltheImpala
nodes.Youdonotneedtomanually copyanyUDF-relatedfilesbetweenservers.
â¢BecauseImpalacurrentlydoesnothaveanyALTER FUNCTION statement,ifyouneedtorenameafunction,
moveittoadifferentdatabase,orchangeitssignatureorotherproperties, issueaDROP FUNCTION statement
fortheoriginalfunctionfollowedbyaCREATE FUNCTION withthedesiredproperties.
â¢BecauseeachUDFisassociatedwithaparticular database,eitherissueaUSEstatementbeforedoinganyCREATE
FUNCTION statements,orspecifythenameofthefunctionasdb_name.function_name .
IfyouconnecttodifferentImpalanodeswithinanimpala-shell sessionforload-balancing purposes, youcanenable
theSYNC_DDL queryoptiontomakeeachDDLstatementwaitbeforereturning,untiltheneworchangedmetadata
hasbeenreceivedbyalltheImpalanodes.SeeSYNC_DDL QueryOptiononpage361fordetails.
Compatibility:
ImpalacanrunUDFsthatwerecreatedthroughHive,aslongastheyrefertoImpala-compatibledatatypes(not
compositeornestedcolumntypes).HivecanrunJava-basedUDFsthatwerecreatedthroughImpala,butnotImpala
UDFswritteninC++.
TheHivecurrent_user() functioncannotbecalledfromaJavaUDFthroughImpala.
Persistence:
InCDH5.7/Impala2.5andhigher,ImpalaUDFsandUDAswritteninC++arepersistedinthemetastoredatabase.
JavaUDFsarealsopersisted,iftheywerecreatedwiththenewCREATE FUNCTION syntaxforJavaUDFs,wherethe
Javafunctionargumentandreturntypesareomitted.Java-basedUDFscreatedwiththeoldCREATE FUNCTION syntax
donotpersistacrossrestartsbecausetheyareheldinthememoryofthecatalogd daemon. Untilyoure-createsuch
JavaUDFsusingthenewCREATE FUNCTION syntax,youmustreloadthoseJava-basedUDFsbyrunningtheoriginal
CREATE FUNCTION statementsagaineachtimeyourestartthecatalogd daemon. PriortoCDH5.7/Impala2.5the
requirementtoreloadfunctions afterarestartappliedtobothC++andJavafunctions.
Cancellation:Cannotbecancelled.
HDFSpermissions: ThisstatementdoesnottouchanyHDFSfilesordirectories,thereforenoHDFSpermissions are
required.
Examples:
Foradditional examplesofallkindsofuser-definedfunctions, seeUser-DefinedFunctions (UDFs)onpage525.
ThefollowingexampleshowshowtotakeaJavajarfileandmakeallthefunctions insideoneofitsclassesintoUDFs
underasingle(overloaded) functionnameinImpala.EachCREATE FUNCTION orDROP FUNCTION statementapplies
toalltheoverloaded Javafunctions withthesamename.ThisexampleusesthesignaturelesssyntaxforCREATE
FUNCTION andDROP FUNCTION ,whichisavailableinCDH5.7/Impala2.5andhigher.
ApacheImpalaGuide|231ImpalaSQLLanguageReference
Atthestart,thejarfileisinthelocalfilesystem.ThenitiscopiedintoHDFS,sothatitisavailableforImpalatoreference
throughtheCREATE FUNCTION statementandqueriesthatrefertotheImpalafunctionname.
$ jar -tvf udf-examples-cdh570.jar
     0 Mon Feb 22 04:06:50 PST 2016 META-INF/
   122 Mon Feb 22 04:06:48 PST 2016 META-INF/MANIFEST.MF
     0 Mon Feb 22 04:06:46 PST 2016 com/
     0 Mon Feb 22 04:06:46 PST 2016 com/cloudera/
     0 Mon Feb 22 04:06:46 PST 2016 com/cloudera/impala/
  2460 Mon Feb 22 04:06:46 PST 2016 com/cloudera/impala/IncompatibleUdfTest.class
   541 Mon Feb 22 04:06:46 PST 2016 com/cloudera/impala/TestUdfException.class
  3438 Mon Feb 22 04:06:46 PST 2016 com/cloudera/impala/JavaUdfTest.class
  5872 Mon Feb 22 04:06:46 PST 2016 com/cloudera/impala/TestUdf.class
...
$ hdfs dfs -put udf-examples-cdh570.jar /user/impala/udfs
$ hdfs dfs -ls /user/impala/udfs
Found 2 items
-rw-r--r--   3 jrussell supergroup        853 2015-10-09 14:05 
/user/impala/udfs/hello_world.jar
-rw-r--r--   3 jrussell supergroup       7366 2016-06-08 14:25 
/user/impala/udfs/udf-examples-cdh570.jar
Inimpala-shell ,theCREATE FUNCTION referstotheHDFSpathofthejarfileandthefullyqualified classname
insidethejar.Eachofthefunctions insidetheclassbecomesanImpalafunction, eachoneoverloaded underthe
specified Impalafunctionname.
[localhost:21000] > create function testudf location 
'/user/impala/udfs/udf-examples-cdh570.jar' symbol='com.cloudera.impala.TestUdf';
[localhost:21000] > show functions;
+-------------+---------------------------------------+-------------+---------------+
| return type | signature                             | binary type | is persistent |
+-------------+---------------------------------------+-------------+---------------+
| BIGINT      | testudf(BIGINT)                       | JAVA        | true          |
| BOOLEAN     | testudf(BOOLEAN)                      | JAVA        | true          |
| BOOLEAN     | testudf(BOOLEAN, BOOLEAN)             | JAVA        | true          |
| BOOLEAN     | testudf(BOOLEAN, BOOLEAN, BOOLEAN)    | JAVA        | true          |
| DOUBLE      | testudf(DOUBLE)                       | JAVA        | true          |
| DOUBLE      | testudf(DOUBLE, DOUBLE)               | JAVA        | true          |
| DOUBLE      | testudf(DOUBLE, DOUBLE, DOUBLE)       | JAVA        | true          |
| FLOAT       | testudf(FLOAT)                        | JAVA        | true          |
| FLOAT       | testudf(FLOAT, FLOAT)                 | JAVA        | true          |
| FLOAT       | testudf(FLOAT, FLOAT, FLOAT)          | JAVA        | true          |
| INT         | testudf(INT)                          | JAVA        | true          |
| DOUBLE      | testudf(INT, DOUBLE)                  | JAVA        | true          |
| INT         | testudf(INT, INT)                     | JAVA        | true          |
| INT         | testudf(INT, INT, INT)                | JAVA        | true          |
| SMALLINT    | testudf(SMALLINT)                     | JAVA        | true          |
| SMALLINT    | testudf(SMALLINT, SMALLINT)           | JAVA        | true          |
| SMALLINT    | testudf(SMALLINT, SMALLINT, SMALLINT) | JAVA        | true          |
| STRING      | testudf(STRING)                       | JAVA        | true          |
| STRING      | testudf(STRING, STRING)               | JAVA        | true          |
| STRING      | testudf(STRING, STRING, STRING)       | JAVA        | true          |
| TINYINT     | testudf(TINYINT)                      | JAVA        | true          |
+-------------+---------------------------------------+-------------+---------------+
Theseareallsimplefunctions thatreturntheirsinglearguments,orsum,concatenate,andsoontheirmultiple
arguments.Impaladetermineswhichoverloaded functiontousebasedonthenumberandtypesofthearguments.
insert into bigint_x values (1), (2), (4), (3);
select testudf(x) from bigint_x;
+-----------------+
| udfs.testudf(x) |
+-----------------+
| 1               |
| 2               |
| 4               |
| 3               |
232|ApacheImpalaGuideImpalaSQLLanguageReference
+-----------------+
insert into int_x values (1), (2), (4), (3);
select testudf(x, x+1, x*x) from int_x;
+-------------------------------+
| udfs.testudf(x, x + 1, x * x) |
+-------------------------------+
| 4                             |
| 9                             |
| 25                            |
| 16                            |
+-------------------------------+
select testudf(x) from string_x;
+-----------------+
| udfs.testudf(x) |
+-----------------+
| one             |
| two             |
| four            |
| three           |
+-----------------+
select testudf(x,x) from string_x;
+--------------------+
| udfs.testudf(x, x) |
+--------------------+
| oneone             |
| twotwo             |
| fourfour           |
| threethree         |
+--------------------+
ThepreviousexampleusedthesameImpalafunctionnameasthenameoftheclass.Thisexampleshowshowthe
Impalafunctionnameisindependen toftheunderlying Javaclassorfunctionnames.AsecondCREATE FUNCTION
statementresultsinasetofoverloaded functions allnamedmy_func ,togoalongwiththeoverloaded functions all
namedtestudf .
create function my_func location '/user/impala/udfs/udf-examples-cdh570.jar'
  symbol='com.cloudera.impala.TestUdf';
show functions;
+-------------+---------------------------------------+-------------+---------------+
| return type | signature                             | binary type | is persistent |
+-------------+---------------------------------------+-------------+---------------+
| BIGINT      | my_func(BIGINT)                       | JAVA        | true          |
| BOOLEAN     | my_func(BOOLEAN)                      | JAVA        | true          |
| BOOLEAN     | my_func(BOOLEAN, BOOLEAN)             | JAVA        | true          |
...
| BIGINT      | testudf(BIGINT)                       | JAVA        | true          |
| BOOLEAN     | testudf(BOOLEAN)                      | JAVA        | true          |
| BOOLEAN     | testudf(BOOLEAN, BOOLEAN)             | JAVA        | true          |
...
Thecorresponding DROP FUNCTION statementwithnosignaturedropsalltheoverloaded functions withthatname.
drop function my_func;
show functions;
+-------------+---------------------------------------+-------------+---------------+
| return type | signature                             | binary type | is persistent |
+-------------+---------------------------------------+-------------+---------------+
| BIGINT      | testudf(BIGINT)                       | JAVA        | true          |
| BOOLEAN     | testudf(BOOLEAN)                      | JAVA        | true          |
| BOOLEAN     | testudf(BOOLEAN, BOOLEAN)             | JAVA        | true          |
...
ThesignaturelessCREATE FUNCTION syntaxforJavaUDFsensuresthatthefunctions showninthisexampleremain
availableaftertheImpalaservice(specifically,theCatalogServer)arerestarted.
ApacheImpalaGuide|233ImpalaSQLLanguageReference
Relatedinformation:
User-DefinedFunctions (UDFs)onpage525formorebackgroundinformation,usageinstructions, andexamplesfor
ImpalaUDFs;DROPFUNCTIONStatementonpage263
CREATEROLEStatement(CDH5.2orhigheronly)
TheCREATE ROLE statementcreatesaroletowhichprivilegescanbegranted.Privilegescanbegrantedtoroles,
whichcanthenbeassignedtousers.Auserthathasbeenassignedarolewillonlybeabletoexercisetheprivileges
ofthatrole.Onlyusersthathaveadministrativeprivilegescancreate/droproles.Bydefault,thehive,impalaand
hueusershaveadministrativeprivilegesinSentry.
Syntax:
CREATE ROLE role_name
Requiredprivileges:
Onlyadministrativeusers(thosewithALLprivilegesontheserver,definedintheSentrypolicyfile)canusethis
statement.
Compatibility:
Impalamakesuseofanyrolesandprivilegesspecified bytheGRANTandREVOKEstatementsinHive,andHivemakes
useofanyrolesandprivilegesspecified bytheGRANTandREVOKEstatementsinImpala.TheImpalaGRANTandREVOKE
statementsforprivilegesdonotrequiretheROLEkeywordtoberepeatedbeforeeachrolename,unliketheequivalent
Hivestatements.
Cancellation:Cannotbecancelled.
HDFSpermissions: ThisstatementdoesnottouchanyHDFSfilesordirectories,thereforenoHDFSpermissions are
required.
Relatedinformation:
EnablingSentryAuthorizationforImpalaonpage87,GRANTStatement(CDH5.2orhigheronly)onpage273,REVOKE
Statement(CDH5.2orhigheronly)onpage293,DROPROLEStatement(CDH5.2orhigheronly)onpage265,SHOW
Statementonpage363
CREATETABLEStatement
Createsanewtableandspecifiesitscharacteristics.Whilecreatingatable,youoptionallyspecifyaspectssuchas:
â¢Whetherthetableisinternalorexternal.
â¢Thecolumnsandassociateddatatypes.
â¢Thecolumnsusedforphysicallypartitioning thedata.
â¢Thefileformatfordatafiles.
â¢TheHDFSdirectorywherethedatafilesarelocated.
Syntax:
Thegeneralsyntaxforcreatingatableandspecifyingitscolumnsisasfollows:
Explicitcolumndefinitions:
CREATE [EXTERNAL] TABLE [IF NOT EXISTS] [ db_name.]table_name
  (col_name data_type
    [COMMENT ' col_comment ']
    [, ...]
  )
  [PARTITIONED BY ( col_name data_type  [COMMENT ' col_comment '], ...)]
[SORT BY ([ column [, column ...]])]
  [COMMENT ' table_comment ']
  [ROW FORMAT row_format ]
  [WITH SERDEPROPERTIES (' key1'='value1', 'key2'='value2', ...)]
234|ApacheImpalaGuideImpalaSQLLanguageReference
  [STORED AS file_format ]
  [LOCATION ' hdfs_path ']
[CACHED IN ' pool_name '[WITH REPLICATION = integer] | UNCACHED]
  [TBLPROPERTIES (' key1'='value1', 'key2'='value2', ...)]
CREATETABLEASSELECT:
CREATE [EXTERNAL] TABLE [IF NOT EXISTS] db_name.]table_name
[PARTITIONED BY ( col_name [, ...])]
[SORT BY ([ column [, column ...]])]
    [COMMENT ' table_comment ']
+   [ROW FORMAT row_format ]
    [WITH SERDEPROPERTIES (' key1'='value1', 'key2'='value2', ...)]
+   [STORED AS ctas_file_format ]
    [LOCATION ' hdfs_path ']
+     [CACHED IN ' pool_name '[WITH REPLICATION = integer] | UNCACHED]
    [TBLPROPERTIES (' key1'='value1', 'key2'='value2', ...)]
  AS
select_statement
Note:Ifcreatingapartitioned table,thepartition keycolumnsmustbelistedlastintheSELECT
columnslist,inthesameorderasinthePARTITIONED BY clause.Otherwise,youwillreceivean
erroraboutacolumnnamemismatch.
primitive_type:
    TINYINT
  | SMALLINT
  | INT
  | BIGINT
  | BOOLEAN
  | FLOAT
  | DOUBLE
| DECIMAL
  | STRING
| CHAR
| VARCHAR
  | TIMESTAMP
complex_type:
    struct_type
  | array_type
  | map_type
struct_type: STRUCT < name : primitive_or_complex_type  [COMMENT ' comment_string '], ...
 >
array_type: ARRAY < primitive_or_complex_type  >
map_type: MAP < primitive_type , primitive_or_complex_type  >
row_format:
  DELIMITED [FIELDS TERMINATED BY ' char' [ESCAPED BY ' char']]
  [LINES TERMINATED BY ' char']
file_format:
    PARQUET
  | TEXTFILE
  | AVRO
  | SEQUENCEFILE
  | RCFILE
ctas_file_format:
    PARQUET
  | TEXTFILE
ApacheImpalaGuide|235ImpalaSQLLanguageReference
Columndefinitionsinferredfromdatafile:
CREATE [EXTERNAL] TABLE [IF NOT EXISTS] [ db_name.]table_name
  LIKE PARQUET ' hdfs_path_of_parquet_file '
  [PARTITIONED BY ( col_name data_type  [COMMENT ' col_comment '], ...)]
[SORT BY ([ column [, column ...]])]
  [COMMENT ' table_comment ']
  [ROW FORMAT row_format ]
  [WITH SERDEPROPERTIES (' key1'='value1', 'key2'='value2', ...)]
  [STORED AS file_format ]
  [LOCATION ' hdfs_path ']
  [CACHED IN ' pool_name '[WITH REPLICATION = integer] | UNCACHED]
  [TBLPROPERTIES (' key1'='value1', 'key2'='value2', ...)]
data_type:
primitive_type
  | array_type
  | map_type
  | struct_type
Kudutables:
CREATE TABLE [IF NOT EXISTS] [ db_name.]table_name
  (col_name data_type
[kudu_column_attribute  ...]
    [COMMENT ' col_comment ']
    [, ...]
    [PRIMARY KEY ( col_name [, ...])]
  )
[PARTITION BY kudu_partition_clause ]
  [COMMENT ' table_comment ']
  STORED AS KUDU
  [TBLPROPERTIES (' key1'='value1', 'key2'='value2', ...)]
Kuducolumnattributes:
  PRIMARY KEY
| [NOT] NULL
| ENCODING codec
| COMPRESSION algorithm
| DEFAULT constant
| BLOCK_SIZE number
kudu_partition_clause:
kudu_partition_clause ::= [ hash_clause  [, ...]] [, range_clause  ]
hash_clause ::=
  HASH [ ( pk_col [, ...]) ]
    PARTITIONS n
range_clause ::=
  RANGE [ ( pk_col [, ...]) ]
  (
    {
      PARTITION constant_expression range_comparison_operator  VALUES 
range_comparison_operator constant_expression
      | PARTITION VALUE = constant_expression_or_tuple
    }
   [, ...]
  )
range_comparison_operator ::= { < | <= }
ExternalKudutables:
CREATE EXTERNAL TABLE [IF NOT EXISTS] [ db_name.]table_name
  [COMMENT ' table_comment ']
236|ApacheImpalaGuideImpalaSQLLanguageReference
  STORED AS KUDU
  [TBLPROPERTIES ('kudu.table_name'=' internal_kudu_name ')]
CREATETABLEASSELECTforKudutables:
CREATE TABLE [IF NOT EXISTS] db_name.]table_name
  [PRIMARY KEY ( col_name [, ...])]
  [PARTITION BY kudu_partition_clause ]
  [COMMENT ' table_comment ']
  STORED AS KUDU
  [TBLPROPERTIES (' key1'='value1', 'key2'='value2', ...)]
AS
select_statement
Statementtype:DDL
Columndefinitions:
Depending ontheformoftheCREATE TABLE statement,thecolumndefinitionsarerequiredornotallowed.
WiththeCREATE TABLE AS SELECT andCREATE TABLE LIKE syntax,youdonotspecifythecolumnsatall;the
columnnamesandtypesarederivedfromthesourcetable,query,ordatafile.
WiththebasicCREATE TABLE syntax,youmustlistoneormorecolumns,itsname,type,andoptionallyacomment,
inadditiontoanycolumnsusedaspartitioning keys.Thereisoneexceptionwherethecolumnlistisnotrequired:
whencreatinganAvrotablewiththeSTORED AS AVRO clause,youcanomitthelistofcolumnsandspecifythesame
metadataaspartoftheTBLPROPERTIES clause.
Complextypeconsiderations:
TheImpalacomplextypes(STRUCT,ARRAY,orMAP)areavailableinCDH5.5/Impala2.3andhigher.Becauseyoucan
nestthesetypes(forexample,tomakeanarrayofmapsorastructwithanarrayfield),thesetypesarealsosometimes
referredtoasnestedtypes.SeeComplexTypes(CDH5.5orhigheronly)onpage139forusagedetails.
Impalacancreatetablescontainingcomplextypecolumns,withanysupportedfileformat.BecausecurrentlyImpala
canonlyquerycomplextypecolumnsinParquettables,creatingtableswithcomplextypecolumnsandotherfile
formatssuchastextisoflimiteduse.Forexample,youmightcreateatexttableincluding somecolumnswithcomplex
typeswithImpala,anduseHiveaspartofyourtoingestthenestedtypedataandcopyittoanidenticalParquettable.
Oryoumightcreateapartitioned tablecontainingcomplextypecolumnsusingonefileformat,anduseALTER TABLE
tochangethefileformatofindividual partitions toParquet;ImpalacanthenqueryonlytheParquet-formatpartitions
inthattable.
Partitioned tablescancontaincomplextypecolumns.Allthepartition keycolumnsmustbescalartypes.
Internalandexternaltables(EXTERNAL andLOCATIONclauses):
Bydefault,Impalacreatesanâinternalâtable,whereImpalamanagestheunderlying datafilesforthetable,and
physicallydeletesthedatafileswhenyoudropthetable.IfyouspecifytheEXTERNAL clause,Impalatreatsthetable
asanâexternalâtable,wherethedatafilesaretypicallyproducedoutsideImpalaandqueriedfromtheiroriginal
locationsinHDFS,andImpalaleavesthedatafilesinplacewhenyoudropthetable.Fordetailsaboutinternaland
externaltables,seeOverviewofImpalaTablesonpage196.
Typically,foranexternaltableyouincludeaLOCATION clausetospecifythepathtotheHDFSdirectorywhereImpala
readsandwritesfilesforthetable.Forexample,ifyourdatapipelineproducesParquetfilesintheHDFSdirectory
/user/etl/destination ,youmightcreateanexternaltableasfollows:
CREATE EXTERNAL TABLE external_parquet (c1 INT, c2 STRING, c3 TIMESTAMP)
  STORED AS PARQUET LOCATION '/user/etl/destination';
Although theEXTERNAL andLOCATION clausesareoftenspecified together,LOCATION isoptionalforexternaltables,
andyoucanalsospecifyLOCATION forinternaltables.ThedifferenceisallaboutwhetherImpalaâtakescontrolâof
theunderlying datafilesandmovesthemwhenyourenamethetable,ordeletesthemwhenyoudropthetable.For
moreaboutinternalandexternaltablesandhowtheyinteractwiththeLOCATION attribute,seeOverviewofImpala
Tablesonpage196.
ApacheImpalaGuide|237ImpalaSQLLanguageReference
Partitioned tables(PARTITIONED BYclause):
ThePARTITIONED BY clausedividesthedatafilesbasedonthevaluesfromoneormorespecified columns.Impala
queriescanusethepartition metadatatominimizetheamountofdatathatisreadfromdiskortransmittedacross
thenetwork,particularly duringjoinqueries.Fordetailsaboutpartitioning ,seePartitioning forImpalaTablesonpage
625.
Note:
AllKudutablesrequirepartitioning ,whichinvolvesdifferentsyntaxthannon-Kudutables.Seethe
PARTITION BY clause,ratherthanPARTITIONED BY ,forKudutables.
InCDH5.13/Impala2.10andhigher,thePARTITION BY clauseisoptionalforKudutables.Ifthe
clauseisomitted,Impalaautomaticallyconstructsasinglepartition thatisnotconnectedtoany
column.BecausesuchatablecannottakeadvantageofKudufeaturesforparallelizedqueriesand
queryoptimizations,omittingthePARTITION BY clauseisonlyappropriateforsmalllookuptables.
PriortoCDH5.7/Impala2.5,youcoulduseapartitioned tableasthesourceandcopydatafromit,butcouldnot
specifyanypartitioning clausesforthenewtable.InCDH5.7/Impala2.5andhigher,youcannowusethePARTITIONED
BYclausewithaCREATE TABLE AS SELECT statement.Seetheexamplesunderthefollowingdiscussion ofthe
CREATE TABLE AS SELECT syntaxvariation.
Sortedtables(SORTBYclause):
TheoptionalSORT BY clauseletsyouspecifyzeroormorecolumnsthataresortedinthedatafilescreatedbyeach
ImpalaINSERTorCREATE TABLE AS SELECT operation.CreatingdatafilesthataresortedismostusefulforParquet
tables,wherethemetadatastoredinsideeachfileincludestheminimum andmaximumvaluesforeachcolumninthe
file.(Thestatisticsapplytoeachrowgroupwithinthefile;forsimplicity ,Impalawritesasinglerowgroupineachfile.)
GroupingdatavaluestogetherinrelativelynarrowrangeswithineachdatafilemakesitpossibleforImpalatoquickly
skipoverdatafilesthatdonotcontainvaluerangesindicatedintheWHEREclauseofaquery,andcanimprovethe
effectivenessofParquetencodingandcompression.
ThisclauseisnotapplicableforKudutablesorHBasetables.Although itworksforotherHDFSfileformatsbesides
Parquet,themoreefficientlayoutismostevidentwithParquettables,becauseeachParquetdatafileincludesstatistics
aboutthedatavaluesinthatfile.
TheSORT BY columnscannotincludeanypartitionkeycolumnsforapartitioned table,becausethosecolumnvalues
arenotrepresentedintheunderlying datafiles.
BecausedatafilescanarriveinImpalatablesbymechanisms thatdonotrespecttheSORT BY clause,suchasLOAD
DATAorETLtoolsthatcreateHDFSfiles,Impaladoesnotguaranteeorrelyonthedatabeingsorted.Thesortingaspect
isonlyusedtocreateamoreefficientlayoutforParquetfilesgeneratedbyImpala,whichhelpstooptimizethe
processingofthoseParquetfilesduringImpalaqueries.DuringanINSERTorCREATE TABLE AS SELECT operation,
thesortingoccurswhentheSORT BY clauseappliestothedestinationtableforthedata,regardlessofwhetherthe
sourcetablehasaSORT BY clause.
Forexample,whencreatingatableintendedtocontaincensusdata,youmightdefinesortcolumnssuchaslastname
andstate.Ifadatafileinthistablecontainsanarrowrangeoflastnames,forexamplefromSmithtoSmythe,Impala
canquicklydetectthatthisdatafilecontainsnomatchesforaWHEREclausesuchasWHERE last_name = 'Jones'
andavoidreadingtheentirefile.
CREATE TABLE census_data (last_name STRING, first_name STRING, state STRING, address 
STRING)
  SORT BY (last_name, state)
  STORED AS PARQUET;
Likewise,ifanexistingtablecontainsdatawithoutanysortorder,youcanreorganizethedatainamoreefficientway
byusingINSERTorCREATE TABLE AS SELECT tocopythatdataintoanewtablewithaSORT BY clause:
CREATE TABLE sorted_census_data
  SORT BY (last_name, state)
238|ApacheImpalaGuideImpalaSQLLanguageReference
  STORED AS PARQUET
  AS SELECT last_name, first_name, state, address
    FROM unsorted_census_data;
ThemetadatafortheSORT BY clauseisstoredintheTBLPROPERTIES fieldsforthetable.OtherSQLenginesthat
caninteroperatewithImpalatables,suchasHiveandSparkSQL,donotrecognizethispropertywheninserting intoa
tablethathasaSORT BY clause.
Kuduconsiderations:
BecauseKudutablesdonotsupportclausesrelatedtoHDFSandS3datafilesandpartitioning mechanisms, thesyntax
associatedwiththeSTORED AS KUDU clauseisshownseparatelyintheabovesyntaxdescriptions.Kudutableshave
theirownsyntaxforCREATE TABLE ,CREATE EXTERNAL TABLE ,andCREATE TABLE AS SELECT .PriortoCDH
5.13/Impala2.10,allinternalKudutablesrequireaPARTITION BY clause,differentthanthePARTITIONED BY
clauseforHDFS-backedtables.
HerearesomeexamplesofcreatingemptyKudutables:
-- Single partition. Only for CDH 5.13 / Impala 2.10  and higher.
-- Only suitable for small lookup tables.
CREATE TABLE kudu_no_partition_by_clause
  (
    id bigint PRIMARY KEY, s STRING, b BOOLEAN
  )
  STORED AS KUDU;
-- Single-column primary key.
CREATE TABLE kudu_t1 (id BIGINT PRIMARY key, s STRING, b BOOLEAN)
  PARTITION BY HASH (id) PARTITIONS 20 STORED AS KUDU;
-- Multi-column primary key.
CREATE TABLE kudu_t2 (id BIGINT, s STRING, b BOOLEAN, PRIMARY KEY (id,s))
  PARTITION BY HASH (s) PARTITIONS 30 STORED AS KUDU;
-- Meaningful primary key column is good for range partitioning.
CREATE TABLE kudu_t3 (id BIGINT, year INT, s STRING,
    b BOOLEAN, PRIMARY KEY (id,year))
  PARTITION BY HASH (id) PARTITIONS 20,
  RANGE (year) (PARTITION 1980 <= VALUES < 1990,
    PARTITION 1990 <= VALUES < 2000,
    PARTITION VALUE = 2001,
    PARTITION 2001 < VALUES)
  STORED AS KUDU;
HereisanexampleofcreatinganexternalKudutable:
-- Inherits column definitions from original table.
-- For tables created through Impala, the kudu.table_name property
-- comes from DESCRIBE FORMATTED output from the original table.
CREATE EXTERNAL TABLE external_t1 STORED AS KUDU
  TBLPROPERTIES ('kudu.table_name'='kudu_tbl_created_via_api');
HereisanexampleofCREATE TABLE AS SELECT syntaxforaKudutable:
-- The CTAS statement defines the primary key and partitioning scheme.
-- The rest of the column definitions are derived from the select list.
CREATE TABLE ctas_t1
  PRIMARY KEY (id) PARTITION BY HASH (id) PARTITIONS 10
  STORED AS KUDU
  AS SELECT id, s FROM kudu_t1;
ThefollowingCREATE TABLE clausesarenotsupportedforKudutables:
ApacheImpalaGuide|239ImpalaSQLLanguageReference
â¢PARTITIONED BY (KudutablesusetheclausePARTITION BY instead)
â¢LOCATION
â¢ROWFORMAT
â¢CACHED IN | UNCACHED
â¢WITH SERDEPROPERTIES
FormoreonthePRIMARY KEY clause,seePrimaryKeyColumnsforKuduTablesonpage671andPRIMARYKEYAttribute
onpage672.
FormoreoncreatingaKudutablewithaspecificreplicationfactor,seeKuduReplicationFactoronpage671.
FormoreontheNULLandNOT NULL attributes,seeNULL|NOTNULLAttributeonpage673.
FormoreontheENCODING attribute,seeENCODINGAttributeonpage674.
FormoreontheCOMPRESSION attribute,seeCOMPRESSIONAttributeonpage675.
FormoreontheDEFAULT attribute,seeDEFAULTAttributeonpage673.
FormoreontheBLOCK_SIZE attribute,seeBLOCK_SIZE Attributeonpage675.
Partitioning forKudutables(PARTITIONBYclause)
ForKudutables,youspecifylogicalpartitioning acrossoneormorecolumnsusingthePARTITION BY clause.In
contrasttopartitioning forHDFS-basedtables,multiplevaluesforapartition keycolumncanbelocatedinthesame
partition. TheoptionalHASHclauseletsyoudivideoneorasetofpartition keycolumnsintoaspecified numberof
buckets.YoucanusemorethanoneHASHclause,specifyingadistinctsetofpartitionkeycolumnsforeach.Theoptional
RANGEclausefurthersubdivides thepartitions, basedonasetofcomparison operationsforthepartitionkeycolumns.
HerearesomeexamplesofthePARTITION BY HASH syntax:
-- Apply hash function to 1 primary key column.
create table hash_t1 (x bigint, y bigint, s string, primary key (x,y))
  partition by hash (x) partitions 10
  stored as kudu;
-- Apply hash function to a different primary key column.
create table hash_t2 (x bigint, y bigint, s string, primary key (x,y))
  partition by hash (y) partitions 10
  stored as kudu;
-- Apply hash function to both primary key columns.
-- In this case, the total number of partitions is 10.
create table hash_t3 (x bigint, y bigint, s string, primary key (x,y))
  partition by hash (x,y) partitions 10
  stored as kudu;
-- When the column list is omitted, apply hash function to all primary key columns.
create table hash_t4 (x bigint, y bigint, s string, primary key (x,y))
  partition by hash partitions 10
  stored as kudu;
-- Hash the X values independently from the Y values.
-- In this case, the total number of partitions is 10 x 20.
create table hash_t5 (x bigint, y bigint, s string, primary key (x,y))
  partition by hash (x) partitions 10, hash (y) partitions 20
  stored as kudu;
HerearesomeexamplesofthePARTITION BY RANGE syntax:
-- Create partitions that cover every possible value of X.
-- Ranges that span multiple values use the keyword VALUES between
-- a pair of < and <= comparisons.
create table range_t1 (x bigint, s string, s2 string, primary key (x, s))
  partition by range (x)
    (
240|ApacheImpalaGuideImpalaSQLLanguageReference
      partition 0 <= values <= 49, partition 50 <= values <= 100,
      partition values < 0, partition 100 < values
    )
  stored as kudu;
-- Create partitions that cover some possible values of X.
-- Values outside the covered range(s) are rejected.
-- New range partitions can be added through ALTER TABLE.
create table range_t2 (x bigint, s string, s2 string, primary key (x, s))
  partition by range (x)
    (
      partition 0 <= values <= 49, partition 50 <= values <= 100
    )
  stored as kudu;
-- A range can also specify a single specific value, using the keyword VALUE
-- with an = comparison.
create table range_t3 (x bigint, s string, s2 string, primary key (x, s))
  partition by range (s)
    (
      partition value = 'Yes', partition value = 'No', partition value = 'Maybe'
    )
  stored as kudu;
-- Using multiple columns in the RANGE clause and tuples inside the partition spec
-- only works for partitions specified with the VALUE= syntax.
create table range_t4 (x bigint, s string, s2 string, primary key (x, s))
  partition by range (x,s)
    (
      partition value = (0,'zero'), partition value = (1,'one'), partition value = 
(2,'two')
    )
  stored as kudu;
Herearesomeexamplescombining bothHASHandRANGEsyntaxforthePARTITION BY clause:
-- Values from each range partition are hashed into 10 associated buckets.
-- Total number of partitions in this case is 10 x 2.
create table combined_t1 (x bigint, s string, s2 string, primary key (x, s))
  partition by hash (x) partitions 10, range (x)
    (
      partition 0 <= values <= 49, partition 50 <= values <= 100
    )
  stored as kudu;
-- The hash partitioning and range partitioning can apply to different columns.
-- But all the columns used in either partitioning scheme must be from the primary key.
create table combined_t2 (x bigint, s string, s2 string, primary key (x, s))
  partition by hash (s) partitions 10, range (x)
    (
      partition 0 <= values <= 49, partition 50 <= values <= 100
    )
  stored as kudu;
FormoreusagedetailsandexamplesoftheKudupartitioning syntax,seeUsingImpalatoQueryKuduTablesonpage
670.
Specifyingfileformat(STOREDASandROWFORMATclauses):
TheSTORED AS clauseidentifiestheformatoftheunderlying datafiles.Currently,Impalacanquerymoretypesof
fileformatsthanitcancreateorinsertinto.UseHivetoperformanycreateordataloadoperationsthatarenot
currentlyavailableinImpala.Forexample,ImpalacancreateanAvro,SequenceFile, orRCFiletablebutcannotinsert
dataintoit.TherearealsoImpala-specific proceduresforusingcompressionwitheachkindoffileformat.Fordetails
aboutworkingwithdatafilesofvariousformats,seeHowImpalaWorkswithHadoopFileFormatsonpage634.
ApacheImpalaGuide|241ImpalaSQLLanguageReference
Note:InImpala1.4.0andhigher,ImpalacancreateAvrotables,whichformerlyrequireddoingthe
CREATE TABLE statementinHive.SeeUsingtheAvroFileFormatwithImpalaTablesonpage659for
detailsandexamples.
Bydefault(whennoSTORED AS clauseisspecified), datafilesinImpalatablesarecreatedastextfileswithCtrl-A(hex
01)charactersasthedelimiter.SpecifytheROW FORMAT DELIMITED clausetoproduceoringestdatafilesthatuse
adifferentdelimitercharactersuchastabor|,oradifferentlineendcharactersuchascarriagereturnornewline.
WhenspecifyingdelimiterandlineendcharacterswiththeFIELDS TERMINATED BY andLINES TERMINATED BY
clauses,use'\t'fortab,'\n'fornewlineorlinefeed,'\r'forcarriagereturn,and\0forASCIInul(hex00).For
moreexamplesoftexttables,seeUsingTextDataFileswithImpalaTablesonpage636.
TheESCAPED BY clauseappliesbothtotextfilesthatyoucreatethroughanINSERTstatementtoanImpalaTEXTFILE
table,andtoexistingdatafilesthatyouputintoanImpalatabledirectory.(Youcaningestexistingdatafileseitherby
creatingthetablewithCREATE EXTERNAL TABLE ... LOCATION ,theLOAD DATA statement,orthroughanHDFS
operationsuchashdfs dfs -put filehdfs_path .)Chooseanescapecharacterthatisnotusedanywhereelse
inthefile,andputitinfrontofeachinstanceofthedelimitercharacterthatoccurswithinafieldvalue.Surrounding
fieldvalueswithquotationmarksdoesnothelpImpalatoparsefieldswithembedded delimitercharacters;the
quotationmarksareconsideredtobepartofthecolumnvalue.Ifyouwanttouse\astheescapecharacter,specify
theclauseinimpala-shell asESCAPED BY '\\' .
Note:TheCREATE TABLE clausesFIELDS TERMINATED BY ,ESCAPED BY ,andLINES TERMINATED
BYhavespecialrulesforthestringliteralusedfortheirargument,becausetheyallrequireasingle
character.Youcanusearegularcharactersurroundedbysingleordoublequotationmarks,anoctal
sequence suchas'\054'(representingacomma),oranintegerintherange'-127'..'128' (with
quotationmarksbutnobackslash),whichisinterpretedasasingle-byteASCIIcharacter.Negative
valuesaresubtractedfrom256;forexample,FIELDS TERMINATED BY '-2' setsthefielddelimiter
toASCIIcode254,theâIcelandic Thornâcharacterusedasadelimiterbysomedataformats.
Cloningtables(LIKEclause):
Tocreateanemptytablewiththesamecolumns,comments,andotherattributesasanothertable,usethefollowing
variation.TheCREATE TABLE ... LIKE formallowsarestrictedsetofclauses,currentlyonlytheLOCATION ,
COMMENT ,andSTORED AS clauses.
CREATE [EXTERNAL] TABLE [IF NOT EXISTS] [ db_name.]table_name
LIKE { [ db_name.]table_name  | PARQUET ' hdfs_path_of_parquet_file ' }
  [COMMENT ' table_comment ']
  [STORED AS file_format ]
  [LOCATION ' hdfs_path ']
Note:
Toclonethestructureofatableandtransferdataintoitinasingleoperation,usetheCREATE TABLE
AS SELECT syntaxdescribed inthenextsubsection.
WhenyouclonethestructureofanexistingtableusingtheCREATE TABLE ... LIKE syntax,thenewtablekeeps
thesamefileformatastheoriginalone,soyouonlyneedtospecifytheSTORED AS clauseifyouwanttouseadifferent
fileformat,orwhenspecifyingaviewastheoriginaltable.(Creatingatableâlikeâaviewproducesatexttableby
default.)
Although normally ImpalacannotcreateanHBasetabledirectly,ImpalacanclonethestructureofanexistingHBase
tablewiththeCREATE TABLE ... LIKE syntax,preservingthefileformatandmetadatafromtheoriginaltable.
TherearesomeexceptionstotheabilitytouseCREATE TABLE ... LIKE withanAvrotable.Forexample,you
cannotusethistechnique foranAvrotablethatisspecified withanAvroschemabutnocolumns.Whenindoubt,
checkifaCREATE TABLE ... LIKE operationworksinHive;ifnot,ittypicallywillnotworkinImpalaeither.
242|ApacheImpalaGuideImpalaSQLLanguageReference
Iftheoriginaltableispartitioned, thenewtableinheritsthesamepartition keycolumns.Becausethenewtableis
initiallyempty,itdoesnotinherittheactualpartitions thatexistintheoriginalone.Tocreatepartitions inthenew
table,insertdataorissueALTER TABLE ... ADD PARTITION statements.
PriortoImpala1.4.0,itwasnotpossibletousetheCREATE TABLE LIKE view_name syntax.InImpala1.4.0and
higher,youcancreateatablewiththesamecolumndefinitionsasaviewusingtheCREATE TABLE LIKE technique.
AlthoughCREATE TABLE LIKE normally inheritsthefileformatoftheoriginaltable,aviewhasnounderlying file
format,soCREATE TABLE LIKE view_name producesatexttablebydefault.Tospecifyadifferentfileformat,
includeaSTORED AS file_format clauseattheendoftheCREATE TABLE LIKE statement.
BecauseCREATE TABLE ... LIKE onlymanipula testablemetadata,notthephysicaldataofthetable,issueINSERT
INTO TABLE statementsafterwardtocopyanydatafromtheoriginaltableintothenewone,optionallyconverting
thedatatoanewfileformat.(Forsomefileformats,ImpalacandoaCREATE TABLE ... LIKE tocreatethetable,
butImpalacannotinsertdatainthatfileformat;inthesecases,youmustloadthedatainHive.SeeHowImpalaWorks
withHadoopFileFormatsonpage634fordetails.)
CREATETABLEASSELECT:
TheCREATE TABLE AS SELECT syntaxisashorthand notationtocreateatablebasedoncolumndefinitionsfrom
anothertable,andcopydatafromthesourcetabletothedestinationtablewithoutissuinganyseparateINSERT
statement.Thisidiomissopopularthatithasitsownacronym,âCTASâ.
ThefollowingexamplesshowhowtocopydatafromasourcetableT1toavarietyofdestinationstables,applying
varioustransformationstothetableproperties, tablelayout,orthedataitselfaspartoftheoperation:
-- Sample table to be the source of CTAS operations.
CREATE TABLE t1 (x INT, y STRING);
INSERT INTO t1 VALUES (1, 'one'), (2, 'two'), (3, 'three');
-- Clone all the columns and data from one table to another.
CREATE TABLE clone_of_t1 AS SELECT * FROM t1;
+-------------------+
| summary           |
+-------------------+
| Inserted 3 row(s) |
+-------------------+
-- Clone the columns and data, and convert the data to a different file format.
CREATE TABLE parquet_version_of_t1 STORED AS PARQUET AS SELECT * FROM t1;
+-------------------+
| summary           |
+-------------------+
| Inserted 3 row(s) |
+-------------------+
-- Copy only some rows to the new table.
CREATE TABLE subset_of_t1 AS SELECT * FROM t1 WHERE x >= 2;
+-------------------+
| summary           |
+-------------------+
| Inserted 2 row(s) |
+-------------------+
-- Same idea as CREATE TABLE LIKE: clone table layout but do not copy any data.
CREATE TABLE empty_clone_of_t1 AS SELECT * FROM t1 WHERE 1=0;
+-------------------+
| summary           |
+-------------------+
| Inserted 0 row(s) |
+-------------------+
-- Reorder and rename columns and transform the data.
CREATE TABLE t5 AS SELECT upper(y) AS s, x+1 AS a, 'Entirely new column' AS n FROM t1;
+-------------------+
| summary           |
+-------------------+
| Inserted 3 row(s) |
+-------------------+
ApacheImpalaGuide|243ImpalaSQLLanguageReference
SELECT * FROM t5;
+-------+---+---------------------+
| s     | a | n                   |
+-------+---+---------------------+
| ONE   | 2 | Entirely new column |
| TWO   | 3 | Entirely new column |
| THREE | 4 | Entirely new column |
+-------+---+---------------------+
SeeSELECTStatementonpage295fordetailsaboutquerysyntaxfortheSELECTportionofaCREATE TABLE AS
SELECTstatement.
Thenewlycreatedtableinheritsthecolumnnamesthatyouselectfromtheoriginaltable,whichyoucanoverrideby
specifyingcolumnaliasesinthequery.Anycolumnortablecommentsfromtheoriginaltablearenotcarriedoverto
thenewtable.
Note:WhenusingtheSTORED AS clausewithaCREATE TABLE AS SELECT statement,the
destinationtablemustbeafileformatthatImpalacanwriteto:currently,textorParquet.Youcannot
specifyanAvro,SequenceFile, orRCFiletableasthedestinationtableforaCTASoperation.
PriortoCDH5.7/Impala2.5youcoulduseapartitioned tableasthesourceandcopydatafromit,butcouldnotspecify
anypartitioning clausesforthenewtable.InCDH5.7/Impala2.5andhigher,youcannowusethePARTITIONED BY
clausewithaCREATE TABLE AS SELECT statement.Thefollowingexampledemonstrateshowyoucancopydata
fromanunpartitioned tableinaCREATE TABLE AS SELECT operation,creatinganewpartitioned tableintheprocess.
ThemainsyntaxconsiderationisthecolumnorderinthePARTITIONED BY clauseandtheselectlist:thepartition
keycolumnsmustbelistedlastintheselectlist,inthesameorderasinthePARTITIONED BY clause.Therefore,in
thiscase,thecolumnorderinthedestinationtableisdifferentfromthesourcetable.Youalsoonlyspecifythecolumn
namesinthePARTITIONED BY clause,notthedatatypesorcolumncomments.
create table partitions_no (year smallint, month tinyint, s string);
insert into partitions_no values (2016, 1, 'January 2016'),
  (2016, 2, 'February 2016'), (2016, 3, 'March 2016');
-- Prove that the source table is not partitioned.
show partitions partitions_no;
ERROR: AnalysisException: Table is not partitioned: ctas_partition_by.partitions_no
-- Create new table with partitions based on column values from source table.
create table partitions_yes partitioned by (year, month)
  as select s, year, month from partitions_no;
+-------------------+
| summary           |
+-------------------+
| Inserted 3 row(s) |
+-------------------+
-- Prove that the destination table is partitioned.
show partitions partitions_yes;
+-------+-------+-------+--------+------+...
| year  | month | #Rows | #Files | Size |...
+-------+-------+-------+--------+------+...
| 2016  | 1     | -1    | 1      | 13B  |...
| 2016  | 2     | -1    | 1      | 14B  |...
| 2016  | 3     | -1    | 1      | 11B  |...
| Total |       | -1    | 3      | 38B  |...
+-------+-------+-------+--------+------+...
Themostconvenientlayoutforpartitioned tablesiswithallthepartitionkeycolumnsattheend.TheCTASPARTITIONED
BYsyntaxrequiresthatcolumnorderintheselectlist,resultinginthatsamecolumnorderinthedestinationtable.
describe partitions_no;
+-------+----------+---------+
| name  | type     | comment |
244|ApacheImpalaGuideImpalaSQLLanguageReference
+-------+----------+---------+
| year  | smallint |         |
| month | tinyint  |         |
| s     | string   |         |
+-------+----------+---------+
-- The CTAS operation forced us to put the partition key columns last.
-- Having those columns last works better with idioms such as SELECT *
-- for partitioned tables.
describe partitions_yes;
+-------+----------+---------+
| name  | type     | comment |
+-------+----------+---------+
| s     | string   |         |
| year  | smallint |         |
| month | tinyint  |         |
+-------+----------+---------+
Attemptingtouseaselectlistwiththepartition keycolumnsnotattheendresultsinanerrorduetoacolumnname
mismatch:
-- We expect this CTAS to fail because non-key column S
-- comes after key columns YEAR and MONTH in the select list.
create table partitions_maybe partitioned by (year, month)
  as select year, month, s from partitions_no;
ERROR: AnalysisException: Partition column name mismatch: year != month
AspartofaCTASoperation,youcanconvertthedatatoanyfileformatthatImpalacanwrite(currently,TEXTFILE
andPARQUET ).Youcannotspecifythelower-levelpropertiesofatexttable,suchasthedelimiter.
Sortingconsiderations:Although youcanspecifyanORDER BY clauseinanINSERT ... SELECT statement,any
ORDER BY clauseisignoredandtheresultsarenotnecessarily sorted.AnINSERT ... SELECT operationpotentially
createsmanydifferentdatafiles,preparedbydifferentexecutorImpaladaemons, andthereforethenotionofthe
databeingstoredinsortedorderisimpractical.
CREATETABLELIKEPARQUET:
ThevariationCREATE TABLE ... LIKE PARQUET ' hdfs_path_of_parquet_file 'letsyouskipthecolumn
definitionsoftheCREATE TABLE statement.Thecolumnnamesanddatatypesareautomaticallyconfiguredbased
ontheorganizationofthespecified Parquetdatafile,whichmustalreadyresideinHDFS.Youcanuseadatafilelocated
outsidetheImpaladatabasedirectories,orafilefromanexistingImpalaParquettable;eitherway,Impalaonlyuses
thecolumndefinitionsfromthefileanddoesnotusetheHDFSlocationfortheLOCATION attributeofthenewtable.
(Although youcanalsospecifytheenclosing directorywiththeLOCATION attribute,tobothusethesameschemaas
thedatafileandpointtheImpalatableattheassociateddirectoryforquerying.)
ThefollowingconsiderationsapplywhenyouusetheCREATE TABLE LIKE PARQUET technique:
â¢Anycolumncommentsfromtheoriginaltablearenotpreservedinthenewtable.Eachcolumninthenewtable
hasacommentstatingthelow-levelParquetfieldtypeusedtodeducetheappropriateSQLcolumntype.
â¢Ifyouuseadatafilefromapartitioned Impalatable,anypartition keycolumnsfromtheoriginaltableareleft
outofthenewtable,becausetheyarerepresentedinHDFSdirectorynamesratherthanstoredinthedatafile.
Topreservethepartition information,repeatthesamePARTITION clauseasintheoriginalCREATE TABLE
statement.
â¢Thefileformatofthenewtabledefaultstotext,aswithotherkindsofCREATE TABLE statements.Tomakethe
newtablealsouseParquetformat,includetheclauseSTORED AS PARQUET intheCREATE TABLE LIKE
PARQUET statement.
â¢IftheParquetdatafilecomesfromanexistingImpalatable,currently,anyTINYINT orSMALLINT columnsare
turnedintoINTcolumnsinthenewtable.Internally,Parquetstoressuchvaluesas32-bitintegers.
â¢WhenthedestinationtableusestheParquetfileformat,theCREATE TABLE AS SELECT andINSERT ...
SELECTstatementsalwayscreateatleastonedatafile,eveniftheSELECTpartofthestatementdoesnotmatch
anyrows.YoucanusesuchanemptyParquetdatafileasatemplateforsubsequentCREATE TABLE LIKE
PARQUET statements.
ApacheImpalaGuide|245ImpalaSQLLanguageReference
FormoredetailsaboutcreatingParquettables,andexamplesoftheCREATE TABLE LIKE PARQUET syntax,see
UsingtheParquetFileFormatwithImpalaTablesonpage643.
Visibility andMetadata(TBLPROPERTIESandWITHSERDEPROPERTIESclauses):
YoucanassociatearbitraryitemsofmetadatawithatablebyspecifyingtheTBLPROPERTIES clause.Thisclausetakes
acomma-separ atedlistofkey-valuepairsandstoresthoseitemsinthemetastoredatabase.Youcanalsochangethe
tablepropertieslaterwithanALTER TABLE statement.Youcanobservethetablepropertiesfordifferentdelimiter
andescapecharactersusingtheDESCRIBE FORMATTED command, andchangethosesettingsforanexistingtable
withALTER TABLE ... SET TBLPROPERTIES .
YoucanalsoassociateSerDespropertieswiththetablebyspecifyingkey-valuepairsthroughtheWITH
SERDEPROPERTIES clause.ThismetadataisnotusedbyImpala,whichhasitsownbuilt-inserializeranddeserializ er
forthefileformatsitsupports. ParticularpropertyvaluesmightbeneededforHivecompatibilitywithcertainvariations
offileformats,particularly Avro.
SomeDDLoperationsthatinteractwithotherHadoopcomponen tsrequirespecifyingparticular valuesinthe
SERDEPROPERTIES orTBLPROPERTIES fields,suchascreatinganAvrotableoranHBasetable.(Youtypicallycreate
HBasetablesinHive,becausetheyrequireadditional clausesnotcurrentlyavailableinImpala.)
Toseethecolumndefinitionsandcolumncommentsforanexistingtable,forexamplebeforeissuingaCREATE TABLE
... LIKE oraCREATE TABLE ... AS SELECT statement,issuethestatementDESCRIBE table_name .Tosee
evenmoredetail,suchasthelocationofdatafilesandthevaluesforclausessuchasROW FORMAT andSTORED AS ,
issuethestatementDESCRIBE FORMATTED table_name .DESCRIBE FORMATTED isalsoneededtoseeanyoverall
tablecomment(asopposedtoindividual columncomments).
Aftercreatingatable,yourimpala-shell sessionoranotherimpala-shell connectedtothesamenodecan
immediatelyquerythattable.Theremightbeabriefinterval(onestatestoreheartbeat)beforethetablecanbequeried
throughadifferentImpalanode.TomaketheCREATE TABLE statementreturnonlywhenthetableisrecognizedby
allImpalanodesinthecluster,enabletheSYNC_DDL queryoption.
HDFScaching(CACHEDINclause):
IfyouspecifytheCACHED IN clause,anyexistingorfuturedatafilesinthetabledirectoryorthepartitionsubdirectories
aredesignatedtobeloadedintomemorywiththeHDFScachingmechanism. SeeUsingHDFSCachingwithImpala
(CDH5.3orhigheronly)onpage593fordetailsaboutusingtheHDFScachingfeature.
InCDH5.4/Impala2.2andhigher,theoptionalWITH REPLICATION clauseforCREATE TABLE andALTER TABLE
letsyouspecifyareplicationfactor,thenumberofhostsonwhichtocachethesamedatablocks.WhenImpala
processesacacheddatablock,wherethecachereplicationfactorisgreaterthan1,Impalarandomly selectsahost
thathasacachedcopyofthatdatablock.ThisoptimizationavoidsexcessiveCPUusageonasinglehostwhenthe
samecacheddatablockisprocessedmultipletimes.Clouderarecommends specifyingavaluegreaterthanorequal
totheHDFSblockreplicationfactor.
Columnorder:
Ifyouintendtousethetabletoholddatafilesproducedbysomeexternalsource,specifythecolumnsinthesame
orderastheyappearinthedatafiles.
IfyouintendtoinsertorcopydataintothetablethroughImpala,orifyouhavecontroloverthewayexternallyproduced
datafilesarearranged,useyourjudgmenttospecifycolumnsinthemostconvenientorder:
â¢IfcertaincolumnsareoftenNULL,specifythosecolumnslast.Youmightproducedatafilesthatomitthesetrailing
columnsentirely.ImpalaautomaticallyfillsintheNULLvaluesifso.
â¢Ifanunpartitioned tablewillbeusedasthesourceforanINSERT ... SELECT operationintoapartitioned
table,specifylastintheunpartitioned tableanycolumnsthatcorrespondtopartitionkeycolumnsinthepartitioned
table,andinthesameorderasthepartition keycolumnsaredeclaredinthepartitioned table.Thistechnique
letsyouuseINSERT ... SELECT * whencopyingdatatothepartitioned table,ratherthanspecifyingeach
columnnameindividually .
â¢Ifyouspecifycolumnsinanorderthatyoulaterdiscoverissuboptimal,youcansometimesworkaroundthe
problemwithoutrecreatingthetable.Youcancreateaviewthatselectscolumnsfromtheoriginaltableina
246|ApacheImpalaGuideImpalaSQLLanguageReference
permutedorder,thendoaSELECT * fromtheview.Wheninsertingdataintoatable,youcanspecifyapermuted
orderfortheinsertedcolumnstomatchtheorderinthedestinationtable.
Hiveconsiderations:
Impalaqueriescanmakeuseofmetadataaboutthetableandcolumns,suchasthenumberofrowsinatableorthe
numberofdifferentvaluesinacolumn.PriortoImpala1.2.2,tocreatethismetadata,youissuedtheANALYZE TABLE
statementinHivetogatherthisinformation,aftercreatingthetableandloadingrepresentativedataintoit.InImpala
1.2.2andhigher,theCOMPUTE STATS statementproducesthesestatisticswithinImpala,withoutneedingtouseHive
atall.
HBaseconsiderations:
Note:
TheImpalaCREATE TABLE statementcannotcreateanHBasetable,becauseitcurrentlydoesnot
supporttheSTORED BY clauseneededforHBasetables.CreatesuchtablesinHive,thenquerythem
throughImpala.ForinformationonusingImpalawithHBasetables,seeUsingImpalatoQueryHBase
Tablesonpage684.
AmazonS3considerations:
TocreateatablewherethedataresidesintheAmazonSimpleStorageService(S3),specifyas3a://prefixLOCATION
attributepointingtothedatafilesinS3.
InCDH5.8/Impala2.6andhigher,youcanusethisspecialLOCATION syntaxaspartofaCREATE TABLE AS SELECT
statement.
InCDH5.8/Impala2.6andhigher,ImpalaDDLstatementssuchasCREATE DATABASE ,CREATE TABLE ,DROP
DATABASE CASCADE ,DROP TABLE ,andALTER TABLE [ADD|DROP] PARTITION cancreateorremovefoldersas
neededintheAmazonS3system.PriortoCDH5.8/Impala2.6,youhadtocreatefoldersyourselfandpointImpala
database,tables,orpartitions atthem,andmanually removefolderswhennolongerneeded.SeeUsingImpalawith
theAmazonS3Filesystemonpage692fordetailsaboutreadingandwritingS3datawithImpala.
Sortingconsiderations:Although youcanspecifyanORDER BY clauseinanINSERT ... SELECT statement,any
ORDER BY clauseisignoredandtheresultsarenotnecessarily sorted.AnINSERT ... SELECT operationpotentially
createsmanydifferentdatafiles,preparedbydifferentexecutorImpaladaemons, andthereforethenotionofthe
databeingstoredinsortedorderisimpractical.
HDFSconsiderations:
TheCREATE TABLE statementforaninternaltablecreatesadirectoryinHDFS.TheCREATE EXTERNAL TABLE
statementassociatesthetablewithanexistingHDFSdirectory,anddoesnotcreateanynewdirectoryinHDFS.To
locatetheHDFSdatadirectoryforatable,issueaDESCRIBE FORMATTED tablestatement.Toexaminethecontents
ofthatHDFSdirectory,useanOScommand suchashdfs dfs -ls hdfs:// path,eitherfromtheOScommand
lineorthroughtheshellor!commands inimpala-shell .
TheCREATE TABLE AS SELECT syntaxcreatesdatafilesunderthetabledatadirectorytoholdanydatacopiedby
theINSERTportionofthestatement.(Evenifnodataiscopied,Impalamightcreateoneormoreemptydatafiles.)
HDFSpermissions:
TheuserIDthattheimpalad daemonrunsunder,typicallytheimpalauser,musthavebothexecuteandwrite
permission forthedatabasedirectorywherethetableisbeingcreated.
Securityconsiderations:
Ifthesestatementsinyourenvironmentcontainsensitiveliteralvaluessuchascreditcardnumbersortaxidentifiers,
Impalacanredactthissensitiveinformationwhendisplayingthestatementsinlogfilesandotheradministrative
contexts.Seehttp://www.cloudera.com/content/cloudera/en/documen tation/core/latest/topics/sg_redaction.h tml
fordetails.
ApacheImpalaGuide|247ImpalaSQLLanguageReference
Cancellation:Certainmulti-stagestatements(CREATE TABLE AS SELECT andCOMPUTE STATS )canbecancelled
duringsomestages,whenrunningINSERTorSELECToperationsinternally.Tocancelthisstatement,useCtrl-Cfrom
theimpala-shell interpreter,theCancelbuttonfromtheWatchpageinHue,Actions>CancelfromtheQueries
listinClouderaManager,orCancelfromthelistofin-flightqueries(foraparticular node)ontheQueriestabinthe
ImpalawebUI(port25000).
Relatedinformation:
OverviewofImpalaTablesonpage196,ALTERTABLEStatementonpage205,DROPTABLEStatementonpage268,
Partitioning forImpalaTablesonpage625,InternalTablesonpage197,ExternalTablesonpage197,COMPUTE STATS
Statementonpage219,SYNC_DDL QueryOptiononpage361,SHOWTABLESStatementonpage369,SHOWCREATE
TABLEStatementonpage370,DESCRIBEStatementonpage251
CREATEVIEWStatement
TheCREATE VIEW statementletsyoucreateashorthand abbreviationforamorecomplicatedquery.Thebasequery
caninvolvejoins,expressions,reorderedcolumns,columnaliases,andotherSQLfeaturesthatcanmakeaqueryhard
tounderstandormaintain.
Becauseaviewispurelyalogicalconstruct(analiasforaquery)withnophysicaldatabehindit,ALTER VIEW only
involveschangestometadatainthemetastoredatabase,notanydatafilesinHDFS.
Syntax:
CREATE VIEW [IF NOT EXISTS] view_name
    [(column_name  [COMMENT ' column_comment '][, ...])]
    [COMMENT ' view_comment ']
  AS select_statement
Statementtype:DDL
Usagenotes:
TheCREATE VIEW statementcanbeusefulinscenarios suchasthefollowing:
â¢ToturneventhemostlengthyandcomplicatedSQLqueryintoaone-liner.Youcanissuesimplequeriesagainst
theviewfromapplications,scripts,orinteractivequeriesinimpala-shell .Forexample:
select * from view_name ;
select * from view_name  order by c1 desc limit 10;
Themorecomplicatedandhard-to-readtheoriginalquery,themorebenefitthereistosimplifyingthequery
usingaview.
â¢Tohidetheunderlying tableandcolumnnames,tominimizemaintenanceproblemsifthosenameschange.In
thatcase,youre-createtheviewusingthenewnames,andallqueriesthatusetheviewratherthantheunderlying
tableskeeprunningwithnochanges.
â¢Toexperimen twithoptimizationtechniques andmaketheoptimizedqueriesavailabletoallapplications.For
example,ifyoufindacombinationofWHEREconditions, joinorder,joinhints,andsoonthatworksthebestfor
aclassofqueries,youcanestablishaviewthatincorporatesthebest-performingtechniques. Applicationscan
thenmakerelativelysimplequeriesagainsttheview,withoutrepeatingthecomplicatedandoptimizedlogicover
andover.Ifyoulaterfindabetterwaytooptimizetheoriginalquery,whenyoure-createtheview,allthe
applicationsimmediatelytakeadvantageoftheoptimizedbasequery.
â¢Tosimplifyawholeclassofrelatedqueries,especially complicatedqueriesinvolvingjoinsbetweenmultipletables,
complicatedexpressionsinthecolumnlist,andotherSQLsyntaxthatmakesthequerydifficulttounderstand
anddebug.Forexample,youmightcreateaviewthatjoinsseveraltables,filtersusingseveralWHEREconditions,
andselectsseveralcolumnsfromtheresultset.Applicationsmightissuequeriesagainstthisviewthatonlyvary
intheirLIMIT,ORDER BY ,andsimilarsimpleclauses.
Forqueriesthatrequirerepeatingcomplicatedclausesoverandoveragain,forexampleintheselectlist,ORDER BY ,
andGROUP BY clauses,youcanusetheWITHclauseasanalternativetocreatingaview.
Youcanoptionallyspecifythetable-levelandthecolumn-levelcommentsasintheCREATE TABLE statement.
248|ApacheImpalaGuideImpalaSQLLanguageReference
Complextypeconsiderations:
Fortablescontainingcomplextypecolumns(ARRAY,STRUCT,orMAP),youtypicallyusejoinqueriestorefertothe
complexvalues.Youcanuseviewstohidethejoinnotation,makingsuchtablesseemliketraditional denormaliz ed
tables,andmakingthosetablesqueryablebybusinessintelligencetoolsthatdonothavebuilt-insupportforthose
complextypes.SeeAccessing ComplexTypeDatainFlattenedFormUsingViewsonpage159fordetails.
BecauseyoucannotdirectlyissueSELECT col_name againstacolumnofcomplextype,youcannotuseaviewora
WITHclausetoârenameâacolumnbyselecting itwithacolumnalias.
IfyouconnecttodifferentImpalanodeswithinanimpala-shell sessionforload-balancing purposes, youcanenable
theSYNC_DDL queryoptiontomakeeachDDLstatementwaitbeforereturning,untiltheneworchangedmetadata
hasbeenreceivedbyalltheImpalanodes.SeeSYNC_DDL QueryOptiononpage361fordetails.
Securityconsiderations:
Ifthesestatementsinyourenvironmentcontainsensitiveliteralvaluessuchascreditcardnumbersortaxidentifiers,
Impalacanredactthissensitiveinformationwhendisplayingthestatementsinlogfilesandotheradministrative
contexts.Seehttp://www.cloudera.com/content/cloudera/en/documen tation/core/latest/topics/sg_redaction.h tml
fordetails.
Cancellation:Cannotbecancelled.
HDFSpermissions: ThisstatementdoesnottouchanyHDFSfilesordirectories,thereforenoHDFSpermissions are
required.
Examples:
-- Create a view that is exactly the same as the underlying table.
CREATE VIEW v1 AS SELECT * FROM t1;
-- Create a view that includes only certain columns from the underlying table.
CREATE VIEW v2 AS SELECT c1, c3, c7 FROM t1;
-- Create a view that filters the values from the underlying table.
CREATE VIEW v3 AS SELECT DISTINCT c1, c3, c7 FROM t1 WHERE c1 IS NOT NULL AND c5 > 0;
-- Create a view that that reorders and renames columns from the underlying table.
CREATE VIEW v4 AS SELECT c4 AS last_name, c6 AS address, c2 AS birth_date FROM t1;
-- Create a view that runs functions to convert or transform certain columns.
CREATE VIEW v5 AS SELECT c1, CAST(c3 AS STRING) c3, CONCAT(c4,c5) c5, TRIM(c6) c6, 
"Constant" c8 FROM t1;
-- Create a view that hides the complexity of a view query.
CREATE VIEW v6 AS SELECT t1.c1, t2.c2 FROM t1 JOIN t2 ON t1.id = t2.id;
-- Create a view with a column comment and a table comment.
CREATE VIEW v7 (c1 COMMENT 'Comment for c1', c2) COMMENT 'Comment for v7' AS SELECT 
t1.c1, t1.c2 FROM t1;
Relatedinformation:
OverviewofImpalaViewsonpage199,ALTERVIEWStatementonpage218,DROPVIEWStatementonpage270
DELETEStatement(CDH5.10orhigheronly)
DeletesanarbitrarynumberofrowsfromaKudutable.ThisstatementonlyworksforImpalatablesthatusetheKudu
storageengine.
Syntax:
DELETE [FROM] [ database_name .]table_name  [ WHERE where_conditions  ]
DELETE table_ref  FROM [joined_table_refs ] [ WHERE where_conditions  ]
ApacheImpalaGuide|249ImpalaSQLLanguageReference
ThefirstformevaluatesrowsfromonetableagainstanoptionalWHEREclause,anddeletesalltherowsthatmatch
theWHEREconditions, orallrowsifWHEREisomitted.
Thesecondformevaluatesoneormorejoinclauses,anddeletesallmatchingrowsfromoneofthetables.Thejoin
clausescanincludenon-Kudutables,butthetablefromwhichtherowsaredeletedmustbeaKudutable.TheFROM
keywordisrequiredinthiscase,toseparatethenameofthetablewhoserowsarebeingdeletedfromthetablenames
ofthejoinclauses.
Usagenotes:
Theconditions intheWHEREclausearethesameonesallowedfortheSELECTstatement.SeeSELECTStatementon
page295fordetails.
Theconditions intheWHEREclausecanrefertoanycombinationofprimarykeycolumnsorothercolumns.Referring
toprimarykeycolumnsintheWHEREclauseismoreefficientthanreferringtonon-primar ykeycolumns.
IftheWHEREclauseisomitted,allrowsareremovedfromthetable.
BecauseKuducurrentlydoesnotenforcestrongconsistencyduringconcurrentDMLoperations,beawarethatthe
resultsafterthisstatementfinishesmightbedifferentthanyouintuitivelyexpect:
â¢Ifsomerowscannotbedeletedbecausetheirsomeprimarykeycolumnsarenotfound,duetotheirbeingdeleted
byaconcurrentDELETEoperation,thestatementsucceeds butreturnsawarning.
â¢ADELETEstatementmightalsooverlapwithINSERT,UPDATE,orUPSERTstatementsrunningconcurrentlyon
thesametable.Afterthestatementfinishes,theremightbemoreorfewerrowsthanexpectedinthetable
becauseitisundefinedwhethertheDELETEappliestorowsthatareinsertedorupdatedwhiletheDELETEisin
progress.
Thenumberofaffectedrowsisreportedinanimpala-shell messageandinthequeryprofile.
Statementtype:DML
Important:Afteraddingorreplacingdatainatableusedinperformance-critic alqueries,issuea
COMPUTE STATS statementtomakesureallstatisticsareup-to-date.Consider updatingstatisticsfor
atableafteranyINSERT,LOAD DATA ,orCREATE TABLE AS SELECT statementinImpala,orafter
loadingdatathroughHiveanddoingaREFRESH table_name inImpala.Thistechnique isespecially
importantfortablesthatareverylarge,usedinjoinqueries,orboth.
Examples:
Thefollowingexamplesshowhowtodeleterowsfromaspecified table,eitherallrowsorrowsthatmatchaWHERE
clause:
-- Deletes all rows. The FROM keyword is optional.
DELETE FROM kudu_table;
DELETE kudu_table;
-- Deletes 0, 1, or more rows.
-- (If c1 is a single-column primary key, the statement could only
-- delete 0 or 1 rows.)
DELETE FROM kudu_table WHERE c1 = 100;
-- Deletes all rows that match all the WHERE conditions.
DELETE FROM kudu_table WHERE
  (c1 > c2 OR c3 IN ('hello','world')) AND c4 IS NOT NULL;
DELETE FROM t1 WHERE
  (c1 IN (1,2,3) AND c2 > c3) OR c4 IS NOT NULL;
DELETE FROM time_series WHERE
  year = 2016 AND month IN (11,12) AND day > 15;
-- WHERE condition with a subquery.
DELETE FROM t1 WHERE
  c5 IN (SELECT DISTINCT other_col FROM other_table);
250|ApacheImpalaGuideImpalaSQLLanguageReference
-- Does not delete any rows, because the WHERE condition is always false.
DELETE FROM kudu_table WHERE 1 = 0;
Thefollowingexamplesshowhowtodeleterowsthatarepartoftheresultsetfromajoin:
-- Remove _all_ rows from t1 that have a matching X value in t2.
DELETE t1 FROM t1 JOIN t2 ON t1.x = t2.x;
-- Remove _some_ rows from t1 that have a matching X value in t2.
DELETE t1 FROM t1 JOIN t2 ON t1.x = t2.x
  WHERE t1.y = FALSE and t2.z > 100;
-- Delete from a Kudu table based on a join with a non-Kudu table.
DELETE t1 FROM kudu_table t1 JOIN non_kudu_table t2 ON t1.x = t2.x;
-- The tables can be joined in any order as long as the Kudu table
-- is specified as the deletion target.
DELETE t2 FROM non_kudu_table t1 JOIN kudu_table t2 ON t1.x = t2.x;
Relatedinformation:
UsingImpalatoQueryKuduTablesonpage670,INSERTStatementonpage277,UPDATEStatement(CDH5.10orhigher
only)onpage383,UPSERTStatement(CDH5.10orhigheronly)onpage384
DESCRIBEStatement
TheDESCRIBE statementdisplaysmetadataaboutatable,suchasthecolumnnamesandtheirdatatypes.InCDH5.5
/Impala2.3andhigher,youcanspecifythenameofacomplextypecolumn,whichtakestheformofadottedpath.
Thepathmightincludemultiplecomponen tsinthecaseofanestedtypedefinition.InCDH5.7/Impala2.5andhigher,
theDESCRIBE DATABASE formcandisplayinformationaboutadatabase.
Syntax:
DESCRIBE [DATABASE] [FORMATTED|EXTENDED] object_name
object_name ::=
    [db_name.]table_name [.complex_col_name  ...]
  | db_name
YoucanusetheabbreviationDESCfortheDESCRIBE statement.
TheDESCRIBE FORMATTED variationdisplaysadditional information,inaformatfamiliartousersofApacheHive.
Theextrainformationincludeslow-leveldetailssuchaswhetherthetableisinternalorexternal,whenitwascreated,
thefileformat,thelocationofthedatainHDFS,whethertheobjectisatableoraview,and(forviews)thetextofthe
queryfromtheviewdefinition.
Note:TheCompressed fieldisnotareliableindicatorofwhetherthetablecontainscompressed
data.IttypicallyalwaysshowsNo,becausethecompressionsettingsonlyapplyduringthesession
thatloadsdataandarenotstoredpersistentlywiththetablemetadata.
Describing databases:
Bydefault,theDESCRIBE outputforadatabaseincludesthelocationandthecomment,whichcanbesetbythe
LOCATION andCOMMENT clausesontheCREATE DATABASE statement.
Theadditional informationdisplayedbytheFORMATTED orEXTENDED keywordincludestheHDFSuserIDthatis
consideredtheownerofthedatabase,andanyoptionaldatabaseproperties. Thepropertiescouldbespecified bythe
WITH DBPROPERTIES clauseifthedatabaseiscreatedusingaHiveCREATE DATABASE statement.Impalacurrently
doesnotsetordoanyspecialprocessingbasedonthoseproperties.
ApacheImpalaGuide|251ImpalaSQLLanguageReference
Thefollowingexamplesshowthevariationsinsyntaxandoutputfordescribing databases.Thisfeatureisavailablein
CDH5.7/Impala2.5andhigher.
describe database default;
+---------+----------------------+-----------------------+
| name    | location             | comment               |
+---------+----------------------+-----------------------+
| default | /user/hive/warehouse | Default Hive database |
+---------+----------------------+-----------------------+
describe database formatted default;
+---------+----------------------+-----------------------+
| name    | location             | comment               |
+---------+----------------------+-----------------------+
| default | /user/hive/warehouse | Default Hive database |
| Owner:  |                      |                       |
|         | public               | ROLE                  |
+---------+----------------------+-----------------------+
describe database extended default;
+---------+----------------------+-----------------------+
| name    | location             | comment               |
+---------+----------------------+-----------------------+
| default | /user/hive/warehouse | Default Hive database |
| Owner:  |                      |                       |
|         | public               | ROLE                  |
+---------+----------------------+-----------------------+
Describing tables:
IftheDATABASE keywordisomitted,thedefaultfortheDESCRIBE statementistorefertoatable.
IfyouhavetheSELECTprivilegeonasubsetofthetablecolumnsandnootherrelevanttable/database/server-level
privileges,DESCRIBE returnsthedatafromthecolumnsyouhaveaccessto.
IfyouhavetheSELECTprivilegeonasubsetofthetablecolumnsandnootherrelevanttable/database/server-level
privileges,DESCRIBE FORMATTED/EXTENDED doesnotreturntheLOCATION field.TheLOCATION dataisshownif
youhaveanyprivilegeonthetable,thecontainingdatabaseortheserver.
-- By default, the table is assumed to be in the current database.
describe my_table;
+------+--------+---------+
| name | type   | comment |
+------+--------+---------+
| x    | int    |         |
| s    | string |         |
+------+--------+---------+
-- Use a fully qualified table name to specify a table in any database.
describe my_database.my_table;
+------+--------+---------+
| name | type   | comment |
+------+--------+---------+
| x    | int    |         |
| s    | string |         |
+------+--------+---------+
-- The formatted or extended output includes additional useful information.
-- The LOCATION field is especially useful to know for DDL statements and HDFS commands
-- during ETL jobs. (The LOCATION includes a full hdfs:// URL, omitted here for 
readability.)
describe formatted my_table;
+------------------------------+----------------------------------------------+----------------------+
| name                         | type                                         | comment
              |
+------------------------------+----------------------------------------------+----------------------+
| # col_name                   | data_type                                    | comment
              |
|                              | NULL                                         | NULL  
252|ApacheImpalaGuideImpalaSQLLanguageReference
               |
| x                            | int                                          | NULL  
               |
| s                            | string                                       | NULL  
               |
|                              | NULL                                         | NULL  
               |
| # Detailed Table Information | NULL                                         | NULL  
               |
| Database:                    | my_database                                  | NULL  
               |
| Owner:                       | jrussell                                     | NULL  
               |
| CreateTime:                  | Fri Mar 18 15:58:00 PDT 2016                 | NULL  
               |
| LastAccessTime:              | UNKNOWN                                      | NULL  
               |
| Protect Mode:                | None                                         | NULL  
               |
| Retention:                   | 0                                            | NULL  
               |
| Location:                    | /user/hive/warehouse/my_database.db/my_table | NULL  
               |
| Table Type:                  | MANAGED_TABLE                                | NULL  
               |
| Table Parameters:            | NULL                                         | NULL  
               |
|                              | transient_lastDdlTime                        | 1458341880
           |
|                              | NULL                                         | NULL  
               |
| # Storage Information        | NULL                                         | NULL  
               |
| SerDe Library:               | org. ... .LazySimpleSerDe                    | NULL  
               |
| InputFormat:                 | org.apache.hadoop.mapred.TextInputFormat     | NULL  
               |
| OutputFormat:                | org. ... .HiveIgnoreKeyTextOutputFormat      | NULL  
               |
| Compressed:                  | No                                           | NULL  
               |
| Num Buckets:                 | 0                                            | NULL  
               |
| Bucket Columns:              | []                                           | NULL  
               |
| Sort Columns:                | []                                           | NULL  
               |
+------------------------------+----------------------------------------------+----------------------+
Complextypeconsiderations:
Becausethecolumndefinitionsforcomplextypescanbecomelong,particularly whensuchtypesarenested,the
DESCRIBE statementusesspecialformattingforcomplextypecolumnstomaketheoutputreadable.
FortheARRAY,STRUCT,andMAPtypesavailableinCDH5.5/Impala2.3andhigher,theDESCRIBE outputisformatted
toavoidexcessivelylonglinesformultiplefieldswithinaSTRUCT,oranestedsequence ofcomplextypes.
Youcanpassamulti-part qualified nametoDESCRIBE tospecifyanARRAY,STRUCT,orMAPcolumnandvisualizeits
structureasifitwereatable.Forexample,iftableT1containsanARRAYcolumnA1,youcouldissuethestatement
DESCRIBE t1.a1 .IftableT1containedaSTRUCTcolumnS1,andafieldF1withintheSTRUCTwasaMAP,youcould
issuethestatementDESCRIBE t1.s1.f1 .AnARRAYisshownasatwo-columntable,withITEMandPOScolumns.
ASTRUCTisshownasatablewitheachfieldrepresentingacolumninthetable.AMAPisshownasatwo-columntable,
withKEYandVALUEcolumns.
Forexample,hereistheDESCRIBE outputforatablecontainingasingletop-levelcolumnofeachcomplextype:
create table t1 (x int, a array<int>, s struct<f1: string, f2: bigint>, m map<string,int>)
 stored as parquet;
ApacheImpalaGuide|253ImpalaSQLLanguageReference
describe t1;
+------+-----------------+---------+
| name | type            | comment |
+------+-----------------+---------+
| x    | int             |         |
| a    | array<int>      |         |
| s    | struct<         |         |
|      |   f1:string,    |         |
|      |   f2:bigint     |         |
|      | >               |         |
| m    | map<string,int> |         |
+------+-----------------+---------+
Hereareexamplesshowinghowtoâdrilldownâintothelayoutsofcomplextypes,including usingmulti-part names
toexaminethedefinitionsofnestedtypes.The< >delimitersidentifythecolumnswithcomplextypes;thesearethe
columnswhereyoucandescendanotherleveltoseethepartsthatmakeupthecomplextype.Thistechnique helps
youtounderstandthemulti-part namesyouuseastablereferencesinqueriesinvolvingcomplextypes,andthe
corresponding columnnamesyourefertointheSELECTlist.ThesetablesarefromtheânestedTPC-Hâschema,shown
indetailinSampleSchemaandDataforExperimen tingwithImpalaComplexTypesonpage160.
TheREGIONtablecontainsanARRAYofSTRUCTelements:
â¢ThefirstDESCRIBE specifiesthetablename,todisplaythedefinitionofeachtop-levelcolumn.
â¢ThesecondDESCRIBE specifiesthenameofacomplexcolumn,REGION.R_NATIONS ,showingthatwhenyou
includethenameofanARRAYcolumninaFROMclause,thattablereferenceactslikeatwo-columntablewith
columnsITEMandPOS.
â¢ThefinalDESCRIBE specifiesthefullyqualified nameoftheITEMfield,todisplaythelayoutofitsunderlying
STRUCTtypeintableformat,withthefieldsmappedtocolumnnames.
-- #1: The overall layout of the entire table.
describe region;
+-------------+-------------------------+---------+
| name        | type                    | comment |
+-------------+-------------------------+---------+
| r_regionkey | smallint                |         |
| r_name      | string                  |         |
| r_comment   | string                  |         |
| r_nations   | array<struct<           |         |
|             |   n_nationkey:smallint, |         |
|             |   n_name:string,        |         |
|             |   n_comment:string      |         |
|             | >>                      |         |
+-------------+-------------------------+---------+
-- #2: The ARRAY column within the table.
describe region.r_nations;
+------+-------------------------+---------+
| name | type                    | comment |
+------+-------------------------+---------+
| item | struct<                 |         |
|      |   n_nationkey:smallint, |         |
|      |   n_name:string,        |         |
|      |   n_comment:string      |         |
|      | >                       |         |
| pos  | bigint                  |         |
+------+-------------------------+---------+
-- #3: The STRUCT that makes up each ARRAY element.
--     The fields of the STRUCT act like columns of a table.
describe region.r_nations.item;
+-------------+----------+---------+
| name        | type     | comment |
+-------------+----------+---------+
| n_nationkey | smallint |         |
| n_name      | string   |         |
254|ApacheImpalaGuideImpalaSQLLanguageReference
| n_comment   | string   |         |
+-------------+----------+---------+
TheCUSTOMER tablecontainsanARRAYofSTRUCTelements,whereonefieldintheSTRUCTisanotherARRAYof
STRUCTelements:
â¢Again,theinitialDESCRIBE specifiesonlythetablename.
â¢ThesecondDESCRIBE specifiesthequalifiednameofthecomplexcolumn,CUSTOMER.C_ORDERS ,showinghow
anARRAYisrepresentedasatwo-columntablewithcolumnsITEMandPOS.
â¢ThethirdDESCRIBE specifiesthequalified nameoftheITEMoftheARRAYcolumn,toseethestructureofthe
nestedARRAY.Again,ithashastwoparts,ITEMandPOS.BecausetheARRAYcontainsaSTRUCT,thelayoutof
theSTRUCTisshown.
â¢ThefourthandfifthDESCRIBE statementsdrilldownintoaSTRUCTfieldthatisitselfacomplextype,anARRAY
ofSTRUCT.TheITEMportionofthequalified nameisonlyrequiredwhentheARRAYelementsareanonymous.
ThefieldsoftheSTRUCTgivenamestoanyothercomplextypesnestedinsidetheSTRUCT.Therefore,the
DESCRIBE parametersCUSTOMER.C_ORDERS.ITEM.O_LINEITEMS andCUSTOMER.C_ORDERS.O_LINEITEMS
areequivalent.(Forbrevity,leaveouttheITEMportionofaqualified namewhenitisnotrequired.)
â¢ThefinalDESCRIBE showsthelayoutofthedeeplynestedSTRUCTtype.Becausetherearenomorecomplex
typesnestedinsidethisSTRUCT,thisisasfarasyoucandrilldownintothelayoutforthistable.
-- #1: The overall layout of the entire table.
describe customer;
+--------------+------------------------------------+
| name         | type                               |
+--------------+------------------------------------+
| c_custkey    | bigint                             |
... more scalar columns ...
| c_orders     | array<struct<                      |
|              |   o_orderkey:bigint,               |
|              |   o_orderstatus:string,            |
|              |   o_totalprice:decimal(12,2),      |
|              |   o_orderdate:string,              |
|              |   o_orderpriority:string,          |
|              |   o_clerk:string,                  |
|              |   o_shippriority:int,              |
|              |   o_comment:string,                |
|              |   o_lineitems:array<struct<        |
|              |     l_partkey:bigint,              |
|              |     l_suppkey:bigint,              |
|              |     l_linenumber:int,              |
|              |     l_quantity:decimal(12,2),      |
|              |     l_extendedprice:decimal(12,2), |
|              |     l_discount:decimal(12,2),      |
|              |     l_tax:decimal(12,2),           |
|              |     l_returnflag:string,           |
|              |     l_linestatus:string,           |
|              |     l_shipdate:string,             |
|              |     l_commitdate:string,           |
|              |     l_receiptdate:string,          |
|              |     l_shipinstruct:string,         |
|              |     l_shipmode:string,             |
|              |     l_comment:string               |
|              |   >>                               |
|              | >>                                 |
+--------------+------------------------------------+
-- #2: The ARRAY column within the table.
describe customer.c_orders;
+------+------------------------------------+
| name | type                               |
+------+------------------------------------+
| item | struct<                            |
|      |   o_orderkey:bigint,               |
ApacheImpalaGuide|255ImpalaSQLLanguageReference
|      |   o_orderstatus:string,            |
... more struct fields ...
|      |   o_lineitems:array<struct<        |
|      |     l_partkey:bigint,              |
|      |     l_suppkey:bigint,              |
... more nested struct fields ...
|      |     l_comment:string               |
|      |   >>                               |
|      | >                                  |
| pos  | bigint                             |
+------+------------------------------------+
-- #3: The STRUCT that makes up each ARRAY element.
--     The fields of the STRUCT act like columns of a table.
describe customer.c_orders.item;
+-----------------+----------------------------------+
| name            | type                             |
+-----------------+----------------------------------+
| o_orderkey      | bigint                           |
| o_orderstatus   | string                           |
| o_totalprice    | decimal(12,2)                    |
| o_orderdate     | string                           |
| o_orderpriority | string                           |
| o_clerk         | string                           |
| o_shippriority  | int                              |
| o_comment       | string                           |
| o_lineitems     | array<struct<                    |
|                 |   l_partkey:bigint,              |
|                 |   l_suppkey:bigint,              |
... more struct fields ...
|                 |   l_comment:string               |
|                 | >>                               |
+-----------------+----------------------------------+
-- #4: The ARRAY nested inside the STRUCT elements of the first ARRAY.
describe customer.c_orders.item.o_lineitems;
+------+----------------------------------+
| name | type                             |
+------+----------------------------------+
| item | struct<                          |
|      |   l_partkey:bigint,              |
|      |   l_suppkey:bigint,              |
... more struct fields ...
|      |   l_comment:string               |
|      | >                                |
| pos  | bigint                           |
+------+----------------------------------+
-- #5: Shorter form of the previous DESCRIBE. Omits the .ITEM portion of the name
--     because O_LINEITEMS and other field names provide a way to refer to things
--     inside the ARRAY element.
describe customer.c_orders.o_lineitems;
+------+----------------------------------+
| name | type                             |
+------+----------------------------------+
| item | struct<                          |
|      |   l_partkey:bigint,              |
|      |   l_suppkey:bigint,              |
... more struct fields ...
|      |   l_comment:string               |
|      | >                                |
| pos  | bigint                           |
+------+----------------------------------+
-- #6: The STRUCT representing ARRAY elements nested inside
--     another ARRAY of STRUCTs. The lack of any complex types
--     in this output means this is as far as DESCRIBE can
--     descend into the table layout.
describe customer.c_orders.o_lineitems.item;
+-----------------+---------------+
| name            | type          |
+-----------------+---------------+
| l_partkey       | bigint        |
256|ApacheImpalaGuideImpalaSQLLanguageReference
| l_suppkey       | bigint        |
... more scalar columns ...
| l_comment       | string        |
+-----------------+---------------+
Usagenotes:
Aftertheimpalad daemons arerestarted,thefirstqueryagainstatablecantakelongerthansubsequentqueries,
becausethemetadataforthetableisloadedbeforethequeryisprocessed.Thisone-time delayforeachtablecan
causemisleading resultsinbenchmark testsorcauseunnecessar yconcern.ToâwarmupâtheImpalametadatacache,
youcanissueaDESCRIBE statementinadvanceforeachtableyouintendtoaccesslater.
WhenyouaredealingwithdatafilesstoredinHDFS,sometimesitisimportanttoknowdetailssuchasthepathofthe
datafilesforanImpalatable,andthehostnameforthenamenode. YoucangetthisinformationfromtheDESCRIBE
FORMATTED output.YouspecifyHDFSURIsorpathspecificationswithstatementssuchasLOAD DATA andtheLOCATION
clauseofCREATE TABLE orALTER TABLE .YoumightalsouseHDFSURIsorpathswithLinuxcommands suchas
hadoopandhdfstocopy,rename,andsoon,datafilesinHDFS.
IfyouconnecttodifferentImpalanodeswithinanimpala-shell sessionforload-balancing purposes, youcanenable
theSYNC_DDL queryoptiontomakeeachDDLstatementwaitbeforereturning,untiltheneworchangedmetadata
hasbeenreceivedbyalltheImpalanodes.SeeSYNC_DDL QueryOptiononpage361fordetails.
Eachtablecanalsohaveassociatedtablestatisticsandcolumnstatistics.Toseethesecategoriesofinformation,use
theSHOW TABLE STATS table_name andSHOW COLUMN STATS table_name statements.SeeSHOWStatement
onpage363fordetails.
Important:Afteraddingorreplacingdatainatableusedinperformance-critic alqueries,issuea
COMPUTE STATS statementtomakesureallstatisticsareup-to-date.Consider updatingstatisticsfor
atableafteranyINSERT,LOAD DATA ,orCREATE TABLE AS SELECT statementinImpala,orafter
loadingdatathroughHiveanddoingaREFRESH table_name inImpala.Thistechnique isespecially
importantfortablesthatareverylarge,usedinjoinqueries,orboth.
Examples:
ThefollowingexampleshowstheresultsofbothastandardDESCRIBE andDESCRIBE FORMATTED fordifferentkinds
ofschemaobjects:
â¢DESCRIBE foratableoraviewreturnsthename,type,andcommentforeachofthecolumns.Foraview,ifthe
columnvalueiscomputedbyanexpression,thecolumnnameisautomaticallygeneratedas_c0,_c1,andsoon
depending ontheordinalnumberofthecolumn.
â¢AtablecreatedwithnospecialformatorstorageclausesisdesignatedasaMANAGED_TABLE (anâinternaltableâ
inImpalaterminology). ItsdatafilesarestoredinanHDFSdirectoryunderthedefaultHivedatadirectory.By
default,itusesTextdataformat.
â¢AviewisdesignatedasVIRTUAL_VIEW inDESCRIBE FORMATTED output.SomeofitspropertiesareNULLor
blankbecausetheyareinheritedfromthebasetable.Thetextofthequerythatdefinestheviewispartofthe
DESCRIBE FORMATTED output.
â¢Atablewithadditional clausesintheCREATE TABLE statementhasdifferencesinDESCRIBE FORMATTED output.
TheoutputforT2includestheEXTERNAL_TABLE keywordbecauseoftheCREATE EXTERNAL TABLE syntax,
anddifferentInputFormat andOutputFormat fieldstoreflecttheParquetfileformat.
[localhost:21000] > create table t1 (x int, y int, s string);
Query: create table t1 (x int, y int, s string)
[localhost:21000] > describe t1;
Query: describe t1
Query finished, fetching results ...
+------+--------+---------+
| name | type   | comment |
+------+--------+---------+
| x    | int    |         |
| y    | int    |         |
ApacheImpalaGuide|257ImpalaSQLLanguageReference
| s    | string |         |
+------+--------+---------+
Returned 3 row(s) in 0.13s
[localhost:21000] > describe formatted t1;
Query: describe formatted t1
Query finished, fetching results ...
+------------------------------+--------------------------------------------+------------+
| name                         | type                                       | comment 
   |
+------------------------------+--------------------------------------------+------------+
| # col_name                   | data_type                                  | comment 
   |
|                              | NULL                                       | NULL    
   |
| x                            | int                                        | None    
   |
| y                            | int                                        | None    
   |
| s                            | string                                     | None    
   |
|                              | NULL                                       | NULL    
   |
| # Detailed Table Information | NULL                                       | NULL    
   |
| Database:                    | describe_formatted                         | NULL    
   |
| Owner:                       | doc_demo                                   | NULL    
   |
| CreateTime:                  | Mon Jul 22 17:03:16 EDT 2013               | NULL    
   |
| LastAccessTime:              | UNKNOWN                                    | NULL    
   |
| Protect Mode:                | None                                       | NULL    
   |
| Retention:                   | 0                                          | NULL    
   |
| Location:                    | hdfs://127.0.0.1:8020/user/hive/warehouse/ |         
   |
|                              |   describe_formatted.db/t1                 | NULL    
   |
| Table Type:                  | MANAGED_TABLE                              | NULL    
   |
| Table Parameters:            | NULL                                       | NULL    
   |
|                              | transient_lastDdlTime                      | 1374526996
 |
|                              | NULL                                       | NULL    
   |
| # Storage Information        | NULL                                       | NULL    
   |
| SerDe Library:               | org.apache.hadoop.hive.serde2.lazy.        |         
   |
|                              |   LazySimpleSerDe                          | NULL    
   |
| InputFormat:                 | org.apache.hadoop.mapred.TextInputFormat   | NULL    
   |
| OutputFormat:                | org.apache.hadoop.hive.ql.io.              |         
   |
|                              |   HiveIgnoreKeyTextOutputFormat            | NULL    
   |
| Compressed:                  | No                                         | NULL    
   |
| Num Buckets:                 | 0                                          | NULL    
   |
| Bucket Columns:              | []                                         | NULL    
   |
| Sort Columns:                | []                                         | NULL    
   |
+------------------------------+--------------------------------------------+------------+
Returned 26 row(s) in 0.03s
[localhost:21000] > create view v1 as select x, upper(s) from t1;
Query: create view v1 as select x, upper(s) from t1
[localhost:21000] > describe v1;
258|ApacheImpalaGuideImpalaSQLLanguageReference
Query: describe v1
Query finished, fetching results ...
+------+--------+---------+
| name | type   | comment |
+------+--------+---------+
| x    | int    |         |
| _c1  | string |         |
+------+--------+---------+
Returned 2 row(s) in 0.10s
[localhost:21000] > describe formatted v1;
Query: describe formatted v1
Query finished, fetching results ...
+------------------------------+------------------------------+----------------------+
| name                         | type                         | comment              |
+------------------------------+------------------------------+----------------------+
| # col_name                   | data_type                    | comment              |
|                              | NULL                         | NULL                 |
| x                            | int                          | None                 |
| _c1                          | string                       | None                 |
|                              | NULL                         | NULL                 |
| # Detailed Table Information | NULL                         | NULL                 |
| Database:                    | describe_formatted           | NULL                 |
| Owner:                       | doc_demo                     | NULL                 |
| CreateTime:                  | Mon Jul 22 16:56:38 EDT 2013 | NULL                 |
| LastAccessTime:              | UNKNOWN                      | NULL                 |
| Protect Mode:                | None                         | NULL                 |
| Retention:                   | 0                            | NULL                 |
| Table Type:                  | VIRTUAL_VIEW                 | NULL                 |
| Table Parameters:            | NULL                         | NULL                 |
|                              | transient_lastDdlTime        | 1374526598           |
|                              | NULL                         | NULL                 |
| # Storage Information        | NULL                         | NULL                 |
| SerDe Library:               | null                         | NULL                 |
| InputFormat:                 | null                         | NULL                 |
| OutputFormat:                | null                         | NULL                 |
| Compressed:                  | No                           | NULL                 |
| Num Buckets:                 | 0                            | NULL                 |
| Bucket Columns:              | []                           | NULL                 |
| Sort Columns:                | []                           | NULL                 |
|                              | NULL                         | NULL                 |
| # View Information           | NULL                         | NULL                 |
| View Original Text:          | SELECT x, upper(s) FROM t1   | NULL                 |
| View Expanded Text:          | SELECT x, upper(s) FROM t1   | NULL                 |
+------------------------------+------------------------------+----------------------+
Returned 28 row(s) in 0.03s
[localhost:21000] > create external table t2 (x int, y int, s string) stored as parquet
 location '/user/doc_demo/sample_data';
[localhost:21000] > describe formatted t2;
Query: describe formatted t2
Query finished, fetching results ...
+------------------------------+----------------------------------------------------+------------+
| name                         | type                                               | 
comment    |
+------------------------------+----------------------------------------------------+------------+
| # col_name                   | data_type                                          | 
comment    |
|                              | NULL                                               | 
NULL       |
| x                            | int                                                | 
None       |
| y                            | int                                                | 
None       |
| s                            | string                                             | 
None       |
|                              | NULL                                               | 
NULL       |
| # Detailed Table Information | NULL                                               | 
NULL       |
| Database:                    | describe_formatted                                 | 
NULL       |
| Owner:                       | doc_demo                                           | 
NULL       |
| CreateTime:                  | Mon Jul 22 17:01:47 EDT 2013                       | 
ApacheImpalaGuide|259ImpalaSQLLanguageReference
NULL       |
| LastAccessTime:              | UNKNOWN                                            | 
NULL       |
| Protect Mode:                | None                                               | 
NULL       |
| Retention:                   | 0                                                  | 
NULL       |
| Location:                    | hdfs://127.0.0.1:8020/user/doc_demo/sample_data    | 
NULL       |
| Table Type:                  | EXTERNAL_TABLE                                     | 
NULL       |
| Table Parameters:            | NULL                                               | 
NULL       |
|                              | EXTERNAL                                           | 
TRUE       |
|                              | transient_lastDdlTime                              | 
1374526907 |
|                              | NULL                                               | 
NULL       |
| # Storage Information        | NULL                                               | 
NULL       |
| SerDe Library:               | org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe | 
NULL       |
| InputFormat:                 | com.cloudera.impala.hive.serde.ParquetInputFormat  | 
NULL       |
| OutputFormat:                | com.cloudera.impala.hive.serde.ParquetOutputFormat | 
NULL       |
| Compressed:                  | No                                                 | 
NULL       |
| Num Buckets:                 | 0                                                  | 
NULL       |
| Bucket Columns:              | []                                                 | 
NULL       |
| Sort Columns:                | []                                                 | 
NULL       |
+------------------------------+----------------------------------------------------+------------+
Returned 27 row(s) in 0.17s
Cancellation:Cannotbecancelled.
HDFSpermissions:
TheuserIDthattheimpalad daemonrunsunder,typicallytheimpalauser,musthavereadandexecutepermissions
foralldirectoriesthatarepartofthetable.(AtablecouldspanmultipledifferentHDFSdirectoriesifitispartitioned.
Thedirectoriescouldbewidelyscatteredbecauseapartition canresideinanarbitraryHDFSdirectorybasedonits
LOCATION attribute.)
ClouderaManagerconsiderations:
AchangeinthebehaviorofmetadataloadinginCDH5.12/Impala2.9couldleadtocertainlong-running statements
beingleftoutoftheClouderaManagerlistofImpalaqueriesuntilthestatementsarecompleted.
PriortoCDH5.12/Impala2.9,statementssuchasDESCRIBE couldcausetheImpalawebUI,andClouderaManager
monitoringpagesthatrelyoninformationfromthewebUI,tobecomeunresponsivewhiletheyran.Thefirsttime
Impalareferencesalargetable,forexampleonewiththousands ofpartitions, thestatementmighttakelongerthan
normalwhilethemetadataforthetableisloaded.InCDH5.12/Impala2.9andhigher,theImpalawebUIandassociated
ClouderaManagermonitoringpagesaremoreresponsivewhileametadataloadingoperationisinprogress.
Although thestatementthatloadsthemetadatashowsupontheImpalawebUI/queriespageimmediately,itdoes
notshowupintheClouderaManagerlistofqueriesuntilthemetadataisfinishedloading.Forexample,thefirst
DESCRIBE ofalargepartitioned tablemighttake30minutesduetometadataloading,andthestatementdoesnot
showupinClouderaManagerduringthose30minutes.
Kuduconsiderations:
TheinformationdisplayedforKudutablesincludestheadditional attributesthatareonlyapplicableforKudutables:
â¢Whetherornotthecolumnispartoftheprimarykey.EveryKudutablehasatruevaluehereforatleastone
column.Therecouldbemultipletruevalues,fortableswithcompositeprimarykeys.
260|ApacheImpalaGuideImpalaSQLLanguageReference
â¢Whetherornotthecolumnisnullable.Specified bytheNULLorNOT NULL attributesontheCREATE TABLE
statement.Columns thatarepartoftheprimarykeyareautomaticallynon-nullable.
â¢Thedefaultvalue,ifany,forthecolumn.Specified bytheDEFAULT attributeontheCREATE TABLE statement.
IfthedefaultvalueisNULL,thatisnotindicatedinthiscolumn.Itisimpliedbynullable beingtrueandnoother
defaultvaluespecified.
â¢Theencodingusedforvaluesinthecolumn.Specified bytheENCODING attributeontheCREATE TABLE statement.
â¢Thecompressionusedforvaluesinthecolumn.Specified bytheCOMPRESSION attributeontheCREATE TABLE
statement.
â¢Theblocksize(inbytes)usedfortheunderlying Kudustoragelayerforthecolumn.Specified bytheBLOCK_SIZE
attributeontheCREATE TABLE statement.
ThefollowingexampleshowsDESCRIBE outputforasimpleKudutable,withasingle-columnprimarykeyandall
columnattributesleftwiththeirdefaultvalues:
describe million_rows;
+------+--------+---------+-------------+----------+---------------+---------------+---------------------+------------+
| name | type   | comment | primary_key | nullable | default_value | encoding      | 
compression         | block_size |
+------+--------+---------+-------------+----------+---------------+---------------+---------------------+------------+
| id   | string |         | true        | false    |               | AUTO_ENCODING | 
DEFAULT_COMPRESSION | 0          |
| s    | string |         | false       | false    |               | AUTO_ENCODING | 
DEFAULT_COMPRESSION | 0          |
+------+--------+---------+-------------+----------+---------------+---------------+---------------------+------------+
ThefollowingexampleshowsDESCRIBE outputforaKudutablewithatwo-columnprimarykey,andKudu-specific
attributesappliedtosomecolumns:
create table kudu_describe_example
(
  c1 int, c2 int,
  c3 string, c4 string not null, c5 string default 'n/a', c6 string default '',
  c7 bigint not null, c8 bigint null default null, c9 bigint default -1 encoding 
bit_shuffle,
  primary key(c1,c2)
)
partition by hash (c1, c2) partitions 10 stored as kudu;
describe kudu_describe_example;
+------+--------+---------+-------------+----------+---------------+---------------+---------------------+------------+
| name | type   | comment | primary_key | nullable | default_value | encoding      | 
compression         | block_size |
+------+--------+---------+-------------+----------+---------------+---------------+---------------------+------------+
| c1   | int    |         | true        | false    |               | AUTO_ENCODING | 
DEFAULT_COMPRESSION | 0          |
| c2   | int    |         | true        | false    |               | AUTO_ENCODING | 
DEFAULT_COMPRESSION | 0          |
| c3   | string |         | false       | true     |               | AUTO_ENCODING | 
DEFAULT_COMPRESSION | 0          |
| c4   | string |         | false       | false    |               | AUTO_ENCODING | 
DEFAULT_COMPRESSION | 0          |
| c5   | string |         | false       | true     | n/a           | AUTO_ENCODING | 
DEFAULT_COMPRESSION | 0          |
| c6   | string |         | false       | true     |               | AUTO_ENCODING | 
DEFAULT_COMPRESSION | 0          |
| c7   | bigint |         | false       | false    |               | AUTO_ENCODING | 
DEFAULT_COMPRESSION | 0          |
| c8   | bigint |         | false       | true     |               | AUTO_ENCODING | 
DEFAULT_COMPRESSION | 0          |
| c9   | bigint |         | false       | true     | -1            | BIT_SHUFFLE   | 
DEFAULT_COMPRESSION | 0          |
+------+--------+---------+-------------+----------+---------------+---------------+---------------------+------------+
Relatedinformation:
ApacheImpalaGuide|261ImpalaSQLLanguageReference
OverviewofImpalaTablesonpage196,CREATETABLEStatementonpage234,SHOWTABLESStatementonpage369,
SHOWCREATETABLEStatementonpage370
DROPDATABASEStatement
Removesadatabasefromthesystem.Thephysicaloperationsinvolveremovingthemetadataforthedatabasefrom
themetastore,anddeletingthecorresponding *.dbdirectoryfromHDFS.
Syntax:
DROP (DATABASE|SCHEMA) [IF EXISTS] database_name [RESTRICT | CASCADE] ;
Statementtype:DDL
Usagenotes:
Bydefault,thedatabasemustbeemptybeforeitcanbedropped,toavoidlosinganydata.
InCDH5.5/Impala2.3andhigher,youcanincludetheCASCADE clausetomakeImpaladropalltablesandother
objectsinthedatabasebeforedroppingthedatabaseitself.TheRESTRICT clauseenforcestheoriginalrequirement
thatthedatabasebeemptybeforebeingdropped.BecausetheRESTRICT behaviorisstillthedefault,thisclauseis
optional.
TheautomaticdroppingresultingfromtheCASCADE clausefollowsthesamerulesasthecorresponding DROP TABLE ,
DROP VIEW ,andDROP FUNCTION statements.Inparticular ,theHDFSdirectoriesanddatafilesforanyexternaltables
areleftbehindwhenthetablesareremoved.
WhenyoudonotusetheCASCADE clause,dropormovealltheobjectsinsidethedatabasemanually beforedropping
thedatabaseitself:
â¢UsetheSHOW TABLES statementtolocatealltablesandviewsinthedatabase,andissueDROP TABLE andDROP
VIEWstatementstoremovethemall.
â¢UsetheSHOW FUNCTIONS andSHOW AGGREGATE FUNCTIONS statementstolocatealluser-definedfunctions
inthedatabase,andissueDROP FUNCTION andDROP AGGREGATE FUNCTION statementstoremovethemall.
â¢Tokeeptablesorviewscontainedbyadatabasewhileremovingthedatabaseitself,useALTER TABLE andALTER
VIEWtomovetherelevantobjectstoadifferentdatabasebeforedroppingtheoriginaldatabase.
Youcannotdropthecurrentdatabase,thatis,thedatabaseyoursessionconnectedtoeitherthroughtheUSEstatement
orthe-doptionofimpala-shell .IssueaUSEstatementtoswitchtoadifferentdatabasefirst.Becausethedefault
databaseisalwaysavailable,issuingUSE default isaconvenientwaytoleavethecurrentdatabasebeforedropping
it.
Hiveconsiderations:
WhenyoudropadatabaseinImpala,thedatabasecannolongerbeusedbyHive.
Examples:
SeeCREATEDATABASEStatementonpage226forexamplescoveringCREATE DATABASE ,USE,andDROP DATABASE .
AmazonS3considerations:
InCDH5.8/Impala2.6andhigher,ImpalaDDLstatementssuchasCREATE DATABASE ,CREATE TABLE ,DROP
DATABASE CASCADE ,DROP TABLE ,andALTER TABLE [ADD|DROP] PARTITION cancreateorremovefoldersas
neededintheAmazonS3system.PriortoCDH5.8/Impala2.6,youhadtocreatefoldersyourselfandpointImpala
database,tables,orpartitions atthem,andmanually removefolderswhennolongerneeded.SeeUsingImpalawith
theAmazonS3Filesystemonpage692fordetailsaboutreadingandwritingS3datawithImpala.
Cancellation:Cannotbecancelled.
HDFSpermissions:
262|ApacheImpalaGuideImpalaSQLLanguageReference
TheuserIDthattheimpalad daemonrunsunder,typicallytheimpalauser,musthavewritepermission forthe
directoryassociatedwiththedatabase.
Examples:
create database first_db;
use first_db;
create table t1 (x int);
create database second_db;
use second_db;
-- Each database has its own namespace for tables.
-- You can reuse the same table names in each database.
create table t1 (s string);
create database temp;
-- You can either USE a database after creating it,
-- or qualify all references to the table name with the name of the database.
-- Here, tables T2 and T3 are both created in the TEMP database.
create table temp.t2 (x int, y int);
use database temp;
create table t3 (s string);
-- You cannot drop a database while it is selected by the USE statement.
drop database temp;
ERROR: AnalysisException: Cannot drop current default database: temp
-- The always-available database 'default' is a convenient one to USE
-- before dropping a database you created.
use default;
-- Before dropping a database, first drop all the tables inside it,
-- or in CDH 5.5 / Impala 2.3  and higher use the CASCADE clause.
drop database temp;
ERROR: ImpalaRuntimeException: Error making 'dropDatabase' RPC to Hive Metastore:
CAUSED BY: InvalidOperationException: Database temp is not empty
show tables in temp;
+------+
| name |
+------+
| t3   |
+------+
-- CDH 5.5 / Impala 2.3  and higher:
drop database temp cascade;
-- Earlier releases:
drop table temp.t3;
drop database temp;
Relatedinformation:
OverviewofImpalaDatabasesonpage193,CREATEDATABASEStatementonpage226,USEStatementonpage385,
SHOWDATABASESonpage368,DROPTABLEStatementonpage268
DROPFUNCTIONStatement
Removesauser-definedfunction(UDF),sothatitisnotavailableforexecutionduringImpalaSELECTorINSERT
operations.
Syntax:
TodropC++UDFsandUDAs:
DROP [AGGREGATE] FUNCTION [IF EXISTS] [ db_name.]function_name (type[, type...])
ApacheImpalaGuide|263ImpalaSQLLanguageReference
Note:
Theprecedingsyntax,whichincludesthefunctionsignature,alsoappliestoJavaUDFsthatwere
createdusingthecorresponding CREATE FUNCTION syntaxthatincludestheargumentandreturn
types.AfterupgradingtoCDH5.7/Impala2.5orhigher,considerre-creatingallJavaUDFswiththe
CREATE FUNCTION syntaxthatdoesnotincludethefunctionsignature.JavaUDFscreatedthisway
arenowpersistedinthemetastoredatabaseanddonotneedtobere-createdafteranImpalarestart.
TodropJavaUDFs(createdusingtheCREATE FUNCTION syntaxwithnofunctionsignature):
DROP FUNCTION [IF EXISTS] [ db_name.]function_name
Statementtype:DDL
Usagenotes:
Becausethesamefunctionnamecouldbeoverloaded withdifferentargumentsignatures,youspecifytheargument
typestoidentifytheexactfunctiontodrop.
Restrictions:
InCDH5.7/Impala2.5andhigher,ImpalaUDFsandUDAswritteninC++arepersistedinthemetastoredatabase.
JavaUDFsarealsopersisted,iftheywerecreatedwiththenewCREATE FUNCTION syntaxforJavaUDFs,wherethe
Javafunctionargumentandreturntypesareomitted.Java-basedUDFscreatedwiththeoldCREATE FUNCTION syntax
donotpersistacrossrestartsbecausetheyareheldinthememoryofthecatalogd daemon. Untilyoure-createsuch
JavaUDFsusingthenewCREATE FUNCTION syntax,youmustreloadthoseJava-basedUDFsbyrunningtheoriginal
CREATE FUNCTION statementsagaineachtimeyourestartthecatalogd daemon. PriortoCDH5.7/Impala2.5the
requirementtoreloadfunctions afterarestartappliedtobothC++andJavafunctions.
Cancellation:Cannotbecancelled.
HDFSpermissions:
TheuserIDthattheimpalad daemonrunsunder,typicallytheimpalauser,doesnotneedanyparticular HDFS
permissions toperformthisstatement.Allreadandwriteoperationsareonthemetastoredatabase,notHDFSfiles
anddirectories.
Examples:
ThefollowingexampleshowshowtodropJavafunctions createdwiththesignaturelessCREATE FUNCTION syntax
inCDH5.7/Impala2.5andhigher.IssuingDROP FUNCTION function_name removesalltheoverloaded functions
underthatname.(SeeCREATEFUNCTIONStatementonpage228foralongerexampleshowinghowtosetupsuch
functions inthefirstplace.)
create function my_func location '/user/impala/udfs/udf-examples-cdh570.jar'
  symbol='com.cloudera.impala.TestUdf';
show functions;
+-------------+---------------------------------------+-------------+---------------+
| return type | signature                             | binary type | is persistent |
+-------------+---------------------------------------+-------------+---------------+
| BIGINT      | my_func(BIGINT)                       | JAVA        | true          |
| BOOLEAN     | my_func(BOOLEAN)                      | JAVA        | true          |
| BOOLEAN     | my_func(BOOLEAN, BOOLEAN)             | JAVA        | true          |
...
| BIGINT      | testudf(BIGINT)                       | JAVA        | true          |
| BOOLEAN     | testudf(BOOLEAN)                      | JAVA        | true          |
| BOOLEAN     | testudf(BOOLEAN, BOOLEAN)             | JAVA        | true          |
...
drop function my_func;
show functions;
+-------------+---------------------------------------+-------------+---------------+
| return type | signature                             | binary type | is persistent |
264|ApacheImpalaGuideImpalaSQLLanguageReference
+-------------+---------------------------------------+-------------+---------------+
| BIGINT      | testudf(BIGINT)                       | JAVA        | true          |
| BOOLEAN     | testudf(BOOLEAN)                      | JAVA        | true          |
| BOOLEAN     | testudf(BOOLEAN, BOOLEAN)             | JAVA        | true          |
...
Relatedinformation:
User-DefinedFunctions (UDFs)onpage525,CREATEFUNCTIONStatementonpage228
DROPROLEStatement(CDH5.2orhigheronly)
TheDROP ROLE statementremovesarolefromthemetastoredatabase.Oncedropped,theroleisrevokedforall
userstowhomitwaspreviouslyassigned, andallprivilegesgrantedtothatrolearerevoked.Queriesthatarealready
executingarenotaffected.Impalaverifiestheroleinformationapproximatelyevery60seconds,sotheeffectsofDROP
ROLEmightnottakeeffectfornewImpalaqueriesforabriefperiod.
Syntax:
DROP ROLE role_name
Requiredprivileges:
Onlyadministrativeusers(initially,apredefinedsetofusersspecified intheSentryserviceconfigurationfile)canuse
thisstatement.
Compatibility:
Impalamakesuseofanyrolesandprivilegesspecified bytheGRANTandREVOKEstatementsinHive,andHivemakes
useofanyrolesandprivilegesspecified bytheGRANTandREVOKEstatementsinImpala.TheImpalaGRANTandREVOKE
statementsforprivilegesdonotrequiretheROLEkeywordtoberepeatedbeforeeachrolename,unliketheequivalent
Hivestatements.
Relatedinformation:
EnablingSentryAuthorizationforImpalaonpage87,GRANTStatement(CDH5.2orhigheronly)onpage273REVOKE
Statement(CDH5.2orhigheronly)onpage293,CREATEROLEStatement(CDH5.2orhigheronly)onpage234,SHOW
Statementonpage363
Cancellation:Cannotbecancelled.
HDFSpermissions: ThisstatementdoesnottouchanyHDFSfilesordirectories,thereforenoHDFSpermissions are
required.
DROPSTATSStatement
Removesthespecified statisticsfromatableorpartition. Thestatisticswereoriginally createdbytheCOMPUTE STATS
orCOMPUTE INCREMENTAL STATS statement.
Syntax:
DROP STATS [ database_name .]table_name
DROP INCREMENTAL STATS [ database_name .]table_name  PARTITION ( partition_spec )
partition_spec  ::= partition_col =constant_value
ThePARTITION clauseisonlyallowedincombinationwiththeINCREMENTAL clause.ItisoptionalforCOMPUTE
INCREMENTAL STATS ,andrequiredforDROP INCREMENTAL STATS .Wheneveryouspecifypartitions throughthe
PARTITION ( partition_spec )clauseinaCOMPUTE INCREMENTAL STATS orDROP INCREMENTAL STATS
statement,youmustincludeallthepartitioning columnsinthespecification,andspecifyconstantvaluesforallthe
partition keycolumns.
DROP STATS removesallstatisticsfromthetable,whethercreatedbyCOMPUTE STATS orCOMPUTE INCREMENTAL
STATS.
ApacheImpalaGuide|265ImpalaSQLLanguageReference
DROP INCREMENTAL STATS onlyaffectsincrementalstatisticsforasinglepartition, specified throughthePARTITION
clause.Theincrementalstatsaremarkedasoutdated,sothattheyarerecomputedbythenextCOMPUTE INCREMENTAL
STATSstatement.
Usagenotes:
Youtypicallyusethisstatementwhenthestatisticsforatableorapartition havebecomestaleduetodatafilesbeing
addedtoorremovedfromtheassociatedHDFSdatadirectories,whetherbymanualHDFSoperationsorINSERT,
INSERT OVERWRITE ,orLOAD DATA statements,oraddingordroppingpartitions.
Whenatableorpartition hasnoassociatedstatistics,Impalatreatsitasessentiallyzero-sizedwhenconstructingthe
executionplanforaquery.Inparticular ,thestatisticsinfluencetheorderinwhichtablesarejoinedinajoinquery.To
ensureproperqueryplanningandgoodqueryperformance andscalability,makesuretorunCOMPUTE STATS or
COMPUTE INCREMENTAL STATS onthetableorpartition afterremovinganystalestatistics.
Droppingthestatisticsisnotrequiredforanunpartitioned tableorapartitioned tablecoveredbytheoriginaltypeof
statistics.AsubsequentCOMPUTE STATS statementreplacesanyexistingstatisticswithnewones,forallpartitions,
regardlessofwhethertheoldoneswereoutdated.Therefore,thisstatementwasrarelyusedbeforetheintroduction
ofincrementalstatistics.
Droppingthestatisticsisrequiredforapartitioned tablecontainingincrementalstatistics,tomakeasubsequent
COMPUTE INCREMENTAL STATS statementrescananexistingpartition. SeeTableandColumnStatisticsonpage575
forinformationaboutincrementalstatistics,anewfeatureavailableinImpala2.1.0andhigher.
Statementtype:DDL
Cancellation:Cannotbecancelled.
HDFSpermissions:
TheuserIDthattheimpalad daemonrunsunder,typicallytheimpalauser,doesnotneedanyparticular HDFS
permissions toperformthisstatement.Allreadandwriteoperationsareonthemetastoredatabase,notHDFSfiles
anddirectories.
Examples:
Thefollowingexampleshowsapartitioned tablethathasassociatedstatisticsproducedbytheCOMPUTE INCREMENTAL
STATSstatement,andhowthesituationevolvesasstatisticsaredroppedfromspecificpartitions, thentheentire
table.
Initially,alltableandcolumnstatisticsarefilledin.
show table stats item_partitioned;
+-------------+-------+--------+----------+--------------+---------+-----------------
| i_category  | #Rows | #Files | Size     | Bytes Cached | Format  | Incremental stats
+-------------+-------+--------+----------+--------------+---------+-----------------
| Books       | 1733  | 1      | 223.74KB | NOT CACHED   | PARQUET | true
| Children    | 1786  | 1      | 230.05KB | NOT CACHED   | PARQUET | true
| Electronics | 1812  | 1      | 232.67KB | NOT CACHED   | PARQUET | true
| Home        | 1807  | 1      | 232.56KB | NOT CACHED   | PARQUET | true
| Jewelry     | 1740  | 1      | 223.72KB | NOT CACHED   | PARQUET | true
| Men         | 1811  | 1      | 231.25KB | NOT CACHED   | PARQUET | true
| Music       | 1860  | 1      | 237.90KB | NOT CACHED   | PARQUET | true
| Shoes       | 1835  | 1      | 234.90KB | NOT CACHED   | PARQUET | true
| Sports      | 1783  | 1      | 227.97KB | NOT CACHED   | PARQUET | true
| Women       | 1790  | 1      | 226.27KB | NOT CACHED   | PARQUET | true
| Total       | 17957 | 10     | 2.25MB   | 0B           |         |
+-------------+-------+--------+----------+--------------+---------+-----------------
show column stats item_partitioned;
+------------------+-----------+------------------+--------+----------+--------------
| Column           | Type      | #Distinct Values | #Nulls | Max Size | Avg Size
+------------------+-----------+------------------+--------+----------+--------------
| i_item_sk        | INT       | 19443            | -1     | 4        | 4
| i_item_id        | STRING    | 9025             | -1     | 16       | 16
| i_rec_start_date | TIMESTAMP | 4                | -1     | 16       | 16
| i_rec_end_date   | TIMESTAMP | 3                | -1     | 16       | 16
| i_item_desc      | STRING    | 13330            | -1     | 200      | 100.302803039
| i_current_price  | FLOAT     | 2807             | -1     | 4        | 4
266|ApacheImpalaGuideImpalaSQLLanguageReference
| i_wholesale_cost | FLOAT     | 2105             | -1     | 4        | 4
| i_brand_id       | INT       | 965              | -1     | 4        | 4
| i_brand          | STRING    | 725              | -1     | 22       | 16.1776008605
| i_class_id       | INT       | 16               | -1     | 4        | 4
| i_class          | STRING    | 101              | -1     | 15       | 7.76749992370
| i_category_id    | INT       | 10               | -1     | 4        | 4
| i_manufact_id    | INT       | 1857             | -1     | 4        | 4
| i_manufact       | STRING    | 1028             | -1     | 15       | 11.3295001983
| i_size           | STRING    | 8                | -1     | 11       | 4.33459997177
| i_formulation    | STRING    | 12884            | -1     | 20       | 19.9799995422
| i_color          | STRING    | 92               | -1     | 10       | 5.38089990615
| i_units          | STRING    | 22               | -1     | 7        | 4.18690013885
| i_container      | STRING    | 2                | -1     | 7        | 6.99259996414
| i_manager_id     | INT       | 105              | -1     | 4        | 4
| i_product_name   | STRING    | 19094            | -1     | 25       | 18.0233001708
| i_category       | STRING    | 10               | 0      | -1       | -1
+------------------+-----------+------------------+--------+----------+--------------
Toremovestatisticsforparticular partitions, usetheDROP INCREMENTAL STATS statement.Afterremovingstatistics
fortwopartitions, thetable-levelstatisticsreflectthatchangeinthe#RowsandIncremental stats fields.The
counts,maximums,andaveragesofthecolumn-levelstatisticsareunaffected.
Note:(ItispossiblethattherowcountmightbepreservedinfutureafteraDROP INCREMENTAL
STATSstatement.Checktheresolution oftheissueIMPALA-1615 .)
drop incremental stats item_partitioned partition (i_category='Sports');
drop incremental stats item_partitioned partition (i_category='Electronics');
show table stats item_partitioned
+-------------+-------+--------+----------+--------------+---------+------------------
| i_category  | #Rows | #Files | Size     | Bytes Cached | Format  | Incremental stats
+-------------+-------+--------+----------+--------------+---------+-----------------
| Books       | 1733  | 1      | 223.74KB | NOT CACHED   | PARQUET | true
| Children    | 1786  | 1      | 230.05KB | NOT CACHED   | PARQUET | true
| Electronics | -1    | 1      | 232.67KB | NOT CACHED   | PARQUET | false
| Home        | 1807  | 1      | 232.56KB | NOT CACHED   | PARQUET | true
| Jewelry     | 1740  | 1      | 223.72KB | NOT CACHED   | PARQUET | true
| Men         | 1811  | 1      | 231.25KB | NOT CACHED   | PARQUET | true
| Music       | 1860  | 1      | 237.90KB | NOT CACHED   | PARQUET | true
| Shoes       | 1835  | 1      | 234.90KB | NOT CACHED   | PARQUET | true
| Sports      | -1    | 1      | 227.97KB | NOT CACHED   | PARQUET | false
| Women       | 1790  | 1      | 226.27KB | NOT CACHED   | PARQUET | true
| Total       | 17957 | 10     | 2.25MB   | 0B           |         |
+-------------+-------+--------+----------+--------------+---------+-----------------
show column stats item_partitioned
+------------------+-----------+------------------+--------+----------+--------------
| Column           | Type      | #Distinct Values | #Nulls | Max Size | Avg Size
+------------------+-----------+------------------+--------+----------+--------------
| i_item_sk        | INT       | 19443            | -1     | 4        | 4
| i_item_id        | STRING    | 9025             | -1     | 16       | 16
| i_rec_start_date | TIMESTAMP | 4                | -1     | 16       | 16
| i_rec_end_date   | TIMESTAMP | 3                | -1     | 16       | 16
| i_item_desc      | STRING    | 13330            | -1     | 200      | 100.302803039
| i_current_price  | FLOAT     | 2807             | -1     | 4        | 4
| i_wholesale_cost | FLOAT     | 2105             | -1     | 4        | 4
| i_brand_id       | INT       | 965              | -1     | 4        | 4
| i_brand          | STRING    | 725              | -1     | 22       | 16.1776008605
| i_class_id       | INT       | 16               | -1     | 4        | 4
| i_class          | STRING    | 101              | -1     | 15       | 7.76749992370
| i_category_id    | INT       | 10               | -1     | 4        | 4
| i_manufact_id    | INT       | 1857             | -1     | 4        | 4
| i_manufact       | STRING    | 1028             | -1     | 15       | 11.3295001983
| i_size           | STRING    | 8                | -1     | 11       | 4.33459997177
| i_formulation    | STRING    | 12884            | -1     | 20       | 19.9799995422
| i_color          | STRING    | 92               | -1     | 10       | 5.38089990615
| i_units          | STRING    | 22               | -1     | 7        | 4.18690013885
| i_container      | STRING    | 2                | -1     | 7        | 6.99259996414
| i_manager_id     | INT       | 105              | -1     | 4        | 4
| i_product_name   | STRING    | 19094            | -1     | 25       | 18.0233001708
ApacheImpalaGuide|267ImpalaSQLLanguageReference
| i_category       | STRING    | 10               | 0      | -1       | -1
+------------------+-----------+------------------+--------+----------+--------------
Toremoveallstatisticsfromthetable,whetherproducedbyCOMPUTE STATS orCOMPUTE INCREMENTAL STATS ,
usetheDROP STATS statementwithouttheINCREMENTAL clause).Now,bothtable-levelandcolumn-levelstatistics
arereset.
drop stats item_partitioned;
show table stats item_partitioned
+-------------+-------+--------+----------+--------------+---------+------------------
| i_category  | #Rows | #Files | Size     | Bytes Cached | Format  | Incremental stats
+-------------+-------+--------+----------+--------------+---------+------------------
| Books       | -1    | 1      | 223.74KB | NOT CACHED   | PARQUET | false
| Children    | -1    | 1      | 230.05KB | NOT CACHED   | PARQUET | false
| Electronics | -1    | 1      | 232.67KB | NOT CACHED   | PARQUET | false
| Home        | -1    | 1      | 232.56KB | NOT CACHED   | PARQUET | false
| Jewelry     | -1    | 1      | 223.72KB | NOT CACHED   | PARQUET | false
| Men         | -1    | 1      | 231.25KB | NOT CACHED   | PARQUET | false
| Music       | -1    | 1      | 237.90KB | NOT CACHED   | PARQUET | false
| Shoes       | -1    | 1      | 234.90KB | NOT CACHED   | PARQUET | false
| Sports      | -1    | 1      | 227.97KB | NOT CACHED   | PARQUET | false
| Women       | -1    | 1      | 226.27KB | NOT CACHED   | PARQUET | false
| Total       | -1    | 10     | 2.25MB   | 0B           |         |
+-------------+-------+--------+----------+--------------+---------+------------------
show column stats item_partitioned
+------------------+-----------+------------------+--------+----------+----------+
| Column           | Type      | #Distinct Values | #Nulls | Max Size | Avg Size |
+------------------+-----------+------------------+--------+----------+----------+
| i_item_sk        | INT       | -1               | -1     | 4        | 4        |
| i_item_id        | STRING    | -1               | -1     | -1       | -1       |
| i_rec_start_date | TIMESTAMP | -1               | -1     | 16       | 16       |
| i_rec_end_date   | TIMESTAMP | -1               | -1     | 16       | 16       |
| i_item_desc      | STRING    | -1               | -1     | -1       | -1       |
| i_current_price  | FLOAT     | -1               | -1     | 4        | 4        |
| i_wholesale_cost | FLOAT     | -1               | -1     | 4        | 4        |
| i_brand_id       | INT       | -1               | -1     | 4        | 4        |
| i_brand          | STRING    | -1               | -1     | -1       | -1       |
| i_class_id       | INT       | -1               | -1     | 4        | 4        |
| i_class          | STRING    | -1               | -1     | -1       | -1       |
| i_category_id    | INT       | -1               | -1     | 4        | 4        |
| i_manufact_id    | INT       | -1               | -1     | 4        | 4        |
| i_manufact       | STRING    | -1               | -1     | -1       | -1       |
| i_size           | STRING    | -1               | -1     | -1       | -1       |
| i_formulation    | STRING    | -1               | -1     | -1       | -1       |
| i_color          | STRING    | -1               | -1     | -1       | -1       |
| i_units          | STRING    | -1               | -1     | -1       | -1       |
| i_container      | STRING    | -1               | -1     | -1       | -1       |
| i_manager_id     | INT       | -1               | -1     | 4        | 4        |
| i_product_name   | STRING    | -1               | -1     | -1       | -1       |
| i_category       | STRING    | 10               | 0      | -1       | -1       |
+------------------+-----------+------------------+--------+----------+----------+
Relatedinformation:
COMPUTE STATSStatementonpage219,SHOWTABLESTATSStatementonpage373,SHOWCOLUMNSTATSStatement
onpage375,TableandColumnStatisticsonpage575
DROPTABLEStatement
RemovesanImpalatable.Alsoremovestheunderlying HDFSdatafilesforinternaltables,although notforexternal
tables.
Syntax:
DROP TABLE [IF EXISTS] [ db_name.]table_name [PURGE]
IFEXISTSclause:
268|ApacheImpalaGuideImpalaSQLLanguageReference
TheoptionalIF EXISTS clausemakesthestatementsucceedwhetherornotthetableexists.Ifthetabledoesexist,
itisdropped;ifitdoesnotexist,thestatementhasnoeffect.Thiscapabilityisusefulinstandardizedsetupscriptsthat
removeexistingschemaobjectsandcreatenewones.ByusingsomecombinationofIF EXISTS fortheDROPstatements
andIF NOT EXISTS clausesfortheCREATEstatements,thescriptcanrunsuccessfullythefirsttimeyourunit(when
theobjectsdonotexistyet)andsubsequenttimes(whensomeoralloftheobjectsdoalreadyexist).
PURGEclause:
TheoptionalPURGEkeyword,availableinCDH5.5/Impala2.3andhigher,causesImpalatoremovetheassociated
HDFSdatafilesimmediately,ratherthangoingthroughtheHDFStrashcanmechanism. Usethiskeywordwhendropping
atableifitiscrucialtoremovethedataasquicklyaspossibletofreeupspace,orifthereisaproblemwiththetrashcan,
suchasthetrashcannotbeingconfiguredorbeinginadifferentHDFSencryptionzonethanthedatafiles.
Statementtype:DDL
Usagenotes:
Bydefault,ImpalaremovestheassociatedHDFSdirectoryanddatafilesforthetable.IfyouissueaDROP TABLE and
thedatafilesarenotdeleted,itmightbeforthefollowingreasons:
â¢IfthetablewascreatedwiththeEXTERNAL clause,Impalaleavesallfilesanddirectoriesuntouched.Useexternal
tableswhenthedataisunderthecontrolofotherHadoopcomponen ts,andImpalaisonlyusedtoquerythedata
filesfromtheiroriginallocations.
â¢Impalamightleavethedatafilesbehindunintentionally,ifthereisnoHDFSlocationavailabletoholdtheHDFS
trashcanfortheimpalauser.SeeUserAccountRequirementsonpage25fortheproceduretosetuptherequired
HDFShomedirectory.
Makesurethatyouareinthecorrectdatabasebeforedroppingatable,eitherbyissuingaUSEstatementfirstorby
usingafullyqualified namedb_name.table_name .
IfyouintendtoissueaDROP DATABASE statement,firstissueDROP TABLE statementstoremoveallthetablesin
thatdatabase.
Examples:
create database temporary;
use temporary;
create table unimportant (x int);
create table trivial (s string);
-- Drop a table in the current database.
drop table unimportant;
-- Switch to a different database.
use default;
-- To drop a table in a different database...
drop table trivial;
ERROR: AnalysisException: Table does not exist: default.trivial
-- ...use a fully qualified name.
drop table temporary.trivial;
Forothertipsaboutmanaging andreclaiming Impaladiskspace,seeManaging DiskSpaceforImpalaDataonpage
77.
AmazonS3considerations:
TheDROP TABLE statementcanremovedatafilesfromS3iftheassociatedS3tableisaninternaltable.InCDH5.8/
Impala2.6andhigher,aspartofimprovedsupportforwritingtoS3,Impalaalsoremovestheassociatedfolderwhen
droppinganinternaltablethatresidesonS3.SeeUsingImpalawiththeAmazonS3Filesystemonpage692fordetails
aboutworkingwithS3tables.
ForbestcompatibilitywiththeS3writesupportinCDH5.8/Impala2.6andhigher:
â¢UsenativeHadooptechniques tocreatedatafilesinS3forqueryingthroughImpala.
â¢UsethePURGEclauseofDROP TABLE whendroppinginternal(managed)tables.
Bydefault,whenyoudropaninternal(managed)table,thedatafilesaremovedtotheHDFStrashcan.Thisoperation
isexpensivefortablesthatresideontheAmazonS3filesystem.Therefore,forS3tables,prefertouseDROP TABLE
ApacheImpalaGuide|269ImpalaSQLLanguageReference
table_name  PURGEratherthanthedefaultDROP TABLE statement.ThePURGEclausemakesImpaladeletethedata
filesimmediately,skippingtheHDFStrashcan.ForthePURGEclausetoworkeffectively,youmustoriginally createthe
datafilesonS3usingoneofthetoolsfromtheHadoopecosystem,suchashadoop fs -cp ,orINSERTinImpalaor
Hive.
InCDH5.8/Impala2.6andhigher,ImpalaDDLstatementssuchasCREATE DATABASE ,CREATE TABLE ,DROP
DATABASE CASCADE ,DROP TABLE ,andALTER TABLE [ADD|DROP] PARTITION cancreateorremovefoldersas
neededintheAmazonS3system.PriortoCDH5.8/Impala2.6,youhadtocreatefoldersyourselfandpointImpala
database,tables,orpartitions atthem,andmanually removefolderswhennolongerneeded.SeeUsingImpalawith
theAmazonS3Filesystemonpage692fordetailsaboutreadingandwritingS3datawithImpala.
Cancellation:Cannotbecancelled.
HDFSpermissions:
Foraninternaltable,theuserIDthattheimpalad daemonrunsunder,typicallytheimpalauser,musthavewrite
permission forallthefilesanddirectoriesthatmakeupthetable.
Foranexternaltable,droppingthetableonlyinvolveschangestometadatainthemetastoredatabase.BecauseImpala
doesnotremoveanyHDFSfilesordirectorieswhenexternaltablesaredropped,noparticular permissions areneeded
fortheassociatedHDFSfilesordirectories.
Kuduconsiderations:
Kudutablescanbemanagedorexternal,thesameaswithHDFS-basedtables.Foramanagedtable,theunderlying
KudutableanditsdataareremovedbyDROP TABLE .Foranexternaltable,theunderlying Kudutableanditsdata
remainafteraDROP TABLE .
Relatedinformation:
OverviewofImpalaTablesonpage196,ALTERTABLEStatementonpage205,CREATETABLEStatementonpage234,
Partitioning forImpalaTablesonpage625,InternalTablesonpage197,ExternalTablesonpage197
DROPVIEWStatement
Removesthespecified view,whichwasoriginally createdbytheCREATE VIEW statement.Becauseaviewispurelya
logicalconstruct(analiasforaquery)withnophysicaldatabehindit,DROP VIEW onlyinvolveschangestometadata
inthemetastoredatabase,notanydatafilesinHDFS.
Syntax:
DROP VIEW [IF EXISTS] [ db_name.]view_name
Statementtype:DDL
Cancellation:Cannotbecancelled.
HDFSpermissions: ThisstatementdoesnottouchanyHDFSfilesordirectories,thereforenoHDFSpermissions are
required.
Examples:
Thefollowingexamplecreatesaseriesofviewsandthendropsthem.Theseexamplesillustratehowviewsareassociated
withaparticular database,andboththeviewdefinitionsandtheviewnamesforCREATE VIEW andDROP VIEW can
refertoaviewinthecurrentdatabaseorafullyqualified viewname.
-- Create and drop a view in the current database.
CREATE VIEW few_rows_from_t1 AS SELECT * FROM t1 LIMIT 10;
DROP VIEW few_rows_from_t1;
-- Create and drop a view referencing a table in a different database.
CREATE VIEW table_from_other_db AS SELECT x FROM db1.foo WHERE x IS NOT NULL;
DROP VIEW table_from_other_db;
USE db1;
270|ApacheImpalaGuideImpalaSQLLanguageReference
-- Create a view in a different database.
CREATE VIEW db2.v1 AS SELECT * FROM db2.foo;
-- Switch into the other database and drop the view.
USE db2;
DROP VIEW v1;
USE db1;
-- Create a view in a different database.
CREATE VIEW db2.v1 AS SELECT * FROM db2.foo;
-- Drop a view in the other database.
DROP VIEW db2.v1;
Relatedinformation:
OverviewofImpalaViewsonpage199,CREATEVIEWStatementonpage248,ALTERVIEWStatementonpage218
EXPLAINStatement
Returnstheexecutionplanforastatement,showingthelow-levelmechanisms thatImpalawillusetoreadthedata,
dividetheworkamongnodesinthecluster,andtransmitintermediateandfinalresultsacrossthenetwork.Use
explain followedbyacompleteSELECTquery.Forexample:
Syntax:
EXPLAIN { select_query  | ctas_stmt  | insert_stmt  }
Theselect_quer yisaSELECTstatement,optionallyprefixedbyaWITHclause.SeeSELECTStatementonpage295for
details.
Theinsert_stmtisanINSERTstatementthatinsertsintooroverwritesanexistingtable.ItcanuseeithertheINSERT
... SELECT orINSERT ... VALUES syntax.SeeINSERTStatementonpage277fordetails.
Thectas_stmtisaCREATE TABLE statementusingtheAS SELECT clause,typicallyabbreviatedasaâCTASâoperation.
SeeCREATETABLEStatementonpage234fordetails.
Usagenotes:
Youcaninterprettheoutputtojudgewhetherthequeryisperformingefficiently,andadjustthequeryand/orthe
schemaifnot.Forexample,youmightchangethetestsintheWHEREclause,addhintstomakejoinoperationsmore
efficient,introducesubqueries, changetheorderoftablesinajoin,addorchangepartitioning foratable,collect
columnstatisticsand/ortablestatisticsinHive,oranyotherperformance tuningsteps.
TheEXPLAIN outputremindsyouiftableorcolumnstatisticsaremissingfromanytableinvolvedinthequery.These
statisticsareimportantforoptimizingqueriesinvolvinglargetablesormulti-tablejoins.SeeCOMPUTE STATSStatement
onpage219forhowtogatherstatistics,andTableandColumnStatisticsonpage575forhowtousethisinformation
forquerytuning.
ReadtheEXPLAIN planfrombottomtotop:
â¢Thelastpartoftheplanshowsthelow-leveldetailssuchastheexpectedamountofdatathatwillberead,where
youcanjudgetheeffectivenessofyourpartitioning strategyandestimatehowlongitwilltaketoscanatable
basedontotaldatasizeandthesizeofthecluster.
â¢Asyouworkyourwayup,nextyouseetheoperationsthatwillbeparallelizedandperformedoneachImpala
node.
â¢Atthehigherlevels,youseehowdataflowswhenintermediateresultsetsarecombined andtransmittedfrom
onenodetoanother.
â¢SeeEXPLAIN_LEVEL QueryOptiononpage331fordetailsabouttheEXPLAIN_LEVEL queryoption,whichletsyou
customizehowmuchdetailtoshowintheEXPLAIN plandepending onwhetheryouaredoinghigh-levelor
low-leveltuning,dealingwithlogicalorphysicalaspectsofthequery.
Ifyoucomefromatraditional databasebackgroundandarenotfamiliarwithdatawarehousing,keepinmindthat
Impalaisoptimizedforfulltablescansacrossverylargetables.Thestructureanddistribution ofthisdataistypically
notsuitableforthekindofindexingandsingle-rowlookupsthatarecommoninOLTPenvironments.Seeingaquery
ApacheImpalaGuide|271ImpalaSQLLanguageReference
scanentirelythroughalargetableiscommon,notnecessarily anindicationofaninefficientquery.Ofcourse,ifyou
canreducethevolumeofscanneddatabyordersofmagnitude, forexamplebyusingaquerythataffectsonlycertain
partitions withinapartitioned table,thenyoumightbeabletooptimizeaquerysothatitexecutesinsecondsrather
thanminutes.
FormoreinformationandexamplestohelpyouinterpretEXPLAIN output,seeUsingtheEXPLAINPlanforPerformance
Tuningonpage602.
ExtendedEXPLAINoutput:
Forperformance tuningofcomplexqueries,andcapacityplanning(suchasusingtheadmission controlandresource
managementfeatures),youcanenablemoredetailedandinformativeoutputfortheEXPLAIN statement.Inthe
impala-shell interpreter,issuethecommandSET EXPLAIN_LEVEL= level,wherelevelisanintegerfrom0to3
orcorresponding mnemonic valuesminimal ,standard ,extended ,orverbose .
WhenextendedEXPLAIN outputisenabled,EXPLAIN statementsprintinformationaboutestimatedmemory
requirements,minimum numberofvirtualcores,andsoon.
StartinginCDH6.2/Impala3.2,iftheEXPLAIN_LEVEL optionissettoEXTENDED levelorVERBOSE ,theoutput
containsthefollowingadditional information.
â¢Theanalyzedquery,intheoutputheader.
Theanalyzedquerymayhavebeenrewrittentoincludevariousoptimizationsandimplicitcasts.Seetheexample
below.
â¢Thepredicatesintheplanoutputincludesthesameimplicitcastsandliteralsprintedwithacasttoshowthetype.
SeeEXPLAIN_LEVEL QueryOptiononpage331fordetailsandexamples.
Examples:
ThisexampleshowshowthestandardEXPLAIN outputmovesfromthelowest(physical)leveltothehigher(logical)
levels.Thequerybeginsbyscanningacertainamountofdata;eachnodeperformsanaggregationoperation(evaluating
COUNT(*) )onsomesubsetofdatathatislocaltothatnode;theintermediateresultsaretransmittedbacktothe
coordinatornode(labelledhereastheEXCHANGE node);lastly,theintermediateresultsaresummed todisplaythe
finalresult.
[impalad-host:21000] > explain select count(*) from customer_address;
+----------------------------------------------------------+
| Explain String                                           |
+----------------------------------------------------------+
| Estimated Per-Host Requirements: Memory=42.00MB VCores=1 |
|                                                          |
| 03:AGGREGATE [MERGE FINALIZE]                            |
| |  output: sum(count(*))                                 |
| |                                                        |
| 02:EXCHANGE [PARTITION=UNPARTITIONED]                    |
| |                                                        |
| 01:AGGREGATE                                             |
| |  output: count(*)                                      |
| |                                                        |
| 00:SCAN HDFS [default.customer_address]                  |
|    partitions=1/1 size=5.25MB                            |
+----------------------------------------------------------+
ThefollowingexampleshowsanextendedEXPLAIN output.Notethattheanalyzedquerywasrewrittentoinclude:
â¢The'constantfolding'optimization,whichsimplified theexpressionintheoriginalquery,'1000 / 100 'to'10'.
â¢TheimplicitcastsintheWHEREclause.
EXPLAIN SELECT * FROM functional_kudu.alltypestiny WHERE bigint_col < 1000 / 100;
+----------------------------------------------------------+
| Explain String                                           |
+----------------------------------------------------------+
| ...
| Analyzed query: SELECT * FROM mytable WHERE CAST(bigint_col AS DOUBLE) < CAST(10 AS 
272|ApacheImpalaGuideImpalaSQLLanguageReference
DOUBLE)
| ...
| 00:SCAN KUDU [functional_kudu.alltypestiny]
| predicates: CAST(bigint_col AS DOUBLE) < CAST(10 AS DOUBLE)
...
Securityconsiderations:
Ifthesestatementsinyourenvironmentcontainsensitiveliteralvaluessuchascreditcardnumbersortaxidentifiers,
Impalacanredactthissensitiveinformationwhendisplayingthestatementsinlogfilesandotheradministrative
contexts.Seehttp://www.cloudera.com/content/cloudera/en/documen tation/core/latest/topics/sg_redaction.h tml
fordetails.
Cancellation:Cannotbecancelled.
HDFSpermissions:
TheuserIDthattheimpalad daemonrunsunder,typicallytheimpalauser,musthavereadandexecutepermissions
forallapplicabledirectoriesinallsourcetablesforthequerythatisbeingexplained. (ASELECToperationcouldread
filesfrommultipledifferentHDFSdirectoriesifthesourcetableispartitioned.)
Kuduconsiderations:
TheEXPLAIN statementdisplaysequivalentplaninformationforqueriesagainstKudutablesasforqueriesagainst
HDFS-basedtables.
ToseewhichpredicatesImpalacanâpushdownâtoKuduforefficientevaluation,withouttransmittingunnecessar y
rowsbacktoImpala,lookforthekudu predicates iteminthescanphaseofthequery.Thelabelkudu predicates
indicatesaconditionthatcanbeevaluatedefficientlyontheKuduside.Thelabelpredicates inaSCAN KUDU node
indicatesaconditionthatisevaluatedbyImpala.Forexample,inatablewithprimarykeycolumnXandnon-primar y
keycolumnY,youcanseethatsomeoperatorsintheWHEREclauseareevaluatedimmediatelybyKuduandothers
areevaluatedlaterbyImpala:
EXPLAIN SELECT x,y from kudu_table WHERE
  x = 1 AND y NOT IN (2,3) AND z = 1
  AND a IS NOT NULL AND b > 0 AND length(s) > 5;
+----------------
| Explain String
+----------------
...
| 00:SCAN KUDU [kudu_table]
|    predicates: y NOT IN (2, 3), length(s) > 5
|    kudu predicates: a IS NOT NULL, b > 0, x = 1, z = 1
Onlybinarypredicates,IS NULL andIS NOT NULL (inCDH5.12andhigher),andINpredicatescontainingliteral
valuesthatexactlymatchthetypesintheKudutable,anddonotrequireanycasting,canbepushedtoKudu.
Relatedinformation:
SELECTStatementonpage295,INSERTStatementonpage277,CREATETABLEStatementonpage234,Understanding
ImpalaQueryPerformance -EXPLAINPlansandQueryProfilesonpage602
GRANTStatement(CDH5.2orhigheronly)
TheGRANTstatementgrantsaprivilegeonaspecified objecttoaroleorgrantsaroletoagroup.
Syntax:
GRANT ROLE role_name  TO GROUP group_name
GRANT privilege  ON object_type object_name
   TO [ROLE] roleName
   [WITH GRANT OPTION]
ApacheImpalaGuide|273ImpalaSQLLanguageReference
privilege ::= ALL | CREATE | INSERT | REFRESH | SELECT | SELECT( column_name )
object_type ::= SERVER | URI | DATABASE | TABLE
Typically,theobjectnameisanidentifier.ForURIs,itisastringliteral.
Requiredprivileges:
OnlySentryadministrativeusers,userswhobelongtothegroupsdefinedinsentry.service.admin.group ofthe
Sentryconfigurationcangrantrolestoagroup.
TheWITH GRANT OPTION clauseallowsmembersofthespecified roletoissueGRANTandREVOKEstatementsfor
thosesameprivileges.Hence,ifarolehastheALLprivilegeonadatabaseandtheWITH GRANT OPTION set,users
grantedthatrolecanexecuteGRANT/REVOKEstatementsonlyforthatdatabaseorchildtablesofthedatabase.This
meansausercouldrevoketheprivilegesoftheuserthatprovidedthemtheGRANT OPTION .
TheabilitytograntorrevokeSELECTprivilegeonspecificcolumnsisavailableinCDH5.5/Impala2.3andhigher.See
HiveSQLSyntaxforUsewithSentryfordetails.
Usagenotes:
YoucanonlygranttheALLprivilegetotheURIobject.Finer-grainedprivilegesmentionedbelowonaURIarenot
supported.
Thetablebelowliststheminimum levelofprivilegesandthescoperequiredtoexecuteSQLstatementsinCDH6.1/
CDH5.16andhigher.Thefollowingnotationsareused:
â¢ANYdenotestheSELECT,INSERT,CREATE,orREFRESH privilege.
â¢ALLprivilegedenotestheSELECT,INSERT,CREATE,andREFRESH privileges.
â¢TheownerofanobjecteffectivelyhastheALLprivilegeontheobject.
â¢Theparentlevelsofthespecified scopeareimplicitly supported.Forexample,ifaprivilegeislistedwiththeTABLE
scope,thesameprivilegegrantedonDATABASEandSERVERwillallowtheusertoexecutethatspecificSQL
statementonTABLE.
Scope Privileges SQLStatement
TABLE SELECT SELECT
TABLE SELECT WITHSELECT
TABLE SELECT EXPLAINSELECT
TABLE INSERT INSERT
TABLE INSERT EXPLAININSERT
TABLE INSERT TRUNCATE
TABLE INSERT LOAD
URI ALL
SERVER CREATE CREATEDATABASE
SERVER CREATE CREATEDATABASELOCATION
URI ALL
DATABASE CREATE CREATETABLE
DATABASE CREATE CREATETABLELIKE
TABLE SELECT,INSERT,orREFRESH
DATABASE CREATE CREATETABLEASSELECT
DATABASE INSERT
TABLE SELECT
274|ApacheImpalaGuideImpalaSQLLanguageReference
DATABASE CREATE EXPLAINCREATETABLEASSELECT
DATABASE INSERT
TABLE SELECT
TABLE CREATE CREATETABLELOCATION
URI ALL
DATABASE CREATE CREATEVIEW
TABLE SELECT
DATABASE ALLWITHGRANT ALTERDATABASESETOWNER
TABLE ALL ALTERTABLE
TABLE ALL ALTERTABLESETLOCATION
URI ALL
DATABASE CREATE ALTERTABLERENAME
TABLE ALL
TABLE ALLWITHGRANT ALTERTABLESETOWNER
TABLE ALL ALTERVIEW
TABLE SELECT
DATABASE CREATE ALTERVIEWRENAME
TABLE ALL
VIEW ALLWITHGRANT ALTERVIEWSETOWNER
DATABASE ALL DROPDATABASE
TABLE ALL DROPTABLE
TABLE ALL DROPVIEW
DATABASE CREATE CREATEFUNCTION
URI ALL
DATABASE ALL DROPFUNCTION
TABLE ALL COMPUTE STATS
TABLE ALL DROPSTATS
SERVER REFRESH INVALIDATEMETADATA
TABLE REFRESH INVALIDATEMETADATA<table>
TABLE REFRESH REFRESH<table>
SERVER REFRESH REFRESHAUTHORIZATION
DATABASE REFRESH REFRESHFUNCTIONS
DATABASE ALL COMMENT ONDATABASE
TABLE ALL COMMENT ONTABLE
TABLE ALL COMMENT ONVIEW
TABLE ALL COMMENT ONCOLUMN
ApacheImpalaGuide|275ImpalaSQLLanguageReference
DATABASE SELECT,INSERT,orREFRESH DESCRIBEDATABASE
TABLE SELECT,INSERT,orREFRESH DESCRIBE<table/view>
COLUMN SELECT IftheuserhastheSELECTprivilegeat
theCOLUMNlevel,onlythecolumns
theuserhasaccesswillshow.
TABLE ANY USE
TABLE ANY SHOWDATABASES
TABLE ANY SHOWTABLES
DATABASE SELECT,INSERT,orREFRESH SHOWFUNCTIONS
TABLE SELECT,INSERT,orREFRESH SHOWPARTITIONS
TABLE SELECT,INSERT,orREFRESH SHOWTABLESTATS
TABLE SELECT,INSERT,orREFRESH SHOWCOLUMNSTATS
TABLE SELECT,INSERT,orREFRESH SHOWFILES
TABLE SELECT,INSERT,orREFRESH SHOWCREATETABLE
TABLE SELECT,INSERT,orREFRESH SHOWCREATEVIEW
DATABASE SELECT,INSERT,orREFRESH SHOWCREATEFUNCTION
TABLE SELECT,INSERT,orREFRESH SHOWRANGEPARTITIONS(Kuduonly)
TABLE ALL UPDATE(Kuduonly)
TABLE ALL EXPLAINUPDATE(Kuduonly)
TABLE ALL UPSERT(Kuduonly)
TABLE ALL WITHUPSERT(Kuduonly)
TABLE ALL EXPLAINUPSERT(Kuduonly)
TABLE ALL DELETE(Kuduonly)
TABLE ALL EXPLAINDELETE(Kuduonly)
Compatibility:
â¢TheImpalaGRANTandREVOKEstatementsareavailableinCDH5.2/Impala2.0andlater.
â¢InCDH5.1/Impala1.4andlater,Impalacanmakeuseofanyrolesandprivilegesspecified bytheGRANTand
REVOKEstatementsinHive,whenyoursystemisconfiguredtousetheSentryserviceinsteadofthefile-based
policymechanism.
â¢TheImpalaGRANTandREVOKEstatementsforprivilegesdonotrequiretheROLEkeywordtoberepeatedbefore
eachrolename,unliketheequivalentHivestatements.
â¢Currently,eachImpalaGRANTorREVOKEstatementcanonlygrantorrevokeasingleprivilegetoorfromasingle
role.
Cancellation:Cannotbecancelled.
HDFSpermissions: ThisstatementdoesnottouchanyHDFSfilesordirectories,thereforenoHDFSpermissions are
required.
Kuduconsiderations:
AccesstoKudutablesmustbegrantedtoandrevokedfromroleswiththefollowingconsiderations:
â¢OnlyuserswiththeALLprivilegeonSERVERcancreateexternalKudutables.
276|ApacheImpalaGuideImpalaSQLLanguageReference
â¢TheALLprivilegesonSERVERisrequiredtospecifythekudu.master_addresses propertyintheCREATE
TABLEstatementsformanagedtablesaswellasexternaltables.
â¢AccesstoKudutablesisenforcedatthetablelevelandatthecolumnlevel.
â¢TheSELECT-andINSERT-specificpermissions aresupported.
â¢TheDELETE,UPDATE,andUPSERToperationsrequiretheALLprivilege.
Becausenon-SQLAPIscanaccessKududatawithoutgoingthroughSentryauthorization,currentlytheSentrysupport
isconsideredpreliminaryandsubjecttochange.
Relatedinformation:
EnablingSentryAuthorizationforImpalaonpage87,REVOKEStatement(CDH5.2orhigheronly)onpage293,CREATE
ROLEStatement(CDH5.2orhigheronly)onpage234,DROPROLEStatement(CDH5.2orhigheronly)onpage265,
SHOWStatementonpage363
INSERTStatement
Impalasupports inserting intotablesandpartitions thatyoucreatewiththeImpalaCREATE TABLE statement,or
pre-definedtablesandpartitions createdthroughHive.
Syntax:
[with_clause ]
  INSERT [hint_clause ] { INTO | OVERWRITE } [TABLE] table_name
  [(column_list )]
  [ PARTITION ( partition_clause )]
{
    [hint_clause ] select_statement
  | VALUES ( value [, value ...]) [, ( value [, value ...]) ...]
}
partition_clause ::= col_name  [= constant ] [, col_name  [= constant ] ...]
hint_clause ::=
hint_with_dashes  |
hint_with_cstyle_delimiters  |
hint_with_brackets
hint_with_dashes ::= -- +SHUFFLE | -- +NOSHUFFLE -- +CLUSTERED
hint_with_cstyle_comments ::= /* +SHUFFLE */ | /* +NOSHUFFLE */ | /* +CLUSTERED */
hint_with_brackets ::= [SHUFFLE] | [NOSHUFFLE]
  (With this hint format, the square brackets are part of the syntax.)
Note:Thesquarebracketstyleofhintisnowdeprecatedandmightberemovedinafuturerelease.
Forthatreason,anynewlyaddedhintsarenotavailablewiththesquarebracketsyntax.
Appending orreplacing(INTOandOVERWRITEclauses):
TheINSERT INTO syntaxappendsdatatoatable.Theexistingdatafilesareleftas-is,andtheinserteddataisput
intooneormorenewdatafiles.
TheINSERT OVERWRITE syntaxreplacesthedatainatable.Currently,theoverwrittendatafilesaredeleted
immediately;theydonotgothroughtheHDFStrashmechanism.
Complextypeconsiderations:
TheINSERTstatementcurrentlydoesnotsupportwritingdatafilescontainingcomplextypes(ARRAY,STRUCT,and
MAP).ToprepareParquetdataforsuchtables,yougeneratethedatafilesoutsideImpalaandthenuseLOAD DATA
orCREATE EXTERNAL TABLE toassociatethosedatafileswiththetable.Currently,suchtablesmustusetheParquet
fileformat.SeeComplexTypes(CDH5.5orhigheronly)onpage139fordetailsaboutworkingwithcomplextypes.
Kuduconsiderations:
ApacheImpalaGuide|277ImpalaSQLLanguageReference
Currently,theINSERT OVERWRITE syntaxcannotbeusedwithKudutables.
Kudutablesrequireauniqueprimarykeyforeachrow.IfanINSERTstatementattemptstoinsertarowwiththesame
valuesfortheprimarykeycolumnsasanexistingrow,thatrowisdiscardedandtheinsertoperationcontinues.When
rowsarediscardedduetoduplicateprimarykeys,thestatementfinisheswithawarning,notanerror.(Thisisachange
fromearlyreleasesofKuduwherethedefaultwastoreturninerrorinsuchcases,andthesyntaxINSERT IGNORE
wasrequiredtomakethestatementsucceed. TheIGNOREclauseisnolongerpartoftheINSERTsyntax.)
Forsituationswhereyouprefertoreplacerowswithduplicateprimarykeyvalues,ratherthandiscardingthenew
data,youcanusetheUPSERTstatementinsteadofINSERT.UPSERTinsertsrowsthatareentirelynew,andforrows
thatmatchanexistingprimarykeyinthetable,thenon-primar y-keycolumnsareupdatedtoreflectthevaluesinthe
âupsertedâdata.
Ifyoureallywanttostorenewrows,notreplaceexistingones,butcannotdosobecauseoftheprimarykeyuniqueness
constraint,considerrecreatingthetablewithadditional columnsincludedintheprimarykey.
SeeUsingImpalatoQueryKuduTablesonpage670formoredetailsaboutusingImpalawithKudu.
Usagenotes:
Impalacurrentlysupports:
â¢CopydatafromanothertableusingSELECTquery.InImpala1.2.1andhigher,youcancombineCREATE TABLE
andINSERToperationsintoasinglestepwiththeCREATE TABLE AS SELECT syntax,whichbypassestheactual
INSERTkeyword.
â¢AnoptionalWITHclausebeforetheINSERTkeyword,todefineasubqueryreferencedintheSELECTportion.
â¢CreateoneormorenewrowsusingconstantexpressionsthroughVALUESclause.(TheVALUESclausewasadded
inImpala1.0.1.)
â¢Bydefault,thefirstcolumnofeachnewlyinsertedrowgoesintothefirstcolumnofthetable,thesecondcolumn
intothesecondcolumn,andsoon.
Youcanalsospecifythecolumnstobeinserted,anarbitrarilyorderedsubsetofthecolumnsinthedestination
table,byspecifyingacolumnlistimmediatelyafterthenameofthedestinationtable.Thisfeatureletsyouadjust
theinsertedcolumnstomatchthelayoutofaSELECTstatement,ratherthantheotherwayaround.(Thisfeature
wasaddedinImpala1.1.)
Thenumberofcolumnsmentionedinthecolumnlist(knownastheâcolumnpermutationâ)mustmatchthe
numberofcolumnsintheSELECTlistortheVALUEStuples.Theorderofcolumnsinthecolumnpermutation
canbedifferentthanintheunderlying table,andthecolumnsofeachinputrowarereorderedtomatch.Ifthe
numberofcolumnsinthecolumnpermutationislessthaninthedestinationtable,allunmentionedcolumnsare
settoNULL.
â¢AnoptionalhintclauseimmediatelyeitherbeforetheSELECTkeywordoraftertheINSERTkeyword,tofine-tune
thebehaviorwhendoinganINSERT ... SELECT operationintopartitioned Parquettables.Thehintclause
cannotbespecified inmultipleplaces.Thehintkeywordsare[SHUFFLE] and[NOSHUFFLE] ,including thesquare
brackets.Inserting intopartitioned Parquettablescanbearesource-intensiveoperationbecauseitpotentially
involvesmanyfilesbeingwrittentoHDFSsimultaneously,andseparatelargememorybuffersbeingallocatedto
bufferthedataforeachpartition. Forusagedetails,seeLoadingDataintoParquetTablesonpage644.
Note:
â¢Insertcommands thatpartition oraddfilesresultinchangestoHivemetadata.BecauseImpala
usesHivemetadata,suchchangesmaynecessitateametadatarefresh.Formoreinformation,
seetheREFRESHfunction.
â¢Currently,ImpalacanonlyinsertdataintotablesthatusethetextandParquetformats.Forother
fileformats,insertthedatausingHiveanduseImpalatoqueryit.
â¢AsanalternativetotheINSERTstatement,ifyouhaveexistingdatafileselsewhereinHDFS,the
LOAD DATA statementcanmovethosefilesintoatable.Thisstatementworkswithtablesofany
fileformat.
278|ApacheImpalaGuideImpalaSQLLanguageReference
Statementtype:DML(butstillaffectedbySYNC_DDL queryoption)
Usagenotes:
Whenyouinserttheresultsofanexpression,particularly ofabuilt-infunctioncall,intoasmallnumericcolumnsuch
asINT,SMALLINT ,TINYINT,orFLOAT,youmightneedtouseaCAST()expressiontocoercevaluesintotheappropriate
type.Impaladoesnotautomaticallyconvertfromalargertypetoasmallerone.Forexample,toinsertcosinevalues
intoaFLOATcolumn,writeCAST(COS(angle) AS FLOAT) intheINSERTstatementtomaketheconversionexplicit.
Fileformatconsiderations:
BecauseImpalacanreadcertainfileformatsthatitcannotwrite,theINSERTstatementdoesnotworkforallkinds
ofImpalatables.SeeHowImpalaWorkswithHadoopFileFormatsonpage634fordetailsaboutwhatfileformatsare
supportedbytheINSERTstatement.
AnyINSERTstatementforaParquettablerequiresenoughfreespaceintheHDFSfilesystemtowriteoneblock.
BecauseParquetdatafilesuseablocksizeof1GBbydefault,anINSERTmightfail(evenforaverysmallamountof
data)ifyourHDFSisrunninglowonspace.
IfyouconnecttodifferentImpalanodeswithinanimpala-shell sessionforload-balancing purposes, youcanenable
theSYNC_DDL queryoptiontomakeeachDDLstatementwaitbeforereturning,untiltheneworchangedmetadata
hasbeenreceivedbyalltheImpalanodes.SeeSYNC_DDL QueryOptiononpage361fordetails.
Important:Afteraddingorreplacingdatainatableusedinperformance-critic alqueries,issuea
COMPUTE STATS statementtomakesureallstatisticsareup-to-date.Consider updatingstatisticsfor
atableafteranyINSERT,LOAD DATA ,orCREATE TABLE AS SELECT statementinImpala,orafter
loadingdatathroughHiveanddoingaREFRESH table_name inImpala.Thistechnique isespecially
importantfortablesthatareverylarge,usedinjoinqueries,orboth.
Examples:
ThefollowingexamplesetsupnewtableswiththesamedefinitionastheTAB1tablefromtheTutorialsection,using
differentfileformats,anddemonstratesinserting dataintothetablescreatedwiththeSTORED AS TEXTFILE and
STORED AS PARQUET clauses:
CREATE DATABASE IF NOT EXISTS file_formats;
USE file_formats;
DROP TABLE IF EXISTS text_table;
CREATE TABLE text_table
( id INT, col_1 BOOLEAN, col_2 DOUBLE, col_3 TIMESTAMP )
STORED AS TEXTFILE;
DROP TABLE IF EXISTS parquet_table;
CREATE TABLE parquet_table
( id INT, col_1 BOOLEAN, col_2 DOUBLE, col_3 TIMESTAMP )
STORED AS PARQUET;
WiththeINSERT INTO TABLE syntax,eachnewsetofinsertedrowsisappended toanyexistingdatainthetable.
Thisishowyouwouldrecordsmallamountsofdatathatarrivecontinuously,oringestnewbatchesofdataalongside
theexistingdata.Forexample,afterrunning2INSERT INTO TABLE statementswith5rowseach,thetablecontains
10rowstotal:
[localhost:21000] > insert into table text_table select * from default.tab1;
Inserted 5 rows in 0.41s
[localhost:21000] > insert into table text_table select * from default.tab1;
Inserted 5 rows in 0.46s
[localhost:21000] > select count(*) from text_table;
+----------+
| count(*) |
+----------+
| 10       |
ApacheImpalaGuide|279ImpalaSQLLanguageReference
+----------+
Returned 1 row(s) in 0.26s
WiththeINSERT OVERWRITE TABLE syntax,eachnewsetofinsertedrowsreplacesanyexistingdatainthetable.
Thisishowyouloaddatatoqueryinadatawarehousing scenariowhereyouanalyzejustthedataforaparticular day,
quarter,andsoon,discardingthepreviousdataeachtime.Youmightkeeptheentiresetofdatainonerawtable,and
transferandtransformcertainrowsintoamorecompactandefficientformtoperformintensiveanalysisonthat
subset.
Forexample,hereweinsert5rowsintoatableusingtheINSERT INTO clause,thenreplacethedatabyinserting 3
rowswiththeINSERT OVERWRITE clause.Afterward,thetableonlycontainsthe3rowsfromthefinalINSERT
statement.
[localhost:21000] > insert into table parquet_table select * from default.tab1;
Inserted 5 rows in 0.35s
[localhost:21000] > insert overwrite table parquet_table select * from default.tab1 
limit 3;
Inserted 3 rows in 0.43s
[localhost:21000] > select count(*) from parquet_table;
+----------+
| count(*) |
+----------+
| 3        |
+----------+
Returned 1 row(s) in 0.43s
TheVALUESclauseletsyouinsertoneormorerowsbyspecifyingconstantvaluesforallthecolumns.Thenumber,
types,andorderoftheexpressionsmustmatchthetabledefinition.
Note:TheINSERT ... VALUES technique isnotsuitableforloadinglargequantitiesofdatainto
HDFS-basedtables,becausetheinsertoperationscannotbeparallelized,andeachoneproducesa
separatedatafile.Useitforsettingupsmalldimension tablesortinyamountsofdataforexperimen ting
withSQLsyntax,orwithHBasetables.DonotuseitforlargeETLjobsorbenchmark testsforload
operations.Donotrunscriptswiththousands ofINSERT ... VALUES statementsthatinsertasingle
roweachtime.IfyoudorunINSERT ... VALUES operationstoloaddataintoastagingtableas
onestageinanETLpipeline,includemultiplerowvaluesifpossiblewithineachVALUESclause,and
useaseparatedatabasetomakecleanupeasieriftheoperationdoesproducemanytinyfiles.
Thefollowingexampleshowshowtoinsertonerowormultiplerows,withexpressionsofdifferenttypes,usingliteral
values,expressions,andfunctionreturnvalues:
create table val_test_1 (c1 int, c2 float, c3 string, c4 boolean, c5 timestamp);
insert into val_test_1 values (100, 99.9/10, 'abc', true, now());
create table val_test_2 (id int, token string);
insert overwrite val_test_2 values (1, 'a'), (2, 'b'), (-1,'xyzzy');
Theseexamplesshowthetypeofânotimplemen tedâerrorthatyouseewhenattemptingtoinsertdataintoatable
withafileformatthatImpalacurrentlydoesnotwriteto:
DROP TABLE IF EXISTS sequence_table;
CREATE TABLE sequence_table
( id INT, col_1 BOOLEAN, col_2 DOUBLE, col_3 TIMESTAMP )
STORED AS SEQUENCEFILE;
DROP TABLE IF EXISTS rc_table;
CREATE TABLE rc_table
( id INT, col_1 BOOLEAN, col_2 DOUBLE, col_3 TIMESTAMP )
STORED AS RCFILE;
[localhost:21000] > insert into table rc_table select * from default.tab1;
Remote error
Backend 0:RC_FILE not implemented.
280|ApacheImpalaGuideImpalaSQLLanguageReference
[localhost:21000] > insert into table sequence_table select * from default.tab1;
Remote error
Backend 0:SEQUENCE_FILE not implemented. 
Thefollowingexamplesshowhowyoucancopythedatainallthecolumnsfromonetabletoanother,copythedata
fromonlysomecolumns,orspecifythecolumnsintheselectlistinadifferentorderthantheyactuallyappearinthe
table:
-- Start with 2 identical tables.
create table t1 (c1 int, c2 int);
create table t2 like t1;
-- If there is no () part after the destination table name,
-- all columns must be specified, either as * or by name.
insert into t2 select * from t1;
insert into t2 select c1, c2 from t1;
-- With the () notation following the destination table name,
-- you can omit columns (all values for that column are NULL
-- in the destination table), and/or reorder the values
-- selected from the source table. This is the "column permutation" feature.
insert into t2 (c1) select c1 from t1;
insert into t2 (c2, c1) select c1, c2 from t1;
-- The column names can be entirely different in the source and destination tables.
-- You can copy any columns, not just the corresponding ones, from the source table.
-- But the number and type of selected columns must match the columns mentioned in the
 () part.
alter table t2 replace columns (x int, y int);
insert into t2 (y) select c1 from t1;
Sortingconsiderations:Although youcanspecifyanORDER BY clauseinanINSERT ... SELECT statement,any
ORDER BY clauseisignoredandtheresultsarenotnecessarily sorted.AnINSERT ... SELECT operationpotentially
createsmanydifferentdatafiles,preparedbydifferentexecutorImpaladaemons, andthereforethenotionofthe
databeingstoredinsortedorderisimpractical.
Concurrencyconsiderations:EachINSERToperationcreatesnewdatafileswithuniquenames,soyoucanrunmultiple
INSERT INTO statementssimultaneously withoutfilenameconflicts.WhiledataisbeinginsertedintoanImpalatable,
thedataisstagedtemporarilyinasubdirectoryinsidethedatadirectory;duringthisperiod,youcannotissuequeries
againstthattableinHive.IfanINSERToperationfails,thetemporarydatafileandthesubdirectorycouldbeleft
behindinthedatadirectory.Ifso,removetherelevantsubdirectoryandanydatafilesitcontainsmanually,byissuing
anhdfs dfs -rm -r command, specifyingthefullpathoftheworksubdirectory,whosenameendsin_dir.
VALUESClause
TheVALUESclauseisageneral-purpose waytospecifythecolumnsofoneormorerows,typicallywithinanINSERT
statement.
Note:TheINSERT ... VALUES technique isnotsuitableforloadinglargequantitiesofdatainto
HDFS-basedtables,becausetheinsertoperationscannotbeparallelized,andeachoneproducesa
separatedatafile.Useitforsettingupsmalldimension tablesortinyamountsofdataforexperimen ting
withSQLsyntax,orwithHBasetables.DonotuseitforlargeETLjobsorbenchmark testsforload
operations.Donotrunscriptswiththousands ofINSERT ... VALUES statementsthatinsertasingle
roweachtime.IfyoudorunINSERT ... VALUES operationstoloaddataintoastagingtableas
onestageinanETLpipeline,includemultiplerowvaluesifpossiblewithineachVALUESclause,and
useaseparatedatabasetomakecleanupeasieriftheoperationdoesproducemanytinyfiles.
Thefollowingexamplesillustrate:
â¢HowtoinsertasinglerowusingaVALUESclause.
â¢HowtoinsertmultiplerowsusingaVALUESclause.
ApacheImpalaGuide|281ImpalaSQLLanguageReference
â¢HowtheroworrowsfromaVALUESclausecanbeappended toatablethroughINSERT INTO ,orreplacethe
contentsofthetablethroughINSERT OVERWRITE .
â¢HowtheentriesinaVALUESclausecanbeliterals,functionresults,oranyotherkindofexpression.SeeLiterals
onpage167forthenotationtouseforliteralvalues,especially StringLiteralsonpage168forquotingandescaping
conventionsforstrings.SeeSQLOperatorsonpage171andImpalaBuilt-InFunctions onpage391forotherthings
youcanincludeinexpressionswiththeVALUESclause.
[localhost:21000] > describe val_example;
Query: describe val_example
Query finished, fetching results ...
+-------+---------+---------+
| name  | type    | comment |
+-------+---------+---------+
| id    | int     |         |
| col_1 | boolean |         |
| col_2 | double  |         |
+-------+---------+---------+
[localhost:21000] > insert into val_example values (1,true,100.0);
Inserted 1 rows in 0.30s
[localhost:21000] > select * from val_example;
+----+-------+-------+
| id | col_1 | col_2 |
+----+-------+-------+
| 1  | true  | 100   |
+----+-------+-------+
[localhost:21000] > insert overwrite val_example values (10,false,pow(2,5)), 
(50,true,10/3);
Inserted 2 rows in 0.16s
[localhost:21000] > select * from val_example;
+----+-------+-------------------+
| id | col_1 | col_2             |
+----+-------+-------------------+
| 10 | false | 32                |
| 50 | true  | 3.333333333333333 |
+----+-------+-------------------+
WhenusedinanINSERTstatement,theImpalaVALUESclausecanspecifysomeorallofthecolumnsinthedestination
table,andthecolumnscanbespecified inadifferentorderthantheyactuallyappearinthetable.Tospecifyadifferent
setororderofcolumnsthaninthetable,usethesyntax:
INSERT INTO destination
  (col_x, col_y, col_z)
  VALUES
  (val_x, val_y, val_z);
AnycolumnsinthetablethatarenotlistedintheINSERTstatementaresettoNULL.
HDFSconsiderations:
Impalaphysicallywritesallinsertedfilesundertheownershipofitsdefaultuser,typicallyimpala.Therefore,thisuser
musthaveHDFSwritepermission inthecorresponding tabledirectory.
Thepermission requirementisindependen toftheauthorizationperformedbytheSentryframework.(Iftheconnected
userisnotauthorizedtoinsertintoatable,Sentryblocksthatoperationimmediately,regardlessoftheprivileges
availabletotheimpalauser.)FilescreatedbyImpalaarenotownedbyanddonotinheritpermissions fromthe
connecteduser.
ThenumberofdatafilesproducedbyanINSERTstatementdependsonthesizeofthecluster,thenumberofdata
blocksthatareprocessed,thepartitionkeycolumnsinapartitioned table,andthemechanism Impalausesfordividing
theworkinparallel.DonotassumethatanINSERTstatementwillproducesomeparticular numberofoutputfiles.
Incaseofperformance issueswithdatawrittenbyImpala,checkthattheoutputfilesdonotsufferfromissuessuch
asmanytinyfilesormanytinypartitions. (IntheHadoopcontext,evenfilesorpartitions ofafewtensofmegabytes
areconsideredâtinyâ.)
282|ApacheImpalaGuideImpalaSQLLanguageReference
TheINSERTstatementhasalwaysleftbehindahiddenworkdirectoryinsidethedatadirectoryofthetable.Formerly,
thishiddenworkdirectorywasnamed.impala_insert_staging .InImpala2.0.1andlater,thisdirectorynameis
changedto_impala_insert_staging .(WhileHDFStoolsareexpectedtotreatnamesbeginning eitherwith
underscoreanddotashidden,inpracticenamesbeginning withanunderscorearemorewidelysupported.)Ifyou
haveanyscripts,cleanupjobs,andsoonthatrelyonthenameofthisworkdirectory,adjustthemtousethenew
name.
HBaseconsiderations:
YoucanusetheINSERTstatementwithHBasetablesasfollows:
â¢YoucaninsertasingleroworasmallsetofrowsintoanHBasetablewiththeINSERT ... VALUES syntax.This
isagoodusecaseforHBasetableswithImpala,becauseHBasetablesarenotsubjecttothesamekindof
fragmentationfrommanysmallinsertoperationsasHDFStablesare.
â¢YoucaninsertanynumberofrowsatonceintoanHBasetableusingtheINSERT ... SELECT syntax.
â¢IfmorethanoneinsertedrowhasthesamevaluefortheHBasekeycolumn,onlythelastinsertedrowwiththat
valueisvisibletoImpalaqueries.YoucantakeadvantageofthisfactwithINSERT ... VALUES statementsto
effectivelyupdaterowsoneatatime,byinserting newrowswiththesamekeyvaluesasexistingrows.Beaware
thatafteranINSERT ... SELECT operationcopyingfromanHDFStable,theHBasetablemightcontainfewer
rowsthanwereinserted,ifthekeycolumninthesourcetablecontainedduplicatevalues.
â¢YoucannotINSERT OVERWRITE intoanHBasetable.Newrowsarealwaysappended.
â¢WhenyoucreateanImpalaorHivetablethatmapstoanHBasetable,thecolumnorderyouspecifywiththe
INSERTstatementmightbedifferentthantheorderyoudeclarewiththeCREATE TABLE statement.Behindthe
scenes,HBasearrangesthecolumnsbasedonhowtheyaredividedintocolumnfamilies.Thismightcausea
mismatchduringinsertoperations,especially ifyouusethesyntaxINSERT INTO hbase_table  SELECT *
FROM hdfs_table .Beforeinsertingdata,verifythecolumnorderbyissuingaDESCRIBE statementforthetable,
andadjusttheorderoftheselectlistintheINSERTstatement.
SeeUsingImpalatoQueryHBaseTablesonpage684formoredetailsaboutusingImpalawithHBase.
AmazonS3considerations:
InCDH5.8/Impala2.6andhigher,theImpalaDMLstatements(INSERT,LOAD DATA ,andCREATE TABLE AS
SELECT)canwritedataintoatableorpartition thatresidesintheAmazonSimpleStorageService(S3).Thesyntaxof
theDMLstatementsisthesameasforanyothertables,becausetheS3locationfortablesandpartitions isspecified
byans3a://prefixintheLOCATION attributeofCREATE TABLE orALTER TABLE statements.Ifyoubringdatainto
S3usingthenormalS3transfermechanisms insteadofImpalaDMLstatements,issueaREFRESH statementforthe
tablebeforeusingImpalatoquerytheS3data.
BecauseofdifferencesbetweenS3andtraditional filesystems,DMLoperationsforS3tablescantakelongerthanfor
tablesonHDFS.Forexample,boththeLOAD DATA statementandthefinalstageoftheINSERTandCREATE TABLE
AS SELECT statementsinvolvemovingfilesfromonedirectorytoanother.(InthecaseofINSERTandCREATE TABLE
AS SELECT ,thefilesaremovedfromatemporarystagingdirectorytothefinaldestinationdirectory.)BecauseS3
doesnotsupportaârenameâoperationforexistingobjects,inthesecasesImpalaactuallycopiesthedatafilesfrom
onelocationtoanotherandthenremovestheoriginalfiles.InCDH5.8/Impala2.6,theS3_SKIP_INSERT_STAGING
queryoptionprovidesawaytospeedupINSERTstatementsforS3tablesandpartitions, withthetradeoffthata
problemduringstatementexecutioncouldleavedatainaninconsistentstate.ItdoesnotapplytoINSERT OVERWRITE
orLOAD DATA statements.SeeS3_SKIP_INSER T_STAGINGQueryOption(CDH5.8orhigheronly)onpage358for
details.
SeeUsingImpalawiththeAmazonS3Filesystemonpage692fordetailsaboutreadingandwritingS3datawithImpala.
ADLSconsiderations:
InCDH5.12/Impala2.9andhigher,theImpalaDMLstatements(INSERT,LOAD DATA ,andCREATE TABLE AS
SELECT)canwritedataintoatableorpartitionthatresidesintheAzureDataLakeStore(ADLS).ADLSGen2issupported
inCDH6.1andhigher.
ApacheImpalaGuide|283ImpalaSQLLanguageReference
IntheCREATE TABLE orALTER TABLE statements,specifytheADLSlocationfortablesandpartitions withtheadl://
prefixforADLSGen1andabfs:// orabfss:// forADLSGen2intheLOCATION attribute.
IfyoubringdataintoADLSusingthenormalADLStransfermechanisms insteadofImpalaDMLstatements,issuea
REFRESH statementforthetablebeforeusingImpalatoquerytheADLSdata.
SeeUsingImpalawiththeAzureDataLakeStore(ADLS)onpage701fordetailsaboutreadingandwritingADLSdata
withImpala.
Securityconsiderations:
Ifthesestatementsinyourenvironmentcontainsensitiveliteralvaluessuchascreditcardnumbersortaxidentifiers,
Impalacanredactthissensitiveinformationwhendisplayingthestatementsinlogfilesandotheradministrative
contexts.Seehttp://www.cloudera.com/content/cloudera/en/documen tation/core/latest/topics/sg_redaction.h tml
fordetails.
Cancellation:Canbecancelled. Tocancelthisstatement,useCtrl-Cfromtheimpala-shell interpreter,theCancel
buttonfromtheWatchpageinHue,Actions>CancelfromtheQuerieslistinClouderaManager,orCancelfromthe
listofin-flightqueries(foraparticular node)ontheQueriestabintheImpalawebUI(port25000).
HDFSpermissions:
TheuserIDthattheimpalad daemonrunsunder,typicallytheimpalauser,musthavereadpermission forthefiles
inthesourcedirectoryofanINSERT ... SELECT operation,andwritepermission forallaffecteddirectoriesinthe
destinationtable.(AnINSERToperationcouldwritefilestomultipledifferentHDFSdirectoriesifthedestinationtable
ispartitioned.) Thisusermustalsohavewritepermission tocreateatemporaryworkdirectoryinthetop-levelHDFS
directoryofthedestinationtable.AnINSERT OVERWRITE operationdoesnotrequirewritepermission ontheoriginal
datafilesinthetable,onlyonthetabledirectoriesthemselves.
Restrictions:
ForINSERToperationsintoCHARorVARCHAR columns,youmustcastallSTRINGliteralsorexpressionsreturning
STRINGtotoaCHARorVARCHAR typewiththeappropriatelength.
Relatedstartupoptions:
Bydefault,ifanINSERTstatementcreatesanynewsubdirectoriesundernea thapartitioned table,thosesubdirectories
areassigneddefaultHDFSpermissions fortheimpalauser.Tomakeeachsubdirectoryhavethesamepermissions
asitsparentdirectoryinHDFS,specifythe--insert_inherit_permissions startupoptionfortheimpalad
daemon.
Inserting IntoPartitioned TableswithPARTITIONClause
Forapartitioned table,theoptionalPARTITION clauseidentifieswhichpartition orpartitions thevaluesareinserted
into.
Allexamplesinthissectionwillusethetabledeclaredasbelow:
CREATE TABLE t1 (w INT) PARTITIONED BY (x INT, y STRING);
StaticPartitionInserts
Inastaticpartition insertwhereapartition keycolumnisgivenaconstantvalue,suchasPARTITION (year=2012,
month=2) ,therowsareinsertedwiththesamevaluesspecified forthosepartition keycolumns.
ThenumberofcolumnsintheSELECTlistmustequalthenumberofcolumnsinthecolumnpermutation.
ThePARTITION clausemustbeusedforstaticpartitioning inserts.
Example:
284|ApacheImpalaGuideImpalaSQLLanguageReference
Thefollowingstatementwillinsertthesome_other_table.c1 valuesforthewcolumn,andalltherowsinserted
willhavethesamexvalueof10,andthesameyvalueofâaâ.
INSERT INTO t1 PARTITION (x=10, y='a')
            SELECT c1 FROM some_other_table;
DynamicPartitionInserts
Inadynamicpartition insertwhereapartition keycolumnisintheINSERTstatementbutnotassignedavalue,such
asinPARTITION (year, region) (bothcolumnsunassigned) orPARTITION(year, region='CA') (yearcolumn
unassigned), theunassigned columnsarefilledinwiththefinalcolumnsoftheSELECTorVALUESclause.Inthiscase,
thenumberofcolumnsintheSELECTlistmustequalthenumberofcolumnsinthecolumnpermutationplusthe
numberofpartition keycolumnsnotassignedaconstantvalue.
SeeStaticandDynamicPartitioning Clausesforexamplesandperformance characteristicsofstaticanddynamic
partitioned inserts.
Thefollowingrulesapplytodynamicpartition inserts.
â¢ThecolumnsareboundintheordertheyappearintheINSERTstatement.
ThetablebelowshowsthevaluesinsertedwiththeINSERTstatementsofdifferentcolumnorders.
ColumnyValue ColumnxValue ColumnwValue
âcâ 2 1 INSERT INTO t1 (w, x,
y) VALUES (1, 2,
'c');
âcâ 1 2 INSERT INTO t1 (x,w)
PARTITION (y) VALUES
(1, 2, 'c');
â¢Whenapartitionclauseisspecified butthenon-partition columnsarenotspecified intheINSERTstatement,as
inthefirstexamplebelow,thenon-partition columnsaretreatedasthoughtheyhadbeenspecified beforethe
PARTITION clauseintheSQL.
Example:Thesethreestatementsareequivalent,inserting1tow,2tox,andâcâtoycolumns.
INSERT INTO t1 PARTITION (x,y) VALUES (1, 2, âcâ);
INSERT INTO t1 (w) PARTITION (x, y) VALUES (1, 2, âcâ);
INSERT INTO t1 PARTITION (x, y='c') VALUES (1, 2);
â¢ThePARTITION clauseisnotrequiredfordynamicpartition, butallthepartition columnsmustbeexplicitly
presentintheINSERTstatementinthecolumnlistorinthePARTITION clause.Thepartition columnscannot
bedefaultedtoNULL.
Example:
Thefollowingstatementsarevalidbecausethepartitioncolumns,xandy,arepresentintheINSERTstatements,
eitherinthePARTITION clauseorinthecolumnlist.
INSERT INTO t1 PARTITION (x,y) VALUES (1, 2, âcâ);
INSERT INTO t1 (w, x) PARTITION (y) VALUES (1, 2, âcâ);
Thefollowingstatementisnotvalidforthepartitioned tableasdefinedabovebecausethepartition columns,x
andy,arenotpresentintheINSERTstatement.
INSERT INTO t1 VALUES (1, 2, 'c');
â¢Ifpartition columnsdonotexistinthesourcetable,youcanspecifyaspecificvalueforthatcolumninthe
PARTITION clause.
ApacheImpalaGuide|285ImpalaSQLLanguageReference
Example:Thesourcetableonlycontainsthecolumnwandy.Thevalue,20,specified inthePARTITION clause,
isinsertedintothexcolumn.
INSERT INTO t1 PARTITION (x=20, y) SELECT * FROM source;
INVALIDATEMETADATAStatement
TheINVALIDATE METADATA statementmarksthemetadataforoneoralltablesasstale.ThenexttimetheImpala
serviceperformsaqueryagainstatablewhosemetadataisinvalidated,Impalareloadstheassociatedmetadatabefore
thequeryproceeds.Asthisisaveryexpensiveoperationcomparedtotheincrementalmetadataupdatedonebythe
REFRESH statement,whenpossible, preferREFRESH ratherthanINVALIDATE METADATA .
INVALIDATE METADATA isrequiredwhenthefollowingchangesaremadeoutsideofImpala,inHiveandotherHive
client,suchasSparkSQL:
â¢Metadataofexistingtableschanges.
â¢Newtablesareadded,andImpalawillusethetables.
â¢TheSERVERorDATABASE levelSentryprivilegesarechangedfromoutsideofImpala.
â¢Blockmetadatachanges,butthefilesremainthesame(HDFSrebalance).
â¢UDFjarschange.
â¢Sometablesarenolongerqueried,andyouwanttoremovetheirmetadatafromthecatalogandcoordinator
cachestoreducememoryrequirements.
NoINVALIDATE METADATA isneededwhenthechangesaremadebyimpalad .
SeeOverviewofImpalaMetadataandtheMetastoreonpage22fortheinformationaboutthewayImpalauses
metadataandhowitsharesthesamemetastoredatabaseasHive.
Onceissued,theINVALIDATE METADATA statementcannotbecancelled.
Syntax:
INVALIDATE METADATA [[ db_name.]table_name ]
Ifthereisnotablespecified, thecachedmetadataforalltablesisflushedandsyncedwithHiveMetastore(HMS).If
tablesweredroppedfromtheHMS,theywillberemovedfromthecatalog,andifnewtableswereadded,theywill
showupinthecatalog.
Ifyouspecifyatablename,onlythemetadataforthatonetableisflushedandsyncedwiththeHMS.
Usagenotes:
Toreturnaccuratequeryresults,Impalaneedtokeepthemetadatacurrentforthedatabasesandtablesqueried.
Therefore,ifsomeotherentitymodifiesinformationusedbyImpalainthemetastore,theinformationcachedby
ImpalamustbeupdatedviaINVALIDATE METADATA orREFRESH .
INVALIDATE METADATA andREFRESH arecounterparts:
â¢INVALIDATE METADATA isanasynchronousoperationthatsimplydiscardstheloadedmetadatafromthecatalog
andcoordinatorcaches.Afterthatoperation,thecatalogandalltheImpalacoordinatorsknowonlyaboutthe
existenceofdatabasesandtables,nothingmore.Metadataloadingfortablesistriggeredbyanysubsequent
queries.
â¢REFRESH reloadsthemetadatainsyncwiththecoordinatorexecutingthestatement.SettheImpalaSYNC_DLL
optiontotruetoachieveafullysynchronousmetadatareload.REFRESH performsalightweightreloading,not
thefullmetadatareloadingthatoccursafteratablehasbeeninvalidated.REFRESH cannotdetectchangesin
blocklocationstriggeredbyoperationslikeHDFSbalancer,whichcancauseremotereadsduringqueryexecution
thatimpactperformance.
UseREFRESH afterinvalidatingaspecifictabletoseparatethemetadataloadfromthefirstquerythat'srunagainst
thattable.
Examples:
286|ApacheImpalaGuideImpalaSQLLanguageReference
ThisexampleillustratescreatinganewdatabaseandnewtableinHive,thendoinganINVALIDATE METADATA
statementinImpalausingthefullyqualified tablename,afterwhichboththenewtableandthenewdatabaseare
visibletoImpala.
BeforetheINVALIDATE METADATA statementwasissued,Impalawouldgiveaânotfoundâerrorifyoutriedtorefer
tothosedatabaseortablenames.
$ hive
hive> CREATE DATABASE new_db_from_hive;
hive> CREATE TABLE new_db_from_hive.new_table_from_hive (x INT);
hive> quit;
$ impala-shell
> REFRESH new_db_from_hive.new_table_from_hive;
ERROR: AnalysisException: Database does not exist: new_db_from_hive
> INVALIDATE METADATA new_db_from_hive.new_table_from_hive;
> SHOW DATABASES LIKE 'new*';
+--------------------+
| new_db_from_hive   |
+--------------------+
> SHOW TABLES IN new_db_from_hive;
+---------------------+
| new_table_from_hive |
+---------------------+
UsetheREFRESH statementforincrementalmetadataupdate.
> REFRESH new_table_from_hive;
FormoreexamplesofusingINVALIDATE METADATA withacombinationofImpalaandHiveoperations,seeSwitching
BackandForthBetweenImpalaandHiveonpage56.
HDFSconsiderations:
Bydefault,theINVALIDATE METADATA command checksHDFSpermissions oftheunderlying datafilesanddirectories,
cachingthisinformationsothatastatementcanbecancelledimmediatelyifforexampletheimpalauserdoesnot
havepermission towritetothedatadirectoryforthetable.(Thischecking doesnotapplywhenthecatalogd
configurationoption--load_catalog_in_background issettofalse,whichitisbydefault.)Impalareportsany
lackofwritepermissions asanINFOmessageinthelogfile.
IfyouchangeHDFSpermissions tomakedatareadableorwriteablebytheImpalauser,issueanotherINVALIDATE
METADATA tomakeImpalaawareofthechange.
Kuduconsiderations:
Bydefault,muchofthemetadataforKudutablesishandledbytheunderlying storagelayer.Kudutableshaveless
relianceontheMetastoredatabase,andrequirelessmetadatacachingontheImpalaside.Forexample,information
aboutpartitions inKudutablesismanagedbyKudu,andImpaladoesnotcacheanyblocklocalitymetadataforKudu
tables.IftheKuduserviceisnotintegratedwiththeHiveMetastore,ImpalawillmanageKudutablemetadatainthe
HiveMetastore.
TheREFRESH andINVALIDATE METADATA statementsareneededlessfrequentlyforKudutablesthanforHDFS-backed
tables.Neitherstatementisneededwhendataisaddedto,removed,orupdatedinaKudutable,evenifthechanges
aremadedirectlytoKuduthroughaclientprogramusingtheKuduAPI.RunREFRESH table_name orINVALIDATE
METADATA table_name foraKudutableonlyaftermakingachangetotheKudutableschema,suchasaddingor
droppingacolumn.
Relatedinformation:
OverviewofImpalaMetadataandtheMetastoreonpage22,REFRESHStatementonpage291
ApacheImpalaGuide|287ImpalaSQLLanguageReference
LOADDATAStatement
TheLOAD DATA statementstreamlines theETLprocessforaninternalImpalatablebymovingadatafileorallthe
datafilesinadirectoryfromanHDFSlocationintotheImpaladatadirectoryforthattable.
Syntax:
LOAD DATA INPATH ' hdfs_file_or_directory_path ' [OVERWRITE] INTO TABLE tablename
  [PARTITION ( partcol1 =val1, partcol2 =val2 ...)]
WhentheLOAD DATA statementoperatesonapartitioned table,italwaysoperatesononepartitionatatime.Specify
thePARTITION clausesandlistallthepartition keycolumns,withaconstantvaluespecified foreach.
Statementtype:DML(butstillaffectedbySYNC_DDL queryoption)
Usagenotes:
â¢Theloadeddatafilesaremoved,notcopied,intotheImpaladatadirectory.
â¢YoucanspecifytheHDFSpathofasinglefiletobemoved,ortheHDFSpathofadirectorytomoveallthefiles
insidethatdirectory.Youcannotspecifyanysortofwildcardtotakeonlysomeofthefilesfromadirectory.When
loadingadirectoryfullofdatafiles,keepallthedatafilesatthetoplevel,withnonesteddirectoriesundernea th.
â¢Currently,theImpalaLOAD DATA statementonlyimportsfilesfromHDFS,notfromthelocalfilesystem.Itdoes
notsupporttheLOCALkeywordoftheHiveLOAD DATA statement.Youmustspecifyapath,notanhdfs://
URI.
â¢Intheinterestofspeed,onlylimitederrorcheckingisdone.Iftheloadedfileshavethewrongfileformat,different
columnsthanthedestinationtable,orotherkindofmismatch,ImpaladoesnotraiseanyerrorfortheLOAD DATA
statement.Queryingthetableafterwardcouldproducearuntimeerrororunexpectedresults.Currently,theonly
checking theLOAD DATA statementdoesistoavoidmixingtogetheruncompressedandLZO-compressedtext
filesinthesametable.
â¢WhenyouspecifyanHDFSdirectorynameastheLOAD DATA argument,anyhiddenfilesinthatdirectory(files
whosenamesstartwitha.)arenotmovedtotheImpaladatadirectory.
â¢Theoperationfailsifthesourcedirectorycontainsanynon-hidden directories.PriortoCDH5.7/Impala2.5ifthe
sourcedirectorycontainedanysubdirectory,evenahiddenonesuchas_impala_insert_staging ,theLOAD
DATAstatementwouldfail.InCDH5.7/Impala2.5andhigher,LOAD DATA ignoreshiddensubdirectoriesinthe
sourcedirectory,andonlyfailsifanyofthesubdirectoriesarenon-hidden.
â¢Theloadeddatafilesretaintheiroriginalnamesinthenewlocation,unlessanameconflictswithanexistingdata
file,inwhichcasethenameofthenewfileismodified slightlytobeunique.(Thename-mangling isaslight
differencefromtheHiveLOAD DATA statement,whichreplacesidenticallynamedfiles.)
â¢ByprovidinganeasywaytotransportfilesfromknownlocationsinHDFSintotheImpaladatadirectorystructure,
theLOAD DATA statementletsyouavoidmemorizing thelocationsandlayoutofHDFSdirectorytreecontaining
theImpaladatabasesandtables.(ForaquickwaytocheckthelocationofthedatafilesforanImpalatable,issue
thestatementDESCRIBE FORMATTED table_name .)
â¢ThePARTITION clauseisespecially convenientforingestingnewdataforapartitioned table.Asyoureceivenew
dataforatimeperiod,geographicregion,orotherdivisionthatcorrespondstooneormorepartitioning columns,
youcanloadthatdatastraightintotheappropriateImpaladatadirectory,whichmightbenestedseverallevels
downifthetableispartitioned bymultiplecolumns.Whenthetableispartitioned, youmustspecifyconstant
valuesforallthepartitioning columns.
Complextypeconsiderations:
BecauseImpalacurrentlycannotcreateParquetdatafilescontainingcomplextypes(ARRAY,STRUCT,andMAP),the
LOAD DATA statementisespecially importantwhenworkingwithtablescontainingcomplextypecolumns.Youcreate
theParquetdatafilesoutsideImpala,thenuseeitherLOAD DATA ,anexternaltable,orHDFS-levelfileoperations
followedbyREFRESH toassociatethedatafileswiththecorresponding table.SeeComplexTypes(CDH5.5orhigher
only)onpage139fordetailsaboutusingcomplextypes.
IfyouconnecttodifferentImpalanodeswithinanimpala-shell sessionforload-balancing purposes, youcanenable
theSYNC_DDL queryoptiontomakeeachDDLstatementwaitbeforereturning,untiltheneworchangedmetadata
hasbeenreceivedbyalltheImpalanodes.SeeSYNC_DDL QueryOptiononpage361fordetails.
288|ApacheImpalaGuideImpalaSQLLanguageReference
Important:Afteraddingorreplacingdatainatableusedinperformance-critic alqueries,issuea
COMPUTE STATS statementtomakesureallstatisticsareup-to-date.Consider updatingstatisticsfor
atableafteranyINSERT,LOAD DATA ,orCREATE TABLE AS SELECT statementinImpala,orafter
loadingdatathroughHiveanddoingaREFRESH table_name inImpala.Thistechnique isespecially
importantfortablesthatareverylarge,usedinjoinqueries,orboth.
Examples:
First,weuseatrivialPythonscripttowritedifferentnumbersofstrings(oneperline)intofilesstoredinthedoc_demo
HDFSuseraccount.(SubstitutethepathforyourownHDFSuseraccountwhendoinghdfs dfs operationslikethese.)
random_strings.py 1000 | hdfs dfs -put - /user/doc_demo/thousand_strings.txt
random_strings.py 100 | hdfs dfs -put - /user/doc_demo/hundred_strings.txt
random_strings.py 10 | hdfs dfs -put - /user/doc_demo/ten_strings.txt
Next,wecreateatableandloadaninitialsetofdataintoit.Remember ,unlessyouspecifyaSTORED AS clause,Impala
tablesdefaulttoTEXTFILE formatwithCtrl-A(hex01)asthefielddelimiter.Thisexampleusesasingle-columntable,
sothedelimiterisnotsignificant.Forlarge-scaleETLjobs,youwouldtypicallyusebinaryformatdatafilessuchas
ParquetorAvro,andloadthemintoImpalatablesthatusethecorresponding fileformat.
[localhost:21000] > create table t1 (s string);
[localhost:21000] > load data inpath '/user/doc_demo/thousand_strings.txt' into table 
t1;
Query finished, fetching results ...
+----------------------------------------------------------+
| summary                                                  |
+----------------------------------------------------------+
| Loaded 1 file(s). Total files in destination location: 1 |
+----------------------------------------------------------+
Returned 1 row(s) in 0.61s
[kilo2-202-961.cs1cloud.internal:21000] > select count(*) from t1;
Query finished, fetching results ...
+------+
| _c0  |
+------+
| 1000 |
+------+
Returned 1 row(s) in 0.67s
[localhost:21000] > load data inpath '/user/doc_demo/thousand_strings.txt' into table 
t1;
ERROR: AnalysisException: INPATH location '/user/doc_demo/thousand_strings.txt' does 
not exist. 
Asindicatedbythemessageattheendofthepreviousexample,thedatafilewasmovedfromitsoriginallocation.
ThefollowingexampleillustrateshowthedatafilewasmovedintotheImpaladatadirectoryforthedestinationtable,
keepingitsoriginalfilename:
$ hdfs dfs -ls /user/hive/warehouse/load_data_testing.db/t1
Found 1 items
-rw-r--r--   1 doc_demo doc_demo      13926 2013-06-26 15:40 
/user/hive/warehouse/load_data_testing.db/t1/thousand_strings.txt
ThefollowingexampledemonstratesthedifferencebetweentheINTO TABLE andOVERWRITE TABLE clauses.The
tablealreadycontains1000rows.AfterissuingtheLOAD DATA statementwiththeINTO TABLE clause,thetable
contains100morerows,foratotalof1100.AfterissuingtheLOAD DATA statementwiththeOVERWRITE INTO
TABLEclause,theformercontentsaregone,andnowthetableonlycontainsthe10rowsfromthejust-loadeddata
file.
[localhost:21000] > load data inpath '/user/doc_demo/hundred_strings.txt' into table 
t1;
Query finished, fetching results ...
+----------------------------------------------------------+
| summary                                                  |
+----------------------------------------------------------+
ApacheImpalaGuide|289ImpalaSQLLanguageReference
| Loaded 1 file(s). Total files in destination location: 2 |
+----------------------------------------------------------+
Returned 1 row(s) in 0.24s
[localhost:21000] > select count(*) from t1;
Query finished, fetching results ...
+------+
| _c0  |
+------+
| 1100 |
+------+
Returned 1 row(s) in 0.55s
[localhost:21000] > load data inpath '/user/doc_demo/ten_strings.txt' overwrite into 
table t1;
Query finished, fetching results ...
+----------------------------------------------------------+
| summary                                                  |
+----------------------------------------------------------+
| Loaded 1 file(s). Total files in destination location: 1 |
+----------------------------------------------------------+
Returned 1 row(s) in 0.26s
[localhost:21000] > select count(*) from t1;
Query finished, fetching results ...
+-----+
| _c0 |
+-----+
| 10  |
+-----+
Returned 1 row(s) in 0.62s
AmazonS3considerations:
InCDH5.8/Impala2.6andhigher,theImpalaDMLstatements(INSERT,LOAD DATA ,andCREATE TABLE AS
SELECT)canwritedataintoatableorpartition thatresidesintheAmazonSimpleStorageService(S3).Thesyntaxof
theDMLstatementsisthesameasforanyothertables,becausetheS3locationfortablesandpartitions isspecified
byans3a://prefixintheLOCATION attributeofCREATE TABLE orALTER TABLE statements.Ifyoubringdatainto
S3usingthenormalS3transfermechanisms insteadofImpalaDMLstatements,issueaREFRESH statementforthe
tablebeforeusingImpalatoquerytheS3data.
BecauseofdifferencesbetweenS3andtraditional filesystems,DMLoperationsforS3tablescantakelongerthanfor
tablesonHDFS.Forexample,boththeLOAD DATA statementandthefinalstageoftheINSERTandCREATE TABLE
AS SELECT statementsinvolvemovingfilesfromonedirectorytoanother.(InthecaseofINSERTandCREATE TABLE
AS SELECT ,thefilesaremovedfromatemporarystagingdirectorytothefinaldestinationdirectory.)BecauseS3
doesnotsupportaârenameâoperationforexistingobjects,inthesecasesImpalaactuallycopiesthedatafilesfrom
onelocationtoanotherandthenremovestheoriginalfiles.InCDH5.8/Impala2.6,theS3_SKIP_INSERT_STAGING
queryoptionprovidesawaytospeedupINSERTstatementsforS3tablesandpartitions, withthetradeoffthata
problemduringstatementexecutioncouldleavedatainaninconsistentstate.ItdoesnotapplytoINSERT OVERWRITE
orLOAD DATA statements.SeeS3_SKIP_INSER T_STAGINGQueryOption(CDH5.8orhigheronly)onpage358for
details.
SeeUsingImpalawiththeAmazonS3Filesystemonpage692fordetailsaboutreadingandwritingS3datawithImpala.
ADLSconsiderations:
InCDH5.12/Impala2.9andhigher,theImpalaDMLstatements(INSERT,LOAD DATA ,andCREATE TABLE AS
SELECT)canwritedataintoatableorpartitionthatresidesintheAzureDataLakeStore(ADLS).ADLSGen2issupported
inCDH6.1andhigher.
IntheCREATE TABLE orALTER TABLE statements,specifytheADLSlocationfortablesandpartitions withtheadl://
prefixforADLSGen1andabfs:// orabfss:// forADLSGen2intheLOCATION attribute.
IfyoubringdataintoADLSusingthenormalADLStransfermechanisms insteadofImpalaDMLstatements,issuea
REFRESH statementforthetablebeforeusingImpalatoquerytheADLSdata.
SeeUsingImpalawiththeAzureDataLakeStore(ADLS)onpage701fordetailsaboutreadingandwritingADLSdata
withImpala.
Cancellation:Cannotbecancelled.
290|ApacheImpalaGuideImpalaSQLLanguageReference
HDFSpermissions:
TheuserIDthattheimpalad daemonrunsunder,typicallytheimpalauser,musthavereadandwritepermissions
forthefilesinthesourcedirectory,andwritepermission forthedestinationdirectory.
Kuduconsiderations:
TheLOAD DATA statementcannotbeusedwithKudutables.
HBaseconsiderations:
TheLOAD DATA statementcannotbeusedwithHBasetables.
Relatedinformation:
TheLOAD DATA statementisanalternativetotheINSERTstatement.UseLOAD DATA whenyouhavethedatafiles
inHDFSbutoutsideofanyImpalatable.
TheLOAD DATA statementisalsoanalternativetotheCREATE EXTERNAL TABLE statement.UseLOAD DATA when
itisappropriatetomovethedatafilesunderImpalacontrolratherthanqueryingthemfromtheiroriginallocation.
SeeExternalTablesonpage197forinformationaboutworkingwithexternaltables.
REFRESHStatement
TheREFRESH statementreloadsthemetadataforthetablefromthemetastoredatabaseanddoesanincremental
reloadofthefileandblockmetadatafromtheHDFSNameNode. REFRESH isusedtoavoidinconsistenciesbetween
Impalaandexternalmetadatasources,namelyHiveMetastore(HMS)andNameNodes.
TheREFRESH statementisonlyrequiredifyouloaddatafromoutsideofImpala.Updatedmetadata,asaresultof
runningREFRESH ,isbroadcasttoallImpalacoordinators.
SeeOverviewofImpalaMetadataandtheMetastoreonpage22fortheinformationaboutthewayImpalauses
metadataandhowitsharesthesamemetastoredatabaseasHive.
Syntax:
REFRESH [ db_name.]table_name  [PARTITION ( key_col1 =val1 [, key_col2 =val2...])]
Usagenotes:
Thetablenameisarequiredparameter,andthetablemustalreadyexistandbeknowntoImpala.
Onlythemetadataforthespecified tableisreloaded.
UsetheREFRESH statementtoloadthelatestmetastoremetadataforaparticular tableafteroneofthefollowing
scenarios happensoutsideofImpala:
â¢Deleting,adding,ormodifyingfiles.
Forexample,afterloadingnewdatafilesintotheHDFSdatadirectoryforthetable,appending toanexistingHDFS
file,inserting datafromHiveviaINSERTorLOAD DATA .
â¢Deleting,adding,ormodifyingpartitions.
Forexample,afterissuingALTER TABLE orothertable-modif yingSQLstatementinHive
Note:
InCDH5.5/Impala2.3andhigher,theALTER TABLE table_name  RECOVER PARTITIONS statement
isafasteralternativetoREFRESH whenyouareonlyaddingnewpartition directoriesthroughHive
ormanualHDFSoperations.SeeALTERTABLEStatementonpage205fordetails.
INVALIDATE METADATA andREFRESH arecounterparts:
ApacheImpalaGuide|291ImpalaSQLLanguageReference
â¢INVALIDATE METADATA isanasynchronousoperationthatsimplydiscardstheloadedmetadatafromthecatalog
andcoordinatorcaches.Afterthatoperation,thecatalogandalltheImpalacoordinatorsknowonlyaboutthe
existenceofdatabasesandtables,nothingmore.Metadataloadingfortablesistriggeredbyanysubsequent
queries.
â¢REFRESH reloadsthemetadatainsyncwiththecoordinatorexecutingthestatement.SettheImpalaSYNC_DLL
optiontotruetoachieveafullysynchronousmetadatareload.REFRESH performsalightweightreloading,not
thefullmetadatareloadingthatoccursafteratablehasbeeninvalidated.REFRESH cannotdetectchangesin
blocklocationstriggeredbyoperationslikeHDFSbalancer,whichcancauseremotereadsduringqueryexecution
thatimpactperformance.
Refreshingasinglepartition:
InCDH5.9/Impala2.7andhigher,theREFRESH statementcanapplytoasinglepartition atatime,ratherthanthe
wholetable.IncludetheoptionalPARTITION ( partition_spec )clauseandspecifyvaluesforeachofthepartition
keycolumns.
Thefollowingrulesapply:
â¢ThePARTITION clauseoftheREFRESH statementmustincludeallthepartition keycolumns.
â¢Theorderofthepartition keycolumnsdoesnothavetomatchthecolumnorderinthetable.
â¢Specifyinganonexistentpartition doesnotcauseanerror.
â¢Thepartition canbeonethatImpalacreatedandisalreadyawareof,oranewpartition createdthroughHive.
Thefollowingexamplesdemonstratestheaboverules.
-- Partition doesn't exist.
REFRESH p2 PARTITION (y=0, z=3);
REFRESH p2 PARTITION (y=0, z=-1)
-- Key columns specified in a different order than the table definition.
REFRESH p2 PARTITION (z=1, y=0)
-- Incomplete partition spec causes an error.
REFRESH p2 PARTITION (y=0)
ERROR: AnalysisException: Items in partition spec must exactly match the partition 
columns in the table definition: default.p2 (1 vs 2)
ForexamplesofusingREFRESH andINVALIDATE METADATA withacombinationofImpalaandHiveoperations,see
SwitchingBackandForthBetweenImpalaandHiveonpage56.
Relatedimpala-shell options:
Duetotheexpenseofreloadingthemetadataforalltables,theimpala-shell -roptionisnotrecommended.
HDFSconsiderations:
AllHDFSandSentrypermissions andprivilegerequirementsarethesamewhetheryourefreshtheentiretableora
singlepartition.
TheREFRESH statementchecksHDFSpermissions oftheunderlying datafilesanddirectories,cachingthisinformation
sothatastatementcanbecancelledimmediatelyifforexampletheimpalauserdoesnothavepermission towrite
tothedatadirectoryforthetable.Impalareportsanylackofwritepermissions asanINFOmessageinthelogfile.
IfyouchangeHDFSpermissions tomakedatareadableorwriteablebytheImpalauser,issueanotherREFRESH to
makeImpalaawareofthechange.
Kuduconsiderations:
Bydefault,muchofthemetadataforKudutablesishandledbytheunderlying storagelayer.Kudutableshaveless
relianceontheMetastoredatabase,andrequirelessmetadatacachingontheImpalaside.Forexample,information
aboutpartitions inKudutablesismanagedbyKudu,andImpaladoesnotcacheanyblocklocalitymetadataforKudu
tables.IftheKuduserviceisnotintegratedwiththeHiveMetastore,ImpalawillmanageKudutablemetadatainthe
HiveMetastore.
292|ApacheImpalaGuideImpalaSQLLanguageReference
TheREFRESH andINVALIDATE METADATA statementsareneededlessfrequentlyforKudutablesthanforHDFS-backed
tables.Neitherstatementisneededwhendataisaddedto,removed,orupdatedinaKudutable,evenifthechanges
aremadedirectlytoKuduthroughaclientprogramusingtheKuduAPI.RunREFRESH table_name orINVALIDATE
METADATA table_name foraKudutableonlyaftermakingachangetotheKudutableschema,suchasaddingor
droppingacolumn.
Relatedinformation:
OverviewofImpalaMetadataandtheMetastoreonpage22,INVALIDATEMETADATAStatementonpage286
REFRESHAUTHORIZATIONStatement
TheREFRESH AUTHORIZATION statementexplicitlyrefreshesauthorizationdata,including privilegesandprincipals.
Whenthereisanexternalupdatetoauthorizationmetadata,usethisstatementtoforceImpalatorefreshits
authorizationdatawithouthavingtowaitfortheSentrypollingorrunINVALIDATE METADATA .
Onceissued,theREFRESH AUTHORIZATION statementcannotbecancelled.
SeeImpalaAuthorizationforinformationonenablingandusingauthorizationinImpala.
Syntax:
REFRESH AUTHORIZATION
Usagenotes:Ifauthorizationisnotenabled, Impalareturnsanerror.
Addedin:Impala3.2
REFRESHFUNCTIONSStatement
InCDH5.12/Impala2.9andhigher,youcanruntheREFRESH FUNCTIONS statementtorefreshtheuser-defined
functions (UDFs)createdoutsideofImpala.Forexample,youcanaddJava-basedUDFstothemetastoredatabase
throughtheHiveCREATE FUNCTION statementsandmakethoseUDFsvisibletoImpalaatthedatabaselevelby
subsequentlyrunningREFRESH FUNCTIONS .
TheREFRESH FUNCTIONS statementisonlyrequiredifyoucreateormodifyUDFsfromoutsideofImpala.Updated
metadata,asaresultofrunningREFRESH FUNCTIONS ,isbroadcasttoallImpalacoordinators.
Onceissued,theREFRESH FUNCTIONS statementcannotbecancelled.
Syntax:
REFRESH FUNCTIONS db_name
REVOKEStatement(CDH5.2orhigheronly)
TheREVOKEstatementrevokesrolesorprivilegesonaspecified objectfromgroups.
Syntax:
REVOKE ROLE role_name  FROM GROUP group_name
REVOKE [GRANT OPTION FOR] privilege  ON object_type object_name
  FROM [ROLE] role_name
privilege  ::= ALL | CREATE | INSERT | REFRESH | SELECT | SELECT( column_name )
object_type ::= SERVER | URI | DATABASE | TABLE
SeeGRANTStatement(CDH5.2orhigheronly)fortherequiredprivilegesandthescopeforSQLoperations.
TheALLprivilegeisadistinctprivilegeandnotaunionofallotherprivileges.RevokingSELECT,INSERT,etc.froma
rolethatonlyhastheALLprivilegehasnoeffect.ToreducetheprivilegesofthatroleyoumustREVOKE ALL and
GRANTthedesiredprivileges.
ApacheImpalaGuide|293ImpalaSQLLanguageReference
YoucannotrevokeaprivilegegrantedwiththeWITH GRANT OPTION .IfaprivilegeisgrantedwiththeWITH GRANT
OPTION,firstrevokethegrantoption,andthenrevoketheprivilege.
YoucannotrevoketheGRANTprivilegefromarolewithoutalsorevokingtheprivilege.TorevoketheGRANTprivilege,
revoketheprivilegethatitappliestoandthengrantthatprivilegeagainwithouttheWITHGRANTOPTIONclause.
YoucannotrevokeaprivilegegrantedwiththeWITH GRANT OPTION .IfaprivilegeisgrantedwiththeWITH GRANT
OPTION,firstrevokethegrantoption,andthenrevoketheprivilege.
Forexample:
GRANT ALL ON SERVER TO ROLE foo_role;
...
REVOKE GRANT OPTION FOR ALL ON SERVER FROM ROLE foo_role;
REVOKE ALL ON SERVER FROM ROLE foo_role;
Typically,theobjectnameisanidentifier.ForURIs,itisastringliteral.
TheabilitytograntorrevokeSELECTprivilegeonspecificcolumnsisavailableinCDH5.5/Impala2.3andhigher.See
HiveSQLSyntaxforUsewithSentryfordetails.fordetails.
Requiredprivileges:
OnlySentryadministrativeusers,userswhobelongtothegroupsdefinedinsentry.service.admin.group ofthe
Sentryconfigurationcanrevokearolefromagroup.
Compatibility:
â¢TheImpalaREVOKEstatementisavailableinCDH5.2/Impala2.0andhigher.
â¢InCDH5.1/Impala1.4andhigher,Impalamakesuseofanyrolesandprivilegesspecified bytheGRANTand
REVOKEstatementsinHive,whenyoursystemisconfiguredtousetheSentryserviceinsteadofthefile-based
policymechanism.
â¢TheImpalaREVOKEstatementsdonotrequiretheROLEkeywordtoberepeatedbeforeeachrolename,unlike
theequivalentHivestatements.
â¢Currently,eachImpalaGRANTorREVOKEstatementcanonlygrantorrevokeasingleprivilegetoorfromasingle
role.
Cancellation:Cannotbecancelled.
HDFSpermissions: ThisstatementdoesnottouchanyHDFSfilesordirectories,thereforenoHDFSpermissions are
required.
Kuduconsiderations:
AccesstoKudutablesmustbegrantedtoandrevokedfromroleswiththefollowingconsiderations:
â¢OnlyuserswiththeALLprivilegeonSERVERcancreateexternalKudutables.
â¢TheALLprivilegesonSERVERisrequiredtospecifythekudu.master_addresses propertyintheCREATE
TABLEstatementsformanagedtablesaswellasexternaltables.
â¢AccesstoKudutablesisenforcedatthetablelevelandatthecolumnlevel.
â¢TheSELECT-andINSERT-specificpermissions aresupported.
â¢TheDELETE,UPDATE,andUPSERToperationsrequiretheALLprivilege.
Becausenon-SQLAPIscanaccessKududatawithoutgoingthroughSentryauthorization,currentlytheSentrysupport
isconsideredpreliminaryandsubjecttochange.
Relatedinformation:
EnablingSentryAuthorizationforImpalaonpage87,GRANTStatement(CDH5.2orhigheronly)onpage273CREATE
ROLEStatement(CDH5.2orhigheronly)onpage234,DROPROLEStatement(CDH5.2orhigheronly)onpage265,
SHOWStatementonpage363
294|ApacheImpalaGuideImpalaSQLLanguageReference
SELECTStatement
TheSELECTstatementperformsqueries,retrievingdatafromoneormoretablesandproducingresultsetsconsisting
ofrowsandcolumns.
TheImpalaINSERTstatementalsotypicallyendswithaSELECTstatement,todefinedatatocopyfromonetableto
another.
Syntax:
[WITH name AS (select_expression ) [, ...] ]
SELECT
  [ALL | DISTINCT]
  [STRAIGHT_JOIN]
expression  [, expression  ...]
FROM table_reference  [, table_reference  ...]
[[FULL | [LEFT | RIGHT] INNER | [LEFT | RIGHT] OUTER | [LEFT | RIGHT] SEMI | [LEFT | 
RIGHT] ANTI | CROSS]
  JOIN table_reference
  [ON join_equality_clauses  | USING ( col1[, col2 ...]] ...
WHERE conditions
GROUP BY { column | expression  [, ...] }
HAVING conditions
ORDER BY { column | expression  [ASC | DESC] [NULLS FIRST | NULLS LAST] [, ...] }
LIMIT expression  [OFFSET expression ]
[UNION [ALL] select_statement ] ...]
table_reference := { table_name  | (subquery ) }
[ TABLESAMPLE SYSTEM( percentage ) [REPEATABLE( seed)] ]
ImpalaSELECTqueriessupport:
â¢SQLscalardatatypes:BOOLEAN ,TINYINT ,SMALLINT ,INT,BIGINT,DECIMALFLOAT,DOUBLE,TIMESTAMP ,
STRING,VARCHAR ,CHAR.
â¢ThecomplexdatatypesARRAY,STRUCT,andMAP,areavailableinCDH5.5/Impala2.3andhigher.Queries
involvingthesetypestypicallyinvolvespecialqualified namesusingdotnotationforreferringtothecomplex
columnfields,andjoinclausesforbringingthecomplexcolumnsintotheresultset.SeeComplexTypes(CDH5.5
orhigheronly)onpage139fordetails.
â¢AnoptionalWITHclausebeforetheSELECTkeyword,todefineasubquerywhosenameorcolumnnamescan
bereferencedfromlaterinthemainquery.Thisclauseletsyouabstractrepeatedclauses,suchasaggregation
functions, thatarereferencedmultipletimesinthesamequery.
â¢Subqueries inaFROMclause.InCDH5.2/Impala2.0andhigher,subqueries canalsogointheWHEREclause,for
examplewiththeIN(),EXISTS,andNOT EXISTS operators.
â¢WHERE,GROUP BY ,HAVINGclauses.
â¢ORDER BY .PriortoImpala1.4.0,ImpalarequiredthatqueriesusinganORDER BY clausealsoincludeaLIMIT
clause.InImpala1.4.0andhigher,thisrestrictionislifted;sortoperationsthatwouldexceedtheImpalamemory
limitautomaticallyuseatemporarydiskworkareatoperformthesort.
â¢Impalasupports awidevarietyofJOINclauses.Left,right,semi,full,andouterjoinsaresupportedinallImpala
versions.TheCROSS JOIN operatorisavailableinImpala1.2.2andhigher.Duringperformance tuning,youcan
overridethereorderingofjoinclausesthatImpaladoesinternallybyincluding thekeywordSTRAIGHT_JOIN
immediatelyaftertheSELECTandanyDISTINCT orALLkeywords.
SeeJoinsinImpalaSELECTStatementsonpage296fordetailsandexamplesofjoinqueries.
â¢UNION ALL .
â¢LIMIT.
â¢Externaltables.
â¢Relationaloperatorssuchasgreaterthan,lessthan,orequalto.
â¢Arithmeticoperatorssuchasadditionorsubtraction.
â¢Logical/Boolean operatorsAND,OR,andNOT.Impaladoesnotsupportthecorresponding symbols&&,||,and!.
â¢Common SQLbuilt-infunctions suchasCOUNT,SUM,CAST,LIKE,IN,BETWEEN ,andCOALESCE .Impalaspecifically
supports built-insdescribed inImpalaBuilt-InFunctions onpage391.
ApacheImpalaGuide|295ImpalaSQLLanguageReference
â¢InCDH5.12/Impala2.9andhigher,anoptionalTABLESAMPLE clauseimmediatelyafteratablereference,to
specifythatthequeryonlyprocessesaspecified percentageofthetabledata.SeeTABLESAMPLEClauseonpage
315fordetails.
Impalaqueriesignorefileswithextensionscommonly usedfortemporaryworkfilesbyHadooptools.Anyfileswith
extensions.tmpor.copying arenotconsideredpartoftheImpalatable.Thesuffixmatchingiscase-insensitiv e,so
forexampleImpalaignoresboth.copying and.COPYING suffixes.
Securityconsiderations:
Ifthesestatementsinyourenvironmentcontainsensitiveliteralvaluessuchascreditcardnumbersortaxidentifiers,
Impalacanredactthissensitiveinformationwhendisplayingthestatementsinlogfilesandotheradministrative
contexts.Seehttp://www.cloudera.com/content/cloudera/en/documen tation/core/latest/topics/sg_redaction.h tml
fordetails.
AmazonS3considerations:
InCDH5.8/Impala2.6andhigher,ImpalaqueriesareoptimizedforfilesstoredinAmazonS3.ForImpalatablesthat
usethefileformatsParquet,ORC,RCFile,SequenceFile, Avro,anduncompressedtext,thesettingfs.s3a.block.size
inthecore-site.xml configurationfiledetermineshowImpaladividestheI/Oworkofreadingthedatafiles.This
configurationsettingisspecified inbytes.Bydefault,thisvalueis33554432 (32MB),meaningthatImpalaparallelizes
S3readoperationsonthefilesasiftheyweremadeupof32MBblocks.Forexample,ifyourS3queriesprimarily
accessParquetfileswrittenbyMapReduceorHive,increasefs.s3a.block.size to134217728 (128MB)tomatch
therowgroupsizeofthosefiles.IfmostS3queriesinvolveParquetfileswrittenbyImpala,increase
fs.s3a.block.size to268435456 (256MB)tomatchtherowgroupsizeproducedbyImpala.
Cancellation:Canbecancelled. Tocancelthisstatement,useCtrl-Cfromtheimpala-shell interpreter,theCancel
buttonfromtheWatchpageinHue,Actions>CancelfromtheQuerieslistinClouderaManager,orCancelfromthe
listofin-flightqueries(foraparticular node)ontheQueriestabintheImpalawebUI(port25000).
HDFSpermissions:
TheuserIDthattheimpalad daemonrunsunder,typicallytheimpalauser,musthavereadpermissions forthefiles
inallapplicabledirectoriesinallsourcetables,andreadandexecutepermissions fortherelevantdatadirectories.(A
SELECToperationcouldreadfilesfrommultipledifferentHDFSdirectoriesifthesourcetableispartitioned.) Ifaquery
attemptstoreadadatafileandisunabletobecauseofanHDFSpermission error,thequeryhaltsanddoesnotreturn
anyfurtherresults.
Relatedinformation:
TheSELECTsyntaxissoextensivethatitformsitsowncategoryofstatements:queries.Theothermajorclassifications
ofSQLstatementsaredatadefinitionlanguage(seeDDLStatementsonpage203)anddatamanipula tionlanguage(see
DMLStatementsonpage204).
BecausethefocusofImpalaisonfastquerieswithinteractiveresponsetimesoverhugedatasets,queryperformance
andscalabilityareimportantconsiderations.SeeTuningImpalaforPerformance onpage565andScalability
ConsiderationsforImpalaonpage605fordetails.
JoinsinImpalaSELECTStatements
AjoinqueryisaSELECTstatementthatcombinesdatafromtwoormoretables,andreturnsaresultsetcontaining
itemsfromsomeorallofthosetables.Itisawaytocross-referenceandcorrelaterelateddatathatisorganizedinto
multipletables,typicallyusingidentifiersthatarerepeatedineachofthejoinedtables.
Syntax:
Impalasupports awidevarietyofJOINclauses.Left,right,semi,full,andouterjoinsaresupportedinallImpala
versions.TheCROSS JOIN operatorisavailableinImpala1.2.2andhigher.Duringperformancetuning,youcanoverride
thereorderingofjoinclausesthatImpaladoesinternallybyincluding thekeywordSTRAIGHT_JOIN immediatelyafter
theSELECTandanyDISTINCT orALLkeywords.
SELECT select_list  FROM
table_or_subquery1  [INNER] JOIN table_or_subquery2  |
296|ApacheImpalaGuideImpalaSQLLanguageReference
table_or_subquery1  {LEFT [OUTER] | RIGHT [OUTER] | FULL [OUTER]} JOIN table_or_subquery2
 |
table_or_subquery1  {LEFT | RIGHT} SEMI JOIN table_or_subquery2  |
table_or_subquery1  {LEFT | RIGHT} ANTI JOIN table_or_subquery2  |
    [ ON col1 = col2 [AND col3 = col4 ...] |
      USING ( col1 [, col2 ...]) ]
  [other_join_clause  ...]
[ WHERE where_clauses  ]
SELECT select_list  FROM
table_or_subquery1 , table_or_subquery2  [, table_or_subquery3  ...]
  [other_join_clause  ...]
WHERE
col1 = col2 [AND col3 = col4 ...]
SELECT select_list  FROM
table_or_subquery1  CROSS JOIN table_or_subquery2
  [other_join_clause  ...]
[ WHERE where_clauses  ]
SQL-92andSQL-89Joins:
QuerieswiththeexplicitJOINkeywordsareknownasSQL-92stylejoins,referringtotheleveloftheSQLstandard
wheretheywereintroduced.Thecorresponding ONorUSINGclausesclearlyshowwhichcolumnsareusedasthejoin
keysineachcase:
SELECT t1.c1, t2.c2 FROM t1 JOIN t2
ON t1.id = t2.id and t1.type_flag = t2.type_flag
  WHERE t1.c1 > 100;
SELECT t1.c1, t2.c2 FROM t1 JOIN t2
USING (id, type_flag)
  WHERE t1.c1 > 100;
TheONclauseisageneralwaytocomparecolumnsacrossthetwotables,evenifthecolumnnamesaredifferent.The
USINGclauseisashorthand notationforspecifyingthejoincolumns,whenthecolumnnamesarethesameinboth
tables.YoucancodeequivalentWHEREclausesthatcomparethecolumns,insteadofONorUSINGclauses,butthat
practiceisnotrecommended becausemixingthejoincomparisons withotherfilteringclausesistypicallylessreadable
andhardertomaintain.
Querieswithacomma-separ atedlistoftablesandsubqueries areknownasSQL-89stylejoins.Inthesequeries,the
equalitycomparisons betweencolumnsofthejoinedtablesgointheWHEREclausealongside otherkindsofcomparisons.
Thissyntaxiseasytolearn,butitisalsoeasytoaccidentallyremoveaWHEREclauseneededforthejointowork
correctly.
SELECT t1.c1, t2.c2 FROM t1, t2
  WHERE
t1.id = t2.id AND t1.type_flag = t2.type_flag
  AND t1.c1 > 100;
Self-joins:
Impalacandoself-joins, forexampletojoinontwodifferentcolumnsinthesametabletorepresentparent-child
relationshipsorothertree-structureddata.Thereisnoexplicitsyntaxforthis;justusethesametablenameforboth
theleft-handandright-handtable,andassigndifferenttablealiasestousewhenreferringtothefullyqualifiedcolumn
names:
-- Combine fields from both parent and child rows.
SELECT lhs.id, rhs.parent, lhs.c1, rhs.c2 FROM tree_data lhs, tree_data rhs WHERE lhs.id
 = rhs.parent;
Innerandouterjoins:
Aninnerjoinisthemostcommonandfamiliartype:rowsintheresultsetcontaintherequestedcolumnsfromthe
appropriatetables,forallcombinationsofrowswherethejoincolumnsofthetableshaveidenticalvalues.Ifacolumn
ApacheImpalaGuide|297ImpalaSQLLanguageReference
withthesamenameoccursinbothtables,useafullyqualified nameoracolumnaliastorefertothecolumninthe
selectlistorotherclauses.ImpalaperformsinnerjoinsbydefaultforbothSQL-89andSQL-92joinsyntax:
-- The following 3 forms are all equivalent.
SELECT t1.id, c1, c2 FROM t1, t2 WHERE t1.id = t2.id;
SELECT t1.id, c1, c2 FROM t1 JOIN t2 ON t1.id = t2.id;
SELECT t1.id, c1, c2 FROM t1 INNER JOIN t2 ON t1.id = t2.id;
Anouterjoinretrievesallrowsfromtheleft-handtable,ortheright-handtable,orboth;whereverthereisnomatching
datainthetableontheothersideofthejoin,thecorresponding columnsintheresultsetaresettoNULL.Toperform
anouterjoin,includetheOUTERkeywordinthejoinoperator,alongwitheitherLEFT,RIGHT,orFULL:
SELECT * FROM t1 LEFT OUTER JOIN t2 ON t1.id = t2.id;
SELECT * FROM t1 RIGHT OUTER JOIN t2 ON t1.id = t2.id;
SELECT * FROM t1 FULL OUTER JOIN t2 ON t1.id = t2.id;
Forouterjoins,ImpalarequiresSQL-92syntax;thatis,theJOINkeywordinsteadofcomma-separ atedtablenames.
Impaladoesnotsupportvendorextensionssuchas(+)or*=notationfordoingouterjoinswithSQL-89querysyntax.
EquijoinsandNon-Equijoins:
Bydefault,Impalarequiresanequalitycomparison betweentheleft-handandright-handtables,eitherthroughON,
USING,orWHEREclauses.Thesetypesofqueriesareclassified broadlyasequijoins. Inner,outer,full,andsemijoins
canallbeequijoins basedonthepresenceofequalitytestsbetweencolumnsintheleft-handandright-handtables.
InImpala1.2.2andhigher,non-equijoin queriesarealsopossible, withcomparisons suchas!=or<betweenthejoin
columns.Thesekindsofqueriesrequirecaretoavoidproducinghugeresultsetsthatcouldexceedresourcelimits.
Onceyouhaveplannedanon-equijoin querythatproducesaresultsetofacceptablesize,youcancodethequery
usingtheCROSS JOIN operator,andaddtheextracomparisons intheWHEREclause:
SELECT * FROM t1 CROSS JOIN t2 WHERE t1.total > t2.maximum_price;
InCDH5.5/Impala2.3andhigher,additional non-equijoin queriesarepossibleduetotheadditionofnestedloop
joins.ThesequeriestypicallyinvolveSEMI JOIN ,ANTI JOIN ,orFULL OUTER JOIN clauses.Impalasometimesalso
usesnestedloopjoinsinternallywhenevaluatingOUTER JOIN queriesinvolvingcomplextypecolumns.Queryphases
involvingnestedloopjoinsdonotusethespill-to-diskmechanism iftheyexceedthememorylimit.Impaladecides
internallywhentouseeachjoinmechanism; youcannotspecifyanyqueryhinttochoosebetweenthenestedloop
joinortheoriginalhashjoinalgorithm.
SELECT * FROM t1 LEFT OUTER JOIN t2 ON t1.int_col < t2.int_col;
Semi-joins:
Semi-joins arearelativelyrarelyusedvariation.Withtheleftsemi-join, onlydatafromtheleft-handtableisreturned,
forrowswherethereismatchingdataintheright-handtable,basedoncomparisons betweenjoincolumnsinONor
WHEREclauses.Onlyoneinstanceofeachrowfromtheleft-handtableisreturned,regardlessofhowmanymatching
rowsexistintheright-handtable.Arightsemi-join (availableinImpala2.0andhigher)reversesthecomparison and
returnsdatafromtheright-handtable.
SELECT t1.c1, t1.c2, t1.c2 FROM t1 LEFT SEMI JOIN t2 ON t1.id = t2.id;
Naturaljoins(notsupported):
ImpaladoesnotsupporttheNATURAL JOIN operator,againtoavoidinconsistentorhugeresultsets.Naturaljoins
doawaywiththeONandUSINGclauses,andinsteadautomaticallyjoinonallcolumnswiththesamenamesinthe
left-handandright-handtables.Thiskindofqueryisnotrecommended forrapidlyevolvingdatastructuressuchas
aretypicallyusedinHadoop.Thus,ImpaladoesnotsupporttheNATURAL JOIN syntax,whichcanproducedifferent
queryresultsascolumnsareaddedtoorremovedfromtables.
298|ApacheImpalaGuideImpalaSQLLanguageReference
IfyoudohaveanyqueriesthatuseNATURAL JOIN ,makesuretorewritethemwithexplicitUSINGclauses,because
ImpalacouldinterprettheNATURAL keywordasatablealias:
-- 'NATURAL' is interpreted as an alias for 't1' and Impala attempts an inner join,
-- resulting in an error because inner joins require explicit comparisons between columns.
SELECT t1.c1, t2.c2 FROM t1 NATURAL JOIN t2;
ERROR: NotImplementedException: Join with 't2' requires at least one conjunctive equality
 predicate.
  To perform a Cartesian product between two tables, use a CROSS JOIN.
-- If you expect the tables to have identically named columns with matching values,
-- list the corresponding column names in a USING clause.
SELECT t1.c1, t2.c2 FROM t1 JOIN t2 USING (id, type_flag, name, address);
Anti-joins(CDH5.2/Impala2.0andhigheronly):
Impalasupports theLEFT ANTI JOIN andRIGHT ANTI JOIN clausesinCDH5.2andhigher.TheLEFTorRIGHT
keywordisrequiredforthiskindofjoin.ForLEFT ANTI JOIN ,thisclausereturnsthosevaluesfromtheleft-hand
tablethathavenomatchingvalueintheright-handtable.RIGHT ANTI JOIN reversesthecomparison andreturns
valuesfromtheright-handtable.YoucanexpressthisnegativerelationshipeitherthroughtheANTI JOIN clauseor
throughaNOT EXISTS operatorwithasubquery.
Complextypeconsiderations:
Whenreferringtoacolumnwithacomplextype(STRUCT,ARRAY,orMAP)inaquery,youusejoinnotationtoâunpackâ
thescalarfieldsofthestruct,theelementsofthearray,orthekey-valuepairsofthemap.(Thejoinnotationisnot
requiredforaggregationoperations,suchasCOUNT() orSUM()forarrayelements.)BecauseImpalarecognizeswhich
complextypeelementsareassociatedwithwhichrowoftheresultset,youusethesamesyntaxasforacrossor
cartesianjoin,withoutanexplicitjoincondition. SeeComplexTypes(CDH5.5orhigheronly)onpage139fordetails
aboutImpalasupportforcomplextypes.
Usagenotes:
Youtypicallyusejoinqueriesinsituationslikethese:
â¢Whenrelateddataarrivesfromdifferentsources,witheachdatasetphysicallyresidinginaseparatetable.For
example,youmighthaveaddressdatafrombusinessrecordsthatyoucross-check againstphonelistingsorcensus
data.
Note:Impalacanjointablesofdifferentfileformats,including Impala-manag edtablesandHBase
tables.Forexample,youmightkeepsmalldimension tablesinHBase,forconvenienceofsingle-row
lookupsandupdates,andforthelargerfacttablesuseParquetorotherbinaryfileformat
optimizedforscanoperations.Then,youcanissueajoinquerytocross-referencethefacttables
withthedimension tables.
â¢Whendataisnormalized,atechnique forreducingdataduplicationbydividingitacrossmultipletables.Thiskind
oforganizationisoftenfoundindatathatcomesfromtraditional relationaldatabasesystems.Forexample,
insteadofrepeatingsomelongstringsuchasacustomernameinmultipletables,eachtablemightcontaina
numericcustomerID.Queriesthatneedtodisplaythecustomernamecouldâjoinâthetablethatspecifieswhich
customerIDcorrespondstowhichname.
â¢Whencertaincolumnsarerarelyneededforqueries,sotheyaremovedintoseparatetablestoreduceoverhead
forcommonqueries.Forexample,abiography fieldmightberarelyneededinqueriesonemployeedata.Putting
thatfieldinaseparatetablereducestheamountofI/Oforcommonqueriesonemployeeaddressesorphone
numbers.Queriesthatdoneedthebiography columncanretrieveitbyperformingajoinwiththatseparate
table.
â¢InCDH5.5/Impala2.3orhigher,whenreferringtocomplextypecolumnsinqueries.SeeComplexTypes(CDH
5.5orhigheronly)onpage139fordetails.
ApacheImpalaGuide|299ImpalaSQLLanguageReference
Whencomparing columnswiththesamenamesinONorWHEREclauses,usethefullyqualified namessuchas
db_name.table_name ,orassigntablealiases,columnaliases,orbothtomakethecodemorecompactand
understandable:
select t1.c1 as first_id, t2.c2 as second_id from
  t1 join t2 on first_id = second_id;
select fact.custno, dimension.custno from
  customer_data as fact join customer_address as dimension
  using (custno)
Note:
Performance forjoinqueriesisacrucialaspectforImpala,becausecomplexjoinqueriesare
resource-intensiveoperations.AnefficientjoinqueryproducesmuchlessnetworktrafficandCPU
overheadthananinefficientone.Forbestresults:
â¢Makesurethatbothtableandcolumnstatisticsareavailableforallthetablesinvolvedinajoin
query,andespecially forthecolumnsreferencedinanyjoinconditions. Impalausesthestatistics
toautomaticallydeduceanefficientjoinorder.UseSHOW TABLE STATS table_name and
SHOW COLUMN STATS table_name tocheckifstatisticsarealreadypresent.IssuetheCOMPUTE
STATS table_name foranonpartitioned table,or(inImpala2.1.0andhigher)COMPUTE
INCREMENTAL STATS table_name forapartitioned table,tocollecttheinitialstatisticsatboth
thetableandcolumnlevels,andtokeepthestatisticsuptodateafteranysubstantialINSERT
orLOAD DATA operations.
â¢Iftableorcolumnstatisticsarenotavailable,jointhelargesttablefirst.Youcanchecktheexistence
ofstatisticswiththeSHOW TABLE STATS table_name andSHOW COLUMN STATS table_name
statements.
â¢Iftableorcolumnstatisticsarenotavailable,joinsubsequenttablesaccordingtowhichtable
hasthemostselectivefilter,basedonoverallsizeandWHEREclauses.Joiningthetablewiththe
mostselectivefilterresultsinthefewestnumberofrowsbeingreturned.
Formoreinformationandexamplesofperformance forjoinqueries,seePerformance Considerations
forJoinQueriesonpage568.
Tocontroltheresultsetfromajoinquery,includethenamesofcorresponding columnnamesinbothtablesinanON
orUSINGclause,orbycodingequalitycomparisons forthosecolumnsintheWHEREclause.
[localhost:21000] > select c_last_name, ca_city from customer join customer_address 
where c_customer_sk = ca_address_sk;
+-------------+-----------------+
| c_last_name | ca_city         |
+-------------+-----------------+
| Lewis       | Fairfield       |
| Moses       | Fairview        |
| Hamilton    | Pleasant Valley |
| White       | Oak Ridge       |
| Moran       | Glendale        |
...
| Richards    | Lakewood         |
| Day         | Lebanon          |
| Painter     | Oak Hill         |
| Bentley     | Greenfield       |
| Jones       | Stringtown       |
+-------------+------------------+
Returned 50000 row(s) in 9.82s
Onepotentialdownsideofjoinsisthepossibility ofexcessresourceusageinpoorlyconstructedqueries.Impalaimposes
restrictionsonjoinqueriestoguardagainstsuchissues.Tominimizethechanceofrunawayqueriesonlargedatasets,
Impalarequireseveryjoinquerytocontainatleastoneequalitypredicatebetweenthecolumnsofthevarioustables.
Forexample,ifT1contains1000rowsandT2contains1,000,000 rows,aquerySELECT columns FROM t1 JOIN
300|ApacheImpalaGuideImpalaSQLLanguageReference
t2couldreturnupto1billionrows(1000*1,000,000); ImpalarequiresthatthequeryincludeaclausesuchasON
t1.c1 = t2.c2 orWHERE t1.c1 = t2.c2 .
Becauseevenwithequalityclauses,theresultsetcanstillbelarge,aswesawinthepreviousexample,youmightuse
aLIMITclausetoreturnasubsetoftheresults:
[localhost:21000] > select c_last_name, ca_city from customer, customer_address where 
c_customer_sk = ca_address_sk limit 10;
+-------------+-----------------+
| c_last_name | ca_city         |
+-------------+-----------------+
| Lewis       | Fairfield       |
| Moses       | Fairview        |
| Hamilton    | Pleasant Valley |
| White       | Oak Ridge       |
| Moran       | Glendale        |
| Sharp       | Lakeview        |
| Wiles       | Farmington      |
| Shipman     | Union           |
| Gilbert     | New Hope        |
| Brunson     | Martinsville    |
+-------------+-----------------+
Returned 10 row(s) in 0.63s
Oryoumightuseadditional comparison operatorsoraggregationfunctions tocondensealargeresultsetintoasmaller
setofvalues:
[localhost:21000] > -- Find the names of customers who live in one particular town.
[localhost:21000] > select distinct c_last_name from customer, customer_address where
  c_customer_sk = ca_address_sk
  and ca_city = "Green Acres";
+---------------+
| c_last_name   |
+---------------+
| Hensley       |
| Pearson       |
| Mayer         |
| Montgomery    |
| Ricks         |
...
| Barrett       |
| Price         |
| Hill          |
| Hansen        |
| Meeks         |
+---------------+
Returned 332 row(s) in 0.97s
[localhost:21000] > -- See how many different customers in this town have names starting
 with "A".
[localhost:21000] > select count(distinct c_last_name) from customer, customer_address
 where
  c_customer_sk = ca_address_sk
  and ca_city = "Green Acres"
  and substr(c_last_name,1,1) = "A";
+-----------------------------+
| count(distinct c_last_name) |
+-----------------------------+
| 12                          |
+-----------------------------+
Returned 1 row(s) in 1.00s
Becauseajoinquerycaninvolvereadinglargeamountsofdatafromdisk,sendinglargeamountsofdataacrossthe
network,andloadinglargeamountsofdataintomemorytodothecomparisons andfiltering,youmightdo
benchmarking ,performanceanalysis,andquerytuningtofindthemostefficientjoinqueriesforyourdataset,hardware
capacity,networkconfiguration,andclusterworkload.
ThetwocategoriesofjoinsinImpalaareknownaspartitioned joinsandbroadcastjoins.Ifinaccuratetableorcolumn
statistics,orsomequirkofthedatadistribution, causesImpalatochoosethewrongmechanism foraparticular join,
considerusingqueryhintsasatemporaryworkaround.Fordetails,seeOptimizerHintsinImpalaonpage387.
ApacheImpalaGuide|301ImpalaSQLLanguageReference
Handling NULLsinJoinColumns:
Bydefault,joinkeycolumnsdonotmatchifeitheronecontainsaNULLvalue.Totreatsuchcolumnsasequalifboth
containNULL,youcanuseanexpressionsuchasA = B OR (A IS NULL AND B IS NULL) .InCDH5.7/Impala
2.5andhigher,the<=>operator(shorthand forIS NOT DISTINCT FROM )performsthesamecomparison inaconcise
andefficientform.The<=>operatorismoreefficientinforcomparing joinkeysinaNULL-safemanner,becausethe
operatorcanuseahashjoinwhiletheORexpressioncannot.
Examples:
Thefollowingexamplesrefertothesesimpletablescontainingsmallsetsofintegers:
[localhost:21000] > create table t1 (x int);
[localhost:21000] > insert into t1 values (1), (2), (3), (4), (5), (6);
[localhost:21000] > create table t2 (y int);
[localhost:21000] > insert into t2 values (2), (4), (6);
[localhost:21000] > create table t3 (z int);
[localhost:21000] > insert into t3 values (1), (3), (5);
Thefollowingexampledemonstratesananti-join,returningthevaluesfromT1thatdonotexistinT2(inthiscase,
theoddnumbers1,3,and5):
[localhost:21000] > select x from t1 left anti join t2 on (t1.x = t2.y);
+---+
| x |
+---+
| 1 |
| 3 |
| 5 |
+---+
Relatedinformation:
Seethesetutorialsforexamplesofdifferentkindsofjoins:
â¢CrossJoinsandCartesianProductswiththeCROSSJOINOperatoronpage57
ORDERBYClause
TheORDER BY clauseofaSELECTstatementsortstheresultsetbasedonthevaluesfromoneormorecolumns.
First,dataissortedlocallybyeachimpalad daemon, thenstreamedtothecoordinatordaemon, whichmergesthe
sortedresultsets.Fordistributedqueries,thisisarelativelyexpensiveoperationandcanrequiremorememorycapacity
thanaquerywithoutORDER BY .Evenifthequerytakesapproximatelythesametimetofinishwithorwithoutthe
ORDER BY clause,subjectivelyitcanappearslowerbecausenoresultsareavailableuntilallprocessingisfinished,
ratherthanresultscomingbackgraduallyasrowsmatchingtheWHEREclausearefound.Therefore,ifyouonlyneed
thefirstNresultsfromthesortedresultset,alsoincludetheLIMITclause,whichreducesnetworkoverheadandthe
memoryrequirementonthecoordinatornode.
Syntax:
ThefullsyntaxfortheORDER BY clauseis:
ORDER BY col_ref [, col_ref ...] [ASC | DESC] [NULLS FIRST | NULLS LAST]
col_ref ::= column_name  | integer_literal
Although themostcommonusageisORDER BY column_name ,youcanalsospecifyORDER BY 1 tosortbythefirst
columnoftheresultset,ORDER BY 2 tosortbythesecondcolumn,andsoon.Thenumbermustbeanumericliteral,
notsomeotherkindofconstantexpression.(Iftheargumentissomeotherexpression,evenaSTRINGvalue,thequery
succeeds buttheorderofresultsisundefined.)
ORDER BY column_number canonlybeusedwhenthequeryexplicitlyliststhecolumnsintheSELECTlist,notwith
SELECT * queries.
302|ApacheImpalaGuideImpalaSQLLanguageReference
Ascending anddescending sorts:
Thedefaultsortorder(thesameasusingtheASCkeyword)putsthesmallestvaluesatthestartoftheresultset,and
thelargestvaluesattheend.SpecifyingtheDESCkeywordreversesthatorder.
SortorderforNULLvalues:
SeeNULLonpage170fordetailsabouthowNULLvaluesarepositioned inthesortedresultset,andhowtousethe
NULLS FIRST andNULLS LAST clauses.(ThesortpositionforNULLvaluesinORDER BY ... DESC queriesischanged
inImpala1.2.1andhighertobemorestandards-compliant,andtheNULLS FIRST andNULLS LAST keywordsare
newinImpala1.2.1.)
PriortoImpala1.4.0,Impalarequiredanyqueryincluding anORDER BY clausetoalsouseaLIMITclause.InImpala
1.4.0andhigher,theLIMITclauseisoptionalforORDER BY queries.Incaseswheresortingahugeresultsetrequires
enoughmemorytoexceedtheImpalamemorylimitforaparticular executorImpaladaemon, Impalaautomatically
usesatemporarydiskworkareatoperformthesortoperation.
Complextypeconsiderations:
InCDH5.5/Impala2.3andhigher,thecomplexdatatypesSTRUCT,ARRAY,andMAPareavailable.Thesecolumns
cannotbereferenceddirectlyintheORDER BY clause.Whenyouqueryacomplextypecolumn,youusejoinnotation
toâunpackâ theelementsofthecomplextype,andwithinthejoinqueryyoucanincludeanORDER BY clausetocontrol
theorderintheresultsetofthescalarelementsfromthecomplextype.SeeComplexTypes(CDH5.5orhigheronly)
onpage139fordetailsaboutImpalasupportforcomplextypes.
ThefollowingqueryshowshowacomplextypecolumncannotbedirectlyusedinanORDER BY clause:
CREATE TABLE games (id BIGINT, score ARRAY <BIGINT>) STORED AS PARQUET;
...use LOAD DATA to load externally created Parquet files into the table...
SELECT id FROM games ORDER BY score DESC;
ERROR: AnalysisException: ORDER BY expression 'score' with complex type 'ARRAY<BIGINT>'
 is not supported.
Examples:
ThefollowingqueryretrievestheuserIDandscore,onlyforscoresgreaterthanonemillion,withthehighestscores
foreachuserlistedfirst.Becausetheindividual arrayelementsarenowrepresentedasseparaterowsintheresult
set,theycanbeusedintheORDER BY clause,referencedusingtheITEMpseudo-columnthatrepresentseacharray
element.
SELECT id, item FROM games, games.score
  WHERE item > 1000000
ORDER BY id, item desc;
ThefollowingqueriesusesimilarORDER BY techniques withvariationsoftheGAMEStable,wherethecomplextype
isanARRAYcontainingSTRUCTorMAPelementstorepresentadditional detailsabouteachgamethatwasplayed.For
anarrayofstructures,thefieldsofthestructurearereferencedasITEM.field_name .Foranarrayofmaps,thekeys
andvalueswithineacharrayelementarereferencedasITEM.KEY andITEM.VALUE .
CREATE TABLE games2 (id BIGINT, play array < struct <game_name: string, score: BIGINT,
 high_score: boolean> >) STORED AS PARQUET
...use LOAD DATA to load externally created Parquet files into the table...
SELECT id, item.game_name, item.score FROM games2, games2.play
  WHERE item.score > 1000000
ORDER BY id, item.score DESC;
CREATE TABLE games3 (id BIGINT, play ARRAY < MAP <STRING, BIGINT> >) STORED AS PARQUET;
...use LOAD DATA to load externally created Parquet files into the table...
SELECT id, info.key AS k, info.value AS v from games3, games3.play AS plays, 
games3.play.item AS info
  WHERE info.KEY = 'score' AND info.VALUE > 1000000
ORDER BY id, info.value desc;
Usagenotes:
ApacheImpalaGuide|303ImpalaSQLLanguageReference
Although theLIMITclauseisnowoptionalonORDER BY queries,ifyourqueryonlyneedssomenumberofrowsthat
youcanpredictinadvance,usetheLIMITclausetoreduceunnecessar yprocessing. Forexample,ifthequeryhasa
clauseLIMIT 10 ,eachexecutorImpaladaemonsortsitsportionoftherelevantresultsetandonlyreturns10rows
tothecoordinatornode.Thecoordinatornodepicksthe10highestorlowestrowvaluesoutofthissmallintermediate
resultset.
IfanORDER BY clauseisappliedtoanearlyphaseofqueryprocessing,suchasasubqueryoraviewdefinition,Impala
ignorestheORDER BY clause.Togetorderedresultsfromasubqueryorview,applyanORDER BY clausetothe
outermostorfinalSELECTlevel.
ORDER BY isoftenusedincombinationwithLIMITtoperformâtop-Nâqueries:
SELECT user_id AS "Top 10 Visitors", SUM(page_views) FROM web_stats
  GROUP BY page_views, user_id
  ORDER BY SUM(page_views) DESC LIMIT 10;
ORDER BY issometimesusedincombinationwithOFFSETandLIMITtopaginatequeryresults,although itisrelatively
inefficienttoissuemultiplequerieslikethisagainstthelargetablestypicallyusedwithImpala:
SELECT page_title AS "Page 1 of search results", page_url FROM search_content
  WHERE LOWER(page_title) LIKE '%game%')
  ORDER BY page_title LIMIT 10 OFFSET 0;
SELECT page_title AS "Page 2 of search results", page_url FROM search_content
  WHERE LOWER(page_title) LIKE '%game%')
  ORDER BY page_title LIMIT 10 OFFSET 10;
SELECT page_title AS "Page 3 of search results", page_url FROM search_content
  WHERE LOWER(page_title) LIKE '%game%')
  ORDER BY page_title LIMIT 10 OFFSET 20;
Internaldetails:
ImpalasortstheintermediateresultsofanORDER BY clauseinmemorywheneverpractical.InaclusterofNexecutor
Impaladaemons, eachdaemonsortsroughly1/Nthoftheresultset,theexactproportion varyingdepending onhow
thedatamatchingthequeryisdistributedinHDFS.
IfthesizeofthesortedintermediateresultsetonanyexecutorImpaladaemonwouldcausethequerytoexceedthe
Impalamemorylimit,Impalasortsasmuchaspracticalinmemory,thenwritespartiallysorteddatatodisk.(This
technique isknowninindustryterminology asâexternalsortingâandâspillingtodiskâ.)Aseach8MBbatchofdatais
writtentodisk,Impalafreesthecorresponding memorytosortanew8MBbatchofdata.Whenallthedatahasbeen
processed,afinalmergesortoperationisperformedtocorrectlyorderthein-memor yandon-diskresultsastheresult
setistransmittedbacktothecoordinatornode.Whenexternalsortingbecomesnecessary,Impalarequiresapproximately
60MBofRAMataminimum forthebuffersneededtoread,write,andsorttheintermediateresults.IfmoreRAMis
availableontheImpaladaemon, Impalawillusetheadditional RAMtominimizetheamountofdiskI/Oforsorting.
Thisexternalsorttechnique isusedasappropriateoneachImpaladaemon(possibly including thecoordinatornode)
tosorttheportionoftheresultsetthatisprocessedonthatnode.Whenthesortedintermediateresultsaresentback
tothecoordinatornodetoproducethefinalresultset,thecoordinatornodeusesamergesorttechnique toproduce
afinalsortedresultsetwithoutusinganyextraresourcesonthecoordinatornode.
Configurationfordiskusage:
Bydefault,intermediatefilesusedduringlargesort,join,aggregation,oranalyticfunctionoperationsarestoredin
thedirectory/tmp/impala-scratch .Thesefilesareremovedwhentheoperationfinishes.(Multiple concurrent
queriescanperformoperationsthatusetheâspilltodiskâtechnique, withoutanynameconflictsforthesetemporary
files.)Youcanspecifyadifferentlocationbystartingtheimpalad daemonwiththe
--scratch_dirs=" path_to_directory "configurationoptionortheequivalentconfigurationoptionintheCloudera
Manageruserinterface.Youcanspecifyasingledirectory,oracomma-separ atedlistofdirectories.Thescratch
directoriesmustbeonthelocalfilesystem,notinHDFS.Youmightspecifydifferentdirectorypathsfordifferenthosts,
depending onthecapacityandspeedoftheavailablestoragedevices.InCDH5.5/Impala2.3orhigher,Impala
successfullystarts(withawarningwrittentothelog)ifitcannotcreateorreadandwritefilesinoneofthescratch
directories.Ifthereislessthan1GBfreeonthefilesystemwherethatdirectoryresides,Impalastillruns,butwritesa
304|ApacheImpalaGuideImpalaSQLLanguageReference
warningmessagetoitslog.IfImpalaencountersanerrorreadingorwritingfilesinascratchdirectoryduringaquery,
Impalalogstheerrorandthequeryfails.
Sortingconsiderations:Although youcanspecifyanORDER BY clauseinanINSERT ... SELECT statement,any
ORDER BY clauseisignoredandtheresultsarenotnecessarily sorted.AnINSERT ... SELECT operationpotentially
createsmanydifferentdatafiles,preparedbydifferentexecutorImpaladaemons, andthereforethenotionofthe
databeingstoredinsortedorderisimpractical.
AnORDER BY clausewithoutanadditional LIMITclauseisignoredinanyviewdefinition.Ifyouneedtosorttheentire
resultsetfromaview,useanORDER BY clauseintheSELECTstatementthatqueriestheview.Youcanstillmakea
simpleâtop10âreportbycombining theORDER BY andLIMITclausesinthesameviewdefinition:
[localhost:21000] > create table unsorted (x bigint);
[localhost:21000] > insert into unsorted values (1), (9), (3), (7), (5), (8), (4), (6),
 (2);
[localhost:21000] > create view sorted_view as select x from unsorted order by x;
[localhost:21000] > select x from sorted_view; -- ORDER BY clause in view has no effect.
+---+
| x |
+---+
| 1 |
| 9 |
| 3 |
| 7 |
| 5 |
| 8 |
| 4 |
| 6 |
| 2 |
+---+
[localhost:21000] > select x from sorted_view order by x; -- View query requires ORDER
 BY at outermost level.
+---+
| x |
+---+
| 1 |
| 2 |
| 3 |
| 4 |
| 5 |
| 6 |
| 7 |
| 8 |
| 9 |
+---+
[localhost:21000] > create view top_3_view as select x from unsorted order by x limit 
3;
[localhost:21000] > select x from top_3_view; -- ORDER BY and LIMIT together in view 
definition are preserved.
+---+
| x |
+---+
| 1 |
| 2 |
| 3 |
+---+
WiththeliftingoftherequirementtoincludeaLIMITclauseineveryORDER BY query(inImpala1.4andhigher):
â¢Nowtheuseofscratchdiskspaceraisesthepossibility ofanâoutofdiskspaceâerroronaparticular Impala
daemon, asopposedtothepreviouspossibility ofanâoutofmemoryâerror.Makesuretokeepatleast1GBfree
onthefilesystemusedfortemporarysortingwork.
InImpala1.2.1andhigher,allNULLvaluescomeattheendoftheresultsetforORDER BY ... ASC queries,andat
thebeginning oftheresultsetforORDER BY ... DESC queries.Ineffect,NULLisconsideredgreaterthanallother
valuesforsortingpurposes. TheoriginalImpalabehavioralwaysputNULLvaluesattheend,evenforORDER BY ...
DESCqueries.ThenewbehaviorinImpala1.2.1makesImpalamorecompatiblewithotherpopulardatabasesystems.
ApacheImpalaGuide|305ImpalaSQLLanguageReference
InImpala1.2.1andhigher,youcanoverrideorspecifythesortingbehaviorforNULLbyaddingtheclauseNULLS
FIRSTorNULLS LAST attheendoftheORDER BY clause.
[localhost:21000] > create table numbers (x int);
[localhost:21000] > insert into numbers values (1), (null), (2), (null), (3);
[localhost:21000] > select x from numbers order by x nulls first;
+------+
| x    |
+------+
| NULL |
| NULL |
| 1    |
| 2    |
| 3    |
+------+
[localhost:21000] > select x from numbers order by x desc nulls first;
+------+
| x    |
+------+
| NULL |
| NULL |
| 3    |
| 2    |
| 1    |
+------+
[localhost:21000] > select x from numbers order by x nulls last;
+------+
| x    |
+------+
| 1    |
| 2    |
| 3    |
| NULL |
| NULL |
+------+
[localhost:21000] > select x from numbers order by x desc nulls last;
+------+
| x    |
+------+
| 3    |
| 2    |
| 1    |
| NULL |
| NULL |
+------+
Relatedinformation:
SeeSELECTStatementonpage295forfurtherexamplesofquerieswiththeORDER BY clause.
Analyticfunctions usetheORDER BY clauseinadifferentcontexttodefinethesequence inwhichrowsareanalyzed.
SeeImpalaAnalyticFunctions onpage506fordetails.
GROUPBYClause
SpecifytheGROUP BY clauseinqueriesthatuseaggregationfunctions, suchasCOUNT() ,SUM(),AVG(),MIN(),and
MAX().SpecifyintheGROUP BY clausethenamesofallthecolumnsthatdonotparticipateintheaggregationoperation.
Complextypeconsiderations:
InCDH5.5/Impala2.3andhigher,thecomplexdatatypesSTRUCT,ARRAY,andMAPareavailable.Thesecolumns
cannotbereferenceddirectlyintheORDER BY clause.Whenyouqueryacomplextypecolumn,youusejoinnotation
toâunpackâ theelementsofthecomplextype,andwithinthejoinqueryyoucanincludeanORDER BY clausetocontrol
theorderintheresultsetofthescalarelementsfromthecomplextype.SeeComplexTypes(CDH5.5orhigheronly)
onpage139fordetailsaboutImpalasupportforcomplextypes.
Zero-lengthstrings:Forpurposes ofclausessuchasDISTINCT andGROUP BY ,Impalaconsiderszero-lengthstrings
(""),NULL,andspacetoallbedifferentvalues.
Examples:
306|ApacheImpalaGuideImpalaSQLLanguageReference
Forexample,thefollowingqueryfindsthe5itemsthatsoldthehighesttotalquantity(usingtheSUM()function, and
alsocountsthenumberofsalestransactions forthoseitems(usingtheCOUNT() function). Becausethecolumn
representingtheitemIDsisnotusedinanyaggregationfunctions, wespecifythatcolumnintheGROUP BY clause.
select
ss_item_sk  as Item,
count(ss_item_sk) as Times_Purchased,
sum(ss_quantity) as Total_Quantity_Purchased
from store_sales
group by ss_item_sk
  order by sum(ss_quantity) desc
  limit 5;
+-------+-----------------+--------------------------+
| item  | times_purchased | total_quantity_purchased |
+-------+-----------------+--------------------------+
| 9325  | 372             | 19072                    |
| 4279  | 357             | 18501                    |
| 7507  | 371             | 18475                    |
| 5953  | 369             | 18451                    |
| 16753 | 375             | 18446                    |
+-------+-----------------+--------------------------+
TheHAVINGclauseletsyoufiltertheresultsofaggregatefunctions, becauseyoucannotrefertothoseexpressionsin
theWHEREclause.Forexample,tofindthe5lowest-sellingitemsthatwereincludedinatleast100salestransactions,
wecouldusethisquery:
select
ss_item_sk  as Item,
count(ss_item_sk) as Times_Purchased,
sum(ss_quantity) as Total_Quantity_Purchased
from store_sales
group by ss_item_sk
having count(ss_item_sk)>= 100
  order by sum(ss_quantity)
  limit 5;
+-------+-----------------+--------------------------+
| item  | times_purchased | total_quantity_purchased |
+-------+-----------------+--------------------------+
| 13943 | 105             | 4087                     |
| 2992  | 101             | 4176                     |
| 4773  | 107             | 4204                     |
| 14350 | 103             | 4260                     |
| 11956 | 102             | 4275                     |
+-------+-----------------+--------------------------+
Whenperformingcalculationsinvolvingscientificorfinancialdata,remember thatcolumnswithtypeFLOATorDOUBLE
arestoredastruefloating-pointnumbers,whichcannotpreciselyrepresenteverypossiblefractionalvalue.Thus,if
youincludeaFLOATorDOUBLEcolumninaGROUP BY clause,theresultsmightnotpreciselymatchliteralvaluesin
yourqueryorfromanoriginalTextdatafile.Useroundingoperations,theBETWEEN operator,oranotherarithmetic
technique tomatchfloating-pointvaluesthatareânearâliteralvaluesyouexpect.Forexample,thisqueryonthe
ss_wholesale_cost columnreturnscostvaluesthatareclosebutnotidenticaltotheoriginalfiguresthatwere
enteredasdecimalfractions.
select ss_wholesale_cost, avg(ss_quantity * ss_sales_price) as avg_revenue_per_sale
  from sales
  group by ss_wholesale_cost
  order by avg(ss_quantity * ss_sales_price) desc
  limit 5;
+-------------------+----------------------+
| ss_wholesale_cost | avg_revenue_per_sale |
+-------------------+----------------------+
| 96.94000244140625 | 4454.351539300434    |
| 95.93000030517578 | 4423.119941283189    |
| 98.37999725341797 | 4332.516490316291    |
| 97.97000122070312 | 4330.480601655014    |
| 98.52999877929688 | 4291.316953108634    |
+-------------------+----------------------+
ApacheImpalaGuide|307ImpalaSQLLanguageReference
Noticehowwholesale costvaluesoriginally enteredasdecimalfractionssuchas96.94and98.38areslightlylarger
orsmallerintheresultset,duetoprecisionlimitationsinthehardwarefloating-pointtypes.Theimpreciserepresentation
ofFLOATandDOUBLEvaluesiswhyfinancialdataprocessingsystemsoftenstorecurrencyusingdatatypesthatare
lessspace-efficientbutavoidthesetypesofroundingerrors.
Relatedinformation:
SELECTStatementonpage295,ImpalaAggregateFunctions onpage479
HAVINGClause
PerformsafilteroperationonaSELECTquery,byexaminingtheresultsofaggregationfunctions ratherthantesting
eachindividual tablerow.Therefore,itisalwaysusedinconjunction withafunctionsuchasCOUNT() ,SUM(),AVG(),
MIN(),orMAX(),andtypicallywiththeGROUP BY clausealso.
Restrictions:
ThefilterexpressionintheHAVINGclausecannotincludeascalarsubquery.
Relatedinformation:
SELECTStatementonpage295,GROUPBYClauseonpage306,ImpalaAggregateFunctions onpage479
LIMITClause
TheLIMITclauseinaSELECTquerysetsamaximumnumberofrowsfortheresultset.Pre-selecting themaximum
sizeoftheresultsethelpsImpalatooptimizememoryusagewhileprocessingadistributedquery.
Syntax:
LIMIT constant_integer_expression
TheargumenttotheLIMITclausemustevaluatetoaconstantvalue.Itcanbeanumericliteral,oranotherkindof
numericexpressioninvolvingoperators,casts,andfunctionreturnvalues.Youcannotrefertoacolumnorusea
subquery.
Usagenotes:
Thisclauseisusefulincontextssuchas:
â¢ToreturnexactlyNitemsfromatop-Nquery,suchasthe10highest-rateditemsinashopping categoryorthe
50hostnamesthatreferthemosttraffictoawebsite.
â¢Todemonstratesomesamplevaluesfromatableoraparticular query.(Todisplaysomearbitraryitems,usea
querywithnoORDER BY clause.AnORDER BY clausecausesadditional memoryand/ordiskusageduringthe
query.)
â¢Tokeepqueriesfromreturninghugeresultsetsbyaccidentifatableislargerthanexpected,oraWHEREclause
matchesmorerowsthanexpected.
Originally ,thevaluefortheLIMITclausehadtobeanumericliteral.InImpala1.2.1andhigher,itcanbeanumeric
expression.
PriortoImpala1.4.0,Impalarequiredanyqueryincluding anORDER BY clausetoalsouseaLIMITclause.InImpala
1.4.0andhigher,theLIMITclauseisoptionalforORDER BY queries.Incaseswheresortingahugeresultsetrequires
enoughmemorytoexceedtheImpalamemorylimitforaparticular executorImpaladaemon, Impalaautomatically
usesatemporarydiskworkareatoperformthesortoperation.
SeeORDERBYClauseonpage302fordetails.
InImpala1.2.1andhigher,youcancombineaLIMITclausewithanOFFSETclausetoproduceasmallresultsetthat
isdifferentfromatop-Nquery,forexample,toreturnitems11through20.Thistechnique canbeusedtosimulate
âpagedâresults.BecauseImpalaqueriestypicallyinvolvesubstantialamountsofI/O,usethistechnique onlyfor
compatibilityincaseswhereyoucannotrewritetheapplicationlogic.Forbestperformance andscalability,wherever
practical,queryasmanyitemsasyouexpecttoneed,cachethemontheapplicationside,anddisplaysmallgroupsof
resultstousersusingapplicationlogic.
308|ApacheImpalaGuideImpalaSQLLanguageReference
Restrictions:
Correlatedsubqueries usedinEXISTSandINoperatorscannotincludeaLIMITclause.
Examples:
ThefollowingexampleshowshowtheLIMITclausecapsthesizeoftheresultset,withthelimitbeingappliedafter
anyotherclausessuchasWHERE.
[localhost:21000] > create database limits;
[localhost:21000] > use limits;
[localhost:21000] > create table numbers (x int);
[localhost:21000] > insert into numbers values (1), (3), (4), (5), (2);
Inserted 5 rows in 1.34s
[localhost:21000] > select x from numbers limit 100;
+---+
| x |
+---+
| 1 |
| 3 |
| 4 |
| 5 |
| 2 |
+---+
Returned 5 row(s) in 0.26s
[localhost:21000] > select x from numbers limit 3;
+---+
| x |
+---+
| 1 |
| 3 |
| 4 |
+---+
Returned 3 row(s) in 0.27s
[localhost:21000] > select x from numbers where x > 2 limit 2;
+---+
| x |
+---+
| 3 |
| 4 |
+---+
Returned 2 row(s) in 0.27s
Fortop-Nandbottom-Nqueries,youusetheORDER BY andLIMITclausestogether:
[localhost:21000] > select x as "Top 3" from numbers order by x desc limit 3;
+-------+
| top 3 |
+-------+
| 5     |
| 4     |
| 3     |
+-------+
[localhost:21000] > select x as "Bottom 3" from numbers order by x limit 3;
+----------+
| bottom 3 |
+----------+
| 1        |
| 2        |
| 3        |
+----------+
YoucanuseconstantvaluesbesidesintegerliteralsastheLIMITargument:
-- Other expressions that yield constant integer values work too.
SELECT x FROM t1 LIMIT 1e6;                        -- Limit is one million.
SELECT x FROM t1 LIMIT length('hello world');      -- Limit is 11.
SELECT x FROM t1 LIMIT 2+2;                        -- Limit is 4.
SELECT x FROM t1 LIMIT cast(truncate(9.9) AS INT); -- Limit is 9.
ApacheImpalaGuide|309ImpalaSQLLanguageReference
OFFSETClause
TheOFFSETclauseinaSELECTquerycausestheresultsettostartsomenumberofrowsafterthelogicalfirstitem.
Theresultsetisnumberedstartingfromzero,soOFFSET 0 producesthesameresultasleavingouttheOFFSETclause.
AlwaysusethisclauseincombinationwithORDER BY (sothatitisclearwhichitemshouldbefirst,second,andsoon)
andLIMIT(sothattheresultsetcoversabounded range,suchasitems0-9,100-199, andsoon).
InImpala1.2.1andhigher,youcancombineaLIMITclausewithanOFFSETclausetoproduceasmallresultsetthat
isdifferentfromatop-Nquery,forexample,toreturnitems11through20.Thistechnique canbeusedtosimulate
âpagedâresults.BecauseImpalaqueriestypicallyinvolvesubstantialamountsofI/O,usethistechnique onlyfor
compatibilityincaseswhereyoucannotrewritetheapplicationlogic.Forbestperformance andscalability,wherever
practical,queryasmanyitemsasyouexpecttoneed,cachethemontheapplicationside,anddisplaysmallgroupsof
resultstousersusingapplicationlogic.
Examples:
Thefollowingexampleshowshowyoucouldrunaâpagingâqueryoriginally writtenforatraditionaldatabaseapplication.
BecausetypicalImpalaqueriesprocessmegabytesorgigabytesofdataandreadlargedatafilesfromdiskeachtime,
itisinefficienttorunaseparatequerytoretrieveeachsmallgroupofitems.Usethistechnique onlyforcompatibility
whileportingolderapplications,thenrewritetheapplicationcodetouseasinglequerywithalargeresultset,and
displaypagesofresultsfromthecachedresultset.
[localhost:21000] > create table numbers (x int);
[localhost:21000] > insert into numbers select x from very_long_sequence;
Inserted 1000000 rows in 1.34s
[localhost:21000] > select x from numbers order by x limit 5 offset 0;
+----+
| x  |
+----+
| 1  |
| 2  |
| 3  |
| 4  |
| 5  |
+----+
[localhost:21000] > select x from numbers order by x limit 5 offset 5;
+----+
| x  |
+----+
| 6  |
| 7  |
| 8  |
| 9  |
| 10 |
+----+
UNIONClause
TheUNIONclauseletsyoucombinetheresultsetsofmultiplequeries.Bydefault,theresultsetsarecombined asif
theDISTINCT operatorwasapplied.
Syntax:
query_1 UNION [DISTINCT | ALL] query_2
Usagenotes:
TheUNIONkeywordbyitselfisthesameasUNION DISTINCT .Becauseeliminatingduplicatescanbeamemory-intensive
processforalargeresultset,preferUNION ALL wherepractical.(Thatis,whenyouknowthedifferentqueriesinthe
unionwillnotproduceanyduplicates,orwheretheduplicatevaluesareacceptable.)
WhenanORDER BY clauseappliestoaUNION ALL orUNIONquery,inImpala1.4andhigher,theLIMITclauseisno
longerrequired.TomaketheORDER BY andLIMITclausesapplytotheentireresultset,turntheUNIONqueryinto
asubquery,SELECTfromthesubquery,andputtheORDER BY clauseattheend,outsidethesubquery.
Examples:
310|ApacheImpalaGuideImpalaSQLLanguageReference
First,setupsomesampledata,including duplicate1values:
[localhost:21000] > create table few_ints (x int);
[localhost:21000] > insert into few_ints values (1), (1), (2), (3);
[localhost:21000] > set default_order_by_limit=1000;
ThisexampleshowshowUNION ALL returnsallrowsfrombothqueries,withoutanyadditional filteringtoeliminate
duplicates.ForthelargeresultsetscommonwithImpalaqueries,thisisthemostmemory-efficienttechnique.
[localhost:21000] > select x from few_ints order by x;
+---+
| x |
+---+
| 1 |
| 1 |
| 2 |
| 3 |
+---+
Returned 4 row(s) in 0.41s
[localhost:21000] > select x from few_ints union all select x from few_ints;
+---+
| x |
+---+
| 1 |
| 1 |
| 2 |
| 3 |
| 1 |
| 1 |
| 2 |
| 3 |
+---+
Returned 8 row(s) in 0.42s
[localhost:21000] > select * from (select x from few_ints union all select x from 
few_ints) as t1 order by x;
+---+
| x |
+---+
| 1 |
| 1 |
| 1 |
| 1 |
| 2 |
| 2 |
| 3 |
| 3 |
+---+
Returned 8 row(s) in 0.53s
[localhost:21000] > select x from few_ints union all select 10;
+----+
| x  |
+----+
| 10 |
| 1  |
| 1  |
| 2  |
| 3  |
+----+
Returned 5 row(s) in 0.38s
ThisexampleshowshowtheUNIONclausewithouttheALLkeywordcondenses theresultsettoeliminateallduplicate
values,makingthequerytakemoretimeandpotentiallymorememory.Theextraprocessingtypicallymakesthis
technique notrecommended forqueriesthatreturnresultsetswithmillionsorbillionsofvalues.
[localhost:21000] > select x from few_ints union select x+1 from few_ints;
+---+
| x |
+---+
| 3 |
| 4 |
ApacheImpalaGuide|311ImpalaSQLLanguageReference
| 1 |
| 2 |
+---+
Returned 4 row(s) in 0.51s
[localhost:21000] > select x from few_ints union select 10;
+----+
| x  |
+----+
| 2  |
| 10 |
| 1  |
| 3  |
+----+
Returned 4 row(s) in 0.49s
[localhost:21000] > select * from (select x from few_ints union select x from few_ints)
 as t1 order by x;
+---+
| x |
+---+
| 1 |
| 2 |
| 3 |
+---+
Returned 3 row(s) in 0.53s
Subqueries inImpalaSELECTStatements
Asubqueryisaquerythatisnestedwithinanotherquery.Subqueries letqueriesononetabledynamicallyadaptbased
onthecontentsofanothertable.Thistechnique providesgreatflexibilityandexpressivepowerforSQLqueries.
AsubquerycanreturnaresultsetforuseintheFROMorWITHclauses,orwithoperatorssuchasINorEXISTS.
Ascalarsubqueryproducesaresultsetwithasinglerowcontainingasinglecolumn,typicallyproducedbyanaggregation
functionsuchasMAX()orSUM().Thissingleresultvaluecanbesubstitutedinscalarcontextssuchasargumentsto
comparison operators.Iftheresultsetisempty,thevalueofthescalarsubqueryisNULL.Forexample,thefollowing
queryfindsthemaximumvalueofT2.YandthensubstitutesthatvalueintotheWHEREclauseoftheouterblockthat
queriesT1:
SELECT x FROM t1 WHERE x > (SELECT MAX(y) FROM t2);
Uncorrelatedsubqueries donotrefertoanytablesfromtheouterblockofthequery.Thesamevalueorsetofvalues
producedbythesubqueryisusedwhenevaluatingeachrowfromtheouterqueryblock.Inthisexample,thesubquery
returnsanarbitrarynumberofvaluesfromT2.Y,andeachvalueofT1.Xistestedformembershipinthatsameset
ofvalues:
SELECT x FROM t1 WHERE x IN (SELECT y FROM t2);
Correlatedsubqueries compareoneormorevaluesfromtheouterqueryblocktovaluesreferencedintheWHERE
clauseofthesubquery.EachrowevaluatedbytheouterWHEREclausecanbeevaluatedusingadifferentsetofvalues.
Thesekindsofsubqueries arerestrictedinthekindsofcomparisons theycandobetweencolumnsoftheinnerand
outertables.(SeethefollowingRestrictionsitem.)
Forexample,thefollowingqueryfindsalltheemployeeswithsalariesthatarehigherthanaveragefortheirdepartmen t.
ThesubquerypotentiallycomputesadifferentAVG()valueforeachemployee.
SELECT employee_name, employee_id FROM employees one WHERE
  salary > (SELECT avg(salary) FROM employees two WHERE one.dept_id = two.dept_id);
Syntax:
SubqueryintheFROMclause:
SELECT select_list  FROM table_ref  [, table_ref  ...]
table_ref  ::= table_name  | (select_statement )
312|ApacheImpalaGuideImpalaSQLLanguageReference
Subqueries inWHEREclause:
WHERE valuecomparison_operator  (scalar_select_statement )
WHERE value [NOT] IN ( select_statement )
WHERE [NOT] EXISTS ( correlated_select_statement )
WHERE NOT EXISTS ( correlated_select_statement )
comparison_operator isanumericcomparison suchas=,<=,!=,andsoon,orastringcomparison operatorsuch
asLIKEorREGEXP.
Although youcanusenon-equality comparison operatorssuchas<or>=,thesubquerymustincludeatleastone
equalitycomparison betweenthecolumnsoftheinnerandouterqueryblocks.
Allsyntaxisavailableforbothcorrelatedanduncorrelatedqueries,exceptthattheNOT EXISTS clausecannotbe
usedwithanuncorrelatedsubquery.
Impalasubqueries canbenestedarbitrarilydeep.
Standardscompliance: IntroducedinSQL:1999 .
Examples:
Thisexampleillustrateshowsubqueries canbeusedintheFROMclausetoorganizethetablenames,columnnames,
andcolumnvaluesbyproducingintermediateresultsets,especially forjoinqueries.
SELECT avg(t1.x), max(t2.y) FROM
  (SELECT id, cast(a AS DECIMAL(10,5)) AS x FROM raw_data WHERE a BETWEEN 0 AND 100) AS
 t1
  JOIN
  (SELECT id, length(s) AS y FROM raw_data WHERE s LIKE 'A%') AS t2;
  USING (id);
TheseexamplesshowhowaquerycantestfortheexistenceofvaluesinaseparatetableusingtheEXISTS() operator
withasubquery.
Thefollowingexamplesshowhowavaluecanbecomparedagainstasetofvaluesreturnedbyasubquery.
SELECT count(x) FROM t1 WHERE EXISTS(SELECT 1 FROM t2 WHERE t1.x = t2.y * 10);
SELECT x FROM t1 WHERE x IN (SELECT y FROM t2 WHERE state = 'CA');
Thefollowingexamplesdemonstratescalarsubqueries. Whenasubqueryisknowntoreturnasinglevalue,youcan
substituteitwhereyouwouldnormally putaconstantvalue.
SELECT x FROM t1 WHERE y = (SELECT max(z) FROM t2);
SELECT x FROM t1 WHERE y > (SELECT count(z) FROM t2);
Usagenotes:
Ifthesametableisreferencedinboththeouterandinnerqueryblocks,constructatablealiasintheouterqueryblock
anduseafullyqualified nametodistinguishtheinnerandoutertablereferences:
SELECT * FROM t1 one WHERE id IN (SELECT parent FROM t1 two WHERE t1.parent = t2.id);
TheSTRAIGHT_JOIN hintaffectsthejoinorderoftablereferencesinthequeryblockcontainingthehint.Itdoesnot
affectthejoinorderofnestedqueries,suchasviews,inlineviews,orWHERE-clausesubqueries. Tousethishintfor
performance tuningofcomplexqueries,applythehinttoallqueryblocksthatneedafixedjoinorder.
Internaldetails:
Internally,subqueries involvingIN,NOT IN,EXISTS,orNOT EXISTS clausesarerewrittenintojoinqueries.Depending
onthesyntax,thesubquerymightberewrittentoanouterjoin,semijoin,crossjoin,orantijoin.
ApacheImpalaGuide|313ImpalaSQLLanguageReference
Aqueryisprocesseddifferentlydepending onwhetherthesubquerycallsanyaggregationfunctions. Therearecorrelated
anduncorrelatedforms,withandwithoutcallstoaggregationfunctions. Eachofthesefourcategoriesisrewritten
differently.
Columnstatisticsconsiderations:
Becausequeriesthatincludecorrelatedanduncorrelatedsubqueries intheWHEREclausearewrittenintojoinqueries,
toachievebestperformance, followthesameguidelines forrunningtheCOMPUTE STATS statementasyoudofor
tablesinvolvedinregularjoinqueries.RuntheCOMPUTE STATS statementforeachassociatedtablesafterloadingor
substantiallychanging thedatainthattable.SeeTableandColumnStatisticsonpage575fordetails.
Addedin:Subqueries aresubstantiallyenhanced startinginImpala2.0forCDH4,andCDH5.2.0.Now,theycanbe
usedintheWHEREclause,incombinationwithclausessuchasEXISTSandIN,ratherthanjustintheFROMclause.
Restrictions:
TheinitialImpalasupportfornestedsubqueries addressesthemostcommonusecases.Somerestrictionsremain:
â¢Although youcanusesubqueries inaqueryinvolvingUNIONorUNION ALL inImpala2.1.0andhigher,currently
youcannotconstructaunionoftwosubqueries (forexample,intheargumentofanINorEXISTSoperator).
â¢Subqueries returningscalarvaluescannotbeusedwiththeoperatorsANYorALL.(Impaladoesnotcurrentlyhave
aSOMEoperator,butifitdid,thesamerestrictionwouldapply.)
â¢FortheEXISTSandNOT EXISTS clauses,anysubquerycomparing valuesfromtheouterqueryblocktoanother
tablemustuseatleastoneequalitycomparison, notexclusivelyotherkindsofcomparisons suchaslessthan,
greaterthan,BETWEEN ,or!=.
â¢Currently,ascalarsubquerycannotbeusedasthefirstorsecondargumenttotheBETWEEN operator.
â¢AsubquerycannotbeusedinsideanORconjunction. Expressionsinsideasubquery,forexampleintheWHERE
clause,canuseORconjunctions; therestrictiononlyappliestopartsofthequeryâaboveâthesubquery.
â¢Scalarsubqueries areonlysupportedinnumericcontexts.Youcannotuseascalarsubqueryasanargumentto
theLIKE,REGEXP,orRLIKEoperators,orcompareittoavalueofanon-numeric typesuchasTIMESTAMP or
BOOLEAN .
â¢Youcannotusesubqueries withtheCASEfunctiontogeneratethecomparison value,thevaluestobecompared
against,orthereturnvalue.
â¢AsubqueryisnotallowedinthefilterconditionfortheHAVINGclause.(Strictlyspeaking,asubquerycannot
appearanywhereoutsidetheWITH,FROM,andWHEREclauses.)
â¢Youmustuseafullyqualified name(table_name .column_name or
database_name .table_name .column_name )whenreferringtoanycolumnfromtheouterqueryblockwithin
asubquery.
â¢TheTABLESAMPLE clauseoftheSELECTstatementdoesnotapplytoatablereferencederivedfromaview,a
subquery,oranythingotherthanarealbasetable.ThisclauseonlyworksfortablesbackedbyHDFSorHDFS-like
datafiles,thereforeitdoesnotapplytoKuduorHBasetables.
Complextypeconsiderations:
Forthecomplextypes(ARRAY,STRUCT,andMAP)availableinCDH5.5/Impala2.3andhigher,thejoinqueriesthat
âunpackâ complextypecolumnsoftenusecorrelatedsubqueries intheFROMclause.Forexample,ifthefirsttablein
thejoinclauseisCUSTOMER ,thesecondjoinclausemighthaveasubquerythatselectsfromthecolumn
CUSTOMER.C_ORDERS ,whichisanARRAY.Thesubqueryre-evaluatestheARRAYelementscorresponding toeachrow
fromtheCUSTOMER table.SeeComplexTypes(CDH5.5orhigheronly)onpage139fordetailsandexamplesofusing
subqueries withcomplextypes.
Relatedinformation:
EXISTSOperatoronpage176,INOperatoronpage180
314|ApacheImpalaGuideImpalaSQLLanguageReference
TABLESAMPLEClause
SpecifytheTABLESAMPLE clausewhenyouneedtoexplorethedatadistribution withinthetable,thetableisvery
large,anditisimpracticalorunnecessar ytoprocessallthedatafromthetableorselectedpartitions.
Theclausemakesthequeryprocessarandomizedsetofdatafilesfromthetable,sothatthetotalvolumeofdatais
greaterthanorequaltothespecified percentageofdatabyteswithinthattable.(Orthedatabyteswithinthesetof
partitions thatremainafterpartition pruningisperformed.)
Syntax:
TABLESAMPLE SYSTEM( percentage ) [REPEATABLE( seed)]
TheTABLESAMPLE clausecomesimmediatelyafteratablenameortablealias.
TheSYSTEMkeywordrepresentsthesampling method.Currently,Impalaonlysupports asinglesampling method
namedSYSTEM.
Thepercentageargumentisanintegerliteralfrom0to100.Apercentageof0producesanemptyresultsetfora
particular tablereference,whileapercentageof100usestheentirecontents.Becausethesampling worksbyselecting
arandomsetofdatafiles,theproportionofsampleddatafromthetablemaybegreaterthanthespecified percentage,
basedonthenumberandsizesoftheunderlying datafiles.Seetheusagenotesfordetails.
TheoptionalREPEATABLE keywordletsyouspecifyanarbitrarypositiveintegerseedvaluethatensuresthatwhen
thequeryisrunagain,thesampling selectsthesamesetofdatafileseachtime.REPEATABLE doesnothaveadefault
value.IfyouomittheREPEATABLE keyword,therandomseedisderivedfromthecurrenttime.
Addedin:CDH5.12.0/Impala2.9.0
SeeCOMPUTE STATSStatementfortheTABLESAMPLE clauseusedintheCOMPUTE STATS statement.
Usagenotes:
Youmightusethisclausewithaggregationqueries,suchasfindingtheapproximateaverage,minimum, ormaximum
whereexactprecisionisnotrequired.Youcanusethesefindingstoplanthemosteffectivestrategyforconstructing
queriesagainstthefulltableordesigning apartitioning strategyforthedata.
SomeotherdatabasesystemshaveaTABLESAMPLE clause.TheImpalasyntaxforthisclauseismodeled onthesyntax
forpopularrelationaldatabases,nottheHiveTABLESAMPLE clause.Forexample,thereisnoBUCKETS keywordasin
HiveQL.
Theprecisionofthepercentagethresholddependsonthenumberandsizesoftheunderlying datafiles.Impalabrings
inadditional datafiles,oneatatime,untilthenumberofbytesexceedsthespecified percentagebasedonthetotal
numberofbytesfortheentiresetoftabledata.Theprecisionofthepercentagethresholdishigherwhenthetable
containsmanydatafileswithconsistentsizes.Seethecodelistingslaterinthissectionforexamples.
Whenyouestimatecharacteristicsofthedatadistribution basedonsampling apercentageofthetabledata,beaware
thatthedatamightbeunevenlydistributedbetweendifferentfiles.Donotassumethatthepercentagefigurereflects
thepercentageofrowsinthetable.Forexample,onefilemightcontainallblankvaluesforaSTRINGcolumn,while
anotherfilecontainslongstringsinthatcolumn;therefore,onefilecouldcontainmanymorerowsthananother.
Likewise,atablecreatedwiththeSORT BY clausemightcontainnarrowrangesofvaluesforthesortcolumns,making
itimpracticaltoextrapolatethenumberofdistinctvaluesforthosecolumnsbasedonsampling onlysomeofthedata
files.
Becauseasampleofthetabledatamightnotcontainallvaluesforaparticular column,iftheTABLESAMPLE isused
inajoinquery,thekeyrelationshipsbetweenthetablesmightproduceincompleteresultsetscomparedtojoinsusing
allthetabledata.Forexample,ifyoujoin50%oftableAwith50%oftableB,somevaluesinthejoincolumnsmight
notmatchbetweenthetwotables,eventhoughoverallthereisa1:1relationshipbetweenthetables.
TheREPEATABLE keywordmakesidenticalqueriesuseaconsistentsetofdatafileswhenthequeryisrepeated.You
specifyanarbitraryintegerkeythatactsasaseedvaluewhenImpalarandomly selectsthesetofdatafilestousein
thequery.Thistechnique letsyouverifycorrectness,examineperformance, andsoonforqueriesusingthe
TABLESAMPLE clausewithoutthesampleddatabeingdifferenteachtime.Therepeatableaspectisreset(thatis,the
ApacheImpalaGuide|315ImpalaSQLLanguageReference
setofselecteddatafilesmaychange)anytimethecontentsofthetablechange.Thestatementsoroperationsthat
canmakesampling resultsnon-repeatableare:
â¢INSERT.
â¢TRUNCATE TABLE .
â¢LOAD DATA .
â¢REFRESH orINVALIDATE METADATA afterfilesareaddedorremovedbyanon-Impala mechanism.
â¢
ThisclauseissimilarinsomewaystotheLIMITclause,becausebothservetolimitthesizeoftheintermediatedata
andfinalresultset.LIMIT 0 ismoreefficientthanTABLESAMPLE SYSTEM(0) forverifyingthataquerycanexecute
withoutproducinganyresults.TABLESAMPLE SYSTEM( n)oftenmakesqueryprocessingmoreefficientthanusinga
LIMITclausebyitself,becauseallphasesofqueryexecutionuselessdataoverall.Iftheintentistoretrievesome
representativevaluesfromthetableinanefficientway,youmightcombineTABLESAMPLE ,ORDER BY ,andLIMIT
clauseswithinasinglequery.
Partitioning:
Whenyouqueryapartitioned table,anypartitionpruninghappensbeforeImpalaselectsthedatafilestosample.For
example,inatablepartitioned byyear,aquerywithWHERE year = 2017 andaTABLESAMPLE SYSTEM(10) clause
wouldsampledatafilesrepresentingatleast10%ofthebytespresentinthe2017partition.
AmazonS3considerations:
ThisclauseappliestoS3tablesthesamewayastableswithdatafilesstoredonHDFS.
ADLSconsiderations:
ThisclauseappliestoADLStablesthesamewayastableswithdatafilesstoredonHDFS.
Kuduconsiderations:
ThisclausedoesnotapplytoKudutables.
HBaseconsiderations:
ThisclausedoesnotapplytoHBasetables.
Performance considerations:
Fromaperformance perspective,theTABLESAMPLE clauseisespecially valuableforexploratoryqueriesontext,Avro,
orotherfileformatsotherthanParquet.Text-basedorrow-orientedfileformatsmustprocesssubstantialamounts
ofredundantdataforqueriesthatderiveaggregateresultssuchasMAX(),MIN(),orAVG()forasinglecolumn.
Therefore,youmightuseTABLESAMPLE earlyintheETLpipeline,whendataisstillinrawtextformatandhasnot
beenconvertedtoParquetormovedintoapartitioned table.
Restrictions:
Thisclauseappliesonlytotablesthatuseastoragelayerwithunderlying rawdatafiles,suchasHDFS,AmazonS3,or
MicrosoftADLS.
Thisclausedoesnotapplytotablereferencesthatrepresentviews.AquerythatappliestheTABLESAMPLE clauseto
avieworasubqueryfailswithasemanticerror.
Becausethesampling worksatthelevelofentiredatafiles,itisbynaturecoarse-grained.Itispossibletospecifya
smallsamplepercentagebutstillprocessasubstantialportionofthetabledataifthetablecontainsrelativelyfew
datafiles,ifeachdatafileisverylarge,orifthedatafilesvarysubstantiallyinsize.Besurethatyouunderstandthe
datadistribution andphysicalfilelayoutsothatyoucanverifyiftheresultsaresuitableforextrapolation.Forexample,
ifthetablecontainsonlyasingledatafile,theâsampleâwillconsistofallthetabledataregardlessofthepercentage
youspecify.Ifthetablecontainsdatafilesof1GiB,1GiB,and1KiB,whenyouspecifyasampling percentageof50
youwouldeitherprocessslightlymorethan50%ofthetable(1GiB+1KiB)oralmosttheentiretable(1GiB+1GiB),
depending onwhichdatafileswereselectedforsampling.
316|ApacheImpalaGuideImpalaSQLLanguageReference
Ifdatafilesareaddedbyanon-Impala mechanism, andthetablemetadataisnotupdatedbyaREFRESH orINVALIDATE
METADATA statement,theTABLESAMPLE clausedoesnotconsiderthosenewfileswhencomputing thenumberof
bytesinthetableorselecting whichfilestosample.
Ifdatafilesareremovedbyanon-Impala mechanism, andthetablemetadataisnotupdatedbyaREFRESH or
INVALIDATE METADATA statement,thequeryfailsiftheTABLESAMPLE clauseattemptstoreferenceanyofthe
missingfiles.
Examples:
ThefollowingexamplesdemonstratetheTABLESAMPLE clause.Theseexamplesintentionallyuseverysmalldatasets
toillustratehowthenumberoffiles,sizeofeachfile,andoverallsizeofdatainthetableinteractwiththepercentage
specified intheclause.
Theseexamplesuseanunpartitioned table,containingseveralfilesofroughlythesamesize:
create table sample_demo (x int, s string);
insert into sample_demo values (1, 'one');
insert into sample_demo values (2, 'two');
insert into sample_demo values (3, 'three');
insert into sample_demo values (4, 'four');
insert into sample_demo values (5, 'five');
show files in sample_demo;
+---------------------+------+-----------+
| Path                | Size | Partition |
+---------------------+------+-----------+
| 991213608_data.0.   | 7B   |           |
| 982196806_data.0.   | 6B   |           |
| _2122096884_data.0. | 8B   |           |
| _586325431_data.0.  | 6B   |           |
| 1894746258_data.0.  | 7B   |           |
+---------------------+------+-----------+
show table stats sample_demo;
+-------+--------+------+--------+-------------------------+
| #Rows | #Files | Size | Format | Location                |
+-------+--------+------+--------+-------------------------+
| -1    | 5      | 34B  | TEXT   | /tsample.db/sample_demo |
+-------+--------+------+--------+-------------------------+
Aquerythatsamples50%ofthetablemustprocessatleast17bytesofdata.Basedonthesizesofthedatafiles,we
canpredictthateachsuchqueryuses3arbitraryfiles.Any1or2filesarenotenoughtoreach50%ofthetotaldata
inthetable(34bytes),sothequeryaddsmorefilesuntilitpassesthe50%threshold:
select distinct x from sample_demo tablesample system(50);
+---+
| x |
+---+
| 4 |
| 1 |
| 5 |
+---+
select distinct x from sample_demo tablesample system(50);
+---+
| x |
+---+
| 5 |
| 4 |
| 2 |
+---+
select distinct x from sample_demo tablesample system(50);
+---+
| x |
+---+
| 5 |
ApacheImpalaGuide|317ImpalaSQLLanguageReference
| 3 |
| 2 |
+---+
Tohelprunreproducibleexperimen ts,theREPEATABLE clausecausesImpalatochoosethesamesetoffilesforeach
query.Although thedatasetbeingconsideredisdeterministic,theorderofresultsvaries(intheabsenceofanORDER
BYclause)becauseofthewaydistributedqueriesareprocessed:
select distinct x from sample_demo
  tablesample system(50) repeatable (12345);
+---+
| x |
+---+
| 3 |
| 2 |
| 1 |
+---+
select distinct x from sample_demo
  tablesample system(50) repeatable (12345);
+---+
| x |
+---+
| 2 |
| 1 |
| 3 |
+---+
Thefollowingexamplesshowhowunevendatadistribution affectswhichdataissampled. Addinganotherdatafile
containingalongstringvaluechangesthethresholdfor50%ofthetotaldatainthetable:
insert into sample_demo values
(1000, 'Boyhood is the longest time in life for a boy. The last term of the school-year
 is made of decades, not of weeks, and living through them is like waiting for the 
millennium. Booth Tarkington');
show files in sample_demo;
+---------------------+------+-----------+
| Path                | Size | Partition |
+---------------------+------+-----------+
| 991213608_data.0.   | 7B   |           |
| 982196806_data.0.   | 6B   |           |
| _253317650_data.0.  | 196B |           |
| _2122096884_data.0. | 8B   |           |
| _586325431_data.0.  | 6B   |           |
| 1894746258_data.0.  | 7B   |           |
+---------------------+------+-----------+
show table stats sample_demo;
+-------+--------+------+--------+-------------------------+
| #Rows | #Files | Size | Format | Location                |
+-------+--------+------+--------+-------------------------+
| -1    | 6      | 230B | TEXT   | /tsample.db/sample_demo |
+-------+--------+------+--------+-------------------------+
EventhoughthequeriesdonotrefertotheScolumncontainingthelongvalue,allthesampling queriesincludethe
datafilecontainingthecolumnvalueX=1000,becausethequerycannotreachthe50%threshold(115bytes)without
including thatfile.Thelargefilemightbeconsideredfirst,inwhichcaseitistheonlyfileprocessedbythequery.Or
anarbitrarysetofotherfilesmightbeconsideredfirst.
select distinct x from sample_demo tablesample system(50);
+------+
| x    |
+------+
| 1000 |
| 3    |
| 1    |
+------+
318|ApacheImpalaGuideImpalaSQLLanguageReference
select distinct x from sample_demo tablesample system(50);
+------+
| x    |
+------+
| 1000 |
+------+
select distinct x from sample_demo tablesample system(50);
+------+
| x    |
+------+
| 1000 |
| 4    |
| 2    |
| 1    |
+------+
ThefollowingexamplesdemonstratehowtheTABLESAMPLE clauseinteractswithothertableaspects,suchas
partitioning andfileformat:
create table sample_demo_partitions (x int, s string) partitioned by (n int) stored as
 parquet;
insert into sample_demo_partitions partition (n = 1) select * from sample_demo;
insert into sample_demo_partitions partition (n = 2) select * from sample_demo;
insert into sample_demo_partitions partition (n = 3) select * from sample_demo;
show files in sample_demo_partitions;
+--------------------------------+--------+-----------+
| Path                           | Size   | Partition |
+--------------------------------+--------+-----------+
| 000000_364262785_data.0.parq   | 1.24KB | n=1       |
| 000001_973526736_data.0.parq   | 566B   | n=1       |
| 0000000_1300598134_data.0.parq | 1.24KB | n=2       |
| 0000001_689099063_data.0.parq  | 568B   | n=2       |
| 0000000_1861371709_data.0.parq | 1.24KB | n=3       |
| 0000001_1065507912_data.0.parq | 566B   | n=3       |
+--------------------------------+--------+-----------+
show table stats tablesample_demo_partitioned;
+-------+-------+--------+--------+---------+----------------------------------------------+
| n     | #Rows | #Files | Size   | Format  | Location                                
     |
+-------+-------+--------+--------+---------+----------------------------------------------+
| 1     | -1    | 2      | 1.79KB | PARQUET | /tsample.db/tablesample_demo_partitioned/n=1
 |
| 2     | -1    | 2      | 1.80KB | PARQUET | /tsample.db/tablesample_demo_partitioned/n=2
 |
| 3     | -1    | 2      | 1.79KB | PARQUET | /tsample.db/tablesample_demo_partitioned/n=3
 |
| Total | -1    | 6      | 5.39KB |         |                                         
     |
+-------+-------+--------+--------+---------+----------------------------------------------+
Ifthequerydoesnotinvolveanypartition pruning,thesampling appliestothedatavolumeoftheentiretable:
-- 18 rows total.
select count(*) from sample_demo_partitions;
+----------+
| count(*) |
+----------+
| 18       |
+----------+
-- The number of rows per data file is not
-- perfectly balanced, therefore the count
-- is different depending on which set of files
-- is considered.
select count(*) from sample_demo_partitions
ApacheImpalaGuide|319ImpalaSQLLanguageReference
  tablesample system(75);
+----------+
| count(*) |
+----------+
| 14       |
+----------+
select count(*) from sample_demo_partitions
  tablesample system(75);
+----------+
| count(*) |
+----------+
| 16       |
+----------+
Ifthequeryonlyprocessescertainpartitions, thequerycomputesthesampling thresholdbasedonthedatasizeand
setoffilesonlyfromtherelevantpartitions:
select count(*) from sample_demo_partitions
  tablesample system(50) where n = 1;
+----------+
| count(*) |
+----------+
| 6        |
+----------+
select count(*) from sample_demo_partitions
  tablesample system(50) where n = 1;
+----------+
| count(*) |
+----------+
| 2        |
+----------+
Relatedinformation:
SELECTStatementonpage295
WITHClause
AclausethatcanbeaddedbeforeaSELECTstatement,todefinealiasesforcomplicatedexpressionsthatarereferenced
multipletimeswithinthebodyoftheSELECT.SimilartoCREATE VIEW ,exceptthatthetableandcolumnnames
definedintheWITHclausedonotpersistafterthequeryfinishes,anddonotconflictwithnamesusedinactualtables
orviews.Alsoknownasâsubqueryfactoringâ.
Youcanrewriteaqueryusingsubqueries toworkthesameaswiththeWITHclause.Thepurposes oftheWITHclause
are:
â¢Convenienceandeaseofmaintenancefromlessrepetitionwiththebodyofthequery.Typicallyusedwithqueries
involvingUNION,joins,oraggregationfunctions wherethesimilarcomplicatedexpressionsarereferencedmultiple
times.
â¢SQLcodethatiseasiertoreadandunderstandbyabstractingthemostcomplexpartofthequeryintoaseparate
block.
â¢ImprovedcompatibilitywithSQLfromotherdatabasesystemsthatsupportthesameclause(primarily Oracle
Database).
Note:
TheImpalaWITHclausedoesnotsupportrecursivequeriesintheWITH,whichissupportedin
someotherdatabasesystems.
Standardscompliance: IntroducedinSQL:1999 .
320|ApacheImpalaGuideImpalaSQLLanguageReference
Examples:
-- Define 2 subqueries that can be referenced from the body of a longer query.
with t1 as (select 1), t2 as (select 2) insert into tab select * from t1 union all select
 * from t2;
-- Define one subquery at the outer level, and another at the inner level as part of 
the
-- initial stage of the UNION ALL query.
with t1 as (select 1) (with t2 as (select 2) select * from t2) union all select * from
 t1;
DISTINCTOperator
TheDISTINCT operatorinaSELECTstatementfilterstheresultsettoremoveduplicates.
-- Returns the unique values from one column.
-- NULL is included in the set of values if any rows have a NULL in this column.
SELECT DISTINCT c_birth_country FROM customer;
-- Returns the unique combinations of values from multiple columns.
SELECT DISTINCT c_salutation, c_last_name FROM customer;
YoucanuseDISTINCT incombinationwithanaggregationfunction, typicallyCOUNT() ,tofindhowmanydifferent
valuesacolumncontains.
-- Counts the unique values from one column.
-- NULL is not included as a distinct value in the count.
SELECT COUNT(DISTINCT c_birth_country) FROM customer;
-- Counts the unique combinations of values from multiple columns.
SELECT COUNT(DISTINCT c_salutation, c_last_name) FROM customer;
Zero-lengthstrings:Forpurposes ofclausessuchasDISTINCT andGROUP BY ,Impalaconsiderszero-lengthstrings
(""),NULL,andspacetoallbedifferentvalues.
Note:
IncontrastwithsomedatabasesystemsthatalwaysreturnDISTINCT valuesinsortedorder,Impala
doesnotdoanyorderingofDISTINCT values.AlwaysincludeanORDER BY clauseifyouneedthe
valuesinalphabeticalornumericsortedorder.
SETStatement
TheSETstatementspecifiesvaluesforqueryoptionsthatcontroltheruntimebehaviorofotherstatementswithin
thesamesession.
Whenissuedinimpala-shell ,theSETcommand isinterpretedasanimpala-shell command thathasdifferences
fromtheSQLSETstatement.Seeimpala-shell Command Referenceonpage721fortheinformationabouttheSET
command inimpala-shell .
Syntax:
SET
SET ALL
SET query_option =option_value
SET query_option =""
SETandSET ALL withnoargumentsreturnaresultsetconsistingofalltheapplicablequeryoptionsandtheircurrent
values.
Thequery_optionandoption_value arecase-insensitiv e.
ApacheImpalaGuide|321ImpalaSQLLanguageReference
Unliketheimpala-shell command versionofSET,whenusedasaSQLstatement,thestringvaluesforoption_value
needtobequoted,e.g.SET option="new_value" .
TheSET query_option  = ""statementunsetsthevalueofthequery_optioninthecurrentsession,revertingitto
thedefaultstate.Inimpala-shell ,usetheUNSETcommand tosetaqueryoptiontoitsdefault.
Eachqueryoptionhasaspecificallowednotationforitsarguments.SeeQueryOptionsfortheSETStatementonpage
322forthedetailsofeachqueryoption.
Usagenotes:
InCDH5.14/Impala2.11andhigher,theoutputsoftheSETandSET ALL statementswerereorganizedasbelow:
â¢Theoptionsaredividedintogroups:Regular Query Options ,Advanced Query Options ,Development
Query Options ,andDeprecated Query Options .
âTheadvancedoptionsareintendedforuseinspecifickindsofperformance tuninganddebuggingscenarios.
âThedevelopmentoptionsarerelatedtointernaldevelopmentofImpalaorfeaturesthatarenotyetfinalized.
Theseoptionsmightbechangedorremovedwithoutnotice.
âThedeprecatedoptionsarerelatedtofeaturesthatareremovedorchangedsothattheoptionsnolonger
haveanypurpose. Theseoptionsmightberemovedinfutureversions.
â¢Bydefault,onlythefirsttwogroups,regularandadvanced,aredisplayedbytheSETcommand. UseSET ALL to
seeallgroupsofoptions.
â¢impala-shell optionsanduser-specified variablesarealwaysdisplayedattheendofthelistofqueryoptions,
afterallappropriateoptiongroups.
Addedin:CDH5.2.0/Impala2.0.0
SEThasalwaysbeenavailableasanimpala-shell command. PromotingittoaSQLstatementletsyouusethis
featureinclientapplicationsthroughtheJDBCandODBCAPIs.
HDFSpermissions: ThisstatementdoesnottouchanyHDFSfilesordirectories,thereforenoHDFSpermissions are
required.
ClouderaManager:YoucansetanyofthequeryoptionsgloballyinClouderaManagertoaffectallthequeriesinthe
cluster.
1.NavigatetoImpalacluster>Configuration>ImpalaDaemonQueryOptionsAdvancedConfigurationSnippet
(SafetyValve)
2.Inthefield,typeakey-valuepairofaqueryoptionandthevalue,e.g.EXPLAIN_LEVEL=2 .
3.Click+toenteranadditional option.
4.CliveSaveChanges.
Relatedinformation:
SeeQueryOptionsfortheSETStatementonpage322forthequeryoptionsyoucanadjustusingthisstatement.
QueryOptionsfortheSETStatement
YoucanspecifythefollowingoptionsusingtheSETstatement,andthosesettingsaffectallqueriesissuedfromthat
session.
Somequeryoptionsareusefulinday-to-dayoperationsforimprovingusability,performance, orflexibility.
Otherqueryoptionscontrolspecial-purpose aspectsofImpalaoperationandareintendedprimarily foradvanced
debuggingortroubleshooting.
OptionswithBooleanparameterscanbesetto1ortruetoenable,or0orfalsetoturnoff.
322|ApacheImpalaGuideImpalaSQLLanguageReference
Note:
InImpala2.0andlater,youcansetqueryoptionsdirectlythroughtheJDBCandODBCinterfacesby
usingtheSETstatement.Formerly,SETwasonlyavailableasacommand withintheimpala-shell
interpreter.
InCDH5.14/Impala2.11andlater,youcansetqueryoptionsforanimpala-shell sessionby
specifyingoneormorecommand-line argumentsoftheform--query_option= option=value.
Seeimpala-shell ConfigurationOptionsonpage714fordetails.
Relatedinformation:
SETStatementonpage321
ABORT_ON_ERR ORQueryOption
Whenthisoptionisenabled, Impalacancelsaqueryimmediatelywhenanyofthenodesencountersanerror,rather
thancontinuingandpossiblyreturningincompleteresults.Thisoptionisdisabledbydefault,tohelpgathermaximum
diagnosticinformationwhenanerroroccurs,forexample,whetherthesameproblemoccurredonallnodesoronly
asinglenode.Currently,theerrorsthatImpalacanskipoverinvolvedatacorruption,suchasacolumnthatcontains
astringvaluewhenexpectedtocontainanintegervalue.
TocontrolhowmuchloggingImpaladoesfornon-fatalerrorswhenABORT_ON_ERROR isturnedoff,usetheMAX_ERRORS
option.
Type:Boolean; recognizedvaluesare1and0,ortrueandfalse;anyothervalueinterpretedasfalse
Default:false(shownas0inoutputofSETstatement)
Relatedinformation:
MAX_ERR ORSQueryOptiononpage339,UsingImpalaLoggingonpage709
ALLOW_ERASURE_C ODED_FILE SQueryOption
UsetheALLOW_ERASURE_CODED_FILES queryoptiontoenableordisablethesupportoferasurecodedfilesinImpala.
UntilImpalaisfullytestedandcertifiedwitherasurecodedfiles,thisqueryoptionissettoFALSEbydefault.
WhentheALLOW_ERASURE_CODED_FILES queryoptionissettoFALSE,Impalareturnsanerrorwhenaqueryrequires
scanninganerasurecodedfile.
Type:BOOLEAN
Default:FALSE
Addedin:CDH6.1
ALLOW_UNSUPPOR TED_FORMATSQueryOption
Note:ThisqueryoptionwasremovedinCDH6.1andnolongerhasanyeffect.Donotuse.
Type:Boolean; recognizedvaluesare1and0,ortrueandfalse;anyothervalueinterpretedasfalse
Default:false(shownas0inoutputofSETstatement)
APPX_COUNT_DIS TINCTQueryOption(CDH5.2orhigheronly)
WhentheAPPX_COUNT_DISTINCT queryoptionissettoTRUE,ImpalaimplicitlyconvertsCOUNT(DISTINCT) operations
totheNDV()functioncalls.Theresultingcountisapproximateratherthanprecise.Enablethequeryoptionwhena
tolerableamountoferrorisacceptableinordertoobtainfasterqueryresultsthanwithaCOUNT (DISTINCT) queries.
Type:Boolean; recognizedvaluesare1and0,ortrueandfalse;anyothervalueinterpretedasfalse
Default:false(shownas0inoutputofSETstatement)
ApacheImpalaGuide|323ImpalaSQLLanguageReference
Relatedinformation:
COUNTFunction onpage485,DISTINCTOperatoronpage321,NDVFunction onpage497
BATCH_SIZEQueryOption
NumberofrowsevaluatedatatimebySQLoperators.Unspecified orasizeof0usesapredefineddefaultsize.Using
alargenumberimprovesresponsiveness,especially forscanoperations,atthecostofahighermemoryfootprint.
Thisoptionisprimarily fortestingduringImpaladevelopment,orforuseunderthedirectionofClouderaSupport.
Type:numeric
Default:0(meaning thepredefineddefaultof1024)
BUFFER_POOL_LIMIT QueryOption
Definesalimitontheamountofmemorythataquerycanallocatefromtheinternalbufferpool.Thevalueforthis
limitappliestothememoryoneachhost,nottheaggregatememoryacrossthecluster.Typicallynotchangedbyusers,
exceptduringdiagnosis ofout-of-memor yerrorsduringqueries.
Type:integer
Default:
Thedefaultsettingforthisoptionisthelowerof80%oftheMEM_LIMIT setting,ortheMEM_LIMIT settingminus32
MB.
Addedin:CDH5.13.0/Impala2.10.0
Usagenotes:
Ifqueriesencounterout-of-memor yerrors,considerdecreasingtheBUFFER_POOL_LIMIT settingtolessthan80%
oftheMEM_LIMIT setting .
Examples:
-- Set an absolute value.
set buffer_pool_limit=8GB;
-- Set a relative value based on the MEM_LIMIT setting.
set buffer_pool_limit=80%;
Relatedinformation:
DEFAULT_SPILLABLE_BUFFER_SIZE QueryOptiononpage327,MAX_ROW_SIZEQueryOptiononpage340,
MIN_SPILLABLE_BUFFER_SIZE QueryOptiononpage345,EffectofBufferPoolonMemoryUsage(CDH5.13andhigher)
onpage607
COMPRESSION_CODECQueryOption(CDH5.2orhigheronly)
WhenImpalawritesParquetdatafilesusingtheINSERTstatement,theunderlying compressioniscontrolledbythe
COMPRESSION_CODEC queryoption.
Note:PriortoImpala2.0,thisoptionwasnamedPARQUET_COMPRESSION_CODEC .InImpala2.0and
later,thePARQUET_COMPRESSION_CODEC nameisnotrecognized.Usethemoregeneralname
COMPRESSION_CODEC fornewcode.
Syntax:
SET COMPRESSION_CODEC= codec_name ; // Supported for all codecs.
SET COMPRESSION_CODEC= codec_name :compression_level ; // Only supported for ZSTD.
TheallowedvaluesforthisqueryoptionareSNAPPY(thedefault),GZIP,ZSTD,andNONE.
324|ApacheImpalaGuideImpalaSQLLanguageReference
ZSTDalsosupports settingacompressionlevel.Thelowerthelevel,thefasterthespeedatthecostofcompression
ratio.Compressionlevelsfrom1upto22aresupportedforZSTD.Thedefaultcompressionlevel3isused,ifoneis
notpassedusingthecompression_codec queryoption.
Note:AParquetfilecreatedwithCOMPRESSION_CODEC=NONE isstilltypicallysmallerthantheoriginal
data,duetoencodingschemessuchasrun-lengthencodinganddictionaryencodingthatareapplied
separatelyfromcompression.
Theoptionvalueisnotcase-sensitiv e.
Iftheoptionissettoanunrecognizedvalue,allkindsofquerieswillfailduetotheinvalidoptionsetting,notjust
queriesinvolvingParquettables.(ThevalueBZIP2isalsorecognized,butisnotcompatiblewithParquettables.)
Type:STRING
Default:SNAPPY
Examples:
set compression_codec=zstd; // Default compression level 3.
insert into parquet_table_zstd_default_compressed select * from t1;
set compression_codec=zstd:12; // Compression level 12.
insert into parquet_table_zstd_highly_compressed select * from t1;
set compression_codec=gzip;
insert into parquet_table_highly_compressed select * from t1;
set compression_codec=snappy;
insert into parquet_table_compression_plus_fast_queries select * from t1;
set compression_codec=none;
insert into parquet_table_no_compression select * from t1;
set compression_codec=foo;
select * from t1 limit 5;
ERROR: Invalid compression codec: foo
Relatedinformation:
ForinformationabouthowcompressingParquetdatafilesaffectsqueryperformance, seeCompressionsforParquet
DataFilesonpage647.
COMPUTE_S TATS_MIN_SAMPLE_SIZE QueryOption
TheCOMPUTE_STATS_MIN_SAMPLE_SIZE queryoptionspecifiestheminimum numberofbytesthatwillbescanned
inCOMPUTE STATS TABLESAMPLE ,regardlessoftheuser-supplied sampling percent.Thisqueryoptionprevents
sampling forverysmalltableswhereaccuratestatscanbeobtainedcheaplywithoutsampling becausetheminimum
samplesizeisrequiredtogetmeaningful stats.
Type:integer
Default:1GB
Addedin:CDH5.15/Impala2.12
Usagenotes:
DEBUG_A CTIONQueryOption
Introducesartificialproblemconditions withinqueries.ForinternalClouderadebuggingandtroubleshooting.
Type:STRING
Default:emptystring
ApacheImpalaGuide|325ImpalaSQLLanguageReference
DECIMAL_V2 QueryOption
AqueryoptionthatchangesbehaviorrelatedtotheDECIMAL datatype.SetthisoptiontoFALSEforbackward
compatibilitytoImpala2.x.
Type:Boolean
Default:TRUE
DEFAULT_JOIN_DIS TRIBUTION_MODE QueryOption
Thisoptiondeterminesthejoindistribution thatImpalauseswhenanyofthetablesinvolvedinajoinqueryismissing
statistics.
Impalaoptimizesjoinqueriesbasedonthepresenceoftablestatistics,whichareproducedbytheImpalaCOMPUTE
STATSstatement.Bydefault,whenatableinvolvedinthejoinquerydoesnothavestatistics,Impalausestheâbroadcastâ
technique thattransmitstheentirecontentsofthetabletoallexecutornodesparticipatinginthequery.Ifonetable
involvedinajoinhasstatisticsandtheotherdoesnot,thetablewithoutstatisticsisbroadcast.Ifbothtablesaremissing
statistics,thetableontheright-handsideofthejoinisbroadcast.Thisbehaviorisappropriatewhenthetableinvolved
isrelativelysmall,butcanleadtoexcessivenetwork,memory,andCPUoverheadifthetablebeingbroadcastislarge.
BecauseImpalaqueriesfrequentlyinvolveverylargetables,andsuboptimaljoinsforsuchtablescouldresultinspilling
orout-of-memor yerrors,thesettingDEFAULT_JOIN_DISTRIBUTION_MODE=SHUFFLE letsyouoverridethedefault
behavior.Theshufflejoinmechanism dividesthecorresponding rowsofeachtableinvolvedinajoinqueryusinga
hashingalgorithm,andtransmitssubsetsoftherowstoothernodesforprocessing. Typically,thiskindofjoinismore
efficientforjoinsbetweenlargetablesofsimilarsize.
ThesettingDEFAULT_JOIN_DISTRIBUTION_MODE=SHUFFLE isrecommended whensettingupanddeployingnew
clusters,becauseitislesslikelytoresultinseriousconsequences suchasspillingorout-of-memor yerrorsifthequery
planisbasedonincompleteinformation.Thissettingisnotthedefault,toavoidchangingtheperformancecharacteristics
ofjoinqueriesforclustersthatarealreadytunedfortheirexistingworkloads.
Type:integer
TheallowedvaluesareBROADCAST (equivalentto0)orSHUFFLE (equivalentto1).
Examples:
Thefollowingexamplesdemonstrateappropriatescenarios foreachsettingofthisqueryoption.
-- Create a billion-row table.
create table big_table stored as parquet
  as select * from huge_table limit 1e9;
-- For a big table with no statistics, the
-- shuffle join mechanism is appropriate.
set default_join_distribution_mode=shuffle;
...join queries involving the big table...
-- Create a hundred-row table.
create table tiny_table stored as parquet
  as select * from huge_table limit 100;
-- For a tiny table with no statistics, the
-- broadcast join mechanism is appropriate.
set default_join_distribution_mode=broadcast;
...join queries involving the tiny table...
compute stats tiny_table;
compute stats big_table;
-- Once the stats are computed, the query option has
326|ApacheImpalaGuideImpalaSQLLanguageReference
-- no effect on join queries involving these tables.
-- Impala can determine the absolute and relative sizes
-- of each side of the join query by examining the
-- row size, cardinality, and so on of each table.
...join queries involving both of these tables...
Relatedinformation:
COMPUTE STATSStatementonpage219,JoinsinImpalaSELECTStatementsonpage296,Performance Considerations
forJoinQueriesonpage568
DEFAULT_SPILLABLE_BUFFER_SIZE QueryOption
Specifies thedefaultsizeforamemorybufferusedwhenthespill-to-diskmechanism isactivated,forexamplefor
queriesagainstalargetablewithnostatistics,orlargejoinoperations.
Type:integer
Default:
2097152 (2MB)
Units:Anumericargumentrepresentsasizeinbytes;youcanalsouseasuffixofmormbformegabytes,orgorgbfor
gigabytes.Ifyouspecifyavaluewithunrecognizedformats,subsequentqueriesfailwithanerror.
Addedin:CDH5.13.0/Impala2.10.0
Usagenotes:
Thisqueryoptionsetsanupperboundonthesizeoftheinternalbuffersizethatcanbeusedduringspill-to-disk
operations.Theactualsizeofthebufferischosenbythequeryplanner.
Ifoverallqueryperformance islimitedbythetimeneededforspilling,considerincreasingthe
DEFAULT_SPILLABLE_BUFFER_SIZE setting.LargerbuffersizesresultinImpalaissuinglargerI/Orequeststostorage
devices,whichmightresultinhigherthroughput, particularly onrotationaldisks.
Thetradeoffwithalargevalueforthissettingisincreasedmemoryusageduringspill-to-diskoperations.Reducingthis
valuemayreducememoryconsumption.
Todetermineifthevalueforthissettingishavinganeffectbycappingthespillablebuffersize,youcanseethebuffer
sizechosenbythequeryplannerforaparticular query.EXPLAIN thequerywhilethesettingEXPLAIN_LEVEL=2 isin
effect.
Examples:
set default_spillable_buffer_size=4MB;
Relatedinformation:
BUFFER_POOL_LIMIT QueryOptiononpage324,MAX_ROW_SIZEQueryOptiononpage340,
MIN_SPILLABLE_BUFFER_SIZE QueryOptiononpage345,EffectofBufferPoolonMemoryUsage(CDH5.13andhigher)
onpage607
DISABLE_CODEGENQueryOption
TheDISABLE_CODEGEN isadebugoption,andit'susedtoworkaroundanyissueswithImpala'sruntimecodegeneration.
Ifaqueryfailswithanâillegalinstructionâ orotherhardware-specific message,trysettingDISABLE_CODEGEN=true
andrunningthequeryagain.Ifthequerysucceeds onlywhentheDISABLE_CODEGEN optionisturnedon,submitthe
problemtoClouderaSupportandincludethatdetailintheproblemreport.
MostquerieswillrunsignificantlyslowerwithDISABLE_CODEGEN=true .
InImpala2.10andhigher,theDISABLE_CODEGEN_ROWS_THRESHOLD optimisationautomaticallydisablescodegen
forsmallqueriesbecauseshort-running queriesmayrunfasterwithouttheoverheadofcodegen.
ApacheImpalaGuide|327ImpalaSQLLanguageReference
Thefollowingvaluesaresupported:
â¢TRUEor1:Disablescodegen.
â¢FALSEor0:Enablescodegen.
Type:Boolean
Default:false(shownas0inoutputofSETstatement)
DISABLE_CODEGEN_ROWS_THRESHOLDQueryOption(CDH5.13/Impala2.10orhigheronly)
Thissettingcontrolsthecutoffpoint(intermsofnumberofrowsprocessedperImpaladaemon) belowwhichImpala
disablesnativecodegenerationforthewholequery.Nativecodegenerationisverybeneficialforqueriesthatprocess
manyrowsbecauseitreducesthetimetakentoprocessofeachrow.However,generatingthenativecodeaddslatency
toquerystartup.Therefore,automaticallydisabling codegenforqueriesthatprocessrelativelysmallamountsofdata
canimprovequeryresponsetime.
Syntax:
SET DISABLE_CODEGEN_ROWS_THRESHOLD= number_of_rows
Type:numeric
Default:50000
Usagenotes:Typically,youincreasethedefaultvaluetomakethisoptimizationapplytomorequeries.Ifincorrector
corruptedtableandcolumnstatisticscauseImpalatoapplythisoptimizationincorrectlytoqueriesthatactuallyinvolve
substantialwork,youmightseethequeriesbeingslowerasaresultofcodegenbeingdisabled. Inthatcase,recompute
statisticswiththeCOMPUTE STATS orCOMPUTE INCREMENTAL STATS statement.Ifthereisaproblemcollecting
accuratestatistics,youcanturnthisfeatureoffbysettingthevalueto0.
Internaldetails:
Thissettingappliestoquerieswherethenumberofrowsprocessedcanbeaccuratelydetermined, eitherthrough
tableandcolumnstatistics,orbythepresenceofaLIMITclause.IfImpalacannotaccuratelyestimatethenumberof
rows,thenthissettingdoesnotapply.
IfaqueryusesthecomplexdatatypesSTRUCT,ARRAY,orMAP,thencodegenisneverautomaticallydisabledregardless
oftheDISABLE_CODEGEN_ROWS_THRESHOLD setting.
Addedin:CDH5.13.0/Impala2.10.0
DISABLE_ROW_RUNTIME_FIL TERINGQueryOption(CDH5.7orhigheronly)
TheDISABLE_ROW_RUNTIME_FILTERING queryoptionreducesthescopeoftheruntimefilteringfeature.Queries
stilldynamicallyprunepartitions, butdonotapplythefilteringlogictoindividual rowswithinpartitions.
OnlyappliestoqueriesagainstParquettables.Forotherfileformats,Impalaonlyprunesatthelevelofpartitions, not
individual rows.
Type:Boolean; recognizedvaluesare1and0,ortrueandfalse;anyothervalueinterpretedasfalse
Default:false
Addedin:CDH5.7.0/Impala2.5.0
Usagenotes:
Impalaautomaticallyevaluateswhethertheper-rowfiltersarebeingeffectiveatreducingtheamountofintermediate
data.Therefore,thisoptionistypicallyonlyneededfortherarecasewhereImpalacannotaccuratelydeterminehow
effectivetheper-rowfilteringisforaquery.
Becausetheruntimefilteringfeatureappliesmainlytoresource-intensiveandlong-running queries,onlyadjustthis
queryoptionwhentuninglong-running queriesinvolvingsomecombinationoflargepartitioned tablesandjoins
involvinglargetables.
328|ApacheImpalaGuideImpalaSQLLanguageReference
Becausethissettingonlyimprovesqueryperformance inveryspecificcircumstances,depending onthequery
characteristicsanddatadistribution, onlyuseitwhenyoudeterminethroughbenchmarking thatitimprovesperformance
ofspecificexpensivequeries.Consider settingthisqueryoptionimmediatelybeforetheexpensivequeryandunsetting
itimmediatelyafterward.
Fileformatconsiderations:
ThisqueryoptiononlyappliestoqueriesagainstHDFS-basedtablesusingtheParquetfileformat.
Kuduconsiderations:
WhenappliedtoaqueryinvolvingaKudutable,thisoptionturnsoffallruntimefilteringfortheKudutable.
Relatedinformation:
RuntimeFilteringforImpalaQueries(CDH5.7orhigheronly)onpage588,RUNTIME_FIL TER_MODE QueryOption(CDH
5.7orhigheronly)onpage358
DISABLE_STREAMING_PRE AGGREGATIONSQueryOption(CDH5.7orhigheronly)
TurnsofftheâstreamingpreaggregationâoptimizationthatisavailableinCDH5.7/Impala2.5andhigher.This
optimizationreducesunnecessar yworkperformedbyqueriesthatperformaggregationoperationsoncolumnswith
fewornoduplicatevalues,forexampleDISTINCT id_column orGROUP BY unique_column .Iftheoptimization
causesregressionsinexistingqueriesthatuseaggregationfunctions, youcanturnitoffasneededbysettingthisquery
option.
Type:Boolean; recognizedvaluesare1and0,ortrueandfalse;anyothervalueinterpretedasfalse
Default:false(shownas0inoutputofSETstatement)
Note:InCDH5.7.0/Impala2.5.0,onlythevalue1enablestheoption,andthevaluetrueisnot
recognized.ThislimitationistrackedbytheissueIMPALA-3334 ,whichshowsthereleaseswherethe
problemisfixed.
Usagenotes:
Typically,queriesthatwouldrequireenablingthisoptioninvolveverylargenumbersofaggregatedvalues,suchasa
billionormoredistinctkeysbeingprocessedoneachworkernode.
Addedin:CDH5.7.0/Impala2.5.0
DISABLE_UNS AFE_SPILLS QueryOption(CDH5.2orhigheronly)
EnablethisoptionifyouprefertohavequeriesfailwhentheyexceedtheImpalamemorylimit,ratherthanwrite
temporarydatatodisk.
Queriesthatâspillâtodisktypicallycompletesuccessfully,wheninearlierImpalareleasestheywouldhavefailed.
However,querieswithexorbitantmemoryrequirementsduetomissingstatisticsorinefficientjoinclausescould
becomesoslowasaresultthatyouwouldratherhavethemcancelledautomaticallyandreducethememoryusage
throughstandardImpalatuningtechniques.
Thisoptionpreventsonlyâunsafeâspilloperations,meaningthatoneormoretablesaremissingstatisticsorthequery
doesnotincludeahinttosetthemostefficientmechanism forajoinorINSERT ... SELECT intoapartitioned table.
Thesearethetablesmostlikelytoresultinsuboptimalexecutionplansthatcouldcauseunnecessar yspilling.Therefore,
leavingthisoptionenabledisagoodwaytofindtablesonwhichtoruntheCOMPUTE STATS statement.
SeeSQLOperationsthatSpilltoDiskonpage607forinformationabouttheâspilltodiskâfeatureforqueriesprocessing
largeresultsetswithjoins,ORDER BY ,GROUP BY ,DISTINCT ,aggregationfunctions, oranalyticfunctions.
Type:Boolean; recognizedvaluesare1and0,ortrueandfalse;anyothervalueinterpretedasfalse
Default:false(shownas0inoutputofSETstatement)
Addedin:CDH5.2.0/Impala2.0.0
ApacheImpalaGuide|329ImpalaSQLLanguageReference
ENABLE_EXPR_REWRITE SQueryOption
TheENABLE_EXPR_REWRITES queryoptioncontrolswhethertoenableordisablethequerycompiletimeoptimizations.
Theseoptimizationsrewritetheexpressiontreestoamorecompactandoptimizedformthathelpsavoidredundant
expressionevaluationatruntime.Performance optimizationscontrolledbythisqueryoptioninclude:
â¢Constantfolding(addedin)
â¢Extractingcommonconjunctsfromdisjunctions (addedin)
â¢Simplifyconditionals withconstantconditions (addedin)
Settheoptiontofalseor0todisabletheperformance optimizations.
Type:boolean
Default:true(1)
Addedin:CDH5.10
EXEC_SINGLE_NODE_R OWS_THRESHOLDQueryOption(CDH5.3orhigheronly)
Thissettingcontrolsthecutoffpoint(intermsofnumberofrowsscanned)belowwhichImpalatreatsaqueryasa
âsmallâquery,turningoffoptimizationssuchasparallelexecutionandnativecodegeneration.Theoverheadforthese
optimizationsisapplicableforqueriesinvolvingsubstantialamountsofdata,butitmakessensetoskipthemforqueries
involvingtinyamountsofdata.ReducingtheoverheadforsmallqueriesallowsImpalatocompletethemmorequickly,
keepingadmission controlslots,CPU,memory,andsoonavailableforresource-intensivequeries.
Syntax:
SET EXEC_SINGLE_NODE_ROWS_THRESHOLD= number_of_rows
Type:numeric
Default:100
Usagenotes:Typically,youincreasethedefaultvaluetomakethisoptimizationapplytomorequeries.Ifincorrector
corruptedtableandcolumnstatisticscauseImpalatoapplythisoptimizationincorrectlytoqueriesthatactuallyinvolve
substantialwork,youmightseethequeriesbeingslowerasaresultofremotereads.Inthatcase,recomputestatistics
withtheCOMPUTE STATS orCOMPUTE INCREMENTAL STATS statement.Ifthereisaproblemcollectingaccurate
statistics,youcanturnthisfeatureoffbysettingthevalueto-1.
Internaldetails:
Thissettingappliestoquerieswherethenumberofrowsprocessedcanbeaccuratelydetermined, eitherthrough
tableandcolumnstatistics,orbythepresenceofaLIMITclause.IfImpalacannotaccuratelyestimatethenumberof
rows,thenthissettingdoesnotapply.
InCDH5.5/Impala2.3andhigher,whereImpalasupports thecomplexdatatypesSTRUCT,ARRAY,andMAP,ifaquery
referstoanycolumnofthosetypes,thesmall-quer yoptimizationisturnedoffforthatqueryregardlessofthe
EXEC_SINGLE_NODE_ROWS_THRESHOLD setting.
Foraquerythatisdeterminedtobeâsmallâ,allworkisperformedonthecoordinatornode.Thismightresultinsome
I/Obeingperformedbyremotereads.Thesavingsfromnotdistributingthequeryworkandnotgeneratingnative
codeareexpectedtooutweighanyoverheadfromtheremotereads.
Addedin:CDH5.13
Examples:
Acommonusecaseistoqueryjustafewrowsfromatabletoinspecttypicaldatavalues.Inthisexample,Impaladoes
notparallelizethequeryorperformnativecodegenerationbecausetheresultsetisguaranteedtobesmallerthan
thethresholdvaluefromthisqueryoption:
SET EXEC_SINGLE_NODE_ROWS_THRESHOLD=500;
SELECT * FROM enormous_table LIMIT 300;
330|ApacheImpalaGuideImpalaSQLLanguageReference
EXEC_TIME_LIMIT_S QueryOption(CDH5.15/Impala2.12orhigheronly)
TheEXEC_TIME_LIMIT_S queryoptionsetsatimelimitonqueryexecution.Ifaqueryisstillexecutingwhentime
limitexpires,itisautomaticallycanceled.Theoptionisintendedtopreventrunawayqueriesthatexecuteformuch
longerthanintended.
Forexample,anImpalaadministratorcouldsetadefaultvalueofEXEC_TIME_LIMIT_S=3600 foraresourcepoolto
automaticallykillqueriesthatexecuteforlongerthanonehour(seeAdmission ControlandQueryQueuingonpage
549forinformationaboutdefaultqueryoptions).Then,ifauseraccidentallyrunsalargequerythatexecutesformore
thanonehour,itwillbeautomaticallykilledafterthetimelimitexpirestofreeupresources.Userscanoverridethe
defaultvalueperqueryorpersessioniftheydonotwantthedefaultEXEC_TIME_LIMIT_S valuetoapplytoaspecific
queryorasession.
Note:
Thetimelimitonlystartsoncethequeryisexecuting.Timespentplanningthequery,scheduling the
query,orinadmission controlisnotcountedtowardstheexecutiontimelimit.SELECTstatements
areeligibleforautomaticcancellationuntiltheclienthasfetchedallresultrows.DMLqueriesare
eligibleforautomaticcancellationuntiltheDMLstatementhasfinished.
Syntax:
SET EXEC_TIME_LIMIT_S= seconds;
Type:numeric
Default:0(notimelimit)
Addedin:CDH5.15/Impala2.12
Relatedinformation:
SettingTimeoutPeriodsforDaemons, Queries,andSessionsonpage70
EXPLAIN_LEVEL QueryOption
ControlstheamountofdetailprovidedintheoutputoftheEXPLAIN statement.Thebasicoutputcanhelpyouidentify
high-levelperformance issuessuchasscanningahighervolumeofdataormorepartitions thanyouexpect.Thehigher
levelsofdetailshowhowintermediateresultsflowbetweennodesandhowdifferentSQLoperationssuchasORDER
BY,GROUP BY ,joins,andWHEREclausesareimplemen tedwithinadistributedquery.
Type:STRINGorINT
Default:1
Arguments:
Theallowedrangeofnumericvaluesforthisoptionis0to3:
â¢0orMINIMAL :Abareboneslist,onelineperoperation.Primarily usefulforchecking thejoinorderinverylong
querieswheretheregularEXPLAIN outputistoolongtoreadeasily.
â¢1orSTANDARD :Thedefaultlevelofdetail,showingthelogicalwaythatworkissplitupforthedistributedquery.
â¢2orEXTENDED :Includesadditional detailabouthowthequeryplannerusesstatisticsinitsdecision-making
process,tounderstandhowaquerycouldbetunedbygatheringstatistics,usingqueryhints,addingorremoving
predicates,andsoon.InCDH6.2/Impala3.2andhigher,theoutputalsoincludestheanalyzedquerywiththe
castinformationintheoutputheader,andtheimplicitcastinfointhePredicatesection.
â¢3orVERBOSE :Themaximumlevelofdetail,showinghowworkissplitupwithineachnodeintoâqueryfragmentsâ
thatareconnectedinapipeline.Thisextradetailisprimarily usefulforlow-levelperformance testingandtuning
withinImpalaitself,ratherthanforrewritingtheSQLcodeattheuserlevel.
ApacheImpalaGuide|331ImpalaSQLLanguageReference
Note:PriortoImpala1.3,theallowedargumentrangeforEXPLAIN_LEVEL was0to1:level0had
themnemonic NORMAL,andlevel1wasVERBOSE .InImpala1.3andhigher,NORMALisnotavalid
mnemonic value,andVERBOSE stillappliestothehighestlevelofdetailbutnowcorrespondstolevel
3.Youmightneedtoadjustthevaluesifyouhaveanyolderimpala-shell scriptfilesthatsetthe
EXPLAIN_LEVEL queryoption.
Changing thevalueofthisoptioncontrolstheamountofdetailintheoutputoftheEXPLAIN statement.Theextended
informationfromlevel2or3isespecially usefulduringperformance tuning,whenyouneedtoconfirmwhetherthe
workforthequeryisdistributedthewayyouexpect,particularly forthemostresource-intensiveoperationssuchas
joinqueriesagainstlargetables,queriesagainsttableswithlargenumbersofpartitions, andinsertoperationsfor
Parquettables.Theextendedinformationalsohelpstocheckestimatedresourceusagewhenyouusetheadmission
controlorresourcemanagementfeaturesexplainedinResourceManagementonpage549.SeeEXPLAINStatement
onpage271forthesyntaxoftheEXPLAIN statement,andUsingtheEXPLAINPlanforPerformance Tuningonpage
602fordetailsabouthowtousetheextendedinformation.
Usagenotes:
Asalways,readtheEXPLAIN outputfrombottomtotop.Thelowestlinesrepresenttheinitialworkofthequery
(scanningdatafiles),thelinesinthemiddlerepresentcalculationsdoneoneachnodeandhowintermediateresults
aretransmittedfromonenodetoanother,andthetopmostlinesrepresentthefinalresultsbeingsentbacktothe
coordinatornode.
Thenumbersintheleftcolumnaregeneratedinternallyduringtheinitialplanningphaseanddonotrepresentthe
actualorderofoperations,soitisnotsignificantiftheyappearoutoforderintheEXPLAIN output.
AtallEXPLAIN levels,theplancontainsawarningifanytablesinthequeryaremissingstatistics.UsetheCOMPUTE
STATSstatementtogatherstatisticsforeachtableandsuppressthiswarning.SeeTableandColumnStatisticsonpage
575fordetailsabouthowthestatisticshelpqueryperformance.
ThePROFILE command inimpala-shell alwaysstartswithanexplainplanshowingfulldetail,thesameaswith
EXPLAIN_LEVEL=3 .Aftertheexplainplancomestheexecutivesummary,thesameoutputasproducedbytheSUMMARY
command inimpala-shell .
Examples:
Theseexamplesuseatrivial,emptytabletoillustratehowtheessentialaspectsofqueryplanningareshowninEXPLAIN
output:
[localhost:21000] > create table t1 (x int, s string);
[localhost:21000] > set explain_level=1;
[localhost:21000] > explain select count(*) from t1;
+------------------------------------------------------------------------+
| Explain String                                                         |
+------------------------------------------------------------------------+
| Estimated Per-Host Requirements: Memory=10.00MB VCores=1               |
| WARNING: The following tables are missing relevant table and/or column |
|   statistics.                                                          |
| explain_plan.t1                                                        |
|                                                                        |
| 03:AGGREGATE [MERGE FINALIZE]                                          |
| |  output: sum(count(*))                                               |
| |                                                                      |
| 02:EXCHANGE [PARTITION=UNPARTITIONED]                                  |
| |                                                                      |
| 01:AGGREGATE                                                           |
| |  output: count(*)                                                    |
| |                                                                      |
| 00:SCAN HDFS [explain_plan.t1]                                         |
|    partitions=1/1 size=0B                                              |
+------------------------------------------------------------------------+
[localhost:21000] > explain select * from t1;
+------------------------------------------------------------------------+
| Explain String                                                         |
+------------------------------------------------------------------------+
| Estimated Per-Host Requirements: Memory=-9223372036854775808B VCores=0 |
332|ApacheImpalaGuideImpalaSQLLanguageReference
| WARNING: The following tables are missing relevant table and/or column |
|   statistics.                                                          |
| explain_plan.t1                                                        |
|                                                                        |
| 01:EXCHANGE [PARTITION=UNPARTITIONED]                                  |
| |                                                                      |
| 00:SCAN HDFS [explain_plan.t1]                                         |
|    partitions=1/1 size=0B                                              |
+------------------------------------------------------------------------+
[localhost:21000] > set explain_level=2;
[localhost:21000] > explain select * from t1;
+------------------------------------------------------------------------+
| Explain String                                                         |
+------------------------------------------------------------------------+
| Estimated Per-Host Requirements: Memory=-9223372036854775808B VCores=0 |
| WARNING: The following tables are missing relevant table and/or column |
|   statistics.                                                          |
| explain_plan.t1                                                        |
|                                                                        |
| 01:EXCHANGE [PARTITION=UNPARTITIONED]                                  |
| |  hosts=0 per-host-mem=unavailable                                    |
| |  tuple-ids=0 row-size=19B cardinality=unavailable                    |
| |                                                                      |
| 00:SCAN HDFS [explain_plan.t1, PARTITION=RANDOM]                       |
|    partitions=1/1 size=0B                                              |
|    table stats: unavailable                                            |
|    column stats: unavailable                                           |
|    hosts=0 per-host-mem=0B                                             |
|    tuple-ids=0 row-size=19B cardinality=unavailable                    |
+------------------------------------------------------------------------+
[localhost:21000] > set explain_level=3;
[localhost:21000] > explain select * from t1;
+------------------------------------------------------------------------+
| Explain String                                                         |
+------------------------------------------------------------------------+
| Estimated Per-Host Requirements: Memory=-9223372036854775808B VCores=0 |
| WARNING: The following tables are missing relevant table and/or column |
|   statistics.                                                          |
| explain_plan.t1                                                        |
|                                                                        |
| F01:PLAN FRAGMENT [PARTITION=UNPARTITIONED]                            |
|   01:EXCHANGE [PARTITION=UNPARTITIONED]                                |
|      hosts=0 per-host-mem=unavailable                                  |
|      tuple-ids=0 row-size=19B cardinality=unavailable                  |
|                                                                        |
| F00:PLAN FRAGMENT [PARTITION=RANDOM]                                   |
|   DATASTREAM SINK [FRAGMENT=F01, EXCHANGE=01, PARTITION=UNPARTITIONED] |
|   00:SCAN HDFS [explain_plan.t1, PARTITION=RANDOM]                     |
|      partitions=1/1 size=0B                                            |
|      table stats: unavailable                                          |
|      column stats: unavailable                                         |
|      hosts=0 per-host-mem=0B                                           |
|      tuple-ids=0 row-size=19B cardinality=unavailable                  |
+------------------------------------------------------------------------+
Asthewarningmessagedemonstrates,mostoftheinformationneededforImpalatodoefficientqueryplanning,and
foryoutounderstandtheperformance characteristicsofthequery,requiresrunningtheCOMPUTE STATS statement
forthetable:
[localhost:21000] > compute stats t1;
+-----------------------------------------+
| summary                                 |
+-----------------------------------------+
| Updated 1 partition(s) and 2 column(s). |
+-----------------------------------------+
[localhost:21000] > explain select * from t1;
+------------------------------------------------------------------------+
| Explain String                                                         |
+------------------------------------------------------------------------+
| Estimated Per-Host Requirements: Memory=-9223372036854775808B VCores=0 |
|                                                                        |
| F01:PLAN FRAGMENT [PARTITION=UNPARTITIONED]                            |
ApacheImpalaGuide|333ImpalaSQLLanguageReference
|   01:EXCHANGE [PARTITION=UNPARTITIONED]                                |
|      hosts=0 per-host-mem=unavailable                                  |
|      tuple-ids=0 row-size=20B cardinality=0                            |
|                                                                        |
| F00:PLAN FRAGMENT [PARTITION=RANDOM]                                   |
|   DATASTREAM SINK [FRAGMENT=F01, EXCHANGE=01, PARTITION=UNPARTITIONED] |
|   00:SCAN HDFS [explain_plan.t1, PARTITION=RANDOM]                     |
|      partitions=1/1 size=0B                                            |
|      table stats: 0 rows total                                         |
|      column stats: all                                                 |
|      hosts=0 per-host-mem=0B                                           |
|      tuple-ids=0 row-size=20B cardinality=0                            |
+------------------------------------------------------------------------+
Joinsandothercomplicated,multi-part queriesaretheoneswhereyoumostcommonly needtoexaminetheEXPLAIN
outputandcustomizetheamountofdetailintheoutput.ThisexampleshowsthedefaultEXPLAIN outputfora
three-wayjoinquery,thentheequivalentoutputwitha[SHUFFLE] hinttochangethejoinmechanism betweenthe
firsttwotablesfromabroadcastjointoashufflejoin.
[localhost:21000] > set explain_level=1;
[localhost:21000] > explain select one.*, two.*, three.* from t1 one, t1 two, t1 three
 where one.x = two.x and two.x = three.x;
+---------------------------------------------------------+
| Explain String                                          |
+---------------------------------------------------------+
| Estimated Per-Host Requirements: Memory=4.00GB VCores=3 |
|                                                         |
| 07:EXCHANGE [PARTITION=UNPARTITIONED]                   |
| |                                                       |
| 04:HASH JOIN [INNER JOIN, BROADCAST]                    |
| |  hash predicates: two.x = three.x                     |
| |                                                       |
| |--06:EXCHANGE [BROADCAST]                              |
| |  |                                                    |
| |  02:SCAN HDFS [explain_plan.t1 three]                 |
| |     partitions=1/1 size=0B                            |
| |                                                       |
| 03:HASH JOIN [INNER JOIN, BROADCAST]                    |
| |  hash predicates: one.x = two.x                       |
| |                                                       |
| |--05:EXCHANGE [BROADCAST]                              |
| |  |                                                    |
| |  01:SCAN HDFS [explain_plan.t1 two]                   |
| |     partitions=1/1 size=0B                            |
| |                                                       |
| 00:SCAN HDFS [explain_plan.t1 one]                      |
|    partitions=1/1 size=0B                               |
+---------------------------------------------------------+
[localhost:21000] > explain select one.*, two.*, three.*
                  > from t1 one join [shuffle] t1 two join t1 three
                  > where one.x = two.x and two.x = three.x;
+---------------------------------------------------------+
| Explain String                                          |
+---------------------------------------------------------+
| Estimated Per-Host Requirements: Memory=4.00GB VCores=3 |
|                                                         |
| 08:EXCHANGE [PARTITION=UNPARTITIONED]                   |
| |                                                       |
| 04:HASH JOIN [INNER JOIN, BROADCAST]                    |
| |  hash predicates: two.x = three.x                     |
| |                                                       |
| |--07:EXCHANGE [BROADCAST]                              |
| |  |                                                    |
| |  02:SCAN HDFS [explain_plan.t1 three]                 |
| |     partitions=1/1 size=0B                            |
| |                                                       |
| 03:HASH JOIN [INNER JOIN, PARTITIONED]                  |
| |  hash predicates: one.x = two.x                       |
| |                                                       |
| |--06:EXCHANGE [PARTITION=HASH(two.x)]                  |
| |  |                                                    |
334|ApacheImpalaGuideImpalaSQLLanguageReference
| |  01:SCAN HDFS [explain_plan.t1 two]                   |
| |     partitions=1/1 size=0B                            |
| |                                                       |
| 05:EXCHANGE [PARTITION=HASH(one.x)]                     |
| |                                                       |
| 00:SCAN HDFS [explain_plan.t1 one]                      |
|    partitions=1/1 size=0B                               |
+---------------------------------------------------------+
Forajoininvolvingmanydifferenttables,thedefaultEXPLAIN outputmightstretchoverseveralpages,andtheonly
detailsyoucareaboutmightbethejoinorderandthemechanism (broadcastorshuffle)forjoiningeachpairoftables.
Inthatcase,youmightsetEXPLAIN_LEVEL toitslowestvalueof0,tofocusonjustthejoinorderandjoinmechanism
foreachstage.Thefollowingexampleshowshowtherowsfromthefirstandsecondjoinedtablesarehashedand
dividedamongthenodesoftheclusterforfurtherfiltering;thentheentirecontentsofthethirdtablearebroadcast
toallnodesforthefinalstageofjoinprocessing.
[localhost:21000] > set explain_level=0;
[localhost:21000] > explain select one.*, two.*, three.*
                  > from t1 one join [shuffle] t1 two join t1 three
                  > where one.x = two.x and two.x = three.x;
+---------------------------------------------------------+
| Explain String                                          |
+---------------------------------------------------------+
| Estimated Per-Host Requirements: Memory=4.00GB VCores=3 |
|                                                         |
| 08:EXCHANGE [PARTITION=UNPARTITIONED]                   |
| 04:HASH JOIN [INNER JOIN, BROADCAST]                    |
| |--07:EXCHANGE [BROADCAST]                              |
| |  02:SCAN HDFS [explain_plan.t1 three]                 |
| 03:HASH JOIN [INNER JOIN, PARTITIONED]                  |
| |--06:EXCHANGE [PARTITION=HASH(two.x)]                  |
| |  01:SCAN HDFS [explain_plan.t1 two]                   |
| 05:EXCHANGE [PARTITION=HASH(one.x)]                     |
| 00:SCAN HDFS [explain_plan.t1 one]                      |
+---------------------------------------------------------+
HBASE_CACHE_BLOCKSQueryOption
SettingthisoptionisequivalenttocallingthesetCacheBlocks methodoftheclass
org.apache.hadoop.hbase.clien t.Scan,inanHBaseJavaapplication.Helpstocontrolthememorypressureonthe
HBaseRegionServer,inconjunction withtheHBASE_CACHING queryoption.
Type:Boolean; recognizedvaluesare1and0,ortrueandfalse;anyothervalueinterpretedasfalse
Default:false(shownas0inoutputofSETstatement)
Relatedinformation:
UsingImpalatoQueryHBaseTablesonpage684,HBASE_CACHINGQueryOptiononpage335
HBASE_CACHINGQueryOption
SettingthisoptionisequivalenttocallingthesetCaching methodoftheclassorg.apache.hadoop.hbase.clien t.Scan,
inanHBaseJavaapplication.HelpstocontrolthememorypressureontheHBaseRegionServer,inconjunction with
theHBASE_CACHE_BLOCKS queryoption.
Type:BOOLEAN
Default:0
Relatedinformation:
UsingImpalatoQueryHBaseTablesonpage684,HBASE_CACHE_BLOCKSQueryOptiononpage335
IDLE_SESSION_TIME OUTQueryOption(CDH5.15/Impala2.12orhigheronly)
TheIDLE_SESSION_TIMEOUT queryoptionsetsthetimeinsecondsafterwhichanidlesessioniscancelled. Asession
isidlewhennoactivityisoccurring foranyofthequeriesinthatsession,andthesessionhasnotstartedanynew
ApacheImpalaGuide|335ImpalaSQLLanguageReference
queries.Onceasessionisexpired,youcannotissueanynewqueryrequeststoit.Thesessionremainsopen,butthe
onlyoperationyoucanperformistocloseit.
TheIDLE_SESSION_TIMEOUT queryoptionoverridesthe--idle_session_timeout startupoption.SeeSetting
TimeoutPeriodsforDaemons, Queries,andSessionsonpage70forthe--idle_session_timeout startupoption.
TheIDLE_SESSION_TIMEOUT queryoptionallowsJDBC/ODBC connections tosetthesessiontimeoutasaquery
optionwiththeSETstatement.
Syntax:
SET IDLE_SESSION_TIMEOUT= seconds;
Type:numeric
Default:0
â¢If--idle_session_timeout isnotset,thesessionneverexpires.
â¢If--idle_session_timeout isset,usethattimeoutvalue.
Addedin:CDH5.15/Impala2.12
Relatedinformation:
SettingTimeoutPeriodsforDaemons, Queries,andSessionsonpage70
KUDU_READ_MODE QueryOption(CDH6.1orhigheronly)
TheKUDU_READ_MODE queryoptionallowsyoutosetadesiredconsistencylevelforscansofKudutables.
Type:String
Default:"DEFAULT"
Addedin:CDH6.1
Usagenotes:
Thefollowingvaluesaresupportedforthequeryoption:
â¢"DEFAULT" :Thevalueofthestartupflag,--kudu_read_mode ,isused.
â¢"READ_LATEST" :Commonly knownastheReadCommittedisolationmode,inthismode,Kuduprovidesno
consistencyguaranteesforthismode,exceptthatallreturnedrowswerecommittedatsomepoint.
â¢"READ_AT_SNAPSHOT" :Kuduwilltakeasnapshotofthecurrentstateofthedataandperformthescanoverthe
snapshot,possiblyafterbrieflywaitingforongoingwritestocomplete.Thisprovides"ReadYourWrites"consistency
withinasingleImpalasession,exceptinthecaseofaKuduleaderchange.SeetheKududocumen tationformore
details.
LIVE_PROGRESSQueryOption(CDH5.5orhigheronly)
WhentheLIVE_PROGRESS queryoptionissettoTRUE,Impaladisplaysaninteractiveprogressbarshowingroughly
whatpercentageofprocessinghasbeencompletedforqueriessubmittedthroughtheimpala-shell command.
Whenthequeryfinishes,theprogressbariserasedfromtheimpala-shell consoleoutput.
StartinginCDH6.1,thesummaryoutputalsoincludesthequeuingstatusconsistingofwhetherthequerywasqueued
andwhatwasthelatestqueuingreason.
Type:Boolean
Default:FALSE (0)
Command-line equivalent:
Youcanenablethisqueryoptionwithinimpala-shell bystartingtheshellwiththe--live_progress command-line
option.YoucanstillturnthissettingoffandonagainwithintheshellthroughtheSETcommand.
Usagenotes:
336|ApacheImpalaGuideImpalaSQLLanguageReference
Theoutputfromthisqueryoptionisprintedtostandarderror.Theoutputisonlydisplayedininteractivemode,that
is,notwhenthe-qor-foptionsareused.
Foramoredetailedwayoftrackingtheprogressofaninteractivequerythroughallphasesofprocessing,see
LIVE_SUMMAR YQueryOption(CDH5.5orhigheronly)onpage337.
Restrictions:
Becausethepercentagecompletefigureiscalculatedusingthenumberofissuedandcompletedâscanrangesâ,which
occurwhilereadingthetabledata,theprogressbarmightreach100%beforethequeryisentirelyfinished.Forexample,
thequerymightdoworktoperformaggregationsafterallthetabledatahasbeenread.Ifmanyofyourqueriesfall
intothiscategory,considerusingtheLIVE_SUMMARY optioninsteadformoregranularprogressreporting.
TheLIVE_PROGRESS andLIVE_SUMMARY queryoptionscurrentlydonotproduceanyoutputduringCOMPUTE STATS
operations.
BecausetheLIVE_PROGRESS andLIVE_SUMMARY queryoptionsareavailableonlywithintheimpala-shell
interpreter:
â¢YoucannotchangethesequeryoptionsthroughtheSQLSETstatementusingtheJDBCorODBCinterfaces.The
SETcommand inimpala-shell recognizesthesenamesasshell-only options.
â¢Becarefulwhenusingimpala-shell onapre-CDH5.5systemtoconnecttoImpalarunningonaCDH5.5or
highersystem.Theolderimpala-shell doesnotrecognizethesequeryoptionnames.Upgradeimpala-shell
onthesystemswhereyouintendtousethesequeryoptions.
â¢Likewise,theimpala-shell command reliesonsomeinformationonlyavailableinCDH5.5/Impala2.3and
highertoprepareliveprogressreportsandquerysummaries. TheLIVE_PROGRESS andLIVE_SUMMARY query
optionshavenoeffectwhenimpala-shell connectstoaclusterrunninganolderversionofImpala.
Addedin:CDH5.5.0/Impala2.3.0
Examples:
[localhost:21000] > set live_progress=true;
LIVE_PROGRESS set to true
[localhost:21000] > select count(*) from customer;
+----------+
| count(*) |
+----------+
| 150000   |
+----------+
[localhost:21000] > select count(*) from customer t1 cross join customer t2;
[###################################                                   ] 50%
[######################################################################] 100%
ToseehowtheLIVE_PROGRESS andLIVE_SUMMARY queryoptionsworkinrealtime,seethisanimateddemo.
LIVE_SUMMAR YQueryOption(CDH5.5orhigheronly)
WhentheLIVE_SUMMARY queryoptionissettoTRUE,ImpaladisplaysthesameoutputastheSUMMARY command
forqueriessubmittedthroughtheimpala-shell command, withthemeasurementsupdatedinrealtimeasthe
queryprogresses.Whenthequeryfinishes,thefinalSUMMARY outputremainsvisibleintheimpala-shell console
output.
StartinginCDH6.1,thesummaryoutputalsoincludesthequeuingstatusconsistingofwhetherthequerywasqueued
andwhatwasthelatestqueuingreason.
Type:Boolean
Default:FALSE (0)
Command-line equivalent:
ApacheImpalaGuide|337ImpalaSQLLanguageReference
Youcanenablethisqueryoptionwithinimpala-shell bystartingtheshellwiththe--live_summary command-line
option.YoucanstillturnthissettingoffandonagainwithintheshellthroughtheSETcommand.
Usagenotes:
Thelivesummaryoutputcanbeusefulforevaluatinglong-running queries,toevaluatewhichphaseofexecutiontakes
upthemosttime,orifsomehoststakemuchlongerthanothersforcertainoperations,draggingoverallperformance
down.Bymakingtheinformationavailableinrealtime,thisfeatureletsyoudecidewhatactiontotakeevenbefore
youcancelaquerythatistakingmuchlongerthannormal.
Forexample,youmightseetheHDFSscanphasetakingalongtime,andthereforerevisitperformance-r elatedaspects
ofyourschemadesignsuchasconstructingapartitioned table,switchingtotheParquetfileformat,runningthe
COMPUTE STATS statementforthetable,andsoon.Oryoumightseeawidevariationbetweentheaverageand
maximumtimesforallhoststoperformsomephaseofthequery,andthereforeinvestigateifoneparticular host
neededmorememoryorwasexperiencing anetworkproblem.
Theoutputfromthisqueryoptionisprintedtostandarderror.Theoutputisonlydisplayedininteractivemode,that
is,notwhenthe-qor-foptionsareused.
Forasimpleandconcisewayoftrackingtheprogressofaninteractivequery,seeLIVE_PROGRESSQueryOption(CDH
5.5orhigheronly)onpage336.
Restrictions:
TheLIVE_PROGRESS andLIVE_SUMMARY queryoptionscurrentlydonotproduceanyoutputduringCOMPUTE STATS
operations.
BecausetheLIVE_PROGRESS andLIVE_SUMMARY queryoptionsareavailableonlywithintheimpala-shell
interpreter:
â¢YoucannotchangethesequeryoptionsthroughtheSQLSETstatementusingtheJDBCorODBCinterfaces.The
SETcommand inimpala-shell recognizesthesenamesasshell-only options.
â¢Becarefulwhenusingimpala-shell onapre-CDH5.5systemtoconnecttoImpalarunningonaCDH5.5or
highersystem.Theolderimpala-shell doesnotrecognizethesequeryoptionnames.Upgradeimpala-shell
onthesystemswhereyouintendtousethesequeryoptions.
â¢Likewise,theimpala-shell command reliesonsomeinformationonlyavailableinCDH5.5/Impala2.3and
highertoprepareliveprogressreportsandquerysummaries. TheLIVE_PROGRESS andLIVE_SUMMARY query
optionshavenoeffectwhenimpala-shell connectstoaclusterrunninganolderversionofImpala.
Addedin:CDH5.5.0/Impala2.3.0
Examples:
ThefollowingexampleshowsaseriesofLIVE_SUMMARY reportsthataredisplayedduringthecourseofaquery,
showinghowthenumbersincreasetoshowtheprogressofdifferentphasesofthedistributedquery.Whenyoudo
thesameinimpala-shell ,onlyasinglereportisdisplayedatanyonetime,witheachupdateoverwritingtheprevious
numbers.
[localhost:21000] > set live_summary=true;
LIVE_SUMMARY set to true
[localhost:21000] > select count(*) from customer t1 cross join customer t2;
+---------------------+--------+----------+----------+---------+------------+----------+---------------+-----------------------+
| Operator            | #Hosts | Avg Time | Max Time | #Rows   | Est. #Rows | Peak Mem | Est. Peak Mem | Detail                |
+---------------------+--------+----------+----------+---------+------------+----------+---------------+-----------------------+
| 06:AGGREGATE        | 0      | 0ns      | 0ns      | 0       | 1          | 0 B      | -1 B          | FINALIZE              |
| 05:EXCHANGE         | 0      | 0ns      | 0ns      | 0       | 1          | 0 B      | -1 B          | UNPARTITIONED         |
| 03:AGGREGATE        | 0      | 0ns      | 0ns      | 0       | 1          | 0 B      | 10.00 MB      |                       |
| 02:NESTED LOOP JOIN | 0      | 0ns      | 0ns      | 0       | 22.50B     | 0 B      | 0 B           | CROSS JOIN, BROADCAST |
| |--04:EXCHANGE      | 0      | 0ns      | 0ns      | 0       | 150.00K    | 0 B      | 0 B           | BROADCAST             |
| |  01:SCAN HDFS     | 1      | 503.57ms | 503.57ms | 150.00K | 150.00K    | 24.09 MB | 64.00 MB      | tpch.customer t2      |
| 00:SCAN HDFS        | 0      | 0ns      | 0ns      | 0       | 150.00K    | 0 B      | 64.00 MB      | tpch.customer t1      |
+---------------------+--------+----------+----------+---------+------------+----------+---------------+-----------------------+
+---------------------+--------+----------+----------+---------+------------+----------+---------------+-----------------------+
| Operator            | #Hosts | Avg Time | Max Time | #Rows   | Est. #Rows | Peak Mem | Est. Peak Mem | Detail                |
+---------------------+--------+----------+----------+---------+------------+----------+---------------+-----------------------+
| 06:AGGREGATE        | 0      | 0ns      | 0ns      | 0       | 1          | 0 B      | -1 B          | FINALIZE              |
| 05:EXCHANGE         | 0      | 0ns      | 0ns      | 0       | 1          | 0 B      | -1 B          | UNPARTITIONED         |
| 03:AGGREGATE        | 1      | 0ns      | 0ns      | 0       | 1          | 20.00 KB | 10.00 MB      |                       |
| 02:NESTED LOOP JOIN | 1      | 17.62s   | 17.62s   | 81.14M  | 22.50B     | 3.23 MB  | 0 B           | CROSS JOIN, BROADCAST |
| |--04:EXCHANGE      | 1      | 26.29ms  | 26.29ms  | 150.00K | 150.00K    | 0 B      | 0 B           | BROADCAST             |
| |  01:SCAN HDFS     | 1      | 503.57ms | 503.57ms | 150.00K | 150.00K    | 24.09 MB | 64.00 MB      | tpch.customer t2      |
338|ApacheImpalaGuideImpalaSQLLanguageReference
| 00:SCAN HDFS        | 1      | 247.53ms | 247.53ms | 1.02K   | 150.00K    | 24.39 MB | 64.00 MB      | tpch.customer t1      |
+---------------------+--------+----------+----------+---------+------------+----------+---------------+-----------------------+
+---------------------+--------+----------+----------+---------+------------+----------+---------------+-----------------------+
| Operator            | #Hosts | Avg Time | Max Time | #Rows   | Est. #Rows | Peak Mem | Est. Peak Mem | Detail                |
+---------------------+--------+----------+----------+---------+------------+----------+---------------+-----------------------+
| 06:AGGREGATE        | 0      | 0ns      | 0ns      | 0       | 1          | 0 B      | -1 B          | FINALIZE              |
| 05:EXCHANGE         | 0      | 0ns      | 0ns      | 0       | 1          | 0 B      | -1 B          | UNPARTITIONED         |
| 03:AGGREGATE        | 1      | 0ns      | 0ns      | 0       | 1          | 20.00 KB | 10.00 MB      |                       |
| 02:NESTED LOOP JOIN | 1      | 61.85s   | 61.85s   | 283.43M | 22.50B     | 3.23 MB  | 0 B           | CROSS JOIN, BROADCAST |
| |--04:EXCHANGE      | 1      | 26.29ms  | 26.29ms  | 150.00K | 150.00K    | 0 B      | 0 B           | BROADCAST             |
| |  01:SCAN HDFS     | 1      | 503.57ms | 503.57ms | 150.00K | 150.00K    | 24.09 MB | 64.00 MB      | tpch.customer t2      |
| 00:SCAN HDFS        | 1      | 247.59ms | 247.59ms | 2.05K   | 150.00K    | 24.39 MB | 64.00 MB      | tpch.customer t1      |
+---------------------+--------+----------+----------+---------+------------+----------+---------------+-----------------------+
ToseehowtheLIVE_PROGRESS andLIVE_SUMMARY queryoptionsworkinrealtime,seethisanimateddemo.
MAX_ERR ORSQueryOption
Maximumnumberofnon-fatalerrorsforanyparticular querythatarerecordedintheImpalalogfile.Forexample,if
abillion-rowtablehadanon-fataldataerrorineveryrow,youcoulddiagnose theproblemwithoutallbillionerrors
beinglogged.Unspecified or0indicatesthebuilt-indefaultvalueof1000.
Thisoptiononlycontrolshowmanyerrorsarereported.TospecifywhetherImpalacontinuesorhaltswhenitencounters
sucherrors,usetheABORT_ON_ERROR option.
Type:numeric
Default:0(meaning 1000errors)
Relatedinformation:
ABORT_ON_ERR ORQueryOptiononpage323,UsingImpalaLoggingonpage709
MAX_MEM_E STIMATE_FOR_ADMISSION QueryOption
UsetheMAX_MEM_ESTIMATE_FOR_ADMISSION queryoptiontosetanupperlimitonthememoryestimatesofaquery
asaworkaroundforover-estimatesprecludingaqueryfrombeingadmitted.
Thequeryoptiontakeseffectwhenallofthebelowconditions aremet:
â¢Memory-basedadmission controlisenabledforthepool.
â¢TheMEM_LIMIT queryoptionisnotsetatthequery,session,resourcepool,orgloballevel.
Whentheaboveconditions aremet,MIN(MAX_MEM_ESTIMATE_FOR_ADMISSION ,mem_estimate)isusedforadmission
control.
SettingtheMEM_LIMIT queryoptionisusuallyabetteroption.UsetheMAX_MEM_ESTIMATE_FOR_ADMISSION query
optionwhenitisnotfeasibletosetMEM_LIMIT foreachindividual query.
Type:integer
Addedin:CDH6.1
MAX_NUM_RUNTIME_FIL TERSQueryOption(CDH5.7orhigheronly)
TheMAX_NUM_RUNTIME_FILTERS queryoptionsetsanupperlimitonthenumberofruntimefiltersthatcanbe
producedforeachquery.
Type:integer
Default:10
Addedin:CDH5.7.0/Impala2.5.0
Usagenotes:
Eachruntimefilterimposessomememoryoverheadonthequery.Depending onthesettingofthe
RUNTIME_BLOOM_FILTER_SIZE queryoption,eachfiltermightconsumebetween1and16megabytesperplan
fragment.Therearetypically5orfewerfiltersperplanfragment.
ApacheImpalaGuide|339ImpalaSQLLanguageReference
Impalaevaluatestheeffectivenessofeachfilter,andkeepstheonesthateliminatethelargestnumberofpartitions
orrows.Therefore,thissettingcanprotectagainstpotentialproblemsduetoexcessivememoryoverheadforfilter
production, whilestillallowingahighlevelofoptimizationforsuitablequeries.
Becausetheruntimefilteringfeatureappliesmainlytoresource-intensiveandlong-running queries,onlyadjustthis
queryoptionwhentuninglong-running queriesinvolvingsomecombinationoflargepartitioned tablesandjoins
involvinglargetables.
Kuduconsiderations:
ThisqueryoptionaffectsonlyBloomfilters,notthemin/maxfiltersthatareappliedtoKudutables.Therefore,itdoes
notaffecttheperformance ofqueriesagainstKudutables.
Relatedinformation:
RuntimeFilteringforImpalaQueries(CDH5.7orhigheronly)onpage588,RUNTIME_BL OOM_FILTER_SIZE QueryOption
(CDH5.7orhigheronly)onpage356,RUNTIME_FIL TER_MODE QueryOption(CDH5.7orhigheronly)onpage358
MAX_ROW_SIZEQueryOption
EnsuresthatImpalacanprocessrowsofatleastthespecified size.(Largerrowsmightbesuccessfullyprocessed,but
thatisnotguaranteed.)Applieswhenconstructingintermediateorfinalrowsintheresultset.Thissettingprevents
out-of-controlmemoryusewhenaccessing columnscontaininghugestrings.
Type:integer
Default:
524288(512KB)
Units:Anumericargumentrepresentsasizeinbytes;youcanalsouseasuffixofmormbformegabytes,orgorgbfor
gigabytes.Ifyouspecifyavaluewithunrecognizedformats,subsequentqueriesfailwithanerror.
Addedin:CDH5.13.0/Impala2.10.0
Usagenotes:
Ifaqueryfailsbecauseitinvolvesrowswithlongstringsand/ormanycolumns,causingthetotalrowsizetoexceed
MAX_ROW_SIZE bytes,increasetheMAX_ROW_SIZE settingtoaccommodatethetotalbytesstoredinthelargestrow.
Examinetheerrormessagesforanyfailedqueriestoseethesizeoftherowthatcausedtheproblem.
ImpalaattemptstohandlerowsthatexceedtheMAX_ROW_SIZE valuewherepractical,soinmanycases,queries
succeeddespitehavingrowsthatarelargerthanthissetting.
SpecifyingavaluethatissubstantiallyhigherthanactuallyneededcancauseImpalatoreservemorememorythanis
necessarytoexecutethequery.
InaHadoopclusterwithhighlyconcurrentworkloadsandqueriesthatprocesshighvolumesofdata,traditional SQL
tuningadviceaboutminimizing wastedmemoryisworthremembering. Forexample,ifatablehasSTRINGcolumns
whereasinglevaluemightbemultiplemegabytes,makesurethattheSELECTlistsinqueriesonlyrefertocolumns
thatareactuallyneededintheresultset,insteadofusingtheSELECT * shorthand.
IfyouareupgradingImpalatoCDH5.13/Impala2.10orhigherfromCDH5.12/Impala2.9orlower,followthe
instructions inHandling LargeRowsDuringUpgradetoCDH5.13/Impala2.10orHigheronpage38tocheckifyour
queriesareaffectedbythesechangesandtomodifyyourconfigurationsettingsifso.Thisadviceisespecially important
foranyuserswhohaveincreasedthe--read_size configurationsettingfromitsdefaultvalueof8MB.
Examples:
ThefollowingexamplesshowthekindsofsituationswhereitisnecessarytoadjusttheMAX_ROW_SIZE setting.First,
wecreateatablecontainingsomeverylongvaluesinSTRINGcolumns:
create table big_strings (s1 string, s2 string, s3 string) stored as parquet;
-- Turn off compression to more easily reason about data volume by doing SHOW TABLE 
STATS.
340|ApacheImpalaGuideImpalaSQLLanguageReference
-- Does not actually affect query success or failure, because MAX_ROW_SIZE applies when
-- column values are materialized in memory.
set compression_codec=none;
set;
...
  MAX_ROW_SIZE: [524288]
...
-- A very small row.
insert into big_strings values ('one', 'two', 'three');
-- A row right around the default MAX_ROW_SIZE limit: a 500 KiB string and a 30 KiB 
string.
insert into big_strings values (repeat('12345',100000), 'short', repeat('123',10000));
-- A row that is too big if the query has to materialize both S1 and S3.
insert into big_strings values (repeat('12345',100000), 'short', repeat('12345',100000));
WiththedefaultMAX_ROW_SIZE setting,differentqueriessucceedorfailbasedonwhichcolumnvalueshavetobe
materializedduringqueryprocessing:
-- All the S1 values can be materialized within the 512 KB MAX_ROW_SIZE buffer.
select count(distinct s1) from big_strings;
+--------------------+
| count(distinct s1) |
+--------------------+
| 2                  |
+--------------------+
-- A row where even the S1 value is too large to materialize within MAX_ROW_SIZE.
insert into big_strings values (repeat('12345',1000000), 'short', 
repeat('12345',1000000));
-- The 5 MiB string is too large to materialize. The message explains the size of the 
result
-- set row the query is attempting to materialize.
select count(distinct(s1)) from big_strings;
WARNINGS: Row of size 4.77 MB could not be materialized in plan node with id 1.
  Increase the max_row_size query option (currently 512.00 KB) to process larger rows.
-- If more columns are involved, the result set row being materialized is bigger.
select count(distinct s1, s2, s3) from big_strings;
WARNINGS: Row of size 9.54 MB could not be materialized in plan node with id 1.
  Increase the max_row_size query option (currently 512.00 KB) to process larger rows.
-- Column S2, containing only short strings, can still be examined.
select count(distinct(s2)) from big_strings;
+----------------------+
| count(distinct (s2)) |
+----------------------+
| 2                    |
+----------------------+
-- Queries that do not materialize the big column values are OK.
select count(*) from big_strings;
+----------+
| count(*) |
+----------+
| 4        |
+----------+
ThefollowingexamplesshowhowadjustingMAX_ROW_SIZE upwardallowsqueriesinvolvingthelongstringcolumns
tosucceed:
-- Boosting MAX_ROW_SIZE moderately allows all S1 values to be materialized.
set max_row_size=7mb;
select count(distinct s1) from big_strings;
ApacheImpalaGuide|341ImpalaSQLLanguageReference
+--------------------+
| count(distinct s1) |
+--------------------+
| 3                  |
+--------------------+
-- But the combination of S1 + S3 strings is still too large.
select count(distinct s1, s2, s3) from big_strings;
WARNINGS: Row of size 9.54 MB could not be materialized in plan node with id 1. Increase
 the max_row_size query option (currently 7.00 MB) to process larger rows.
-- Boosting MAX_ROW_SIZE to larger than the largest row in the table allows
-- all queries to complete successfully.
set max_row_size=12mb;
select count(distinct s1, s2, s3) from big_strings;
+----------------------------+
| count(distinct s1, s2, s3) |
+----------------------------+
| 4                          |
+----------------------------+
ThefollowingexamplesshowhowtoreasonaboutappropriatevaluesforMAX_ROW_SIZE ,basedonthecharacteristics
ofthecolumnscontainingthelongvalues:
-- With a large MAX_ROW_SIZE in place, we can examine the columns to
-- understand the practical lower limit for MAX_ROW_SIZE based on the
-- table structure and column values.
select max(length(s1) + length(s2) + length(s3)) / 1e6 as megabytes from big_strings;
+-----------+
| megabytes |
+-----------+
| 10.000005 |
+-----------+
-- We can also examine the 'Max Size' for each column after computing stats.
compute stats big_strings;
show column stats big_strings;
+--------+--------+------------------+--------+----------+-----------+
| Column | Type   | #Distinct Values | #Nulls | Max Size | Avg Size  |
+--------+--------+------------------+--------+----------+-----------+
| s1     | STRING | 2                | -1     | 5000000  | 2500002.5 |
| s2     | STRING | 2                | -1     | 10       | 7.5       |
| s3     | STRING | 2                | -1     | 5000000  | 2500005   |
+--------+--------+------------------+--------+----------+-----------+
Relatedinformation:
BUFFER_POOL_LIMIT QueryOptiononpage324,DEFAULT_SPILLABLE_BUFFER_SIZE QueryOptiononpage327,
MIN_SPILLABLE_BUFFER_SIZE QueryOptiononpage345,EffectofBufferPoolonMemoryUsage(CDH5.13andhigher)
onpage607
MAX_SCAN_RANGE_LENG THQueryOption
Maximumlengthofthescanrange.InteractswiththenumberofHDFSblocksinthetabletodeterminehowmany
CPUcoresacrosstheclusterareinvolvedwiththeprocessingforaquery.(Eachcoreprocessesonescanrange.)
LoweringthevaluecansometimesincreaseparallelismifyouhaveunusedCPUcapacity,butatoo-smallvaluecan
limitqueryperformance becauseeachscanrangeinvolvesextraoverhead.
OnlyapplicabletoHDFStables.HasnoeffectonParquettables.Unspecified or0indicatesbackenddefault,whichis
thesameastheHDFSblocksizeforeachtable.
Although thescanrangecanbearbitrarilylong,Impalainternallyusesan8MBreadbuffersothatitcanquerytables
withhugeblocksizeswithoutallocatingequivalentblocksofmemory.
Type:numeric
342|ApacheImpalaGuideImpalaSQLLanguageReference
InCDH5.9/Impala2.7andhigher,theargumentvaluecanincludeunitspecifiers,suchas100mor100mb.Inprevious
versions,Impalainterpretedsuchformattedvaluesas0,leadingtoqueryfailures.
Default:0
MEM_LIMIT QueryOption
TheMEM_LIMIT queryoptiondefinesthemaximumamountofmemoryaquerycanallocateoneachnode.Thetotal
memorythatcanbeusedbyaqueryistheMEM_LIMIT timesthenumberofnodes.
TherearetwolevelsofmemorylimitforImpala.The--mem_limit startupoptionsetsanoveralllimitfortheimpalad
process(whichhandlesmultiplequeriesconcurrently).Thatprocessmemorylimitcanbeexpressedeitherasa
percentageofRAMavailabletotheprocesssuchas-mem_limit=70% orasafixedamountofmemory,suchas
--mem_limit=100gb .Thememoryavailabletotheprocessisbasedonthehost'sphysicalmemoryand,sinceCDH
6.1/Impala3.2,memorylimitsfromLinuxControlGroups.Forexample,ifanimpalad processisrunninginaDocker
containeronahostwith100GBofmemory,thememoryavailableis100GBortheDockercontainer'smemorylimit,
whicheverisless.
TheMEM_LIMIT queryoption,whichyousetthroughimpala-shell ortheSETstatementinaJDBCorODBC
application,appliestoeachindividual query.TheMEM_LIMIT queryoptionisusuallyexpressedasafixedsizesuchas
10gb,andmustalwaysbelessthantheimpalad memorylimit.
Ifqueryprocessingexceedsthespecified memorylimitonanynode,eithertheper-querylimitortheimpalad limit,
Impalacancelsthequeryautomatically.Memorylimitsarecheckedperiodicallyduringqueryprocessing,sotheactual
memoryinusemightbrieflyexceedthelimitwithoutthequerybeingcancelled.
Type:numeric
Units:Anumericargumentrepresentsmemorysizeinbytes;youcanalsouseasuffixofmormbformegabytes,or
morecommonly gorgbforgigabytes.Ifyouspecifyavaluewithunrecognizedformats,subsequentqueriesfailwith
anerror.
Default:0(unlimited)
Usagenotes:
TheMEM_LIMIT settingisprimarily usefulinahigh-concurrencysetting,oronaclusterwithaworkloadsharedbetween
Impalaandotherdataprocessingcomponen ts.Youcanpreventanyqueryfromaccidentallyusingmuchmorememory
thanexpected,whichcouldnegativelyimpactotherImpalaqueries.
UsetheoutputoftheSUMMARY command inimpala-shell togetareportofmemoryusedforeachphaseofyour
mostheavyweightqueriesoneachnode,andthensetaMEM_LIMIT somewhathigherthanthat.SeeUsingthe
SUMMAR YReportforPerformance Tuningonpage603forusageinformationabouttheSUMMARY command.
Examples:
ThefollowingexamplesshowhowtosettheMEM_LIMIT queryoptionusingafixednumberofbytes,orsuffixes
representinggigabytesormegabytes.
[localhost:21000] > set mem_limit=3000000000;
MEM_LIMIT set to 3000000000
[localhost:21000] > select 5;
Query: select 5
+---+
| 5 |
+---+
| 5 |
+---+
[localhost:21000] > set mem_limit=3g;
MEM_LIMIT set to 3g
[localhost:21000] > select 5;
Query: select 5
+---+
| 5 |
+---+
ApacheImpalaGuide|343ImpalaSQLLanguageReference
| 5 |
+---+
[localhost:21000] > set mem_limit=3gb;
MEM_LIMIT set to 3gb
[localhost:21000] > select 5;
+---+
| 5 |
+---+
| 5 |
+---+
[localhost:21000] > set mem_limit=3m;
MEM_LIMIT set to 3m
[localhost:21000] > select 5;
+---+
| 5 |
+---+
| 5 |
+---+
[localhost:21000] > set mem_limit=3mb;
MEM_LIMIT set to 3mb
[localhost:21000] > select 5;
+---+
| 5 |
+---+
ThefollowingexamplesshowhowunrecognizedMEM_LIMIT valuesleadtoerrorsforsubsequentqueries.
[localhost:21000] > set mem_limit=3tb;
MEM_LIMIT set to 3tb
[localhost:21000] > select 5;
ERROR: Failed to parse query memory limit from '3tb'.
[localhost:21000] > set mem_limit=xyz;
MEM_LIMIT set to xyz
[localhost:21000] > select 5;
Query: select 5
ERROR: Failed to parse query memory limit from 'xyz'.
ThefollowingexamplesshowstheautomaticquerycancellationwhentheMEM_LIMIT valueisexceededonanyhost
involvedintheImpalaquery.Firstitrunsasuccessfulqueryandchecksthelargestamountofmemoryusedonany
nodeforanystageofthequery.Thenitsetsanartificially lowMEM_LIMIT settingsothatthesamequerycannotrun.
[localhost:21000] > select count(*) from customer;
Query: select count(*) from customer
+----------+
| count(*) |
+----------+
| 150000   |
+----------+
[localhost:21000] > select count(distinct c_name) from customer;
Query: select count(distinct c_name) from customer
+------------------------+
| count(distinct c_name) |
+------------------------+
| 150000                 |
+------------------------+
[localhost:21000] > summary;
+--------------+--------+----------+----------+---------+------------+----------+---------------+---------------+
| Operator     | #Hosts | Avg Time | Max Time | #Rows   | Est. #Rows | Peak Mem | Est. Peak Mem | Detail        |
+--------------+--------+----------+----------+---------+------------+----------+---------------+---------------+
| 06:AGGREGATE | 1      | 230.00ms | 230.00ms | 1       | 1          | 16.00 KB | -1 B          | FINALIZE      |
| 05:EXCHANGE  | 1      | 43.44us  | 43.44us  | 1       | 1          | 0 B      | -1 B          | UNPARTITIONED |
| 02:AGGREGATE | 1      | 227.14ms | 227.14ms | 1       | 1          | 12.00 KB | 10.00 MB      |               |
| 04:AGGREGATE | 1      | 126.27ms | 126.27ms | 150.00K | 150.00K    | 15.17 MB | 10.00 MB      |               |
| 03:EXCHANGE  | 1      | 44.07ms  | 44.07ms  | 150.00K | 150.00K    | 0 B      | 0 B           | HASH(c_name)  |
| 01:AGGREGATE | 1      | 361.94ms | 361.94ms | 150.00K | 150.00K    | 23.04 MB | 10.00 MB      |               |
| 00:SCAN HDFS | 1      | 43.64ms  | 43.64ms  | 150.00K | 150.00K    | 24.19 MB | 64.00 MB      | tpch.customer |
+--------------+--------+----------+----------+---------+------------+----------+---------------+---------------+
[localhost:21000] > set mem_limit=15mb;
MEM_LIMIT set to 15mb
[localhost:21000] > select count(distinct c_name) from customer;
Query: select count(distinct c_name) from customer
ERROR:
Memory limit exceeded
Query did not have enough memory to get the minimum required buffers in the block manager.
344|ApacheImpalaGuideImpalaSQLLanguageReference
MIN_SPILLABLE_BUFFER_SIZE QueryOption
Specifies theminimum sizeforamemorybufferusedwhenthespill-to-diskmechanism isactivated,forexamplefor
queriesagainstalargetablewithnostatistics,orlargejoinoperations.
Type:integer
Default:
65536(64KB)
Units:Anumericargumentrepresentsasizeinbytes;youcanalsouseasuffixofmormbformegabytes,orgorgbfor
gigabytes.Ifyouspecifyavaluewithunrecognizedformats,subsequentqueriesfailwithanerror.
Addedin:CDH5.13.0/Impala2.10.0
Usagenotes:
Thisqueryoptionsetsalowerboundonthesizeoftheinternalbuffersizethatcanbeusedduringspill-to-disk
operations.Theactualsizeofthebufferischosenbythequeryplanner.
Ifoverallqueryperformance islimitedbythetimeneededforspilling,considerincreasingthe
MIN_SPILLABLE_BUFFER_SIZE setting.LargerbuffersizesresultinImpalaissuinglargerI/Orequeststostorage
devices,whichmightresultinhigherthroughput, particularly onrotationaldisks.
Thetradeoffwithalargevalueforthissettingisincreasedmemoryusageduringspill-to-diskoperations.Reducingthis
valuemayreducememoryconsumption.
Todetermineifthevalueforthissettingishavinganeffectbycappingthespillablebuffersize,youcanseethebuffer
sizechosenbythequeryplannerforaparticular query.EXPLAIN thequerywhilethesettingEXPLAIN_LEVEL=2 isin
effect.
Examples:
set min_spillable_buffer_size=128KB;
Relatedinformation:
BUFFER_POOL_LIMIT QueryOptiononpage324,DEFAULT_SPILLABLE_BUFFER_SIZE QueryOptiononpage327,
MAX_ROW_SIZEQueryOptiononpage340,EffectofBufferPoolonMemoryUsage(CDH5.13andhigher)onpage607
MT_DOP QueryOption
Setsthedegreeofparallelismusedforcertainoperationsthatcanbenefitfrommultithreadedexecution.Youcan
specifyvalueshigherthanzerotofindtheidealbalanceofresponsetime,memoryusage,andCPUusageduring
statementprocessing.
Note:
TheImpalaexecutionengineisbeingrevampedincrementallytoaddadditional parallelismwithina
singlehostforcertainstatementsandkindsofoperations.ThesettingMT_DOP=0 usestheâoldâcode
pathwithlimitedintra-nodeparallelism.
Currently,theoperationsaffectedbytheMT_DOPqueryoptionare:
â¢COMPUTE [INCREMENTAL] STATS .ImpalaautomaticallysetsMT_DOP=4 forCOMPUTE STATS
andCOMPUTE INCREMENTAL STATS statementsonParquettables.
â¢Querieswithexecutionplanscontainingonlyscanandaggregationoperators.Otherqueries
produceanerrorifMT_DOPissettoanon-zerovalue.Therefore,thisqueryoptionistypically
onlysetforthedurationofspecificlong-running ,CPU-intensivequeries.
Type:integer
ApacheImpalaGuide|345ImpalaSQLLanguageReference
Default:0
BecauseCOMPUTE STATS andCOMPUTE INCREMENTAL STATS statementsforParquettablesbenefitsubstantially
fromextraintra-nodeparallelism,ImpalaautomaticallysetsMT_DOP=4 whencomputing statsforParquettables.
Range:0to64
Examples:
Note:
Anytimingfiguresinthefollowingexamplesareonasmall,lightlyloadeddevelopmentcluster.Your
mileagemayvary.Speedupsdependonmanyfactors,including thenumberofrows,columns,and
partitions withineachtable.
ThefollowingexampleshowshowtorunaCOMPUTE STATS statementagainstaParquettablewithorwithoutan
explicitMT_DOPsetting:
-- Explicitly setting MT_DOP to 0 selects the old code path.
set mt_dop = 0;
MT_DOP set to 0
-- The analysis for the billion rows is distributed among hosts,
-- but uses only a single core on each host.
compute stats billion_rows_parquet;
+-----------------------------------------+
| summary                                 |
+-----------------------------------------+
| Updated 1 partition(s) and 2 column(s). |
+-----------------------------------------+
drop stats billion_rows_parquet;
-- Using 4 logical processors per host is faster.
set mt_dop = 4;
MT_DOP set to 4
compute stats billion_rows_parquet;
+-----------------------------------------+
| summary                                 |
+-----------------------------------------+
| Updated 1 partition(s) and 2 column(s). |
+-----------------------------------------+
drop stats billion_rows_parquet;
-- Unsetting the option reverts back to its default.
-- Which for COMPUTE STATS and a Parquet table is 4,
-- so again it uses the fast path.
unset MT_DOP;
Unsetting option MT_DOP
compute stats billion_rows_parquet;
+-----------------------------------------+
| summary                                 |
+-----------------------------------------+
| Updated 1 partition(s) and 2 column(s). |
+-----------------------------------------+
ThefollowingexampleshowstheeffectsofsettingMT_DOPforaqueryinvolvingonlyscanandaggregationoperations
foraParquettable:
set mt_dop = 0;
MT_DOP set to 0
346|ApacheImpalaGuideImpalaSQLLanguageReference
-- COUNT(DISTINCT) for a unique column is CPU-intensive.
select count(distinct id) from billion_rows_parquet;
+--------------------+
| count(distinct id) |
+--------------------+
| 1000000000         |
+--------------------+
Fetched 1 row(s) in 67.20s
set mt_dop = 16;
MT_DOP set to 16
-- Introducing more intra-node parallelism for the aggregation
-- speeds things up, and potentially reduces memory overhead by
-- reducing the number of scanner threads.
select count(distinct id) from billion_rows_parquet;
+--------------------+
| count(distinct id) |
+--------------------+
| 1000000000         |
+--------------------+
Fetched 1 row(s) in 17.19s
Thefollowingexampleshowshowqueriesthatarenotcompatiblewithnon-zeroMT_DOPsettingsproduceanerror
whenMT_DOPisset:
set mt_dop=1;
MT_DOP set to 1
select * from a1 inner join a2
  on a1.id = a2.id limit 4;
ERROR: NotImplementedException: MT_DOP not supported for plans with
  base table joins or table sinks.
Relatedinformation:
COMPUTE STATSStatementonpage219,ImpalaAggregateFunctions onpage479
NUM_NODE SQueryOption
Limitthenumberofnodesthatprocessaquery,typicallyduringdebugging.
Type:numeric
Allowedvalues:Onlyacceptsthevalues0(meaning allnodes)or1(meaning allworkisdoneonthecoordinatornode).
Default:0
Usagenotes:
Ifyouarediagnosing aproblemthatyoususpectisduetoatimingissueduetodistributedqueryprocessing,youcan
setNUM_NODES=1 toverifyiftheproblemstilloccurswhenalltheworkisdoneonasinglenode.
YoumightsettheNUM_NODES optionto1briefly,duringINSERTorCREATE TABLE AS SELECT statements.Normally,
thosestatementsproduceoneormoredatafilesperdatanode.Ifthewriteoperationinvolvessmallamountsofdata,
aParquettable,and/orapartitioned table,thedefaultbehaviorcouldproducemanysmallfileswhenintuitivelyyou
mightexpectonlyasingleoutputfile.SET NUM_NODES=1 turnsofftheâdistributedâaspectofthewriteoperation,
makingitmorelikelytoproduceonlyoneorafewdatafiles.
ApacheImpalaGuide|347ImpalaSQLLanguageReference
Warning:
Becausethisoptionresultsinincreasedresourceutilizationonasinglehost,itcouldcauseproblems
duetocontentionwithotherImpalastatementsorhighresourceusage.Symptomscouldinclude
queriesrunningslowly,exceedingthememorylimit,orappearing tohang.Useitonlyinasingle-user
development/testenvironment;donotuseitinaproduction environmentorinaclusterwitha
high-concurrencyorhigh-volumeorperformance-critic alworkload.
NUM_ROWS_PRODUCED_LIMIT QueryOption
TheNUM_ROWS_PRODUCED_LIMIT queryoptionlimitsthenumberofrowsproducedbyaquery.Aqueryiscanceled
whenitsexecutionproducesmorerowsthanthespecified limitsetbytheNUM_ROWS_PRODUCED_LIMIT option.
Thislimitonlyapplieswhentheresultsarereturnedtoaclient,forexample,toaSELECTquery,butnottoanINSERT
query.
Thedefaultvalueof0specifiesthatthereisnolimitonthenumberofrowsproduced.
Type:INT
Allowedvalues:0orpositivenumbers
Default:0
NUM_SCANNER_THRE ADSQueryOption
Maximumnumberofscannerthreads(oneachnode)usedforeachquery.Bydefault,Impalausesasmanycoresas
areavailable(onethreadpercore).Youmightlowerthisvalueifqueriesareusingexcessiveresourcesonabusycluster.
Impalaimposesamaximumvalueautomatically,soahighvaluehasnopracticaleffect.
Type:numeric
Default:0
OPTIMIZE_PARTITION_KEY_SCANS QueryOption(CDH5.7orhigheronly)
Enablesafastcodepathforqueriesthatapplysimpleaggregatefunctions topartitionkeycolumns:MIN(key_column ),
MAX(key_column ),orCOUNT(DISTINCT key_column ).
Type:Boolean; recognizedvaluesare1and0,ortrueandfalse;anyothervalueinterpretedasfalse
Default:false(shownas0inoutputofSETstatement)
Note:InCDH5.7.0/Impala2.5.0,onlythevalue1enablestheoption,andthevaluetrueisnot
recognized.ThislimitationistrackedbytheissueIMPALA-3334 ,whichshowsthereleaseswherethe
problemisfixed.
Addedin:CDH5.7.0/Impala2.5.0
Usagenotes:
Thisoptimizationspeedsupcommonâintrospectionâ operationsoverpartitionkeycolumns,forexampledetermining
thedistinctvaluesofpartition keys.
ThisoptimizationdoesnotapplytoSELECTstatementsthatreferencecolumnsthatarenotpartitionkeys.Italsoonly
applieswhenallthepartition keycolumnsintheSELECTstatementarereferencedinoneofthefollowingcontexts:
â¢WithinaMAX()orMAX()aggregatefunctionorastheargumentofanyaggregatefunctionwiththeDISTINCT
keywordapplied.
â¢WithinaWHERE,GROUP BY orHAVINGclause.
348|ApacheImpalaGuideImpalaSQLLanguageReference
Thisoptimizationisenabledbyaqueryoptionbecauseitskipssomeconsistencychecksandthereforecanreturn
slightlydifferentpartitionvaluesifpartitions areintheprocessofbeingadded,dropped,orloadedoutsideofImpala.
Queriesmightexhibitdifferentbehaviordepending onthesettingofthisoptioninthefollowingcases:
â¢Iffilesareremovedfromapartition usingHDFSorothernon-Impala operations,thereisaperioduntilthenext
REFRESH ofthetablewhereregularqueriesfailatruntimebecausetheydetectthemissingfiles.Withthis
optimizationenabled,queriesthatevaluateonlythepartitionkeycolumnvalues(notthecontentsofthepartition
itself)succeed, andtreatthepartition asifitstillexists.
â¢Ifapartitioncontainsanydatafiles,butthedatafilesdonotcontainanyrows,aregularqueryconsidersthatthe
partition doesnotexist.Withthisoptimizationenabled, thepartition istreatedasifitexists.
Ifthepartition includesnofilesatall,thisoptimizationdoesnotchangethequerybehavior:thepartition is
consideredtonotexistwhetherornotthisoptimizationisenabled.
Examples:
Thefollowingexampleshowsinitialschemasetupandthedefaultbehaviorofqueriesthatreturnjustthepartition
keycolumnforatable:
-- Make a partitioned table with 3 partitions.
create table t1 (s string) partitioned by (year int);
insert into t1 partition (year=2015) values ('last year');
insert into t1 partition (year=2016) values ('this year');
insert into t1 partition (year=2017) values ('next year');
-- Regardless of the option setting, this query must read the
-- data files to know how many rows to return for each year value.
explain select year from t1;
+-----------------------------------------------------+
| Explain String                                      |
+-----------------------------------------------------+
| Estimated Per-Host Requirements: Memory=0B VCores=0 |
|                                                     |
| F00:PLAN FRAGMENT [UNPARTITIONED]                   |
|   00:SCAN HDFS [key_cols.t1]                        |
|      partitions=3/3 files=4 size=40B                |
|      table stats: 3 rows total                      |
|      column stats: all                              |
|      hosts=3 per-host-mem=unavailable               |
|      tuple-ids=0 row-size=4B cardinality=3          |
+-----------------------------------------------------+
-- The aggregation operation means the query does not need to read
-- the data within each partition: the result set contains exactly 1 row
-- per partition, derived from the partition key column value.
-- By default, Impala still includes a 'scan' operation in the query.
explain select distinct year from t1;
+------------------------------------------------------------------------------------+
| Explain String                                                                     |
+------------------------------------------------------------------------------------+
| Estimated Per-Host Requirements: Memory=0B VCores=0                                |
|                                                                                    |
| 01:AGGREGATE [FINALIZE]                                                            |
| |  group by: year                                                                  |
| |                                                                                  |
| 00:SCAN HDFS [key_cols.t1]                                                         |
|    partitions=0/0 files=0 size=0B                                                  |
+------------------------------------------------------------------------------------+
ThefollowingexamplesshowhowtheplanismademoreefficientwhentheOPTIMIZE_PARTITION_KEY_SCANS
optionisenabled:
set optimize_partition_key_scans=1;
OPTIMIZE_PARTITION_KEY_SCANS set to 1
-- The aggregation operation is turned into a UNION internally,
ApacheImpalaGuide|349ImpalaSQLLanguageReference
-- with constant values known in advance based on the metadata
-- for the partitioned table.
explain select distinct year from t1;
+-----------------------------------------------------+
| Explain String                                      |
+-----------------------------------------------------+
| Estimated Per-Host Requirements: Memory=0B VCores=0 |
|                                                     |
| F00:PLAN FRAGMENT [UNPARTITIONED]                   |
|   01:AGGREGATE [FINALIZE]                           |
|   |  group by: year                                 |
|   |  hosts=1 per-host-mem=unavailable               |
|   |  tuple-ids=1 row-size=4B cardinality=3          |
|   |                                                 |
|   00:UNION                                          |
|      constant-operands=3                            |
|      hosts=1 per-host-mem=unavailable               |
|      tuple-ids=0 row-size=4B cardinality=3          |
+-----------------------------------------------------+
-- The same optimization applies to other aggregation queries
-- that only return values based on partition key columns:
-- MIN, MAX, COUNT(DISTINCT), and so on.
explain select min(year) from t1;
+-----------------------------------------------------+
| Explain String                                      |
+-----------------------------------------------------+
| Estimated Per-Host Requirements: Memory=0B VCores=0 |
|                                                     |
| F00:PLAN FRAGMENT [UNPARTITIONED]                   |
|   01:AGGREGATE [FINALIZE]                           |
|   |  output: min(year)                              |
|   |  hosts=1 per-host-mem=unavailable               |
|   |  tuple-ids=1 row-size=4B cardinality=1          |
|   |                                                 |
|   00:UNION                                          |
|      constant-operands=3                            |
|      hosts=1 per-host-mem=unavailable               |
|      tuple-ids=0 row-size=4B cardinality=3          |
+-----------------------------------------------------+
PARQUET_COMPRESSION_CODECQueryOption
Deprecated.UseCOMPRESSION_CODEC inImpala2.0andlater.SeeCOMPRESSION_CODECQueryOption(CDH5.2or
higheronly)onpage324fordetails.
PARQUET_ANNO TATE_STRINGS_UTF8 QueryOption(CDH5.8orhigheronly)
CausesImpalaINSERTandCREATE TABLE AS SELECT statementstowriteParquetfilesthatusetheUTF-8annotation
forSTRINGcolumns.
Usagenotes:
Bydefault,ImpalarepresentsaSTRINGcolumninParquetasanunannotatedbinaryfield.
ImpalaalwaysusestheUTF-8annotationwhenwritingCHARandVARCHAR columnstoParquetfiles.Analternativeto
usingthequeryoptionistocastSTRINGvaluestoVARCHAR .
ThisoptionistohelpmakeImpala-writ tendatamoreinteroperablewithotherdataprocessingengines.Impalaitself
currentlydoesnotsupportalloperationsonUTF-8data.Although dataprocessedbyImpalaistypicallyrepresented
inASCII,itisvalidtodesignatethedataasUTF-8whenstoringondisk,becauseASCIIisasubsetofUTF-8.
Type:Boolean; recognizedvaluesare1and0,ortrueandfalse;anyothervalueinterpretedasfalse
Default:false(shownas0inoutputofSETstatement)
Addedin:CDH5.8.0/Impala2.6.0
Relatedinformation:
UsingtheParquetFileFormatwithImpalaTablesonpage643
350|ApacheImpalaGuideImpalaSQLLanguageReference
PARQUET_ARRA Y_RESOLUTIONQueryOption(CDH5.12orhigheronly)
ThePARQUET_ARRAY_RESOLUTION queryoptioncontrolsthebehavioroftheindexed-based resolution fornested
arraysinParquet.
InParquet,youcanrepresentanarrayusinga2-levelor3-levelrepresentation.Themodern,standardrepresentation
is3-level.Thelegacy2-levelschemeissupportedforcompatibilitywitholderParquetfiles.However,thereisnoreliable
metadatawithinParquetfilestoindicatewhichencodingwasused.Itisevenpossibletohavemixedencodingswithin
thesamefileiftherearemultiplearrays.ThePARQUET_ARRAY_RESOLUTION optioncontrolstheprocessofresolution
thatistomatcheverycolumn/field referencefromaquerytoacolumnintheParquetfile.
Thesupportedvaluesforthequeryoptionare:
â¢THREE_LEVEL :Assumes arraysareencodedwiththe3-levelrepresentation,anddoesnotattemptthe2-level
resolution.
â¢TWO_LEVEL :Assumes arraysareencodedwiththe2-levelrepresentation,anddoesnotattemptthe3-level
resolution.
â¢TWO_LEVEL_THEN_THREE_LEVEL :Firsttriestoresolveassuming a2-levelrepresentation,andifunsuccess ful,
triesa3-levelrepresentation.
Alloftheaboveoptionsresolvearraysencodedwithasinglelevel.
Afailuretoresolveacolumn/field referenceinaquerywithagivenarrayresolution policydoesnotnecessarily result
inawarningorerrorreturnedbythequery.Amismatchmightbetreatedlikeamissingcolumn(returnsNULLvalues),
anditisnotpossibletoreliablydistinguishthe'badresolution' and'legitimatelymissingcolumn'cases.
Thename-based policygenerallydoesnothavetheproblemofambiguous arrayrepresentations.Youspecifytouse
thename-based policybysettingthePARQUET_FALLBACK_SCHEMA_RESOLUTION queryoptiontoNAME.
Type:EnumofTWO_LEVEL ,TWO_LEVEL_THEN_THREE_LEVEL ,andTHREE_LEVEL
Default:THREE_LEVEL
Addedin:CDH5.12.0/Impala2.9.0
Examples:
EXAMPLE A:ThefollowingParquetschemaofafilecanbeinterpretedasa2-levelor3-level:
ParquetSchemaExampleA {
  optional group single_element_groups (LIST) {
    repeated group single_element_group {
      required int64 count;
    }
  }
}
Thefollowingtableschemacorrespondstoa2-levelinterpretation:
CREATE TABLE t (col1 array<struct<f1: bigint>>) STORED AS PARQUET;
Successfulquerywitha2-levelinterpretation:
SET PARQUET_ARRAY_RESOLUTION=TWO_LEVEL;
SELECT ITEM.f1 FROM t.col1;
Thefollowingtableschemacorrespondstoa3-levelinterpretation:
CREATE TABLE t (col1 array<bigint>) STORED AS PARQUET;
ApacheImpalaGuide|351ImpalaSQLLanguageReference
Successfulquerywitha3-levelinterpretation:
SET PARQUET_ARRAY_RESOLUTION=THREE_LEVEL;
SELECT ITEM FROM t.col1
EXAMPLE B:ThefollowingParquetschemaofafilecanbeonlybesuccessfullyinterpretedasa2-level:
ParquetSchemaExampleB {
  required group list_of_ints (LIST) {
    repeated int32 list_of_ints_tuple;
  }
}
Thefollowingtableschemacorrespondstoa2-levelinterpretation:
CREATE TABLE t (col1 array<int>) STORED AS PARQUET;
Successfulquerywitha2-levelinterpretation:
SET PARQUET_ARRAY_RESOLUTION=TWO_LEVEL;
SELECT ITEM FROM t.col1
Unsuccess fulquerywitha3-levelinterpretation.ThequeryreturnsNULLsasifthecolumnwasmissinginthefile:
SET PARQUET_ARRAY_RESOLUTION=THREE_LEVEL;
SELECT ITEM FROM t.col1
PARQUET_DIC TIONARY_FILTERINGQueryOption(CDH5.12orhigheronly)
ThePARQUET_DICTIONARY_FILTERING queryoptioncontrolswhetherImpalausesdictionaryfilteringforParquet
files.
Toefficientlyprocessahighlyselectivescanquery,whenthisoptionisenabled,ImpalachecksthevaluesintheParquet
dictionarypageanddeterminesifthewholerowgroupcanbethrownout.
Acolumnchunkispurelydictionaryencodedandcanbeusedbydictionaryfilteringifanyofthefollowingconditions
aremet:
1.Iftheencoding_stats isintheParquetfile,dictionaryfilteringusesittodetermineifthereareonlydictionary
encodedpages(i.e.therearenodatapageswithanencodingotherthanPLAIN_DIC TIONARY).
2.Iftheencodingstatsarenotpresent,dictionaryfilteringlooksattheencodings.Thecolumnispurelydictionary
encodedifbothoftheconditions satisfy:
â¢PLAIN_DIC TIONARYispresent.
â¢OnlyPLAIN_DIC TIONARY,RLE,orBIT_PACKEDencodingsarelisted.
3.DictionaryfilteringworksfortheParquetdictionaries withlessthan40000valuesifthefilewaswrittenbyor
lower.
InthequeryruntimeprofileoutputforeachImpaladinstance,theNumDictFilteredRowGroups fieldintheSCAN
nodesectionshowsthenumberofrowgroupsthatwereskippedbasedondictionaryfiltering.
NotethatrowgroupscanbefilteredoutbyParquetstatistics,andinsuchcases,dictionaryfilteringwillnotbeconsidered.
Thesupportedvaluesforthequeryoptionare:
â¢true(1):Usedictionaryfiltering.
â¢false(0):Donotusedictionaryfiltering
â¢Anyothervaluesaretreatedasfalse.
352|ApacheImpalaGuideImpalaSQLLanguageReference
Type:Boolean
Default:true(1)
Addedin:CDH5.12.0/Impala2.9.0
PARQUET_FALLBACK_SCHEMA_RE SOLUTIONQueryOption(CDH5.8orhigheronly)
ThePARQUET_FALLBACK_SCHEMA_RESOLUTION queryoptionallowsImpalatolookupcolumnswithinParquetfiles
bycolumnname,ratherthancolumnorder,whennecessary.Theallowedvaluesare:
â¢POSITION (0)
â¢NAME(1)
Usagenotes:
Bydefault,ImpalalooksupcolumnswithinaParquetfilebasedontheorderofcolumnsinthetable.Thenamesetting
forthisoptionenablesbehaviorforImpalaqueriessimilartotheHivesettingparquet.column.index access=false .
ItalsoallowsImpalatoqueryParquetfilescreatedbyHivewiththeparquet.column.index.access=false setting
ineffect.
Type:integerorstring
Addedin:CDH5.8.0/Impala2.6.0
Relatedinformation:
SchemaEvolutionforParquetTablesonpage654
PARQUET_FILE_SIZE QueryOption
Specifies themaximumsizeofeachParquetdatafileproducedbyImpalaINSERTstatements.
Syntax:
Specifythesizeinbytes,orwithatrailingmorgcharactertoindicatemegabytesorgigabytes.Forexample:
-- 128 megabytes.
set PARQUET_FILE_SIZE=134217728
INSERT OVERWRITE parquet_table SELECT * FROM text_table;
-- 512 megabytes.
set PARQUET_FILE_SIZE=512m;
INSERT OVERWRITE parquet_table SELECT * FROM text_table;
-- 1 gigabyte.
set PARQUET_FILE_SIZE=1g;
INSERT OVERWRITE parquet_table SELECT * FROM text_table;
Usagenotes:
Withtablesthataresmallorfinelypartitioned, thedefaultParquetblocksize(formerly1GB,now256MBinImpala
2.0andlater)couldbemuchlargerthanneededforeachdatafile.ForINSERToperationsintosuchtables,youcan
increaseparallelismbyspecifyingasmallerPARQUET_FILE_SIZE value,resultinginmoreHDFSblocksthatcanbe
processedbydifferentnodes.
Type:numeric, withoptionalunitspecifier
Important:
Currently,themaximumvalueforthissettingis1gigabyte(1g).Settingavaluehigherthan1gigabyte
couldresultinerrorsduringanINSERToperation.
Default:0(producesfileswithatargetsizeof256MB;filesmightbelargerforverywidetables)
Isilonconsiderations:
ApacheImpalaGuide|353ImpalaSQLLanguageReference
BecausetheEMCIsilonstoragedevicesuseaglobalvaluefortheblocksizeratherthanaconfigurablevalueforeach
file,thePARQUET_FILE_SIZE queryoptionhasnoeffectwhenImpalainsertsdataintoatableorpartition residing
onIsilonstorage.Usetheisicommand tosetthedefaultblocksizegloballyontheIsilondevice.Forexample,toset
theIsilondefaultblocksizeto256MB,therecommended sizeforParquetdatafilesforImpala,issuethefollowing
command:
isi hdfs settings modify --default-block-size=256MB
Relatedinformation:
ForinformationabouttheParquetfileformat,andhowthenumberandsizeofdatafilesaffectsqueryperformance,
seeUsingtheParquetFileFormatwithImpalaTablesonpage643.
PARQUET_RE AD_STATISTICSQueryOption(CDH5.12orhigheronly)
ThePARQUET_READ_STATISTICS queryoptioncontrolswhethertoreadstatisticsfromParquetfilesandusethem
duringqueryprocessing.
Parquetstoresmin/maxstatswhichcanbeusedtoskipreadingrowgroupsiftheydon'tqualifyacertainpredicate.
Whenthisqueryoptionissettotrue,ImpalareadstheParquetstatisticsandskipsreadingrowgroupsthatdonot
matchtheconditions intheWHEREclause.
Impalasupports filteringbasedonParquetstatistics:
â¢Ofthenumericaltypesfortheoldversionofthestatistics:Boolean, Integer,Float
â¢Ofthetypesforthenewversionofthestatistics(startinginIMPALA2.8):Boolean, Integer,Float,Decimal,String,
Timestamp
â¢Forsimplepredicatesoftheforms:<slot> <op> <constant> or<constant> <op> <slot> ,where<op>
isLT,LE,GE,GT,andEQ
ThePARQUET_READ_STATISTICS optionprovidesaworkaroundwhendealingwithfilesthathavecorruptParquet
statisticsandunknownerrors.
InthequeryruntimeprofileoutputforeachImpaladinstance,theNumStatsFilteredRowGroups fieldintheSCAN
nodesectionshowsthenumberofrowgroupsthatwereskippedbasedonParquetstatistics.
Thesupportedvaluesforthequeryoptionare:
â¢true(1):ReadstatisticsfromParquetfilesandusetheminqueryprocessing.
â¢false(0):DonotuseParquetreadstatistics.
â¢Anyothervaluesaretreatedasfalse.
Type:Boolean
Default:true
Addedin:CDH5.12.0/Impala2.9.0
PREFETCH_MODE QueryOption(CDH5.8orhigheronly)
Determineswhethertheprefetchingoptimizationisappliedduringjoinqueryprocessing.
Type:numeric(0,1)orcorresponding mnemonic strings(NONE,HT_BUCKET ).
Default:1(equivalenttoHT_BUCKET )
Addedin:CDH5.8.0/Impala2.6.0
Usagenotes:
Thedefaultmodeis1,whichmeansthathashtablebucketsareprefetchedduringjoinqueryprocessing.
Relatedinformation:
JoinsinImpalaSELECTStatementsonpage296,Performance ConsiderationsforJoinQueriesonpage568.
354|ApacheImpalaGuideImpalaSQLLanguageReference
QUERY_TIMEOUT_SQueryOption(CDH5.2orhigheronly)
Setstheidlequerytimeoutvalueforthesession,inseconds.Queriesthatsitidleforlongerthanthetimeoutvalue
areautomaticallycancelled. Ifthesystemadministratorspecified the--idle_query_timeout startupoption,
QUERY_TIMEOUT_S mustbesmallerthanorequaltothe--idle_query_timeout value.
Note:
Thetimeoutclockforqueriesandsessionsonlystartstickingwhenthequeryorsessionisidle.
Forqueries,thismeansthequeryhasresultsreadybutiswaitingforaclienttofetchthedata.Aquery
canrunforanarbitrarytimewithouttriggeringatimeout,becausethequeryiscomputing results
ratherthansittingidlewaitingfortheresultstobefetched.Thetimeoutperiodisintendedtoprevent
unclosed queriesfromconsuming resourcesandtakingupslotsintheadmission countofrunning
queries,potentiallypreventingotherqueriesfromstarting.
Forsessions, thismeansthatnoqueryhasbeensubmittedforsomeperiodoftime.
Syntax:
SET QUERY_TIMEOUT_S= seconds;
Type:numeric
Default:0(notimeoutif--idle_query_timeout notineffect;otherwise,use--idle_query_timeout value)
Addedin:CDH5.2.0/Impala2.0.0
Relatedinformation:
SettingTimeoutPeriodsforDaemons, Queries,andSessionsonpage70
REPLICA_PREFERENCE QueryOption(CDH5.9orhigheronly)
TheREPLICA_PREFERENCE queryoptionletsyoudistributetheworkmoreevenlyifhotspotsandbottleneckspersist.
Itcausestheaccesscostofallreplicasofadatablocktobeconsideredequaltoorworsethantheconfiguredvalue.
ThisallowsImpalatoschedule readstosuboptimalreplicas(e.g.localinthepresenceofcachedones)inorderto
distributetheworkacrossmoreexecutornodes.
Allowedvaluesare:CACHE_LOCAL (0),DISK_LOCAL (2),REMOTE(4)
Type:Enum
Default:CACHE_LOCAL (0)
Addedin:CDH5.9.0/Impala2.7.0
UsageNotes:
BydefaultImpalaselectsthebestreplicaitcanfindintermsofaccesscost.Thepreferredorderiscached,local,and
remote.WithREPLICA_PREFERENCE ,thepreferenceofallreplicasarecappedattheselectedvalue.Forexample,
whenREPLICA_PREFERENCE issettoDISK_LOCAL ,cachedandlocalreplicasaretreatedwiththeequalpreference.
WhensettoREMOTE,allthreetypesofreplicas,cached,local,remote,aretreatedwithequalpreference.
Relatedinformation:
UsingHDFSCachingwithImpala(CDH5.3orhigheronly)onpage593,SCHEDULE_RANDOM_REPLICA QueryOption
(CDH5.7orhigheronly)onpage360
REQUEST_POOLQueryOption
Thepoolorqueuenamethatqueriesshouldbesubmittedto.OnlyapplieswhenyouenabletheImpalaadmission
controlfeature.Specifies thenameofthepoolusedbyrequestsfromImpalatotheresourcemanager.
Type:STRING
ApacheImpalaGuide|355ImpalaSQLLanguageReference
Default:empty(usetheuser-to-poolmapping definedbyanimpalad startupoptionintheImpalaconfigurationfile)
Relatedinformation:
Admission ControlandQueryQueuingonpage549
RESOURCE_TRACE_RATIOQueryOption(CDH6.2/Impala3.2orhigheronly)
TheRESOURCE_TRACE_RATIO queryoptionspecifiestheratioofquerieswheretheCPUusageinfowillbeincluded
intheprofiles.Collecting CPUusageandsendingitaroundaddsaslightoverheadduringqueryexecution.Thisquery
optionletsyoucontrolwhethertocollectadditional informationtodiagnose theresourceusage.
Forexample,settingRESOURCE_TRACE_RATIO=1 addsatraceoftheCPUusagetotheprofileofeachquery.
SettingRESOURCE_TRACE_RATIO=0.5 meansthatrandomly selectedhalfofallquerieswillhavethatinformation
collectedbythecoordinatorandincludedintheprofiles.
SettingRESOURCE_TRACE_RATIO=0 meansthatCPUusagewillnotbetrackedandincludedintheprofiles.
Valuesfrom0to1areallowed.
Type:Number
Default:0
Addedin:CDH6.2
RUNTIME_BL OOM_FILTER_SIZE QueryOption(CDH5.7orhigheronly)
Size(inbytes)ofBloomfilterdatastructureusedbytheruntimefilteringfeature.
Important:
InCDH5.8/Impala2.6andhigher,thisqueryoptiononlyappliesasafallback,whenstatisticsarenot
available.Bydefault,ImpalaestimatestheoptimalsizeoftheBloomfilterstructureregardlessofthe
settingforthisoption.(ThisisachangefromtheoriginalbehaviorinCDH5.7/Impala2.5.)
InCDH5.8/Impala2.6andhigher,whenthevalueofthisqueryoptionisusedforqueryplanning,it
isconstrainedbytheminimum andmaximumsizesspecified bytheRUNTIME_FILTER_MIN_SIZE
andRUNTIME_FILTER_MAX_SIZE queryoptions.Thefiltersizeisadjustedupwardordownwardif
necessarytofitwithintheminimum/ma ximumrange.
Type:integer
Default:1048576 (1MB)
Maximum:16MB
Addedin:CDH5.7.0/Impala2.5.0
Usagenotes:
Thissettingaffectsoptimizationsforlargeandcomplexqueries,suchasdynamicpartition pruningforpartitioned
tables,andjoinoptimizationforqueriesthatjoinlargetables.Largerfiltersaremoreeffectiveathandlinghigher
cardinalityinputsets,butconsumemorememoryperfilter.
Ifyourqueryfiltersonhigh-cardinalitycolumns(forexample,millionsofdifferentvalues)andyoudonotgetthe
expectedspeedupfromtheruntimefilteringmechanism, considerdoingsomebenchmark swithahighervaluefor
RUNTIME_BLOOM_FILTER_SIZE .TheextramemorydevotedtotheBloomfilterdatastructurescanhelpmakethe
filteringmoreaccurate.
Becausetheruntimefilteringfeatureappliesmainlytoresource-intensiveandlong-running queries,onlyadjustthis
queryoptionwhentuninglong-running queriesinvolvingsomecombinationoflargepartitioned tablesandjoins
involvinglargetables.
356|ApacheImpalaGuideImpalaSQLLanguageReference
Becausetheeffectivenessofthissettingdependssomuchonquerycharacteristicsanddatadistribution, youtypically
onlyuseitforspecificqueriesthatneedsomeextratuning,andtheidealvaluedependsonthequery.Consider setting
thisqueryoptionimmediatelybeforetheexpensivequeryandunsettingitimmediatelyafterward.
Kuduconsiderations:
ThisqueryoptionaffectsonlyBloomfilters,notthemin/maxfiltersthatareappliedtoKudutables.Therefore,itdoes
notaffecttheperformance ofqueriesagainstKudutables.
Relatedinformation:
RuntimeFilteringforImpalaQueries(CDH5.7orhigheronly)onpage588,RUNTIME_FIL TER_MODE QueryOption(CDH
5.7orhigheronly)onpage358,RUNTIME_FIL TER_MIN_SIZE QueryOption(CDH5.8orhigheronly)onpage357,
RUNTIME_FIL TER_MAX_SIZE QueryOption(CDH5.8orhigheronly)onpage357
RUNTIME_FIL TER_MAX_SIZE QueryOption(CDH5.8orhigheronly)
TheRUNTIME_FILTER_MAX_SIZE queryoptionadjuststhesettingsfortheruntimefilteringfeature.Thisoption
definesthemaximumsizeforafilter,nomatterwhattheestimatesproducedbytheplannerare.Thisvaluealso
overridesanylowernumberspecified fortheRUNTIME_BLOOM_FILTER_SIZE queryoption.Filtersizesarerounded
uptothenearestpoweroftwo.
Type:integer
Default:0(meaning usethevaluefromthecorresponding impalad startupoption)
Addedin:CDH5.8.0/Impala2.6.0
Usagenotes:
Becausetheruntimefilteringfeatureappliesmainlytoresource-intensiveandlong-running queries,onlyadjustthis
queryoptionwhentuninglong-running queriesinvolvingsomecombinationoflargepartitioned tablesandjoins
involvinglargetables.
Kuduconsiderations:
ThisqueryoptionaffectsonlyBloomfilters,notthemin/maxfiltersthatareappliedtoKudutables.Therefore,itdoes
notaffecttheperformance ofqueriesagainstKudutables.
Relatedinformation:
RuntimeFilteringforImpalaQueries(CDH5.7orhigheronly)onpage588,RUNTIME_FIL TER_MODE QueryOption(CDH
5.7orhigheronly)onpage358,RUNTIME_FIL TER_MIN_SIZE QueryOption(CDH5.8orhigheronly)onpage357,
RUNTIME_BL OOM_FILTER_SIZE QueryOption(CDH5.7orhigheronly)onpage356
RUNTIME_FIL TER_MIN_SIZE QueryOption(CDH5.8orhigheronly)
TheRUNTIME_FILTER_MIN_SIZE queryoptionadjuststhesettingsfortheruntimefilteringfeature.Thisoption
definestheminimum sizeforafilter,nomatterwhattheestimatesproducedbytheplannerare.Thisvaluealso
overridesanylowernumberspecified fortheRUNTIME_BLOOM_FILTER_SIZE queryoption.Filtersizesarerounded
uptothenearestpoweroftwo.
Type:integer
Default:0(meaning usethevaluefromthecorresponding impalad startupoption)
Addedin:CDH5.8.0/Impala2.6.0
Usagenotes:
Becausetheruntimefilteringfeatureappliesmainlytoresource-intensiveandlong-running queries,onlyadjustthis
queryoptionwhentuninglong-running queriesinvolvingsomecombinationoflargepartitioned tablesandjoins
involvinglargetables.
Kuduconsiderations:
ThisqueryoptionaffectsonlyBloomfilters,notthemin/maxfiltersthatareappliedtoKudutables.Therefore,itdoes
notaffecttheperformance ofqueriesagainstKudutables.
ApacheImpalaGuide|357ImpalaSQLLanguageReference
Relatedinformation:
RuntimeFilteringforImpalaQueries(CDH5.7orhigheronly)onpage588,RUNTIME_FIL TER_MODE QueryOption(CDH
5.7orhigheronly)onpage358,RUNTIME_FIL TER_MAX_SIZE QueryOption(CDH5.8orhigheronly)onpage357,
RUNTIME_BL OOM_FILTER_SIZE QueryOption(CDH5.7orhigheronly)onpage356
RUNTIME_FIL TER_MODE QueryOption(CDH5.7orhigheronly)
TheRUNTIME_FILTER_MODE queryoptionadjuststhesettingsfortheruntimefilteringfeature.Itturnsthisfeature
onandoff,andcontrolshowextensivelythefiltersaretransmittedbetweenhosts.
Type:numeric(0,1,2)orcorresponding mnemonic strings(OFF,LOCAL,GLOBAL).
Default:2(equivalenttoGLOBAL);formerlywas1/LOCAL,inCDH5.7/Impala2.5
Addedin:CDH5.7.0/Impala2.5.0
Usagenotes:
InCDH5.8/Impala2.6andhigher,thedefaultisGLOBAL.Thissettingisrecommended forawidevarietyofworkloads,
toprovidebestperformance withâoutoftheboxâsettings.
ThelowestsettingofLOCALdoesasimilarlevelofoptimization(suchaspartitionpruning)asinearlierImpalareleases.
ThissettingwasthedefaultinCDH5.7/Impala2.5,toallowforaperiodofpost-upgradetestingforexistingworkloads.
Thissettingissuitableforworkloadswithnon-performance-critic alqueries,orifthecoordinatornodeisunderheavy
CPUormemorypressure.
YoumightchangethesettingtoOFFifyourworkloadcontainsmanyqueriesinvolvingpartitioned tablesorjoinsthat
donotexperience aperformance increasefromtheruntimefiltersfeature.Iftheoverheadofproducingtheruntime
filtersoutweighstheperformance benefitforqueries,youcanturnthefeatureoffentirely.
Relatedinformation:
Partitioning forImpalaTablesonpage625fordetailsaboutruntimefiltering.DISABLE_ROW_RUNTIME_FIL TERING
QueryOption(CDH5.7orhigheronly)onpage328,RUNTIME_BL OOM_FILTER_SIZE QueryOption(CDH5.7orhigher
only)onpage356,RUNTIME_FIL TER_WAIT_TIME_MS QueryOption(CDH5.7orhigheronly)onpage358,and
MAX_NUM_RUNTIME_FIL TERSQueryOption(CDH5.7orhigheronly)onpage339fortuningoptionsforruntime
filtering.
RUNTIME_FIL TER_WAIT_TIME_MS QueryOption(CDH5.7orhigheronly)
TheRUNTIME_FILTER_WAIT_TIME_MS queryoptionadjuststhesettingsfortheruntimefilteringfeature.Itspecifies
atimeinmillisecondsthateachscannodewaitsforruntimefilterstobeproducedbyotherplanfragments.
Type:integer
Default:0(meaning usethevaluefromthecorresponding impalad startupoption)
Addedin:CDH5.7.0/Impala2.5.0
Usagenotes:
Becausetheruntimefilteringfeatureappliesmainlytoresource-intensiveandlong-running queries,onlyadjustthis
queryoptionwhentuninglong-running queriesinvolvingsomecombinationoflargepartitioned tablesandjoins
involvinglargetables.
Relatedinformation:
RuntimeFilteringforImpalaQueries(CDH5.7orhigheronly)onpage588,RUNTIME_FIL TER_MODE QueryOption(CDH
5.7orhigheronly)onpage358
S3_SKIP_INSER T_STAGINGQueryOption(CDH5.8orhigheronly)
SpeedsupINSERToperationsontablesorpartitions residingontheAmazonS3filesystem.Thetradeoffisthepossibility
ofinconsistentdataleftbehindifanerroroccurspartwaythroughtheoperation.
Bydefault,ImpalawriteoperationstoS3tablesandpartitions involveatwo-stageprocess.Impalawritesintermediate
filestoS3,then(becauseS3doesnotprovideaârenameâoperation)thoseintermediatefilesarecopiedtotheirfinal
358|ApacheImpalaGuideImpalaSQLLanguageReference
location,makingtheprocessmoreexpensiveasonafilesystemthatsupports renamingormovingfiles.Thisquery
optionmakesImpalaskiptheintermediatefiles,andinsteadwritethenewdatadirectlytothefinaldestination.
Usagenotes:
Important:
IfahostthatisparticipatingintheINSERToperationfailspartwaythroughthequery,youmightbe
leftwithatableorpartition thatcontainssomebutnotalloftheexpecteddatafiles.Therefore,this
optionismostappropriateforadevelopmentortestenvironmentwhereyouhavetheabilityto
reconstructthetableifaproblemduringINSERTleavesthedatainaninconsistentstate.
ThetimingoffiledeletionduringanINSERT OVERWRITE operationmakesitimpracticaltowritenewfilestoS3and
deletetheoldfilesinasingleoperation.Therefore,thisqueryoptiononlyaffectsregularINSERTstatementsthatadd
totheexistingdatainatable,notINSERT OVERWRITE statements.UseTRUNCATE TABLE ifyouneedtoremoveall
contentsfromanS3tablebeforeperformingafastINSERTwiththisoptionenabled.
Performance improvementswiththisoptionenabledcanbesubstantial.Thespeedincreasemightbemorenoticeable
fornon-partitioned tablesthanforpartitioned tables.
Type:Boolean; recognizedvaluesare1and0,ortrueandfalse;anyothervalueinterpretedasfalse
Default:true(shownas1inoutputofSETstatement)
Addedin:CDH5.8.0/Impala2.6.0
Relatedinformation:
UsingImpalawiththeAmazonS3Filesystemonpage692
SCAN_BYTES_LIMITQueryOption(CDH6.1orhigheronly)
TheSCAN_BYTES_LIMIT queryoptionsetsalimitonthebytesscannedbyHDFSandHBaseSCANoperations.Ifa
queryisstillexecutingwhenthequeryâscoordinatordetectsthatithasexceededthelimit,thequeryisterminated
withanerror.Theoptionisintendedtopreventrunawayqueriesthatscanmoredatathanisintended.
Forexample,anImpalaadministratorcouldsetadefaultvalueofSCAN_BYTES_LIMIT=100GB foraresourcepoolto
automaticallykillqueriesthatscanmorethan100GBofdata(seeImpalaAdmission ControlandQueryQueuingfor
informationaboutdefaultqueryoptions).Ifauseraccidentallyomitsapartition filterinaWHEREclauseandrunsa
largequerythatscansalotofdata,thequerywillbeautomaticallyterminatedafteritscansmoredatathanthe
SCAN_BYTES_LIMIT .
Youcanoverridethedefaultvalueper-queryorper-session, inthesamewayasotherqueryoptions,ifyoudonot
wantthedefaultSCAN_BYTES_LIMIT valuetoapplytoaspecificqueryorsession.
Note:
â¢Onlydataactuallyreadfromtheunderlying storagelayeriscountedtowardsthelimit.E.g.Impalaâs
Parquetscanneremploysseveraltechniques toskipoverdatainafilethatisnotrelevanttoa
specificquery,sooftenonlyafractionofthefilesizeiscountedtowardsSCAN_BYTES_LIMIT .
â¢AsofImpala3.1,bytesscannedbyKudutabletserversarenotcountedtowardsthelimit.
Becausethechecksaredoneperiodically,thequerymayscanoverthelimitattimes.
Syntax:SET SCAN_BYTES_LIMIT=bytes;
Type:numeric
Units:
â¢Anumericargumentrepresentsmemorysizeinbytes.
â¢Specifyasuffixofmormbformegabytes.
ApacheImpalaGuide|359ImpalaSQLLanguageReference
â¢Specifyasuffixofgorgbforgigabytes.
â¢Ifyouspecifyasuffixwithunrecognizedformats,subsequentqueriesfailwithanerror.
Default:0(nolimit)
Addedin:CDH6.1
SCHEDULE_RANDOM_REPLICA QueryOption(CDH5.7orhigheronly)
TheSCHEDULE_RANDOM_REPLICA queryoptionfine-tunes thescheduling algorithmfordecidingwhichhostprocesses
eachHDFSdatablockorKudutablettoreducethechanceofCPUhotspots.
Bydefault,Impalaestimateshowmuchworkeachhosthasdoneforthequery,andselectsthehostthathasthelowest
workload.ThisalgorithmisintendedtoreduceCPUhotspotsarisingwhenthesamehostisselectedtoprocessmultiple
datablocks/tablets.UsetheSCHEDULE_RANDOM_REPLICA queryoptionifhotspots stillariseforsomecombinations
ofqueriesanddatalayout.
TheSCHEDULE_RANDOM_REPLICA queryoptiononlyappliestotablesandpartitions thatarenotenabledfortheHDFS
caching.
Type:Boolean; recognizedvaluesare1and0,ortrueandfalse;anyothervalueinterpretedasfalse
Default:false
Addedin:CDH5.7.0/Impala2.5.0
Relatedinformation:
UsingHDFSCachingwithImpala(CDH5.3orhigheronly)onpage593,AvoidingCPUHotspots forHDFSCachedData
onpage612,REPLICA_PREFERENCE QueryOption(CDH5.9orhigheronly)onpage355
SCRATCH_LIMIT QueryOption
Specifies themaximumamountofdiskstorage,inbytes,thatanyImpalaquerycanconsumeonanyhostusingthe
âspilltodiskâmechanism thathandlesqueriesthatexceedthememorylimit.
Syntax:
Specifythesizeinbytes,orwithatrailingmorgcharactertoindicatemegabytesorgigabytes.Forexample:
-- 128 megabytes.
set SCRATCH_LIMIT=134217728
-- 512 megabytes.
set SCRATCH_LIMIT=512m;
-- 1 gigabyte.
set SCRATCH_LIMIT=1g;
Usagenotes:
Avalueofzeroturnsoffthespilltodiskfeatureforqueriesinthecurrentsession,causingthemtofailimmediatelyif
theyexceedthememorylimit.
TheamountofmemoryusedperhostforaqueryislimitedbytheMEM_LIMIT queryoption.
ThemoreDataNodesinthecluster,thelessmemoryisusedoneachhost,andthereforealsolessscratchspaceis
requiredforqueriesthatexceedthememorylimit.
Type:numeric, withoptionalunitspecifier
Default:-1(amountofspillspaceisunlimited)
Relatedinformation:
SQLOperationsthatSpilltoDiskonpage607,MEM_LIMIT QueryOptiononpage343
360|ApacheImpalaGuideImpalaSQLLanguageReference
SHUFFLE_DIS TINCT_EXPRSQueryOption
TheSHUFFLE_DISTINCT_EXPRS queryoptioncontrolstheshufflingbehaviorwhenaqueryhasbothgroupingand
distinctexpressions.Impalacanoptionallyincludethedistinctexpressionsinthehashexchangetospreadthedata
amongmorenodes.However,thisplanrequiresonemorehashexchangephase.
Itisrecommended thatyouturnoffthisoptioniftheNDVsofthegroupingexpressionsarehigh.
Type:Boolean; recognizedvaluesare1and0,ortrueandfalse;anyothervalueinterpretedasfalse
Default:false
SUPPORT_START_OVERQueryOption
Leavethissettingatitsdefaultvalue.Itisaread-only setting,testedbysomeclientapplicationssuchasHue.
Ifyouaccidentallychangeitthroughimpala-shell ,subsequentqueriesencountererrorsuntilyouundothechange
byissuingUNSET support_start_over .
Type:Boolean; recognizedvaluesare1and0,ortrueandfalse;anyothervalueinterpretedasfalse
Default:false
SYNC_DDL QueryOption
Whenenabled,causesanyDDLoperationsuchasCREATE TABLE orALTER TABLE toreturnonlywhenthechanges
havebeenpropagatedtoallotherImpalanodesintheclusterbytheImpalacatalogservice.Thatway,ifyouissuea
subsequentCONNECT statementinimpala-shell toconnecttoadifferentnodeinthecluster,youcanbesurethat
othernodewillalreadyrecognizeanyaddedorchangedtables.(ThecatalogserviceautomaticallybroadcaststheDDL
changestoallnodesautomatically,butwithoutthisoptiontherecouldbeaperiodofinconsistencyifyouquickly
switchedtoanothernode,suchasbyissuingasubsequentquerythroughaload-balancing proxy.)
AlthoughINSERTisclassified asaDMLstatement,whentheSYNC_DDL optionisenabled,INSERTstatementsalso
delaytheircompletionuntilalltheunderlying dataandmetadatachangesarepropagatedtoallImpalanodes.Internally,
Impalainsertshavesimilarities withDDLstatementsintraditional databasesystems,becausetheycreatemetadata
neededtotrackHDFSblocklocationsfornewfilesandtheypotentiallyaddnewpartitions topartitioned tables.
Note:Becausethisoptioncanintroduceadelayaftereachwriteoperation,ifyouarerunninga
sequence ofCREATE DATABASE ,CREATE TABLE ,ALTER TABLE ,INSERT,andsimilarstatements
withinasetupscript,tominimizetheoveralldelayyoucanenabletheSYNC_DDL queryoptiononly
neartheend,beforethefinalDDLstatement.
Type:Boolean; recognizedvaluesare1and0,ortrueandfalse;anyothervalueinterpretedasfalse
Default:false(shownas0inoutputofSETstatement)
Relatedinformation:
DDLStatementsonpage203
THREAD_RESERVATION_AGGREGATE_LIMIT QueryOption(CDH6.1orhigheronly)
TheTHREAD_RESERVATION_AGGREGATE_LIMIT queryoptionlimitsthenumberofreservedthreadsforaquery
acrossallnodesonwhichitisexecuting.Theoptionisintendedtopreventexecutionofcomplexqueriesthatcan
consumeexcessiveCPUoroperatingsystemresourcesonacluster.Queriesthathavemorethreadsthanthisthreshold
arerejectedbyImpalaâsadmission controllerbeforetheystartexecuting.
Forexample,anImpalaadministratorcouldsetadefaultvalueofTHREAD_RESERVATION_AGGREGATE_LIMIT=2000
foraresourcepoolona100nodewheretheyexpectonlyrelativelysimplequerieswithlessthan20threadspernode
torun.Thiswillrejectqueriesthatrequiremorethan2000reservedthreadsacrossallnodes,forexampleaquerywith
21fragmentsrunningonall100nodesofthecluster.
Youcanoverridethedefaultvalueper-queryorper-session, inthesamewayasotherqueryoptions,ifyoudonot
wantthedefaultTHREAD_RESERVATION_AGGREGATE_LIMIT valuetoapplytoaspecificqueryorsession.
Syntax:SET THREAD_RESERVATION_AGGREGATE_LIMIT=number;
ApacheImpalaGuide|361ImpalaSQLLanguageReference
Type:numeric
Default:0(nolimit)
Addedin:CDH6.1
THREAD_RESERVATION_LIMIT QueryOption(CDH6.1orhigheronly)
TheTHREAD_RESERVATION_LIMIT queryoptionlimitsthenumberofreservedthreadsforaqueryoneachnode.
TheoptionisintendedtopreventexecutionofcomplexqueriesthatcanconsumeexcessiveCPUoroperatingsystem
resourcesonasinglenode.QueriesthathavemorethreadspernodethanthisthresholdarerejectedbyImpalaâs
admission controllerbeforetheystartexecuting.Youcanseethenumberofreservedthreadsforaqueryinitsexplain
planintheâPer-HostResourceReservation"line.
Forexample,anImpalaadministratorcouldsetadefaultvalueofTHREAD_RESERVATION_LIMIT=100 foraresource
poolwheretheyexpectonlyrelativelysimplequeriestorun.Thiswillrejectqueriesthatrequiremorethan100reserved
threadsonanode,forexample,querieswithmorethan100fragments.
Youcanoverridethedefaultvalueper-queryorper-session, inthesamewayasotherqueryoptions,ifyoudonot
wantthedefaultTHREAD_RESERVATION_LIMIT valuetoapplytoaspecificqueryorsession.
Note:Thenumberofreservedthreadsonanodemaybelowerthanthemaximumvalueinthe
explainplanifnotallfragmentsofthatqueryarescheduled oneverynode.
Syntax:SET THREAD_RESERVATION_LIMIT=number;
Type:numeric
Default:3000
Addedin:CDH6.1
TIMEZONEQueryOption(CDH6.1/Impala3.1orhigheronly)
TheTIMEZONE queryoptiondefinesthetimezoneusedforconversionsbetweenUTCandthelocaltime.Ifnotset,
ImpalausesthesystemtimezonewheretheCoordinatorImpaladruns.AsqueryoptionsarenotsenttotheCoordinator
immediately,thetimezonesarevalidatedonlywhenthequeryruns.
Impalatakesthetimezoneintoaconsiderationinthefollowingcases:
â¢WhencallingtheNOW()function
â¢WhenconvertingbetweenUnixtimeandtimestampiftheuse_local_tz_for_unix_timestamp_conversions
flagisTRUE
â¢WhenreadingParquettimestampswrittenbyHiveiftheconvert_legacy_hive_parquet_utc_timestamps
flagisTRUE
Syntax:
SET TIMEZONE= time zone
timezonecanbeacanonicalcodeoratimezonenamedefinedinIANATimeZoneDatabase.Thevalueiscase-sensitiv e.
Leading/trailingquotes(')anddoublequotes(")arestripped.
Iftimezoneisanemptystring,thetimezoneforthequeryissettothedefaulttimezoneoftheImpaladCoordinator.
IftimezoneisNULLoraspacecharacter,Impalareturnsanerrorwhenthequeryisexecuted.
Type:String
Default:ThesystemtimezonewheretheCoordinatorImpaladruns
362|ApacheImpalaGuideImpalaSQLLanguageReference
Examples:
SET TIMEZONE=UTC;
SET TIMEZONE="Europe/Budapest";
Addedin:CDH6.1
TOPN_BYTES_LIMITQueryOption(CDH6.1/Impala3.1orhigheronly)
TheTOPN_BYTES_LIMIT queryoptionplacesalimitontheamountofestimatedmemorythatImpalacanprocessfor
top-Nqueries.
Top-NqueriesarethequeriesthatincludebothORDER BY andLIMITclauses.Top-Nqueriesdon'tspilltodisksohave
tokeepallrowstheyprocessinmemory,andthosequeriescancauseout-of-memor yissueswhenrunningwithalarge
limitandanoffset.IftheImpalaplannerestimatesthatatop-Noperatorwillprocessmorebytesthanthe
TOPN_BYTES_LIMIT value,itwillreplacethetop-Noperatorwiththesortoperator.Switchingtothesortoperator
allowsImpalatospilltodisk,thusrequiringlessmemorythantop-N,butpotentiallywithperformance penalties.
Theoptionhasnoeffectwhensetto0or-1.
Syntax:
SET TOPN_BYTES_LIMIT= limit
Type:Number
Default:536870912 (512MB)
Addedin:CDH6.1
SHOWStatement
TheSHOWstatementisaflexiblewaytogetinformationaboutdifferenttypesofImpalaobjects.
Syntax:
SHOW DATABASES [[LIKE] ' pattern']
SHOW SCHEMAS [[LIKE] ' pattern'] - an alias for SHOW DATABASES
SHOW TABLES [IN database_name ] [[LIKE] ' pattern']
SHOW [AGGREGATE | ANALYTIC] FUNCTIONS [IN database_name ] [[LIKE] ' pattern']
SHOW CREATE TABLE [ database_name ].table_name
SHOW CREATE VIEW [ database_name ].view_name
SHOW TABLE STATS [ database_name .]table_name
SHOW COLUMN STATS [ database_name .]table_name
SHOW [RANGE] PARTITIONS [ database_name .]table_name
SHOW FILES IN [ database_name .]table_name [PARTITION ( key_col_expression  [, 
key_col_expression ]]
SHOW ROLES
SHOW CURRENT ROLES
SHOW ROLE GRANT GROUP group_name
SHOW GRANT ROLE role_name
SHOW GRANT USER user_name
SHOW GRANT USER user_name  ON SERVER
SHOW GRANT USER user_name  ON DATABASE database_name
SHOW GRANT USER user_name  ON TABLE table_name
SHOW GRANT USER user_name  ON URI uri
IssueaSHOW object_type statementtoseetheappropriateobjectsinthecurrentdatabase,orSHOW object_type
IN database_name toseeobjectsinaspecificdatabase.
ApacheImpalaGuide|363ImpalaSQLLanguageReference
Theoptionalpatternargumentisaquotedstringliteral,usingUnix-style*wildcardsandallowing|foralternation.
TheprecedingLIKEkeywordisalsooptional.Allobjectnamesarestoredinlowercase,sousealllowercaselettersin
thepatternstring.Forexample:
show databases 'a*';
show databases like 'a*';
show tables in some_db like '*fact*';
use some_db;
show tables '*dim*|*fact*';
Cancellation:Cannotbecancelled.
SHOWFILESStatement
TheSHOW FILES statementdisplaysthefilesthatconstituteaspecified table,orapartitionwithinapartitioned table.
ThissyntaxisavailableinCDH5.4/Impala2.2andhigheronly.Theoutputincludesthenamesofthefiles,thesizeof
eachfile,andtheapplicablepartitionforapartitioned table.ThesizeincludesasuffixofBforbytes,MBformegabytes,
andGBforgigabytes.
InCDH5.10/Impala2.8andhigher,youcanusegeneralexpressionswithoperatorssuchas<,IN,LIKE,andBETWEEN
inthePARTITION clause,insteadofonlyequalityoperators.Forexample:
show files in sample_table partition (j < 5);
show files in sample_table partition (k = 3, l between 1 and 10);
show files in sample_table partition (month like 'J%');
Note:Thisstatementappliestotablesandpartitions storedonHDFS,orintheAmazonSimpleStorage
System(S3).Itdoesnotapplytoviews.ItdoesnotapplytotablesmappedontoHBaseorKudu,
becausethosedatamanagementsystemsdonotusethesamefile-based storagelayout.
Usagenotes:
YoucanusethisstatementtoverifytheresultsofyourETLprocess:thatis,thattheexpectedfilesarepresent,with
theexpectedsizes.Youcanexaminethefileinformationtodetectconditions suchasemptyfiles,missingfiles,or
inefficientlayoutsduetoalargenumberofsmallfiles.WhenyouuseINSERTstatementstocopyfromonetableto
another,youcanseehowthefilelayoutchangesduetofileformatconversions,compaction ofsmallinputfilesinto
largedatablocks,andmultipleoutputfilesfromparallelqueriesandpartitioned inserts.
TheoutputfromthisstatementdoesnotincludefilesthatImpalaconsiderstobehiddenorinvisible,suchasthose
whosenamesstartwithadotoranunderscore,orthatendwiththesuffixes.copying or.tmp.
Theinformationforpartitioned tablescomplemen tstheoutputoftheSHOW PARTITIONS statement,whichsummariz es
informationabouteachpartition.SHOW PARTITIONS producessomeoutputforeachpartition, whileSHOW FILES
doesnotproduceanyoutputforemptypartitions becausetheydonotincludeanydatafiles.
HDFSpermissions:
TheuserIDthattheimpalad daemonrunsunder,typicallytheimpalauser,musthavereadpermission forallthe
tablefiles,readandexecutepermission forallthedirectoriesthatmakeupthetable,andexecutepermission forthe
databasedirectoryandallitsparentdirectories.
Examples:
ThefollowingexampleshowsaSHOW FILES statementforanunpartitioned tableusingtextformat:
[localhost:21000] > create table unpart_text (x bigint, s string);
[localhost:21000] > insert into unpart_text (x, s) select id, name
                  > from oreilly.sample_data limit 20e6;
[localhost:21000] > show files in unpart_text;
+---------------------------------------------------------------------+----------+-----------+
| path                                                                | size     | partition |
+---------------------------------------------------------------------+----------+-----------+
| hdfs:// impala_data_dir /d.db/unpart_text/35665776ef85cfaf_1012432410_data.0. | 448.31MB |           |
+---------------------------------------------------------------------+----------+-----------+
[localhost:21000] > insert into unpart_text (x, s) select id, name from oreilly.sample_data limit 100e6;
364|ApacheImpalaGuideImpalaSQLLanguageReference
[localhost:21000] > show files in unpart_text;
+-----------------------------------------------------------------------------+----------+-----------+
| path                                                                        | size     | partition |
+-----------------------------------------------------------------------------+----------+-----------+
| hdfs:// impala_data_dir /d.db/unpart_text/35665776ef85cfaf_1012432410_data.0. | 448.31MB |           |
| hdfs:// impala_data_dir /d.db/unpart_text/ac3dba252a8952b8_1663177415_data.0. | 2.19GB   |           |
+-----------------------------------------------------------------------------+----------+-----------+
Thisexampleillustrateshow,afterissuingsomeINSERT ... VALUES statements,thetablenowcontainssometiny
filesofjustafewbytes.Suchsmallfilescouldcauseinefficientprocessingofparallelqueriesthatareexpecting
multi-meg abyteinputfiles.TheexampleshowshowyoumightcompactthesmallfilesbydoinganINSERT ...
SELECTintoadifferenttable,possiblyconvertingthedatatoParquetintheprocess:
[localhost:21000] > insert into unpart_text values (10,'hello'), (20, 'world');
[localhost:21000] > insert into unpart_text values (-1,'foo'), (-1000, 'bar');
[localhost:21000] > show files in unpart_text;
+-----------------------------------------------------------------------------+----------+
| path                                                                        | size     |
+-----------------------------------------------------------------------------+----------+
| hdfs:// impala_data_dir /d.db/unpart_text/4f11b8bdf8b6aa92_238145083_data.0.  | 18B
| hdfs:// impala_data_dir /d.db/unpart_text/35665776ef85cfaf_1012432410_data.0. | 448.31MB
| hdfs:// impala_data_dir /d.db/unpart_text/ac3dba252a8952b8_1663177415_data.0. | 2.19GB
| hdfs:// impala_data_dir /d.db/unpart_text/cfb8252452445682_1868457216_data.0. | 17B
+-----------------------------------------------------------------------------+----------+
[localhost:21000] > create table unpart_parq stored as parquet as select * from unpart_text;
+---------------------------+
| summary                   |
+---------------------------+
| Inserted 120000002 row(s) |
+---------------------------+
[localhost:21000] > show files in unpart_parq;
+---------------------------------------------------------------------------------+----------+
| path                                                                            | size     |
+---------------------------------------------------------------------------------+----------+
| hdfs:// impala_data_dir /d.db/unpart_parq/60798d96ba630184_549959007_data.0.parq  | 255.36MB |
| hdfs:// impala_data_dir /d.db/unpart_parq/60798d96ba630184_549959007_data.1.parq  | 178.52MB |
| hdfs:// impala_data_dir /d.db/unpart_parq/60798d96ba630185_549959007_data.0.parq  | 255.37MB |
| hdfs:// impala_data_dir /d.db/unpart_parq/60798d96ba630185_549959007_data.1.parq  | 57.71MB  |
| hdfs:// impala_data_dir /d.db/unpart_parq/60798d96ba630186_2141167244_data.0.parq | 255.40MB |
| hdfs:// impala_data_dir /d.db/unpart_parq/60798d96ba630186_2141167244_data.1.parq | 175.52MB |
| hdfs:// impala_data_dir /d.db/unpart_parq/60798d96ba630187_1006832086_data.0.parq | 255.40MB |
| hdfs:// impala_data_dir /d.db/unpart_parq/60798d96ba630187_1006832086_data.1.parq | 214.61MB |
+---------------------------------------------------------------------------------+----------+
ThefollowingexampleshowsaSHOW FILES statementforapartitioned texttablewithdataintwodifferentpartitions,
andtwoemptypartitions. Thepartitions withnodataarenotrepresentedintheSHOW FILES output.
[localhost:21000] > create table part_text (x bigint, y int, s string)
                                        > partitioned by (year bigint, month bigint, day bigint);
[localhost:21000] > insert overwrite part_text (x, y, s) partition (year=2014,month=1,day=1)
                  > select id, val, name from oreilly.normalized_parquet
where id between 1 and 1000000;
[localhost:21000] > insert overwrite part_text (x, y, s) partition (year=2014,month=1,day=2)
                  > select id, val, name from oreilly.normalized_parquet
                  > where id between 1000001 and 2000000;
[localhost:21000] > alter table part_text add partition (year=2014,month=1,day=3);
[localhost:21000] > alter table part_text add partition (year=2014,month=1,day=4);
[localhost:21000] > show partitions part_text;
+-------+-------+-----+-------+--------+---------+--------------+-------------------+--------+-------------------+
| year  | month | day | #Rows | #Files | Size    | Bytes Cached | Cache Replication | Format | Incremental stats |
+-------+-------+-----+-------+--------+---------+--------------+-------------------+--------+-------------------+
| 2014  | 1     | 1   | -1    | 4      | 25.16MB | NOT CACHED   | NOT CACHED        | TEXT   | false             |
| 2014  | 1     | 2   | -1    | 4      | 26.22MB | NOT CACHED   | NOT CACHED        | TEXT   | false             |
| 2014  | 1     | 3   | -1    | 0      | 0B      | NOT CACHED   | NOT CACHED        | TEXT   | false             |
| 2014  | 1     | 4   | -1    | 0      | 0B      | NOT CACHED   | NOT CACHED        | TEXT   | false             |
| Total |       |     | -1    | 8      | 51.38MB | 0B           |                   |        |                   |
+-------+-------+-----+-------+--------+---------+--------------+-------------------+--------+-------------------+
[localhost:21000] > show files in part_text;
+------------------------------------------------------------------------------------------------+--------+-------------------------+
| path                                                                                           | size   | partition            
   |
+------------------------------------------------------------------------------------------------+--------+-------------------------+
| hdfs:// impala_data_dir /d.db/part_text/year=2014/month=1/day=1/80732d9dc80689f_1418645991_data.0.  | 5.77MB | year=2014/month=1/day=1
 |
| hdfs:// impala_data_dir /d.db/part_text/year=2014/month=1/day=1/80732d9dc8068a0_1418645991_data.0.  | 6.25MB | year=2014/month=1/day=1
 |
| hdfs:// impala_data_dir /d.db/part_text/year=2014/month=1/day=1/80732d9dc8068a1_147082319_data.0.   | 7.16MB | year=2014/month=1/day=1
 |
| hdfs:// impala_data_dir /d.db/part_text/year=2014/month=1/day=1/80732d9dc8068a2_2111411753_data.0.  | 5.98MB | year=2014/month=1/day=1
 |
| hdfs:// impala_data_dir /d.db/part_text/year=2014/month=1/day=2/21a828cf494b5bbb_501271652_data.0.  | 6.42MB | year=2014/month=1/day=2
 |
| hdfs:// impala_data_dir /d.db/part_text/year=2014/month=1/day=2/21a828cf494b5bbc_501271652_data.0.  | 6.62MB | year=2014/month=1/day=2
 |
| hdfs:// impala_data_dir /d.db/part_text/year=2014/month=1/day=2/21a828cf494b5bbd_1393490200_data.0. | 6.98MB | year=2014/month=1/day=2
 |
| hdfs:// impala_data_dir /d.db/part_text/year=2014/month=1/day=2/21a828cf494b5bbe_1393490200_data.0. | 6.20MB | year=2014/month=1/day=2
 |
+------------------------------------------------------------------------------------------------+--------+-------------------------+
ThefollowingexampleshowsaSHOW FILES statementforapartitioned Parquettable.Thenumberandsizesoffiles
aredifferentfromtheequivalentpartitioned texttableusedinthepreviousexample,becauseINSERToperationsfor
ApacheImpalaGuide|365ImpalaSQLLanguageReference
Parquettablesareparallelizeddifferentlythanfortexttables.(Also,theamountofdataissosmallthatitcanbewritten
toParquetwithoutinvolvingallthehostsinthis4-nodecluster.)
[localhost:21000] > create table part_parq (x bigint, y int, s string)
                  > partitioned by (year bigint, month bigint, day bigint) stored as parquet;
[localhost:21000] > insert into part_parq partition (year,month,day) select x, y, s, year, month, day from partitioned_text;
[localhost:21000] > show partitions part_parq;
+-------+-------+-----+-------+--------+---------+--------------+-------------------+---------+-------------------+
| year  | month | day | #Rows | #Files | Size    | Bytes Cached | Cache Replication | Format  | Incremental stats |
+-------+-------+-----+-------+--------+---------+--------------+-------------------+---------+-------------------+
| 2014  | 1     | 1   | -1    | 3      | 17.89MB | NOT CACHED   | NOT CACHED        | PARQUET | false             |
| 2014  | 1     | 2   | -1    | 3      | 17.89MB | NOT CACHED   | NOT CACHED        | PARQUET | false             |
| Total |       |     | -1    | 6      | 35.79MB | 0B           |                   |         |                   |
+-------+-------+-----+-------+--------+---------+--------------+-------------------+---------+-------------------+
[localhost:21000] > show files in part_parq;
+--------------------------------------------------------------------------------------+--------+-------------------------+
| path                                                                                 | size   | partition               |
+--------------------------------------------------------------------------------------+--------+-------------------------+
| hdfs:// impala_data_dir /d.db/part_parq/year=2014/month=1/day=1/1134113650_data.0.parq | 4.49MB | year=2014/month=1/day=1 |
| hdfs:// impala_data_dir /d.db/part_parq/year=2014/month=1/day=1/617567880_data.0.parq  | 5.14MB | year=2014/month=1/day=1 |
| hdfs:// impala_data_dir /d.db/part_parq/year=2014/month=1/day=1/2099499416_data.0.parq | 8.27MB | year=2014/month=1/day=1 |
| hdfs:// impala_data_dir /d.db/part_parq/year=2014/month=1/day=2/945567189_data.0.parq  | 8.80MB | year=2014/month=1/day=2 |
| hdfs:// impala_data_dir /d.db/part_parq/year=2014/month=1/day=2/2145850112_data.0.parq | 4.80MB | year=2014/month=1/day=2 |
| hdfs:// impala_data_dir /d.db/part_parq/year=2014/month=1/day=2/665613448_data.0.parq  | 4.29MB | year=2014/month=1/day=2 |
+--------------------------------------------------------------------------------------+--------+-------------------------+
ThefollowingexampleshowsoutputfromtheSHOW FILES statementforatablewherethedatafilesarestoredin
AmazonS3:
[localhost:21000] > show files in s3_testing.sample_data_s3;
+-----------------------------------------------------------------------+---------+
| path                                                                  | size    |
+-----------------------------------------------------------------------+---------+
| s3a://impala-demo/sample_data/e065453cba1988a6_1733868553_data.0.parq | 24.84MB |
+-----------------------------------------------------------------------+---------+
SHOWROLESStatement
TheSHOW ROLES statementdisplaysroles.ThissyntaxisavailableinCDH5.2/Impala2.0andlateronly,whenyou
areusingtheSentryauthorizationframeworkalongwiththeSentryservice,asdescribed inUsingImpalawiththe
SentryService(CDH5.1orhigheronly)onpage91.
Securityconsiderations:
Whenauthorizationisenabled, theoutputoftheSHOWstatementonlyshowsthoseobjectsforwhichyouhavethe
privilegetoview.IfyoubelieveanobjectexistsbutyoucannotseeitintheSHOWoutput,checkwiththesystem
administratorifyouneedtobegrantedanewprivilegeforthatobject.SeeEnablingSentryAuthorizationforImpala
onpage87forhowtosetupauthorizationandaddprivilegesforspecificobjects.
Kuduconsiderations:
Examples:
Depending ontherolessetupwithinyourorganizationbytheCREATE ROLE statement,theoutputmightlook
somethinglikethis:
show roles;
+-----------+
| role_name |
+-----------+
| analyst   |
| role1     |
| sales     |
| superuser |
| test_role |
+-----------+
HDFSpermissions: ThisstatementdoesnottouchanyHDFSfilesordirectories,thereforenoHDFSpermissions are
required.
Relatedinformation:
EnablingSentryAuthorizationforImpalaonpage87
366|ApacheImpalaGuideImpalaSQLLanguageReference
SHOWCURRENT ROLES
TheSHOW CURRENT ROLES statementdisplaysrolesassignedtothecurrentuser.ThissyntaxisavailableinCDH5.2
/Impala2.0andlateronly,whenyouareusingtheSentryauthorizationframeworkalongwiththeSentryservice,as
described inUsingImpalawiththeSentryService(CDH5.1orhigheronly)onpage91.
Securityconsiderations:
Whenauthorizationisenabled, theoutputoftheSHOWstatementonlyshowsthoseobjectsforwhichyouhavethe
privilegetoview.IfyoubelieveanobjectexistsbutyoucannotseeitintheSHOWoutput,checkwiththesystem
administratorifyouneedtobegrantedanewprivilegeforthatobject.SeeEnablingSentryAuthorizationforImpala
onpage87forhowtosetupauthorizationandaddprivilegesforspecificobjects.
Kuduconsiderations:
Examples:
Depending ontherolessetupwithinyourorganizationbytheCREATE ROLE statement,theoutputmightlook
somethinglikethis:
show current roles;
+-----------+
| role_name |
+-----------+
| role1     |
| superuser |
+-----------+
HDFSpermissions: ThisstatementdoesnottouchanyHDFSfilesordirectories,thereforenoHDFSpermissions are
required.
Relatedinformation:
EnablingSentryAuthorizationforImpalaonpage87
SHOWROLEGRANTGROUPStatement
TheSHOW ROLE GRANT GROUP statementlistsalltherolesassignedtothespecified group.Thisstatementisonly
allowedforSentryadministrativeusersandothersusersthatarepartofthespecified group.Thissyntaxisavailable
inCDH5.2/Impala2.0andlateronly,whenyouareusingtheSentryauthorizationframeworkalongwiththeSentry
service,asdescribed inUsingImpalawiththeSentryService(CDH5.1orhigheronly)onpage91.
Securityconsiderations:
Whenauthorizationisenabled, theoutputoftheSHOWstatementonlyshowsthoseobjectsforwhichyouhavethe
privilegetoview.IfyoubelieveanobjectexistsbutyoucannotseeitintheSHOWoutput,checkwiththesystem
administratorifyouneedtobegrantedanewprivilegeforthatobject.SeeEnablingSentryAuthorizationforImpala
onpage87forhowtosetupauthorizationandaddprivilegesforspecificobjects.
HDFSpermissions: ThisstatementdoesnottouchanyHDFSfilesordirectories,thereforenoHDFSpermissions are
required.
Kuduconsiderations:
Relatedinformation:
EnablingSentryAuthorizationforImpalaonpage87
SHOWGRANTROLEStatement
TheSHOW GRANT ROLE statementlistallthegrantsforthegivenrolename.ThisstatementisonlyallowedforSentry
administrativeusersandotherusersthathavebeengrantedthespecified role.ThissyntaxisavailableinCDH5.2/
Impala2.0andlateronly,whenyouareusingtheSentryauthorizationframeworkalongwiththeSentryservice,as
described inUsingImpalawiththeSentryService(CDH5.1orhigheronly)onpage91.
Securityconsiderations:
ApacheImpalaGuide|367ImpalaSQLLanguageReference
Whenauthorizationisenabled, theoutputoftheSHOWstatementonlyshowsthoseobjectsforwhichyouhavethe
privilegetoview.IfyoubelieveanobjectexistsbutyoucannotseeitintheSHOWoutput,checkwiththesystem
administratorifyouneedtobegrantedanewprivilegeforthatobject.SeeEnablingSentryAuthorizationforImpala
onpage87forhowtosetupauthorizationandaddprivilegesforspecificobjects.
HDFSpermissions: ThisstatementdoesnottouchanyHDFSfilesordirectories,thereforenoHDFSpermissions are
required.
Kuduconsiderations:
Relatedinformation:
EnablingSentryAuthorizationforImpalaonpage87
SHOWGRANTUSERStatement
TheSHOW GRANT USER statementshowsthelistofprivilegesforagivenuser.ThisstatementisonlyallowedforSentry
administrativeusers.However,thecurrentusercanrunSHOW GRANT USER forthemselves.
ThissyntaxisavailableinCDH6.1/Impala3.1andlateronly,whenyouareusingtheSentryauthorizationframework
alongwiththeSentryservice,asdescribed inUsingImpalawiththeSentryService(CDH5.1orhigheronly)onpage
91.
Securityconsiderations:
Whenauthorizationisenabled, theoutputoftheSHOWstatementonlyshowsthoseobjectsforwhichyouhavethe
privilegetoview.IfyoubelieveanobjectexistsbutyoucannotseeitintheSHOWoutput,checkwiththesystem
administratorifyouneedtobegrantedanewprivilegeforthatobject.SeeEnablingSentryAuthorizationforImpala
onpage87forhowtosetupauthorizationandaddprivilegesforspecificobjects.
HDFSpermissions: ThisstatementdoesnottouchanyHDFSfilesordirectories,thereforenoHDFSpermissions are
required.
Relatedinformation:
EnablingSentryAuthorizationforImpalaonpage87
SHOWDATABASES
TheSHOW DATABASES statementisoftenthefirstoneyouissuewhenconnecting toaninstanceforthefirsttime.
YoutypicallyissueSHOW DATABASES toseethenamesyoucanspecifyinaUSE db_name statement,thenafter
switchingtoadatabaseyouissueSHOW TABLES toseethenamesyoucanspecifyinSELECTandINSERTstatements.
InCDH5.7/Impala2.5andhigher,theoutputincludesasecondcolumnshowinganyassociatedcommentforeach
database.
TheoutputofSHOW DATABASES includesthespecial_impala_builtins database,whichletsyouviewdefinitions
ofbuilt-infunctions, asdescribed underSHOW FUNCTIONS .
Securityconsiderations:
Whenauthorizationisenabled, theoutputoftheSHOWstatementonlyshowsthoseobjectsforwhichyouhavethe
privilegetoview.IfyoubelieveanobjectexistsbutyoucannotseeitintheSHOWoutput,checkwiththesystem
administratorifyouneedtobegrantedanewprivilegeforthatobject.SeeEnablingSentryAuthorizationforImpala
onpage87forhowtosetupauthorizationandaddprivilegesforspecificobjects.
Examples:
Thisexampleshowshowyoumightlocateaparticular tableonanunfamiliarsystem.TheDEFAULT databaseisthe
oneyouinitiallyconnectto;adatabasewiththatnameispresentoneverysystem.YoucanissueSHOW TABLES IN
db_name withoutgoingintoadatabase,orSHOW TABLES onceyouareinsideaparticular database.
[localhost:21000] > show databases;
+------------------+----------------------------------------------+
| name             | comment                                      |
+------------------+----------------------------------------------+
368|ApacheImpalaGuideImpalaSQLLanguageReference
| _impala_builtins | System database for Impala builtin functions |
| default          | Default Hive database                        |
| file_formats     |                                              |
+------------------+----------------------------------------------+
Returned 3 row(s) in 0.02s
[localhost:21000] > show tables in file_formats;
+--------------------+
| name               |
+--------------------+
| parquet_table      |
| rcfile_table       |
| sequencefile_table |
| textfile_table     |
+--------------------+
Returned 4 row(s) in 0.01s
[localhost:21000] > use file_formats;
[localhost:21000] > show tables like '*parq*';
+--------------------+
| name               |
+--------------------+
| parquet_table      |
+--------------------+
Returned 1 row(s) in 0.01s
HDFSpermissions: ThisstatementdoesnottouchanyHDFSfilesordirectories,thereforenoHDFSpermissions are
required.
Relatedinformation:
OverviewofImpalaDatabasesonpage193,CREATEDATABASEStatementonpage226,DROPDATABASEStatementon
page262,USEStatementonpage385SHOWTABLESStatementonpage369,SHOWFUNCTIONSStatementonpage379
SHOWTABLESStatement
Displaysthenamesoftables.Bydefault,liststablesinthecurrentdatabase,orwiththeINclause,inaspecified
database.Bydefault,listsalltables,orwiththeLIKEclause,onlythosewhosenamematchapatternwith*wildcards.
Securityconsiderations:
Whenauthorizationisenabled, theoutputoftheSHOWstatementonlyshowsthoseobjectsforwhichyouhavethe
privilegetoview.IfyoubelieveanobjectexistsbutyoucannotseeitintheSHOWoutput,checkwiththesystem
administratorifyouneedtobegrantedanewprivilegeforthatobject.SeeEnablingSentryAuthorizationforImpala
onpage87forhowtosetupauthorizationandaddprivilegesforspecificobjects.
TheuserIDthattheimpalad daemonrunsunder,typicallytheimpalauser,musthavereadandexecutepermissions
foralldirectoriesthatarepartofthetable.(AtablecouldspanmultipledifferentHDFSdirectoriesifitispartitioned.
Thedirectoriescouldbewidelyscatteredbecauseapartition canresideinanarbitraryHDFSdirectorybasedonits
LOCATION attribute.)
Examples:
ThefollowingexamplesdemonstratetheSHOW TABLES statement.Ifthedatabasecontainsnotables,theresultset
isempty.Ifthedatabasedoescontaintables,SHOW TABLES IN db_name listsallthetablenames.SHOW TABLES
withnoqualifierslistsallthetablenamesinthecurrentdatabase.
create database empty_db;
show tables in empty_db;
Fetched 0 row(s) in 0.11s
create database full_db;
create table full_db.t1 (x int);
create table full_db.t2 like full_db.t1;
show tables in full_db;
+------+
| name |
+------+
| t1   |
ApacheImpalaGuide|369ImpalaSQLLanguageReference
| t2   |
+------+
use full_db;
show tables;
+------+
| name |
+------+
| t1   |
| t2   |
+------+
ThisexampledemonstrateshowSHOW TABLES LIKE ' wildcard_pattern 'liststablenamesthatmatchapattern,
ormultiplealternativepatterns.Theabilitytodowildcardmatchesfortablenamesmakesithelpfultoestablishnaming
conventionsfortablestoconvenientlylocateagroupofrelatedtables.
create table fact_tbl (x int);
create table dim_tbl_1 (s string);
create table dim_tbl_2 (s string);
/* Asterisk is the wildcard character. Only 2 out of the 3 just-created tables are 
returned. */
show tables like 'dim*';
+-----------+
| name      |
+-----------+
| dim_tbl_1 |
| dim_tbl_2 |
+-----------+
/* We are already in the FULL_DB database, but just to be sure we can specify the database
 name also. */
show tables in full_db like 'dim*';
+-----------+
| name      |
+-----------+
| dim_tbl_1 |
| dim_tbl_2 |
+-----------+
/* The pipe character separates multiple wildcard patterns. */
show tables like '*dim*|t*';
+-----------+
| name      |
+-----------+
| dim_tbl_1 |
| dim_tbl_2 |
| t1        |
| t2        |
+-----------+
HDFSpermissions: ThisstatementdoesnottouchanyHDFSfilesordirectories,thereforenoHDFSpermissions are
required.
Relatedinformation:
OverviewofImpalaTablesonpage196,CREATETABLEStatementonpage234,ALTERTABLEStatementonpage205,
DROPTABLEStatementonpage268,DESCRIBEStatementonpage251,SHOWCREATETABLEStatementonpage370,
SHOWTABLESTATSStatementonpage373,SHOWDATABASESonpage368,SHOWFUNCTIONSStatementonpage
379
SHOWCREATETABLEStatement
Asaschemachangesovertime,youmightrunaCREATE TABLE statementfollowedbyseveralALTER TABLE
statements.Tocapturethecumulativeeffectofallthosestatements,SHOW CREATE TABLE displaysaCREATE TABLE
statementthatwouldreproducethecurrentstructureofatable.Youcanusethisoutputinscriptsthatsetuporclone
agroupoftables,ratherthantryingtoreproducetheoriginalsequence ofCREATE TABLE andALTER TABLE
statements.Whencreatingvariationsontheoriginaltable,orcloningtheoriginaltableonadifferentsystem,you
370|ApacheImpalaGuideImpalaSQLLanguageReference
mightneedtoedittheSHOW CREATE TABLE outputtochangethingssuchasthedatabasename,LOCATION field,
andsoonthatmightbedifferentonthedestinationsystem.
IfyouspecifyaviewnameintheSHOW CREATE TABLE ,itreturnsaCREATE VIEW statementwithcolumnnamesand
theoriginalSQLstatementtoreproducetheview.YouneedtheVIEW_METADATA privilegeontheviewandSELECT
privilegeonallunderlying viewsandtablestosuccessfullyruntheSHOW CREATE VIEW statementforaview.The
SHOW CREATE VIEW isavailableasanaliasforSHOW CREATE TABLE .
Securityconsiderations:
Whenauthorizationisenabled, theoutputoftheSHOWstatementonlyshowsthoseobjectsforwhichyouhavethe
privilegetoview.IfyoubelieveanobjectexistsbutyoucannotseeitintheSHOWoutput,checkwiththesystem
administratorifyouneedtobegrantedanewprivilegeforthatobject.SeeEnablingSentryAuthorizationforImpala
onpage87forhowtosetupauthorizationandaddprivilegesforspecificobjects.
HDFSpermissions: ThisstatementdoesnottouchanyHDFSfilesordirectories,thereforenoHDFSpermissions are
required.
Kuduconsiderations:
ForKudutables:
â¢ThecolumnspecificationsincludeattributessuchasNULL,NOT NULL ,ENCODING ,andCOMPRESSION .Ifyoudo
notspecifythoseattributesintheoriginalCREATE TABLE statement,theSHOW CREATE TABLE outputdisplays
thedefaultsthatwereused.
â¢ThespecificationsofanyRANGEclausesarenotdisplayedinfull.Toseethedefinitionoftherangeclausesfora
Kudutable,usetheSHOW RANGE PARTITIONS statement.
â¢TheTBLPROPERTIES outputreflectstheKudumasteraddressandtheinternalKudunameassociatedwiththe
Impalatable.
show CREATE TABLE numeric_grades_default_letter;
+------------------------------------------------------------------------------------------------+
| result                                                                              
           |
+------------------------------------------------------------------------------------------------+
| CREATE TABLE user.numeric_grades_default_letter (                                   
           |
|   score TINYINT NOT NULL ENCODING AUTO_ENCODING COMPRESSION DEFAULT_COMPRESSION,    
           |
|   letter_grade STRING NULL ENCODING AUTO_ENCODING COMPRESSION DEFAULT_COMPRESSION 
DEFAULT '-', |
|   student STRING NULL ENCODING AUTO_ENCODING COMPRESSION DEFAULT_COMPRESSION,       
           |
|   PRIMARY KEY (score)                                                               
           |
| )                                                                                   
           |
| PARTITION BY RANGE (score) (...)
      |
| STORED AS KUDU                                                                      
           |
| TBLPROPERTIES ('kudu.master_addresses'='vd0342.example.com:7051')                   
           |
+------------------------------------------------------------------------------------------------+
show range partitions numeric_grades_default_letter;
+--------------------+
| RANGE (score)      |
+--------------------+
| 0 <= VALUES < 50   |
| 50 <= VALUES < 65  |
| 65 <= VALUES < 80  |
| 80 <= VALUES < 100 |
+--------------------+
ApacheImpalaGuide|371ImpalaSQLLanguageReference
Examples:
ThefollowingexampleshowshowvariousclausesfromtheCREATE TABLE statementarerepresentedintheoutput
ofSHOW CREATE TABLE .
create table show_create_table_demo (id int comment "Unique ID", y double, s string)
  partitioned by (year smallint)
  stored as parquet;
show create table show_create_table_demo;
+----------------------------------------------------------------------------------------+
| result                                                                              
   |
+----------------------------------------------------------------------------------------+
| CREATE TABLE scratch.show_create_table_demo (                                       
   |
|   id INT COMMENT 'Unique ID',                                                       
   |
|   y DOUBLE,                                                                         
   |
|   s STRING                                                                          
   |
| )                                                                                   
   |
| PARTITIONED BY (                                                                    
   |
|   year SMALLINT                                                                     
   |
| )                                                                                   
   |
| STORED AS PARQUET                                                                   
   |
| LOCATION 'hdfs://127.0.0.1:8020/user/hive/warehouse/scratch.db/show_create_table_demo'
 |
| TBLPROPERTIES ('transient_lastDdlTime'='1418152582')                                
   |
+----------------------------------------------------------------------------------------+
Thefollowingexampleshowshow,afterasequence ofALTER TABLE statements,theoutputfromSHOW CREATE
TABLErepresentsthecurrentstateofthetable.Thisoutputcouldbeusedtocreateamatchingtableratherthan
executingtheoriginalCREATE TABLE andsequence ofALTER TABLE statements.
alter table show_create_table_demo drop column s;
alter table show_create_table_demo set fileformat textfile;
show create table show_create_table_demo;
+----------------------------------------------------------------------------------------+
| result                                                                              
   |
+----------------------------------------------------------------------------------------+
| CREATE TABLE scratch.show_create_table_demo (                                       
   |
|   id INT COMMENT 'Unique ID',                                                       
   |
|   y DOUBLE                                                                          
   |
| )                                                                                   
   |
| PARTITIONED BY (                                                                    
   |
|   year SMALLINT                                                                     
   |
| )                                                                                   
   |
| STORED AS TEXTFILE                                                                  
   |
| LOCATION 'hdfs://127.0.0.1:8020/user/hive/warehouse/demo.db/show_create_table_demo' 
   |
| TBLPROPERTIES ('transient_lastDdlTime'='1418152638')                                
   |
372|ApacheImpalaGuideImpalaSQLLanguageReference
+----------------------------------------------------------------------------------------+
Relatedinformation:
CREATETABLEStatementonpage234,DESCRIBEStatementonpage251,SHOWTABLESStatementonpage369
SHOWCREATEVIEWStatement
TheSHOW CREATE VIEW ,itreturnsaCREATE VIEW statementwithcolumnnamesandtheoriginalSQLstatement
toreproducetheview.YouneedtheVIEW_METADATA privilegeontheviewandSELECTprivilegeonallunderlying
viewsandtablestosuccessfullyruntheSHOW CREATE VIEW statementforaview.
TheSHOW CREATE VIEW isanaliasforSHOW CREATE TABLE .
SHOWTABLESTATSStatement
TheSHOW TABLE STATS andSHOW COLUMN STATS variantsareimportantfortuningperformance anddiagnosing
performance issues,especially withthelargesttablesandthemostcomplexjoinqueries.
Anyvaluesthatarenotavailable(becausetheCOMPUTE STATS statementhasnotbeenrunyet)aredisplayedas-1.
SHOW TABLE STATS providessomegeneralinformationaboutthetable,suchasthenumberoffiles,overallsizeof
thedata,whethersomeorallofthedataisintheHDFScache,andthefileformat,thatisusefulwhetherornotyou
haveruntheCOMPUTE STATS statement.A-1inthe#RowsoutputcolumnindicatesthattheCOMPUTE STATS
statementhasneverbeenrunforthistable.Ifthetableispartitioned, SHOW TABLE STATS providesthisinformation
foreachpartition. (ItproducesthesameoutputastheSHOW PARTITIONS statementinthiscase.)
TheoutputofSHOW COLUMN STATS isprimarily onlyusefulaftertheCOMPUTE STATS statementhasbeenrunon
thetable.A-1inthe#Distinct Values outputcolumnindicatesthattheCOMPUTE STATS statementhasnever
beenrunforthistable.Currently,Impalaalwaysleavesthe#Nullscolumnas-1,evenafterCOMPUTE STATS has
beenrun.
TheseSHOWstatementsworkonactualtablesonly,notonviews.
Securityconsiderations:
Whenauthorizationisenabled, theoutputoftheSHOWstatementonlyshowsthoseobjectsforwhichyouhavethe
privilegetoview.IfyoubelieveanobjectexistsbutyoucannotseeitintheSHOWoutput,checkwiththesystem
administratorifyouneedtobegrantedanewprivilegeforthatobject.SeeEnablingSentryAuthorizationforImpala
onpage87forhowtosetupauthorizationandaddprivilegesforspecificobjects.
Kuduconsiderations:
BecauseKudutablesdonothavecharacteristicsderivedfromHDFS,suchasnumberoffiles,fileformat,andHDFS
cachestatus,theoutputofSHOW TABLE STATS reflectsdifferentcharacteristicsthatapplytoKudutables.IftheKudu
tableiscreatedwiththeclausePARTITIONS 20 ,thentheresultsetofSHOW TABLE STATS consistsof20rows,each
representingoneofthenumberedpartitions. Forexample:
show table stats kudu_table;
+--------+-----------+----------+-----------------------+------------+
| # Rows | Start Key | Stop Key | Leader Replica        | # Replicas |
+--------+-----------+----------+-----------------------+------------+
| -1     |           | 00000001 | host.example.com:7050 | 3          |
| -1     | 00000001  | 00000002 | host.example.com:7050 | 3          |
| -1     | 00000002  | 00000003 | host.example.com:7050 | 3          |
| -1     | 00000003  | 00000004 | host.example.com:7050 | 3          |
| -1     | 00000004  | 00000005 | host.example.com:7050 | 3          |
...
ImpaladoesnotcomputethenumberofrowsforeachpartitionforKudutables.Therefore,youdonotneedtore-run
COMPUTE STATS whenyousee-1inthe# RowscolumnoftheoutputfromSHOW TABLE STATS .Thatcolumnalways
shows-1forallKudutables.
ApacheImpalaGuide|373ImpalaSQLLanguageReference
Examples:
ThefollowingexamplesshowhowtheSHOW TABLE STATS statementdisplaysphysicalinformationaboutatable
andtheassociateddatafiles:
show table stats store_sales;
+-------+--------+----------+--------------+--------+-------------------+
| #Rows | #Files | Size     | Bytes Cached | Format | Incremental stats |
+-------+--------+----------+--------------+--------+-------------------+
| -1    | 1      | 370.45MB | NOT CACHED   | TEXT   | false             |
+-------+--------+----------+--------------+--------+-------------------+
show table stats customer;
+-------+--------+---------+--------------+--------+-------------------+
| #Rows | #Files | Size    | Bytes Cached | Format | Incremental stats |
+-------+--------+---------+--------------+--------+-------------------+
| -1    | 1      | 12.60MB | NOT CACHED   | TEXT   | false             |
+-------+--------+---------+--------------+--------+-------------------+
Thefollowingexampleshowshow,afteraCOMPUTE STATS orCOMPUTE INCREMENTAL STATS statement,the#Rows
fieldisnowfilledin.BecausetheSTORE_SALES tableinthisexampleisnotpartitioned, theCOMPUTE INCREMENTAL
STATSstatementproducesregularstatsratherthanincrementalstats,thereforetheIncremental stats field
remainsfalse.
compute stats customer;
+------------------------------------------+
| summary                                  |
+------------------------------------------+
| Updated 1 partition(s) and 18 column(s). |
+------------------------------------------+
show table stats customer;
+--------+--------+---------+--------------+--------+-------------------+
| #Rows  | #Files | Size    | Bytes Cached | Format | Incremental stats |
+--------+--------+---------+--------------+--------+-------------------+
| 100000 | 1      | 12.60MB | NOT CACHED   | TEXT   | false             |
+--------+--------+---------+--------------+--------+-------------------+
compute incremental stats store_sales;
+------------------------------------------+
| summary                                  |
+------------------------------------------+
| Updated 1 partition(s) and 23 column(s). |
+------------------------------------------+
show table stats store_sales;
+---------+--------+----------+--------------+--------+-------------------+
| #Rows   | #Files | Size     | Bytes Cached | Format | Incremental stats |
+---------+--------+----------+--------------+--------+-------------------+
| 2880404 | 1      | 370.45MB | NOT CACHED   | TEXT   | false             |
+---------+--------+----------+--------------+--------+-------------------+
HDFSpermissions:
TheuserIDthattheimpalad daemonrunsunder,typicallytheimpalauser,musthavereadandexecutepermissions
foralldirectoriesthatarepartofthetable.(AtablecouldspanmultipledifferentHDFSdirectoriesifitispartitioned.
Thedirectoriescouldbewidelyscatteredbecauseapartition canresideinanarbitraryHDFSdirectorybasedonits
LOCATION attribute.)TheImpalausermustalsohaveexecutepermission forthedatabasedirectory,andanyparent
directoriesofthedatabasedirectoryinHDFS.
Relatedinformation:
COMPUTE STATSStatementonpage219,SHOWCOLUMNSTATSStatementonpage375
SeeTableandColumnStatisticsonpage575forusageinformationandexamples.
374|ApacheImpalaGuideImpalaSQLLanguageReference
SHOWCOLUMNSTATSStatement
TheSHOW TABLE STATS andSHOW COLUMN STATS variantsareimportantfortuningperformance anddiagnosing
performance issues,especially withthelargesttablesandthemostcomplexjoinqueries.
Securityconsiderations:
Whenauthorizationisenabled, theoutputoftheSHOWstatementonlyshowsthoseobjectsforwhichyouhavethe
privilegetoview.IfyoubelieveanobjectexistsbutyoucannotseeitintheSHOWoutput,checkwiththesystem
administratorifyouneedtobegrantedanewprivilegeforthatobject.SeeEnablingSentryAuthorizationforImpala
onpage87forhowtosetupauthorizationandaddprivilegesforspecificobjects.
Kuduconsiderations:
TheoutputforSHOW COLUMN STATS includestherelevantinformationforKudutables.Theinformationforcolumn
statisticsthatoriginatesintheunderlying KudustoragelayerisalsorepresentedinthemetastoredatabasethatImpala
uses.
Examples:
ThefollowingexamplesshowtheoutputoftheSHOW COLUMN STATS statementforsometables,beforetheCOMPUTE
STATSstatementisrun.Impaladeducessomeinformation,suchasmaximumandaveragesizeforfixed-lengthcolumns,
andleavesandunknownvaluesas-1.
show column stats customer;
+------------------------+--------+------------------+--------+----------+----------+
| Column                 | Type   | #Distinct Values | #Nulls | Max Size | Avg Size |
+------------------------+--------+------------------+--------+----------+----------+
| c_customer_sk          | INT    | -1               | -1     | 4        | 4        |
| c_customer_id          | STRING | -1               | -1     | -1       | -1       |
| c_current_cdemo_sk     | INT    | -1               | -1     | 4        | 4        |
| c_current_hdemo_sk     | INT    | -1               | -1     | 4        | 4        |
| c_current_addr_sk      | INT    | -1               | -1     | 4        | 4        |
| c_first_shipto_date_sk | INT    | -1               | -1     | 4        | 4        |
| c_first_sales_date_sk  | INT    | -1               | -1     | 4        | 4        |
| c_salutation           | STRING | -1               | -1     | -1       | -1       |
| c_first_name           | STRING | -1               | -1     | -1       | -1       |
| c_last_name            | STRING | -1               | -1     | -1       | -1       |
| c_preferred_cust_flag  | STRING | -1               | -1     | -1       | -1       |
| c_birth_day            | INT    | -1               | -1     | 4        | 4        |
| c_birth_month          | INT    | -1               | -1     | 4        | 4        |
| c_birth_year           | INT    | -1               | -1     | 4        | 4        |
| c_birth_country        | STRING | -1               | -1     | -1       | -1       |
| c_login                | STRING | -1               | -1     | -1       | -1       |
| c_email_address        | STRING | -1               | -1     | -1       | -1       |
| c_last_review_date     | STRING | -1               | -1     | -1       | -1       |
+------------------------+--------+------------------+--------+----------+----------+
show column stats store_sales;
+-----------------------+-------+------------------+--------+----------+----------+
| Column                | Type  | #Distinct Values | #Nulls | Max Size | Avg Size |
+-----------------------+-------+------------------+--------+----------+----------+
| ss_sold_date_sk       | INT   | -1               | -1     | 4        | 4        |
| ss_sold_time_sk       | INT   | -1               | -1     | 4        | 4        |
| ss_item_sk            | INT   | -1               | -1     | 4        | 4        |
| ss_customer_sk        | INT   | -1               | -1     | 4        | 4        |
| ss_cdemo_sk           | INT   | -1               | -1     | 4        | 4        |
| ss_hdemo_sk           | INT   | -1               | -1     | 4        | 4        |
| ss_addr_sk            | INT   | -1               | -1     | 4        | 4        |
| ss_store_sk           | INT   | -1               | -1     | 4        | 4        |
| ss_promo_sk           | INT   | -1               | -1     | 4        | 4        |
| ss_ticket_number      | INT   | -1               | -1     | 4        | 4        |
| ss_quantity           | INT   | -1               | -1     | 4        | 4        |
| ss_wholesale_cost     | FLOAT | -1               | -1     | 4        | 4        |
| ss_list_price         | FLOAT | -1               | -1     | 4        | 4        |
| ss_sales_price        | FLOAT | -1               | -1     | 4        | 4        |
| ss_ext_discount_amt   | FLOAT | -1               | -1     | 4        | 4        |
| ss_ext_sales_price    | FLOAT | -1               | -1     | 4        | 4        |
| ss_ext_wholesale_cost | FLOAT | -1               | -1     | 4        | 4        |
| ss_ext_list_price     | FLOAT | -1               | -1     | 4        | 4        |
| ss_ext_tax            | FLOAT | -1               | -1     | 4        | 4        |
ApacheImpalaGuide|375ImpalaSQLLanguageReference
| ss_coupon_amt         | FLOAT | -1               | -1     | 4        | 4        |
| ss_net_paid           | FLOAT | -1               | -1     | 4        | 4        |
| ss_net_paid_inc_tax   | FLOAT | -1               | -1     | 4        | 4        |
| ss_net_profit         | FLOAT | -1               | -1     | 4        | 4        |
+-----------------------+-------+------------------+--------+----------+----------+
ThefollowingexamplesshowtheoutputoftheSHOW COLUMN STATS statementforsometables,aftertheCOMPUTE
STATSstatementisrun.Nowmostofthe-1valuesarechangedtoreflecttheactualtabledata.The#Nullscolumn
remains-1becauseImpaladoesnotusethenumberofNULLvaluestoinfluencequeryplanning.
compute stats customer;
+------------------------------------------+
| summary                                  |
+------------------------------------------+
| Updated 1 partition(s) and 18 column(s). |
+------------------------------------------+
compute stats store_sales;
+------------------------------------------+
| summary                                  |
+------------------------------------------+
| Updated 1 partition(s) and 23 column(s). |
+------------------------------------------+
show column stats customer;
+------------------------+--------+------------------+--------+----------+--------+
| Column                 | Type   | #Distinct Values | #Nulls | Max Size | Avg Size
+------------------------+--------+------------------+--------+----------+--------+
| c_customer_sk          | INT    | 139017           | -1     | 4        | 4      |
| c_customer_id          | STRING | 111904           | -1     | 16       | 16     |
| c_current_cdemo_sk     | INT    | 95837            | -1     | 4        | 4      |
| c_current_hdemo_sk     | INT    | 8097             | -1     | 4        | 4      |
| c_current_addr_sk      | INT    | 57334            | -1     | 4        | 4      |
| c_first_shipto_date_sk | INT    | 4374             | -1     | 4        | 4      |
| c_first_sales_date_sk  | INT    | 4409             | -1     | 4        | 4      |
| c_salutation           | STRING | 7                | -1     | 4        | 3.1308 |
| c_first_name           | STRING | 3887             | -1     | 11       | 5.6356 |
| c_last_name            | STRING | 4739             | -1     | 13       | 5.9106 |
| c_preferred_cust_flag  | STRING | 3                | -1     | 1        | 0.9656 |
| c_birth_day            | INT    | 31               | -1     | 4        | 4      |
| c_birth_month          | INT    | 12               | -1     | 4        | 4      |
| c_birth_year           | INT    | 71               | -1     | 4        | 4      |
| c_birth_country        | STRING | 205              | -1     | 20       | 8.4001 |
| c_login                | STRING | 1                | -1     | 0        | 0      |
| c_email_address        | STRING | 94492            | -1     | 46       | 26.485 |
| c_last_review_date     | STRING | 349              | -1     | 7        | 6.7561 |
+------------------------+--------+------------------+--------+----------+--------+
show column stats store_sales;
+-----------------------+-------+------------------+--------+----------+----------+
| Column                | Type  | #Distinct Values | #Nulls | Max Size | Avg Size |
+-----------------------+-------+------------------+--------+----------+----------+
| ss_sold_date_sk       | INT   | 4395             | -1     | 4        | 4        |
| ss_sold_time_sk       | INT   | 63617            | -1     | 4        | 4        |
| ss_item_sk            | INT   | 19463            | -1     | 4        | 4        |
| ss_customer_sk        | INT   | 122720           | -1     | 4        | 4        |
| ss_cdemo_sk           | INT   | 242982           | -1     | 4        | 4        |
| ss_hdemo_sk           | INT   | 8097             | -1     | 4        | 4        |
| ss_addr_sk            | INT   | 70770            | -1     | 4        | 4        |
| ss_store_sk           | INT   | 6                | -1     | 4        | 4        |
| ss_promo_sk           | INT   | 355              | -1     | 4        | 4        |
| ss_ticket_number      | INT   | 304098           | -1     | 4        | 4        |
| ss_quantity           | INT   | 105              | -1     | 4        | 4        |
| ss_wholesale_cost     | FLOAT | 9600             | -1     | 4        | 4        |
| ss_list_price         | FLOAT | 22191            | -1     | 4        | 4        |
| ss_sales_price        | FLOAT | 20693            | -1     | 4        | 4        |
| ss_ext_discount_amt   | FLOAT | 228141           | -1     | 4        | 4        |
| ss_ext_sales_price    | FLOAT | 433550           | -1     | 4        | 4        |
| ss_ext_wholesale_cost | FLOAT | 406291           | -1     | 4        | 4        |
| ss_ext_list_price     | FLOAT | 574871           | -1     | 4        | 4        |
| ss_ext_tax            | FLOAT | 91806            | -1     | 4        | 4        |
| ss_coupon_amt         | FLOAT | 228141           | -1     | 4        | 4        |
376|ApacheImpalaGuideImpalaSQLLanguageReference
| ss_net_paid           | FLOAT | 493107           | -1     | 4        | 4        |
| ss_net_paid_inc_tax   | FLOAT | 653523           | -1     | 4        | 4        |
| ss_net_profit         | FLOAT | 611934           | -1     | 4        | 4        |
+-----------------------+-------+------------------+--------+----------+----------+
HDFSpermissions:
TheuserIDthattheimpalad daemonrunsunder,typicallytheimpalauser,musthavereadandexecutepermissions
foralldirectoriesthatarepartofthetable.(AtablecouldspanmultipledifferentHDFSdirectoriesifitispartitioned.
Thedirectoriescouldbewidelyscatteredbecauseapartition canresideinanarbitraryHDFSdirectorybasedonits
LOCATION attribute.)TheImpalausermustalsohaveexecutepermission forthedatabasedirectory,andanyparent
directoriesofthedatabasedirectoryinHDFS.
Relatedinformation:
COMPUTE STATSStatementonpage219,SHOWTABLESTATSStatementonpage373
SeeTableandColumnStatisticsonpage575forusageinformationandexamples.
SHOWPARTITIONSStatement
SHOW PARTITIONS displaysinformationabouteachpartition forapartitioned table.(Theoutputisthesameasthe
SHOW TABLE STATS statement,butSHOW PARTITIONS onlyworksonapartitioned table.)Becauseitdisplaystable
statisticsforallpartitions, theoutputismoreinformativeifyouhaveruntheCOMPUTE STATS statementaftercreating
allthepartitions. SeeCOMPUTE STATSStatementonpage219fordetails.Forexample,onaCENSUStablepartitioned
ontheYEARcolumn:
BecauseKudutablesareallconsideredtobepartitioned, theSHOW PARTITIONS statementworksforanyKudutable.
ThedefaultoutputisthesameasforSHOW TABLE STATS ,withthesameKudu-specific columnsintheresultset:
show table stats kudu_table;
+--------+-----------+----------+-----------------------+------------+
| # Rows | Start Key | Stop Key | Leader Replica        | # Replicas |
+--------+-----------+----------+-----------------------+------------+
| -1     |           | 00000001 | host.example.com:7050 | 3          |
| -1     | 00000001  | 00000002 | host.example.com:7050 | 3          |
| -1     | 00000002  | 00000003 | host.example.com:7050 | 3          |
| -1     | 00000003  | 00000004 | host.example.com:7050 | 3          |
| -1     | 00000004  | 00000005 | host.example.com:7050 | 3          |
...
Securityconsiderations:
Whenauthorizationisenabled, theoutputoftheSHOWstatementonlyshowsthoseobjectsforwhichyouhavethe
privilegetoview.IfyoubelieveanobjectexistsbutyoucannotseeitintheSHOWoutput,checkwiththesystem
administratorifyouneedtobegrantedanewprivilegeforthatobject.SeeEnablingSentryAuthorizationforImpala
onpage87forhowtosetupauthorizationandaddprivilegesforspecificobjects.
Kuduconsiderations:
TheoptionalRANGEclauseonlyappliestoKudutables.Itdisplaysonlythepartitions definedbytheRANGEclauseof
CREATE TABLE orALTER TABLE .
Although youcanspecify<or<=comparison operatorswhendefiningrangepartitions forKudutables,Kudurewrites
themifnecessarytorepresenteachrangeaslow_bound  <= VALUES < high_bound .Thisrewritingmightinvolve
incrementingoneoftheboundaryvaluesorappending a\0forstringvalues,sothatthepartition coversthesame
rangeasoriginally specified.
Examples:
ApacheImpalaGuide|377ImpalaSQLLanguageReference
ThefollowingexampleshowstheoutputforaParquet,text,orotherHDFS-backedtablepartitioned ontheYEAR
column:
[localhost:21000] > show partitions census;
+-------+-------+--------+------+---------+
| year  | #Rows | #Files | Size | Format  |
+-------+-------+--------+------+---------+
| 2000  | -1    | 0      | 0B   | TEXT    |
| 2004  | -1    | 0      | 0B   | TEXT    |
| 2008  | -1    | 0      | 0B   | TEXT    |
| 2010  | -1    | 0      | 0B   | TEXT    |
| 2011  | 4     | 1      | 22B  | TEXT    |
| 2012  | 4     | 1      | 22B  | TEXT    |
| 2013  | 1     | 1      | 231B | PARQUET |
| Total | 9     | 3      | 275B |         |
+-------+-------+--------+------+---------+
ThefollowingexampleshowstheoutputforaKudutableusingthehashpartitioning mechanism. Thenumberofrows
intheresultsetcorrespondstothevaluesusedinthePARTITIONS NclauseofCREATE TABLE .
show partitions million_rows_hash;
+--------+-----------+----------+-----------------------+--
| # Rows | Start Key | Stop Key | Leader Replica        | # Replicas
+--------+-----------+----------+-----------------------+--
| -1     |           | 00000001 | n236.example.com:7050 | 3
| -1     | 00000001  | 00000002 | n236.example.com:7050 | 3
| -1     | 00000002  | 00000003 | n336.example.com:7050 | 3
| -1     | 00000003  | 00000004 | n238.example.com:7050 | 3
| -1     | 00000004  | 00000005 | n338.example.com:7050 | 3
....
| -1     | 0000002E  | 0000002F | n240.example.com:7050 | 3
| -1     | 0000002F  | 00000030 | n336.example.com:7050 | 3
| -1     | 00000030  | 00000031 | n240.example.com:7050 | 3
| -1     | 00000031  |          | n334.example.com:7050 | 3
+--------+-----------+----------+-----------------------+--
Fetched 50 row(s) in 0.05s
ThefollowingexampleshowstheoutputforaKudutableusingtherangepartitioning mechanism:
show range partitions million_rows_range;
+-----------------------+
| RANGE (id)            |
+-----------------------+
| VALUES < "A"          |
| "A" <= VALUES < "["   |
| "a" <= VALUES < "{"   |
| "{" <= VALUES < "~\0" |
+-----------------------+
HDFSpermissions:
TheuserIDthattheimpalad daemonrunsunder,typicallytheimpalauser,musthavereadandexecutepermissions
foralldirectoriesthatarepartofthetable.(AtablecouldspanmultipledifferentHDFSdirectoriesifitispartitioned.
Thedirectoriescouldbewidelyscatteredbecauseapartition canresideinanarbitraryHDFSdirectorybasedonits
LOCATION attribute.)TheImpalausermustalsohaveexecutepermission forthedatabasedirectory,andanyparent
directoriesofthedatabasedirectoryinHDFS.
Relatedinformation:
SeeTableandColumnStatisticsonpage575forusageinformationandexamples.
SHOWTABLESTATSStatementonpage373,Partitioning forImpalaTablesonpage625
378|ApacheImpalaGuideImpalaSQLLanguageReference
SHOWFUNCTIONSStatement
Bydefault,SHOW FUNCTIONS displaysuser-definedfunctions (UDFs)andSHOW AGGREGATE FUNCTIONS displays
user-definedaggregatefunctions (UDAFs)associatedwithaparticular database.TheoutputfromSHOW FUNCTIONS
includestheargumentsignatureofeachfunction. YouspecifythisargumentsignatureaspartoftheDROP FUNCTION
statement.YoumighthaveseveralUDFswiththesamename,eachacceptingdifferentargumentdatatypes.
Usagenotes:
InCDH5.7/Impala2.5andhigher,theSHOW FUNCTIONS outputincludesanewcolumn,labelledis persistent .
ThispropertyistrueforImpalabuilt-infunctions, C++UDFs,andJavaUDFscreatedusingthenewCREATE FUNCTION
syntaxwithnosignature.ItisfalseforJavaUDFscreatedusingtheoldCREATE FUNCTION syntaxthatincludesthe
typesfortheargumentsandreturnvalue.Anyfunctions withfalseshownforthispropertymustbecreatedagain
bytheCREATE FUNCTION statementeachtimetheImpalacatalogserverisrestarted.SeeCREATE FUNCTION for
informationonswitchingtothenewsyntax,sothatJavaUDFsarepreservedacrossrestarts.JavaUDFsthatarepersisted
thiswayarealsoeasiertoshareacrossImpalaandHive.
Securityconsiderations:
Whenauthorizationisenabled, theoutputoftheSHOWstatementonlyshowsthoseobjectsforwhichyouhavethe
privilegetoview.IfyoubelieveanobjectexistsbutyoucannotseeitintheSHOWoutput,checkwiththesystem
administratorifyouneedtobegrantedanewprivilegeforthatobject.SeeEnablingSentryAuthorizationforImpala
onpage87forhowtosetupauthorizationandaddprivilegesforspecificobjects.
HDFSpermissions: ThisstatementdoesnottouchanyHDFSfilesordirectories,thereforenoHDFSpermissions are
required.
Examples:
TodisplayImpalabuilt-infunctions, specifythespecialdatabasename_impala_builtins :
show functions in _impala_builtins;
+--------------+-------------------------------------------------+-------------+---------------+
| return type  | signature                                       | binary type | is 
persistent |
+--------------+-------------------------------------------------+-------------+---------------+
| BIGINT       | abs(BIGINT)                                     | BUILTIN     | true 
         |
| DECIMAL(*,*) | abs(DECIMAL(*,*))                               | BUILTIN     | true 
         |
| DOUBLE       | abs(DOUBLE)                                     | BUILTIN     | true 
         |
| FLOAT        | abs(FLOAT)                                      | BUILTIN     | true 
         |
+----------------+----------------------------------------+
...
show functions in _impala_builtins like '*week*';
+-------------+------------------------------+-------------+---------------+
| return type | signature                    | binary type | is persistent |
+-------------+------------------------------+-------------+---------------+
| INT         | dayofweek(TIMESTAMP)         | BUILTIN     | true          |
| INT         | weekofyear(TIMESTAMP)        | BUILTIN     | true          |
| TIMESTAMP   | weeks_add(TIMESTAMP, BIGINT) | BUILTIN     | true          |
| TIMESTAMP   | weeks_add(TIMESTAMP, INT)    | BUILTIN     | true          |
| TIMESTAMP   | weeks_sub(TIMESTAMP, BIGINT) | BUILTIN     | true          |
| TIMESTAMP   | weeks_sub(TIMESTAMP, INT)    | BUILTIN     | true          |
+-------------+------------------------------+-------------+---------------+
Relatedinformation:
OverviewofImpalaFunctions onpage194,ImpalaBuilt-InFunctions onpage391,User-DefinedFunctions (UDFs)on
page525,SHOWDATABASESonpage368,SHOWTABLESStatementonpage369
SHUTDOWNStatement
TheSHUTDOWN statementperformsagracefulshutdownofImpalaDaemon. TheImpaladaemonwillnotifyother
Impaladaemons thatitisshuttingdown,waitforagraceperiod,thenshutitselfdownoncenomorequeriesor
ApacheImpalaGuide|379ImpalaSQLLanguageReference
fragmentsareexecutingonthatdaemon. The--shutdown_grace_period_s flagdeterminesthedurationofthe
graceperiodinseconds.
Syntax:
:SHUTDOWN()
:SHUTDOWN([ host_name [:port_number ] )
:SHUTDOWN( deadline )
:SHUTDOWN([ host_name [:port_number ], deadline )
Usagenotes:
AllargumentsareoptionalforSHUTDOWN .
Description Default Type Argument
Addressoftheimpalad tobeshutdown. Thecurrentimpalad hosttowhomthe
SHUTDOWN statementissubmitted.STRING host_name
Specifies theportbywhichtheimpalad can
becontacted.INT port_number â¢InImpala3.1/CDH6.1,thecurrent
impalad'sportusedforthethriftbased
communic ationwithotherimpalad s
(bydefault,22000).â¢InImpala3.1/CDH6.1,usethesame
impalad portusedforthethriftbased
inter-Impala communic ation.â¢InImpala3.2andhigher,thecurrent
impalad'sportusedfortheKRPCbasedâ¢InImpala3.2andhigher,usethesame
impalad portusedfortheKRPCbased
inter-Impala communic ation.communic ationwithotherimpalad s
(bydefault,27000).
deadline mustbeanon-negativenumber,
specified inseconds.
Thevalue,0,fordeadlinespecifiesan
immediateshutdown.Thevalueofthe--shutdown_deadline_s
flag,whichdefaultsto1hour.INT deadline
TakethefollowingpointsintoconsiderationwhenrunningtheSHUTDOWN statement:
â¢Aclientcanshutdownthecoordinatorimpalad thatitisconnectedtovia:SHUTDOWN() .
â¢Aclientcanremotelyshutdownanyimpalad via:SHUTDOWN(' hostname ').
â¢Theshutdowntimelimitcanbeoverriddentoforceaquickerorslowershutdownbyspecifyingadeadline. The
defaultdeadlineisdeterminedbythe--shutdown_deadline_s flag,whichdefaultsto1hour.
â¢Executorscanbeshutdownwithoutdisruptingrunningqueries.Short-running querieswillfinish,andlong-running
querieswillcontinueuntilthedeadlineisreached.
â¢Ifqueriesaresubmittedtoacoordinatoraftershutdownofthatcoordinatorhasstarted,theywillfail.
â¢Longrunningqueriesorotherissues,suchasstuckfragments,willslowdownbutnotpreventeventualshutdown.
Securityconsiderations:
TheALLprivilegeisrequiredontheserver.
Cancellation:Cannotbecancelled.
Examples:
:SHUTDOWN(); -- Shut down the current impalad  with the default deadline.
:SHUTDOWN('hostname'); --  Shut down impalad running on hostname  with the default 
deadline.
:SHUTDOWN(\"hostname:1234\"); -- Shut down impalad running on host at port 1234  with 
the default deadline.
:SHUTDOWN(10); - Shut down the current impalad after 10 seconds.
:SHUTDOWN('hostname', 10); - Shut down impalad running on hostname when all queries 
running on hostname finish, or after 10 seconds.
:SHUTDOWN('hostname:11', 10 * 60); -- Shut down impalad running on hostname at port 11
380|ApacheImpalaGuideImpalaSQLLanguageReference
 when all queries running on hostname finish, or after 600 seconds.
:SHUTDOWN(0); -- Perform an immdediate shutdown of the current impalad.
Addedin:CDH6.1
TRUNCATETABLEStatement(CDH5.5orhigheronly)
RemovesthedatafromanImpalatablewhileleavingthetableitself.
Syntax:
TRUNCATE [TABLE] [IF EXISTS]  [db_name.]table_name
Statementtype:DDL
Usagenotes:
OftenusedtoemptytablesthatareusedduringETLcycles,afterthedatahasbeencopiedtoanothertableforthe
nextstageofprocessing. Thisstatementisalow-overheadalternativetodroppingandrecreatingthetable,orusing
INSERT OVERWRITE toreplacethedataduringthenextETLcycle.
Thisstatementremovesallthedataandassociateddatafilesinthetable.Itcanremovedatafilesfrominternaltables,
externaltables,partitioned tables,andtablesmappedtoHBaseortheAmazonSimpleStorageService(S3).Thedata
removalappliestotheentiretable,including allpartitions ofapartitioned table.
AnystatisticsproducedbytheCOMPUTE STATS statementareresetwhenthedataisremoved.
Makesurethatyouareinthecorrectdatabasebeforetruncatingatable,eitherbyissuingaUSEstatementfirstorby
usingafullyqualified namedb_name.table_name .
TheoptionalTABLEkeyworddoesnotaffectthebehaviorofthestatement.
TheoptionalIF EXISTS clausemakesthestatementsucceedwhetherornotthetableexists.Ifthetabledoesexist,
itistruncated;ifitdoesnotexist,thestatementhasnoeffect.Thiscapabilityisusefulinstandardizedsetupscripts
thataremightberunbothbeforeandaftersomeofthetablesexist.ThisclauseisavailableinCDH5.7/Impala2.5
andhigher.
Forothertipsaboutmanaging andreclaiming Impaladiskspace,seeManaging DiskSpaceforImpalaDataonpage
77.
AmazonS3considerations:
Although ImpalacannotwritenewdatatoatablestoredintheAmazonS3filesystem,theTRUNCATE TABLE statement
canremovedatafilesfromS3.SeeUsingImpalawiththeAmazonS3Filesystemonpage692fordetailsaboutworking
withS3tables.
Cancellation:Cannotbecancelled.
HDFSpermissions:
TheuserIDthattheimpalad daemonrunsunder,typicallytheimpalauser,musthavewritepermission forallthe
filesanddirectoriesthatmakeupthetable.
Kuduconsiderations:
Currently,theTRUNCATE TABLE statementcannotbeusedwithKudutables.
Examples:
Thefollowingexampleshowsatablecontainingsomedataandwithtableandcolumnstatistics.AftertheTRUNCATE
TABLEstatement,thedataisremovedandthestatisticsarereset.
CREATE TABLE truncate_demo (x INT);
INSERT INTO truncate_demo VALUES (1), (2), (4), (8);
SELECT COUNT(*) FROM truncate_demo;
+----------+
ApacheImpalaGuide|381ImpalaSQLLanguageReference
| count(*) |
+----------+
| 4        |
+----------+
COMPUTE STATS truncate_demo;
+-----------------------------------------+
| summary                                 |
+-----------------------------------------+
| Updated 1 partition(s) and 1 column(s). |
+-----------------------------------------+
SHOW TABLE STATS truncate_demo;
+-------+--------+------+--------------+-------------------+--------+-------------------+
| #Rows | #Files | Size | Bytes Cached | Cache Replication | Format | Incremental stats
 |
+-------+--------+------+--------------+-------------------+--------+-------------------+
| 4     | 1      | 8B   | NOT CACHED   | NOT CACHED        | TEXT   | false           
  |
+-------+--------+------+--------------+-------------------+--------+-------------------+
SHOW COLUMN STATS truncate_demo;
+--------+------+------------------+--------+----------+----------+
| Column | Type | #Distinct Values | #Nulls | Max Size | Avg Size |
+--------+------+------------------+--------+----------+----------+
| x      | INT  | 4                | -1     | 4        | 4        |
+--------+------+------------------+--------+----------+----------+
-- After this statement, the data and the table/column stats will be gone.
TRUNCATE TABLE truncate_demo;
SELECT COUNT(*) FROM truncate_demo;
+----------+
| count(*) |
+----------+
| 0        |
+----------+
SHOW TABLE STATS truncate_demo;
+-------+--------+------+--------------+-------------------+--------+-------------------+
| #Rows | #Files | Size | Bytes Cached | Cache Replication | Format | Incremental stats
 |
+-------+--------+------+--------------+-------------------+--------+-------------------+
| -1    | 0      | 0B   | NOT CACHED   | NOT CACHED        | TEXT   | false           
  |
+-------+--------+------+--------------+-------------------+--------+-------------------+
SHOW COLUMN STATS truncate_demo;
+--------+------+------------------+--------+----------+----------+
| Column | Type | #Distinct Values | #Nulls | Max Size | Avg Size |
+--------+------+------------------+--------+----------+----------+
| x      | INT  | -1               | -1     | 4        | 4        |
+--------+------+------------------+--------+----------+----------+
ThefollowingexampleshowshowtheIF EXISTS clauseallowstheTRUNCATE TABLE statementtoberunwithout
errorwhetherornotthetableexists:
CREATE TABLE staging_table1 (x INT, s STRING);
Fetched 0 row(s) in 0.33s
SHOW TABLES LIKE 'staging*';
+----------------+
| name           |
+----------------+
| staging_table1 |
+----------------+
Fetched 1 row(s) in 0.25s
-- Our ETL process involves removing all data from several staging tables
-- even though some might be already dropped, or not created yet.
TRUNCATE TABLE IF EXISTS staging_table1;
Fetched 0 row(s) in 5.04s
TRUNCATE TABLE IF EXISTS staging_table2;
Fetched 0 row(s) in 0.25s
382|ApacheImpalaGuideImpalaSQLLanguageReference
TRUNCATE TABLE IF EXISTS staging_table3;
Fetched 0 row(s) in 0.25s
Relatedinformation:
OverviewofImpalaTablesonpage196,ALTERTABLEStatementonpage205,CREATETABLEStatementonpage234,
Partitioning forImpalaTablesonpage625,InternalTablesonpage197,ExternalTablesonpage197
UPDATEStatement(CDH5.10orhigheronly)
UpdatesanarbitrarynumberofrowsinaKudutable.ThisstatementonlyworksforImpalatablesthatusetheKudu
storageengine.
Syntax:
UPDATE [ database_name .]table_name  SET col = val [, col = val ... ]
  [ FROM joined_table_refs  ]
  [ WHERE where_conditions  ]
Usagenotes:
NoneofthecolumnsthatmakeuptheprimarykeycanbeupdatedbytheSETclause.
Theconditions intheWHEREclausearethesameonesallowedfortheSELECTstatement.SeeSELECTStatementon
page295fordetails.
IftheWHEREclauseisomitted,allrowsinthetableareupdated.
Theconditions intheWHEREclausecanrefertoanycombinationofprimarykeycolumnsorothercolumns.Referring
toprimarykeycolumnsintheWHEREclauseismoreefficientthanreferringtonon-primar ykeycolumns.
BecauseKuducurrentlydoesnotenforcestrongconsistencyduringconcurrentDMLoperations,beawarethatthe
resultsafterthisstatementfinishesmightbedifferentthanyouintuitivelyexpect:
â¢Ifsomerowscannotbeupdatedbecausetheirsomeprimarykeycolumnsarenotfound,duetotheirbeingdeleted
byaconcurrentDELETEoperation,thestatementsucceeds butreturnsawarning.
â¢AnUPDATEstatementmightalsooverlapwithINSERT,UPDATE,orUPSERTstatementsrunningconcurrentlyon
thesametable.Afterthestatementfinishes,theremightbemoreorfewermatchingrowsthanexpectedinthe
tablebecauseitisundefinedwhethertheUPDATEappliestorowsthatareinsertedorupdatedwhiletheUPDATE
isinprogress.
Thenumberofaffectedrowsisreportedinanimpala-shell messageandinthequeryprofile.
TheoptionalFROMclauseletsyourestricttheupdatestoonlytherowsinthespecified tablethatarepartoftheresult
setforajoinquery.Thejoinclausescanincludenon-Kudutables,butthetablefromwhichtherowsaredeletedmust
beaKudutable.
Statementtype:DML
Important:Afteraddingorreplacingdatainatableusedinperformance-critic alqueries,issuea
COMPUTE STATS statementtomakesureallstatisticsareup-to-date.Consider updatingstatisticsfor
atableafteranyINSERT,LOAD DATA ,orCREATE TABLE AS SELECT statementinImpala,orafter
loadingdatathroughHiveanddoingaREFRESH table_name inImpala.Thistechnique isespecially
importantfortablesthatareverylarge,usedinjoinqueries,orboth.
Examples:
Thefollowingexamplesshowhowtoperformasimpleupdateonatable,withorwithoutaWHEREclause:
-- Set all rows to the same value for column c3.
ApacheImpalaGuide|383ImpalaSQLLanguageReference
-- In this case, c1 and c2 are primary key columns
-- and so cannot be updated.
UPDATE kudu_table SET c3 = 'not applicable';
-- Update only the rows that match the condition.
UPDATE kudu_table SET c3 = NULL WHERE c1 > 100 AND c3 IS NULL;
-- Does not update any rows, because the WHERE condition is always false.
UPDATE kudu_table SET c3 = 'impossible' WHERE 1 = 0;
-- Change the values of multiple columns in a single UPDATE statement.
UPDATE kudu_table SET c3 = upper(c3), c4 = FALSE, c5 = 0 WHERE c6 = TRUE;
ThefollowingexamplesshowhowtoperformanupdateusingtheFROMkeywordwithajoinclause:
-- Uppercase a column value, only for rows that have
-- an ID that matches the value from another table.
UPDATE kudu_table SET c3 = upper(c3)
  FROM kudu_table JOIN non_kudu_table
  ON kudu_table.id = non_kudu_table.id;
-- Same effect as previous statement.
-- Assign table aliases in FROM clause, then refer to
-- short names elsewhere in the statement.
UPDATE t1 SET c3 = upper(c3)
  FROM kudu_table t1 JOIN non_kudu_table t2
  ON t1.id = t2.id;
-- Same effect as previous statements, but more efficient.
-- Use WHERE clause to skip updating values that are
-- already uppercase.
UPDATE t1 SET c3 = upper(c3)
  FROM kudu_table t1 JOIN non_kudu_table t2
  ON t1.id = t2.id
  WHERE c3 != upper(c3);
Relatedinformation:
UsingImpalatoQueryKuduTablesonpage670,INSERTStatementonpage277,DELETEStatement(CDH5.10orhigher
only)onpage249,UPSERTStatement(CDH5.10orhigheronly)onpage384
UPSERTStatement(CDH5.10orhigheronly)
ActsasacombinationoftheINSERTandUPDATEstatements.ForeachrowprocessedbytheUPSERTstatement:
â¢Ifanotherrowalreadyexistswiththesamesetofprimarykeyvalues,theothercolumnsareupdatedtomatch
thevaluesfromtherowbeingâUPSERTedâ.
â¢Ifthereisnotanyrowwiththesamesetofprimarykeyvalues,therowiscreated,thesameasiftheINSERT
statementwasused.
ThisstatementonlyworksforImpalatablesthatusetheKudustorageengine.
Syntax:
UPSERT [hint_clause ] INTO [TABLE] [ db_name.]table_name
  [(column_list )]
{
    [hint_clause ] select_statement
  | VALUES ( value [, value ...]) [, ( value [, value ...]) ...]
}
hint_clause ::= [SHUFFLE] | [NOSHUFFLE]
  (Note: the square brackets are part of the syntax.)
Theselect_statementclausecanusethefullsyntax,suchasWHEREandjoinclauses,asSELECTStatementonpage295.
384|ApacheImpalaGuideImpalaSQLLanguageReference
Statementtype:DML
Usagenotes:
Ifyouspecifyacolumnlist,anyomittedcolumnsintheinsertedorupdatedrowsaresettotheirdefaultvalue(ifthe
columnhasone)orNULL(ifthecolumndoesnothaveadefaultvalue).Therefore,ifacolumnisnotnullableandhas
nodefaultvalue,itmustbeincludedinthecolumnlistforanyUPSERTstatement.Becauseallprimarykeycolumns
meettheseconditions, alltheprimarykeycolumnsmustbespecified ineveryUPSERTstatement.
BecauseKudutablescanefficientlyhandlesmallincrementalchanges,theVALUESclauseismorepracticaltousewith
KudutablesthanwithHDFS-basedtables.
Important:Afteraddingorreplacingdatainatableusedinperformance-critic alqueries,issuea
COMPUTE STATS statementtomakesureallstatisticsareup-to-date.Consider updatingstatisticsfor
atableafteranyINSERT,LOAD DATA ,orCREATE TABLE AS SELECT statementinImpala,orafter
loadingdatathroughHiveanddoingaREFRESH table_name inImpala.Thistechnique isespecially
importantfortablesthatareverylarge,usedinjoinqueries,orboth.
Examples:
UPSERT INTO kudu_table (pk, c1, c2, c3) VALUES (0, 'hello', 50, true), (1, 'world', -1,
 false);
UPSERT INTO production_table SELECT * FROM staging_table;
UPSERT INTO production_table SELECT * FROM staging_table WHERE c1 IS NOT NULL AND c2 >
 0;
Relatedinformation:
UsingImpalatoQueryKuduTablesonpage670,INSERTStatementonpage277,UPDATEStatement(CDH5.10orhigher
only)onpage383
USEStatement
Switchesthecurrentsessiontoaspecified database.ThecurrentdatabaseiswhereanyCREATE TABLE ,INSERT,
SELECT,orotherstatementsactwhenyouspecifyatableorotherobjectname,withoutprefixingitwithadatabase
name.ThenewcurrentdatabaseappliesforthedurationofthesessionoruntianotherUSEstatementisexecuted.
Syntax:
USE db_name
Bydefault,whenyouconnecttoanImpalainstance,youbegininadatabasenameddefault .
Usagenotes:
Switchingthedefaultdatabaseisconvenientinthefollowingsituations:
â¢Toavoidqualifyingeachreferencetoatablewiththedatabasename.Forexample,SELECT * FROM t1 JOIN
t2ratherthanSELECT * FROM db.t1 JOIN db.t2 .
â¢Todoasequence ofoperationsallwithinthesamedatabase,suchascreatingatable,insertingdata,andquerying
thetable.
Tostarttheimpala-shell interpreterandautomaticallyissueaUSEstatementforaparticular database,specifythe
option-d db_name fortheimpala-shell command. The-doptionisusefultorunSQLscripts,suchassetupor
testscripts,againstmultipledatabaseswithouthardcodingaUSEstatementintotheSQLsource.
Examples:
SeeCREATEDATABASEStatementonpage226forexamplescoveringCREATE DATABASE ,USE,andDROP DATABASE .
Cancellation:Cannotbecancelled.
ApacheImpalaGuide|385ImpalaSQLLanguageReference
HDFSpermissions: ThisstatementdoesnottouchanyHDFSfilesordirectories,thereforenoHDFSpermissions are
required.
Relatedinformation:
CREATEDATABASEStatementonpage226,DROPDATABASEStatementonpage262,SHOWDATABASESonpage368
VALUESStatement
InadditiontobeingpartoftheINSERTstatement,theVALUESclausecanbeusedasstand-alone statementorwith
theSELECTstatementtoconstructadatasetwithoutcreatingatable.Forexample,thefollowingstatementreturns
adatasetof2rowsand3columns.
VALUES ('r1_c1', 'r1_c2', 'r1_c3')
     , ('r2_c1', 'r2_c2', 'r2_c3');
Syntax:
VALUES ( row)[, (row), ...];
SELECT select_list  FROM (VALUES ( row)[, (row), ...]) AS alias;
row ::= column [[AS alias], column [AS alias], ...]
â¢TheVALUESkeywordisfollowedbyacommaseparatedlistofoneormorerows.
â¢rowisacomma-separ atedlistofoneormorecolumns.
â¢Eachrowmusthavethesamenumberofcolumns.
â¢columncanbeaconstant,avariable,oranexpression.
â¢Thecorresponding columnsmusthavecompatibledatatypesinallrows.SeethethirdqueryintheExamples
sectionbelow.
â¢Bydefault,thefirstrowisusedtonamecolumns.ButusingtheASkeyword,youcanoptionallygivethecolumn
analias.
â¢IfusedintheSELECTstatement,theASkeywordwithanaliasisrequired.
â¢select_lististhecolumnstobeselectedfortheresultset.
Examples:
> SELECT * FROM (VALUES(4,5,6),(7,8,9)) AS t;
+---+---+---+
| 4 | 5 | 6 |
+---+---+---+
| 4 | 5 | 6 |
| 7 | 8 | 9 |
+---+---+---+
> SELECT * FROM (VALUES(1 AS c1, true AS c2, 'abc' AS c3),(100,false,'xyz')) AS t;
+-----+-------+-----+
| c1  | c2    | c3  |
+-----+-------+-----+
| 1   | true  | abc |
| 100 | false | xyz |
+-----+-------+-----+
> VALUES (CAST('2019-01-01' AS TIMESTAMP)), ('2019-02-02');
+---------------------------------+
| cast('2019-01-01' as timestamp) |
+---------------------------------+
| 2019-01-01 00:00:00             |
| 2019-02-02 00:00:00             |
+---------------------------------+
Relatedinformation:
SELECTStatementonpage295
386|ApacheImpalaGuideImpalaSQLLanguageReference
OptimizerHintsinImpala
TheImpalaSQLdialectsupportsqueryhints,forfine-tuning theinnerworkingsofqueries.Specifyhintsasatemporary
workaroundforexpensivequeries,wheremissingstatisticsorotherfactorscauseinefficientperformance.
Hintsaremostoftenusedforthemostresource-intensivekindsofImpalaqueries:
â¢Joinqueriesinvolvinglargetables,whereintermediateresultsetsaretransmittedacrossthenetworktoevaluate
thejoinconditions.
â¢Inserting intopartitioned Parquettables,wheremanymemorybufferscouldbeallocatedoneachhosttohold
intermediateresultsforeachpartition.
Syntax:
InCDH5.2/Impala2.0andhigher,youcanspecifythehintsinsidecommentsthatuseeitherthe/* */or--notation.
Specifya+symbolimmediatelybeforethehintname.Recentlyaddedhintsareonlyavailableusingthe/* */and
--notation.Forclarity,the/* */and--stylesareusedinthesyntaxandexamplesthroughoutthissection.With
the/* */or--notationforhints,specifya+symbolimmediatelybeforethefirsthintname.Multiplehintscanbe
specified separatedbycommas,forexample/* +clustered,shuffle */
SELECT STRAIGHT_JOIN select_list  FROM
join_left_hand_table
  JOIN /* +BROADCAST|SHUFFLE */
join_right_hand_table
remainder_of_query ;
SELECT select_list  FROM
join_left_hand_table
  JOIN -- +BROADCAST|SHUFFLE
join_right_hand_table
remainder_of_query ;
INSERT insert_clauses
  /* +SHUFFLE|NOSHUFFLE */
  SELECT remainder_of_query ;
INSERT insert_clauses
  -- +SHUFFLE|NOSHUFFLE
  SELECT remainder_of_query ;
INSERT /* +SHUFFLE|NOSHUFFLE */
insert_clauses
  SELECT remainder_of_query ;
INSERT -- +SHUFFLE|NOSHUFFLE
insert_clauses
  SELECT remainder_of_query ;
UPSERT /* +SHUFFLE|NOSHUFFLE */
upsert_clauses
  SELECT remainder_of_query ;
UPSERT -- +SHUFFLE|NOSHUFFLE
upsert_clauses
  SELECT remainder_of_query ;
SELECT select_list  FROM
table_ref
  /* +{SCHEDULE_CACHE_LOCAL | SCHEDULE_DISK_LOCAL | SCHEDULE_REMOTE}
    [,RANDOM_REPLICA] */
remainder_of_query ;
INSERT insert_clauses
  -- +CLUSTERED
  SELECT remainder_of_query ;
INSERT insert_clauses
  /* +CLUSTERED */
  SELECT remainder_of_query ;
ApacheImpalaGuide|387ImpalaSQLLanguageReference
INSERT -- +CLUSTERED
insert_clauses
  SELECT remainder_of_query ;
INSERT /* +CLUSTERED */
insert_clauses
  SELECT remainder_of_query ;
UPSERT -- +CLUSTERED
upsert_clauses
  SELECT remainder_of_query ;
UPSERT /* +CLUSTERED */
upsert_clauses
  SELECT remainder_of_query ;
CREATE /* +SHUFFLE|NOSHUFFLE */
table_clauses
  AS SELECT remainder_of_query ;
CREATE -- +SHUFFLE|NOSHUFFLE
table_clauses
  AS SELECT remainder_of_query ;
CREATE /* +CLUSTERED|NOCLUSTERED */
table_clauses
  AS SELECT remainder_of_query ;
CREATE -- +CLUSTERED|NOCLUSTERED
table_clauses
  AS SELECT remainder_of_query ;
Thesquarebracketstylehintsaresupportedforbackwardcompatibility,butthesyntaxisdeprecatedandwillbe
removedinafuturerelease.Forthatreason,anynewlyaddedhintsarenotavailablewiththesquarebracketsyntax.
SELECT STRAIGHT_JOIN select_list  FROM
join_left_hand_table
  JOIN [{ /* +BROADCAST */ | /* +SHUFFLE */ }]
join_right_hand_table
remainder_of_query ;
INSERT insert_clauses
  [{ /* +SHUFFLE */ | /* +NOSHUFFLE */ }]
  [/* +CLUSTERED */ ]
  SELECT remainder_of_query ;
UPSERT [{ /* +SHUFFLE */ | /* +NOSHUFFLE */ }]
  [/* +CLUSTERED */ ]
upsert_clauses
  SELECT remainder_of_query ;
Usagenotes:
Withbothformsofhintsyntax,includetheSTRAIGHT_JOIN keywordimmediatelyaftertheSELECTandanyDISTINCT
orALLkeywordstopreventImpalafromreorderingthetablesinawaythatmakesthejoin-relatedhintsineffective.
TheSTRAIGHT_JOIN hintaffectsthejoinorderoftablereferencesinthequeryblockcontainingthehint.Itdoesnot
affectthejoinorderofnestedqueries,suchasviews,inlineviews,orWHERE-clausesubqueries. Tousethishintfor
performance tuningofcomplexqueries,applythehinttoallqueryblocksthatneedafixedjoinorder.
Toreducetheneedtousehints,runtheCOMPUTE STATS statementagainstalltablesinvolvedinjoins,orusedasthe
sourcetablesforINSERT ... SELECT operationswherethedestinationisapartitioned Parquettable.Dothis
operationafterloadingdataormakingsubstantialchangestothedatawithineachtable.Havingup-to-datestatistics
helpsImpalachoosemoreefficientqueryplanswithouttheneedforhinting.SeeTableandColumnStatisticsonpage
575fordetailsandexamples.
Toseewhichjoinstrategyisusedforaparticular query,examinetheEXPLAIN outputforthatquery.SeeUsingthe
EXPLAINPlanforPerformance Tuningonpage602fordetailsandexamples.
388|ApacheImpalaGuideImpalaSQLLanguageReference
Hintsforjoinqueries:
The/* +BROADCAST */ and/* +SHUFFLE */ hintscontroltheexecutionstrategyforjoinqueries.Specifyoneof
thefollowingconstructsimmediatelyaftertheJOINkeywordinaquery:
â¢/* +SHUFFLE */ makesthatjoinoperationusetheâpartitionedâ technique, whichdividesupcorresponding
rowsfrombothtablesusingahashingalgorithm,sendingsubsetsoftherowstoothernodesforprocessing. (The
keywordSHUFFLE isusedtoindicateaâpartitioned joinâ,becausethattypeofjoinisnotrelatedtoâpartitioned
tablesâ.)Sincethealternativeâbroadcastâjoinmechanism isthedefaultwhentableandindexstatisticsare
unavailable,youmightusethishintforquerieswherebroadcastjoinsareunsuitable;typically,partitioned joins
aremoreefficientforjoinsbetweenlargetablesofsimilarsize.
â¢/* +BROADCAST */ makesthatjoinoperationusetheâbroadcastâtechnique thatsendstheentirecontentsof
theright-handtabletoallnodesinvolvedinprocessingthejoin.Thisisthedefaultmodeofoperationwhentable
andindexstatisticsareunavailable,soyouwouldtypicallyonlyneeditifstalemetadatacausedImpalatomistakenly
chooseapartitioned joinoperation.Typically,broadcastjoinsaremoreefficientincaseswhereonetableismuch
smallerthantheother.(PutthesmallertableontherightsideoftheJOINoperator.)
HintsforINSERT...SELECTandCREATETABLEASSELECT(CTAS):
Wheninserting intopartitioned tables,suchasusingtheParquetfileformat,youcanincludeahintintheINSERTor
CREATE TABLE AS SELECT(CTAS) statementstofine-tune theoverallperformanceoftheoperationanditsresource
usage.
YouwouldonlyusehintsifanINSERTorCTASintoapartitioned tablewasfailingduetocapacitylimits,orifsuchan
operationwassucceeding butwithless-than-op timalperformance.
â¢/* +SHUFFLE */ and/* +NOSHUFFLE */ Hints
â/* +SHUFFLE */ addsanexchangenode,beforewritingthedata,whichre-partitions theresultofthe
SELECTbasedonthepartitioning columnsofthetargettable.Withthishint,onlyonenodewritestoa
partitionatatime,minimizing theglobalnumberofsimultaneouswritesandthenumberofmemorybuffers
holdingdataforindividual partitions. Thisalsoreducesfragmentation,resultinginfewerfiles.Thusitreduces
overallresourceusageoftheINSERTorCTASoperationandallowssomeoperationstosucceedthatotherwise
wouldfail.Itdoesinvolvesomedatatransferbetweenthenodessothatthedatafilesforaparticular partition
areallwrittenonthesamenode.
Use/* +SHUFFLE */ incaseswhereanINSERTorCTASstatementfailsorrunsinefficientlyduetoall
nodesattemptingtowritedataforallpartitions.
Ifthetableisunpartitioned oreverypartitioning expressionisconstant,then/* +SHUFFLE */ willcause
everywritetohappenonthecoordinatornode.
â/* +NOSHUFFLE */ doesnotaddexchangenodebeforeinserting topartitioned tablesanddisables
re-partitioning. Sotheselectedexecutionplanmightbefasteroverall,butmightalsoproducealargernumber
ofsmalldatafilesorexceedcapacitylimits,causingtheINSERTorCTASoperationtofail.
Impalaautomaticallyusesthe/* +SHUFFLE */ methodifanypartition keycolumninthesourcetable,
mentionedintheSELECTclause,doesnothavecolumnstatistics.Inthiscase,usethe/* +NOSHUFFLE */
hintifyouwanttooverridethisdefaultbehavior.
âIfcolumnstatisticsareavailableforallpartition keycolumnsinthesourcetablementionedintheINSERT
... SELECT orCTASquery,Impalachooseswhethertousethe/* +SHUFFLE */ or/* +NOSHUFFLE */
technique basedontheestimatednumberofdistinctvaluesinthosecolumnsandthenumberofnodes
involvedintheoperation.Inthiscase,youmightneedthe/* +SHUFFLE */ orthe/* +NOSHUFFLE */
hinttooverridetheexecutionplanselectedbyImpala.
â¢/* +CLUSTERED */ and/* +NOCLUSTERED */ Hints
â/* +CLUSTERED */ sortsdatabythepartition columnsbeforeinserting toensurethatonlyonepartition
iswrittenatatimepernode.Usethishinttoreducethenumberoffileskeptopenandthenumberofbuffers
keptinmemorysimultaneously.Thistechnique isprimarily usefulforinsertsintoParquettables,wherethe
largeblocksizerequiressubstantialmemorytobufferdataformultipleoutputfilesatonce.Thishintis
availableinCDH5.10/Impala2.8orhigher.
ApacheImpalaGuide|389ImpalaSQLLanguageReference
StartinginCDH6.0/Impala3.0,/* +CLUSTERED */ isthedefaultbehaviorforHDFStables.
â/* +NOCLUSTERED */ doesnotsortbyprimarykeybeforeinsert.ThishintisavailableinCDH5.10/Impala
2.8orhigher.
Usethishintwheninserting toKudutables.
IntheversionslowerthanCDH6.0/Impala3.0,/* +NOCLUSTERED */ isthedefaultinHDFStables.
Kuduconsideration:
StartingfromCDH5.12/Impala2.9,theINSERTorUPSERToperationsintoKudutablesautomaticallyaddanexchange
andasortnodetotheplanthatpartitions andsortstherowsaccordingtothepartitioning /primarykeyschemeofthe
targettable(unlessthenumberofrowstobeinsertedissmallenoughtotriggersinglenodeexecution). SinceKudu
partitions andsortsrowsonwrite,pre-partitioning andsortingtakessomeoftheloadoffofKuduandhelpslarge
INSERToperationstocompletewithouttimingout.However,thisdefaultbehaviormayslowdowntheend-to-end
performance oftheINSERTorUPSERToperations.StartingfromCDH5.13/Impala2.10,youcanusethe /*
+NOCLUSTERED */ and/* +NOSHUFFLE */ hintstogethertodisablepartitioning andsortingbeforetherowsare
senttoKudu.Additionally ,sincesortingmayconsumealargeamountofmemory,considersettingtheMEM_LIMIT
queryoptionforthosequeries.
Hintsforscheduling ofscanranges(HDFSdatablocksorKudutablets):
Thehints/* +SCHEDULE_CACHE_LOCAL */ ,/* +SCHEDULE_DISK_LOCAL */ ,and/* +SCHEDULE_REMOTE */
havethesameeffectasspecifyingtheREPLICA_PREFERENCE queryoptionwiththerespectiveoptionsettingsof
CACHE_LOCAL ,DISK_LOCAL ,orREMOTE.
Specifyingthereplicapreferenceasaqueryhintalwaysoverridesthequeryoptionsetting.
Thehint/* +RANDOM_REPLICA */ isthesameasenablingtheSCHEDULE_RANDOM_REPLICA queryoption.
Youcanusethesehintsincombinationbyseparatingthemwithcommas,forexample,/*
+SCHEDULE_CACHE_LOCAL,RANDOM_REPLICA */ .SeeREPLICA_PREFERENCE QueryOption(CDH5.9orhigheronly)
onpage355andSCHEDULE_RANDOM_REPLICA QueryOption(CDH5.7orhigheronly)onpage360forinformation
abouthowthesesettingsinfluencethewayImpalaprocessesHDFSdatablocksorKudutablets.
SpecifyingeithertheSCHEDULE_RANDOM_REPLICA queryoptionorthecorresponding RANDOM_REPLICA queryhint
enablestherandomtie-breakingbehaviorwhenprocessingdatablocksduringthequery.
Suggestionsversusdirectives:
InearlyImpalareleases,hintswerealwaysobeyedandsoactedmorelikedirectives.OnceImpalagainedjoinorder
optimizations,sometimesjoinquerieswereautomaticallyreorderedinawaythatmadeahintirrelevant.Therefore,
thehintsactmorelikesuggestionsinImpala1.2.2andhigher.
ToforceImpalatofollowthehintedexecutionmechanism forajoinquery,includetheSTRAIGHT_JOIN keywordin
theSELECTstatement.SeeOverridingJoinReorderingwithSTRAIGHT_JOIN onpage569fordetails.Whenyouuse
thistechnique, Impaladoesnotreorderthejoinedtablesatall,soyoumustbecarefultoarrangethejoinordertoput
thelargesttable(orsubqueryresultset)first,thenthesmallest,secondsmallest,thirdsmallest,andsoon.Thisordering
letsImpaladothemostI/O-intensivepartsofthequeryusinglocalreadsontheDataNodes,andthenreducethesize
oftheintermediateresultsetasmuchaspossibleaseachsubsequenttableorsubqueryresultsetisjoined.
Restrictions:
Queriesthatincludesubqueries intheWHEREclausecanberewritteninternallyasjoinqueries.Currently,youcannot
applyhintstothejoinsproducedbythesetypesofqueries.
Becausehintscanpreventqueriesfromtakingadvantageofnewmetadataorimprovementsinqueryplanning,use
themonlywhenrequiredtoworkaroundperformance issues,andbepreparedtoremovethemwhentheyareno
longerrequired,suchasafteranewImpalareleaseorbugfix.
Inparticular ,the/* +BROADCAST */ and/* +SHUFFLE */ hintsareexpectedtobeneededmuchlessfrequently
inImpala1.2.2andhigher,becausethejoinorderoptimizationfeatureincombinationwiththeCOMPUTE STATS
390|ApacheImpalaGuideImpalaSQLLanguageReference
statementnowautomaticallychoosejoinorderandjoinmechanism withouttheneedtorewritethequeryandadd
hints.SeePerformance ConsiderationsforJoinQueriesonpage568fordetails.
Compatibility:
Thehintsembedded within--commentsarecompatiblewithHivequeries.Thehintsembedded within/* */
commentsor[ ]squarebracketsarenotrecognizedbyornotcompatiblewithHive.Forexample,Hiveraisesanerror
forImpalahintswithin/* */commentsbecauseitdoesnotrecognizetheImpalahintnames.
Considerationsforviews:
Ifyouuseahintinthequerythatdefinesaview,thehintispreservedwhenyouquerytheview.Impalainternally
rewritesallhintsinviewstousethe--commentnotation,sothatHivecanquerysuchviewswithouterrorsdueto
unrecognizedhintnames.
Examples:
Forexample,thisqueryjoinsalargecustomertablewithasmalllookuptableoflessthan100rows.Theright-hand
tablecanbebroadcastefficientlytoallnodesinvolvedinthejoin.Thus,youwouldusethe/* +broadcast */ hint
toforceabroadcastjoinstrategy:
select straight_join customer.address, state_lookup.state_name
  from customer join /* +broadcast */  state_lookup
  on customer.state_id = state_lookup.state_id;
Thisqueryjoinstwolargetablesofunpredictablesize.Youmightbenchmark thequerywithbothkindsofhintsand
findthatitismoreefficienttotransmitportionsofeachtabletoothernodesforprocessing. Thus,youwouldusethe
/* +shuffle */ hinttoforceapartitioned joinstrategy:
select straight_join weather.wind_velocity, geospatial.altitude
  from weather join /* +shuffle */  geospatial
  on weather.lat = geospatial.lat and weather.long = geospatial.long;
Forjoinsinvolvingthreeormoretables,thehintappliestothetablesoneithersideofthatspecificJOINkeyword.
TheSTRAIGHT_JOIN keywordensuresthatjoinsareprocessedinapredictableorderfromlefttoright.Forexample,
thisqueryjoinst1andt2usingapartitioned join,thenjoinsthatresultsettot3usingabroadcastjoin:
select straight_join t1.name, t2.id, t3.price
  from t1 join /* +shuffle */  t2 join /* +broadcast */  t3
  on t1.id = t2.id and t2.id = t3.id;
Relatedinformation:
Formorebackgroundinformationaboutjoinqueries,seeJoinsinImpalaSELECTStatementsonpage296.Forperformance
considerations,seePerformance ConsiderationsforJoinQueriesonpage568.
ImpalaBuilt-InFunctions
Impalasupports severalcategoriesofbuilt-infunctions. Thesefunctions letyouperformmathematicalcalculations,
stringmanipula tion,datecalculations,andotherkindsofdatatransformationsdirectlyinSQLstatements.
Thecategoriesofbuilt-infunctions supportedbyImpalaare:
â¢ImpalaMathematicalFunctions onpage397
â¢ImpalaTypeConversionFunctions onpage423
â¢ImpalaDateandTimeFunctions onpage424
â¢ImpalaConditional Functions onpage457
â¢ImpalaStringFunctions onpage462
â¢ImpalaAggregateFunctions onpage479.
â¢ImpalaAnalyticFunctions onpage506
â¢ImpalaBitFunctions onpage414
ApacheImpalaGuide|391ImpalaSQLLanguageReference
â¢ImpalaMiscellaneous Functions onpage477
Thefollowingisacompletelistofbuilt-infunctions supportedinImpala:
ABS
ACOS
ADD_MONTHS
ADDDATE
APPX_MEDIAN
ASCII
ASIN
ATAN
ATAN2
AVG
AVG-AnalyticFunction
BASE64DECODE
BASE64ENC ODE
BITAND
BIN
BITNOT
BITOR
BITXOR
BTRIM
CASE
CASEWHEN
CAST
CEIL,CEILING,DCEIL
CHAR_LENG TH
CHR
COALESCE
CONCAT
CONCAT_WS
CONV
COS
COSH
COT
COUNT
COUNT-AnalyticFunction
392|ApacheImpalaGuideImpalaSQLLanguageReference
COUNTSET
CUME_DIS T
CURRENT_D ATABASE
CURRENT_TIME STAMP
DATE_ADD
DATE_PART
DATE_SUB
DATE_TRUNC
DATEDIFF
DAY
DAYNAME
DAYOFWEEK
DAYOFYEAR
DAYS_ADD
DAYS_SUB
DECODE
DEGREES
DENSE_RANK
E
EFFECTIVE_USER
EXP
EXTRACT
FACTORIAL
FIND_IN_SET
FIRST_VALUE
FLOOR,DFLOOR
FMOD
FNV_HASH
GET_JSON_OBJE CT
FROM_UNIXTIME
FROM_TIME STAMP
FROM_UTC_TIMESTAMP
GETBIT
GREATEST
GROUP_CONCAT
GROUP_CONCAT-AnalyticFunction
ApacheImpalaGuide|393ImpalaSQLLanguageReference
HEX
HOUR
HOURS_ADD
HOURS_SUB
IF
IFNULL
INITCAP
INSTR
INT_MONTHS_BETWEEN
IS_INF
IS_NAN
ISFALSE
ISNOTFALSE
ISNOTTRUE
ISNULL
ISTRUE
LAG
LAST_VALUE
LEAD
LEAST
LEFT
LENGTH
LN
LOCATE
LOG
LOG10
LOG2
LOWER,LCASE
LPAD
LTRIM
MAX
MAX-AnalyticFunction
MAX_INT,MAX_TINYINT ,MAX_SMALLINT ,MAX_BIGINT
MICROSECONDS_ADD
MICROSECONDS_SUB
MILLISECOND
394|ApacheImpalaGuideImpalaSQLLanguageReference
MILLISECONDS_ADD
MILLISECONDS_SUB
MIN
MIN-AnalyticFunction
MIN_INT,MIN_TINYINT ,MIN_SMALLINT ,MIN_BIGINT
MINUTE
MINUTES_ADD
MINUTES_SUB
MOD
MONTH
MONTHNAME
MONTHS_ADD
MONTHS_BETWEEN
MONTHS_SUB
MURMUR_HASH
NANOSECONDS_ADD
NANOSECONDS_SUB
NDV
NEGATIVE
NEXT_DAY
NONNULL VALUE
NOW
NTILE
NULLIF
NULLIFZERO
NULLVALUE
NVL
NVL2
OVERClause
PARSE_URL
PERCENT_RANK
PI
PID
PMOD
POSITIVE
POW,POWER,DPOW,FPOW
ApacheImpalaGuide|395ImpalaSQLLanguageReference
PRECISION
QUARTER
QUOTIENT
RADIANS
RAND,RANDOM
RANK
REGEXP_ESCAPE
REGEXP_EXTRA CT
REGEXP_LIKE
REGEXP_REPLA CE
REPEAT
REPLACE
REVERSE
RIGHT
ROTATELEFT
ROTATERIGHT
ROUND,DROUND
ROW_NUMBER
RPAD
RTRIM
SCALE
SECOND
SECONDS_ADD
SECONDS_SUB
SETBIT
SHIFTLEFT
SHIFTRIGHT
SIGN
SIN
SINH
SLEEP
SPACE
SPLIT_PART
SQRT
STDDEV,STDDEV_SAMP,STDDEV_POP
STRLEFT
396|ApacheImpalaGuideImpalaSQLLanguageReference
STRRIGHT
SUBDATE
SUBSTR,SUBSTRING
SUM
SUM-AnalyticFunction
TAN
TANH
TIMEOFDAY
TIMESTAMP_CMP
TO_DATE
TO_TIMESTAMP
TO_UTC_TIMESTAMP
TRANSLATE
TRIM
TRUNC
TRUNCATE,DTRUNC,TRUNC
TYPEOF
UNHEX
UNIX_TIME STAMP
UPPER,UCASE
USER
UTC_TIMESTAMP
UUID
VARIANCE, VARIANCE_S AMP,VARIANCE_POP ,VAR_SAMP,VAR_POP
VERSION
WEEKOFYEAR
WEEKS_ADD
WEEKS_SUB
WIDTH_BUCKET
YEAR
YEARS_ADD
YEARS_SUB
ZEROIFNULL
ImpalaMathematicalFunctions
Mathematicalfunctions, orarithmeticfunctions, performnumericcalculationsthataretypicallymorecomplexthan
basicaddition,subtraction,multiplication,anddivision.Forexample,thesefunctions includetrigonometric,logarithmic,
andbaseconversionoperations.
ApacheImpalaGuide|397ImpalaSQLLanguageReference
Note:InImpala,exponentiationusesthePOW()functionratherthananexponentiationoperator
suchas**.
Relatedinformation:
Themathematicalfunctions operatemainlyonthesedatatypes:INTDataTypeonpage117,BIGINTDataTypeonpage
105,SMALLINT DataTypeonpage122,TINYINTDataTypeonpage136,DOUBLEDataTypeonpage114,FLOATData
Typeonpage116,andDECIMALDataType(CDH6.0/Impala3.0orhigheronly)onpage109.Fortheoperatorsthat
performthestandardoperationssuchasaddition, subtraction,multiplication,anddivision,seeArithmeticOperators
onpage171.
Functions thatperformbitwiseoperationsareexplainedinImpalaBitFunctions onpage414.
Function reference:
Impalasupports thefollowingmathematicalfunctions:
â¢ABS
â¢ACOS
â¢ASIN
â¢ATAN
â¢ATAN2
â¢BIN
â¢CEIL,CEILING,DCEIL
â¢CONV
â¢COS
â¢COSH
â¢COT
â¢DEGREES
â¢E
â¢EXP
â¢FACTORIAL
â¢FLOOR,DFLOOR
â¢FMOD
â¢FNV_HASH
â¢GREATEST
â¢HEX
â¢IS_INF
â¢IS_NAN
â¢LEAST
â¢LN
â¢LOG
â¢LOG10
â¢LOG2
â¢MAX_INT,MAX_TINYINT ,MAX_SMALLINT ,MAX_BIGINT
â¢MIN_INT,MIN_TINYINT ,MIN_SMALLINT ,MIN_BIGINT
â¢MOD
â¢MURMUR_HASH
â¢NEGATIVE
â¢PI
â¢PMOD
â¢POSITIVE
â¢POW,POWER,DPOW,FPOW
398|ApacheImpalaGuideImpalaSQLLanguageReference
â¢PRECISION
â¢QUOTIENT
â¢RADIANS
â¢RAND,RANDOM
â¢ROUND,DROUND
â¢SCALE
â¢SIGN
â¢SIN
â¢SINH
â¢SQRT
â¢TAN
â¢TANH
â¢TRUNCATE,DTRUNC,TRUNC
â¢UNHEX
â¢WIDTH_BUCKET
ABS(numeric_type a)
Purpose: Returnstheabsolutevalueoftheargument.
Returntype:Sameastheinputvalue
Usagenotes:Usethisfunctiontoensureallreturnvaluesarepositive.Thisisdifferentthanthepositive()
function, whichreturnsitsargumentunchanged(eveniftheargumentwasnegative).
ACOS(DOUBLE a)
Purpose: Returnsthearccosineoftheargument.
Returntype:DOUBLE
ASIN(DOUBLE a)
Purpose: Returnsthearcsineoftheargument.
Returntype:DOUBLE
ATAN(DOUBLE a)
Purpose: Returnsthearctangentoftheargument.
Returntype:DOUBLE
ATAN(DOUBLE a,DOUBLEb)
Purpose: Returnsthearctangentofthetwoarguments,withthesignsoftheargumentsusedtodeterminethe
quadrantoftheresult.
Returntype:DOUBLE
BIN(BIGINT a)
Purpose: Returnsthebinaryrepresentationofanintegervalue,thatis,astringof0and1digits.
Returntype:STRING
CEIL(DOUBLE a),CEIL(DECIMAL(p,s) a),CEILING(DOUBLE a),CEILING(DE CIMAL(p,s) a),DCEIL(DOUBLE a),
DCEIL(DECIMAL(p,s) a)
Purpose: Returnsthesmallestintegerthatisgreaterthanorequaltotheargument.
Returntype:Sameastheinputtype
CONV(BIGINT n,INTfrom_base, INTto_base),CONV(STRINGs,INTfrom_base, INTto_base)
Purpose: Returnsastringrepresentationofthefirstargumentconvertedfromfrom_base toto_base .Thefirst
argumentcanbespecified asanumberorastring.Forexample,conv(100, 2, 10) andconv('100', 2, 10)
bothreturn'4'.
ApacheImpalaGuide|399ImpalaSQLLanguageReference
Returntype:STRING
Usagenotes:
Ifto_base isnegative,thefirstargumentistreatedassigned,andotherwise,itistreatedasunsigned. Forexample:
â¢conv(-17, 10, -2) returns'-10001' , -17inbase2.
â¢conv(-17, 10, 10) returns'18446744073709551599' .-17isinterpretedasanunsigned, 2^64-17, and
thenthevalueisreturnedinbase10.
ThefunctionreturnsNULLwhenthefollowingillegalargumentsarespecified:
â¢AnyargumentisNULL.
â¢from_base orto_base isbelow-36orabove36.
â¢from_base orto_base is-1,0,or1.
â¢Thefirstargumentrepresentsapositivenumberandfrom_base isanegativenumber.
Ifthefirstargumentrepresentsanegativenumberandfrom_base isanegativenumber,thefunctionreturns0.
Ifthefirstargumentrepresentsanumberlargerthanthemaximumbigint,thefunctionreturns:
â¢Thestringrepresentationof-1into_base ifto_base isnegative.
â¢Thestringrepresentationof18446744073709551615' (2^64-1)into_base ifto_base ispositive.
Ifthefirstargumentdoesnotrepresentavalidnumberinfrom_base ,e.g.3inbase2or'1a23'inbase10,the
digitsinthefirstargumentareevaluatedfromleft-to-rightandusedifavaliddigitinfrom_base .Theinvaliddigit
andthedigitstotherightareignored.
Forexample:
â¢conv(445, 5, 10) isconvertedtoconv(44, 5, 10) andreturns'24'.
â¢conv('1a23', 10, 16) isconvertedtoconv('1', 10 , 16) andreturns'1'.
COS(DOUBLE a)
Purpose: Returnsthecosineoftheargument.
Returntype:DOUBLE
COSH(DOUBLE a)
Purpose: Returnsthehyperbolic cosineoftheargument.
Returntype:DOUBLE
COT(DOUBLE a)
Purpose: Returnsthecotangentoftheargument.
Returntype:DOUBLE
Addedin:CDH5.5.0/Impala2.3.0
DEGREES(DOUBLE a)
Purpose: Convertsargumentvaluefromradianstodegrees.
Returntype:DOUBLE
E()
Purpose: Returnsthemathematicalconstante.
Returntype:DOUBLE
EXP(DOUBLE a),DEXP(DOUBLE a)
Purpose: Returnsthemathematicalconstanteraisedtothepoweroftheargument.
Returntype:DOUBLE
400|ApacheImpalaGuideImpalaSQLLanguageReference
FACTORIAL(integer_typea)
Purpose: Computesthefactorialofanintegervalue.Itworkswithanyintegertype.
Addedin:CDH5.5.0/Impala2.3.0
Usagenotes:Youcanuseeitherthefactorial() functionorthe!operator.Thefactorialof0is1.Likewise,the
factorial() functionreturns1foranynegativevalue.Themaximumpositivevaluefortheinputargumentis20;
avalueof21orgreateroverflowstherangeforaBIGINTandcausesanerror.
Returntype:BIGINT
Addedin:CDH5.5.0/Impala2.3.0
select factorial(5);
+--------------+
| factorial(5) |
+--------------+
| 120          |
+--------------+
select 5!;
+-----+
| 5!  |
+-----+
| 120 |
+-----+
FLOOR(DOUBLE a),FLOOR(DECIMAL(p,s) a),DFLOOR(DOUBLE a),DFLOOR(DECIMAL(p,s) a)
Purpose: Returnsthelargestintegerthatislessthanorequaltotheargument.
Returntype:Sameastheinputtype
FMOD(DOUBLE a,DOUBLEb),FMOD(FL OATa,FLOATb)
Purpose: Returnsthemodulusofafloating-pointnumber.
Returntype:FLOATorDOUBLE,depending ontypeofarguments
Addedin:Impala1.1.1
Usagenotes:
BecausethisfunctionoperatesonDOUBLEorFLOATvalues,itissubjecttopotentialroundingerrorsforvaluesthat
cannotberepresentedprecisely.Prefertousewholenumbers,orvaluesthatyouknowcanberepresentedprecisely
bytheDOUBLEorFLOATtypes.
Examples:
Thefollowingexamplesshowequivalentoperationswiththefmod()functionandthe%arithmeticoperator,for
valuesnotsubjecttoanyroundingerror.
select fmod(10,3);
+-------------+
| fmod(10, 3) |
+-------------+
| 1           |
+-------------+
select fmod(5.5,2);
+--------------+
| fmod(5.5, 2) |
+--------------+
| 1.5          |
+--------------+
select 10 % 3;
+--------+
| 10 % 3 |
+--------+
ApacheImpalaGuide|401ImpalaSQLLanguageReference
| 1      |
+--------+
select 5.5 % 2;
+---------+
| 5.5 % 2 |
+---------+
| 1.5     |
+---------+
Thefollowingexamplesshowoperationswiththefmod()functionforvaluesthatcannotberepresentedprecisely
bytheDOUBLEorFLOATtypes,andthusaresubjecttoroundingerror.fmod(9.9,3.0) returnsavalueslightly
differentthantheexpected0.9becauseofrounding.fmod(9.9,3.3) returnsavaluequitedifferentfromthe
expectedvalueof0becauseofroundingerrorduringintermediatecalculations.
select fmod(9.9,3.0);
+--------------------+
| fmod(9.9, 3.0)     |
+--------------------+
| 0.8999996185302734 |
+--------------------+
select fmod(9.9,3.3);
+-------------------+
| fmod(9.9, 3.3)    |
+-------------------+
| 3.299999713897705 |
+-------------------+
FNV_HASH(type v)
Purpose: Returnsaconsistent64-bitvaluederivedfromtheinputargument,forconvenienceofimplemen ting
hashinglogicinanapplication.
Returntype:BIGINT
Usagenotes:
Youmightusethereturnvalueinanapplicationwhereyouperformloadbalancing ,bucketing,orsomeother
technique todivideprocessingorstorage.
Becausetheresultcanbeany64-bitvalue,torestrictthevaluetoaparticular range,youcanuseanexpression
thatincludestheABS()functionandthe%(modulo) operator.Forexample,toproduceahashvalueintherange
0-9,youcouldusetheexpressionABS(FNV_HASH(x)) % 10 .
Thisfunctionimplemen tsthesamealgorithmthatImpalausesinternallyforhashing,onsystemswheretheCRC32
instructions arenotavailable.
Thisfunctionimplemen tstheFowlerâNollâV ohashfunction,inparticular theFNV-1avariation.Thisisnotaperfect
hashfunction: somecombinationsofvaluescouldproducethesameresultvalue.Itisnotsuitableforcryptographic
use.
Similarinputvaluesofdifferenttypescouldproducedifferenthashvalues,forexamplethesamenumericvalue
representedasSMALLINT orBIGINT,FLOATorDOUBLE,orDECIMAL(5,2) orDECIMAL(20,5) .
Examples:
[localhost:21000] > create table h (x int, s string);
[localhost:21000] > insert into h values (0, 'hello'), (1,'world'), 
(1234567890,'antidisestablishmentarianism');
[localhost:21000] > select x, fnv_hash(x) from h;
+------------+----------------------+
| x          | fnv_hash(x)          |
+------------+----------------------+
| 0          | -2611523532599129963 |
| 1          | 4307505193096137732  |
| 1234567890 | 3614724209955230832  |
+------------+----------------------+
402|ApacheImpalaGuideImpalaSQLLanguageReference
[localhost:21000] > select s, fnv_hash(s) from h;
+------------------------------+---------------------+
| s                            | fnv_hash(s)         |
+------------------------------+---------------------+
| hello                        | 6414202926103426347 |
| world                        | 6535280128821139475 |
| antidisestablishmentarianism | -209330013948433970 |
+------------------------------+---------------------+
[localhost:21000] > select s, abs(fnv_hash(s)) % 10 from h;
+------------------------------+-------------------------+
| s                            | abs(fnv_hash(s)) % 10.0 |
+------------------------------+-------------------------+
| hello                        | 8                       |
| world                        | 6                       |
| antidisestablishmentarianism | 4                       |
+------------------------------+-------------------------+
Forshortargumentvalues,thehigh-orderbitsoftheresulthaverelativelylowentropy:
[localhost:21000] > create table b (x boolean);
[localhost:21000] > insert into b values (true), (true), (false), (false);
[localhost:21000] > select x, fnv_hash(x) from b;
+-------+---------------------+
| x     | fnv_hash(x)         |
+-------+---------------------+
| true  | 2062020650953872396 |
| true  | 2062020650953872396 |
| false | 2062021750465500607 |
| false | 2062021750465500607 |
+-------+---------------------+
Addedin:Impala1.2.2
GREATEST(BIGINT a[,BIGINTb...]),GREATEST(DOUBLE a[,DOUBLEb...]),GREATEST(DECIMAL(p,s) a[,DECIMAL(p,s)
b...]),GREATEST(STRINGa[,STRINGb...]),GREATEST(TIMESTAMPa[,TIMESTAMPb...])
Purpose: Returnsthelargestvaluefromalistofexpressions.
Returntype:sameastheinitialargumentvalue,exceptthatintegervaluesarepromotedtoBIGINTandfloating-point
valuesarepromotedtoDOUBLE;useCAST()wheninserting intoasmallernumericcolumn
HEX(BIGINT a),HEX(STRINGa)
Purpose: Returnsthehexadecimal representationofanintegervalue,orofthecharactersinastring.
Returntype:STRING
IS_INF(DOUBLE a)
Purpose: Testswhetheravalueisequaltothespecialvalueâinfâ,signifyinginfinity.
Returntype:BOOLEAN
Usagenotes:
InfinityandNaNcanbespecified intextdatafilesasinfandnanrespectively,andImpalainterpretsthemasthese
specialvalues.Theycanalsobeproducedbycertainarithmeticexpressions;forexample,1/0returnsInfinity
andpow(-1, 0.5) returnsNaN.Oryoucancasttheliteralvalues,suchasCAST('nan' AS DOUBLE) or
CAST('inf' AS DOUBLE) .
IS_NAN(DOUBLE a)
Purpose: TestswhetheravalueisequaltothespecialvalueâNaNâ,signifyingânotanumberâ.
Returntype:BOOLEAN
Usagenotes:
InfinityandNaNcanbespecified intextdatafilesasinfandnanrespectively,andImpalainterpretsthemasthese
specialvalues.Theycanalsobeproducedbycertainarithmeticexpressions;forexample,1/0returnsInfinity
ApacheImpalaGuide|403ImpalaSQLLanguageReference
andpow(-1, 0.5) returnsNaN.Oryoucancasttheliteralvalues,suchasCAST('nan' AS DOUBLE) or
CAST('inf' AS DOUBLE) .
LEAST(BIGINT a[,BIGINTb...]),LEAST(DOUBLE a[,DOUBLEb...]),LEAST(DECIMAL(p,s) a[,DECIMAL(p,s) b...]),
LEAST(STRINGa[,STRINGb...]),LEAST(TIMESTAMPa[,TIMESTAMPb...])
Purpose: Returnsthesmallestvaluefromalistofexpressions.
Returntype:sameastheinitialargumentvalue,exceptthatintegervaluesarepromotedtoBIGINTandfloating-point
valuesarepromotedtoDOUBLE;useCAST()wheninserting intoasmallernumericcolumn
LN(DOUBLE a),DLOG1(DOUBLE a)
Purpose: Returnsthenaturallogarithmoftheargument.
Returntype:DOUBLE
LOG(DOUBLE base,DOUBLEa)
Purpose: Returnsthelogarithmofthesecondargumenttothespecified base.
Returntype:DOUBLE
LOG10(DOUBLE a),DLOG10(DOUBLE a)
Purpose: Returnsthelogarithmoftheargumenttothebase10.
Returntype:DOUBLE
LOG2(DOUBLE a)
Purpose: Returnsthelogarithmoftheargumenttothebase2.
Returntype:DOUBLE
MAX_INT() ,MAX_TINYINT() ,MAX_SMALLINT() ,MAX_BIGINT()
Purpose: Returnsthelargestvalueoftheassociatedintegraltype.
Returntype:Thesameastheintegraltypebeingchecked.
Usagenotes:Usethecorresponding min_andmax_functions tocheckifallvaluesinacolumnarewithinthe
allowedrange,beforecopyingdataoralteringcolumndefinitions. Ifnot,switchtothenexthigherintegraltypeor
toaDECIMAL withsufficientprecision.
MIN_INT() ,MIN_TINYINT() ,MIN_SMALLINT() ,MIN_BIGINT()
Purpose: Returnsthesmallestvalueoftheassociatedintegraltype(anegativenumber).
Returntype:Thesameastheintegraltypebeingchecked.
Usagenotes:Usethecorresponding min_andmax_functions tocheckifallvaluesinacolumnarewithinthe
allowedrange,beforecopyingdataoralteringcolumndefinitions. Ifnot,switchtothenexthigherintegraltypeor
toaDECIMAL withsufficientprecision.
MOD(numeric_type a,same_type b)
Purpose: Returnsthemodulusofanumber.Equivalenttothe%arithmeticoperator.Workswithanysizeinteger
type,anysizefloating-pointtype,andDECIMAL withanyprecisionandscale.
Returntype:Sameastheinputvalue
Addedin:CDH5.4.0/Impala2.2.0
Usagenotes:
BecausethisfunctionworkswithDECIMAL values,preferitoverfmod()whenworkingwithfractionalvalues.Itis
notsubjecttotheroundingerrorsthatmakefmod()problematicwithfloating-pointnumbers.
QueryplansshowstheMOD()functionasthe%operator.
Examples:
404|ApacheImpalaGuideImpalaSQLLanguageReference
Thefollowingexamplesshowhowthemod()functionworksforwholenumbersandfractionalvalues,andhow
the%operatorworksthesameway.Inthecaseofmod(9.9,3) ,thetypeconversionforthesecondargument
resultsinthefirstargumentbeinginterpretedasDOUBLE,sotoproduceanaccurateDECIMAL resultrequirescasting
thesecondargumentorwritingitasaDECIMAL literal,3.0.
select mod(10,3);
+-------------+
| mod(10, 3) |
+-------------+
| 1           |
+-------------+
select mod(5.5,2);
+--------------+
| mod(5.5, 2) |
+--------------+
| 1.5          |
+--------------+
select 10 % 3;
+--------+
| 10 % 3 |
+--------+
| 1      |
+--------+
select 5.5 % 2;
+---------+
| 5.5 % 2 |
+---------+
| 1.5     |
+---------+
select mod(9.9,3.3);
+---------------+
| mod(9.9, 3.3) |
+---------------+
| 0.0           |
+---------------+
select mod(9.9,3);
+--------------------+
| mod(9.9, 3)        |
+--------------------+
| 0.8999996185302734 |
+--------------------+
select mod(9.9, cast(3 as decimal(2,1)));
+-----------------------------------+
| mod(9.9, cast(3 as decimal(2,1))) |
+-----------------------------------+
| 0.9                               |
+-----------------------------------+
select mod(9.9,3.0);
+---------------+
| mod(9.9, 3.0) |
+---------------+
| 0.9           |
+---------------+
MURMUR_HASH(type v)
Purpose: Returnsaconsistent64-bitvaluederivedfromtheinputargument,forconvenienceofimplemen ting
MurmurHash2 non-cryptographichashfunction.
Returntype:BIGINT
Usagenotes:
ApacheImpalaGuide|405ImpalaSQLLanguageReference
Youmightusethereturnvalueinanapplicationwhereyouperformloadbalancing ,bucketing,orsomeother
technique todivideprocessingorstorage.Thisfunctionprovidesagoodperformance forallkindsofkeyssuchas
number,asciistringandUTF-8.Itcanberecommended asgeneral-purpose hashingfunction.
Regardingcomparison ofmurmur_hash withfnv_hash,murmur_hash isbasedonMurmur2 hashalgorithmand
fnv_hashfunctionisbasedonFNV-1ahashalgorithm.Murmur2 andFNV-1acanshowverygoodrandomness and
performance comparedwithwellknownotherhashalgorithms,butMurmur2 slightlyshowbetterrandomness
andperformance thanFNV-1a.See[1][2][3]fordetails.
Similarinputvaluesofdifferenttypescouldproducedifferenthashvalues,forexamplethesamenumericvalue
representedasSMALLINT orBIGINT,FLOATorDOUBLE,orDECIMAL(5,2) orDECIMAL(20,5) .
Examples:
[localhost:21000] > create table h (x int, s string);
[localhost:21000] > insert into h values (0, 'hello'), (1,'world'), 
(1234567890,'antidisestablishmentarianism');
[localhost:21000] > select x, murmur_hash(x) from h;
+------------+----------------------+
| x          | murmur_hash(x)       |
+------------+----------------------+
| 0          | 6960269033020761575  |
| 1          | -780611581681153783  |
| 1234567890 | -5754914572385924334 |
+------------+----------------------+
[localhost:21000] > select s, murmur_hash(s) from h;
+------------------------------+----------------------+
| s                            | murmur_hash(s)       |
+------------------------------+----------------------+
| hello                        | 2191231550387646743  |
| world                        | 5568329560871645431  |
| antidisestablishmentarianism | -2261804666958489663 |
+------------------------------+----------------------+ 
Forshortargumentvalues,thehigh-orderbitsoftheresulthaverelativelyhigherentropythanfnv_hash:
[localhost:21000] > create table b (x boolean);
[localhost:21000] > insert into b values (true), (true), (false), (false);
[localhost:21000] > select x, murmur_hash(x) from b;
+-------+----------------------+
| x     | murmur_hash(x)       |
+-------+---------------------++
| true  | -5720937396023583481 |
| true  | -5720937396023583481 |
| false | 6351753276682545529  |
| false | 6351753276682545529  |
+-------+--------------------+-+
Addedin:Impala2.12.0
NEGATIVE(numeric_type a)
Purpose: Returnstheargumentwiththesignreversed;returnsapositivevalueiftheargumentwasalreadynegative.
Returntype:Sameastheinputvalue
Usagenotes:Use-abs(a) insteadifyouneedtoensureallreturnvaluesarenegative.
PI()
Purpose: Returnstheconstantpi.
Returntype:double
PMOD(BIGINT a,BIGINTb),PMOD(DOUBLE a,DOUBLEb)
Purpose: Returnsthepositivemodulusofanumber.Primarily forHiveQLcompatibility.
Returntype:INTorDOUBLE,depending ontypeofarguments
Examples:
406|ApacheImpalaGuideImpalaSQLLanguageReference
Thefollowingexamplesshowhowthefmod()functionsometimesreturnsanegativevaluedepending onthesign
ofitsarguments,andthepmod()functionreturnsthesamevalueasfmod(),butsometimeswiththesignflipped.
select fmod(-5,2);
+-------------+
| fmod(-5, 2) |
+-------------+
| -1          |
+-------------+
select pmod(-5,2);
+-------------+
| pmod(-5, 2) |
+-------------+
| 1           |
+-------------+
select fmod(-5,-2);
+--------------+
| fmod(-5, -2) |
+--------------+
| -1           |
+--------------+
select pmod(-5,-2);
+--------------+
| pmod(-5, -2) |
+--------------+
| -1           |
+--------------+
select fmod(5,-2);
+-------------+
| fmod(5, -2) |
+-------------+
| 1           |
+-------------+
select pmod(5,-2);
+-------------+
| pmod(5, -2) |
+-------------+
| -1          |
+-------------+
POSITIVE(numeric_type a)
Purpose: Returnstheoriginalargumentunchanged(eveniftheargumentisnegative).
Returntype:Sameastheinputvalue
Usagenotes:Useabs()insteadifyouneedtoensureallreturnvaluesarepositive.
POW(DOUBLE a,doublep),POWER(DOUBLE a,DOUBLEp),DPOW(DOUBLE a,DOUBLEp),FPOW(DOUBLE a,DOUBLE
p)
Purpose: Returnsthefirstargumentraisedtothepowerofthesecondargument.
Returntype:DOUBLE
PRECISION(numeric_e xpression)
Purpose: Computestheprecision(numberofdecimaldigits)neededtorepresentthetypeoftheargumentexpression
asaDECIMAL value.
Usagenotes:
Typicallyusedincombinationwiththescale() function, todeterminetheappropriate
DECIMAL( precision ,scale)typetodeclareinaCREATE TABLE statementorCAST()function.
Returntype:INT
Examples:
ApacheImpalaGuide|407ImpalaSQLLanguageReference
Thefollowingexamplesdemonstratehowtochecktheprecisionandscaleofnumericliteralsorothernumeric
expressions.Impalarepresentsnumericliteralsinthesmallestappropriatetype.5isaTINYINT value,whichranges
from-128to127,therefore3decimaldigitsareneededtorepresenttheentirerange,andbecauseitisaninteger
valuetherearenofractionaldigits.1.333isinterpretedasaDECIMAL value,with4digitstotaland3digitsafter
thedecimalpoint.
[localhost:21000] > select precision(5), scale(5);
+--------------+----------+
| precision(5) | scale(5) |
+--------------+----------+
| 3            | 0        |
+--------------+----------+
[localhost:21000] > select precision(1.333), scale(1.333);
+------------------+--------------+
| precision(1.333) | scale(1.333) |
+------------------+--------------+
| 4                | 3            |
+------------------+--------------+
[localhost:21000] > with t1 as
  ( select cast(12.34 as decimal(20,2)) x union select cast(1 as decimal(8,6)) x )
  select precision(x), scale(x) from t1 limit 1;
+--------------+----------+
| precision(x) | scale(x) |
+--------------+----------+
| 24           | 6        |
+--------------+----------+
QUOTIENT(BIGINT numerator,BIGINTdenomina tor),QUOTIENT(DOUBLE numerator,DOUBLEdenomina tor)
Purpose: Returnsthefirstargumentdividedbythesecondargument,discardinganyfractionalpart.Avoidspromoting
integerargumentstoDOUBLEashappenswiththe/SQLoperator.AlsoincludesanoverloadthatacceptsDOUBLE
arguments,discardsthefractionalpartofeachargumentvaluebeforedividing,andagainreturnsBIGINT.With
integerarguments,thisfunctionworksthesameastheDIVoperator.
Returntype:BIGINT
RADIANS(DOUBLE a)
Purpose: Convertsargumentvaluefromdegreestoradians.
Returntype:DOUBLE
RAND(),RAND(BIGINT seed),RANDOM() ,RANDOM(BIGINT seed)
Purpose: Returnsarandomvaluebetween0and1.Afterrand()iscalledwithaseedargument,itproducesa
consistentrandomsequence basedontheseedvalue.
Returntype:DOUBLE
Usagenotes:Currently,therandomsequence isresetaftereachquery,andmultiplecallstorand()withinthe
samequeryreturnthesamevalueeachtime.Fordifferentnumbersequences thataredifferentforeachquery,
passauniqueseedvaluetoeachcalltorand().Forexample,select rand(unix_timestamp()) from ...
Examples:
Thefollowingexamplesshowhowrand()canproducesequences ofvaryingpredictability,sothatyoucanreproduce
queryresultsinvolvingrandomvaluesorgenerateuniquesequences ofrandomvaluesforeachquery.When
rand()iscalledwithnoargument,itgeneratesthesamesequence ofvalueseachtime,regardlessoftheordering
oftheresultset.Whenrand()iscalledwithaconstantinteger,itgeneratesadifferentsequence ofvalues,but
stillalwaysthesamesequence forthesameseedvalue.Ifyoupassinaseedvaluethatchanges,suchasthereturn
valueoftheexpressionunix_timestamp(now()) ,eachquerywilluseadifferentsequence ofrandomvalues,
potentiallymoreusefulinprobability calculationsalthough moredifficulttoreproduceatalatertime.Therefore,
thefinaltwoexampleswithanunpredictableseedvaluealsoincludetheseedintheresultset,tomakeitpossible
toreproducethesamerandomsequence later.
select x, rand() from three_rows;
+---+-----------------------+
408|ApacheImpalaGuideImpalaSQLLanguageReference
| x | rand()                |
+---+-----------------------+
| 1 | 0.0004714746030380365 |
| 2 | 0.5895895192351144    |
| 3 | 0.4431900859080209    |
+---+-----------------------+
select x, rand() from three_rows order by x desc;
+---+-----------------------+
| x | rand()                |
+---+-----------------------+
| 3 | 0.0004714746030380365 |
| 2 | 0.5895895192351144    |
| 1 | 0.4431900859080209    |
+---+-----------------------+
select x, rand(1234) from three_rows order by x;
+---+----------------------+
| x | rand(1234)           |
+---+----------------------+
| 1 | 0.7377511392057646   |
| 2 | 0.009428468537250751 |
| 3 | 0.208117277924026    |
+---+----------------------+
select x, rand(1234) from three_rows order by x desc;
+---+----------------------+
| x | rand(1234)           |
+---+----------------------+
| 3 | 0.7377511392057646   |
| 2 | 0.009428468537250751 |
| 1 | 0.208117277924026    |
+---+----------------------+
select x, unix_timestamp(now()), rand(unix_timestamp(now()))
  from three_rows order by x;
+---+-----------------------+-----------------------------+
| x | unix_timestamp(now()) | rand(unix_timestamp(now())) |
+---+-----------------------+-----------------------------+
| 1 | 1440777752            | 0.002051228658320023        |
| 2 | 1440777752            | 0.5098743483004506          |
| 3 | 1440777752            | 0.9517714925817081          |
+---+-----------------------+-----------------------------+
select x, unix_timestamp(now()), rand(unix_timestamp(now()))
  from three_rows order by x desc;
+---+-----------------------+-----------------------------+
| x | unix_timestamp(now()) | rand(unix_timestamp(now())) |
+---+-----------------------+-----------------------------+
| 3 | 1440777761            | 0.9985985015512437          |
| 2 | 1440777761            | 0.3251255333074953          |
| 1 | 1440777761            | 0.02422675025846192         |
+---+-----------------------+-----------------------------+
ROUND(DOUBLE a),ROUND(DOUBLE a,INTd),ROUND(DE CIMALa,int_typed),DROUND(DOUBLE a),
DROUND(DOUBLE a,INTd),DROUND(DE CIMAL(p,s) a,int_typed)
Purpose: Roundsafloating-pointvalue.Bydefault(withasingleargument),roundstothenearestinteger.Values
endingin.5areroundedupforpositivenumbers,downfornegativenumbers(thatis,awayfromzero).Theoptional
secondargumentspecifieshowmanydigitstoleaveafterthedecimalpoint;valuesgreaterthanzeroproducea
floating-pointreturnvalueroundedtotherequestednumberofdigitstotherightofthedecimalpoint.
Returntype:Sameastheinputtype
SCALE(numeric_e xpression)
Purpose: Computesthescale(numberofdecimaldigitstotherightofthedecimalpoint)neededtorepresentthe
typeoftheargumentexpressionasaDECIMAL value.
Usagenotes:
ApacheImpalaGuide|409ImpalaSQLLanguageReference
Typicallyusedincombinationwiththeprecision() function, todeterminetheappropriate
DECIMAL( precision ,scale)typetodeclareinaCREATE TABLE statementorCAST()function.
Returntype:int
Examples:
Thefollowingexamplesdemonstratehowtochecktheprecisionandscaleofnumericliteralsorothernumeric
expressions.Impalarepresentsnumericliteralsinthesmallestappropriatetype.5isaTINYINT value,whichranges
from-128to127,therefore3decimaldigitsareneededtorepresenttheentirerange,andbecauseitisaninteger
valuetherearenofractionaldigits.1.333isinterpretedasaDECIMAL value,with4digitstotaland3digitsafter
thedecimalpoint.
[localhost:21000] > select precision(5), scale(5);
+--------------+----------+
| precision(5) | scale(5) |
+--------------+----------+
| 3            | 0        |
+--------------+----------+
[localhost:21000] > select precision(1.333), scale(1.333);
+------------------+--------------+
| precision(1.333) | scale(1.333) |
+------------------+--------------+
| 4                | 3            |
+------------------+--------------+
[localhost:21000] > with t1 as
  ( select cast(12.34 as decimal(20,2)) x union select cast(1 as decimal(8,6)) x )
  select precision(x), scale(x) from t1 limit 1;
+--------------+----------+
| precision(x) | scale(x) |
+--------------+----------+
| 24           | 6        |
+--------------+----------+
SIGN(DOUBLE a)
Purpose: Returns-1,0,or1toindicatethesignedness oftheargumentvalue.
Returntype:INT
SIN(DOUBLE a)
Purpose: Returnsthesineoftheargument.
Returntype:DOUBLE
SINH(DOUBLE a)
Purpose: Returnsthehyperbolic sineoftheargument.
Returntype:DOUBLE
SQRT(DOUBLE a),DSQRT(DOUBLE a)
Purpose: Returnsthesquarerootoftheargument.
Returntype:DOUBLE
TAN(DOUBLE a)
Purpose: Returnsthetangentoftheargument.
Returntype:DOUBLE
TANH(DOUBLE a)
Purpose: Returnsthehyperbolic tangentoftheargument.
Returntype:DOUBLE
TRUNCATE(DOUBLE_or_DE CIMALa[,digits_to_leave]),DTRUNC(DOUBLE_or_DE CIMALa[,digits_to_leave]),
TRUNC(DOUBLE_or_DE CIMALa[,digits_to_leave])
Purpose: Removessomeorallfractionaldigitsfromanumericvalue.
410|ApacheImpalaGuideImpalaSQLLanguageReference
Arguments:Withasinglefloating-pointargument,removesallfractionaldigits,leavinganintegervalue.Theoptional
secondargumentspecifiesthenumberoffractionaldigitstoincludeinthereturnvalue,andonlyapplieswhenthe
argumenttypeisDECIMAL .Asecondargumentof0truncatestoawholeintegervalue.Asecondargumentof
negativeNsetsNdigitsto0ontheleftsideofthedecimal
Scaleargument:ThescaleargumentappliesonlywhentruncatingDECIMAL values.Itisanintegerspecifyinghow
manysignificantdigitstoleavetotherightofthedecimalpoint.Ascaleargumentof0truncatestoawholeinteger
value.AscaleargumentofnegativeNsetsNdigitsto0ontheleftsideofthedecimalpoint.
TRUNCATE() ,DTRUNC() ,andTRUNC() arealiasesforthesamefunction.
Returntype:Sameastheinputtype
Addedin:TheTRUNC() aliaswasaddedinCDH5.13/Impala2.10.
Usagenotes:
YoucanalsopassaDOUBLEargument,orDECIMAL argumentwithoptionalscale,totheDTRUNC() orTRUNCATE
functions. UsingtheTRUNC() functionfornumericvaluesiscommonwithotherindustry-standarddatabasesystems,
soyoumightfindsuchTRUNC() callsincodethatyouareportingtoImpala.
TheTRUNC() functionalsohasasignaturethatappliestoTIMESTAMP values.SeeImpalaDateandTimeFunctions
fordetails.
Examples:
ThefollowingexamplesdemonstratetheTRUNCATE() andDTRUNC() signaturesforthisfunction:
select truncate(3.45);
+----------------+
| truncate(3.45) |
+----------------+
| 3              |
+----------------+
select truncate(-3.45);
+-----------------+
| truncate(-3.45) |
+-----------------+
| -3              |
+-----------------+
select truncate(3.456,1);
+--------------------+
| truncate(3.456, 1) |
+--------------------+
| 3.4                |
+--------------------+
select dtrunc(3.456,1);
+------------------+
| dtrunc(3.456, 1) |
+------------------+
| 3.4              |
+------------------+
select truncate(3.456,2);
+--------------------+
| truncate(3.456, 2) |
+--------------------+
| 3.45               |
+--------------------+
select truncate(3.456,7);
+--------------------+
| truncate(3.456, 7) |
+--------------------+
| 3.4560000          |
+--------------------+
ApacheImpalaGuide|411ImpalaSQLLanguageReference
ThefollowingexamplesdemonstrateusingTRUNC() withDECIMAL orDOUBLEvalues,andwithanoptionalscale
argumentforDECIMAL values.(ThebehavioristhesamefortheTRUNCATE() andDTRUNC() aliasesalso.)
create table t1 (d decimal(20,7));
-- By default, no digits to the right of the decimal point.
insert into t1 values (1.1), (2.22), (3.333), (4.4444), (5.55555);
select trunc(d) from t1 order by d;
+----------+
| trunc(d) |
+----------+
| 1        |
| 2        |
| 3        |
| 4        |
| 5        |
+----------+
-- 1 digit to the right of the decimal point.
select trunc(d,1) from t1 order by d;
+-------------+
| trunc(d, 1) |
+-------------+
| 1.1         |
| 2.2         |
| 3.3         |
| 4.4         |
| 5.5         |
+-------------+
-- 2 digits to the right of the decimal point,
-- including trailing zeroes if needed.
select trunc(d,2) from t1 order by d;
+-------------+
| trunc(d, 2) |
+-------------+
| 1.10        |
| 2.22        |
| 3.33        |
| 4.44        |
| 5.55        |
+-------------+
insert into t1 values (9999.9999), (8888.8888);
-- Negative scale truncates digits to the left
-- of the decimal point.
select trunc(d,-2) from t1 where d > 100 order by d;
+--------------+
| trunc(d, -2) |
+--------------+
| 8800         |
| 9900         |
+--------------+
-- The scale of the result is adjusted to match the
-- scale argument.
select trunc(d,2),
  precision(trunc(d,2)) as p,
  scale(trunc(d,2)) as s
from t1 order by d;
+-------------+----+---+
| trunc(d, 2) | p  | s |
+-------------+----+---+
| 1.10        | 15 | 2 |
| 2.22        | 15 | 2 |
| 3.33        | 15 | 2 |
| 4.44        | 15 | 2 |
| 5.55        | 15 | 2 |
| 8888.88     | 15 | 2 |
412|ApacheImpalaGuideImpalaSQLLanguageReference
| 9999.99     | 15 | 2 |
+-------------+----+---+
create table dbl (d double);
insert into dbl values
  (1.1), (2.22), (3.333), (4.4444), (5.55555),
  (8888.8888), (9999.9999);
-- With double values, there is no optional scale argument.
select trunc(d) from dbl order by d;
+----------+
| trunc(d) |
+----------+
| 1        |
| 2        |
| 3        |
| 4        |
| 5        |
| 8888     |
| 9999     |
+----------+
UNHEX(S TRINGa)
Purpose: ReturnsastringofcharacterswithASCIIvaluescorresponding topairsofhexadecimal digitsintheargument.
Returntype:STRING
WIDTH_BUCKET(DE CIMALexpr,DECIMALmin_value,DECIMALmax_value,INTnum_buck ets)
Purpose: Returnsthebucketnumberinwhichtheexprvaluewouldfallinthehistogramwhereitsrangebetween
min_value andmax_value isdividedintonum_buckets bucketsofidenticalsizes.
Thefunctionreturns:
â¢NULLifanyargumentisNULL.
â¢0ifexpr<min_value .
â¢num_buckets + 1 ifexpr>=max_val .
â¢Ifnoneoftheabove,thebucketnumberwhereexprfalls.
Arguments:Thefollowingrulesapplytothearguments.
â¢min_val istheminimum valueofthehistogramrange.
â¢max_val isthemaximumvalueofthehistogramrange.
â¢num_buckets mustbegreaterthan0.
â¢min_value mustbelessthanmax_value .
Usagenotes:
Eachbucketcontainsvaluesequaltoorgreaterthanthebasevalueofthatbucketandlessthanthebasevalueof
thenextbucket.Forexample,withwidth_bucket(8, 1, 10, 3) ,thebucketrangesareactuallythe0th
"underflo wbucket"withtherange(-infinityto0.999...), (1to3.999...), (4,to6.999...), (7to9.999...), andthe
"overflowbucket"withtherange(10toinfinity).
Returntype:BIGINT
Addedin:CDH6.1.
Examples:
Thebelowfunctioncreates3bucketsbetweentherangeof1and20withthebucketwidthof6.333,andreturns
2forthebucket#2wherethevalue8fallsin:
WIDTH_BUCKET(8, 1, 20, 3)
ApacheImpalaGuide|413ImpalaSQLLanguageReference
Thebelowstatementreturnsalistofaccountswiththeenergyspending andthespending bracketeachaccount
fallsin,between0and11.Bucket0(underflo wbucket)willbeassignedtotheaccountswhoseenergyspendings
arelessthan$50.Bucket11(overflowbucket)willbeassignedtotheaccountswhoseenergyspendings aremore
thanorequalto$1000.
SELECT account, invoice_amount, WIDTH_BUCKET(invoice_amount,50,1000,10)
FROM invoices_june2018
ORDER BY 3;
ImpalaBitFunctions
Bitmanipula tionfunctions performbitwiseoperationsinvolvedinscientificprocessingorcomputersciencealgorithms.
Forexample,thesefunctions includesetting,clearing,ortestingbitswithinanintegervalue,orchanging thepositions
ofbitswithorwithoutwraparound.
Ifafunctiontakestwointegerargumentsthatarerequiredtobeofthesametype,thesmallerargumentispromoted
tothetypeofthelargeroneifrequired.Forexample,BITAND(1,4096) treatsbothargumentsasSMALLINT ,because
1canberepresentedasaTINYINT but4096requiresaSMALLINT .
Remember thatallImpalaintegervaluesaresigned.Therefore,whendealingwithbinaryvalueswherethemost
significantbitis1,thespecified orreturnedvaluesmightbenegativewhenrepresentedinbase10.
WheneveranyargumentisNULL,eithertheinputvalue,bitposition,ornumberofshiftorrotatepositions, thereturn
valuefromanyofthesefunctions isalsoNULL
Relatedinformation:
Thebitfunctions operateonalltheintegraldatatypes:INTDataTypeonpage117,BIGINTDataTypeonpage105,
SMALLINT DataTypeonpage122,andTINYINTDataTypeonpage136.
Function reference:
Impalasupports thefollowingbitfunctions:
â¢BITAND
â¢BITNOT
â¢BITOR
â¢BITXOR
â¢COUNTSET
â¢GETBIT
â¢ROTATELEFT
â¢ROTATERIGHT
â¢SETBIT
â¢SHIFTLEFT
â¢SHIFTRIGHT
BITAND(integer_typea,same_type b)
Purpose: Returnsanintegervaluerepresentingthebitsthataresetto1inbothofthearguments.Ifthearguments
areofdifferentsizes,thesmallerispromotedtothetypeofthelarger.
Usagenotes:TheBITAND() functionisequivalenttothe&binaryoperator.
Returntype:Sameastheinputvalue
Addedin:CDH5.5.0/Impala2.3.0
Examples:
ThefollowingexamplesshowtheresultsofANDingintegervalues.255containsall1bitsinitslowermost7bits.
32767containsall1bitsinitslowermost15bits.Youcanusethebin()functiontocheckthebinaryrepresentation
414|ApacheImpalaGuideImpalaSQLLanguageReference
ofanyintegervalue,although theresultisalwaysrepresentedasa64-bitvalue.Ifnecessary,thesmallerargument
ispromotedtothetypeofthelargerone.
select bitand(255, 32767); /* 0000000011111111 & 0111111111111111 */
+--------------------+
| bitand(255, 32767) |
+--------------------+
| 255                |
+--------------------+
select bitand(32767, 1); /* 0111111111111111 & 0000000000000001 */
+------------------+
| bitand(32767, 1) |
+------------------+
| 1                |
+------------------+
select bitand(32, 16); /* 00010000 & 00001000 */
+----------------+
| bitand(32, 16) |
+----------------+
| 0              |
+----------------+
select bitand(12,5); /* 00001100 & 00000101 */
+---------------+
| bitand(12, 5) |
+---------------+
| 4             |
+---------------+
select bitand(-1,15); /* 11111111 & 00001111 */
+----------------+
| bitand(-1, 15) |
+----------------+
| 15             |
+----------------+
BITNOT(integer_typea)
Purpose: Invertsallthebitsoftheinputargument.
Usagenotes:TheBITNOT() functionisequivalenttothe~unaryoperator.
Returntype:Sameastheinputvalue
Addedin:CDH5.5.0/Impala2.3.0
Examples:
Theseexamplesillustratewhathappenswhenyouflipallthebitsofanintegervalue.Thesignalwayschanges.The
decimalrepresentationisonedifferentbetweenthepositiveandnegativevalues.
select bitnot(127); /* 01111111 -> 10000000 */
+-------------+
| bitnot(127) |
+-------------+
| -128        |
+-------------+
select bitnot(16); /* 00010000 -> 11101111 */
+------------+
| bitnot(16) |
+------------+
| -17        |
+------------+
select bitnot(0); /* 00000000 -> 11111111 */
+-----------+
| bitnot(0) |
+-----------+
| -1        |
ApacheImpalaGuide|415ImpalaSQLLanguageReference
+-----------+
select bitnot(-128); /* 10000000 -> 01111111 */
+--------------+
| bitnot(-128) |
+--------------+
| 127          |
+--------------+
BITOR(integer_typea,same_type b)
Purpose: Returnsanintegervaluerepresentingthebitsthataresetto1ineitherofthearguments.Ifthearguments
areofdifferentsizes,thesmallerispromotedtothetypeofthelarger.
Usagenotes:TheBITOR() functionisequivalenttothe|binaryoperator.
Returntype:Sameastheinputvalue
Addedin:CDH5.5.0/Impala2.3.0
Examples:
ThefollowingexamplesshowtheresultsofORingintegervalues.
select bitor(1,4); /* 00000001 | 00000100 */
+-------------+
| bitor(1, 4) |
+-------------+
| 5           |
+-------------+
select bitor(16,48); /* 00001000 | 00011000 */
+---------------+
| bitor(16, 48) |
+---------------+
| 48            |
+---------------+
select bitor(0,7); /* 00000000 | 00000111 */
+-------------+
| bitor(0, 7) |
+-------------+
| 7           |
+-------------+
BITXOR(integer_typea,same_type b)
Purpose: Returnsanintegervaluerepresentingthebitsthataresetto1inonebutnotbothofthearguments.If
theargumentsareofdifferentsizes,thesmallerispromotedtothetypeofthelarger.
Usagenotes:TheBITXOR() functionisequivalenttothe^binaryoperator.
Returntype:Sameastheinputvalue
Addedin:CDH5.5.0/Impala2.3.0
Examples:
ThefollowingexamplesshowtheresultsofXORingintegervalues.XORinganon-zerovaluewithzeroreturnsthe
non-zerovalue.XORingtwoidenticalvaluesreturnszero,becauseallthe1bitsfromthefirstargumentarealso1
bitsinthesecondargument.XORingdifferentnon-zerovaluesturnsoffsomebitsandleavesothersturnedon,
basedonwhetherthesamebitissetinbotharguments.
select bitxor(0,15); /* 00000000 ^ 00001111 */
+---------------+
| bitxor(0, 15) |
+---------------+
| 15            |
+---------------+
416|ApacheImpalaGuideImpalaSQLLanguageReference
select bitxor(7,7); /* 00000111 ^ 00000111 */
+--------------+
| bitxor(7, 7) |
+--------------+
| 0            |
+--------------+
select bitxor(8,4); /* 00001000 ^ 00000100 */
+--------------+
| bitxor(8, 4) |
+--------------+
| 12           |
+--------------+
select bitxor(3,7); /* 00000011 ^ 00000111 */
+--------------+
| bitxor(3, 7) |
+--------------+
| 4            |
+--------------+
COUNTSET(integer_typea[,INTzero_or_one])
Purpose: Bydefault,returnsthenumberof1bitsinthespecified integervalue.Iftheoptionalsecondargumentis
settozero,itreturnsthenumberof0bitsinstead.
Usagenotes:
Indiscussions ofinformationtheory,thisoperationisreferredtoastheâpopulationcountâorâpopcountâ.
Returntype:Sameastheinputvalue
Addedin:CDH5.5.0/Impala2.3.0
Examples:
Thefollowingexamplesshowhowtocountthenumberof1bitsinanintegervalue.
select countset(1); /* 00000001 */
+-------------+
| countset(1) |
+-------------+
| 1           |
+-------------+
select countset(3); /* 00000011 */
+-------------+
| countset(3) |
+-------------+
| 2           |
+-------------+
select countset(16); /* 00010000 */
+--------------+
| countset(16) |
+--------------+
| 1            |
+--------------+
select countset(17); /* 00010001 */
+--------------+
| countset(17) |
+--------------+
| 2            |
+--------------+
select countset(7,1); /* 00000111 = 3 1 bits; the function counts 1 bits by default */
+----------------+
| countset(7, 1) |
+----------------+
| 3              |
+----------------+
ApacheImpalaGuide|417ImpalaSQLLanguageReference
select countset(7,0); /* 00000111 = 5 0 bits; third argument can only be 0 or 1 */
+----------------+
| countset(7, 0) |
+----------------+
| 5              |
+----------------+
GETBIT(in teger_typea,INTposition)
Purpose: Returnsa0or1representingthebitataspecified position. Thepositions arenumberedrighttoleft,
startingatzero.Thepositionargumentcannotbenegative.
Usagenotes:
Whenyouusealiteralinputvalue,itistreatedasan8-bit,16-bit,andsoonvalue,thesmallesttypethatis
appropriate.Thetypeoftheinputvaluelimitstherangeofthepositions. Casttheinputvaluetotheappropriate
typeifyouneedtoensureitistreatedasa64-bit,32-bit,andsoonvalue.
Returntype:Sameastheinputvalue
Addedin:CDH5.5.0/Impala2.3.0
Examples:
Thefollowingexamplesshowhowtotestaspecificbitwithinanintegervalue.
select getbit(1,0); /* 00000001 */
+--------------+
| getbit(1, 0) |
+--------------+
| 1            |
+--------------+
select getbit(16,1) /* 00010000 */
+---------------+
| getbit(16, 1) |
+---------------+
| 0             |
+---------------+
select getbit(16,4) /* 00010000 */
+---------------+
| getbit(16, 4) |
+---------------+
| 1             |
+---------------+
select getbit(16,5) /* 00010000 */
+---------------+
| getbit(16, 5) |
+---------------+
| 0             |
+---------------+
select getbit(-1,3); /* 11111111 */
+---------------+
| getbit(-1, 3) |
+---------------+
| 1             |
+---------------+
select getbit(-1,25); /* 11111111 */
ERROR: Invalid bit position: 25
select getbit(cast(-1 as int),25); /* 11111111111111111111111111111111 */
+-----------------------------+
| getbit(cast(-1 as int), 25) |
+-----------------------------+
| 1                           |
+-----------------------------+
418|ApacheImpalaGuideImpalaSQLLanguageReference
ROTATELEFT(in teger_typea,INTpositions)
Purpose: Rotatesanintegervalueleftbyaspecified numberofbits.Asthemostsignificantbitistakenoutofthe
originalvalue,ifitisa1bit,itisârotatedâbacktotheleastsignificantbit.Therefore,thefinalvaluehasthesame
numberof1bitsastheoriginalvalue,justindifferentpositions. Incomputerscienceterms,thisoperationisa
âcircularshiftâ.
Usagenotes:
Specifyingasecondargumentofzeroleavestheoriginalvalueunchanged.Rotatinga-1valuebyanynumberof
positions stillreturns-1,becausetheoriginalvaluehasall1bitsandallthe1bitsarepreservedduringrotation.
Similarly,rotatinga0valuebyanynumberofpositions stillreturns0.Rotatingavaluebythesamenumberofbits
asinthevaluereturnsthesamevalue.Becausethisisacircularoperation,thenumberofpositions isnotlimited
tothenumberofbitsintheinputvalue.Forexample,rotatingan8-bitvalueby1,9,17,andsoonpositions returns
anidenticalresultineachcase.
Returntype:Sameastheinputvalue
Addedin:CDH5.5.0/Impala2.3.0
Examples:
select rotateleft(1,4); /* 00000001 -> 00010000 */
+------------------+
| rotateleft(1, 4) |
+------------------+
| 16               |
+------------------+
select rotateleft(-1,155); /* 11111111 -> 11111111 */
+---------------------+
| rotateleft(-1, 155) |
+---------------------+
| -1                  |
+---------------------+
select rotateleft(-128,1); /* 10000000 -> 00000001 */
+---------------------+
| rotateleft(-128, 1) |
+---------------------+
| 1                   |
+---------------------+
select rotateleft(-127,3); /* 10000001 -> 00001100 */
+---------------------+
| rotateleft(-127, 3) |
+---------------------+
| 12                  |
+---------------------+
ROTATERIGHT(in teger_typea,INTpositions)
Purpose: Rotatesanintegervaluerightbyaspecified numberofbits.Astheleastsignificantbitistakenoutofthe
originalvalue,ifitisa1bit,itisârotatedâbacktothemostsignificantbit.Therefore,thefinalvaluehasthesame
numberof1bitsastheoriginalvalue,justindifferentpositions. Incomputerscienceterms,thisoperationisa
âcircularshiftâ.
Usagenotes:
Specifyingasecondargumentofzeroleavestheoriginalvalueunchanged.Rotatinga-1valuebyanynumberof
positions stillreturns-1,becausetheoriginalvaluehasall1bitsandallthe1bitsarepreservedduringrotation.
Similarly,rotatinga0valuebyanynumberofpositions stillreturns0.Rotatingavaluebythesamenumberofbits
asinthevaluereturnsthesamevalue.Becausethisisacircularoperation,thenumberofpositions isnotlimited
tothenumberofbitsintheinputvalue.Forexample,rotatingan8-bitvalueby1,9,17,andsoonpositions returns
anidenticalresultineachcase.
Returntype:Sameastheinputvalue
ApacheImpalaGuide|419ImpalaSQLLanguageReference
Addedin:CDH5.5.0/Impala2.3.0
Examples:
select rotateright(16,4); /* 00010000 -> 00000001 */
+--------------------+
| rotateright(16, 4) |
+--------------------+
| 1                  |
+--------------------+
select rotateright(-1,155); /* 11111111 -> 11111111 */
+----------------------+
| rotateright(-1, 155) |
+----------------------+
| -1                   |
+----------------------+
select rotateright(-128,1); /* 10000000 -> 01000000 */
+----------------------+
| rotateright(-128, 1) |
+----------------------+
| 64                   |
+----------------------+
select rotateright(-127,3); /* 10000001 -> 00110000 */
+----------------------+
| rotateright(-127, 3) |
+----------------------+
| 48                   |
+----------------------+
SETBIT(in teger_typea,INTposition[,INTzero_or_one])
Purpose: Bydefault,changesabitataspecified positiontoa1,ifitisnotalready.Iftheoptionalthirdargument
issettozero,thespecified bitissetto0instead.
Usagenotes:
Ifthebitatthespecified positionwasalready1(bydefault)or0(withathirdargumentofzero),thereturnvalue
isthesameasthefirstargument.Thepositions arenumberedrighttoleft,startingatzero.(Therefore,thereturn
valuecouldbedifferentfromthefirstargumentevenifthepositionargumentiszero.)Thepositionargument
cannotbenegative.
Whenyouusealiteralinputvalue,itistreatedasan8-bit,16-bit,andsoonvalue,thesmallesttypethatis
appropriate.Thetypeoftheinputvaluelimitstherangeofthepositions. Casttheinputvaluetotheappropriate
typeifyouneedtoensureitistreatedasa64-bit,32-bit,andsoonvalue.
Returntype:Sameastheinputvalue
Addedin:CDH5.5.0/Impala2.3.0
Examples:
select setbit(0,0); /* 00000000 -> 00000001 */
+--------------+
| setbit(0, 0) |
+--------------+
| 1            |
+--------------+
select setbit(0,3); /* 00000000 -> 00001000 */
+--------------+
| setbit(0, 3) |
+--------------+
| 8            |
+--------------+
select setbit(7,3); /* 00000111 -> 00001111 */
+--------------+
| setbit(7, 3) |
420|ApacheImpalaGuideImpalaSQLLanguageReference
+--------------+
| 15           |
+--------------+
select setbit(15,3); /* 00001111 -> 00001111 */
+---------------+
| setbit(15, 3) |
+---------------+
| 15            |
+---------------+
select setbit(0,32); /* By default, 0 is a TINYINT with only 8 bits. */
ERROR: Invalid bit position: 32
select setbit(cast(0 as bigint),32); /* For BIGINT, the position can be 0..63. */
+-------------------------------+
| setbit(cast(0 as bigint), 32) |
+-------------------------------+
| 4294967296                    |
+-------------------------------+
select setbit(7,3,1); /* 00000111 -> 00001111; setting to 1 is the default */
+-----------------+
| setbit(7, 3, 1) |
+-----------------+
| 15              |
+-----------------+
select setbit(7,2,0); /* 00000111 -> 00000011; third argument of 0 clears instead of 
sets */
+-----------------+
| setbit(7, 2, 0) |
+-----------------+
| 3               |
+-----------------+
SHIFTLEFT(in teger_typea,INTpositions)
Purpose: Shiftsanintegervalueleftbyaspecified numberofbits.Asthemostsignificantbitistakenoutofthe
originalvalue,itisdiscardedandtheleastsignificantbitbecomes0.Incomputerscienceterms,thisoperationisa
âlogicalshiftâ.
Usagenotes:
Thefinalvaluehaseitherthesamenumberof1bitsastheoriginalvalue,orfewer.Shiftingan8-bitvalueby8
positions, a16-bitvalueby16positions, andsoonproducesaresultofzero.
Specifyingasecondargumentofzeroleavestheoriginalvalueunchanged.Shiftinganyvalueby0returnstheoriginal
value.Shiftinganyvalueby1isthesameasmultiplying itby2,aslongasthevalueissmallenough;largervalues
eventuallybecomenegativewhenshifted,asthesignbitisset.Startingwiththevalue1andshiftingitleftbyN
positions givesthesameresultas2totheNthpower,orpow(2,N).
Returntype:Sameastheinputvalue
Addedin:CDH5.5.0/Impala2.3.0
Examples:
select shiftleft(1,0); /* 00000001 -> 00000001 */
+-----------------+
| shiftleft(1, 0) |
+-----------------+
| 1               |
+-----------------+
select shiftleft(1,3); /* 00000001 -> 00001000 */
+-----------------+
| shiftleft(1, 3) |
+-----------------+
| 8               |
+-----------------+
ApacheImpalaGuide|421ImpalaSQLLanguageReference
select shiftleft(8,2); /* 00001000 -> 00100000 */
+-----------------+
| shiftleft(8, 2) |
+-----------------+
| 32              |
+-----------------+
select shiftleft(127,1); /* 01111111 -> 11111110 */
+-------------------+
| shiftleft(127, 1) |
+-------------------+
| -2                |
+-------------------+
select shiftleft(127,5); /* 01111111 -> 11100000 */
+-------------------+
| shiftleft(127, 5) |
+-------------------+
| -32               |
+-------------------+
select shiftleft(-1,4); /* 11111111 -> 11110000 */
+------------------+
| shiftleft(-1, 4) |
+------------------+
| -16              |
+------------------+
SHIFTRIGHT(in teger_typea,INTpositions)
Purpose: Shiftsanintegervaluerightbyaspecified numberofbits.Astheleastsignificantbitistakenoutofthe
originalvalue,itisdiscardedandthemostsignificantbitbecomes0.Incomputerscienceterms,thisoperationis
aâlogicalshiftâ.
Usagenotes:
Therefore,thefinalvaluehaseitherthesamenumberof1bitsastheoriginalvalue,orfewer.Shiftingan8-bitvalue
by8positions, a16-bitvalueby16positions, andsoonproducesaresultofzero.
Specifyingasecondargumentofzeroleavestheoriginalvalueunchanged.Shiftinganyvalueby0returnstheoriginal
value.Shiftinganypositivevaluerightby1isthesameasdividingitby2.Negativevaluesbecomepositivewhen
shiftedright.
Returntype:Sameastheinputvalue
Addedin:CDH5.5.0/Impala2.3.0
Examples:
select shiftright(16,0); /* 00010000 -> 00010000 */
+-------------------+
| shiftright(16, 0) |
+-------------------+
| 16                |
+-------------------+
select shiftright(16,4); /* 00010000 -> 00000001 */
+-------------------+
| shiftright(16, 4) |
+-------------------+
| 1                 |
+-------------------+
select shiftright(16,5); /* 00010000 -> 00000000 */
+-------------------+
| shiftright(16, 5) |
+-------------------+
| 0                 |
+-------------------+
422|ApacheImpalaGuideImpalaSQLLanguageReference
select shiftright(-1,1); /* 11111111 -> 01111111 */
+-------------------+
| shiftright(-1, 1) |
+-------------------+
| 127               |
+-------------------+
select shiftright(-1,5); /* 11111111 -> 00000111 */
+-------------------+
| shiftright(-1, 5) |
+-------------------+
| 7                 |
+-------------------+
ImpalaTypeConversionFunctions
Conversionfunctions areusuallyusedincombinationwithotherfunctions, toexplicitlypasstheexpecteddatatypes.
Impalahasstrictrulesregardingdatatypesforfunctionparameters.Forexample,Impaladoesnotautomatically
convertaDOUBLEvaluetoFLOAT,aBIGINTvaluetoINT,orotherconversionwhereprecisioncouldbelostoroverflow
couldoccur.Also,forreportingordealingwithlooselydefinedschemasinbigdatacontexts,youmightfrequently
needtoconvertvaluestoorfromtheSTRINGtype.
Note:Although inCDH5.5/Impala2.3,theSHOW FUNCTIONS outputfordatabase
_IMPALA_BUILTINS containssomefunctionsignaturesmatchingthepatterncastto*,thesefunctions
arenotintendedforpublicuseandareexpectedtobehiddeninfuture.
Function reference:
Impalasupports thefollowingtypeconversionfunctions:
â¢CAST
â¢TYPEOF
CAST(exprAStype)
Purpose: Convertsthevalueofanexpressiontoanyothertype.Iftheexpressionvalueisofatypethatcannotbe
convertedtothetargettype,theresultisNULL.
Usagenotes:UseCASTwhenpassingacolumnvalueorliteraltoafunctionthatexpectsaparameterwithadifferent
type.FrequentlyusedinSQLoperationssuchasCREATE TABLE AS SELECT andINSERT ... VALUES toensure
thatvaluesfromvarioussourcesareoftheappropriatetypeforthedestinationcolumns.Wherepractical,doa
one-timeCAST()operationduringtheingestionprocesstomakeeachcolumnintotheappropriatetype,rather
thanusingmanyCAST()operationsineachquery;doingtypeconversionsforeachrowduringeachquerycanbe
expensivefortableswithmillionsorbillionsofrows.
ThewaythisfunctiondealswithtimezoneswhenconvertingtoorfromTIMESTAMP valuesisaffectedbythe
--use_local_tz_for_unix_timestamp_conversions startupflagfortheimpalad daemon. SeeTIMESTAMP
DataTypeonpage130fordetailsabouthowImpalahandlestimezoneconsiderationsfortheTIMESTAMP data
type.
Examples:
SELECT CONCAT('Here are the first ',10,' results.'); -- Fails
SELECT CONCAT('Here are the first ',CAST(10 AS STRING),' results.'); -- Succeeds
ThefollowingexamplestartswithatexttablewhereeverycolumnhasatypeofSTRING,whichmightbehowyou
ingestdataofunknownschemauntilyoucanverifythecleanliness oftheunderlyvalues.ThenitusesCAST()to
createanewParquettablewiththesamedata,butusingspecificnumericdatatypesforthecolumnswithnumeric
ApacheImpalaGuide|423ImpalaSQLLanguageReference
data.Usingnumerictypesofappropriatesizescanresultinsubstantialspacesavingsondiskandinmemory,and
performance improvementsinqueries,overusingstringsorlarger-than-necessar ynumerictypes.
CREATE TABLE t1 (name STRING, x STRING, y STRING, z STRING);
CREATE TABLE t2 STORED AS PARQUET
AS SELECT
  name,
  CAST(x AS BIGINT) x,
  CAST(y AS TIMESTAMP) y,
  CAST(z AS SMALLINT) z
FROM t1;
Relatedinformation:
Fordetailsofcastsfromeachkindofdatatype,seethedescriptionoftheappropriatetype:TINYINTDataTypeon
page136,SMALLINT DataTypeonpage122,INTDataTypeonpage117,BIGINTDataTypeonpage105,FLOATData
Typeonpage116,DOUBLEDataTypeonpage114,DECIMALDataType(CDH6.0/Impala3.0orhigheronly)onpage
109,STRINGDataTypeonpage123,CHARDataType(CDH5.2orhigheronly)onpage107,VARCHARDataType(CDH
5.2orhigheronly)onpage137,TIMESTAMPDataTypeonpage130,BOOLEANDataTypeonpage106
TYPEOF(typevalue)
Purpose: Returnsthenameofthedatatypecorresponding toanexpression.Fortypeswithextraattributes,such
aslengthforCHARandVARCHAR ,orprecisionandscaleforDECIMAL ,includesthefullspecificationofthetype.
Returntype:STRING
Usagenotes:Typicallyusedininteractiveexplorationofaschema,orinapplicationcodethatprogrammatically
generatesschemadefinitionssuchasCREATE TABLE statements,forexample,togetthetypeofanexpression
suchascol1 / col2 orCONCAT(col1, col2, col3) .Thisfunctionisespecially usefulforarithmeticexpressions
involvingDECIMAL typesbecausetheprecisionandscaleoftheresultiscanbedifferentthanthatoftheoperands.
Addedin:CDH5.5.0/Impala2.3.0
Examples:
SELECT TYPEOF(2), TYPEOF(2+2);
+-----------+---------------+
| typeof(2) | typeof(2 + 2) |
+-----------+---------------+
| TINYINT   | SMALLINT      |
+-----------+---------------+
ImpalaDateandTimeFunctions
Theunderlying ImpaladatatypefordateandtimedataisTIMESTAMP ,whichhasbothadateandatimeportion.
Functions thatextractasinglefield,suchashour()orminute() ,typicallyreturnanintegervalue.Functions that
formatthedateportion,suchasdate_add() orto_date() ,typicallyreturnastringvalue.
YoucanalsoadjustaTIMESTAMP valuebyaddingorsubtractinganINTERVAL expression.SeeTIMESTAMPDataType
onpage130fordetails.INTERVAL expressionsarealsoallowedasthesecondargumentforthedate_add() and
date_sub() functions, ratherthanintegers.
Someofthesefunctions areaffectedbythesettingofthe--use_local_tz_for_unix_timestamp_conversions
startupflagfortheimpalad daemon. Thissettingisoffbydefault,meaningthatfunctions suchasfrom_unixtime()
andunix_timestamp() considertheinputvaluestoalwaysrepresenttheUTCtimezone.Thissettingalsoapplies
whenyouCAST()aBIGINTvaluetoTIMESTAMP ,oraTIMESTAMP valuetoBIGINT.Whenthissettingisenabled,
thesefunctions andoperationsconverttoandfromvaluesrepresentingthelocaltimezone.SeeTIMESTAMPData
Typeonpage130fordetailsabouthowImpalahandlestimezoneconsiderationsfortheTIMESTAMP datatype.
Function reference:
Impalasupports thefollowingdataandtimefunctions:
â¢ADD_MONTHS
424|ApacheImpalaGuideImpalaSQLLanguageReference
â¢ADDDATE
â¢CURRENT_TIME STAMP
â¢DATE_ADD
â¢DATE_PART
â¢DATE_SUB
â¢DATE_TRUNC
â¢DATEDIFF
â¢DAY
â¢DAYNAME
â¢DAYOFWEEK
â¢DAYOFYEAR
â¢DAYS_ADD
â¢DAYS_SUB
â¢EXTRACT
â¢FROM_TIME STAMP
â¢FROM_UNIXTIME
â¢FROM_UTC_TIMESTAMP
â¢HOUR
â¢HOURS_ADD
â¢HOURS_SUB
â¢INT_MONTHS_BETWEEN
â¢MICROSECONDS_ADD
â¢MICROSECONDS_SUB
â¢MILLISECOND
â¢MILLISECONDS_ADD
â¢MILLISECONDS_SUB
â¢MINUTE
â¢MINUTES_ADD
â¢MINUTES_SUB
â¢MONTH
â¢MONTHNAME
â¢MONTHS_ADD
â¢MONTHS_BETWEEN
â¢MONTHS_SUB
â¢NANOSECONDS_ADD
â¢NANOSECONDS_SUB
â¢NEXT_DAY
â¢NOW
â¢QUARTER
â¢SECOND
â¢SECONDS_ADD
â¢SECONDS_SUB
â¢SUBDATE
â¢TIMEOFDAY
â¢TIMESTAMP_CMP
â¢TO_DATE
â¢TO_TIMESTAMP
â¢TO_UTC_TIMESTAMP
â¢TRUNC
â¢UNIX_TIME STAMP
ApacheImpalaGuide|425ImpalaSQLLanguageReference
â¢UTC_TIMESTAMP
â¢WEEKOFYEAR
â¢WEEKS_ADD
â¢WEEKS_SUB
â¢YEAR
â¢YEARS_ADD
â¢YEARS_SUB
ADD_MONTHS(TIME STAMPdate,INTmonths),ADD_MONTHS(TIME STAMPdate,BIGINTmonths)
Purpose: Returnsthespecified dateandtimeplussomenumberofmonths.
Returntype:TIMESTAMP
Usagenotes:
SameasMONTHS_ADD() .AvailableinImpala1.4andhigher.Forcompatibilitywhenportingcodewithvendor
extensions.
Examples:
Thefollowingexamplesdemonstrateaddingmonthstoconstructthesamedayofthemonthinadifferentmonth;
howifthecurrentdayofthemonthdoesnotexistinthetargetmonth,thelastdayofthatmonthissubstituted;
andhowanegativeargumentproducesareturnvaluefromapreviousmonth.
select now(), add_months(now(), 2);
+-------------------------------+-------------------------------+
| now()                         | add_months(now(), 2)          |
+-------------------------------+-------------------------------+
| 2016-05-31 10:47:00.429109000 | 2016-07-31 10:47:00.429109000 |
+-------------------------------+-------------------------------+
select now(), add_months(now(), 1);
+-------------------------------+-------------------------------+
| now()                         | add_months(now(), 1)          |
+-------------------------------+-------------------------------+
| 2016-05-31 10:47:14.540226000 | 2016-06-30 10:47:14.540226000 |
+-------------------------------+-------------------------------+
select now(), add_months(now(), -1);
+-------------------------------+-------------------------------+
| now()                         | add_months(now(), -1)         |
+-------------------------------+-------------------------------+
| 2016-05-31 10:47:31.732298000 | 2016-04-30 10:47:31.732298000 |
+-------------------------------+-------------------------------+
ADDDATE(TIMESTAMPstartdate,INTdays),ADDDATE(TIMESTAMPstartdate,BIGINTdays)
Purpose: Addsaspecified numberofdaystoaTIMESTAMP value.SimilartoDATE_ADD() ,butstartswithanactual
TIMESTAMP valueinsteadofastringthatisconvertedtoaTIMESTAMP .
Returntype:TIMESTAMP
Examples:
ThefollowingexamplesshowhowtoaddanumberofdaystoaTIMESTAMP .Thenumberofdayscanalsobe
negative,whichgivesthesameeffectasthesubdate() function.
select now() as right_now, adddate(now(), 30) as now_plus_30;
+-------------------------------+-------------------------------+
| right_now                     | now_plus_30                   |
+-------------------------------+-------------------------------+
| 2016-05-20 10:23:08.640111000 | 2016-06-19 10:23:08.640111000 |
+-------------------------------+-------------------------------+
select now() as right_now, adddate(now(), -15) as now_minus_15;
426|ApacheImpalaGuideImpalaSQLLanguageReference
+-------------------------------+-------------------------------+
| right_now                     | now_minus_15                  |
+-------------------------------+-------------------------------+
| 2016-05-20 10:23:38.214064000 | 2016-05-05 10:23:38.214064000 |
+-------------------------------+-------------------------------+
CURRENT_TIME STAMP()
Purpose: AliasfortheNOW()function.
Returntype:TIMESTAMP
Examples:
select now(), current_timestamp();
+-------------------------------+-------------------------------+
| now()                         | current_timestamp()           |
+-------------------------------+-------------------------------+
| 2016-05-19 16:10:14.237849000 | 2016-05-19 16:10:14.237849000 |
+-------------------------------+-------------------------------+
select current_timestamp() as right_now,
  current_timestamp() + interval 3 hours as in_three_hours;
+-------------------------------+-------------------------------+
| right_now                     | in_three_hours                |
+-------------------------------+-------------------------------+
| 2016-05-19 16:13:20.017117000 | 2016-05-19 19:13:20.017117000 |
+-------------------------------+-------------------------------+
DATE_ADD(TIME STAMPstartdate,INTdays),DATE_ADD(TIME STAMPstartdate,interval_expression)
Purpose: Addsaspecified numberofdaystoaTIMESTAMP value.WithanINTERVAL expressionasthesecond
argument,youcancalculateadeltavalueusingotherunitssuchasweeks,years,hours,seconds,andsoon;see
TIMESTAMPDataTypeonpage130fordetails.
Returntype:TIMESTAMP
Examples:
Thefollowingexampleshowsthesimplestusage,ofaddingaspecified numberofdaystoaTIMESTAMP value:
select now() as right_now, date_add(now(), 7) as next_week;
+-------------------------------+-------------------------------+
| right_now                     | next_week                     |
+-------------------------------+-------------------------------+
| 2016-05-20 11:03:48.687055000 | 2016-05-27 11:03:48.687055000 |
+-------------------------------+-------------------------------+
Thefollowingexamplesshowtheshorthand notationofanINTERVAL expression,insteadofspecifyingtheprecise
numberofdays.TheINTERVAL notationalsoletsyouworkwithunitssmallerthanasingleday.
select now() as right_now, date_add(now(), interval 3 weeks) as in_3_weeks;
+-------------------------------+-------------------------------+
| right_now                     | in_3_weeks                    |
+-------------------------------+-------------------------------+
| 2016-05-20 11:05:39.173331000 | 2016-06-10 11:05:39.173331000 |
+-------------------------------+-------------------------------+
select now() as right_now, date_add(now(), interval 6 hours) as in_6_hours;
+-------------------------------+-------------------------------+
| right_now                     | in_6_hours                    |
+-------------------------------+-------------------------------+
| 2016-05-20 11:13:51.492536000 | 2016-05-20 17:13:51.492536000 |
+-------------------------------+-------------------------------+
ApacheImpalaGuide|427ImpalaSQLLanguageReference
Likealldate/timefunctions thatdealwithmonths,date_add() handlesnonexistentdatespasttheendofamonth
bysettingthedatetothelastdayofthemonth.ThefollowingexampleshowshowthenonexistentdateApril31st
isnormalizedtoApril30th:
select date_add(cast('2016-01-31' as timestamp), interval 3 months) as 'april_31st';
+---------------------+
| april_31st          |
+---------------------+
| 2016-04-30 00:00:00 |
+---------------------+
DATE_PART(STRINGa,TIMESTAMPtimestamp)
Purpose: SimilartoEXTRACT() ,withtheargumentorderreversed.Supports thesamedateandtimeunitsas
EXTRACT() .ForcompatibilitywithSQLcodecontainingvendorextensions.
Returntype:bigint
Examples:
select date_part('year',now()) as current_year;
+--------------+
| current_year |
+--------------+
| 2016         |
+--------------+
select date_part('hour',now()) as hour_of_day;
+-------------+
| hour_of_day |
+-------------+
| 11          |
+-------------+
DATE_SUB(TIME STAMPstartdate,INTdays),DATE_SUB(TIME STAMPstartdate,interval_expression)
Purpose: Subtractsaspecified numberofdaysfromaTIMESTAMP value.WithanINTERVAL expressionasthe
secondargument,youcancalculateadeltavalueusingotherunitssuchasweeks,years,hours,seconds,andso
on;seeTIMESTAMPDataTypeonpage130fordetails.
Returntype:TIMESTAMP
Examples:
Thefollowingexampleshowsthesimplestusage,ofsubtractingaspecified numberofdaysfromaTIMESTAMP
value:
select now() as right_now, date_sub(now(), 7) as last_week;
+-------------------------------+-------------------------------+
| right_now                     | last_week                     |
+-------------------------------+-------------------------------+
| 2016-05-20 11:21:30.491011000 | 2016-05-13 11:21:30.491011000 |
+-------------------------------+-------------------------------+
Thefollowingexamplesshowtheshorthand notationofanINTERVAL expression,insteadofspecifyingtheprecise
numberofdays.TheINTERVAL notationalsoletsyouworkwithunitssmallerthanasingleday.
select now() as right_now, date_sub(now(), interval 3 weeks) as 3_weeks_ago;
+-------------------------------+-------------------------------+
| right_now                     | 3_weeks_ago                   |
+-------------------------------+-------------------------------+
| 2016-05-20 11:23:05.176953000 | 2016-04-29 11:23:05.176953000 |
+-------------------------------+-------------------------------+
select now() as right_now, date_sub(now(), interval 6 hours) as 6_hours_ago;
428|ApacheImpalaGuideImpalaSQLLanguageReference
+-------------------------------+-------------------------------+
| right_now                     | 6_hours_ago                   |
+-------------------------------+-------------------------------+
| 2016-05-20 11:23:35.439631000 | 2016-05-20 05:23:35.439631000 |
+-------------------------------+-------------------------------+
Likealldate/timefunctions thatdealwithmonths,DATE_ADD() handlesnonexistentdatespasttheendofamonth
bysettingthedatetothelastdayofthemonth.ThefollowingexampleshowshowthenonexistentdateApril31st
isnormalizedtoApril30th:
select date_sub(cast('2016-05-31' as timestamp), interval 1 months) as 'april_31st';
+---------------------+
| april_31st          |
+---------------------+
| 2016-04-30 00:00:00 |
+---------------------+
DATE_TRUNC(S TRINGunit,TIMESTAMPtimestamp)
Purpose: TruncatesaTIMESTAMP valuetothespecified precision.
Unitargument:TheunitargumentvaluefortruncatingTIMESTAMP valuesisnotcase-sensitiv e.Thisargument
stringcanbeoneof:
â¢microseconds
â¢milliseconds
â¢second
â¢minute
â¢hour
â¢day
â¢week
â¢month
â¢year
â¢decade
â¢century
â¢millennium
Forexample,callingdate_trunc('hour',ts) truncateststothebeginning ofthecorresponding hour,withall
minutes,seconds,milliseconds,andsoonsettozero.Callingdate_trunc('milliseconds',ts) truncatests
tothebeginning ofthecorresponding millisecond,withallmicrosecondsandnanosecondssettozero.
Note:Thesub-secondunitsarespecified inpluralform.Allunitsrepresentingonesecondormore
arespecified insingularform.
Addedin:CDH5.14.0/Impala2.11.0
Usagenotes:
Although thisfunctionissimilartocallingTRUNC() withaTIMESTAMP argument,theorderofargumentsandthe
recognizedunitsaredifferentbetweenTRUNC() andDATE_TRUNC() .Therefore,thesefunctions arenot
interchangeable.
ThisfunctionistypicallyusedinGROUP BY queriestoaggregateresultsfromthesamehour,day,week,month,
quarter,andsoon.YoucanalsousethisfunctioninanINSERT ... SELECT intoapartitioned tabletodivide
TIMESTAMP valuesintothecorrectpartition.
BecausethereturnvalueisaTIMESTAMP ,ifyoucasttheresultofDATE_TRUNC() toSTRING,youwilloftensee
zeroed-outportionssuchas00:00:00 inthetimefield.Ifyouonlyneedtheindividual unitssuchashour,day,
month,oryear,usetheEXTRACT() functioninstead.Ifyouneedtheindividual unitsfromatruncatedTIMESTAMP
value,runtheTRUNCATE() functionontheoriginalvalue,thenrunEXTRACT() ontheresult.
ApacheImpalaGuide|429ImpalaSQLLanguageReference
Returntype:TIMESTAMP
Examples:
ThefollowingexamplesshowhowtocallDATE_TRUNC() withdifferentunitvalues:
select now(), date_trunc('second', now());
+-------------------------------+-----------------------------------+
| now()                         | date_trunc('second', now())       |
+-------------------------------+-----------------------------------+
| 2017-12-05 13:58:04.565403000 | 2017-12-05 13:58:04               |
+-------------------------------+-----------------------------------+
select now(), date_trunc('hour', now());
+-------------------------------+---------------------------+
| now()                         | date_trunc('hour', now()) |
+-------------------------------+---------------------------+
| 2017-12-05 13:59:01.884459000 | 2017-12-05 13:00:00       |
+-------------------------------+---------------------------+
select now(), date_trunc('millennium', now());
+-------------------------------+---------------------------------+
| now()                         | date_trunc('millennium', now()) |
+-------------------------------+---------------------------------+
| 2017-12-05 14:00:30.296812000 | 2000-01-01 00:00:00             |
+-------------------------------+---------------------------------+
DATEDIFF(TIME STAMPenddate,TIMESTAMPstartdate)
Purpose: ReturnsthenumberofdaysbetweentwoTIMESTAMP values.
Returntype:INT
Usagenotes:
Ifthefirstargumentrepresentsalaterdatethanthesecondargument,thereturnvalueispositive.Ifbotharguments
representthesamedate,thereturnvalueiszero.ThetimeportionsoftheTIMESTAMP valuesareirrelevant.For
example,11:59PMononedayand12:01onthenextdayrepresentadatediff() of-1becausethedate/time
valuesrepresentdifferentdays,eventhoughtheTIMESTAMP valuesdifferbyonly2minutes.
Examples:
Thefollowingexampleshowshowcomparing aâlateâvaluewithanâearlierâvalueproducesapositivenumber.In
thiscase,theresultis(365*5)+1,becauseoneoftheinterveningyearsisaleapyear.
select now() as right_now, datediff(now() + interval 5 years, now()) as in_5_years;
+-------------------------------+------------+
| right_now                     | in_5_years |
+-------------------------------+------------+
| 2016-05-20 13:43:55.873826000 | 1826       |
+-------------------------------+------------+
Thefollowingexamplesshowhowthereturnvaluerepresentthenumberofdaysbetweentheassociateddates,
regardlessofthetimeportionofeachTIMESTAMP .Forexample,differenttimesonthesamedayproducea
DATE_DIFF() of0,regardlessofwhichoneisearlierorlater.Butiftheargumentsrepresentdifferentdates,
DATE_DIFF() returnsanon-zerointegervalue,regardlessofthetimeportionsofthedates.
select now() as right_now, datediff(now(), now() + interval 4 hours) as in_4_hours;
+-------------------------------+------------+
| right_now                     | in_4_hours |
+-------------------------------+------------+
| 2016-05-20 13:42:05.302747000 | 0          |
+-------------------------------+------------+
select now() as right_now, datediff(now(), now() - interval 4 hours) as 4_hours_ago;
+-------------------------------+-------------+
430|ApacheImpalaGuideImpalaSQLLanguageReference
| right_now                     | 4_hours_ago |
+-------------------------------+-------------+
| 2016-05-20 13:42:21.134958000 | 0           |
+-------------------------------+-------------+
select now() as right_now, datediff(now(), now() + interval 12 hours) as in_12_hours;
+-------------------------------+-------------+
| right_now                     | in_12_hours |
+-------------------------------+-------------+
| 2016-05-20 13:42:44.765873000 | -1          |
+-------------------------------+-------------+
select now() as right_now, datediff(now(), now() - interval 18 hours) as 18_hours_ago;
+-------------------------------+--------------+
| right_now                     | 18_hours_ago |
+-------------------------------+--------------+
| 2016-05-20 13:54:38.829827000 | 1            |
+-------------------------------+--------------+
DAY(TIMESTAMPdate),DAYOFMONTH(TIME STAMPdate)
Purpose: ReturnsthedayfieldfromthedateportionofaTIMESTAMP .Thevaluerepresentsthedayofthemonth,
thereforeisintherange1-31,orlessformonthswithout31days.
Returntype:INT
Examples:
Thefollowingexamplesshowhowthedayvaluecorrespondstothedayofthemonth,resettingbackto1atthe
startofeachmonth.
select now(), day(now());
+-------------------------------+------------+
| now()                         | day(now()) |
+-------------------------------+------------+
| 2016-05-20 15:01:51.042185000 | 20         |
+-------------------------------+------------+
select now() + interval 11 days, day(now() + interval 11 days);
+-------------------------------+-------------------------------+
| now() + interval 11 days      | day(now() + interval 11 days) |
+-------------------------------+-------------------------------+
| 2016-05-31 15:05:56.843139000 | 31                            |
+-------------------------------+-------------------------------+
select now() + interval 12 days, day(now() + interval 12 days);
+-------------------------------+-------------------------------+
| now() + interval 12 days      | day(now() + interval 12 days) |
+-------------------------------+-------------------------------+
| 2016-06-01 15:06:05.074236000 | 1                             |
+-------------------------------+-------------------------------+
ThefollowingexamplesshowhowthedayvalueisNULLfornonexistentdatesormisformatteddatestrings.
-- 2016 is a leap year, so it has a Feb. 29.
select day('2016-02-29');
+-------------------+
| day('2016-02-29') |
+-------------------+
| 29                |
+-------------------+
-- 2015 is not a leap year, so Feb. 29 is nonexistent.
select day('2015-02-29');
+-------------------+
| day('2015-02-29') |
+-------------------+
| NULL              |
+-------------------+
ApacheImpalaGuide|431ImpalaSQLLanguageReference
-- A string that does not match the expected YYYY-MM-DD format
-- produces an invalid TIMESTAMP, causing day() to return NULL.
select day('2016-02-028');
+--------------------+
| day('2016-02-028') |
+--------------------+
| NULL               |
+--------------------+
DAYNAME(TIME STAMPdate)
Purpose: ReturnsthedayfieldfromaTIMESTAMP value,convertedtothestringcorresponding tothatdayname.
Therangeofreturnvaluesis'Sunday' to'Saturday' .Usedinreport-generatingqueries,asanalternativeto
callingDAYOFWEEK() andturningthatnumericreturnvalueintoastringusingaCASEexpression.
Returntype:STRING
Examples:
ThefollowingexamplesshowthedaynameassociatedwithTIMESTAMP valuesrepresentingdifferentdays.
select now() as right_now,
  dayofweek(now()) as todays_day_of_week,
  dayname(now()) as todays_day_name;
+-------------------------------+--------------------+-----------------+
| right_now                     | todays_day_of_week | todays_day_name |
+-------------------------------+--------------------+-----------------+
| 2016-05-31 10:57:03.953670000 | 3                  | Tuesday         |
+-------------------------------+--------------------+-----------------+
select now() + interval 1 day as tomorrow,
  dayname(now() + interval 1 day) as tomorrows_day_name;
+-------------------------------+--------------------+
| tomorrow                      | tomorrows_day_name |
+-------------------------------+--------------------+
| 2016-06-01 10:58:53.945761000 | Wednesday          |
+-------------------------------+--------------------+
DAYOFWEEK(TIME STAMPdate)
Purpose: ReturnsthedayfieldfromthedateportionofaTIMESTAMP ,corresponding tothedayoftheweek.The
rangeofreturnvaluesis1(Sunday)to7(Saturday).
Returntype:INT
Examples:
select now() as right_now,
  dayofweek(now()) as todays_day_of_week,
  dayname(now()) as todays_day_name;
+-------------------------------+--------------------+-----------------+
| right_now                     | todays_day_of_week | todays_day_name |
+-------------------------------+--------------------+-----------------+
| 2016-05-31 10:57:03.953670000 | 3                  | Tuesday         |
+-------------------------------+--------------------+-----------------+
DAYOFYEAR(TIMESTAMPdate)
Purpose: ReturnsthedayfieldfromaTIMESTAMP value,corresponding tothedayoftheyear.Therangeofreturn
valuesis1(January1)to366(December 31ofaleapyear).
Returntype:INT
Examples:
432|ApacheImpalaGuideImpalaSQLLanguageReference
Thefollowingexamplesshowreturnvaluesfromthedayofyear() function. Thesamedateindifferentyears
returnsadifferentdaynumberforalldatesafterFebruary28,because2016isaleapyearwhile2015isnotaleap
year.
select now() as right_now,
  dayofyear(now()) as today_day_of_year;
+-------------------------------+-------------------+
| right_now                     | today_day_of_year |
+-------------------------------+-------------------+
| 2016-05-31 11:05:48.314932000 | 152               |
+-------------------------------+-------------------+
select now() - interval 1 year as last_year,
  dayofyear(now() - interval 1 year) as year_ago_day_of_year;
+-------------------------------+----------------------+
| last_year                     | year_ago_day_of_year |
+-------------------------------+----------------------+
| 2015-05-31 11:07:03.733689000 | 151                  |
+-------------------------------+----------------------+
DAYS_ADD(TIME STAMPstartdate,INTdays),DAYS_ADD(TIME STAMPstartdate,BIGINTdays)
Purpose: Addsaspecified numberofdaystoaTIMESTAMP value.SimilartoDATE_ADD() ,butstartswithanactual
TIMESTAMP valueinsteadofastringthatisconvertedtoaTIMESTAMP .
Returntype:TIMESTAMP
Examples:
select now() as right_now, days_add(now(), 31) as 31_days_later;
+-------------------------------+-------------------------------+
| right_now                     | 31_days_later                 |
+-------------------------------+-------------------------------+
| 2016-05-31 11:12:32.216764000 | 2016-07-01 11:12:32.216764000 |
+-------------------------------+-------------------------------+
DAYS_SUB(TIME STAMPstartdate,INTdays),DAYS_SUB(TIME STAMPstartdate,BIGINTdays)
Purpose: Subtractsaspecified numberofdaysfromaTIMESTAMP value.SimilartoDATE_SUB() ,butstartswith
anactualTIMESTAMP valueinsteadofastringthatisconvertedtoaTIMESTAMP .
Returntype:TIMESTAMP
Examples:
select now() as right_now, days_sub(now(), 31) as 31_days_ago;
+-------------------------------+-------------------------------+
| right_now                     | 31_days_ago                   |
+-------------------------------+-------------------------------+
| 2016-05-31 11:13:42.163905000 | 2016-04-30 11:13:42.163905000 |
+-------------------------------+-------------------------------+
EXTRACT(TIMESTAMPtimestamp,STRINGunit),EXTRACT(unitFROMTIMESTAMPts)
Purpose: ReturnsoneofthenumericdateortimefieldsfromaTIMESTAMP value.
Unitargument:Theunitstringcanbeoneofepoch,year,quarter ,month,day,hour,minute,second,or
millisecond .Thisargumentvalueiscase-insensitiv e.
Ifyouspecifymillisecond fortheunitargument,thefunctionreturnsthesecondscomponen tandthemilliseconds
componen t.Forexample,EXTRACT(CAST('2006-05-12 18:27:28.123456789' AS TIMESTAMP),
'MILLISECOND') willreturn28123.
ApacheImpalaGuide|433ImpalaSQLLanguageReference
InImpala2.0andhigher,youcanusespecialsyntaxratherthanaregularfunctioncall,forcompatibilitywithcode
thatusestheSQL-99formatwiththeFROMkeyword.Withthisstyle,theunitnamesareidentifiersratherthan
STRINGliterals.Forexample,thefollowingcallsarebothequivalent:
EXTRACT(year FROM NOW());
EXTRACT(NOW(), 'year');
Usagenotes:
TypicallyusedinGROUP BY queriestoarrangeresultsbyhour,day,month,andsoon.Youcanalsousethisfunction
inanINSERT ... SELECT statementtoinsertintoapartitioned tabletosplitupTIMESTAMP valuesintoindividual
parts,ifthepartitioned tablehasseparatepartition keycolumnsrepresentingyear,month,day,andsoon.Ifyou
needtodividebymorecomplexunitsoftime,suchasbyweekorbyquarter,usetheTRUNC() functioninstead.
Returntype:BIGINT
Examples:
SELECT NOW() AS right_now,
  EXTRACT(day FROM NOW()) AS this_day,
  EXTRACT(hour FROM NOW()) AS this_hour;
+-------------------------------+----------+-----------+
| right_now                     | this_day | this_hour |
+-------------------------------+----------+-----------+
| 2016-05-31 11:19:24.025303000 | 31       | 11        |
+-------------------------------+----------+-----------+
FROM_TIME STAMP(TIME STAMPdatetime,STRINGpattern),FROM_TIME STAMP(STRINGdatetime,STRINGpattern)
Purpose: ConvertsaTIMESTAMP valueintoastringrepresentingthesamevalue.
Returntype:STRING
Addedin:CDH5.5.0/Impala2.3.0
Usagenotes:
TheFROM_TIMESTAMP() functionprovidesaflexiblewaytoconvertTIMESTAMP valuesintoarbitrarystringformats
forreportingpurposes.
BecauseImpalaimplicitly convertsstringvaluesintoTIMESTAMP ,youcanpassdate/timevaluesrepresentedas
strings(inthestandardyyyy-MM-dd HH:mm:ss.SSS format)tothisfunction. Theresultisastringusingdifferent
separatorcharacters,orderoffields,spelled-out monthnames,orothervariationofthedate/timestring
representation.
TheallowedtokensforthepatternstringarethesameasfortheFROM_UNIXTIME() function.
Examples:
ThefollowingexamplesshowdifferentwaystoformataTIMESTAMP valueasastring:
-- Reformat a TIMESTAMP value.
SELECT FROM_TIMESTAMP(NOW(), 'yyyy/MM/dd');
+-------------------------------------+
| from_timestamp(now(), 'yyyy/mm/dd') |
+-------------------------------------+
| 2018/10/09                          |
+-------------------------------------+
-- Alternative format for reporting purposes.
SELECT FROM_TIMESTAMP('1984-09-25 16:45:30.125', 'MMM dd, yyyy HH:mm:ss.SSS');
+------------------------------------------------------------------------+
| from_timestamp('1984-09-25 16:45:30.125', 'mmm dd, yyyy hh:mm:ss.sss') |
+------------------------------------------------------------------------+
| Sep 25, 1984 16:45:30.125                                              |
+------------------------------------------------------------------------+
434|ApacheImpalaGuideImpalaSQLLanguageReference
FROM_UNIXTIME(BIGINT unixtime[, STRINGformat])
Purpose: ConvertsthenumberofsecondsfromtheUnixepochtothespecified timeintoastringinthelocaltime
zone.
Returntype:STRING
InImpala2.2.0andhigher,built-infunctions thatacceptorreturnintegersrepresentingTIMESTAMP valuesusethe
BIGINTtypeforparametersandreturnvalues,ratherthanINT.Thischangeletsthedateandtimefunctions avoid
anoverflowerrorthatwouldotherwiseoccuronJanuary19th,2038(knownastheâYear2038problemâorâY2K38
problemâ).ThischangeaffectstheFROM_UNIXTIME() andUNIX_TIMESTAMP() functions. Youmightneedto
changeapplicationcodethatinteractswiththesefunctions, changethetypesofcolumnsthatstorethereturn
values,oraddCAST()callstoSQLstatementsthatcallthesefunctions.
Usagenotes:
TheformatstringacceptsthevariationsallowedfortheTIMESTAMP datatype:dateplustime,datebyitself,time
byitself,andoptionalfractionalsecondsforthetime.SeeTIMESTAMPDataTypeonpage130fordetails.
Currently,theformatstringiscase-sensitiv e,especially todistinguishmforminutesandMformonths.InImpala1.3
andlater,youcanswitchtheorderofelements,usealternativeseparatorcharacters,anduseadifferentnumber
ofplaceholder sforeachunit.Addingmoreinstancesofy,d,H,andsoonproducesoutputstringszero-padded to
therequestednumberofcharacters.TheexceptionisMformonths,whereMproducesanon-padded valuesuch
as3,MMproducesazero-padded valuesuchas03,MMMproducesanabbreviatedmonthnamesuchasMar,and
sequences of4ormoreMarenotallowed.Adatestringincluding allfieldscouldbe'yyyy-MM-dd
HH:mm:ss.SSSSSS' ,'dd/MM/yyyy HH:mm:ss.SSSSSS' ,'MMM dd, yyyy HH.mm.ss (SSSSSS)' orother
combinationsofplaceholder sandseparatorcharacters.
ThewaythisfunctiondealswithtimezoneswhenconvertingtoorfromTIMESTAMP valuesisaffectedbythe
--use_local_tz_for_unix_timestamp_conversions startupflagfortheimpalad daemon. SeeTIMESTAMP
DataTypeonpage130fordetailsabouthowImpalahandlestimezoneconsiderationsfortheTIMESTAMP data
type.
Note:
Themoreflexibleformatstringsallowedwiththebuilt-infunctions donotchangetherulesabout
usingCAST()toconvertfromastringtoaTIMESTAMP value.Stringsbeingconvertedthrough
CAST()muststillhavetheelementsinthespecifiedorderandusethespecifieddelimitercharacters,
asdescribed inTIMESTAMPDataTypeonpage130.
Examples:
SELECT FROM_UNIXTIME(1392394861,'yyyy-MM-dd HH:mm:ss.SSSS');
+-------------------------------------------------------+
| from_unixtime(1392394861, 'yyyy-mm-dd hh:mm:ss.ssss') |
+-------------------------------------------------------+
| 2014-02-14 16:21:01.0000                              |
+-------------------------------------------------------+
SELECT FROM_UNIXTIME(1392394861,'HH:mm:ss.SSSS');
+--------------------------------------------+
| from_unixtime(1392394861, 'hh:mm:ss.ssss') |
+--------------------------------------------+
| 16:21:01.0000                              |
+--------------------------------------------+
UNIX_TIMESTAMP() andFROM_UNIXTIME() areoftenusedincombinationtoconvertaTIMESTAMP valueinto
aparticular stringformat.Forexample:
SELECT FROM_UNIXTIME(UNIX_TIMESTAMP(NOW() + interval 3 days),
  'yyyy/MM/dd HH:mm') AS yyyy_mm_dd_hh_mm;
+------------------+
| yyyy_mm_dd_hh_mm |
ApacheImpalaGuide|435ImpalaSQLLanguageReference
+------------------+
| 2016/06/03 11:38 |
+------------------+
FROM_UTC_TIMESTAMP(TIME STAMPtimestamp,STRINGtimezone)
Purpose: Convertsaspecified UTCtimestampvalueintotheappropriatevalueforaspecified timezone.
Returntype:TIMESTAMP
Usagenotes:OftenusedtotranslateUTCtimezonedatastoredinatablebacktothelocaldateandtimefor
reporting. TheoppositeoftheTO_UTC_TIMESTAMP() function.
Todeterminethetimezoneoftheserveryouareconnectedto,inCDH5.5/Impala2.3andhigheryoucancallthe
timeofday() function, whichincludesthetimezonespecifierinitsreturnvalue.Remember thatwithcloud
computing ,theserveryouinteractwithmightbeinadifferenttimezonethanyouare,ordifferentsessionsmight
connecttoserversindifferenttimezones,oraclustermightincludeserversinmorethanonetimezone.
Examples:
Seediscussion oftimezonesinTIMESTAMPDataTypeonpage130forinformationaboutusingthisfunctionfor
conversionsbetweenthelocaltimezoneandUTC.
ThefollowingexampleshowshowwhenTIMESTAMP valuesrepresentingtheUTCtimezonearestoredinatable,
aquerycandisplaytheequivalentlocaldateandtimeforadifferenttimezone.
with t1 as (select cast('2016-06-02 16:25:36.116143000' as timestamp) as utc_datetime)
  select utc_datetime as 'Date/time in Greenwich UK',
    from_utc_timestamp(utc_datetime, 'PDT')
      as 'Equivalent in California USA'
  from t1;
+-------------------------------+-------------------------------+
| date/time in greenwich uk     | equivalent in california usa  |
+-------------------------------+-------------------------------+
| 2016-06-02 16:25:36.116143000 | 2016-06-02 09:25:36.116143000 |
+-------------------------------+-------------------------------+
Thefollowingexampleshowsthatforadateandtimewhendaylightsavingsisineffect(PDT),theUTCtimeis7
hoursaheadofthelocalCaliforniatime;whilewhendaylightsavingsisnotineffect(PST),theUTCtimeis8hours
aheadofthelocalCaliforniatime.
select now() as local_datetime,
  to_utc_timestamp(now(), 'PDT') as utc_datetime;
+-------------------------------+-------------------------------+
| local_datetime                | utc_datetime                  |
+-------------------------------+-------------------------------+
| 2016-05-31 11:50:02.316883000 | 2016-05-31 18:50:02.316883000 |
+-------------------------------+-------------------------------+
select '2016-01-05' as local_datetime,
  to_utc_timestamp('2016-01-05', 'PST') as utc_datetime;
+----------------+---------------------+
| local_datetime | utc_datetime        |
+----------------+---------------------+
| 2016-01-05     | 2016-01-05 08:00:00 |
+----------------+---------------------+
HOUR(TIME STAMPdate)
Purpose: ReturnsthehourfieldfromaTIMESTAMP field.
Returntype:INT
436|ApacheImpalaGuideImpalaSQLLanguageReference
Examples:
select now() as right_now, hour(now()) as current_hour;
+-------------------------------+--------------+
| right_now                     | current_hour |
+-------------------------------+--------------+
| 2016-06-01 14:14:12.472846000 | 14           |
+-------------------------------+--------------+
select now() + interval 12 hours as 12_hours_from_now,
  hour(now() + interval 12 hours) as hour_in_12_hours;
+-------------------------------+-------------------+
| 12_hours_from_now             | hour_in_12_hours  |
+-------------------------------+-------------------+
| 2016-06-02 02:15:32.454750000 | 2                 |
+-------------------------------+-------------------+
HOURS_ADD(TIME STAMPdate,INThours),HOURS_ADD(TIME STAMPdate,BIGINThours)
Purpose: Returnsthespecified dateandtimeplussomenumberofhours.
Returntype:TIMESTAMP
Examples:
select now() as right_now,
  hours_add(now(), 12) as in_12_hours;
+-------------------------------+-------------------------------+
| right_now                     | in_12_hours                   |
+-------------------------------+-------------------------------+
| 2016-06-01 14:19:48.948107000 | 2016-06-02 02:19:48.948107000 |
+-------------------------------+-------------------------------+
HOURS_SUB(TIME STAMPdate,INThours),HOURS_SUB(TIME STAMPdate,BIGINThours)
Purpose: Returnsthespecified dateandtimeminussomenumberofhours.
Returntype:TIMESTAMP
Examples:
select now() as right_now,
  hours_sub(now(), 18) as 18_hours_ago;
+-------------------------------+-------------------------------+
| right_now                     | 18_hours_ago                  |
+-------------------------------+-------------------------------+
| 2016-06-01 14:23:13.868150000 | 2016-05-31 20:23:13.868150000 |
+-------------------------------+-------------------------------+
INT_MONTHS_BETWEEN(TIME STAMPnewer,TIMESTAMPolder)
Purpose: ReturnsthenumberofmonthsbetweenthedateportionsoftwoTIMESTAMP values,asanINTrepresenting
onlythefullmonthsthatpassed.
Returntype:INT
Addedin:CDH5.5.0/Impala2.3.0
Usagenotes:
Typicallyusedinbusinesscontexts,forexampletodeterminewhetheraspecified numberofmonthshavepassed
orwhethersomeend-of-mon thdeadlinewasreached.
Themethodofdetermining thenumberofelapsedmonthsincludessomespecialhandlingofmonthswithdifferent
numbersofdaysthatcreatesedgecasesfordatesbetweenthe28thand31stdaysofcertainmonths.See
MONTHS_BETWEEN() fordetails.TheINT_MOINTHS_BETWEEN() resultisessentiallytheFLOOR() ofthe
MONTHS_BETWEEN() result.
ApacheImpalaGuide|437ImpalaSQLLanguageReference
IfeithervalueisNULL,whichcouldhappenforexamplewhenconvertinganonexistentdatestringsuchas
'2015-02-29' toaTIMESTAMP ,theresultisalsoNULL.
Ifthefirstargumentrepresentsanearliertimethanthesecondargument,theresultisnegative.
Examples:
/* Less than a full month = 0. */
select int_months_between('2015-02-28', '2015-01-29');
+------------------------------------------------+
| int_months_between('2015-02-28', '2015-01-29') |
+------------------------------------------------+
| 0                                              |
+------------------------------------------------+
/* Last day of month to last day of next month = 1. */
select int_months_between('2015-02-28', '2015-01-31');
+------------------------------------------------+
| int_months_between('2015-02-28', '2015-01-31') |
+------------------------------------------------+
| 1                                              |
+------------------------------------------------+
/* Slightly less than 2 months = 1. */
select int_months_between('2015-03-28', '2015-01-31');
+------------------------------------------------+
| int_months_between('2015-03-28', '2015-01-31') |
+------------------------------------------------+
| 1                                              |
+------------------------------------------------+
/* 2 full months (identical days of the month) = 2. */
select int_months_between('2015-03-31', '2015-01-31');
+------------------------------------------------+
| int_months_between('2015-03-31', '2015-01-31') |
+------------------------------------------------+
| 2                                              |
+------------------------------------------------+
/* Last day of month to last day of month-after-next = 2. */
select int_months_between('2015-03-31', '2015-01-30');
+------------------------------------------------+
| int_months_between('2015-03-31', '2015-01-30') |
+------------------------------------------------+
| 2                                              |
+------------------------------------------------+
LAST_DAY(TIMESTAMPt)
Purpose: ReturnsaTIMESTAMP corresponding tothebeginning ofthelastcalendardayinthesamemonthasthe
TIMESTAMP argument.
Returntype:TIMESTAMP
Addedin:CDH5.12.0/Impala2.9.0
Usagenotes:
IftheinputargumentdoesnotrepresentavalidImpalaTIMESTAMP including bothdateandtimeportions, the
functionreturnsNULL.Forexample,iftheinputargumentisastringthatcannotbeimplicitly casttoTIMESTAMP ,
doesnotincludeadateportion,orisoutoftheallowedrangeforImpalaTIMESTAMP values,thefunctionreturns
NULL.
Examples:
Thefollowingexampleshowshowtoexaminethecurrentdate,anddatesaroundtheendofthemonth,as
TIMESTAMP valueswithanytimeportionremoved:
select
    now() as right_now
438|ApacheImpalaGuideImpalaSQLLanguageReference
  , trunc(now(),'dd') as today
  , last_day(now()) as last_day_of_month
  , last_day(now()) + interval 1 day as first_of_next_month;
+-------------------------------+---------------------+---------------------+---------------------+
| right_now                     | today               | last_day_of_month   | 
first_of_next_month |
+-------------------------------+---------------------+---------------------+---------------------+
| 2017-08-15 15:07:58.823812000 | 2017-08-15 00:00:00 | 2017-08-31 00:00:00 | 2017-09-01
 00:00:00 |
+-------------------------------+---------------------+---------------------+---------------------+
Thefollowingexampleshowshowtoexaminethecurrentdateanddatesaroundtheendofthemonthasintegers
representingthedayofthemonth:
select
    now() as right_now
  , dayofmonth(now()) as day
  , extract(day from now()) as also_day
  , dayofmonth(last_day(now())) as last_day
  , extract(day from last_day(now())) as also_last_day;
+-------------------------------+-----+----------+----------+---------------+
| right_now                     | day | also_day | last_day | also_last_day |
+-------------------------------+-----+----------+----------+---------------+
| 2017-08-15 15:07:59.417755000 | 15  | 15       | 31       | 31            |
+-------------------------------+-----+----------+----------+---------------+
MICROSECONDS_ADD(TIME STAMPdate,INTmicroseconds),MICROSECONDS_ADD(TIME STAMPdate,BIGINT
microseconds)
Purpose: Returnsthespecified dateandtimeplussomenumberofmicroseconds.
Returntype:TIMESTAMP
Examples:
select now() as right_now,
  microseconds_add(now(), 500000) as half_a_second_from_now;
+-------------------------------+-------------------------------+
| right_now                     | half_a_second_from_now        |
+-------------------------------+-------------------------------+
| 2016-06-01 14:25:11.455051000 | 2016-06-01 14:25:11.955051000 |
+-------------------------------+-------------------------------+
MICROSECONDS_SUB(TIME STAMPdate,INTmicroseconds),MICROSECONDS_SUB(TIME STAMPdate,BIGINT
microseconds)
Purpose: Returnsthespecified dateandtimeminussomenumberofmicroseconds.
Returntype:TIMESTAMP
Examples:
select now() as right_now,
  microseconds_sub(now(), 500000) as half_a_second_ago;
+-------------------------------+-------------------------------+
| right_now                     | half_a_second_ago             |
+-------------------------------+-------------------------------+
| 2016-06-01 14:26:16.509990000 | 2016-06-01 14:26:16.009990000 |
+-------------------------------+-------------------------------+
MILLISECOND(TIME STAMPt)
Purpose: Returnsthemillisecondportionofatvalue.
Returntype:INT
ApacheImpalaGuide|439ImpalaSQLLanguageReference
Addedin:CDH5.7.0/Impala2.5.0
Usagenotes:
Themillisecondvalueistruncated,notrounded,iftheTIMESTAMP valuecontainsmorethan3significantdigitsto
therightofthedecimalpoint.
Examples:
252.4 milliseconds truncated to 252.
select now(), millisecond(now());
+-------------------------------+--------------------+
| now()                         | millisecond(now()) |
+-------------------------------+--------------------+
| 2016-03-14 22:30:25.252400000 | 252                |
+-------------------------------+--------------------+
761.767 milliseconds truncated to 761.
select now(), millisecond(now());
+-------------------------------+--------------------+
| now()                         | millisecond(now()) |
+-------------------------------+--------------------+
| 2016-03-14 22:30:58.761767000 | 761                |
+-------------------------------+--------------------+
MILLISECONDS_ADD(TIME STAMPdate,INTmilliseconds),MILLISECONDS_ADD(TIME STAMPdate,BIGINTmilliseconds)
Purpose: Returnsthespecified dateandtimeplussomenumberofmilliseconds.
Returntype:TIMESTAMP
Examples:
select now() as right_now,
  milliseconds_add(now(), 1500) as 1_point_5_seconds_from_now;
+-------------------------------+-------------------------------+
| right_now                     | 1_point_5_seconds_from_now    |
+-------------------------------+-------------------------------+
| 2016-06-01 14:30:30.067366000 | 2016-06-01 14:30:31.567366000 |
+-------------------------------+-------------------------------+
MILLISECONDS_SUB(TIME STAMPdate,INTmilliseconds),MILLISECONDS_SUB(TIME STAMPdate,BIGINTmilliseconds)
Purpose: Returnsthespecified dateandtimeminussomenumberofmilliseconds.
Returntype:TIMESTAMP
Examples:
select now() as right_now,
  milliseconds_sub(now(), 1500) as 1_point_5_seconds_ago;
+-------------------------------+-------------------------------+
| right_now                     | 1_point_5_seconds_ago         |
+-------------------------------+-------------------------------+
| 2016-06-01 14:30:53.467140000 | 2016-06-01 14:30:51.967140000 |
+-------------------------------+-------------------------------+
MINUTE(TIME STAMPdate)
Purpose: ReturnstheminutefieldfromaTIMESTAMP value.
Returntype:INT
440|ApacheImpalaGuideImpalaSQLLanguageReference
Examples:
select now() as right_now, minute(now()) as current_minute;
+-------------------------------+----------------+
| right_now                     | current_minute |
+-------------------------------+----------------+
| 2016-06-01 14:34:08.051702000 | 34             |
+-------------------------------+----------------+
MINUTES_ADD(TIME STAMPdate,INTminutes),MINUTES_ADD(TIME STAMPdate,BIGINTminutes)
Purpose: Returnsthespecified dateandtimeplussomenumberofminutes.
Returntype:TIMESTAMP
Examples:
select now() as right_now, minutes_add(now(), 90) as 90_minutes_from_now;
+-------------------------------+-------------------------------+
| right_now                     | 90_minutes_from_now           |
+-------------------------------+-------------------------------+
| 2016-06-01 14:36:04.887095000 | 2016-06-01 16:06:04.887095000 |
+-------------------------------+-------------------------------+
MINUTES_SUB(TIME STAMPdate,INTminutes),MINUTES_SUB(TIME STAMPdate,BIGINTminutes)
Purpose: Returnsthespecified dateandtimeminussomenumberofminutes.
Returntype:TIMESTAMP
Examples:
select now() as right_now, minutes_sub(now(), 90) as 90_minutes_ago;
+-------------------------------+-------------------------------+
| right_now                     | 90_minutes_ago                |
+-------------------------------+-------------------------------+
| 2016-06-01 14:36:32.643061000 | 2016-06-01 13:06:32.643061000 |
+-------------------------------+-------------------------------+
MONTH(TIME STAMPdate)
Purpose: Returnsthemonthfield,representedasaninteger,fromthedateportionofaTIMESTAMP .
Returntype:INT
Examples:
select now() as right_now, month(now()) as current_month;
+-------------------------------+---------------+
| right_now                     | current_month |
+-------------------------------+---------------+
| 2016-06-01 14:43:37.141542000 | 6             |
+-------------------------------+---------------+
MONTHNAME(TIME STAMPdate)
Purpose: ReturnsthemonthfieldfromaTIMESTAMP value,convertedtothestringcorresponding tothatmonth
name.
Returntype:STRING
MONTHS_ADD(TIME STAMPdate,INTmonths),MONTHS_ADD(TIME STAMPdate,BIGINTmonths)
Purpose: Returnsthespecified dateandtimeplussomenumberofmonths.
Returntype:TIMESTAMP
Examples:
ApacheImpalaGuide|441ImpalaSQLLanguageReference
ThefollowingexampleshowstheeffectsofaddingsomenumberofmonthstoaTIMESTAMP value,usingboththe
months_add() functionanditsadd_months() alias.Theseexamplesusetrunc() tostripoffthetimeportion
andleavejustthedate.
with t1 as (select trunc(now(), 'dd') as today)
  select today, months_add(today,1) as next_month from t1;
+---------------------+---------------------+
| today               | next_month          |
+---------------------+---------------------+
| 2016-05-19 00:00:00 | 2016-06-19 00:00:00 |
+---------------------+---------------------+
with t1 as (select trunc(now(), 'dd') as today)
  select today, add_months(today,1) as next_month from t1;
+---------------------+---------------------+
| today               | next_month          |
+---------------------+---------------------+
| 2016-05-19 00:00:00 | 2016-06-19 00:00:00 |
+---------------------+---------------------+
Thefollowingexamplesshowhowifmonths_add() wouldreturnanonexistentdate,duetodifferentmonths
havingdifferentnumbersofdays,thefunctionreturnsaTIMESTAMP fromthelastdayoftherelevantmonth.For
example,addingonemonthtoJanuary31producesadateofFebruary29thintheyear2016(aleapyear),and
February28thintheyear2015(anon-leap year).
with t1 as (select cast('2016-01-31' as timestamp) as jan_31)
  select jan_31, months_add(jan_31,1) as feb_31 from t1;
+---------------------+---------------------+
| jan_31              | feb_31              |
+---------------------+---------------------+
| 2016-01-31 00:00:00 | 2016-02-29 00:00:00 |
+---------------------+---------------------+
with t1 as (select cast('2015-01-31' as timestamp) as jan_31)
  select jan_31, months_add(jan_31,1) as feb_31 from t1;
+---------------------+---------------------+
| jan_31              | feb_31              |
+---------------------+---------------------+
| 2015-01-31 00:00:00 | 2015-02-28 00:00:00 |
+---------------------+---------------------+
MONTHS_BETWEEN(TIME STAMPnewer,TIMESTAMPolder)
Purpose: ReturnsthenumberofmonthsbetweenthedateportionsoftwoTIMESTAMP values.Canincludea
fractionalpartrepresentingextradaysinadditiontothefullmonthsbetweenthedates.Thefractionalcomponen t
iscomputedbydividingthedifferenceindaysby31(regardlessofthemonth).
Returntype:DOUBLE
Addedin:CDH5.5.0/Impala2.3.0
Usagenotes:
Typicallyusedinbusinesscontexts,forexampletodeterminewhetheraspecified numberofmonthshavepassed
orwhethersomeend-of-mon thdeadlinewasreached.
Iftheonlyconsiderationisthenumberoffullmonthsandanyfractionalvalueisnotsignificant,use
int_months_between() instead.
Themethodofdetermining thenumberofelapsedmonthsincludessomespecialhandlingofmonthswithdifferent
numbersofdaysthatcreatesedgecasesfordatesbetweenthe28thand31stdaysofcertainmonths.
IfeithervalueisNULL,whichcouldhappenforexamplewhenconvertinganonexistentdatestringsuchas
'2015-02-29' toaTIMESTAMP ,theresultisalsoNULL.
Ifthefirstargumentrepresentsanearliertimethanthesecondargument,theresultisnegative.
442|ApacheImpalaGuideImpalaSQLLanguageReference
Examples:
ThefollowingexamplesshowhowdatesthatareonthesamedayofthemonthareconsideredtobeexactlyN
monthsapart,evenifthemonthshavedifferentnumbersofdays.
select months_between('2015-02-28', '2015-01-28');
+--------------------------------------------+
| months_between('2015-02-28', '2015-01-28') |
+--------------------------------------------+
| 1                                          |
+--------------------------------------------+
select months_between(now(), now() + interval 1 month);
+-------------------------------------------------+
| months_between(now(), now() + interval 1 month) |
+-------------------------------------------------+
| -1                                              |
+-------------------------------------------------+
select months_between(now() + interval 1 year, now());
+------------------------------------------------+
| months_between(now() + interval 1 year, now()) |
+------------------------------------------------+
| 12                                             |
+------------------------------------------------+
ThefollowingexamplesshowhowdatesthatareonthelastdayofthemonthareconsideredtobeexactlyNmonths
apart,evenifthemonthshavedifferentnumbersofdays.Forexample,fromJanuary28thtoFebruary28this
exactlyonemonthbecausethedayofthemonthisidentical;January31sttoFebruary28thisexactlyonemonth
becauseinbothcasesitisthelastdayofthemonth;butJanuary29thor30thtoFebruary28thisconsidereda
fractionalmonth.
select months_between('2015-02-28', '2015-01-31');
+--------------------------------------------+
| months_between('2015-02-28', '2015-01-31') |
+--------------------------------------------+
| 1                                          |
+--------------------------------------------+
select months_between('2015-02-28', '2015-01-29');
+--------------------------------------------+
| months_between('2015-02-28', '2015-01-29') |
+--------------------------------------------+
| 0.967741935483871                          |
+--------------------------------------------+
select months_between('2015-02-28', '2015-01-30');;
+--------------------------------------------+
| months_between('2015-02-28', '2015-01-30') |
+--------------------------------------------+
| 0.935483870967742                          |
+--------------------------------------------+
Thefollowingexamplesshowhowdatesthatarenotaprecisenumberofmonthsapartresultinafractionalreturn
value.
select months_between('2015-03-01', '2015-01-28');
+--------------------------------------------+
| months_between('2015-03-01', '2015-01-28') |
+--------------------------------------------+
| 1.129032258064516                          |
+--------------------------------------------+
select months_between('2015-03-01', '2015-02-28');
+--------------------------------------------+
| months_between('2015-03-01', '2015-02-28') |
+--------------------------------------------+
| 0.1290322580645161                         |
+--------------------------------------------+
ApacheImpalaGuide|443ImpalaSQLLanguageReference
select months_between('2015-06-02', '2015-05-29');
+--------------------------------------------+
| months_between('2015-06-02', '2015-05-29') |
+--------------------------------------------+
| 0.1290322580645161                         |
+--------------------------------------------+
select months_between('2015-03-01', '2015-01-25');
+--------------------------------------------+
| months_between('2015-03-01', '2015-01-25') |
+--------------------------------------------+
| 1.225806451612903                          |
+--------------------------------------------+
select months_between('2015-03-01', '2015-02-25');
+--------------------------------------------+
| months_between('2015-03-01', '2015-02-25') |
+--------------------------------------------+
| 0.2258064516129032                         |
+--------------------------------------------+
select months_between('2015-02-28', '2015-02-01');
+--------------------------------------------+
| months_between('2015-02-28', '2015-02-01') |
+--------------------------------------------+
| 0.8709677419354839                         |
+--------------------------------------------+
select months_between('2015-03-28', '2015-03-01');
+--------------------------------------------+
| months_between('2015-03-28', '2015-03-01') |
+--------------------------------------------+
| 0.8709677419354839                         |
+--------------------------------------------+
ThefollowingexamplesshowhowthetimeportionoftheTIMESTAMP valuesareirrelevantforcalculatingthe
monthinterval.Eventhefractionalpartoftheresultonlydependsonthenumberoffulldaysbetweentheargument
values,regardlessofthetimeportion.
select months_between('2015-05-28 23:00:00', '2015-04-28 11:45:00');
+--------------------------------------------------------------+
| months_between('2015-05-28 23:00:00', '2015-04-28 11:45:00') |
+--------------------------------------------------------------+
| 1                                                            |
+--------------------------------------------------------------+
select months_between('2015-03-28', '2015-03-01');
+--------------------------------------------+
| months_between('2015-03-28', '2015-03-01') |
+--------------------------------------------+
| 0.8709677419354839                         |
+--------------------------------------------+
select months_between('2015-03-28 23:00:00', '2015-03-01 11:45:00');
+--------------------------------------------------------------+
| months_between('2015-03-28 23:00:00', '2015-03-01 11:45:00') |
+--------------------------------------------------------------+
| 0.8709677419354839                                           |
+--------------------------------------------------------------+
MONTHS_SUB(TIME STAMPdate,INTmonths),MONTHS_SUB(TIME STAMPdate,BIGINTmonths)
Purpose: Returnsthespecified dateandtimeminussomenumberofmonths.
Returntype:TIMESTAMP
Examples:
with t1 as (select trunc(now(), 'dd') as today)
444|ApacheImpalaGuideImpalaSQLLanguageReference
  select today, months_sub(today,1) as last_month from t1;
+---------------------+---------------------+
| today               | last_month          |
+---------------------+---------------------+
| 2016-06-01 00:00:00 | 2016-05-01 00:00:00 |
+---------------------+---------------------+
NANOSECONDS_ADD(TIME STAMPdate,INTnanoseconds),NANOSECONDS_ADD(TIME STAMPdate,BIGINT
nanoseconds)
Purpose: Returnsthespecified dateandtimeplussomenumberofnanoseconds.
Returntype:TIMESTAMP
Kuduconsiderations:
ThenanosecondportionofanImpalaTIMESTAMP valueisroundedtothenearestmicrosecondwhenthatvalueis
storedinaKudutable.
Examples:
select now() as right_now, nanoseconds_add(now(), 1) as 1_nanosecond_later;
+-------------------------------+-------------------------------+
| right_now                     | 1_nanosecond_later            |
+-------------------------------+-------------------------------+
| 2016-06-01 15:42:00.361026000 | 2016-06-01 15:42:00.361026001 |
+-------------------------------+-------------------------------+
-- 1 billion nanoseconds = 1 second.
select now() as right_now, nanoseconds_add(now(), 1e9) as 1_second_later;
+-------------------------------+-------------------------------+
| right_now                     | 1_second_later                |
+-------------------------------+-------------------------------+
| 2016-06-01 15:42:52.926706000 | 2016-06-01 15:42:53.926706000 |
+-------------------------------+-------------------------------+
NANOSECONDS_SUB(TIME STAMPdate,INTnanoseconds),NANOSECONDS_SUB(TIME STAMPdate,BIGINT
nanoseconds)
Purpose: Returnsthespecified dateandtimeminussomenumberofnanoseconds.
Returntype:TIMESTAMP
Kuduconsiderations:
ThenanosecondportionofanImpalaTIMESTAMP valueisroundedtothenearestmicrosecondwhenthatvalueis
storedinaKudutable.
select now() as right_now, nanoseconds_sub(now(), 1) as 1_nanosecond_earlier;
+-------------------------------+-------------------------------+
| right_now                     | 1_nanosecond_earlier          |
+-------------------------------+-------------------------------+
| 2016-06-01 15:44:14.355837000 | 2016-06-01 15:44:14.355836999 |
+-------------------------------+-------------------------------+
-- 1 billion nanoseconds = 1 second.
select now() as right_now, nanoseconds_sub(now(), 1e9) as 1_second_earlier;
+-------------------------------+-------------------------------+
| right_now                     | 1_second_earlier              |
+-------------------------------+-------------------------------+
| 2016-06-01 15:44:54.474929000 | 2016-06-01 15:44:53.474929000 |
+-------------------------------+-------------------------------+
NEXT_DAY(TIMESTAMPdate,STRINGweekday)
Purpose: Returnsthedateoftheweekdaythatfollowsthespecified date.
Returntype:TIMESTAMP
ApacheImpalaGuide|445ImpalaSQLLanguageReference
Usagenotes:
Theweekdayparameteriscase-insensitiv e.Thefollowingvaluesareacceptedforweekday:"Sunday" /"Sun",
"Monday" /"Mon","Tuesday" /"Tue","Wednesday" /"Wed","Thursday" /"Thu","Friday" /"Fri",
"Saturday" /"Sat"
Callingthefunctionwiththecurrentdateandweekdayreturnsthedatethatisoneweeklater.
Examples:
select next_day('2013-12-25','Saturday');
-- Returns '2013-12-28 00:00:00' the first Saturday after December 25, 2013.
select next_day(to_timestamp('08-1987-21', 'mm-yyyy-dd'), 'Friday');
-- Returns '1987-08-28 00:00:00' the first Friday after August 28, 1987.
select next_day(now(), 'Thu');
-- Executed on 2018-07-12, the function returns '2018-07-13 00:00:00', one week
-- after the current date.
NOW()
Purpose: Returnsthecurrentdateandtime(inthelocaltimezone)asaTIMESTAMP value.
Returntype:TIMESTAMP
Usagenotes:
Tofindadate/timevalueinthefutureorthepastrelativetothecurrentdateandtime,addorsubtractanINTERVAL
expressiontothereturnvalueofnow().SeeTIMESTAMPDataTypeonpage130forexamples.
ToproduceaTIMESTAMP representingthecurrentdateandtimethatcanbesharedorstoredwithoutinteroperability
problemsduetotimezonedifferences,usetheto_utc_timestamp() functionandspecifythetimezoneofthe
server.WhenTIMESTAMP dataisstoredinUTCform,anyapplicationthatqueriesthosevaluescanconvertthem
totheappropriatelocaltimezonebycallingtheinversefunction,from_utc_timestamp() .
Todeterminethetimezoneoftheserveryouareconnectedto,inCDH5.5/Impala2.3andhigheryoucancallthe
timeofday() function, whichincludesthetimezonespecifierinitsreturnvalue.Remember thatwithcloud
computing ,theserveryouinteractwithmightbeinadifferenttimezonethanyouare,ordifferentsessionsmight
connecttoserversindifferenttimezones,oraclustermightincludeserversinmorethanonetimezone.
Anyreferencestothenow()functionareevaluatedatthestartofaquery.Allcallstonow()withinthesamequery
returnthesamevalue,andthevaluedoesnotdependonhowlongthequerytakes.
Examples:
select now() as 'Current time in California USA',
  to_utc_timestamp(now(), 'PDT') as 'Current time in Greenwich UK';
+--------------------------------+-------------------------------+
| current time in california usa | current time in greenwich uk  |
+--------------------------------+-------------------------------+
| 2016-06-01 15:52:08.980072000  | 2016-06-01 22:52:08.980072000 |
+--------------------------------+-------------------------------+
select now() as right_now,
  now() + interval 1 day as tomorrow,
  now() + interval 1 week - interval 3 hours as almost_a_week_from_now;
+-------------------------------+-------------------------------+-------------------------------+
| right_now                     | tomorrow                      | almost_a_week_from_now
        |
+-------------------------------+-------------------------------+-------------------------------+
| 2016-06-01 15:55:39.671690000 | 2016-06-02 15:55:39.671690000 | 2016-06-08 
12:55:39.671690000 |
+-------------------------------+-------------------------------+-------------------------------+
446|ApacheImpalaGuideImpalaSQLLanguageReference
QUARTER(TIME STAMPdate)
Purpose: ReturnsthequarterintheinputTIMESTAMP expressionasanintegervalue,1,2,3,or4,where1represents
January1throughMarch31.
Returntype:INT
SECOND(TIME STAMPdate)
Purpose: ReturnsthesecondfieldfromaTIMESTAMP value.
Returntype:INT
Examples:
select now() as right_now,
  second(now()) as seconds_in_current_minute;
+-------------------------------+---------------------------+
| right_now                     | seconds_in_current_minute |
+-------------------------------+---------------------------+
| 2016-06-01 16:03:57.006603000 | 57                        |
+-------------------------------+---------------------------+
SECONDS_ADD(TIME STAMPdate,INTseconds),SECONDS_ADD(TIME STAMPdate,BIGINTseconds)
Purpose: Returnsthespecified dateandtimeplussomenumberofseconds.
Returntype:TIMESTAMP
Examples:
select now() as right_now,
  seconds_add(now(), 10) as 10_seconds_from_now;
+-------------------------------+-------------------------------+
| right_now                     | 10_seconds_from_now           |
+-------------------------------+-------------------------------+
| 2016-06-01 16:05:21.573935000 | 2016-06-01 16:05:31.573935000 |
+-------------------------------+-------------------------------+
SECONDS_SUB(TIME STAMPdate,INTseconds),SECONDS_SUB(TIME STAMPdate,BIGINTseconds)
Purpose: Returnsthespecified dateandtimeminussomenumberofseconds.
Returntype:TIMESTAMP
Examples:
select now() as right_now,
  seconds_sub(now(), 10) as 10_seconds_ago;
+-------------------------------+-------------------------------+
| right_now                     | 10_seconds_ago                |
+-------------------------------+-------------------------------+
| 2016-06-01 16:06:03.467931000 | 2016-06-01 16:05:53.467931000 |
+-------------------------------+-------------------------------+
SUBDATE(TIMESTAMPstartdate,INTdays),SUBDATE(TIMESTAMPstartdate,BIGINTdays)
Purpose: Subtractsaspecified numberofdaysfromaTIMESTAMP value.SimilartoDATE_SUB() ,butstartswith
anactualTIMESTAMP valueinsteadofastringthatisconvertedtoaTIMESTAMP .
Returntype:TIMESTAMP
Examples:
ApacheImpalaGuide|447ImpalaSQLLanguageReference
ThefollowingexamplesshowhowtosubtractanumberofdaysfromaTIMESTAMP .Thenumberofdayscanalso
benegative,whichgivesthesameeffectastheADDDATE() function.
select now() as right_now, subdate(now(), 30) as now_minus_30;
+-------------------------------+-------------------------------+
| right_now                     | now_minus_30                  |
+-------------------------------+-------------------------------+
| 2016-05-20 11:00:15.084991000 | 2016-04-20 11:00:15.084991000 |
+-------------------------------+-------------------------------+
select now() as right_now, subdate(now(), -15) as now_plus_15;
+-------------------------------+-------------------------------+
| right_now                     | now_plus_15                   |
+-------------------------------+-------------------------------+
| 2016-05-20 11:00:44.766091000 | 2016-06-04 11:00:44.766091000 |
+-------------------------------+-------------------------------+
TIMEOFDAY()
Purpose: Returnsastringrepresentationofthecurrentdateandtime,accordingtothetimeofthelocalsystem,
including anytimezonedesignation.
Returntype:STRING
Addedin:CDH5.5.0/Impala2.3.0
Usagenotes:Theresultvaluerepresentssimilarinformationasthenow()function, onlyasaSTRINGtypeand
withsomewhatdifferentformatting.Forexample,thedayoftheweekandthetimezoneidentifierareincluded.
Thisfunctionisintendedprimarily forcompatibilitywithSQLcodefromothersystemsthatalsohaveatimeofday()
function. Prefertousenow()ifpracticalforanynewImpalacode.
Examples:
ThefollowingexamplesshowtheformatoftheTIMEOFDAY() returnvalue,illustratehowthatvalueisrepresented
asaSTRINGthatyoucanmanipula tewithstringprocessingfunctions, andhowtheformatcompareswiththe
returnvaluefromtheNOW()function.
/* Date and time fields in a STRING return value. */
select timeofday();
+------------------------------+
| timeofday()                  |
+------------------------------+
| Tue Sep 01 15:13:18 2015 PDT |
+------------------------------+
/* The return value can be processed by other string functions. */
select upper(timeofday());
+------------------------------+
| upper(timeofday())           |
+------------------------------+
| TUE SEP 01 15:13:38 2015 PDT |
+------------------------------+
/* The TIMEOFDAY() result is formatted differently than NOW(). NOW() returns a TIMESTAMP.
 */
select now(), timeofday();
+-------------------------------+------------------------------+
| now()                         | timeofday()                  |
+-------------------------------+------------------------------+
| 2015-09-01 15:15:25.930021000 | Tue Sep 01 15:15:25 2015 PDT |
+-------------------------------+------------------------------+
/* You can strip out the time zone field to use in calls to from_utc_timestamp(). */
select regexp_replace(timeofday(), '.* ([A-Z]+)$', '\\1') as current_timezone;
+------------------+
| current_timezone |
+------------------+
| PDT              |
+------------------+
448|ApacheImpalaGuideImpalaSQLLanguageReference
TIMESTAMP_CMP(TIME STAMPt1,TIMESTAMPt2)
Purpose: TestsifoneTIMESTAMP valueisnewerthan,olderthan,oridenticaltoanotherTIMESTAMP
Returntype:INT(either-1,0,1,orNULL)
Addedin:CDH5.5.0/Impala2.3.0
Usagenotes:
Usagenotes:Acomparison functionforTIMESTAMP valuesthatonlytestswhetherthedateandtimeincreases,
decreases,orstaysthesame.SimilartothesIGN()functionfornumericvalues.
Examples:
Thefollowingexamplesshowallthepossiblereturnvaluesfortimestamp_cmp() .Ifthefirstargumentrepresents
alaterpointintimethanthesecondargument,theresultis1.Theamountofthedifferenceisirrelevant,onlythe
factthatoneargumentisgreaterthanorlessthantheother.Ifthefirstargumentrepresentsanearlierpointin
timethanthesecondargument,theresultis-1.Ifthefirstandsecondargumentsrepresentidenticalpointsintime,
theresultis0.IfeitherargumentisNULL,theresultisNULL.
/* First argument 'later' than second argument. */
select timestamp_cmp(now() + interval 70 minutes, now())
  as now_vs_in_70_minutes;
+----------------------+
| now_vs_in_70_minutes |
+----------------------+
| 1                    |
+----------------------+
select timestamp_cmp(now() +
  interval 3 days +
  interval 5 hours, now())
  as now_vs_days_from_now;
+----------------------+
| now_vs_days_from_now |
+----------------------+
| 1                    |
+----------------------+
/* First argument 'earlier' than second argument. */
select timestamp_cmp(now(), now() + interval 2 hours)
  as now_vs_2_hours_ago;
+--------------------+
| now_vs_2_hours_ago |
+--------------------+
| -1                 |
+--------------------+
/* Both arguments represent the same point in time. */
select timestamp_cmp(now(), now())
  as identical_timestamps;
+----------------------+
| identical_timestamps |
+----------------------+
| 0                    |
+----------------------+
select timestamp_cmp
(
  now() + interval 1 hour,
  now() + interval 60 minutes
) as equivalent_date_times;
+-----------------------+
| equivalent_date_times |
+-----------------------+
| 0                     |
+-----------------------+
/* Either argument NULL. */
ApacheImpalaGuide|449ImpalaSQLLanguageReference
select timestamp_cmp(now(), null)
  as now_vs_null;
+-------------+
| now_vs_null |
+-------------+
| NULL        |
+-------------+
TO_DATE(TIMESTAMPtimestamp)
Purpose: Returnsastringrepresentationofthedatefieldfromatimestampvalue.
Returntype:STRING
Examples:
select now() as right_now,
  concat('The date today is ',to_date(now()),'.') as date_announcement;
+-------------------------------+-------------------------------+
| right_now                     | date_announcement             |
+-------------------------------+-------------------------------+
| 2016-06-01 16:30:36.890325000 | The date today is 2016-06-01. |
+-------------------------------+-------------------------------+
TO_TIMESTAMP(BIGINT unixtime) ,TO_TIMESTAMP(STRINGdate,STRINGpattern)
Purpose: Convertsanintegerorstringrepresentingadate/timevalueintothecorresponding TIMESTAMP value.
Returntype:TIMESTAMP
Addedin:CDH5.5.0/Impala2.3.0
Usagenotes:
Anintegerargumentrepresentsthenumberofsecondspasttheepoch(midnightonJanuary1,1970).Itisthe
converseoftheunix_timestamp() function, whichproducesaBIGINTrepresentingthenumberofsecondspast
theepoch.
Astringargument,plusanotherstringargumentrepresentingthepattern,turnsanarbitrarystringrepresentation
ofadateandtimeintoatrueTIMESTAMP value.Theabilitytoparsemanykindsofdateandtimeformatsallows
youtodealwithtemporaldatafromdiversesources,andifdesiredtoconverttoefficientTIMESTAMP valuesduring
yourETLprocess.UsingTIMESTAMP directlyinqueriesandexpressionsletsyouperformdateandtimecalculations
withouttheoverheadofextrafunctioncallsandconversionseachtimeyoureferencetheapplicablecolumns.
Examples:
ThefollowingexamplesdemonstratehowtoconvertanarbitrarystringrepresentationtoTIMESTAMP basedona
patternstring:
select to_timestamp('Sep 25, 1984', 'MMM dd, yyyy');
+----------------------------------------------+
| to_timestamp('sep 25, 1984', 'mmm dd, yyyy') |
+----------------------------------------------+
| 1984-09-25 00:00:00                          |
+----------------------------------------------+
select to_timestamp('1984/09/25', 'yyyy/MM/dd');
+------------------------------------------+
| to_timestamp('1984/09/25', 'yyyy/mm/dd') |
+------------------------------------------+
| 1984-09-25 00:00:00                      |
+------------------------------------------+
450|ApacheImpalaGuideImpalaSQLLanguageReference
ThefollowingexamplesshowhowtoconvertaBIGINTrepresentingsecondspastepochintoaTIMESTAMP value:
-- One day past the epoch.
select to_timestamp(24 * 60 * 60);
+----------------------------+
| to_timestamp(24 * 60 * 60) |
+----------------------------+
| 1970-01-02 00:00:00        |
+----------------------------+
-- 60 seconds in the past.
select now() as 'current date/time',
  unix_timestamp(now()) 'now in seconds',
  to_timestamp(unix_timestamp(now()) - 60) as '60 seconds ago';
+-------------------------------+----------------+---------------------+
| current date/time             | now in seconds | 60 seconds ago      |
+-------------------------------+----------------+---------------------+
| 2017-10-01 22:03:46.885624000 | 1506895426     | 2017-10-01 22:02:46 |
+-------------------------------+----------------+---------------------+
TO_UTC_TIMESTAMP(TIME STAMP,STRINGtimezone)
Purpose: Convertsaspecified timestampvalueinaspecified timezoneintothecorresponding valuefortheUTC
timezone.
Returntype:TIMESTAMP
Usagenotes:
Oftenusedincombinationwiththenow()function, totranslatelocaldateandtimevaluestotheUTCtimezone
forconsistentrepresentationondisk.Theoppositeofthefrom_utc_timestamp() function.
Seediscussion oftimezonesinTIMESTAMPDataTypeonpage130forinformationaboutusingthisfunctionfor
conversionsbetweenthelocaltimezoneandUTC.
Examples:
Thesimplestuseofthisfunctionistoturnalocaldate/timevaluetoonewiththestandardizedUTCtimezone.
BecausethetimezonespecifierisnotsavedaspartoftheImpalaTIMESTAMP value,allapplicationsthatreferto
suchdatamustagreeinadvancewhichtimezonethevaluesrepresent.IfdifferentpartsoftheETLcycle,ordifferent
instancesoftheapplication,occurindifferenttimezones,theidealreferencepointistoconvertallTIMESTAMP
valuestoUTCforstorage.
select now() as 'Current time in California USA',
  to_utc_timestamp(now(), 'PDT') as 'Current time in Greenwich UK';
+--------------------------------+-------------------------------+
| current time in california usa | current time in greenwich uk  |
+--------------------------------+-------------------------------+
| 2016-06-01 15:52:08.980072000  | 2016-06-01 22:52:08.980072000 |
+--------------------------------+-------------------------------+
OnceavalueisconvertedtotheUTCtimezonebyto_utc_timestamp() ,itcanbeconvertedbacktothelocal
timezonewithfrom_utc_timestamp() .Youcancombinethesefunctions usingdifferenttimezoneidentifiers
toconvertaTIMESTAMP betweenanytwotimezones.ThisexamplestartswithaTIMESTAMP valuerepresenting
PacificDaylightTime,convertsittoUTC,andconvertsittotheequivalentvalueinEasternDaylightTime.
select now() as 'Current time in California USA',
  from_utc_timestamp
  (
    to_utc_timestamp(now(), 'PDT'),
    'EDT'
  ) as 'Current time in New York, USA';
+--------------------------------+-------------------------------+
| current time in california usa | current time in new york, usa |
+--------------------------------+-------------------------------+
ApacheImpalaGuide|451ImpalaSQLLanguageReference
| 2016-06-01 18:14:12.743658000  | 2016-06-01 21:14:12.743658000 |
+--------------------------------+-------------------------------+
TRUNC(TIME STAMPtimestamp,STRINGunit)
Purpose: StripsofffieldsfromaTIMESTAMP value.
Unitargument:TheunitargumentvaluefortruncatingTIMESTAMP valuesiscase-sensitiv e.Thisargumentstring
canbeoneof:
â¢SYYYY,YYYY,YEAR,SYEAR,YYY,YY,Y:Year.
â¢Q:Quarter.
â¢MONTH,MON,MM,RM:Month.
â¢WW,W:Samedayoftheweekasthefirstdayofthemonth.
â¢DDD,DD,J:Day.
â¢DAY,DY,D:Startingdayoftheweek.(Notnecessarily thecurrentday.)
â¢HH,HH12,HH24:Hour.ATIMESTAMP valuetruncatedtothehourisalwaysrepresentedin24-hournotation,
evenfortheHH12argumentstring.
â¢MI:Minute.
Addedin:TheabilitytotruncatenumericvaluesisnewstartinginCDH5.13/Impala2.10.
Usagenotes:
TheTIMESTAMP formistypicallyusedinGROUP BY queriestoaggregateresultsfromthesamehour,day,week,
month,quarter,andsoon.YoucanalsousethisfunctioninanINSERT ... SELECT intoapartitioned tableto
divideTIMESTAMP valuesintothecorrectpartition.
BecausethereturnvalueisaTIMESTAMP ,ifyoucasttheresultofTRUNC() toSTRING,youwilloftenseezeroed-out
portionssuchas00:00:00 inthetimefield.Ifyouonlyneedtheindividual unitssuchashour,day,month,oryear,
usetheEXTRACT() functioninstead.Ifyouneedtheindividual unitsfromatruncatedTIMESTAMP value,runthe
TRUNCATE() functionontheoriginalvalue,thenrunEXTRACT() ontheresult.
Thetrunc() functionalsohasasignaturethatappliestoDOUBLEorDECIMAL values.truncate() ,trunc() ,and
dtrunc() areallaliasedtothesamefunction. Seetruncate() underImpalaMathematicalFunctions onpage
397fordetails.
Returntype:TIMESTAMP
Examples:
Thefollowingexampleshowshowtheargument'Q'returnsaTIMESTAMP representingthebeginning ofthe
appropriatecalendarquarter.Thisreturnvalueisthesameforinputvaluesthatcouldbeseparatedbyweeksor
months.Ifyoustoredthetrunc() resultinapartition keycolumn,thetablewouldhavefourpartitions peryear.
select now() as right_now, trunc(now(), 'Q') as current_quarter;
+-------------------------------+---------------------+
| right_now                     | current_quarter     |
+-------------------------------+---------------------+
| 2016-06-01 18:32:02.097202000 | 2016-04-01 00:00:00 |
+-------------------------------+---------------------+
select now() + interval 2 weeks as 2_weeks_from_now,
  trunc(now() + interval 2 weeks, 'Q') as still_current_quarter;
+-------------------------------+-----------------------+
| 2_weeks_from_now              | still_current_quarter |
+-------------------------------+-----------------------+
| 2016-06-15 18:36:19.584257000 | 2016-04-01 00:00:00   |
+-------------------------------+-----------------------+
452|ApacheImpalaGuideImpalaSQLLanguageReference
UNIX_TIME STAMP(),UNIX_TIME STAMP(STRINGdatetime),UNIX_TIME STAMP(STRINGdatetime,STRINGformat),
UNIX_TIME STAMP(TIME STAMPdatetime)
Purpose: ReturnsaUnixtime,whichisanumberofsecondselapsedsince'1970-01-01 00:00:00' UTC.Ifcalledwith
noargument,thecurrentdateandtimeisconvertedtoitsUnixtime.Ifcalledwitharguments,thefirstargument
representedastheTIMESTAMP orSTRINGisconvertedtoitsUnixtime.
Returntype:BIGINT
Usagenotes:
SeeFROM_UNIXTIME() fordetailsaboutthepatternsyoucanuseintheformatstringtorepresenttheposition
ofyear,month,day,andsooninthedatestring.InImpala1.3andhigher,youhavemoreflexibilitytoswitchthe
positions ofelementsandusedifferentseparatorcharacters.
InCDH5.4.3andhigher,youcanincludeatrailinguppercaseZqualifiertoindicateâZuluâtime,asynonymforUTC.
InCDH5.5/Impala2.3andhigher,youcanincludeatimezoneoffsetspecified asminutesandhours,providedyou
alsospecifythedetailsintheformatstringargument.Theoffsetisspecified intheformatstringasaplusorminus
signfollowedbyhh:mm,hhmm,orhh.Thehhmustbelowercase,todistinguishitfromtheHHrepresenthoursin
theactualtimevalue.Currently,onlynumerictimezoneoffsetsareallowed,notsymbolicnames.
InImpala2.2.0andhigher,built-infunctions thatacceptorreturnintegersrepresentingTIMESTAMP valuesusethe
BIGINTtypeforparametersandreturnvalues,ratherthanINT.Thischangeletsthedateandtimefunctions avoid
anoverflowerrorthatwouldotherwiseoccuronJanuary19th,2038(knownastheâYear2038problemâorâY2K38
problemâ).ThischangeaffectstheFROM_UNIXTIME() andUNIX_TIMESTAMP() functions. Youmightneedto
changeapplicationcodethatinteractswiththesefunctions, changethetypesofcolumnsthatstorethereturn
values,oraddCAST()callstoSQLstatementsthatcallthesefunctions.
UNIX_TIMESTAMP() andFROM_UNIXTIME() areoftenusedincombinationtoconvertaTIMESTAMP valueinto
aparticular stringformat.Forexample:
SELECT FROM_UNIXTIME(UNIX_TIMESTAMP(NOW() + interval 3 days),
  'yyyy/MM/dd HH:mm') AS yyyy_mm_dd_hh_mm;
+------------------+
| yyyy_mm_dd_hh_mm |
+------------------+
| 2016/06/03 11:38 |
+------------------+
ThewaythisfunctiondealswithtimezoneswhenconvertingtoorfromTIMESTAMP valuesisaffectedbythe
--use_local_tz_for_unix_timestamp_conversions startupflagfortheimpalad daemon. SeeTIMESTAMP
DataTypeonpage130fordetailsabouthowImpalahandlestimezoneconsiderationsfortheTIMESTAMP data
type.
Examples:
Thefollowingexamplesshowdifferentwaysofturningthesamedateandtimeintoanintegervalue.Aformat
stringthatImpalarecognizesbydefaultisinterpretedasaUTCdateandtime.ThetrailingZisaconfirmationthat
thetimezoneisUTC.Ifthedateandtimestringisformatteddifferently,asecondargumentspecifiestheposition
andunitsforeachofthedateandtimevalues.
ThefinaltwoexamplesshowhowtospecifyatimezoneoffsetofPacificDaylightSavingTime,whichis7hours
earlierthanUTC.Youcanusethenumericoffset-07:00andtheequivalentsuffixof-hh:mmintheformatstring,
orspecifythemnemonic nameforthetimezoneinacalltoto_utc_timestamp() .Thisparticular dateandtime
expressedinPDTtranslatestoadifferentnumberthanthesamedateandtimeexpressedinUTC.
-- 3 ways of expressing the same date/time in UTC and converting to an integer.
select unix_timestamp('2015-05-15 12:00:00');
+---------------------------------------+
| unix_timestamp('2015-05-15 12:00:00') |
+---------------------------------------+
| 1431691200                            |
ApacheImpalaGuide|453ImpalaSQLLanguageReference
+---------------------------------------+
select unix_timestamp('2015-05-15 12:00:00Z');
+----------------------------------------+
| unix_timestamp('2015-05-15 12:00:00z') |
+----------------------------------------+
| 1431691200                             |
+----------------------------------------+
select unix_timestamp
(
  'May 15, 2015 12:00:00',
  'MMM dd, yyyy HH:mm:ss'
) as may_15_month_day_year;
+-----------------------+
| may_15_month_day_year |
+-----------------------+
| 1431691200            |
+-----------------------+
-- 2 ways of expressing the same date and time but in a different timezone.
-- The resulting integer is different from the previous examples.
select unix_timestamp
(
  '2015-05-15 12:00:00-07:00',
  'yyyy-MM-dd HH:mm:ss-hh:mm'
) as may_15_year_month_day;
+-----------------------+
| may_15_year_month_day |
+-----------------------+
| 1431716400            |
+-----------------------+
select unix_timestamp
  (to_utc_timestamp(
    '2015-05-15 12:00:00',
    'PDT')
  ) as may_15_pdt;
+------------+
| may_15_pdt |
+------------+
| 1431716400 |
+------------+
UTC_TIMESTAMP()
Purpose: ReturnsaTIMESTAMP corresponding tothecurrentdateandtimeintheUTCtimezone.
Returntype:TIMESTAMP
Addedin:CDH5.13
Usagenotes:
Similartothenow()orcurrent_timestamp() functions, butdoesnotusethelocaltimezoneasthosefunctions
do.Useutc_timestamp() torecordTIMESTAMP valuesthatareinteroperablewithserversaroundtheworld,in
arbitrarytimezones,withouttheneedforadditional conversionfunctions tostandardizethetimezoneofeach
valuerepresentingadate/time.
Forworkingwithdate/timevaluesrepresentedasintegervalues,youcanconvertbackandforthbetweenTIMESTAMP
andBIGINTwiththeunix_micros_to_utc_timestamp() andutc_to_unix_micros() functions. Theinteger
valuesrepresentthenumberofmicrosecondssincetheUnixepoch(midnightonJanuary1,1970).
Examples:
454|ApacheImpalaGuideImpalaSQLLanguageReference
ThefollowingexampleshowshowNOW()andCURRENT_TIMESTAMP() representthecurrentdate/timeinthe
localtimezone(inthiscase,UTC-7),whileUTC_TIMESTAMP() representsthesamedate/timeinthestandardized
UTCtimezone:
select now(), utc_timestamp();
+-------------------------------+-------------------------------+
| now()                         | utc_timestamp()               |
+-------------------------------+-------------------------------+
| 2017-10-01 23:33:58.919688000 | 2017-10-02 06:33:58.919688000 |
+-------------------------------+-------------------------------+
select current_timestamp(), utc_timestamp();
+-------------------------------+-------------------------------+
| current_timestamp()           | utc_timestamp()               |
+-------------------------------+-------------------------------+
| 2017-10-01 23:34:07.400642000 | 2017-10-02 06:34:07.400642000 |
+-------------------------------+-------------------------------+
WEEK(TIME STAMPdate),WEEKOFYEAR(TIMESTAMPdate)
Purpose: Returnsthecorresponding week(1-53)fromthedateportionofaTIMESTAMP .
Returntype:INT
Examples:
select now() as right_now, weekofyear(now()) as this_week;
+-------------------------------+-----------+
| right_now                     | this_week |
+-------------------------------+-----------+
| 2016-06-01 22:40:06.763771000 | 22        |
+-------------------------------+-----------+
select now() + interval 2 weeks as in_2_weeks,
  weekofyear(now() + interval 2 weeks) as week_after_next;
+-------------------------------+-----------------+
| in_2_weeks                    | week_after_next |
+-------------------------------+-----------------+
| 2016-06-15 22:41:22.098823000 | 24              |
+-------------------------------+-----------------+
WEEKS_ADD(TIME STAMPdate,INTweeks),WEEKS_ADD(TIME STAMPdate,BIGINTweeks)
Purpose: Returnsthespecified dateandtimeplussomenumberofweeks.
Returntype:TIMESTAMP
Examples:
select now() as right_now, weeks_add(now(), 2) as week_after_next;
+-------------------------------+-------------------------------+
| right_now                     | week_after_next               |
+-------------------------------+-------------------------------+
| 2016-06-01 22:43:20.973834000 | 2016-06-15 22:43:20.973834000 |
+-------------------------------+-------------------------------+
WEEKS_SUB(TIME STAMPdate,INTweeks),WEEKS_SUB(TIME STAMPdate,BIGINTweeks)
Purpose: Returnsthespecified dateandtimeminussomenumberofweeks.
Returntype:TIMESTAMP
Examples:
select now() as right_now, weeks_sub(now(), 2) as week_before_last;
+-------------------------------+-------------------------------+
| right_now                     | week_before_last              |
ApacheImpalaGuide|455ImpalaSQLLanguageReference
+-------------------------------+-------------------------------+
| 2016-06-01 22:44:21.291913000 | 2016-05-18 22:44:21.291913000 |
+-------------------------------+-------------------------------+
YEAR(TIMESTAMPdate)
Purpose: ReturnstheyearfieldfromthedateportionofaTIMESTAMP .
Returntype:INT
Examples:
select now() as right_now, year(now()) as this_year;
+-------------------------------+-----------+
| right_now                     | this_year |
+-------------------------------+-----------+
| 2016-06-01 22:46:23.647925000 | 2016      |
+-------------------------------+-----------+
YEARS_ADD(TIME STAMPdate,INTyears),YEARS_ADD(TIME STAMPdate,BIGINTyears)
Purpose: Returnsthespecified dateandtimeplussomenumberofyears.
Returntype:TIMESTAMP
Examples:
select now() as right_now, years_add(now(), 1) as next_year;
+-------------------------------+-------------------------------+
| right_now                     | next_year                     |
+-------------------------------+-------------------------------+
| 2016-06-01 22:47:45.556851000 | 2017-06-01 22:47:45.556851000 |
+-------------------------------+-------------------------------+
Thefollowingexampleshowshowiftheequivalentdatedoesnotexistintheyearoftheresultduetoaleapyear,
thedateischangedtothelastdayoftheappropriatemonth.
-- Spoiler alert: there is no Feb. 29, 2017
select cast('2016-02-29' as timestamp) as feb_29_2016,
  years_add('2016-02-29', 1) as feb_29_2017;
+---------------------+---------------------+
| feb_29_2016         | feb_29_2017         |
+---------------------+---------------------+
| 2016-02-29 00:00:00 | 2017-02-28 00:00:00 |
+---------------------+---------------------+
YEARS_SUB(TIME STAMPdate,INTyears),YEARS_SUB(TIME STAMPdate,BIGINTyears)
Purpose: Returnsthespecified dateandtimeminussomenumberofyears.
Returntype:TIMESTAMP
Examples:
select now() as right_now, years_sub(now(), 1) as last_year;
+-------------------------------+-------------------------------+
| right_now                     | last_year                     |
+-------------------------------+-------------------------------+
| 2016-06-01 22:48:11.851780000 | 2015-06-01 22:48:11.851780000 |
+-------------------------------+-------------------------------+
456|ApacheImpalaGuideImpalaSQLLanguageReference
Thefollowingexampleshowshowiftheequivalentdatedoesnotexistintheyearoftheresultduetoaleapyear,
thedateischangedtothelastdayoftheappropriatemonth.
-- Spoiler alert: there is no Feb. 29, 2015
select cast('2016-02-29' as timestamp) as feb_29_2016,
  years_sub('2016-02-29', 1) as feb_29_2015;
+---------------------+---------------------+
| feb_29_2016         | feb_29_2015         |
+---------------------+---------------------+
| 2016-02-29 00:00:00 | 2015-02-28 00:00:00 |
+---------------------+---------------------+
ImpalaConditional Functions
Impalasupports thefollowingconditional functions fortestingequality,comparison operators,andnullity:
â¢CASE
â¢CASE2
â¢COALESCE
â¢DECODE
â¢IF
â¢IFNULL
â¢ISFALSE
â¢ISNOTFALSE
â¢ISNOTTRUE
â¢ISNULL
â¢ISTRUE
â¢NONNULL VALUE
â¢NULLIF
â¢NULLIFZERO
â¢NULLVALUE
â¢NVL
â¢NVL2
â¢ZEROIFNULL
CASEaWHENbTHENc[WHENdTHENe]...[ELSEf]END
Purpose: Comparesanexpressiontooneormorepossiblevalues,andreturnsacorresponding resultwhenamatch
isfound.
Returntype:sameastheinitialargumentvalue,exceptthatintegervaluesarepromotedtoBIGINTandfloating-point
valuesarepromotedtoDOUBLE;useCAST()wheninserting intoasmallernumericcolumn
Usagenotes:
InthisformoftheCASEexpression,theinitialvalueAbeingevaluatedforeachrowittypicallyacolumnreference,
oranexpressioninvolvingacolumn.Thisformcanonlycompareagainstasetofspecified values,notranges,
multi-valuecomparisons suchasBETWEEN orIN,regularexpressions,orNULL.
Examples:
Although thisexampleissplitacrossmultiplelines,youcanputanyorallpartsofaCASEexpressiononasingle
line,withnopunctuationorotherseparatorsbetweentheWHEN,ELSE,andENDclauses.
select case x
    when 1 then 'one'
    when 2 then 'two'
    when 0 then 'zero'
    else 'out of range'
ApacheImpalaGuide|457ImpalaSQLLanguageReference
  end
    from t1;
CASEWHENaTHENb[WHENcTHENd]...[ELSEe]END
Purpose: Testswhetheranyofasequence ofexpressionsisTRUE,andreturnsacorresponding resultforthefirst
TRUEexpression.
Returntype:sameastheinitialargumentvalue,exceptthatintegervaluesarepromotedtoBIGINTandfloating-point
valuesarepromotedtoDOUBLE;useCAST()wheninserting intoasmallernumericcolumn
Usagenotes:
CASEexpressionswithoutaninitialtestvaluehavemoreflexibility.Forexample,theycantestdifferentcolumns
indifferentWHENclauses,orusecomparison operatorssuchasBETWEEN ,INandIS NULL ratherthancomparing
againstdiscretevalues.
CASEexpressionsareoftenthefoundationoflongqueriesthatsummariz eandformatresultsforeasy-to-read
reports.Forexample,youmightuseaCASEfunctioncalltoturnvaluesfromanumericcolumnintocategorystrings
corresponding tointegervalues,orlabelssuchasâSmallâ,âMediumâ andâLargeâbasedonranges.Thensubsequent
partsofthequerymightaggregatebasedonthetransformedvalues,suchashowmanyvaluesareclassified as
small,medium, orlarge.YoucanalsouseCASEtosignalproblemswithout-of-bounds values,NULLvalues,andso
on.
ByusingoperatorssuchasOR,IN,REGEXP,andsooninCASEexpressions,youcanbuildextensivetestsand
transformationsintoasinglequery.Therefore,applicationsthatconstructSQLstatementsoftenrelyheavilyon
CASEcallsinthegeneratedSQLcode.
BecausethisflexibleformoftheCASEexpressionsallowsyoutoperformmanycomparisons andcallmultiple
functions whenevaluatingeachrow,becarefulapplyingelaborateCASEexpressionstoqueriesthatprocesslarge
amountsofdata.Forexample,whenpractical,evaluateandtransformvaluesthroughCASEafterapplyingoperations
suchasaggregationsthatreducethesizeoftheresultset;transformnumberstostringsafterperformingjoinswith
theoriginalnumericvalues.
Examples:
Although thisexampleissplitacrossmultiplelines,youcanputanyorallpartsofaCASEexpressiononasingle
line,withnopunctuationorotherseparatorsbetweentheWHEN,ELSE,andENDclauses.
select case
    when dayname(now()) in ('Saturday','Sunday') then 'result undefined on weekends'
    when x > y then 'x greater than y'
    when x = y then 'x and y are equal'
    when x is null or y is null then 'one of the columns is null'
    else null
  end
    from t1;
COALESCE(type v1,typev2,...)
Purpose: Returnsthefirstspecified argumentthatisnotNULL,orNULLifallargumentsareNULL.
Returntype:sameastheinitialargumentvalue,exceptthatintegervaluesarepromotedtoBIGINTandfloating-point
valuesarepromotedtoDOUBLE;useCAST()wheninserting intoasmallernumericcolumn
DECODE(type expression,typesearch1,typeresult1[,typesearch2,typeresult2...][,typedefault])
Purpose: Comparesthefirstargument,expression ,tothesearchexpressionsusingtheIS NOT DISTINCT
operator,andreturns:
â¢Thecorresponding resultwhenamatchisfound.
â¢Thefirstcorresponding resultiftherearemorethanonematchingsearchexpressions.
â¢Thedefault expressionifnoneofthesearchexpressionsmatchesthefirstargumentexpression .
â¢NULLifthefinaldefault expressionisomittedandnoneofthesearchexpressionsmatchesthefirstargument.
Returntype:Sameasthefirstargumentwiththefollowingexceptions:
458|ApacheImpalaGuideImpalaSQLLanguageReference
â¢IntegervaluesarepromotedtoBIGINT.
â¢Floating-pointvaluesarepromotedtoDOUBLE.
â¢UseCAST()wheninserting intoasmallernumericcolumn.
Usagenotes:
â¢Canbeusedasshorthand foraCASEexpression.
â¢Thefirstargument,expression ,andthesearchexpressionsmustbeofthesametypeorconvertibletypes.
â¢Theresultexpressioncanbeadifferenttype,butallresultexpressionsmustbeofthesametype.
â¢ReturnsasuccessfulmatchifthefirstargumentisNULLandasearchexpressionisalsoNULL.
â¢NULLcanbeusedasasearchexpression.
Examples:
Thefollowingexampletranslatesnumericdayvaluesintoweekdaynames,suchas1toMonday,2toTuesday,etc.
SELECT event, DECODE(day_of_week, 1, "Monday", 2, "Tuesday", 3, "Wednesday",
  4, "Thursday", 5, "Friday", 6, "Saturday", 7, "Sunday", "Unknown day")
  FROM calendar;
IF(BOOLE ANcondition, typeifTrue,typeifFalseOrNull)
Purpose: Testsanexpressionandreturnsacorresponding resultdepending onwhethertheresultisTRUE,FALSE,
orNULL.
Returntype:SameastheifTrueargumentvalue
IFNULL(type a,typeifNull)
Purpose: AliasfortheISNULL() function, withthesamebehavior.TosimplifyportingSQLwithvendorextensions
toImpala.
Addedin:Impala1.3.0
ISFALSE(BOOLE ANexpression)
Purpose: ReturnsTRUEiftheexpressionisFALSE.ReturnsFALSEiftheexpressionisTRUEorNULL.
SameastheIS FALSE operator.
SimilartoISNOTTRUE() ,exceptitreturnstheoppositevalueforaNULLargument.
Returntype:BOOLEAN
Addedin:CDH5.4.0/Impala2.2.0
Usagenotes:
InCDH5.14/Impala2.11andhigher,youcanusetheoperatorsIS [NOT] TRUE andIS [NOT] FALSE as
equivalentsforthebuilt-infunctionsISTRUE() ,ISNOTTRUE() ,ISFALSE() ,andISNOTFALSE() .
ISNOTFALSE(BOOLE ANexpression)
Purpose: TestsifaBooleanexpressionisnotFALSE(thatis,eitherTRUEorNULL).ReturnsTRUEifso.Iftheargument
isNULL,returnsTRUE.
SameastheIS NOT FALSE operator.
SimilartoISTRUE() ,exceptitreturnstheoppositevalueforaNULLargument.
Returntype:BOOLEAN
Usagenotes:Primarily forcompatibilitywithcodecontainingindustryextensionstoSQL.
Addedin:CDH5.4.0/Impala2.2.0
Usagenotes:
InCDH5.14/Impala2.11andhigher,youcanusetheoperatorsIS [NOT] TRUE andIS [NOT] FALSE as
equivalentsforthebuilt-infunctionsISTRUE() ,ISNOTTRUE() ,ISFALSE() ,andISNOTFALSE() .
ApacheImpalaGuide|459ImpalaSQLLanguageReference
ISNOTTRUE(BOOLE ANexpression)
Purpose: TestsifaBooleanexpressionisnotTRUE(thatis,eitherFALSEorNULL).ReturnsTRUEifso.Iftheargument
isNULL,returnsTRUE.
SameastheIS NOT TRUE operator.
SimilartoISFALSE() ,exceptitreturnstheoppositevalueforaNULLargument.
Returntype:BOOLEAN
Addedin:CDH5.4.0/Impala2.2.0
Usagenotes:
InCDH5.14/Impala2.11andhigher,youcanusetheoperatorsIS [NOT] TRUE andIS [NOT] FALSE as
equivalentsforthebuilt-infunctionsISTRUE() ,ISNOTTRUE() ,ISFALSE() ,andISNOTFALSE() .
ISNULL(type a,typeifNull)
Purpose: TestsifanexpressionisNULL,andreturnstheexpressionresultvalueifnot.IfthefirstargumentisNULL,
returnsthesecondargument.
Compatibilitynotes:EquivalenttotheNVL()functionfromOracleDatabaseorIFNULL() fromMySQL.TheNVL()
andIFNULL() functions arealsoavailableinImpala.
Returntype:Sameasthefirstargumentvalue
ISTRUE(BOOLE ANexpression)
Purpose: ReturnsTRUEiftheexpressionisTRUE.ReturnsFALSEiftheexpressionisFALSEorNULL.
SameastheIS TRUE operator.
SimilartoISNOTFALSE() ,exceptitreturnstheoppositevalueforaNULLargument.
Returntype:BOOLEAN
Usagenotes:Primarily forcompatibilitywithcodecontainingindustryextensionstoSQL.
Addedin:CDH5.4.0/Impala2.2.0
Usagenotes:
InCDH5.14/Impala2.11andhigher,youcanusetheoperatorsIS [NOT] TRUE andIS [NOT] FALSE as
equivalentsforthebuilt-infunctionsISTRUE() ,ISNOTTRUE() ,ISFALSE() ,andISNOTFALSE() .
NONNULL VALUE(typeexpression)
Purpose: Testsifanexpression(ofanytype)isNULLornot.ReturnsFALSEifso.Theconverseofnullvalue() .
Returntype:BOOLEAN
Usagenotes:Primarily forcompatibilitywithcodecontainingindustryextensionstoSQL.
Addedin:CDH5.4.0/Impala2.2.0
NULLIF(expr1,expr2)
Purpose: ReturnsNULLifthetwospecified argumentsareequal.Ifthespecified argumentsarenotequal,returns
thevalueofexpr1.Thedatatypesoftheexpressionsmustbecompatible,accordingtotheconversionrulesfrom
DataTypesonpage101.YoucannotuseanexpressionthatevaluatestoNULLforexpr1;thatway,youcandistinguish
areturnvalueofNULLfromanargumentvalueofNULL,whichwouldnevermatchexpr2.
Usagenotes:Thisfunctioniseffectivelyshorthand foraCASEexpressionoftheform:
CASE
  WHEN expr1 = expr2 THEN NULL
  ELSE expr1
END
460|ApacheImpalaGuideImpalaSQLLanguageReference
Itiscommonly usedindivisionexpressions,toproduceaNULLresultinsteadofadivide-by-zeroerrorwhenthe
divisorisequaltozero:
select 1.0 / nullif(c1,0) as reciprocal from t1;
YoumightalsouseitforcompatibilitywithotherdatabasesystemsthatsupportthesameNULLIF() function.
Returntype:sameastheinitialargumentvalue,exceptthatintegervaluesarepromotedtoBIGINTandfloating-point
valuesarepromotedtoDOUBLE;useCAST()wheninserting intoasmallernumericcolumn
Addedin:Impala1.3.0
NULLIFZERO(numeric_e xpr)
Purpose: ReturnsNULLifthenumericexpressionevaluatesto0,otherwisereturnstheresultoftheexpression.
Usagenotes:Usedtoavoiderrorconditions suchasdivide-by-zeroinnumericcalculations.Servesasshorthand
foramoreelaborateCASEexpression,tosimplifyportingSQLwithvendorextensionstoImpala.
Returntype:Sametypeastheinputargument
Addedin:Impala1.3.0
NULLVALUE(expression)
Purpose: Testsifanexpression(ofanytype)isNULLornot.ReturnsTRUEifso.Theconverseofnonnullvalue() .
Returntype:BOOLEAN
Usagenotes:Primarily forcompatibilitywithcodecontainingindustryextensionstoSQL.
Addedin:CDH5.4.0/Impala2.2.0
NVL(type a,typeifNull)
Purpose: AliasfortheISNULL() function. ReturnsthefirstargumentifthefirstargumentisnotNULL.Returnsthe
secondargumentifthefirstargumentisNULL.
EquivalenttotheNVL()functioninOracleDatabaseorIFNULL() inMySQL.
Returntype:Sameasthefirstargumentvalue
Addedin:Impala1.1
NVL2(type a,typeifNotNull, typeifNull)
Purpose: Returnsthesecondargument,ifNotNull ,ifthefirstargumentisnotNULL.Returnsthethirdargument,
ifNull,ifthefirstargumentisNULL.
EquivalenttotheNVL2()functioninOracleDatabase.
Returntype:Sameasthefirstargumentvalue
Addedin:CDH5.12.0/Impala2.9.0
Examples:
SELECT NVL2(NULL, 999, 0); -- Returns 0
SELECT NVL2('ABC', 'Is Not Null', 'Is Null'); -- Returns 'Is Not Null'
ZEROIFNULL(numeric_e xpr)
Purpose: Returns0ifthenumericexpressionevaluatestoNULL,otherwisereturnstheresultoftheexpression.
Usagenotes:UsedtoavoidunexpectedresultsduetounexpectedpropagationofNULLvaluesinnumericcalculations.
Servesasshorthand foramoreelaborateCASEexpression,tosimplifyportingSQLwithvendorextensionstoImpala.
Returntype:Sametypeastheinputargument
Addedin:Impala1.3.0
ApacheImpalaGuide|461ImpalaSQLLanguageReference
ImpalaStringFunctions
Stringfunctions areclassified asthoseprimarily acceptingorreturningSTRING,VARCHAR ,orCHARdatatypes,for
exampletomeasurethelengthofastringorconcatenatetwostringstogether.
â¢Allthefunctions thatacceptSTRINGargumentsalsoaccepttheVARCHAR andCHARtypesintroducedinImpala
2.0.
â¢WheneverVARCHAR orCHARvaluesarepassedtoafunctionthatreturnsastringvalue,thereturntypeisnormalized
toSTRING.Forexample,acalltoconcat() withamixofSTRING,VARCHAR ,andCHARargumentsproducesa
STRINGresult.
Relatedinformation:
Thestringfunctions operatemainlyonthesedatatypes:STRINGDataTypeonpage123,VARCHARDataType(CDH5.2
orhigheronly)onpage137,andCHARDataType(CDH5.2orhigheronly)onpage107.
Function reference:
Impalasupports thefollowingstringfunctions:
â¢ASCII
â¢BASE64DECODE
â¢BASE64ENC ODE
â¢BTRIM
â¢CHAR_LENG TH
â¢CHR
â¢CONCAT
â¢CONCAT_WS
â¢FIND_IN_SET
â¢GROUP_CONCAT
â¢INITCAP
â¢INSTR
â¢LEFT
â¢LENGTH
â¢LEVENSHTEIN, LE_DST
â¢LOCATE
â¢LOWER,LCASE
â¢LPAD
â¢LTRI
â¢PARSE_URL
â¢REGEXP_ESCAPE
â¢REGEXP_EXTRA CT
â¢REGEXP_LIKE
â¢REGEXP_REPLA CE
â¢REPEAT
â¢REPLACE
â¢REVERSE
â¢RIGHT
â¢RPAD
â¢RTRIM
â¢SPACE
â¢SPLIT_PART
â¢STRLEFT
â¢STRRIGHT
â¢SUBSTR,SUBSTRING
462|ApacheImpalaGuideImpalaSQLLanguageReference
â¢TRANSLATE
â¢TRIM
â¢UPPER,UCASE
ASCII(STRINGstr)
Purpose: ReturnsthenumericASCIIcodeofthefirstcharacteroftheargument.
Returntype:INT
BASE64DECODE(STRINGstr)
Purpose:
Returntype:STRING
Usagenotes:
ForgeneralinformationaboutBase64encoding,seeBase64articleonWikipedia .
ThefunctionsBASE64ENCODE() andBASE64DECODE() aretypicallyusedincombination,tostoreinanImpala
tablestringdatathatisproblematictostoreortransmit.Forexample,youcouldusethesefunctions tostorestring
datathatusesanencodingotherthanUTF-8,ortotransformthevaluesincontextsthatrequireASCIIvalues,such
asforpartitionkeycolumns.Keepinmindthatbase64-enc odedvaluesproducedifferentresultsforstringfunctions
suchasLENGTH() ,MAX(),andMIN()thanwhenthosefunctions arecalledwiththeunencodedstringvalues.
ThesetofcharactersthatcanbegeneratedasoutputfromBASE64ENCODE() ,orspecified intheargumentstring
toBASE64DECODE() ,aretheASCIIuppercaseandlowercaseletters(A-Z,a-z),digits(0-9),andthepunctuation
characters+,/,and=.
AllreturnvaluesproducedbyBASE64ENCODE() areamultipleof4bytesinlength.Allargumentvaluessupplied
toBASE64DECODE() mustalsobeamultipleof4bytesinlength.Ifabase64-enc odedvaluewouldotherwisehave
adifferentlength,itcanbepaddedwithtrailing=characterstoreachalengththatisamultipleof4bytes.
IftheargumentstringtoBASE64DECODE() doesnotrepresentavalidbase64-enc odedvalue,subjecttothe
constraintsoftheImpalaimplemen tationsuchastheallowedcharacterset,thefunctionreturnsNULL.
Examples:
ThefollowingexamplesshowhowtouseBASE64ENCODE() andBASE64DECODE() togethertostoreandretrieve
stringvalues:
-- An arbitrary string can be encoded in base 64.
-- The length of the output is a multiple of 4 bytes,
-- padded with trailing = characters if necessary.
select base64encode('hello world') as encoded,
  length(base64encode('hello world')) as length;
+------------------+--------+
| encoded          | length |
+------------------+--------+
| aGVsbG8gd29ybGQ= | 16     |
+------------------+--------+
-- Passing an encoded value to base64decode() produces
-- the original value.
select base64decode('aGVsbG8gd29ybGQ=') as decoded;
+-------------+
| decoded     |
+-------------+
| hello world |
+-------------+
TheseexamplesdemonstrateincorrectencodedvaluesthatproduceNULLreturnvalueswhendecoded:
-- The input value to base64decode() must be a multiple of 4 bytes.
-- In this case, leaving off the trailing = padding character
-- produces a NULL return value.
ApacheImpalaGuide|463ImpalaSQLLanguageReference
select base64decode('aGVsbG8gd29ybGQ') as decoded;
+---------+
| decoded |
+---------+
| NULL    |
+---------+
WARNINGS: UDF WARNING: Invalid base64 string; input length is 15,
  which is not a multiple of 4.
-- The input to base64decode() can only contain certain characters.
-- The $ character in this case causes a NULL return value.
select base64decode('abc$');
+----------------------+
| base64decode('abc$') |
+----------------------+
| NULL                 |
+----------------------+
WARNINGS: UDF WARNING: Could not base64 decode input in space 4; actual output length 
0
Theseexamplesdemonstrateâround-tripping âofanoriginalstringtoanencodedstring,andbackagain.This
technique isapplicableiftheoriginalsourceisinanunknownencoding,orifsomeintermediateprocessingstage
mightcausenationalcharacterstobemisrepresented:
select 'circumflex accents: Ã¢, Ãª, Ã®, Ã´, Ã»' as original,
  base64encode('circumflex accents: Ã¢, Ãª, Ã®, Ã´, Ã»') as encoded;
+-----------------------------------+------------------------------------------------------+
| original                          | encoded                                         
     |
+-----------------------------------+------------------------------------------------------+
| circumflex accents: Ã¢, Ãª, Ã®, Ã´, Ã» | Y2lyY3VtZmxleCBhY2NlbnRzOiDDoiwgw6osIMOuLCDDtCwgw7s=
 |
+-----------------------------------+------------------------------------------------------+
select base64encode('circumflex accents: Ã¢, Ãª, Ã®, Ã´, Ã»') as encoded,
  base64decode(base64encode('circumflex accents: Ã¢, Ãª, Ã®, Ã´, Ã»')) as decoded;
+------------------------------------------------------+-----------------------------------+
| encoded                                              | decoded                      
     |
+------------------------------------------------------+-----------------------------------+
| Y2lyY3VtZmxleCBhY2NlbnRzOiDDoiwgw6osIMOuLCDDtCwgw7s= | circumflex accents: Ã¢, Ãª, Ã®, 
Ã´, Ã» |
+------------------------------------------------------+-----------------------------------+
BASE64ENC ODE(STRINGstr)
Purpose:
Returntype:STRING
Usagenotes:
ForgeneralinformationaboutBase64encoding,seeBase64articleonWikipedia .
ThefunctionsBASE64ENCODE() andBASE64DECODE() aretypicallyusedincombination,tostoreinanImpala
tablestringdatathatisproblematictostoreortransmit.Forexample,youcouldusethesefunctions tostorestring
datathatusesanencodingotherthanUTF-8,ortotransformthevaluesincontextsthatrequireASCIIvalues,such
asforpartitionkeycolumns.Keepinmindthatbase64-enc odedvaluesproducedifferentresultsforstringfunctions
suchasLENGTH() ,MAX(),andMIN()thanwhenthosefunctions arecalledwiththeunencodedstringvalues.
ThesetofcharactersthatcanbegeneratedasoutputfromBASE64ENCODE() ,orspecified intheargumentstring
toBASE64DECODE() ,aretheASCIIuppercaseandlowercaseletters(A-Z,a-z),digits(0-9),andthepunctuation
characters+,/,and=.
AllreturnvaluesproducedbyBASE64ENCODE() areamultipleof4bytesinlength.Allargumentvaluessupplied
toBASE64DECODE() mustalsobeamultipleof4bytesinlength.Ifabase64-enc odedvaluewouldotherwisehave
adifferentlength,itcanbepaddedwithtrailing=characterstoreachalengththatisamultipleof4bytes.
464|ApacheImpalaGuideImpalaSQLLanguageReference
Examples:
ThefollowingexamplesshowhowtouseBASE64ENCODE() andBASE64DECODE() togethertostoreandretrieve
stringvalues:
-- An arbitrary string can be encoded in base 64.
-- The length of the output is a multiple of 4 bytes,
-- padded with trailing = characters if necessary.
select base64encode('hello world') as encoded,
  length(base64encode('hello world')) as length;
+------------------+--------+
| encoded          | length |
+------------------+--------+
| aGVsbG8gd29ybGQ= | 16     |
+------------------+--------+
-- Passing an encoded value to base64decode() produces
-- the original value.
select base64decode('aGVsbG8gd29ybGQ=') as decoded;
+-------------+
| decoded     |
+-------------+
| hello world |
+-------------+
TheseexamplesdemonstrateincorrectencodedvaluesthatproduceNULLreturnvalueswhendecoded:
-- The input value to base64decode() must be a multiple of 4 bytes.
-- In this case, leaving off the trailing = padding character
-- produces a NULL return value.
select base64decode('aGVsbG8gd29ybGQ') as decoded;
+---------+
| decoded |
+---------+
| NULL    |
+---------+
WARNINGS: UDF WARNING: Invalid base64 string; input length is 15,
  which is not a multiple of 4.
-- The input to base64decode() can only contain certain characters.
-- The $ character in this case causes a NULL return value.
select base64decode('abc$');
+----------------------+
| base64decode('abc$') |
+----------------------+
| NULL                 |
+----------------------+
WARNINGS: UDF WARNING: Could not base64 decode input in space 4; actual output length 
0
Theseexamplesdemonstrateâround-tripping âofanoriginalstringtoanencodedstring,andbackagain.This
technique isapplicableiftheoriginalsourceisinanunknownencoding,orifsomeintermediateprocessingstage
mightcausenationalcharacterstobemisrepresented:
select 'circumflex accents: Ã¢, Ãª, Ã®, Ã´, Ã»' as original,
  base64encode('circumflex accents: Ã¢, Ãª, Ã®, Ã´, Ã»') as encoded;
+-----------------------------------+------------------------------------------------------+
| original                          | encoded                                         
     |
+-----------------------------------+------------------------------------------------------+
| circumflex accents: Ã¢, Ãª, Ã®, Ã´, Ã» | Y2lyY3VtZmxleCBhY2NlbnRzOiDDoiwgw6osIMOuLCDDtCwgw7s=
 |
+-----------------------------------+------------------------------------------------------+
select base64encode('circumflex accents: Ã¢, Ãª, Ã®, Ã´, Ã»') as encoded,
  base64decode(base64encode('circumflex accents: Ã¢, Ãª, Ã®, Ã´, Ã»')) as decoded;
+------------------------------------------------------+-----------------------------------+
| encoded                                              | decoded                      
ApacheImpalaGuide|465ImpalaSQLLanguageReference
     |
+------------------------------------------------------+-----------------------------------+
| Y2lyY3VtZmxleCBhY2NlbnRzOiDDoiwgw6osIMOuLCDDtCwgw7s= | circumflex accents: Ã¢, Ãª, Ã®, 
Ã´, Ã» |
+------------------------------------------------------+-----------------------------------+
BTRIM(STRINGa),BTRIM(STRINGa,STRINGchars_to_trim)
Purpose: RemovesallinstancesofoneormorecharactersfromthestartandendofaSTRINGvalue.Bydefault,
removesonlyspaces.Ifanon-NULLoptionalsecondargumentisspecified, thefunctionremovesalloccurrences
ofcharactersinthatsecondargumentfromthebeginning andendofthestring.
Returntype:STRING
Addedin:CDH5.5.0/Impala2.3.0
Examples:
Thefollowingexamplesshowthedefaultbtrim() behavior,andwhatchangeswhenyouspecifytheoptional
secondargument.Alltheexamplesbrackettheoutputvaluewith[ ]sothatyoucanseeanyleadingortrailing
spacesinthebtrim() result.Bydefault,thefunctionremovesandnumberofbothleadingandtrailingspaces.
Whenthesecondargumentisspecified, anynumberofoccurrencesofanycharacterinthesecondargumentare
removedfromthestartandendoftheinputstring;inthiscase,spacesarenotremoved(unlesstheyarepartof
thesecondargument)andanyinstancesofthecharactersarenotremovediftheydonotcomerightatthebeginning
orendofthestring.
-- Remove multiple spaces before and one space after.
select concat('[',btrim('    hello '),']');
+---------------------------------------+
| concat('[', btrim('    hello '), ']') |
+---------------------------------------+
| [hello]                               |
+---------------------------------------+
-- Remove any instances of x or y or z at beginning or end. Leave spaces alone.
select concat('[',btrim('xy    hello zyzzxx','xyz'),']');
+------------------------------------------------------+
| concat('[', btrim('xy    hello zyzzxx', 'xyz'), ']') |
+------------------------------------------------------+
| [    hello ]                                         |
+------------------------------------------------------+
-- Remove any instances of x or y or z at beginning or end.
-- Leave x, y, z alone in the middle of the string.
select concat('[',btrim('xyhelxyzlozyzzxx','xyz'),']');
+----------------------------------------------------+
| concat('[', btrim('xyhelxyzlozyzzxx', 'xyz'), ']') |
+----------------------------------------------------+
| [helxyzlo]                                         |
+----------------------------------------------------+
CHAR_LENG TH(STRINGa),CHARACTER_LENG TH(STRINGa)
Purpose: Returnsthelengthincharactersoftheargumentstring.Aliasesforthelength() function.
Returntype:INT
CHR(INTcharacter_code)
Purpose: Returnsacharacterspecified byadecimalcodepointvalue.Theinterpretationanddisplayoftheresulting
characterdependsonyoursystemlocale.BecauseconsistentprocessingofImpalastringvaluesisonlyguaranteed
forvalueswithintheASCIIrange,onlyusethisfunctionforvaluescorresponding toASCIIcharacters.Inparticular ,
parametervaluesgreaterthan255returnanemptystring.
Returntype:STRING
Usagenotes:Canbeusedastheinverseoftheascii() function, whichconvertsacharactertoitsnumericASCII
code.
466|ApacheImpalaGuideImpalaSQLLanguageReference
Addedin:CDH5.5.0/Impala2.3.0
Examples:
SELECT chr(65);
+---------+
| chr(65) |
+---------+
| A       |
+---------+
SELECT chr(97);
+---------+
| chr(97) |
+---------+
| a       |
+---------+
CONCAT(STRINGa,STRINGb...)
Purpose: Returnsasinglestringrepresentingalltheargumentvaluesjoinedtogether.
Returntype:STRING
Usagenotes:concat() andconcat_ws() areappropriateforconcatenatingthevaluesofmultiplecolumnswithin
thesamerow,whilegroup_concat() joinstogethervaluesfromdifferentrows.
CONCAT_WS(STRINGsep,STRINGa,STRINGb...)
Purpose: Returnsasinglestringrepresentingthesecondandfollowingargumentvaluesjoinedtogether,delimited
byaspecified separator.
Returntype:STRING
Usagenotes:concat() andconcat_ws() areappropriateforconcatenatingthevaluesofmultiplecolumnswithin
thesamerow,whilegroup_concat() joinstogethervaluesfromdifferentrows.
FIND_IN_SET(S TRINGstr,STRINGstrList)
Purpose: Returnstheposition(startingfrom1)ofthefirstoccurrenceofaspecified stringwithinacomma-separ ated
string.ReturnsNULLifeitherargumentisNULL,0ifthesearchstringisnotfound,or0ifthesearchstringcontains
acomma.
Returntype:INT
GROUP_CONCAT(STRINGs[,STRINGsep])
Purpose: Returnsasinglestringrepresentingtheargumentvalueconcatenatedtogetherforeachrowoftheresult
set.Iftheoptionalseparatorstringisspecified, theseparatorisaddedbetweeneachpairofconcatenatedvalues.
Returntype:STRING
Usagenotes:concat() andconcat_ws() areappropriateforconcatenatingthevaluesofmultiplecolumnswithin
thesamerow,whilegroup_concat() joinstogethervaluesfromdifferentrows.
Bydefault,returnsasinglestringcoveringthewholeresultset.Toincludeothercolumnsorvaluesintheresult
set,ortoproducemultipleconcatenatedstringsforsubsetsofrows,includeaGROUP BY clauseinthequery.
Strictlyspeaking,group_concat() isanaggregatefunction, notascalarfunctionliketheothersinthislist.For
additional detailsandexamples,seeGROUP_CONCATFunction onpage489.
INITCAP(STRINGstr)
Purpose: Returnstheinputstringwiththefirstletterofeachwordcapitalizedandallotherlettersinlowercase.
Returntype:STRING
Example:
INITCAP("i gOt mY ChiCkeNs in tHe yard.") returns"I Got My Chickens In The Yard." .
ApacheImpalaGuide|467ImpalaSQLLanguageReference
INSTR(STRINGstr,STRINGsubstr[,BIGINTposition[,BIGINToccurrence]])
Purpose: Returnstheposition(startingfrom1)ofthefirstoccurrenceofasubstrwithinalongerstring.
Returntype:INT
Usagenotes:
Ifthesubstrisnotpresentinstr,thefunctionreturns0.
Theoptionalthirdandfourthargumentsletyoufindinstancesofthesubstrotherthanthefirstinstancestarting
fromtheleft.
â¢Thethirdargument,position,letsyouspecifyastartingpointwithinthestrotherthan1.
-- Restricting the search to positions 7..end,
-- the first occurrence of 'b' is at position 9.
select instr('foo bar bletch', 'b', 7);
+---------------------------------+
| instr('foo bar bletch', 'b', 7) |
+---------------------------------+
| 9                               |
+---------------------------------+
â¢Iftherearenomoreoccurrencesafterthespecified position, theresultis0.
â¢Ifpositionisnegative,thesearchworksright-to-leftstartingthatmanycharactersfromtheright.Thereturn
valuestillrepresentsthepositionstartingfromtheleftsideofstr.
-- Scanning right to left, the first occurrence of 'o'
-- is at position 8. (8th character from the left.)
select instr('hello world','o',-1);
+-------------------------------+
| instr('hello world', 'o', -1) |
+-------------------------------+
| 8                             |
+-------------------------------+
â¢Thefourthargument,occurrence,letsyouspecifyanoccurrenceotherthanthefirst.
-- 2nd occurrence of 'b' is at position 9.
select instr('foo bar bletch', 'b', 1, 2);
+------------------------------------+
| instr('foo bar bletch', 'b', 1, 2) |
+------------------------------------+
| 9                                  |
+------------------------------------+
â¢Ifoccurrenceisgreaterthanthenumberofmatchingoccurrences,thefunctionreturns0.
â¢occurrencecannotbenegativeorzero.Anon-positiv evalueforthisargumentcausesanerror.
â¢Ifeitheroftheoptionalarguments,positionoroccurrence,isNULL,thefunctionalsoreturnsNULL.
LEFT(STRINGa,INTnum_char s)
SeetheSTRLEFT() function.
LENGTH(STRINGa)
Purpose: Returnsthelengthincharactersoftheargumentstring.
Returntype:INT
LEVENSHTEIN(S TRINGstr1,STRINGstr2),LE_DST(STRINGstr1,STRINGstr2)
Purpose: ReturnstheLevenshteindistancebetweentwoinputstrings.TheLevenshteindistancebetweentwo
stringsistheminimum numberofsingle-char actereditsrequiredtotransformonestringtoother.Thefunction
indicateshowdifferenttheinputstringsare.
468|ApacheImpalaGuideImpalaSQLLanguageReference
Returntype:INT
Usagenotes:
Ifinputstringsareequal,thefunctionreturns0.
Ifeitherinputexceeds255characters,thefunctionreturnsanerror.
IfeitherinputstringisNULL,thefunctionreturnsNULL.
Ifthelengthofoneinputstringiszero,thefunctionreturnsthelengthoftheotherstring.
Example:
LEVENSHTEIN ('welcome', 'We come') returns2,firstchangetoreplace'w'to'W',andthentoreplace'l'to
aspacecharacter.
LOCATE(STRINGsubstr,STRINGstr[,INTpos])
Purpose: Returnstheposition(startingfrom1)ofthefirstoccurrenceofasubstringwithinalongerstring,optionally
afteraparticular position.
Returntype:INT
LOWER(STRINGa),LCASE(STRINGa)
Purpose: Returnstheargumentstringconvertedtoall-lowercase.
Returntype:STRING
Usagenotes:
InCDH5.7/Impala2.5andhigher,youcansimplifyqueriesthatusemanyUPPER() andLOWER() callstodo
case-insensitiv ecomparisons, byusingtheILIKEorIREGEXP operatorsinstead.SeeILIKEOperatoronpage179
andIREGEXPOperatoronpage182fordetails.
LPAD(STRINGstr,INTlen,STRINGpad)
Purpose: Returnsastringofaspecified length,basedonthefirstargumentstring.Ifthespecified stringistooshort,
itispaddedontheleftwitharepeatingsequence ofthecharactersfromthepadstring.Ifthespecified stringistoo
long,itistruncatedontheright.
Returntype:STRING
LTRIM(STRINGa[,STRINGchars_to_trim])
Purpose: Returnstheargumentstringwithalloccurrencesofcharactersspecified bythesecondargumentremoved
fromtheleftside.Removesspacesifthesecondargumentisnotspecified.
Returntype:STRING
PARSE_URL(S TRINGurlString,STRINGpartToExtract[,STRINGkeyToExtract])
Purpose: ReturnstheportionofaURLcorresponding toaspecified part.Thepartargumentcanbe'PROTOCOL' ,
'HOST','PATH','REF','AUTHORITY' ,'FILE','USERINFO' ,or'QUERY' .Uppercaseisrequiredforthese
literalvalues.WhenrequestingtheQUERYportionoftheURL,youcanoptionallyspecifyakeytoretrievejustthe
associatedvaluefromthekey-valuepairsinthequerystring.
Returntype:STRING
Usagenotes:Thisfunctionisimportantforthetraditional Hadoopusecaseofinterpretingweblogs.Forexample,
ifthewebtrafficdatafeaturesrawURLsnotdividedintoseparatetablecolumns,youcancountvisitorstoaparticular
pagebyextractingthe'PATH'or'FILE'field,oranalyzesearchtermsbyextractingthecorresponding keyfrom
the'QUERY' field.
ApacheImpalaGuide|469ImpalaSQLLanguageReference
REGEXP_ESCAPE(STRINGsource)
Purpose: TheREGEXP_ESCAPE functionreturnsastringescapedforthespecialcharacterinRE2librarysothatthe
specialcharactersareinterpretedliterallyratherthanasspecialcharacters.Thefollowingspecialcharactersare
escapedbythefunction:
.\+*?[^]$(){}=!<>|:-
Returntype:string
InImpala2.0andlater,theImpalaregularexpressionsyntaxconformstothePOSIXExtendedRegularExpression
syntaxusedbytheGoogleRE2library.Fordetails,seetheRE2documen tation.Ithasmostidiomsfamiliarfrom
regularexpressionsinPerl,Python,andsoon,including.*?fornon-greedymatches.
InImpala2.0andlater,achangeintheunderlying regularexpressionlibrarycouldcausechangesinthewayregular
expressionsareinterpretedbythisfunction. Testanyqueriesthatuseregularexpressionsandadjusttheexpression
patternsifnecessary.
Becausetheimpala-shell interpreterusesthe\characterforescaping,use\\torepresenttheregularexpression
escapecharacterinanyregularexpressionsthatyousubmitthroughimpala-shell .Youmightprefertousethe
equivalentcharacterclassnames,suchas[[:digit:]] insteadof\dwhichyouwouldhavetoescapeas\\d.
Examples:
ThisexampleshowsescapingoneofspecialcharactersinRE2.
+------------------------------------------------------+
| regexp_escape('Hello.world')                         |
+------------------------------------------------------+
| Hello\.world                                         |
+------------------------------------------------------+
ThisexampleshowsescapingallthespecialcharactersinRE2.
+------------------------------------------------------------+
| regexp_escape('a.b\\c+d*e?f[g]h$i(j)k{l}m=n!o<p>q|r:s-t')  |
+------------------------------------------------------------+
| a\.b\\c\+d\*e\?f\[g\]h\$i\(j\)k\{l\}m\=n\!o\<p\>q\|r\:s\-t |
+------------------------------------------------------------+
REGEXP_EXTRA CT(STRINGsubject,STRINGpattern,INTindex)
Purpose: Returnsthespecified ()groupfromastringbasedonaregularexpressionpattern.Group0referstothe
entireextractedstring,whilegroup1,2,andsoonreferstothefirst,second,andsoon(...)portion.
Returntype:STRING
InImpala2.0andlater,theImpalaregularexpressionsyntaxconformstothePOSIXExtendedRegularExpression
syntaxusedbytheGoogleRE2library.Fordetails,seetheRE2documen tation.Ithasmostidiomsfamiliarfrom
regularexpressionsinPerl,Python,andsoon,including.*?fornon-greedymatches.
InImpala2.0andlater,achangeintheunderlying regularexpressionlibrarycouldcausechangesinthewayregular
expressionsareinterpretedbythisfunction. Testanyqueriesthatuseregularexpressionsandadjusttheexpression
patternsifnecessary.
Becausetheimpala-shell interpreterusesthe\characterforescaping,use\\torepresenttheregularexpression
escapecharacterinanyregularexpressionsthatyousubmitthroughimpala-shell .Youmightprefertousethe
equivalentcharacterclassnames,suchas[[:digit:]] insteadof\dwhichyouwouldhavetoescapeas\\d.
Examples:
470|ApacheImpalaGuideImpalaSQLLanguageReference
Thisexampleshowshowgroup0matchesthefullpatternstring,including theportionoutsideany()group:
[localhost:21000] > select regexp_extract('abcdef123ghi456jkl','.*?(\\d+)',0);
+------------------------------------------------------+
| regexp_extract('abcdef123ghi456jkl', '.*?(\\d+)', 0) |
+------------------------------------------------------+
| abcdef123ghi456                                      |
+------------------------------------------------------+
Returned 1 row(s) in 0.11s
Thisexampleshowshowgroup1matchesjustthecontentsinsidethefirst()groupinthepatternstring:
[localhost:21000] > select regexp_extract('abcdef123ghi456jkl','.*?(\\d+)',1);
+------------------------------------------------------+
| regexp_extract('abcdef123ghi456jkl', '.*?(\\d+)', 1) |
+------------------------------------------------------+
| 456                                                  |
+------------------------------------------------------+
Returned 1 row(s) in 0.11s
UnlikeinearlierImpalareleases,theregularexpressionlibraryusedinImpala2.0andlatersupports the.*?idiom
fornon-greedymatches.Thisexampleshowshowapatternstringstartingwith.*?matchestheshortestpossible
portionofthesourcestring,returningtherightmostsetoflowercaseletters.Apatternstringbothstartingand
endingwith.*?findstwopotentialmatchesofequallength,andreturnsthefirstonefound(theleftmostsetof
lowercaseletters).
[localhost:21000] > select regexp_extract('AbcdBCdefGHI','.*?([[:lower:]]+)',1);
+--------------------------------------------------------+
| regexp_extract('abcdbcdefghi', '.*?([[:lower:]]+)', 1) |
+--------------------------------------------------------+
| def                                                    |
+--------------------------------------------------------+
[localhost:21000] > select regexp_extract('AbcdBCdefGHI','.*?([[:lower:]]+).*?',1);
+-----------------------------------------------------------+
| regexp_extract('abcdbcdefghi', '.*?([[:lower:]]+).*?', 1) |
+-----------------------------------------------------------+
| bcd                                                       |
+-----------------------------------------------------------+
REGEXP_LIKE(S TRINGsource,STRINGpattern[,STRINGoptions])
Purpose: Returnstrueorfalsetoindicatewhetherthesourcestringcontainsanywhereinsideittheregular
expressiongivenbythepattern.Theoptionalthirdargumentconsistsofletterflagsthatchangehowthematchis
performed,suchasiforcase-insensitiv ematching.
Syntax:
Theflagsthatyoucanincludeintheoptionalthirdargumentare:
â¢c:Case-sensitiv ematching(thedefault).
â¢i:Case-insensitiv ematching.Ifmultipleinstancesofcandiareincludedinthethirdargument,thelastsuch
optiontakesprecedence.
â¢m:Multi-line matching.The^and$operatorsmatchthestartorendofanylinewithinthesourcestring,not
thestartandendoftheentirestring.
â¢n:Newlinematching.The.operatorcanmatchthenewlinecharacter.Arepetitionoperatorsuchas.*can
matchaportionofthesourcestringthatspansmultiplelines.
Returntype:BOOLEAN
InImpala2.0andlater,theImpalaregularexpressionsyntaxconformstothePOSIXExtendedRegularExpression
syntaxusedbytheGoogleRE2library.Fordetails,seetheRE2documen tation.Ithasmostidiomsfamiliarfrom
regularexpressionsinPerl,Python,andsoon,including.*?fornon-greedymatches.
InImpala2.0andlater,achangeintheunderlying regularexpressionlibrarycouldcausechangesinthewayregular
expressionsareinterpretedbythisfunction. Testanyqueriesthatuseregularexpressionsandadjusttheexpression
patternsifnecessary.
ApacheImpalaGuide|471ImpalaSQLLanguageReference
Becausetheimpala-shell interpreterusesthe\characterforescaping,use\\torepresenttheregularexpression
escapecharacterinanyregularexpressionsthatyousubmitthroughimpala-shell .Youmightprefertousethe
equivalentcharacterclassnames,suchas[[:digit:]] insteadof\dwhichyouwouldhavetoescapeas\\d.
Examples:
ThisexampleshowshowREGEXP_LIKE() cantestfortheexistenceofvariouskindsofregularexpressionpatterns
withinasourcestring:
-- Matches because the 'f' appears somewhere in 'foo'.
select regexp_like('foo','f');
+-------------------------+
| regexp_like('foo', 'f') |
+-------------------------+
| true                    |
+-------------------------+
-- Does not match because the comparison is case-sensitive by default.
select regexp_like('foo','F');
+-------------------------+
| regexp_like('foo', 'f') |
+-------------------------+
| false                   |
+-------------------------+
-- The 3rd argument can change the matching logic, such as 'i' meaning case-insensitive.
select regexp_like('foo','F','i');
+------------------------------+
| regexp_like('foo', 'f', 'i') |
+------------------------------+
| true                         |
+------------------------------+
-- The familiar regular expression notations work, such as ^ and $ anchors...
select regexp_like('foo','f$');
+--------------------------+
| regexp_like('foo', 'f$') |
+--------------------------+
| false                    |
+--------------------------+
select regexp_like('foo','o$');
+--------------------------+
| regexp_like('foo', 'o$') |
+--------------------------+
| true                     |
+--------------------------+
-- ...and repetition operators such as * and +
select regexp_like('foooooobar','fo+b');
+-----------------------------------+
| regexp_like('foooooobar', 'fo+b') |
+-----------------------------------+
| true                              |
+-----------------------------------+
select regexp_like('foooooobar','fx*y*o*b');
+---------------------------------------+
| regexp_like('foooooobar', 'fx*y*o*b') |
+---------------------------------------+
| true                                  |
+---------------------------------------+
REGEXP_REPLA CE(STRINGinitial,STRINGpattern,STRINGreplacemen t)
Purpose: Returnstheinitialargumentwiththeregularexpressionpatternreplacedbythefinalargumentstring.
Returntype:STRING
472|ApacheImpalaGuideImpalaSQLLanguageReference
InImpala2.0andlater,theImpalaregularexpressionsyntaxconformstothePOSIXExtendedRegularExpression
syntaxusedbytheGoogleRE2library.Fordetails,seetheRE2documen tation.Ithasmostidiomsfamiliarfrom
regularexpressionsinPerl,Python,andsoon,including.*?fornon-greedymatches.
InImpala2.0andlater,achangeintheunderlying regularexpressionlibrarycouldcausechangesinthewayregular
expressionsareinterpretedbythisfunction. Testanyqueriesthatuseregularexpressionsandadjusttheexpression
patternsifnecessary.
Becausetheimpala-shell interpreterusesthe\characterforescaping,use\\torepresenttheregularexpression
escapecharacterinanyregularexpressionsthatyousubmitthroughimpala-shell .Youmightprefertousethe
equivalentcharacterclassnames,suchas[[:digit:]] insteadof\dwhichyouwouldhavetoescapeas\\d.
Examples:
Theseexamplesshowhowyoucanreplacepartsofastringmatchingapatternwithreplacemen ttext,whichcan
includebackreferencestoany()groupsinthepatternstring.Thebackreferencenumbersstartat1,andany\
charactersmustbeescapedas\\.
Replaceacharacterpatternwithnewtext:
[localhost:21000] > select regexp_replace('aaabbbaaa','b+','xyz');
+------------------------------------------+
| regexp_replace('aaabbbaaa', 'b+', 'xyz') |
+------------------------------------------+
| aaaxyzaaa                                |
+------------------------------------------+
Returned 1 row(s) in 0.11s
Replaceacharacterpatternwithsubstitutiontextthatincludestheoriginalmatchingtext:
[localhost:21000] > select regexp_replace('aaabbbaaa','(b+)','<\\1>');
+----------------------------------------------+
| regexp_replace('aaabbbaaa', '(b+)', '<\\1>') |
+----------------------------------------------+
| aaa<bbb>aaa                                  |
+----------------------------------------------+
Returned 1 row(s) in 0.11s
Removeallcharactersthatarenotdigits:
[localhost:21000] > select regexp_replace('123-456-789','[^[:digit:]]','');
+---------------------------------------------------+
| regexp_replace('123-456-789', '[^[:digit:]]', '') |
+---------------------------------------------------+
| 123456789                                         |
+---------------------------------------------------+
Returned 1 row(s) in 0.12s
REPEAT(STRINGstr,INTn)
Purpose: Returnstheargumentstringrepeatedaspecified numberoftimes.
Returntype:STRING
REPLACE(STRINGinitial,STRINGtarget,STRINGreplacemen t)
Purpose: Returnstheinitialargumentwithalloccurrencesofthetargetstringreplacedbythereplacemen tstring.
Returntype:STRING
Usagenotes:
Becausethisfunctiondoesnotuseanyregularexpressionpatterns,itistypicallyfasterthanREGEXP_REPLACE()
forsimplestringsubstitutions.
IfanyargumentisNULL,thereturnvalueisNULL.
Matchingiscase-sensitiv e.
ApacheImpalaGuide|473ImpalaSQLLanguageReference
Ifthereplacemen tstringcontainsanotherinstanceofthetargetstring,theexpansion isonlyperformedonce,
insteadofapplyingagaintothenewlyconstructedstring.
Addedin:CDH5.12.0/Impala2.9.0
Examples:
-- Replace one string with another.
select replace('hello world','world','earth');
+------------------------------------------+
| replace('hello world', 'world', 'earth') |
+------------------------------------------+
| hello earth                              |
+------------------------------------------+
-- All occurrences of the target string are replaced.
select replace('hello world','o','0');
+----------------------------------+
| replace('hello world', 'o', '0') |
+----------------------------------+
| hell0 w0rld                      |
+----------------------------------+
-- If no match is found, the original string is returned unchanged.
select replace('hello world','xyz','abc');
+--------------------------------------+
| replace('hello world', 'xyz', 'abc') |
+--------------------------------------+
| hello world                          |
+--------------------------------------+
REVERSE(STRINGa)
Purpose: Returnstheargumentstringwithcharactersinreversedorder.
Returntype:STRING
RIGHT(STRINGa,INTnum_char s)
SeetheSTRRIGHT function.
RPAD(STRINGstr,INTlen,STRINGpad)
Purpose: Returnsastringofaspecified length,basedonthefirstargumentstring.Ifthespecified stringistooshort,
itispaddedontherightwitharepeatingsequence ofthecharactersfromthepadstring.Ifthespecified stringis
toolong,itistruncatedontheright.
Returntype:STRING
RTRIM(STRINGa[,STRINGchars_to_trim])
Purpose: Returnstheargumentstringwithalloccurrencesofcharactersspecified bythesecondargumentremoved
fromtherightside.Removesspacesifthesecondargumentisnotspecified.
Returntype:STRING
SPACE(INTn)
Purpose: Returnsaconcatenatedstringofthespecified numberofspaces.Shorthand forrepeat(' ', n).
Returntype:STRING
SPLIT_PART(STRINGsource,STRINGdelimiter,BIGINTn)
Purpose: Returnsthenthfieldwithinadelimitedstring.Thefieldsarenumberedstartingfrom1.Thedelimitercan
consistofmultiplecharacters,notjustasinglecharacter.Allmatchingofthedelimiterisdoneexactly,notusing
anyregularexpressionpatterns.
Returntype:STRING
InImpala2.0andlater,theImpalaregularexpressionsyntaxconformstothePOSIXExtendedRegularExpression
syntaxusedbytheGoogleRE2library.Fordetails,seetheRE2documen tation.Ithasmostidiomsfamiliarfrom
regularexpressionsinPerl,Python,andsoon,including.*?fornon-greedymatches.
474|ApacheImpalaGuideImpalaSQLLanguageReference
InImpala2.0andlater,achangeintheunderlying regularexpressionlibrarycouldcausechangesinthewayregular
expressionsareinterpretedbythisfunction. Testanyqueriesthatuseregularexpressionsandadjusttheexpression
patternsifnecessary.
Becausetheimpala-shell interpreterusesthe\characterforescaping,use\\torepresenttheregularexpression
escapecharacterinanyregularexpressionsthatyousubmitthroughimpala-shell .Youmightprefertousethe
equivalentcharacterclassnames,suchas[[:digit:]] insteadof\dwhichyouwouldhavetoescapeas\\d.
Examples:
Theseexamplesshowhowtoretrievethenthfieldfromadelimitedstring:
select split_part('x,y,z',',',1);
+-----------------------------+
| split_part('x,y,z', ',', 1) |
+-----------------------------+
| x                           |
+-----------------------------+
select split_part('x,y,z',',',2);
+-----------------------------+
| split_part('x,y,z', ',', 2) |
+-----------------------------+
| y                           |
+-----------------------------+
select split_part('x,y,z',',',3);
+-----------------------------+
| split_part('x,y,z', ',', 3) |
+-----------------------------+
| z                           |
+-----------------------------+
Theseexamplesshowwhathappensforout-of-rangefieldpositions. Specifyingavaluelessthan1producesan
error.Specifyingavaluegreaterthanthenumberoffieldsreturnsazero-lengthstring(whichisnotthesameas
NULL).
select split_part('x,y,z',',',0);
ERROR: Invalid field position: 0
with t1 as (select split_part('x,y,z',',',4) nonexistent_field)
  select
      nonexistent_field
    , concat('[',nonexistent_field,']')
    , length(nonexistent_field);
from t1
+-------------------+-------------------------------------+---------------------------+
| nonexistent_field | concat('[', nonexistent_field, ']') | length(nonexistent_field) 
|
+-------------------+-------------------------------------+---------------------------+
|                   | []                                  | 0                         
|
+-------------------+-------------------------------------+---------------------------+
Theseexamplesshowhowthedelimitercanbeamulti-char actervalue:
select split_part('one***two***three','***',2);
+-------------------------------------------+
| split_part('one***two***three', '***', 2) |
+-------------------------------------------+
| two                                       |
+-------------------------------------------+
ApacheImpalaGuide|475ImpalaSQLLanguageReference
select split_part('one\|/two\|/three','\|/',3);
+-------------------------------------------+
| split_part('one\|/two\|/three', '\|/', 3) |
+-------------------------------------------+
| three                                     |
+-------------------------------------------+
STRLEFT(STRINGa,INTnum_char s)
Purpose: Returnstheleftmostcharactersofthestring.Shorthand foracalltosubstr() with2arguments.
Returntype:STRING
STRRIGHT(S TRINGa,INTnum_char s)
Purpose: Returnstherightmostcharactersofthestring.Shorthand foracalltosubstr() with2arguments.
Returntype:STRING
SUBSTR(STRINGa,INTstart[,INTlen]),SUBSTRING(STRINGa,INTstart[,INTlen])
Purpose: Returnstheportionofthestringstartingataspecified point,optionallywithaspecified maximumlength.
Thecharactersinthestringareindexedstartingat1.
Returntype:STRING
TRANSLATE(STRINGinput,STRINGfrom,STRINGto)
Purpose: Returnstheinputstringwitheachcharacterinthefromargumentreplacedwiththecorresponding
characterinthetoargument.Thecharactersarematchedintheordertheyappearinfromandto.
Forexample:translate ('hello world','world','earth') returns'hetta earth' .
Returntype:STRING
Usagenotes:
Iffromcontainsmorecharactersthanto,thefromcharactersthatarebeyondthelengthoftoareremovedin
theresult.
Forexample:
translate('abcdedg', 'bcd', '1') returns'a1eg'.
translate('Unit Number#2', '# ', '_') returns'UnitNumber_2' .
IffromisNULL,thefunctionreturnsNULL.
Iftocontainsmorecharactersthanfrom,theextracharactersintoareignored.
Iffromcontainsduplicatecharacters,theduplicatecharacterisreplacedwiththefirstmatchingcharacterinto.
Forexample:translate ('hello','ll','67') returns'he66o' .
TRIM(STRINGa)
Purpose: Returnstheinputstringwithbothleadingandtrailingspacesremoved.Thesameaspassingthestring
throughbothLTRIM() andRTRIM() .
Usagenotes:Oftenusedduringdatacleansing operationsduringtheETLcycle,ifinputvaluesmightstillhave
surroundingspaces.Foramoregeneral-purpose functionthatcanremoveotherleadingandtrailingcharacters
besidesspaces,seeBTRIM() .
Returntype:STRING
UPPER(STRINGa),UCASE(STRINGa)
Purpose: Returnstheargumentstringconvertedtoall-uppercase.
Returntype:STRING
Usagenotes:
476|ApacheImpalaGuideImpalaSQLLanguageReference
InCDH5.7/Impala2.5andhigher,youcansimplifyqueriesthatusemanyUPPER() andLOWER() callstodo
case-insensitiv ecomparisons, byusingtheILIKEorIREGEXP operatorsinstead.SeeILIKEOperatoronpage179
andIREGEXPOperatoronpage182fordetails.
ImpalaMiscellaneous Functions
Impalasupports thefollowingutilityfunctions thatdonotoperateonaparticular columnordatatype:
â¢CURRENT_D ATABASE
â¢EFFECTIVE_USER
â¢GET_JSON_OBJE CT
â¢LOGGED_IN_USER
â¢PID
â¢SLEEP
â¢USER
â¢UUID
â¢VERSION
CURREN_D ATABASE()
Purpose: Returnsthedatabasethatthesessioniscurrentlyusing,eitherdefault ifnodatabasehasbeenselected,
orwhateverdatabasethesessionswitchedtothroughaUSEstatementortheimpalad-doption.
Returntype:STRING
EFFECTIVE_USER()
Purpose: TypicallyreturnsthesamevalueasUSER(),exceptifdelegationisenabled, inwhichcaseitreturnsthe
IDofthedelegateduser.
Returntype:STRING
Addedin:CDH5.4.5/Impala2.2.5
GET_JSON_OBJE CT(STRINGjson_str,STRINGselector)
Purpose: ExtractsJSONobjectfromthejson_strbasedontheselectorJSONpathandreturnsthestringofthe
extractedJSONobject.
ThefunctionreturnsNULLiftheinputjson_strisinvalidorifnothingisselectedbasedontheselectorJSONpath.
ThefollowingcharactersaresupportedintheselectorJSONpath:
â¢$:Denotestherootobject
â¢.:Denotesthechildoperator
â¢[]:Denotesthesubscriptoperatorforarray
â¢*:Denotesthewildcardfor[]or.
Returntype:STRING
Examples:
---- QUERY
SELECT GET_JSON_OBJECT ('{"a":true, "b":false, "c":true}', '$.*');
---- RESULTS
[true,false,true]
---- QUERY
SELECT GET_JSON_OBJECT(t.json, '$.a.b.c') FROM (VALUES (
 ('{"a": {"b": {"c": 1}}}' AS json),
 ('{"a": {"b": {"c": 2}}}'),
 ('{"a": {"b": {"c": 3}}}')
)) t
---- RESULTS
'1'
ApacheImpalaGuide|477ImpalaSQLLanguageReference
'2'
'3'
---- QUERY
SELECT GET_JSON_OBJECT(t.json, '$.a'),
 GET_JSON_OBJECT(t.json, '$.b'),
 GET_JSON_OBJECT(t.json, '$.c')
FROM (VALUES (
 ('{"a":1, "b":2, "c":3}' AS json),
 ('{"b":2, "c":3}'),
 ('{"c":3}')
)) t
---- RESULTS
'1','2','3'
'NULL','2','3'
'NULL','NULL','3'
---- QUERY
SELECT GET_JSON_OBJECT(t.json, '$[1]'),
 GET_JSON_OBJECT(t.json, '$[*]')
FROM (VALUES (
 ('["a", "b", "c"]' AS json),
 ('["a", "b"]'),
 ('["a"]')
)) t
---- RESULTS
'b','["a","b","c"]'
'b','["a","b"]'
'NULL','a'
Addedin:CDH6.1
LOGGED_IN_USER()
Purpose: TypicallyreturnsthesamevalueasUSER().Ifdelegationisenabled, itreturnstheIDofthedelegated
user.
LOGGED_IN_USER() isanaliasofEFFECTIVE_USER() .
Returntype:STRING
Addedin:CDH6.1
PID()
Purpose: ReturnstheprocessIDoftheimpalad daemonthatthesessionisconnectedto.Youcanuseitduring
low-leveldebugging,toissueLinuxcommands thattrace,showthearguments,andsoontheimpalad process.
Returntype:INT
SLEEP(INT ms)
Purpose: Pausesthequeryforaspecified numberofmilliseconds.Forslowingdownquerieswithsmallresultsets
enoughtomonitorruntimeexecution,memoryusage,orotherfactorsthatotherwisewouldbedifficulttocapture
duringthebriefintervalofqueryexecution.WhenusedintheSELECTlist,itiscalledonceforeachrowintheresult
set;adjustthenumberofmillisecondsaccordingly.Forexample,aquerySELECT *, sleep(5) FROM
table_with_1000_rows wouldtakeatleast5secondstocomplete(5milliseconds*1000rowsinresultset).To
avoidanexcessivenumberofconcurrentqueries,usethisfunctionfortroubleshooting ontestanddevelopment
systems,notforproduction queries.
Returntype:N/A
USER()
Purpose: Returnstheusername oftheLinuxuserwhoisconnectedtotheimpalad daemon. Typicallycalleda
singletime,inaquerywithoutanyFROMclause,tounderstandhowauthorizationsettingsapplyinasecuritycontext;
onceyouknowthelogged-inusername, youcancheckwhichgroupsthatuserbelongsto,andfromthelistof
groupsyoucancheckwhichrolesareavailabletothosegroupsthroughtheauthorizationpolicyfile.
478|ApacheImpalaGuideImpalaSQLLanguageReference
Impala2.0andlater,USER()returnsthefullKerberosprincipalstring,suchasuser@example.com ,inaKerberized
environment.
Whendelegationisenabled, considercallingtheeffective_user() functioninstead.
Returntype:STRING
UUID()
Purpose: Returnsauniversaluniqueidentifier,a128-bitvalueencodedasastringwithgroupsofhexadecimal digits
separatedbydashes.
EachcalltoUUID()producesanewarbitraryvalue.
IfyougetaUUIDforeachrowofaresultset,youcanuseitasauniqueidentifierwithinatable,orevenaunique
IDacrosstables.
Returntype:STRING
Addedin:CDH5.7.0/Impala2.5.0
Usagenotes:
Ascending numericsequences oftypeBIGINTareoftenusedasidentifierswithinatable,andasjoinkeysacross
multipletables.Theuuid()valueisaconvenientalternativethatdoesnotrequirestoringorqueryingthehighest
sequence number.Forexample,youcanuseittoquicklyconstructnewuniqueidentifiersduringadataimportjob,
ortocombinedatafromdifferenttableswithoutthelikelihoodofIDcollisions.
VERSION()
Purpose: Returnsinformationsuchasthepreciseversionnumberandbuilddatefortheimpalad daemonthat
youarecurrentlyconnectedto.TypicallyusedtoconfirmthatyouareconnectedtotheexpectedlevelofImpala
touseaparticular feature,ortoconnecttoseveralnodesandconfirmtheyareallrunningthesamelevelofimpalad.
Returntype:STRING(withoneormoreembedded newlines)
COORDINA TOR()
Purpose: Returnsthenameofthehostwhichisrunningtheimpalad daemonthatisactingasthecoordinator
forthecurrentquery.
Returntype:STRING
Addedin:CDH6.1
ImpalaAggregateFunctions
Aggregatefunctions areaspecialcategorywithdifferentrules.Thesefunctions calculateareturnvalueacrossallthe
itemsinaresultset,sotheyrequireaFROMclauseinthequery:
select count(product_id) from product_catalog;
select max(height), avg(height) from census_data where age > 20;
Aggregatefunctions alsoignoreNULLvaluesratherthanreturningaNULLresult.Forexample,ifsomerowshaveNULL
foraparticular column,thoserowsareignoredwhencomputing theAVG()forthatcolumn.Likewise,specifying
COUNT(col_name )inaquerycountsonlythoserowswherecol_name containsanon-NULLvalue.
APPX_MEDIAN Function
Anaggregatefunctionthatreturnsavaluethatisapproximatelythemedian(midpoint)ofvaluesinthesetofinput
values.
Syntax:
APPX_MEDIAN([DISTINCT | ALL] expression )
ApacheImpalaGuide|479ImpalaSQLLanguageReference
Thisfunctionworkswithanyinputtype,becausetheonlyrequirementisthatthetypesupports less-than and
greater-thancomparison operators.
Usagenotes:
Becausethereturnvaluerepresentstheestimatedmidpoint,itmightnotreflecttheprecisemidpointvalue,especially
ifthecardinalityoftheinputvaluesisveryhigh.Ifthecardinalityislow(uptoapproximately20,000),theresultis
moreaccuratebecausethesampling considersalloralmostallofthedifferentvalues.
Returntype:Sameastheinputvalue,exceptforCHARandVARCHAR argumentswhichproduceaSTRINGresult
Thereturnvalueisalwaysthesameasoneoftheinputvalues,notanâin-betweenâvalueproducedbyaveraging.
Restrictions:
Thisfunctioncannotbeusedinananalyticcontext.Thatis,theOVER()clauseisnotallowedatallwiththisfunction.
TheAPPX_MEDIAN functionreturnsonlythefirst10charactersforstringvalues(string,varchar,char).Additional
charactersaretruncated.
Examples:
Thefollowingexampleusesatableofamillionrandomfloating-pointnumbersranginguptoapproximately50,000.
Theaverageisapproximately25,000.Becauseoftherandomdistribution, wewouldexpectthemediantobecloseto
thissamenumber.Computing theprecisemedianisamoreintensiveoperationthancomputing theaverage,because
itrequireskeepingtrackofeverydistinctvalueandhowmanytimeseachoccurs.TheAPPX_MEDIAN() functionuses
asampling algorithmtoreturnanapproximateresult,whichinthiscaseisclosetotheexpectedvalue.Tomakesure
thatthevalueisnotsubstantiallyoutofrangeduetoaskeweddistribution, subsequentqueriesconfirmthatthere
areapproximately500,000valueshigherthantheAPPX_MEDIAN() value,andapproximately500,000valueslower
thantheAPPX_MEDIAN() value.
[localhost:21000] > select min(x), max(x), avg(x) from million_numbers;
+-------------------+-------------------+-------------------+
| min(x)            | max(x)            | avg(x)            |
+-------------------+-------------------+-------------------+
| 4.725693727250069 | 49994.56852674231 | 24945.38563793553 |
+-------------------+-------------------+-------------------+
[localhost:21000] > select appx_median(x) from million_numbers;
+----------------+
| appx_median(x) |
+----------------+
| 24721.6        |
+----------------+
[localhost:21000] > select count(x) as higher from million_numbers where x > (select 
appx_median(x) from million_numbers);
+--------+
| higher |
+--------+
| 502013 |
+--------+
[localhost:21000] > select count(x) as lower from million_numbers where x < (select 
appx_median(x) from million_numbers);
+--------+
| lower  |
+--------+
| 497987 |
+--------+
Thefollowingexamplecomputestheapproximatemedianusingasubsetofthevaluesfromthetable,andthenconfirms
thattheresultisareasonable estimateforthemidpoint.
[localhost:21000] > select appx_median(x) from million_numbers where x between 1000 and
 5000;
+-------------------+
| appx_median(x)    |
+-------------------+
| 3013.107787358159 |
+-------------------+
480|ApacheImpalaGuideImpalaSQLLanguageReference
[localhost:21000] > select count(x) as higher from million_numbers where x between 1000
 and 5000 and x > 3013.107787358159;
+--------+
| higher |
+--------+
| 37692  |
+--------+
[localhost:21000] > select count(x) as lower from million_numbers where x between 1000
 and 5000 and x < 3013.107787358159;
+-------+
| lower |
+-------+
| 37089 |
+-------+
AVGFunction
AnaggregatefunctionthatreturnstheaveragevaluefromasetofnumbersorTIMESTAMP values.Itssingleargument
canbenumericcolumn,orthenumericresultofafunctionorexpressionappliedtothecolumnvalue.Rowswitha
NULLvalueforthespecified columnareignored.Ifthetableisempty,orallthevaluessuppliedtoAVGareNULL,AVG
returnsNULL.
Syntax:
AVG([DISTINCT | ALL] expression ) [OVER ( analytic_clause )]
WhenthequerycontainsaGROUP BY clause,returnsonevalueforeachcombinationofgroupingvalues.
Returntype:DOUBLEfornumericvalues;TIMESTAMP forTIMESTAMP values
Complextypeconsiderations:
Toaccessacolumnwithacomplextype(ARRAY,STRUCT,orMAP)inanaggregationfunction, youunpacktheindividual
elementsusingjoinnotationinthequery,andthenapplythefunctiontothefinalscalaritem,field,key,orvalueat
thebottomofanynestedtypehierarchyinthecolumn.SeeComplexTypes(CDH5.5orhigheronly)onpage139for
detailsaboutusingcomplextypesinImpala.
Thefollowingexampledemonstratescallstoseveralaggregationfunctions usingvaluesfromacolumncontaining
nestedcomplextypes(anARRAYofSTRUCTitems).Thearrayisunpackedinsidethequeryusingjoinnotation.The
arrayelementsarereferencedusingtheITEMpseudocolumn,andthestructurefieldsinsidethearrayelementsare
referencedusingdotnotation.NumericvaluessuchasSUM()andAVG()arecomputedusingthenumericR_NATIONKEY
field,andthegeneral-purpose MAX()andMIN()valuesarecomputedfromthestringN_NAMEfield.
describe region;
+-------------+-------------------------+---------+
| name        | type                    | comment |
+-------------+-------------------------+---------+
| r_regionkey | smallint                |         |
| r_name      | string                  |         |
| r_comment   | string                  |         |
| r_nations   | array<struct<           |         |
|             |   n_nationkey:smallint, |         |
|             |   n_name:string,        |         |
|             |   n_comment:string      |         |
|             | >>                      |         |
+-------------+-------------------------+---------+
select r_name, r_nations.item.n_nationkey
  from region, region.r_nations as r_nations
order by r_name, r_nations.item.n_nationkey;
+-------------+------------------+
| r_name      | item.n_nationkey |
+-------------+------------------+
| AFRICA      | 0                |
| AFRICA      | 5                |
| AFRICA      | 14               |
| AFRICA      | 15               |
| AFRICA      | 16               |
ApacheImpalaGuide|481ImpalaSQLLanguageReference
| AMERICA     | 1                |
| AMERICA     | 2                |
| AMERICA     | 3                |
| AMERICA     | 17               |
| AMERICA     | 24               |
| ASIA        | 8                |
| ASIA        | 9                |
| ASIA        | 12               |
| ASIA        | 18               |
| ASIA        | 21               |
| EUROPE      | 6                |
| EUROPE      | 7                |
| EUROPE      | 19               |
| EUROPE      | 22               |
| EUROPE      | 23               |
| MIDDLE EAST | 4                |
| MIDDLE EAST | 10               |
| MIDDLE EAST | 11               |
| MIDDLE EAST | 13               |
| MIDDLE EAST | 20               |
+-------------+------------------+
select
  r_name,
  count(r_nations.item.n_nationkey) as count,
  sum(r_nations.item.n_nationkey) as sum,
  avg(r_nations.item.n_nationkey) as avg,
  min(r_nations.item.n_name) as minimum,
  max(r_nations.item.n_name) as maximum,
  ndv(r_nations.item.n_nationkey) as distinct_vals
from
  region, region.r_nations as r_nations
group by r_name
order by r_name;
+-------------+-------+-----+------+-----------+----------------+---------------+
| r_name      | count | sum | avg  | minimum   | maximum        | distinct_vals |
+-------------+-------+-----+------+-----------+----------------+---------------+
| AFRICA      | 5     | 50  | 10   | ALGERIA   | MOZAMBIQUE     | 5             |
| AMERICA     | 5     | 47  | 9.4  | ARGENTINA | UNITED STATES  | 5             |
| ASIA        | 5     | 68  | 13.6 | CHINA     | VIETNAM        | 5             |
| EUROPE      | 5     | 77  | 15.4 | FRANCE    | UNITED KINGDOM | 5             |
| MIDDLE EAST | 5     | 58  | 11.6 | EGYPT     | SAUDI ARABIA   | 5             |
+-------------+-------+-----+------+-----------+----------------+---------------+
Examples:
-- Average all the non-NULL values in a column.
insert overwrite avg_t values (2),(4),(6),(null),(null);
-- The average of the above values is 4: (2+4+6) / 3. The 2 NULL values are ignored.
select avg(x) from avg_t;
-- Average only certain values from the column.
select avg(x) from t1 where month = 'January' and year = '2013';
-- Apply a calculation to the value of the column before averaging.
select avg(x/3) from t1;
-- Apply a function to the value of the column before averaging.
-- Here we are substituting a value of 0 for all NULLs in the column,
-- so that those rows do factor into the return value.
select avg(isnull(x,0)) from t1;
-- Apply some number-returning function to a string column and average the results.
-- If column s contains any NULLs, length(s) also returns NULL and those rows are ignored.
select avg(length(s)) from t1;
-- Can also be used in combination with DISTINCT and/or GROUP BY.
-- Return more than one result.
select month, year, avg(page_visits) from web_stats group by month, year;
-- Filter the input to eliminate duplicates before performing the calculation.
select avg(distinct x) from t1;
-- Filter the output after performing the calculation.
select avg(x) from t1 group by y having avg(x) between 1 and 20;
482|ApacheImpalaGuideImpalaSQLLanguageReference
ThefollowingexamplesshowhowtouseAVG()inananalyticcontext.Theyuseatablecontainingintegersfrom1to
10.NoticehowtheAVG()isreportedforeachinputvalue,asopposedtotheGROUP BY clausewhichcondenses the
resultset.
select x, property, avg(x) over (partition by property) as avg from int_t where property
 in ('odd','even');
+----+----------+-----+
| x  | property | avg |
+----+----------+-----+
| 2  | even     | 6   |
| 4  | even     | 6   |
| 6  | even     | 6   |
| 8  | even     | 6   |
| 10 | even     | 6   |
| 1  | odd      | 5   |
| 3  | odd      | 5   |
| 5  | odd      | 5   |
| 7  | odd      | 5   |
| 9  | odd      | 5   |
+----+----------+-----+
AddinganORDER BY clauseletsyouexperimen twithresultsthatarecumulativeorapplytoamovingsetofrows(the
âwindowâ).ThefollowingexamplesuseAVG()inananalyticcontext(thatis,withanOVER()clause)toproducea
runningaverageofalltheevenvalues,thenarunningaverageofalltheoddvalues.ThebasicORDER BY x clause
implicitly activatesawindowclauseofRANGE BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW ,whichis
effectivelythesameasROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW ,thereforealloftheseexamples
producethesameresults:
select x, property,
  avg(x) over (partition by property order by x ) as 'cumulative average'
  from int_t where property in ('odd','even');
+----+----------+--------------------+
| x  | property | cumulative average |
+----+----------+--------------------+
| 2  | even     | 2                  |
| 4  | even     | 3                  |
| 6  | even     | 4                  |
| 8  | even     | 5                  |
| 10 | even     | 6                  |
| 1  | odd      | 1                  |
| 3  | odd      | 2                  |
| 5  | odd      | 3                  |
| 7  | odd      | 4                  |
| 9  | odd      | 5                  |
+----+----------+--------------------+
select x, property,
  avg(x) over
  (
    partition by property
order by x
range between unbounded preceding and current row
  ) as 'cumulative average'
from int_t where property in ('odd','even');
+----+----------+--------------------+
| x  | property | cumulative average |
+----+----------+--------------------+
| 2  | even     | 2                  |
| 4  | even     | 3                  |
| 6  | even     | 4                  |
| 8  | even     | 5                  |
| 10 | even     | 6                  |
| 1  | odd      | 1                  |
| 3  | odd      | 2                  |
| 5  | odd      | 3                  |
| 7  | odd      | 4                  |
| 9  | odd      | 5                  |
+----+----------+--------------------+
select x, property,
ApacheImpalaGuide|483ImpalaSQLLanguageReference
  avg(x) over
  (
    partition by property
order by x
rows between unbounded preceding and current row
  ) as 'cumulative average'
  from int_t where property in ('odd','even');
+----+----------+--------------------+
| x  | property | cumulative average |
+----+----------+--------------------+
| 2  | even     | 2                  |
| 4  | even     | 3                  |
| 6  | even     | 4                  |
| 8  | even     | 5                  |
| 10 | even     | 6                  |
| 1  | odd      | 1                  |
| 3  | odd      | 2                  |
| 5  | odd      | 3                  |
| 7  | odd      | 4                  |
| 9  | odd      | 5                  |
+----+----------+--------------------+
Thefollowingexamplesshowhowtoconstructamovingwindow,witharunningaveragetakingintoaccount1row
beforeand1rowafterthecurrentrow,withinthesamepartition (alltheevenvaluesoralltheoddvalues).Because
ofarestrictionintheImpalaRANGEsyntax,thistypeofmovingwindowispossiblewiththeROWS BETWEEN clause
butnottheRANGE BETWEEN clause:
select x, property,
  avg(x) over
  (
    partition by property
order by x
rows between 1 preceding and 1 following
  ) as 'moving average'
  from int_t where property in ('odd','even');
+----+----------+----------------+
| x  | property | moving average |
+----+----------+----------------+
| 2  | even     | 3              |
| 4  | even     | 4              |
| 6  | even     | 6              |
| 8  | even     | 8              |
| 10 | even     | 9              |
| 1  | odd      | 2              |
| 3  | odd      | 3              |
| 5  | odd      | 5              |
| 7  | odd      | 7              |
| 9  | odd      | 8              |
+----+----------+----------------+
-- Doesn't work because of syntax restriction on RANGE clause.
select x, property,
  avg(x) over
  (
    partition by property
order by x
range between 1 preceding and 1 following
  ) as 'moving average'
from int_t where property in ('odd','even');
ERROR: AnalysisException: RANGE is only supported with both the lower and upper bounds
 UNBOUNDED or one UNBOUNDED and the other CURRENT ROW.
Restrictions:
DuetothewayarithmeticonFLOATandDOUBLEcolumnsuseshigh-performancehardwareinstructions, anddistributed
queriescanperformtheseoperationsindifferentorderforeachquery,resultscanvaryslightlyforaggregatefunction
callssuchasSUM()andAVG()forFLOATandDOUBLEcolumns,particularly onlargedatasetswheremillionsorbillions
ofvaluesaresummed oraveraged.Forperfectconsistencyandrepeatability,usetheDECIMAL datatypeforsuch
operationsinsteadofFLOATorDOUBLE.
484|ApacheImpalaGuideImpalaSQLLanguageReference
Relatedinformation:
ImpalaAnalyticFunctions onpage506,MAXFunction onpage490,MINFunction onpage493
COUNTFunction
Anaggregatefunctionthatreturnsthenumberofrows,orthenumberofnon-NULLrows.
Syntax:
COUNT([DISTINCT | ALL] expression ) [OVER ( analytic_clause )]
Depending ontheargument,COUNT() considersrowsthatmeetcertainconditions:
â¢ThenotationCOUNT(*) includesNULLvaluesinthetotal.
â¢ThenotationCOUNT(column_name )onlyconsidersrowswherethecolumncontainsanon-NULLvalue.
â¢YoucanalsocombineCOUNTwiththeDISTINCT operatortoeliminateduplicatesbeforecounting,andtocount
thecombinationsofvaluesacrossmultiplecolumns.
WhenthequerycontainsaGROUP BY clause,returnsonevalueforeachcombinationofgroupingvalues.
Returntype:BIGINT
Usagenotes:
Ifyoufrequentlyrunaggregatefunctions suchasMIN(),MAX(),andCOUNT(DISTINCT) onpartition keycolumns,
considerenablingtheOPTIMIZE_PARTITION_KEY_SCANS queryoption,whichoptimizessuchqueries.Thisfeature
isavailableinCDH5.7/Impala2.5andhigher.SeeOPTIMIZE_PARTITION_KEY_SCANS QueryOption(CDH5.7orhigher
only)onpage348forthekindsofqueriesthatthisoptionappliesto,andslightdifferencesinhowpartitions areevaluated
whenthisqueryoptionisenabled.
Complextypeconsiderations:
Toaccessacolumnwithacomplextype(ARRAY,STRUCT,orMAP)inanaggregationfunction, youunpacktheindividual
elementsusingjoinnotationinthequery,andthenapplythefunctiontothefinalscalaritem,field,key,orvalueat
thebottomofanynestedtypehierarchyinthecolumn.SeeComplexTypes(CDH5.5orhigheronly)onpage139for
detailsaboutusingcomplextypesinImpala.
Thefollowingexampledemonstratescallstoseveralaggregationfunctions usingvaluesfromacolumncontaining
nestedcomplextypes(anARRAYofSTRUCTitems).Thearrayisunpackedinsidethequeryusingjoinnotation.The
arrayelementsarereferencedusingtheITEMpseudocolumn,andthestructurefieldsinsidethearrayelementsare
referencedusingdotnotation.NumericvaluessuchasSUM()andAVG()arecomputedusingthenumericR_NATIONKEY
field,andthegeneral-purpose MAX()andMIN()valuesarecomputedfromthestringN_NAMEfield.
describe region;
+-------------+-------------------------+---------+
| name        | type                    | comment |
+-------------+-------------------------+---------+
| r_regionkey | smallint                |         |
| r_name      | string                  |         |
| r_comment   | string                  |         |
| r_nations   | array<struct<           |         |
|             |   n_nationkey:smallint, |         |
|             |   n_name:string,        |         |
|             |   n_comment:string      |         |
|             | >>                      |         |
+-------------+-------------------------+---------+
select r_name, r_nations.item.n_nationkey
  from region, region.r_nations as r_nations
order by r_name, r_nations.item.n_nationkey;
+-------------+------------------+
| r_name      | item.n_nationkey |
+-------------+------------------+
| AFRICA      | 0                |
| AFRICA      | 5                |
| AFRICA      | 14               |
ApacheImpalaGuide|485ImpalaSQLLanguageReference
| AFRICA      | 15               |
| AFRICA      | 16               |
| AMERICA     | 1                |
| AMERICA     | 2                |
| AMERICA     | 3                |
| AMERICA     | 17               |
| AMERICA     | 24               |
| ASIA        | 8                |
| ASIA        | 9                |
| ASIA        | 12               |
| ASIA        | 18               |
| ASIA        | 21               |
| EUROPE      | 6                |
| EUROPE      | 7                |
| EUROPE      | 19               |
| EUROPE      | 22               |
| EUROPE      | 23               |
| MIDDLE EAST | 4                |
| MIDDLE EAST | 10               |
| MIDDLE EAST | 11               |
| MIDDLE EAST | 13               |
| MIDDLE EAST | 20               |
+-------------+------------------+
select
  r_name,
  count(r_nations.item.n_nationkey) as count,
  sum(r_nations.item.n_nationkey) as sum,
  avg(r_nations.item.n_nationkey) as avg,
  min(r_nations.item.n_name) as minimum,
  max(r_nations.item.n_name) as maximum,
  ndv(r_nations.item.n_nationkey) as distinct_vals
from
  region, region.r_nations as r_nations
group by r_name
order by r_name;
+-------------+-------+-----+------+-----------+----------------+---------------+
| r_name      | count | sum | avg  | minimum   | maximum        | distinct_vals |
+-------------+-------+-----+------+-----------+----------------+---------------+
| AFRICA      | 5     | 50  | 10   | ALGERIA   | MOZAMBIQUE     | 5             |
| AMERICA     | 5     | 47  | 9.4  | ARGENTINA | UNITED STATES  | 5             |
| ASIA        | 5     | 68  | 13.6 | CHINA     | VIETNAM        | 5             |
| EUROPE      | 5     | 77  | 15.4 | FRANCE    | UNITED KINGDOM | 5             |
| MIDDLE EAST | 5     | 58  | 11.6 | EGYPT     | SAUDI ARABIA   | 5             |
+-------------+-------+-----+------+-----------+----------------+---------------+
Examples:
-- How many rows total are in the table, regardless of NULL values?
select count(*) from t1;
-- How many rows are in the table with non-NULL values for a column?
select count(c1) from t1;
-- Count the rows that meet certain conditions.
-- Again, * includes NULLs, so COUNT(*) might be greater than COUNT(col).
select count(*) from t1 where x > 10;
select count(c1) from t1 where x > 10;
-- Can also be used in combination with DISTINCT and/or GROUP BY.
-- Combine COUNT and DISTINCT to find the number of unique values.
-- Must use column names rather than * with COUNT(DISTINCT ...) syntax.
-- Rows with NULL values are not counted.
select count(distinct c1) from t1;
-- Rows with a NULL value in _either_ column are not counted.
select count(distinct c1, c2) from t1;
-- Return more than one result.
select month, year, count(distinct visitor_id) from web_stats group by month, year;
486|ApacheImpalaGuideImpalaSQLLanguageReference
ThefollowingexamplesshowhowtouseCOUNT() inananalyticcontext.Theyuseatablecontainingintegersfrom1
to10.NoticehowtheCOUNT() isreportedforeachinputvalue,asopposedtotheGROUP BY clausewhichcondenses
theresultset.
select x, property, count(x) over (partition by property) as count from int_t where 
property in ('odd','even');
+----+----------+-------+
| x  | property | count |
+----+----------+-------+
| 2  | even     | 5     |
| 4  | even     | 5     |
| 6  | even     | 5     |
| 8  | even     | 5     |
| 10 | even     | 5     |
| 1  | odd      | 5     |
| 3  | odd      | 5     |
| 5  | odd      | 5     |
| 7  | odd      | 5     |
| 9  | odd      | 5     |
+----+----------+-------+
AddinganORDER BY clauseletsyouexperimen twithresultsthatarecumulativeorapplytoamovingsetofrows(the
âwindowâ).ThefollowingexamplesuseCOUNT() inananalyticcontext(thatis,withanOVER()clause)toproducea
runningcountofalltheevenvalues,thenarunningcountofalltheoddvalues.ThebasicORDER BY x clauseimplicitly
activatesawindowclauseofRANGE BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW ,whichiseffectively
thesameasROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW ,thereforealloftheseexamplesproduce
thesameresults:
select x, property,
  count(x) over (partition by property order by x ) as 'cumulative count'
  from int_t where property in ('odd','even');
+----+----------+------------------+
| x  | property | cumulative count |
+----+----------+------------------+
| 2  | even     | 1                |
| 4  | even     | 2                |
| 6  | even     | 3                |
| 8  | even     | 4                |
| 10 | even     | 5                |
| 1  | odd      | 1                |
| 3  | odd      | 2                |
| 5  | odd      | 3                |
| 7  | odd      | 4                |
| 9  | odd      | 5                |
+----+----------+------------------+
select x, property,
  count(x) over
  (
    partition by property
order by x
range between unbounded preceding and current row
  ) as 'cumulative total'
from int_t where property in ('odd','even');
+----+----------+------------------+
| x  | property | cumulative count |
+----+----------+------------------+
| 2  | even     | 1                |
| 4  | even     | 2                |
| 6  | even     | 3                |
| 8  | even     | 4                |
| 10 | even     | 5                |
| 1  | odd      | 1                |
| 3  | odd      | 2                |
| 5  | odd      | 3                |
| 7  | odd      | 4                |
| 9  | odd      | 5                |
+----+----------+------------------+
select x, property,
ApacheImpalaGuide|487ImpalaSQLLanguageReference
  count(x) over
  (
    partition by property
order by x
rows between unbounded preceding and current row
  ) as 'cumulative total'
  from int_t where property in ('odd','even');
+----+----------+------------------+
| x  | property | cumulative count |
+----+----------+------------------+
| 2  | even     | 1                |
| 4  | even     | 2                |
| 6  | even     | 3                |
| 8  | even     | 4                |
| 10 | even     | 5                |
| 1  | odd      | 1                |
| 3  | odd      | 2                |
| 5  | odd      | 3                |
| 7  | odd      | 4                |
| 9  | odd      | 5                |
+----+----------+------------------+
Thefollowingexamplesshowhowtoconstructamovingwindow,witharunningcounttakingintoaccount1row
beforeand1rowafterthecurrentrow,withinthesamepartition(alltheevenvaluesoralltheoddvalues).Therefore,
thecountisconsistently3forrowsinthemiddleofthewindow,and2forrowsneartheendsofthewindow,where
thereisnoprecedingornofollowingrowinthepartition. BecauseofarestrictionintheImpalaRANGEsyntax,this
typeofmovingwindowispossiblewiththeROWS BETWEEN clausebutnottheRANGE BETWEEN clause:
select x, property,
  count(x) over
  (
    partition by property
order by x
rows between 1 preceding and 1 following
  ) as 'moving total'
  from int_t where property in ('odd','even');
+----+----------+--------------+
| x  | property | moving total |
+----+----------+--------------+
| 2  | even     | 2            |
| 4  | even     | 3            |
| 6  | even     | 3            |
| 8  | even     | 3            |
| 10 | even     | 2            |
| 1  | odd      | 2            |
| 3  | odd      | 3            |
| 5  | odd      | 3            |
| 7  | odd      | 3            |
| 9  | odd      | 2            |
+----+----------+--------------+
-- Doesn't work because of syntax restriction on RANGE clause.
select x, property,
  count(x) over
  (
    partition by property
order by x
range between 1 preceding and 1 following
  ) as 'moving total'
from int_t where property in ('odd','even');
ERROR: AnalysisException: RANGE is only supported with both the lower and upper bounds
 UNBOUNDED or one UNBOUNDED and the other CURRENT ROW.
Relatedinformation:
ImpalaAnalyticFunctions onpage506
488|ApacheImpalaGuideImpalaSQLLanguageReference
GROUP_CONCATFunction
Anaggregatefunctionthatreturnsasinglestringrepresentingtheargumentvalueconcatenatedtogetherforeach
rowoftheresultset.Iftheoptionalseparatorstringisspecified, theseparatorisaddedbetweeneachpairof
concatenatedvalues.Thedefaultseparatorisacommafollowedbyaspace.
Syntax:
GROUP_CONCAT([ALL  | DISTINCT ] expression  [, separator ])
Usagenotes:concat() andconcat_ws() areappropriateforconcatenatingthevaluesofmultiplecolumnswithin
thesamerow,whilegroup_concat() joinstogethervaluesfromdifferentrows.
Bydefault,returnsasinglestringcoveringthewholeresultset.Toincludeothercolumnsorvaluesintheresultset,
ortoproducemultipleconcatenatedstringsforsubsetsofrows,includeaGROUP BY clauseinthequery.
Returntype:STRING
Thisfunctioncannotbeusedinananalyticcontext.Thatis,theOVER()clauseisnotallowedatallwiththisfunction.
Currently,Impalareturnsanerroriftheresultvaluegrowslargerthan1GiB.
Examples:
ThefollowingexamplesillustratevariousaspectsoftheGROUP_CONCAT() function.
YoucancallthefunctiondirectlyonaSTRINGcolumn.Touseitwithanumericcolumn,castthevaluetoSTRING.
[localhost:21000] > create table t1 (x int, s string);
[localhost:21000] > insert into t1 values (1, "one"), (3, "three"), (2, "two"), (1, 
"one");
[localhost:21000] > select group_concat(s) from t1;
+----------------------+
| group_concat(s)      |
+----------------------+
| one, three, two, one |
+----------------------+
[localhost:21000] > select group_concat(cast(x as string)) from t1;
+---------------------------------+
| group_concat(cast(x as string)) |
+---------------------------------+
| 1, 3, 2, 1                      |
+---------------------------------+
SpecifytheDISTINCT keywordtoeliminateduplicatevaluesfromtheconcatenatedresult:
[localhost:21000] > select group_concat(distinct s) from t1;
+--------------------------+
| group_concat(distinct s) |
+--------------------------+
| three, two, one          |
+--------------------------+
Theoptionalseparatorletsyouformattheresultinflexibleways.Theseparatorcanbeanarbitrarystringexpression,
notjustasinglecharacter.
[localhost:21000] > select group_concat(s,"|") from t1;
+----------------------+
| group_concat(s, '|') |
+----------------------+
| one|three|two|one    |
+----------------------+
[localhost:21000] > select group_concat(s,'---') from t1;
+-------------------------+
| group_concat(s, '---')  |
+-------------------------+
ApacheImpalaGuide|489ImpalaSQLLanguageReference
| one---three---two---one |
+-------------------------+
Thedefaultseparatorisacommafollowedbyaspace.Togetacomma-delimit edresultwithoutextraspaces,specify
adelimitercharacterthatisonlyacomma.
[localhost:21000] > select group_concat(s,',') from t1;
+----------------------+
| group_concat(s, ',') |
+----------------------+
| one,three,two,one    |
+----------------------+
Including aGROUP BY clauseletsyouproduceadifferentconcatenatedresultforeachgroupintheresultset.Inthis
example,theonlyXvaluethatoccursmorethanonceis1,sothatistheonlyrowintheresultsetwhere
GROUP_CONCAT() returnsadelimitedvalue.Forgroupscontainingasinglevalue,GROUP_CONCAT() returnsthe
originalvalueofitsSTRINGargument.
[localhost:21000] > select x, group_concat(s) from t1 group by x;
+---+-----------------+
| x | group_concat(s) |
+---+-----------------+
| 2 | two             |
| 3 | three           |
| 1 | one, one        |
+---+-----------------+
MAXFunction
Anaggregatefunctionthatreturnsthemaximumvaluefromasetofnumbers.OppositeoftheMINfunction. Itssingle
argumentcanbenumericcolumn,orthenumericresultofafunctionorexpressionappliedtothecolumnvalue.Rows
withaNULLvalueforthespecified columnareignored.Ifthetableisempty,orallthevaluessuppliedtoMAXareNULL,
MAXreturnsNULL.
Syntax:
MAX([DISTINCT | ALL] expression ) [OVER ( analytic_clause )]
WhenthequerycontainsaGROUP BY clause,returnsonevalueforeachcombinationofgroupingvalues.
Restrictions: InImpala2.0andhigher,thisfunctioncanbeusedasananalyticfunction, butwithrestrictionsonany
windowclause.ForMAX()andMIN(),thewindowclauseisonlyallowedifthestartboundisUNBOUNDED PRECEDING .
Returntype:Sameastheinputvalue,exceptforCHARandVARCHAR argumentswhichproduceaSTRINGresult
Usagenotes:
Ifyoufrequentlyrunaggregatefunctions suchasMIN(),MAX(),andCOUNT(DISTINCT) onpartition keycolumns,
considerenablingtheOPTIMIZE_PARTITION_KEY_SCANS queryoption,whichoptimizessuchqueries.Thisfeature
isavailableinCDH5.7/Impala2.5andhigher.SeeOPTIMIZE_PARTITION_KEY_SCANS QueryOption(CDH5.7orhigher
only)onpage348forthekindsofqueriesthatthisoptionappliesto,andslightdifferencesinhowpartitions areevaluated
whenthisqueryoptionisenabled.
Complextypeconsiderations:
Toaccessacolumnwithacomplextype(ARRAY,STRUCT,orMAP)inanaggregationfunction, youunpacktheindividual
elementsusingjoinnotationinthequery,andthenapplythefunctiontothefinalscalaritem,field,key,orvalueat
thebottomofanynestedtypehierarchyinthecolumn.SeeComplexTypes(CDH5.5orhigheronly)onpage139for
detailsaboutusingcomplextypesinImpala.
Thefollowingexampledemonstratescallstoseveralaggregationfunctions usingvaluesfromacolumncontaining
nestedcomplextypes(anARRAYofSTRUCTitems).Thearrayisunpackedinsidethequeryusingjoinnotation.The
arrayelementsarereferencedusingtheITEMpseudocolumn,andthestructurefieldsinsidethearrayelementsare
490|ApacheImpalaGuideImpalaSQLLanguageReference
referencedusingdotnotation.NumericvaluessuchasSUM()andAVG()arecomputedusingthenumericR_NATIONKEY
field,andthegeneral-purpose MAX()andMIN()valuesarecomputedfromthestringN_NAMEfield.
describe region;
+-------------+-------------------------+---------+
| name        | type                    | comment |
+-------------+-------------------------+---------+
| r_regionkey | smallint                |         |
| r_name      | string                  |         |
| r_comment   | string                  |         |
| r_nations   | array<struct<           |         |
|             |   n_nationkey:smallint, |         |
|             |   n_name:string,        |         |
|             |   n_comment:string      |         |
|             | >>                      |         |
+-------------+-------------------------+---------+
select r_name, r_nations.item.n_nationkey
  from region, region.r_nations as r_nations
order by r_name, r_nations.item.n_nationkey;
+-------------+------------------+
| r_name      | item.n_nationkey |
+-------------+------------------+
| AFRICA      | 0                |
| AFRICA      | 5                |
| AFRICA      | 14               |
| AFRICA      | 15               |
| AFRICA      | 16               |
| AMERICA     | 1                |
| AMERICA     | 2                |
| AMERICA     | 3                |
| AMERICA     | 17               |
| AMERICA     | 24               |
| ASIA        | 8                |
| ASIA        | 9                |
| ASIA        | 12               |
| ASIA        | 18               |
| ASIA        | 21               |
| EUROPE      | 6                |
| EUROPE      | 7                |
| EUROPE      | 19               |
| EUROPE      | 22               |
| EUROPE      | 23               |
| MIDDLE EAST | 4                |
| MIDDLE EAST | 10               |
| MIDDLE EAST | 11               |
| MIDDLE EAST | 13               |
| MIDDLE EAST | 20               |
+-------------+------------------+
select
  r_name,
  count(r_nations.item.n_nationkey) as count,
  sum(r_nations.item.n_nationkey) as sum,
  avg(r_nations.item.n_nationkey) as avg,
  min(r_nations.item.n_name) as minimum,
  max(r_nations.item.n_name) as maximum,
  ndv(r_nations.item.n_nationkey) as distinct_vals
from
  region, region.r_nations as r_nations
group by r_name
order by r_name;
+-------------+-------+-----+------+-----------+----------------+---------------+
| r_name      | count | sum | avg  | minimum   | maximum        | distinct_vals |
+-------------+-------+-----+------+-----------+----------------+---------------+
| AFRICA      | 5     | 50  | 10   | ALGERIA   | MOZAMBIQUE     | 5             |
| AMERICA     | 5     | 47  | 9.4  | ARGENTINA | UNITED STATES  | 5             |
| ASIA        | 5     | 68  | 13.6 | CHINA     | VIETNAM        | 5             |
| EUROPE      | 5     | 77  | 15.4 | FRANCE    | UNITED KINGDOM | 5             |
| MIDDLE EAST | 5     | 58  | 11.6 | EGYPT     | SAUDI ARABIA   | 5             |
+-------------+-------+-----+------+-----------+----------------+---------------+
ApacheImpalaGuide|491ImpalaSQLLanguageReference
Examples:
-- Find the largest value for this column in the table.
select max(c1) from t1;
-- Find the largest value for this column from a subset of the table.
select max(c1) from t1 where month = 'January' and year = '2013';
-- Find the largest value from a set of numeric function results.
select max(length(s)) from t1;
-- Can also be used in combination with DISTINCT and/or GROUP BY.
-- Return more than one result.
select month, year, max(purchase_price) from store_stats group by month, year;
-- Filter the input to eliminate duplicates before performing the calculation.
select max(distinct x) from t1;
ThefollowingexamplesshowhowtouseMAX()inananalyticcontext.Theyuseatablecontainingintegersfrom1to
10.NoticehowtheMAX()isreportedforeachinputvalue,asopposedtotheGROUP BY clausewhichcondenses the
resultset.
select x, property, max(x) over (partition by property) as max from int_t where property
 in ('odd','even');
+----+----------+-----+
| x  | property | max |
+----+----------+-----+
| 2  | even     | 10  |
| 4  | even     | 10  |
| 6  | even     | 10  |
| 8  | even     | 10  |
| 10 | even     | 10  |
| 1  | odd      | 9   |
| 3  | odd      | 9   |
| 5  | odd      | 9   |
| 7  | odd      | 9   |
| 9  | odd      | 9   |
+----+----------+-----+
AddinganORDER BY clauseletsyouexperimen twithresultsthatarecumulativeorapplytoamovingsetofrows(the
âwindowâ).ThefollowingexamplesuseMAX()inananalyticcontext(thatis,withanOVER()clause)todisplaythe
smallestvalueofXencountereduptoeachrowintheresultset.TheexamplesusetwocolumnsintheORDER BY
clausetoproduceasequence ofvaluesthatrisesandfalls,toillustratehowtheMAX()resultonlyincreasesorstays
thesamethroughouteachpartition withintheresultset.ThebasicORDER BY x clauseimplicitly activatesawindow
clauseofRANGE BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW ,whichiseffectivelythesameasROWS
BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW ,thereforealloftheseexamplesproducethesameresults:
select x, property,
  max(x) over (order by property, x desc)  as 'maximum to this point'
from int_t where property in ('prime','square');
+---+----------+-----------------------+
| x | property | maximum to this point |
+---+----------+-----------------------+
| 7 | prime    | 7                     |
| 5 | prime    | 7                     |
| 3 | prime    | 7                     |
| 2 | prime    | 7                     |
| 9 | square   | 9                     |
| 4 | square   | 9                     |
| 1 | square   | 9                     |
+---+----------+-----------------------+
select x, property,
  max(x) over
  (
order by property, x desc
rows between unbounded preceding and current row
  ) as 'maximum to this point'
from int_t where property in ('prime','square');
+---+----------+-----------------------+
| x | property | maximum to this point |
+---+----------+-----------------------+
| 7 | prime    | 7                     |
492|ApacheImpalaGuideImpalaSQLLanguageReference
| 5 | prime    | 7                     |
| 3 | prime    | 7                     |
| 2 | prime    | 7                     |
| 9 | square   | 9                     |
| 4 | square   | 9                     |
| 1 | square   | 9                     |
+---+----------+-----------------------+
select x, property,
  max(x) over
  (
order by property, x desc
range between unbounded preceding and current row
  ) as 'maximum to this point'
from int_t where property in ('prime','square');
+---+----------+-----------------------+
| x | property | maximum to this point |
+---+----------+-----------------------+
| 7 | prime    | 7                     |
| 5 | prime    | 7                     |
| 3 | prime    | 7                     |
| 2 | prime    | 7                     |
| 9 | square   | 9                     |
| 4 | square   | 9                     |
| 1 | square   | 9                     |
+---+----------+-----------------------+
Thefollowingexamplesshowhowtoconstructamovingwindow,witharunningmaximumtakingintoaccountall
rowsbeforeand1rowafterthecurrentrow.BecauseofarestrictionintheImpalaRANGEsyntax,thistypeofmoving
windowispossiblewiththeROWS BETWEEN clausebutnottheRANGE BETWEEN clause.BecauseofanextraImpala
restrictionontheMAX()andMIN()functions inananalyticcontext,thelowerboundmustbeUNBOUNDED PRECEDING .
select x, property,
  max(x) over
  (
order by property, x
rows between unbounded preceding and 1 following
  ) as 'local maximum'
from int_t where property in ('prime','square');
+---+----------+---------------+
| x | property | local maximum |
+---+----------+---------------+
| 2 | prime    | 3             |
| 3 | prime    | 5             |
| 5 | prime    | 7             |
| 7 | prime    | 7             |
| 1 | square   | 7             |
| 4 | square   | 9             |
| 9 | square   | 9             |
+---+----------+---------------+
-- Doesn't work because of syntax restriction on RANGE clause.
select x, property,
  max(x) over
  (
order by property, x
range between unbounded preceding and 1 following
  ) as 'local maximum'
from int_t where property in ('prime','square');
ERROR: AnalysisException: RANGE is only supported with both the lower and upper bounds
 UNBOUNDED or one UNBOUNDED and the other CURRENT ROW.
Relatedinformation:
ImpalaAnalyticFunctions onpage506,MINFunction onpage493,AVGFunction onpage481
MINFunction
Anaggregatefunctionthatreturnstheminimum valuefromasetofnumbers.OppositeoftheMAXfunction. Itssingle
argumentcanbenumericcolumn,orthenumericresultofafunctionorexpressionappliedtothecolumnvalue.Rows
ApacheImpalaGuide|493ImpalaSQLLanguageReference
withaNULLvalueforthespecified columnareignored.Ifthetableisempty,orallthevaluessuppliedtoMINareNULL,
MINreturnsNULL.
Syntax:
MIN([DISTINCT | ALL] expression ) [OVER ( analytic_clause )]
WhenthequerycontainsaGROUP BY clause,returnsonevalueforeachcombinationofgroupingvalues.
Restrictions: InImpala2.0andhigher,thisfunctioncanbeusedasananalyticfunction, butwithrestrictionsonany
windowclause.ForMAX()andMIN(),thewindowclauseisonlyallowedifthestartboundisUNBOUNDED PRECEDING .
Returntype:Sameastheinputvalue,exceptforCHARandVARCHAR argumentswhichproduceaSTRINGresult
Usagenotes:
Ifyoufrequentlyrunaggregatefunctions suchasMIN(),MAX(),andCOUNT(DISTINCT) onpartition keycolumns,
considerenablingtheOPTIMIZE_PARTITION_KEY_SCANS queryoption,whichoptimizessuchqueries.Thisfeature
isavailableinCDH5.7/Impala2.5andhigher.SeeOPTIMIZE_PARTITION_KEY_SCANS QueryOption(CDH5.7orhigher
only)onpage348forthekindsofqueriesthatthisoptionappliesto,andslightdifferencesinhowpartitions areevaluated
whenthisqueryoptionisenabled.
Complextypeconsiderations:
Toaccessacolumnwithacomplextype(ARRAY,STRUCT,orMAP)inanaggregationfunction, youunpacktheindividual
elementsusingjoinnotationinthequery,andthenapplythefunctiontothefinalscalaritem,field,key,orvalueat
thebottomofanynestedtypehierarchyinthecolumn.SeeComplexTypes(CDH5.5orhigheronly)onpage139for
detailsaboutusingcomplextypesinImpala.
Thefollowingexampledemonstratescallstoseveralaggregationfunctions usingvaluesfromacolumncontaining
nestedcomplextypes(anARRAYofSTRUCTitems).Thearrayisunpackedinsidethequeryusingjoinnotation.The
arrayelementsarereferencedusingtheITEMpseudocolumn,andthestructurefieldsinsidethearrayelementsare
referencedusingdotnotation.NumericvaluessuchasSUM()andAVG()arecomputedusingthenumericR_NATIONKEY
field,andthegeneral-purpose MAX()andMIN()valuesarecomputedfromthestringN_NAMEfield.
describe region;
+-------------+-------------------------+---------+
| name        | type                    | comment |
+-------------+-------------------------+---------+
| r_regionkey | smallint                |         |
| r_name      | string                  |         |
| r_comment   | string                  |         |
| r_nations   | array<struct<           |         |
|             |   n_nationkey:smallint, |         |
|             |   n_name:string,        |         |
|             |   n_comment:string      |         |
|             | >>                      |         |
+-------------+-------------------------+---------+
select r_name, r_nations.item.n_nationkey
  from region, region.r_nations as r_nations
order by r_name, r_nations.item.n_nationkey;
+-------------+------------------+
| r_name      | item.n_nationkey |
+-------------+------------------+
| AFRICA      | 0                |
| AFRICA      | 5                |
| AFRICA      | 14               |
| AFRICA      | 15               |
| AFRICA      | 16               |
| AMERICA     | 1                |
| AMERICA     | 2                |
| AMERICA     | 3                |
| AMERICA     | 17               |
| AMERICA     | 24               |
| ASIA        | 8                |
| ASIA        | 9                |
| ASIA        | 12               |
494|ApacheImpalaGuideImpalaSQLLanguageReference
| ASIA        | 18               |
| ASIA        | 21               |
| EUROPE      | 6                |
| EUROPE      | 7                |
| EUROPE      | 19               |
| EUROPE      | 22               |
| EUROPE      | 23               |
| MIDDLE EAST | 4                |
| MIDDLE EAST | 10               |
| MIDDLE EAST | 11               |
| MIDDLE EAST | 13               |
| MIDDLE EAST | 20               |
+-------------+------------------+
select
  r_name,
  count(r_nations.item.n_nationkey) as count,
  sum(r_nations.item.n_nationkey) as sum,
  avg(r_nations.item.n_nationkey) as avg,
  min(r_nations.item.n_name) as minimum,
  max(r_nations.item.n_name) as maximum,
  ndv(r_nations.item.n_nationkey) as distinct_vals
from
  region, region.r_nations as r_nations
group by r_name
order by r_name;
+-------------+-------+-----+------+-----------+----------------+---------------+
| r_name      | count | sum | avg  | minimum   | maximum        | distinct_vals |
+-------------+-------+-----+------+-----------+----------------+---------------+
| AFRICA      | 5     | 50  | 10   | ALGERIA   | MOZAMBIQUE     | 5             |
| AMERICA     | 5     | 47  | 9.4  | ARGENTINA | UNITED STATES  | 5             |
| ASIA        | 5     | 68  | 13.6 | CHINA     | VIETNAM        | 5             |
| EUROPE      | 5     | 77  | 15.4 | FRANCE    | UNITED KINGDOM | 5             |
| MIDDLE EAST | 5     | 58  | 11.6 | EGYPT     | SAUDI ARABIA   | 5             |
+-------------+-------+-----+------+-----------+----------------+---------------+
Examples:
-- Find the smallest value for this column in the table.
select min(c1) from t1;
-- Find the smallest value for this column from a subset of the table.
select min(c1) from t1 where month = 'January' and year = '2013';
-- Find the smallest value from a set of numeric function results.
select min(length(s)) from t1;
-- Can also be used in combination with DISTINCT and/or GROUP BY.
-- Return more than one result.
select month, year, min(purchase_price) from store_stats group by month, year;
-- Filter the input to eliminate duplicates before performing the calculation.
select min(distinct x) from t1;
ThefollowingexamplesshowhowtouseMIN()inananalyticcontext.Theyuseatablecontainingintegersfrom1to
10.NoticehowtheMIN()isreportedforeachinputvalue,asopposedtotheGROUP BY clausewhichcondenses the
resultset.
select x, property, min(x) over (partition by property) as min from int_t where property
 in ('odd','even');
+----+----------+-----+
| x  | property | min |
+----+----------+-----+
| 2  | even     | 2   |
| 4  | even     | 2   |
| 6  | even     | 2   |
| 8  | even     | 2   |
| 10 | even     | 2   |
| 1  | odd      | 1   |
| 3  | odd      | 1   |
| 5  | odd      | 1   |
| 7  | odd      | 1   |
| 9  | odd      | 1   |
+----+----------+-----+
ApacheImpalaGuide|495ImpalaSQLLanguageReference
AddinganORDER BY clauseletsyouexperimen twithresultsthatarecumulativeorapplytoamovingsetofrows(the
âwindowâ).ThefollowingexamplesuseMIN()inananalyticcontext(thatis,withanOVER()clause)todisplaythe
smallestvalueofXencountereduptoeachrowintheresultset.TheexamplesusetwocolumnsintheORDER BY
clausetoproduceasequence ofvaluesthatrisesandfalls,toillustratehowtheMIN()resultonlydecreasesorstays
thesamethroughouteachpartition withintheresultset.ThebasicORDER BY x clauseimplicitly activatesawindow
clauseofRANGE BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW ,whichiseffectivelythesameasROWS
BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW ,thereforealloftheseexamplesproducethesameresults:
select x, property, min(x) over (order by property, x desc)  as 'minimum to this point'
  from int_t where property in ('prime','square');
+---+----------+-----------------------+
| x | property | minimum to this point |
+---+----------+-----------------------+
| 7 | prime    | 7                     |
| 5 | prime    | 5                     |
| 3 | prime    | 3                     |
| 2 | prime    | 2                     |
| 9 | square   | 2                     |
| 4 | square   | 2                     |
| 1 | square   | 1                     |
+---+----------+-----------------------+
select x, property,
  min(x) over
  (
order by property, x desc
range between unbounded preceding and current row
  ) as 'minimum to this point'
from int_t where property in ('prime','square');
+---+----------+-----------------------+
| x | property | minimum to this point |
+---+----------+-----------------------+
| 7 | prime    | 7                     |
| 5 | prime    | 5                     |
| 3 | prime    | 3                     |
| 2 | prime    | 2                     |
| 9 | square   | 2                     |
| 4 | square   | 2                     |
| 1 | square   | 1                     |
+---+----------+-----------------------+
select x, property,
  min(x) over
  (
order by property, x desc
rows between unbounded preceding and current row
  ) as 'minimum to this point'
from int_t where property in ('prime','square');
+---+----------+-----------------------+
| x | property | minimum to this point |
+---+----------+-----------------------+
| 7 | prime    | 7                     |
| 5 | prime    | 5                     |
| 3 | prime    | 3                     |
| 2 | prime    | 2                     |
| 9 | square   | 2                     |
| 4 | square   | 2                     |
| 1 | square   | 1                     |
+---+----------+-----------------------+
Thefollowingexamplesshowhowtoconstructamovingwindow,witharunningminimum takingintoaccountallrows
beforeand1rowafterthecurrentrow.BecauseofarestrictionintheImpalaRANGEsyntax,thistypeofmovingwindow
ispossiblewiththeROWS BETWEEN clausebutnottheRANGE BETWEEN clause.BecauseofanextraImpalarestriction
ontheMAX()andMIN()functions inananalyticcontext,thelowerboundmustbeUNBOUNDED PRECEDING .
select x, property,
  min(x) over
  (
order by property, x desc
rows between unbounded preceding and 1 following
496|ApacheImpalaGuideImpalaSQLLanguageReference
  ) as 'local minimum'
from int_t where property in ('prime','square');
+---+----------+---------------+
| x | property | local minimum |
+---+----------+---------------+
| 7 | prime    | 5             |
| 5 | prime    | 3             |
| 3 | prime    | 2             |
| 2 | prime    | 2             |
| 9 | square   | 2             |
| 4 | square   | 1             |
| 1 | square   | 1             |
+---+----------+---------------+
-- Doesn't work because of syntax restriction on RANGE clause.
select x, property,
  min(x) over
  (
order by property, x desc
range between unbounded preceding and 1 following
  ) as 'local minimum'
from int_t where property in ('prime','square');
ERROR: AnalysisException: RANGE is only supported with both the lower and upper bounds
 UNBOUNDED or one UNBOUNDED and the other CURRENT ROW.
Relatedinformation:
ImpalaAnalyticFunctions onpage506,MAXFunction onpage490,AVGFunction onpage481
NDVFunction
AnaggregatefunctionthatreturnsanapproximatevaluesimilartotheresultofCOUNT(DISTINCT col),theânumber
ofdistinctvaluesâ.ItismuchfasterthanthecombinationofCOUNTandDISTINCT ,andusesaconstantamountof
memoryandthusislessmemory-intensiveforcolumnswithhighcardinality.
Syntax:
NDV([DISTINCT | ALL] expression )
Usagenotes:
Thisisthemechanism usedinternallybytheCOMPUTE STATS statementforcomputing thenumberofdistinctvalues
inacolumn.
Becausethisnumberisanestimate,itmightnotreflecttheprecisenumberofdifferentvaluesinthecolumn,especially
ifthecardinalityisveryloworveryhigh.Iftheestimatednumberishigherthanthenumberofrowsinthetable,Impala
adjuststhevalueinternallyduringqueryplanning.
Returntype:DOUBLEinImpala2.0andhigher;STRINGinearlierreleases
Complextypeconsiderations:
Toaccessacolumnwithacomplextype(ARRAY,STRUCT,orMAP)inanaggregationfunction, youunpacktheindividual
elementsusingjoinnotationinthequery,andthenapplythefunctiontothefinalscalaritem,field,key,orvalueat
thebottomofanynestedtypehierarchyinthecolumn.SeeComplexTypes(CDH5.5orhigheronly)onpage139for
detailsaboutusingcomplextypesinImpala.
Thefollowingexampledemonstratescallstoseveralaggregationfunctions usingvaluesfromacolumncontaining
nestedcomplextypes(anARRAYofSTRUCTitems).Thearrayisunpackedinsidethequeryusingjoinnotation.The
arrayelementsarereferencedusingtheITEMpseudocolumn,andthestructurefieldsinsidethearrayelementsare
referencedusingdotnotation.NumericvaluessuchasSUM()andAVG()arecomputedusingthenumericR_NATIONKEY
field,andthegeneral-purpose MAX()andMIN()valuesarecomputedfromthestringN_NAMEfield.
describe region;
+-------------+-------------------------+---------+
| name        | type                    | comment |
+-------------+-------------------------+---------+
ApacheImpalaGuide|497ImpalaSQLLanguageReference
| r_regionkey | smallint                |         |
| r_name      | string                  |         |
| r_comment   | string                  |         |
| r_nations   | array<struct<           |         |
|             |   n_nationkey:smallint, |         |
|             |   n_name:string,        |         |
|             |   n_comment:string      |         |
|             | >>                      |         |
+-------------+-------------------------+---------+
select r_name, r_nations.item.n_nationkey
  from region, region.r_nations as r_nations
order by r_name, r_nations.item.n_nationkey;
+-------------+------------------+
| r_name      | item.n_nationkey |
+-------------+------------------+
| AFRICA      | 0                |
| AFRICA      | 5                |
| AFRICA      | 14               |
| AFRICA      | 15               |
| AFRICA      | 16               |
| AMERICA     | 1                |
| AMERICA     | 2                |
| AMERICA     | 3                |
| AMERICA     | 17               |
| AMERICA     | 24               |
| ASIA        | 8                |
| ASIA        | 9                |
| ASIA        | 12               |
| ASIA        | 18               |
| ASIA        | 21               |
| EUROPE      | 6                |
| EUROPE      | 7                |
| EUROPE      | 19               |
| EUROPE      | 22               |
| EUROPE      | 23               |
| MIDDLE EAST | 4                |
| MIDDLE EAST | 10               |
| MIDDLE EAST | 11               |
| MIDDLE EAST | 13               |
| MIDDLE EAST | 20               |
+-------------+------------------+
select
  r_name,
  count(r_nations.item.n_nationkey) as count,
  sum(r_nations.item.n_nationkey) as sum,
  avg(r_nations.item.n_nationkey) as avg,
  min(r_nations.item.n_name) as minimum,
  max(r_nations.item.n_name) as maximum,
  ndv(r_nations.item.n_nationkey) as distinct_vals
from
  region, region.r_nations as r_nations
group by r_name
order by r_name;
+-------------+-------+-----+------+-----------+----------------+---------------+
| r_name      | count | sum | avg  | minimum   | maximum        | distinct_vals |
+-------------+-------+-----+------+-----------+----------------+---------------+
| AFRICA      | 5     | 50  | 10   | ALGERIA   | MOZAMBIQUE     | 5             |
| AMERICA     | 5     | 47  | 9.4  | ARGENTINA | UNITED STATES  | 5             |
| ASIA        | 5     | 68  | 13.6 | CHINA     | VIETNAM        | 5             |
| EUROPE      | 5     | 77  | 15.4 | FRANCE    | UNITED KINGDOM | 5             |
| MIDDLE EAST | 5     | 58  | 11.6 | EGYPT     | SAUDI ARABIA   | 5             |
+-------------+-------+-----+------+-----------+----------------+---------------+
Restrictions:
Thisfunctioncannotbeusedinananalyticcontext.Thatis,theOVER()clauseisnotallowedatallwiththisfunction.
Examples:
498|ApacheImpalaGuideImpalaSQLLanguageReference
Thefollowingexamplequeriesabillion-rowtabletoillustratetherelativeperformance ofCOUNT(DISTINCT) and
NDV().ItshowshowCOUNT(DISTINCT) givesapreciseanswer,butisinefficientforlarge-scaledatawherean
approximateresultissufficient.TheNDV()functiongivesanapproximateresultbutismuchfaster.
select count(distinct col1) from sample_data;
+---------------------+
| count(distinct col1)|
+---------------------+
| 100000              |
+---------------------+
Fetched 1 row(s) in 20.13s
select cast(ndv(col1) as bigint) as col1 from sample_data;
+----------+
| col1     |
+----------+
| 139017   |
+----------+
Fetched 1 row(s) in 8.91s
ThefollowingexampleshowshowyoucancodemultipleNDV()callsinasinglequery,toeasilylearnwhichcolumns
havesubstantiallymoreorfewerdistinctvalues.Thistechnique isfasterthanrunningasequence ofquerieswith
COUNT(DISTINCT) calls.
select cast(ndv(col1) as bigint) as col1, cast(ndv(col2) as bigint) as col2,
    cast(ndv(col3) as bigint) as col3, cast(ndv(col4) as bigint) as col4
  from sample_data;
+----------+-----------+------------+-----------+
| col1     | col2      | col3       | col4      |
+----------+-----------+------------+-----------+
| 139017   | 282       | 46         | 145636240 |
+----------+-----------+------------+-----------+
Fetched 1 row(s) in 34.97s
select count(distinct col1) from sample_data;
+---------------------+
| count(distinct col1)|
+---------------------+
| 100000              |
+---------------------+
Fetched 1 row(s) in 20.13s
select count(distinct col2) from sample_data;
+----------------------+
| count(distinct col2) |
+----------------------+
| 278                  |
+----------------------+
Fetched 1 row(s) in 20.09s
select count(distinct col3) from sample_data;
+-----------------------+
| count(distinct col3)  |
+-----------------------+
| 46                    |
+-----------------------+
Fetched 1 row(s) in 19.12s
select count(distinct col4) from sample_data;
+----------------------+
| count(distinct col4) |
+----------------------+
| 147135880            |
+----------------------+
Fetched 1 row(s) in 266.95s
STDDEV,STDDEV_SAMP,STDDEV_POP Functions
Anaggregatefunctionthatreturnsthestandarddeviationofasetofnumbers.
ApacheImpalaGuide|499ImpalaSQLLanguageReference
Syntax:
{ STDDEV | STDDEV_SAMP | STDDEV_POP } ([DISTINCT | ALL] expression )
Thisfunctionworkswithanynumericdatatype.
Returntype:DOUBLEinImpala2.0andhigher;STRINGinearlierreleases
Thisfunctionistypicallyusedinmathematicalformulasrelatedtoprobability distributions.
TheSTDDEV_POP() andSTDDEV_SAMP() functions computethepopulationstandarddeviationandsamplestandard
deviation,respectively,oftheinputvalues.(STDDEV() isanaliasforSTDDEV_SAMP() .)Bothfunctions evaluateall
inputrowsmatchedbythequery.ThedifferenceisthatSTDDEV_SAMP() isscaledby1/(N-1) whileSTDDEV_POP()
isscaledby1/N.
Ifnoinputrowsmatchthequery,theresultofanyofthesefunctions isNULL.Ifasingleinputrowmatchesthequery,
theresultofanyofthesefunctions is"0.0".
Examples:
ThisexampledemonstrateshowSTDDEV() andSTDDEV_SAMP() returnthesameresult,whileSTDDEV_POP() uses
aslightlydifferentcalculationtoreflectthattheinputdataisconsideredpartofalargerâpopulationâ.
[localhost:21000] > select stddev(score) from test_scores;
+---------------+
| stddev(score) |
+---------------+
| 28.5          |
+---------------+
[localhost:21000] > select stddev_samp(score) from test_scores;
+--------------------+
| stddev_samp(score) |
+--------------------+
| 28.5               |
+--------------------+
[localhost:21000] > select stddev_pop(score) from test_scores;
+-------------------+
| stddev_pop(score) |
+-------------------+
| 28.4858           |
+-------------------+
Thisexampledemonstratesthat,becausethereturnvalueoftheseaggregatefunctions isaSTRING,youmustcurrently
converttheresultwithCAST.
[localhost:21000] > create table score_stats as select cast(stddev(score) as decimal(7,4))
 `standard_deviation`, cast(variance(score) as decimal(7,4)) `variance` from test_scores;
+-------------------+
| summary           |
+-------------------+
| Inserted 1 row(s) |
+-------------------+
[localhost:21000] > desc score_stats;
+--------------------+--------------+---------+
| name               | type         | comment |
+--------------------+--------------+---------+
| standard_deviation | decimal(7,4) |         |
| variance           | decimal(7,4) |         |
+--------------------+--------------+---------+
Restrictions:
Thisfunctioncannotbeusedinananalyticcontext.Thatis,theOVER()clauseisnotallowedatallwiththisfunction.
Relatedinformation:
TheSTDDEV() ,STDDEV_POP() ,andSTDDEV_SAMP() functions computethestandarddeviation(squarerootofthe
variance)basedontheresultsofVARIANCE() ,VARIANCE_POP() ,andVARIANCE_SAMP() respectively.SeeVARIANCE,
VARIANCE_S AMP,VARIANCE_POP ,VAR_SAMP,VAR_POPFunctions onpage505fordetailsaboutthevarianceproperty.
500|ApacheImpalaGuideImpalaSQLLanguageReference
SUMFunction
Anaggregatefunctionthatreturnsthesumofasetofnumbers.Itssingleargumentcanbenumericcolumn,orthe
numericresultofafunctionorexpressionappliedtothecolumnvalue.RowswithaNULLvalueforthespecified column
areignored.Ifthetableisempty,orallthevaluessuppliedtoMINareNULL,SUMreturnsNULL.
Syntax:
SUM([DISTINCT | ALL] expression ) [OVER ( analytic_clause )]
WhenthequerycontainsaGROUP BY clause,returnsonevalueforeachcombinationofgroupingvalues.
Returntype:BIGINTforintegerarguments,DOUBLEforfloating-pointarguments
Complextypeconsiderations:
Toaccessacolumnwithacomplextype(ARRAY,STRUCT,orMAP)inanaggregationfunction, youunpacktheindividual
elementsusingjoinnotationinthequery,andthenapplythefunctiontothefinalscalaritem,field,key,orvalueat
thebottomofanynestedtypehierarchyinthecolumn.SeeComplexTypes(CDH5.5orhigheronly)onpage139for
detailsaboutusingcomplextypesinImpala.
Thefollowingexampledemonstratescallstoseveralaggregationfunctions usingvaluesfromacolumncontaining
nestedcomplextypes(anARRAYofSTRUCTitems).Thearrayisunpackedinsidethequeryusingjoinnotation.The
arrayelementsarereferencedusingtheITEMpseudocolumn,andthestructurefieldsinsidethearrayelementsare
referencedusingdotnotation.NumericvaluessuchasSUM()andAVG()arecomputedusingthenumericR_NATIONKEY
field,andthegeneral-purpose MAX()andMIN()valuesarecomputedfromthestringN_NAMEfield.
describe region;
+-------------+-------------------------+---------+
| name        | type                    | comment |
+-------------+-------------------------+---------+
| r_regionkey | smallint                |         |
| r_name      | string                  |         |
| r_comment   | string                  |         |
| r_nations   | array<struct<           |         |
|             |   n_nationkey:smallint, |         |
|             |   n_name:string,        |         |
|             |   n_comment:string      |         |
|             | >>                      |         |
+-------------+-------------------------+---------+
select r_name, r_nations.item.n_nationkey
  from region, region.r_nations as r_nations
order by r_name, r_nations.item.n_nationkey;
+-------------+------------------+
| r_name      | item.n_nationkey |
+-------------+------------------+
| AFRICA      | 0                |
| AFRICA      | 5                |
| AFRICA      | 14               |
| AFRICA      | 15               |
| AFRICA      | 16               |
| AMERICA     | 1                |
| AMERICA     | 2                |
| AMERICA     | 3                |
| AMERICA     | 17               |
| AMERICA     | 24               |
| ASIA        | 8                |
| ASIA        | 9                |
| ASIA        | 12               |
| ASIA        | 18               |
| ASIA        | 21               |
| EUROPE      | 6                |
| EUROPE      | 7                |
| EUROPE      | 19               |
| EUROPE      | 22               |
| EUROPE      | 23               |
| MIDDLE EAST | 4                |
| MIDDLE EAST | 10               |
ApacheImpalaGuide|501ImpalaSQLLanguageReference
| MIDDLE EAST | 11               |
| MIDDLE EAST | 13               |
| MIDDLE EAST | 20               |
+-------------+------------------+
select
  r_name,
  count(r_nations.item.n_nationkey) as count,
  sum(r_nations.item.n_nationkey) as sum,
  avg(r_nations.item.n_nationkey) as avg,
  min(r_nations.item.n_name) as minimum,
  max(r_nations.item.n_name) as maximum,
  ndv(r_nations.item.n_nationkey) as distinct_vals
from
  region, region.r_nations as r_nations
group by r_name
order by r_name;
+-------------+-------+-----+------+-----------+----------------+---------------+
| r_name      | count | sum | avg  | minimum   | maximum        | distinct_vals |
+-------------+-------+-----+------+-----------+----------------+---------------+
| AFRICA      | 5     | 50  | 10   | ALGERIA   | MOZAMBIQUE     | 5             |
| AMERICA     | 5     | 47  | 9.4  | ARGENTINA | UNITED STATES  | 5             |
| ASIA        | 5     | 68  | 13.6 | CHINA     | VIETNAM        | 5             |
| EUROPE      | 5     | 77  | 15.4 | FRANCE    | UNITED KINGDOM | 5             |
| MIDDLE EAST | 5     | 58  | 11.6 | EGYPT     | SAUDI ARABIA   | 5             |
+-------------+-------+-----+------+-----------+----------------+---------------+
Examples:
ThefollowingexampleshowshowtouseSUM()tocomputethetotalforallthevaluesinthetable,asubsetofvalues,
orthesumforeachcombinationofvaluesintheGROUP BY clause:
-- Total all the values for this column in the table.
select sum(c1) from t1;
-- Find the total for this column from a subset of the table.
select sum(c1) from t1 where month = 'January' and year = '2013';
-- Find the total from a set of numeric function results.
select sum(length(s)) from t1;
-- Often used with functions that return predefined values to compute a score.
select sum(case when grade = 'A' then 1.0 when grade = 'B' then 0.75 else 0) as 
class_honors from test_scores;
-- Can also be used in combination with DISTINCT and/or GROUP BY.
-- Return more than one result.
select month, year, sum(purchase_price) from store_stats group by month, year;
-- Filter the input to eliminate duplicates before performing the calculation.
select sum(distinct x) from t1;
ThefollowingexamplesshowhowtouseSUM()inananalyticcontext.Theyuseatablecontainingintegersfrom1to
10.NoticehowtheSUM()isreportedforeachinputvalue,asopposedtotheGROUP BY clausewhichcondenses the
resultset.
select x, property, sum(x) over (partition by property)  as sum from int_t where property
 in ('odd','even');
+----+----------+-----+
| x  | property | sum |
+----+----------+-----+
| 2  | even     | 30  |
| 4  | even     | 30  |
| 6  | even     | 30  |
| 8  | even     | 30  |
| 10 | even     | 30  |
| 1  | odd      | 25  |
| 3  | odd      | 25  |
| 5  | odd      | 25  |
| 7  | odd      | 25  |
| 9  | odd      | 25  |
+----+----------+-----+
AddinganORDER BY clauseletsyouexperimen twithresultsthatarecumulativeorapplytoamovingsetofrows(the
âwindowâ).ThefollowingexamplesuseSUM()inananalyticcontext(thatis,withanOVER()clause)toproducea
502|ApacheImpalaGuideImpalaSQLLanguageReference
runningtotalofalltheevenvalues,thenarunningtotalofalltheoddvalues.ThebasicORDER BY x clauseimplicitly
activatesawindowclauseofRANGE BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW ,whichiseffectively
thesameasROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW ,thereforealloftheseexamplesproduce
thesameresults:
select x, property,
  sum(x) over (partition by property order by x ) as 'cumulative total'
  from int_t where property in ('odd','even');
+----+----------+------------------+
| x  | property | cumulative total |
+----+----------+------------------+
| 2  | even     | 2                |
| 4  | even     | 6                |
| 6  | even     | 12               |
| 8  | even     | 20               |
| 10 | even     | 30               |
| 1  | odd      | 1                |
| 3  | odd      | 4                |
| 5  | odd      | 9                |
| 7  | odd      | 16               |
| 9  | odd      | 25               |
+----+----------+------------------+
select x, property,
  sum(x) over
  (
    partition by property
order by x
range between unbounded preceding and current row
  ) as 'cumulative total'
from int_t where property in ('odd','even');
+----+----------+------------------+
| x  | property | cumulative total |
+----+----------+------------------+
| 2  | even     | 2                |
| 4  | even     | 6                |
| 6  | even     | 12               |
| 8  | even     | 20               |
| 10 | even     | 30               |
| 1  | odd      | 1                |
| 3  | odd      | 4                |
| 5  | odd      | 9                |
| 7  | odd      | 16               |
| 9  | odd      | 25               |
+----+----------+------------------+
select x, property,
  sum(x) over
  (
    partition by property
order by x
rows between unbounded preceding and current row
  ) as 'cumulative total'
  from int_t where property in ('odd','even');
+----+----------+------------------+
| x  | property | cumulative total |
+----+----------+------------------+
| 2  | even     | 2                |
| 4  | even     | 6                |
| 6  | even     | 12               |
| 8  | even     | 20               |
| 10 | even     | 30               |
| 1  | odd      | 1                |
| 3  | odd      | 4                |
| 5  | odd      | 9                |
| 7  | odd      | 16               |
| 9  | odd      | 25               |
+----+----------+------------------+
ApacheImpalaGuide|503ImpalaSQLLanguageReference
Changing thedirectionoftheORDER BY clausecausestheintermediateresultsofthecumulativetotaltobecalculated
inadifferentorder:
select sum(x) over (partition by property order by x desc ) as 'cumulative total'
  from int_t where property in ('odd','even');
+----+----------+------------------+
| x  | property | cumulative total |
+----+----------+------------------+
| 10 | even     | 10               |
| 8  | even     | 18               |
| 6  | even     | 24               |
| 4  | even     | 28               |
| 2  | even     | 30               |
| 9  | odd      | 9                |
| 7  | odd      | 16               |
| 5  | odd      | 21               |
| 3  | odd      | 24               |
| 1  | odd      | 25               |
+----+----------+------------------+
Thefollowingexamplesshowhowtoconstructamovingwindow,witharunningtotaltakingintoaccount1rowbefore
and1rowafterthecurrentrow,withinthesamepartition (alltheevenvaluesoralltheoddvalues).Becauseofa
restrictionintheImpalaRANGEsyntax,thistypeofmovingwindowispossiblewiththeROWS BETWEEN clausebutnot
theRANGE BETWEEN clause:
select x, property,
  sum(x) over
  (
    partition by property
order by x
rows between 1 preceding and 1 following
  ) as 'moving total'
  from int_t where property in ('odd','even');
+----+----------+--------------+
| x  | property | moving total |
+----+----------+--------------+
| 2  | even     | 6            |
| 4  | even     | 12           |
| 6  | even     | 18           |
| 8  | even     | 24           |
| 10 | even     | 18           |
| 1  | odd      | 4            |
| 3  | odd      | 9            |
| 5  | odd      | 15           |
| 7  | odd      | 21           |
| 9  | odd      | 16           |
+----+----------+--------------+
-- Doesn't work because of syntax restriction on RANGE clause.
select x, property,
  sum(x) over
  (
    partition by property
order by x
range between 1 preceding and 1 following
  ) as 'moving total'
from int_t where property in ('odd','even');
ERROR: AnalysisException: RANGE is only supported with both the lower and upper bounds
 UNBOUNDED or one UNBOUNDED and the other CURRENT ROW.
Restrictions:
DuetothewayarithmeticonFLOATandDOUBLEcolumnsuseshigh-performancehardwareinstructions, anddistributed
queriescanperformtheseoperationsindifferentorderforeachquery,resultscanvaryslightlyforaggregatefunction
callssuchasSUM()andAVG()forFLOATandDOUBLEcolumns,particularly onlargedatasetswheremillionsorbillions
ofvaluesaresummed oraveraged.Forperfectconsistencyandrepeatability,usetheDECIMAL datatypeforsuch
operationsinsteadofFLOATorDOUBLE.
Relatedinformation:
504|ApacheImpalaGuideImpalaSQLLanguageReference
ImpalaAnalyticFunctions onpage506
VARIANCE, VARIANCE_S AMP,VARIANCE_POP ,VAR_SAMP,VAR_POPFunctions
Anaggregatefunctionthatreturnsthevarianceofasetofnumbers.Thisisamathematicalpropertythatsignifieshow
farthevaluesspreadapartfromthemean.Thereturnvaluecanbezero(iftheinputisasinglevalue,orasetofidentical
values),orapositivenumberotherwise.
Syntax:
{ VARIANCE | VAR[IANCE]_SAMP | VAR[IANCE]_POP } ([DISTINCT | ALL] expression )
Thisfunctionworkswithanynumericdatatype.
Returntype:DOUBLEinImpala2.0andhigher;STRINGinearlierreleases
Thisfunctionistypicallyusedinmathematicalformulasrelatedtoprobability distributions.
TheVARIANCE_SAMP() andVARIANCE_POP() functions computethesamplevarianceandpopulationvariance,
respectively,oftheinputvalues.(VARIANCE() isanaliasforVARIANCE_SAMP() .)Bothfunctions evaluateallinput
rowsmatchedbythequery.ThedifferenceisthatSTDDEV_SAMP() isscaledby1/(N-1) whileSTDDEV_POP() is
scaledby1/N.
ThefunctionsVAR_SAMP() andVAR_POP() arethesameasVARIANCE_SAMP() andVARIANCE_POP() ,respectively.
ThesealiasesareavailableinImpala2.0andlater.
Ifnoinputrowsmatchthequery,theresultofanyofthesefunctions isNULL.Ifasingleinputrowmatchesthequery,
theresultofanyofthesefunctions is"0.0".
Examples:
ThisexampledemonstrateshowVARIANCE() andVARIANCE_SAMP() returnthesameresult,whileVARIANCE_POP()
usesaslightlydifferentcalculationtoreflectthattheinputdataisconsideredpartofalargerâpopulationâ.
[localhost:21000] > select variance(score) from test_scores;
+-----------------+
| variance(score) |
+-----------------+
| 812.25          |
+-----------------+
[localhost:21000] > select variance_samp(score) from test_scores;
+----------------------+
| variance_samp(score) |
+----------------------+
| 812.25               |
+----------------------+
[localhost:21000] > select variance_pop(score) from test_scores;
+---------------------+
| variance_pop(score) |
+---------------------+
| 811.438             |
+---------------------+
Thisexampledemonstratesthat,becausethereturnvalueoftheseaggregatefunctions isaSTRING,youconvertthe
resultwithCASTifyouneedtodofurthercalculationsasanumericvalue.
[localhost:21000] > create table score_stats as select cast(stddev(score) as decimal(7,4))
 `standard_deviation`, cast(variance(score) as decimal(7,4)) `variance` from test_scores;
+-------------------+
| summary           |
+-------------------+
| Inserted 1 row(s) |
+-------------------+
[localhost:21000] > desc score_stats;
+--------------------+--------------+---------+
| name               | type         | comment |
+--------------------+--------------+---------+
| standard_deviation | decimal(7,4) |         |
ApacheImpalaGuide|505ImpalaSQLLanguageReference
| variance           | decimal(7,4) |         |
+--------------------+--------------+---------+
Restrictions:
Thisfunctioncannotbeusedinananalyticcontext.Thatis,theOVER()clauseisnotallowedatallwiththisfunction.
Relatedinformation:
TheSTDDEV() ,STDDEV_POP() ,andSTDDEV_SAMP() functions computethestandarddeviation(squarerootofthe
variance)basedontheresultsofVARIANCE() ,VARIANCE_POP() ,andVARIANCE_SAMP() respectively.SeeSTDDEV,
STDDEV_SAMP,STDDEV_POP Functions onpage499fordetailsaboutthestandarddeviationproperty.
ImpalaAnalyticFunctions
Analyticfunctions (alsoknownaswindowfunctions) areaspecialcategoryofbuilt-infunctions. Likeaggregatefunctions,
theyexaminethecontentsofmultipleinputrowstocomputeeachoutputvalue.However,ratherthanbeinglimited
tooneresultvalueperGROUP BY group,theyoperateonwindowswheretheinputrowsareorderedandgrouped
usingflexibleconditions expressedthroughanOVER()clause.
Addedin:CDH5.2.0/Impala2.0.0
Somefunctions, suchasLAG()andRANK(),canonlybeusedinthisanalyticcontext.Someaggregatefunctions do
doubleduty:whenyoucalltheaggregationfunctions suchasMAX(),SUM(),AVG(),andsoonwithanOVER()clause,
theyproduceanoutputvalueforeachrow,basedoncomputationsacrossotherrowsinthewindow.
Although analyticfunctions oftencomputethesamevalueyouwouldseefromanaggregatefunctioninaGROUP BY
query,theanalyticfunctions produceavalueforeachrowintheresultsetratherthanasinglevalueforeachgroup.
Thisflexibilityletsyouincludeadditional columnsintheSELECTlist,offeringmoreopportunities fororganizingand
filteringtheresultset.
AnalyticfunctioncallsareonlyallowedintheSELECTlistandintheoutermostORDER BY clauseofthequery.During
queryprocessing,analyticfunctions areevaluatedafterotherquerystagessuchasjoins,WHERE,andGROUP BY ,
Therowsthatarepartofeachpartition areanalyzedbycomputationsacrossanorderedorunorderedsetofrows.
Forexample,COUNT() andSUM()mightbeappliedtoalltherowsinthepartition, inwhichcasetheorderofanalysis
doesnotmatter.TheORDER BY clausemightbeusedinsidetheOVER()clausetodefinestheorderingthatapplies
tofunctions suchasLAG()andFIRST_VALUE() .
Analyticfunctions arefrequentlyusedinfieldssuchasfinanceandsciencetoprovidetrend,outlier,andbucketed
analysisforlargedatasets.Youmightalsoseethetermâwindowfunctionsâ indatabaseliterature,referringtothe
sequence ofrows(theâwindowâ)thatthefunctioncallappliesto,particularly whentheOVERclauseincludesaROWS
orRANGEkeyword.
Thefollowingsectionsdescribetheanalyticqueryclausesandthepureanalyticfunctions providedbyImpala.For
usageinformationaboutaggregatefunctions inananalyticcontext,seeImpalaAggregateFunctions onpage479.
OVERClause
TheOVERclauseisrequiredforcallstopureanalyticfunctions suchasLEAD(),RANK(),andFIRST_VALUE() .When
youincludeanOVERclausewithcallstoaggregatefunctions suchasMAX(),COUNT() ,orSUM(),theyoperateas
analyticfunctions.
Syntax:
function( args) OVER([ partition_by_clause ] [order_by_clause  [window_clause ]])
partition_by_clause ::= PARTITION BY expr [, expr ...]
order_by_clause ::= ORDER BY expr  [ASC | DESC] [NULLS FIRST | NULLS LAST] [, expr [ASC
 | DESC] [NULLS FIRST | NULLS LAST] ...]
window_clause: See Window Clause
PARTITIONBYclause:
506|ApacheImpalaGuideImpalaSQLLanguageReference
ThePARTITION BY clauseactsmuchliketheGROUP BY clauseintheoutermostblockofaquery.Itdividestherows
intogroupscontainingidenticalvaluesinoneormorecolumns.Theselogicalgroupsareknownaspartitions .Throughout
thediscussion ofanalyticfunctions, âpartitionsâ referstothegroupsproducedbythePARTITION BY clause,notto
partitioned tables.However,notethefollowinglimitationthatappliesspecificallytoanalyticfunctioncallsinvolving
partitioned tables.
Inqueriesinvolvingbothanalyticfunctions andpartitioned tables,partition pruningonlyoccursforcolumnsnamed
inthePARTITION BY clauseoftheanalyticfunctioncall.Forexample,ifananalyticfunctionqueryhasaclausesuch
asWHERE year=2016 ,thewaytomakethequerypruneallotherYEARpartitions istoincludePARTITION BY year
intheanalyticfunctioncall;forexample,OVER (PARTITION BY year, other_columns
other_analytic_clauses ).
Thesequence ofresultsfromananalyticfunctionâresetsâforeachnewpartition intheresultset.Thatis,thesetof
precedingorfollowingrowsconsideredbytheanalyticfunctionalwayscomefromasinglepartition. AnyMAX(),
SUM(),ROW_NUMBER() ,andsoonapplytoeachpartition independen tly.OmitthePARTITION BY clausetoapply
theanalyticoperationtoalltherowsinthetable.
ORDERBYclause:
TheORDER BY clauseworksmuchliketheORDER BY clauseintheoutermostblockofaquery.Itdefinestheorderin
whichrowsareevaluatedfortheentireinputset,orforeachgroupproducedbyaPARTITION BY clause.Youcan
orderbyoneormultipleexpressions,andforeachexpressionoptionallychooseascending ordescending orderand
whethernullscomefirstorlastinthesortorder.BecausethisORDER BY clauseonlydefinestheorderinwhichrows
areevaluated,ifyouwanttheresultstobeoutputinaspecificorder,alsoincludeanORDER BY clauseintheouter
blockofthequery.
WhentheORDER BY clauseisomitted,theanalyticfunctionappliestoallitemsinthegroupproducedbythePARTITION
BYclause.WhentheORDER BY clauseisincluded, theanalysiscanapplytoallorasubsetoftheitemsinthegroup,
depending ontheoptionalwindowclause.
Theorderinwhichtherowsareanalyzedisonlydefinedforthosecolumnsspecified inORDER BY clauses.
OnedifferencebetweentheanalyticandouterusesoftheORDER BY clause:insidetheOVERclause,ORDER BY 1 or
otherintegervalueisinterpretedasaconstantsortvalue(effectivelyano-op)ratherthanreferringtocolumn1.
Windowclause:
ThewindowclauseisonlyallowedincombinationwithanORDER BY clause.IftheORDER BY clauseisspecified but
thewindowclauseisnot,thedefaultwindowisRANGE BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW .See
WindowClauseonpage508forfulldetails.
HBaseconsiderations:
BecauseHBasetablesareoptimizedforsingle-rowlookupsratherthanfullscans,analyticfunctions usingtheOVER()
clausearenotrecommended forHBasetables.Although suchquerieswork,theirperformance islowerthanon
comparabletablesusingHDFSdatafiles.
Parquetconsiderations:
Analyticfunctions areveryefficientforParquettables.ThedatathatisexaminedduringevaluationoftheOVER()
clausecomesfromaspecified setofcolumns,andthevaluesforeachcolumnarearrangedsequentiallywithineach
datafile.
Texttableconsiderations:
Analyticfunctions areconvenienttousewithtexttablesforexploratorybusinessintelligence.Whenthevolumeof
dataissubstantial,prefertouseParquettablesforperformance-critic alanalyticqueries.
Addedin:CDH5.2.0/Impala2.0.0
Examples:
ApacheImpalaGuide|507ImpalaSQLLanguageReference
Thefollowingexampleshowshowtosynthesizeanumericsequence corresponding toalltherowsinatable.Thenew
tablehasthesamecolumnsastheoldone,plusanadditional columnIDcontainingtheintegers1,2,3,andsoon,
corresponding totheorderofaTIMESTAMP columnintheoriginaltable.
CREATE TABLE events_with_id AS
  SELECT
    row_number() OVER (ORDER BY date_and_time) AS id,
    c1, c2, c3, c4
  FROM events;
Thefollowingexampleshowshowtodeterminethenumberofrowscontainingeachvalueforacolumn.Unlikea
corresponding GROUP BY query,thisonecananalyzeasinglecolumnandstillreturnallvalues(notjustthedistinct
ones)fromtheothercolumns.
SELECT x, y, z,
  count() OVER (PARTITION BY x) AS how_many_x
FROM t1;
Restrictions:
YoucannotdirectlycombinetheDISTINCT operatorwithanalyticfunctioncalls.Youcanputtheanalyticfunctioncall
inaWITHclauseoraninlineview,andapplytheDISTINCT operatortoitsresultset.
WITH t1 AS (SELECT x, sum(x) OVER (PARTITION BY x) AS total FROM t1)
  SELECT DISTINCT x, total FROM t1;
WindowClause
Certainanalyticfunctions acceptanoptionalwindowclause,whichmakesthefunctionanalyzeonlycertainrows
âaroundâthecurrentrowratherthanallrowsinthepartition. Forexample,youcangetamovingaveragebyspecifying
somenumberofprecedingandfollowingrows,orarunningcountorrunningtotalbyspecifyingallrowsuptothe
currentposition. Thisclausecanresultindifferentanalyticresultsforrowswithinthesamepartition.
ThewindowclauseissupportedwiththeAVG(),COUNT() ,FIRST_VALUE() ,LAST_VALUE() ,andSUM()functions.
ForMAX()andMIN(),thewindowclauseonlyallowedifthestartboundisUNBOUNDED PRECEDING
Syntax:
ROWS BETWEEN [ { m | UNBOUNDED } PRECEDING | CURRENT ROW] [ AND [CURRENT ROW | { UNBOUNDED
 | n } FOLLOWING] ]
RANGE BETWEEN [ { m | UNBOUNDED } PRECEDING | CURRENT ROW] [ AND [CURRENT ROW | { UNBOUNDED
 | n } FOLLOWING] ]
ROWS BETWEEN definesthesizeofthewindowintermsoftheindexesoftherowsintheresultset.Thesizeofthe
windowispredictablebasedontheclausesthepositionwithintheresultset.
RANGE BETWEEN doesnotcurrentlysupportnumericargumentstodefineavariable-siz eslidingwindow.
Currently,Impalasupports onlysomecombinationsofargumentstotheRANGEclause:
â¢RANGE BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW (thedefaultwhenORDER BY isspecified and
thewindowclauseisomitted)
â¢RANGE BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING
â¢RANGE BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING
WhenRANGEisused,CURRENT ROW includesnotjustthecurrentrowbutallrowsthataretiedwiththecurrentrow
basedontheORDER BY expressions.
Addedin:CDH5.2.0/Impala2.0.0
Examples:
508|ApacheImpalaGuideImpalaSQLLanguageReference
ThefollowingexamplesshowfinancialdataforafictionalstocksymbolJDR.Theclosingpricemovesupanddown
eachday.
create table stock_ticker (stock_symbol string, closing_price decimal(8,2), closing_date
 timestamp);
...load some data...
select * from stock_ticker order by stock_symbol, closing_date
+--------------+---------------+---------------------+
| stock_symbol | closing_price | closing_date        |
+--------------+---------------+---------------------+
| JDR          | 12.86         | 2014-10-02 00:00:00 |
| JDR          | 12.89         | 2014-10-03 00:00:00 |
| JDR          | 12.94         | 2014-10-04 00:00:00 |
| JDR          | 12.55         | 2014-10-05 00:00:00 |
| JDR          | 14.03         | 2014-10-06 00:00:00 |
| JDR          | 14.75         | 2014-10-07 00:00:00 |
| JDR          | 13.98         | 2014-10-08 00:00:00 |
+--------------+---------------+---------------------+
Thequeriesuseanalyticfunctions withwindowclausestocomputemovingaveragesoftheclosingprice.Forexample,
ROWS BETWEEN 1 PRECEDING AND 1 FOLLOWING producesanaverageofthevaluefroma3-dayspan,producing
adifferentvalueforeachrow.Thefirstrow,whichhasnoprecedingrow,onlygetsaveragedwiththerowfollowing
it.Ifthetablecontainedmorethanonestocksymbol,thePARTITION BY clausewouldlimitthewindowforthe
movingaveragetoonlyconsiderthepricesforasinglestock.
select stock_symbol, closing_date, closing_price,
  avg(closing_price) over (partition by stock_symbol order by closing_date
    rows between 1 preceding and 1 following) as moving_average
  from stock_ticker;
+--------------+---------------------+---------------+----------------+
| stock_symbol | closing_date        | closing_price | moving_average |
+--------------+---------------------+---------------+----------------+
| JDR          | 2014-10-02 00:00:00 | 12.86         | 12.87          |
| JDR          | 2014-10-03 00:00:00 | 12.89         | 12.89          |
| JDR          | 2014-10-04 00:00:00 | 12.94         | 12.79          |
| JDR          | 2014-10-05 00:00:00 | 12.55         | 13.17          |
| JDR          | 2014-10-06 00:00:00 | 14.03         | 13.77          |
| JDR          | 2014-10-07 00:00:00 | 14.75         | 14.25          |
| JDR          | 2014-10-08 00:00:00 | 13.98         | 14.36          |
+--------------+---------------------+---------------+----------------+
TheclauseROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW producesacumulativemovingaverage,
fromtheearliestdatauptothevalueforeachday.
select stock_symbol, closing_date, closing_price,
  avg(closing_price) over (partition by stock_symbol order by closing_date
    rows between unbounded preceding and current row) as moving_average
  from stock_ticker;
+--------------+---------------------+---------------+----------------+
| stock_symbol | closing_date        | closing_price | moving_average |
+--------------+---------------------+---------------+----------------+
| JDR          | 2014-10-02 00:00:00 | 12.86         | 12.86          |
| JDR          | 2014-10-03 00:00:00 | 12.89         | 12.87          |
| JDR          | 2014-10-04 00:00:00 | 12.94         | 12.89          |
| JDR          | 2014-10-05 00:00:00 | 12.55         | 12.81          |
| JDR          | 2014-10-06 00:00:00 | 14.03         | 13.05          |
| JDR          | 2014-10-07 00:00:00 | 14.75         | 13.33          |
| JDR          | 2014-10-08 00:00:00 | 13.98         | 13.42          |
+--------------+---------------------+---------------+----------------+
AVGFunction -AnalyticContext
YoucanincludeanOVERclausewithacalltothisfunctiontouseitasananalyticfunction. SeeAVGFunction onpage
481fordetailsandexamples.
ApacheImpalaGuide|509ImpalaSQLLanguageReference
COUNTFunction -AnalyticContext
YoucanincludeanOVERclausewithacalltothisfunctiontouseitasananalyticfunction. SeeCOUNTFunction on
page485fordetailsandexamples.
CUME_DIS TFunction (CDH5.5orhigheronly)
Returnsthecumulativedistribution ofavalue.Thevalueforeachrowintheresultsetisgreaterthan0andlessthan
orequalto1.
Syntax:
CUME_DIST ( expr)
  OVER ([ partition_by_clause ] order_by_clause )
TheORDER BY clauseisrequired.ThePARTITION BY clauseisoptional.Thewindowclauseisnotallowed.
Usagenotes:
Withineachpartitionoftheresultset,theCUME_DIST() valuerepresentsanascending sequence thatendsat1.Each
valuerepresentstheproportionofrowsinthepartitionwhosevaluesarelessthanorequaltothevalueinthecurrent
row.
Ifthesequence ofinputvaluescontainsties,theCUME_DIST() resultsareidenticalforthetiedvalues.
Impalaonlysupports theCUME_DIST() functioninananalyticcontext,notasaregularaggregatefunction.
Examples:
Thisexampleusesatablewith9rows.TheCUME_DIST() functionevaluatestheentiretablebecausethereisno
PARTITION BY clause,withtherowsorderedbytheweightoftheanimal.thesequence ofvaluesshowsthat1/9of
thevaluesarelessthanorequaltothelightestanimal(mouse), 2/9ofthevaluesarelessthanorequaltothe
second-lightestanimal,andsoonuptotheheaviestanimal(elephant),where9/9oftherowsarelessthanorequal
toitsweight.
create table animals (name string, kind string, kilos decimal(9,3));
insert into animals values
  ('Elephant', 'Mammal', 4000), ('Giraffe', 'Mammal', 1200), ('Mouse', 'Mammal', 0.020),
  ('Condor', 'Bird', 15), ('Horse', 'Mammal', 500), ('Owl', 'Bird', 2.5),
  ('Ostrich', 'Bird', 145), ('Polar bear', 'Mammal', 700), ('Housecat', 'Mammal', 5);
select name, cume_dist() over (order by kilos) from animals;
+------------+-----------------------+
| name       | cume_dist() OVER(...) |
+------------+-----------------------+
| Elephant   | 1                     |
| Giraffe    | 0.8888888888888888    |
| Polar bear | 0.7777777777777778    |
| Horse      | 0.6666666666666666    |
| Ostrich    | 0.5555555555555556    |
| Condor     | 0.4444444444444444    |
| Housecat   | 0.3333333333333333    |
| Owl        | 0.2222222222222222    |
| Mouse      | 0.1111111111111111    |
+------------+-----------------------+
UsingaPARTITION BY clauseproducesaseparatesequence foreachpartition group,inthiscaseoneformammals
andoneforbirds.Becausethereare3birdsand6mammals, thesequence illustrateshow1/3oftheâBirdârowshave
akilosvaluethatislessthanorequaltothelightestbird,1/6oftheâMammalâ rowshaveakilosvaluethatisless
thanorequaltothelightestmammal, andsoonuntilboththeheaviestbirdandheaviestmammalhaveaCUME_DIST()
valueof1.
select name, kind, cume_dist() over (partition by kind order by kilos) from animals
+------------+--------+-----------------------+
| name       | kind   | cume_dist() OVER(...) |
+------------+--------+-----------------------+
510|ApacheImpalaGuideImpalaSQLLanguageReference
| Ostrich    | Bird   | 1                     |
| Condor     | Bird   | 0.6666666666666666    |
| Owl        | Bird   | 0.3333333333333333    |
| Elephant   | Mammal | 1                     |
| Giraffe    | Mammal | 0.8333333333333334    |
| Polar bear | Mammal | 0.6666666666666666    |
| Horse      | Mammal | 0.5                   |
| Housecat   | Mammal | 0.3333333333333333    |
| Mouse      | Mammal | 0.1666666666666667    |
+------------+--------+-----------------------+
WecanreversetheorderingwithineachpartitiongroupbyusinganORDER BY ... DESC clausewithintheOVER()
clause.Nowthelightest(smallestvalueofkilos)animalofeachkindhasaCUME_DIST() valueof1.
select name, kind, cume_dist() over (partition by kind order by kilos desc) from animals
+------------+--------+-----------------------+
| name       | kind   | cume_dist() OVER(...) |
+------------+--------+-----------------------+
| Owl        | Bird   | 1                     |
| Condor     | Bird   | 0.6666666666666666    |
| Ostrich    | Bird   | 0.3333333333333333    |
| Mouse      | Mammal | 1                     |
| Housecat   | Mammal | 0.8333333333333334    |
| Horse      | Mammal | 0.6666666666666666    |
| Polar bear | Mammal | 0.5                   |
| Giraffe    | Mammal | 0.3333333333333333    |
| Elephant   | Mammal | 0.1666666666666667    |
+------------+--------+-----------------------+
Thefollowingexamplemanufacturessomerowswithidenticalvaluesinthekiloscolumn,todemonstratehowthe
resultslookincaseoftievalues.Forsimplicity ,itonlyshowstheCUME_DIST() sequence fortheâBirdârows.Now
with3rowsallwithavalueof15,allofthoserowshavethesameCUME_DIST() value.4/5oftherowshaveavalue
forkilosthatislessthanorequalto15.
insert into animals values ('California Condor', 'Bird', 15), ('Andean Condor', 'Bird',
 15)
select name, kind, cume_dist() over (order by kilos) from animals where kind = 'Bird';
+-------------------+------+-----------------------+
| name              | kind | cume_dist() OVER(...) |
+-------------------+------+-----------------------+
| Ostrich           | Bird | 1                     |
| Condor            | Bird | 0.8                   |
| California Condor | Bird | 0.8                   |
| Andean Condor     | Bird | 0.8                   |
| Owl               | Bird | 0.2                   |
+-------------------+------+-----------------------+
ThefollowingexampleshowshowtouseanORDER BY clauseintheouterblocktoordertheresultsetincaseofties.
Here,alltheâBirdârowsaretogether,thenindescending orderbytheresultoftheCUME_DIST() function, andall
tiedCUME_DIST() valuesareorderedbytheanimalname.
select name, kind, cume_dist() over (partition by kind order by kilos) as ordering
  from animals
where
  kind = 'Bird'
order by kind, ordering desc, name;
+-------------------+------+----------+
| name              | kind | ordering |
+-------------------+------+----------+
| Ostrich           | Bird | 1        |
| Andean Condor     | Bird | 0.8      |
| California Condor | Bird | 0.8      |
| Condor            | Bird | 0.8      |
| Owl               | Bird | 0.2      |
+-------------------+------+----------+
ApacheImpalaGuide|511ImpalaSQLLanguageReference
DENSE_RANK Function
Returnsanascending sequence ofintegers,startingwith1.Theoutputsequence producesduplicateintegersfor
duplicatevaluesoftheORDER BY expressions.Aftergeneratingduplicateoutputvaluesfortheâtiedâinputvalues,
thefunctioncontinuesthesequence withthenexthigherinteger.Therefore,thesequence containsduplicatesbutno
gapswhentheinputcontainsduplicates.Startsthesequence overforeachgroupproducedbythePARTITIONED BY
clause.
Syntax:
DENSE_RANK() OVER([ partition_by_clause ] order_by_clause )
ThePARTITION BY clauseisoptional.TheORDER BY clauseisrequired.Thewindowclauseisnotallowed.
Usagenotes:
Oftenusedfortop-Nandbottom-Nqueries.Forexample,itcouldproduceaâtop10âreportincluding alltheitems
withthe10highestvalues,evenifseveralitemstiedfor1stplace.
SimilartoROW_NUMBER andRANK.Thesefunctions differinhowtheytreatduplicatecombinationsofvalues.
Addedin:CDH5.2.0/Impala2.0.0
Examples:
ThefollowingexampledemonstrateshowtheDENSE_RANK() functionidentifieswhereeachvalueâplacesâinthe
resultset,producingthesameresultforduplicatevalues,butwithastrictsequence from1tothenumberofgroups.
Forexample,whenresultsareorderedbytheXcolumn,both1valuesaretiedforfirst;both2valuesaretiedfor
second;andsoon.
select x, dense_rank() over(order by x) as rank, property from int_t;
+----+------+----------+
| x  | rank | property |
+----+------+----------+
| 1  | 1    | square   |
| 1  | 1    | odd      |
| 2  | 2    | even     |
| 2  | 2    | prime    |
| 3  | 3    | prime    |
| 3  | 3    | odd      |
| 4  | 4    | even     |
| 4  | 4    | square   |
| 5  | 5    | odd      |
| 5  | 5    | prime    |
| 6  | 6    | even     |
| 6  | 6    | perfect  |
| 7  | 7    | lucky    |
| 7  | 7    | lucky    |
| 7  | 7    | lucky    |
| 7  | 7    | odd      |
| 7  | 7    | prime    |
| 8  | 8    | even     |
| 9  | 9    | square   |
| 9  | 9    | odd      |
| 10 | 10   | round    |
| 10 | 10   | even     |
+----+------+----------+
ThefollowingexamplesshowhowtheDENSE_RANK() functionisaffectedbythePARTITION propertywithinthe
ORDER BY clause.
Partitioning bythePROPERTY columngroupsalltheeven,odd,andsoonvaluestogether,andDENSE_RANK() returns
theplaceofeachvaluewithinthegroup,producingseveralascending sequences.
select x, dense_rank() over(partition by property order by x) as rank, property from 
int_t;
+----+------+----------+
| x  | rank | property |
512|ApacheImpalaGuideImpalaSQLLanguageReference
+----+------+----------+
| 2  | 1    | even     |
| 4  | 2    | even     |
| 6  | 3    | even     |
| 8  | 4    | even     |
| 10 | 5    | even     |
| 7  | 1    | lucky    |
| 7  | 1    | lucky    |
| 7  | 1    | lucky    |
| 1  | 1    | odd      |
| 3  | 2    | odd      |
| 5  | 3    | odd      |
| 7  | 4    | odd      |
| 9  | 5    | odd      |
| 6  | 1    | perfect  |
| 2  | 1    | prime    |
| 3  | 2    | prime    |
| 5  | 3    | prime    |
| 7  | 4    | prime    |
| 10 | 1    | round    |
| 1  | 1    | square   |
| 4  | 2    | square   |
| 9  | 3    | square   |
+----+------+----------+
Partitioning bytheXcolumngroupsalltheduplicatenumberstogetherandreturnstheplaceeachvaluewithinthe
group;becauseeachvalueoccursonly1or2times,DENSE_RANK() designateseachXvalueaseitherfirstorsecond
withinitsgroup.
select x, dense_rank() over(partition by x order by property) as rank, property from 
int_t;
+----+------+----------+
| x  | rank | property |
+----+------+----------+
| 1  | 1    | odd      |
| 1  | 2    | square   |
| 2  | 1    | even     |
| 2  | 2    | prime    |
| 3  | 1    | odd      |
| 3  | 2    | prime    |
| 4  | 1    | even     |
| 4  | 2    | square   |
| 5  | 1    | odd      |
| 5  | 2    | prime    |
| 6  | 1    | even     |
| 6  | 2    | perfect  |
| 7  | 1    | lucky    |
| 7  | 1    | lucky    |
| 7  | 1    | lucky    |
| 7  | 2    | odd      |
| 7  | 3    | prime    |
| 8  | 1    | even     |
| 9  | 1    | odd      |
| 9  | 2    | square   |
| 10 | 1    | even     |
| 10 | 2    | round    |
+----+------+----------+
ThefollowingexampleshowshowDENSE_RANK() producesacontinuoussequence whilestillallowingforties.Inthis
case,CroesusandMidasbothhavethesecondlargestfortune,whileCrassushasthethirdlargest.(InRANKFunction
onpage521,youseeasimilarquerywiththeRANK()functionthatshowsthatwhileCrassushasthethirdlargest
fortune,heisthefourthrichestperson.)
select dense_rank() over (order by net_worth desc) as placement, name, net_worth from 
wealth order by placement, name;
+-----------+---------+---------------+
| placement | name    | net_worth     |
+-----------+---------+---------------+
| 1         | Solomon | 2000000000.00 |
| 2         | Croesus | 1000000000.00 |
ApacheImpalaGuide|513ImpalaSQLLanguageReference
| 2         | Midas   | 1000000000.00 |
| 3         | Crassus | 500000000.00  |
| 4         | Scrooge | 80000000.00   |
+-----------+---------+---------------+
Relatedinformation:
RANKFunction onpage521,ROW_NUMBER Function onpage523
FIRST_VALUEFunction
Returnstheexpressionvaluefromthefirstrowinthewindow.Ifyourtablehasnullvalues,youcanusetheIGNORE
NULLSclausetoreturnthefirstnon-nullvaluefromthewindow.Thissamevalueisrepeatedforallresultrowsforthe
group.ThereturnvalueisNULLiftheinputexpressionisNULL.
Syntax:
FIRST_VALUE( expr [IGNORE NULLS]) OVER([ partition_by_clause ] order_by_clause
[window_clause ])
ThePARTITION BY clauseisoptional.TheORDER BY clauseisrequired.Thewindowclauseisoptional.
Usagenotes:
IfanyduplicatevaluesoccurinthetuplesevaluatedbytheORDER BY clause,theresultofthisfunctionisnot
deterministic.Consider addingadditional ORDER BY columnstoensureconsistentordering.
Addedin:CDH5.2.0/Impala2.0.0
Examples:
Thefollowingexampleshowsatablewithawidevarietyofcountry-appropriategreetings.Forconsistency,wewant
tostandardizeonasinglegreetingforeachcountry.TheFIRST_VALUE() functionhelpstoproduceamailmerge
reportwhereeverypersonfromthesamecountryisaddressedwiththesamegreeting.
select name, country, greeting from mail_merge;
+---------+---------+--------------+
| name    | country | greeting     |
+---------+---------+--------------+
| Pete    | USA     | Hello        |
| John    | USA     | Hi           |
| Boris   | Germany | Guten tag    |
| Michael | Germany | Guten morgen |
| Bjorn   | Sweden  | Hej          |
| Mats    | Sweden  | Tja          |
+---------+---------+--------------+
select country, name,
  first_value(greeting)
    over (partition by country order by name, greeting) as greeting
  from mail_merge;
+---------+---------+-----------+
| country | name    | greeting  |
+---------+---------+-----------+
| Germany | Boris   | Guten tag |
| Germany | Michael | Guten tag |
| Sweden  | Bjorn   | Hej       |
| Sweden  | Mats    | Hej       |
| USA     | John    | Hi        |
| USA     | Pete    | Hi        |
+---------+---------+-----------+
Changing theorderinwhichthenamesareevaluatedchangeswhichgreetingisappliedtoeachgroup.
select country, name,
  first_value(greeting)
    over (partition by country order by name desc, greeting) as greeting
  from mail_merge;
514|ApacheImpalaGuideImpalaSQLLanguageReference
+---------+---------+--------------+
| country | name    | greeting     |
+---------+---------+--------------+
| Germany | Michael | Guten morgen |
| Germany | Boris   | Guten morgen |
| Sweden  | Mats    | Tja          |
| Sweden  | Bjorn   | Tja          |
| USA     | Pete    | Hello        |
| USA     | John    | Hello        |
+---------+---------+--------------+
Ifyouintroducenullvaluesinthemail_merge table,theFIRST_VALUE() functionwillproduceadifferentresult
withtheIGNORE NULLS clause.
select * from mail_merge;
+---------+---------+--------------+
| name    | country | greeting     |
+---------+---------+--------------+
| Boris   | Germany | Guten tag    |
| Peng    | China   | Nihao        |
| Mats    | Sweden  | Tja          |
| Bjorn   | Sweden  | Hej          |
| Kei     | Japan   | NULL         |
| Li      | China   | NULL         |
| John    | USA     | Hi           |
| Pete    | USA     | Hello        |
| Michael | Germany | Guten morgen |
+---------+---------+--------------+
select country, name,
  first_value(greeting ignore nulls)
    over (partition by country order by name,greeting) as greeting
  from mail_merge;
+---------+---------+-----------+
| country | name    | greeting  |
+---------+---------+-----------+
| Japan   | Kei     | NULL      |
| Germany | Boris   | Guten tag |
| Germany | Michael | Guten tag |
| China   | Li      | NULL      |
| China   | Peng    | Nihao     |
| Sweden  | Bjorn   | Hej       |
| Sweden  | Mats    | Hej       |
| USA     | John    | Hi        |
| USA     | Pete    | Hi        |
+---------+---------+-----------+
Changing theorderinwhichthenamesareevaluatedchangestheresultbecausenullvaluesarenowencounteredin
adifferentorder.
select country, name,
  first_value(greeting ignore nulls)
    over (partition by country order by name desc, greeting) as greeting
  from mail_merge
+---------+---------+--------------+
| country | name    | greeting     |
+---------+---------+--------------+
| Japan   | Kei     | NULL         |
| China   | Peng    | Nihao        |
| China   | Li      | Nihao        |
| Sweden  | Mats    | Tja          |
| Sweden  | Bjorn   | Tja          |
| USA     | Pete    | Hello        |
| USA     | John    | Hello        |
| Germany | Michael | Guten morgen |
| Germany | Boris   | Guten morgen |
+---------+---------+--------------+
Relatedinformation:
LAST_VALUEFunction onpage517
ApacheImpalaGuide|515ImpalaSQLLanguageReference
LAGFunction
Thisfunctionreturnsthevalueofanexpressionusingcolumnvaluesfromaprecedingrow.Youspecifyaninteger
offset,whichdesignatesarowpositionsomenumberofrowsprevioustothecurrentrow.Anycolumnreferencesin
theexpressionargumentrefertocolumnvaluesfromthatpriorrow.Typically,thetablecontainsatimesequence or
numericsequence columnthatclearlydistinguishes theorderingoftherows.
Syntax:
LAG (expr [, offset] [, default])
  OVER ([ partition_by_clause ] order_by_clause )
TheORDER BY clauseisrequired.ThePARTITION BY clauseisoptional.Thewindowclauseisnotallowed.
Usagenotes:
Sometimesusedananalternativetodoingaself-join.
Addedin:CDH5.2.0/Impala2.0.0
Examples:
ThefollowingexampleusesthesamestockdatacreatedinWindowClauseonpage508.Foreachday,thequeryprints
theclosingpricealongside thepreviousday'sclosingprice.Thefirstrowforeachstocksymbolhasnopreviousrow,
sothatLAG()valueisNULL.
select stock_symbol, closing_date, closing_price,
    lag(closing_price,1) over (partition by stock_symbol order by closing_date) as 
"yesterday closing"
  from stock_ticker
    order by closing_date;
+--------------+---------------------+---------------+-------------------+
| stock_symbol | closing_date        | closing_price | yesterday closing |
+--------------+---------------------+---------------+-------------------+
| JDR          | 2014-09-13 00:00:00 | 12.86         | NULL              |
| JDR          | 2014-09-14 00:00:00 | 12.89         | 12.86             |
| JDR          | 2014-09-15 00:00:00 | 12.94         | 12.89             |
| JDR          | 2014-09-16 00:00:00 | 12.55         | 12.94             |
| JDR          | 2014-09-17 00:00:00 | 14.03         | 12.55             |
| JDR          | 2014-09-18 00:00:00 | 14.75         | 14.03             |
| JDR          | 2014-09-19 00:00:00 | 13.98         | 14.75             |
+--------------+---------------------+---------------+-------------------+
Thefollowingexampledoesanarithmeticoperationbetweenthecurrentrowandavaluefromthepreviousrow,to
produceadeltavalueforeachday.ThisexamplealsodemonstrateshowORDER BY worksindependen tlyinthe
differentpartsofthequery.TheORDER BY closing_date intheOVERclausemakesthequeryanalyzetherowsin
chronologicalorder.ThentheouterqueryblockusesORDER BY closing_date DESC topresenttheresultswith
themostrecentdatefirst.
select stock_symbol, closing_date, closing_price,
    cast(
      closing_price - lag(closing_price,1) over
        (partition by stock_symbol order by closing_date)
      as decimal(8,2)
    )
    as "change from yesterday"
  from stock_ticker
    order by closing_date desc;
+--------------+---------------------+---------------+-----------------------+
| stock_symbol | closing_date        | closing_price | change from yesterday |
+--------------+---------------------+---------------+-----------------------+
| JDR          | 2014-09-19 00:00:00 | 13.98         | -0.76                 |
| JDR          | 2014-09-18 00:00:00 | 14.75         | 0.72                  |
| JDR          | 2014-09-17 00:00:00 | 14.03         | 1.47                  |
| JDR          | 2014-09-16 00:00:00 | 12.55         | -0.38                 |
| JDR          | 2014-09-15 00:00:00 | 12.94         | 0.04                  |
| JDR          | 2014-09-14 00:00:00 | 12.89         | 0.03                  |
516|ApacheImpalaGuideImpalaSQLLanguageReference
| JDR          | 2014-09-13 00:00:00 | 12.86         | NULL                  |
+--------------+---------------------+---------------+-----------------------+
Relatedinformation:
ThisfunctionistheconverseofLEADFunction onpage518.
LAST_VALUEFunction
Returnstheexpressionvaluefromthelastrowinthewindow.Ifyourtablehasnullvalues,youcanusetheIGNORE
NULLSclausetoreturnthelastnon-nullvaluefromthewindow.Thissamevalueisrepeatedforallresultrowsforthe
group.ThereturnvalueisNULLiftheinputexpressionisNULL.
Syntax:
LAST_VALUE( expr [IGNORE NULLS]) OVER([ partition_by_clause ] order_by_clause
[window_clause ])
ThePARTITION BY clauseisoptional.TheORDER BY clauseisrequired.Thewindowclauseisoptional.
Usagenotes:
IfanyduplicatevaluesoccurinthetuplesevaluatedbytheORDER BY clause,theresultofthisfunctionisnot
deterministic.Consider addingadditional ORDER BY columnstoensureconsistentordering.
Addedin:CDH5.2.0/Impala2.0.0
Examples:
ThefollowingexampleusesthesameMAIL_MERGE tableasintheexampleforFIRST_VALUEFunction onpage514.
BecausethedefaultwindowwhenORDER BY isusedisBETWEEN UNBOUNDED PRECEDING AND CURRENT ROW ,the
queryrequirestheUNBOUNDED FOLLOWING tolookaheadtosubsequentrowsandfindthelastvalueforeachcountry.
select country, name,
  last_value(greeting) over (
    partition by country order by name, greeting
    rows between unbounded preceding and unbounded following
  ) as greeting
  from mail_merge
+---------+---------+--------------+
| country | name    | greeting     |
+---------+---------+--------------+
| Germany | Boris   | Guten morgen |
| Germany | Michael | Guten morgen |
| Sweden  | Bjorn   | Tja          |
| Sweden  | Mats    | Tja          |
| USA     | John    | Hello        |
| USA     | Pete    | Hello        |
+---------+---------+--------------+
IntroducingnullvaluesintotheMAIL_MERGE tableasintheexampleforFIRST_VALUEFunctiononpage514,theresult
setchangeswhenyouusetheIGNORE NULLS clause.
select * from mail_merge;
+---------+---------+--------------+
| name    | country | greeting     |
+---------+---------+--------------+
| Kei     | Japan   | NULL         |
| Boris   | Germany | Guten tag    |
| Li      | China   | NULL         |
| Michael | Germany | Guten morgen |
| Bjorn   | Sweden  | Hej          |
| Peng    | China   | Nihao        |
| Pete    | USA     | Hello        |
| Mats    | Sweden  | Tja          |
| John    | USA     | Hi           |
+---------+---------+--------------+
ApacheImpalaGuide|517ImpalaSQLLanguageReference
select country, name,
  last_value(greeting ignore nulls) over (
    partition by country order by name, greeting
    rows between unbounded preceding and unbounded following
  ) as greeting
  from mail_merge;
+---------+---------+--------------+
| country | name    | greeting     |
+---------+---------+--------------+
| Japan   | Kei     | NULL         |
| Germany | Boris   | Guten morgen |
| Germany | Michael | Guten morgen |
| China   | Li      | Nihao        |
| China   | Peng    | Nihao        |
| Sweden  | Bjorn   | Tja          |
| Sweden  | Mats    | Tja          |
| USA     | John    | Hello        |
| USA     | Pete    | Hello        |
+---------+---------+--------------+
Relatedinformation:
FIRST_VALUEFunction onpage514
LEADFunction
Thisfunctionreturnsthevalueofanexpressionusingcolumnvaluesfromafollowingrow.Youspecifyaninteger
offset,whichdesignatesarowpositionsomenumberofrowsaftertothecurrentrow.Anycolumnreferencesinthe
expressionargumentrefertocolumnvaluesfromthatlaterrow.Typically,thetablecontainsatimesequence or
numericsequence columnthatclearlydistinguishes theorderingoftherows.
Syntax:
LEAD (expr [, offset] [, default])
  OVER ([ partition_by_clause ] order_by_clause )
TheORDER BY clauseisrequired.ThePARTITION BY clauseisoptional.Thewindowclauseisnotallowed.
Usagenotes:
Sometimesusedananalternativetodoingaself-join.
Addedin:CDH5.2.0/Impala2.0.0
Examples:
ThefollowingexampleusesthesamestockdatacreatedinWindowClauseonpage508.Thequeryanalyzestheclosing
priceforastocksymbol,andforeachdayevaluatesiftheclosingpriceforthefollowingdayishigherorlower.
select stock_symbol, closing_date, closing_price,
  case
    (lead(closing_price,1)
      over (partition by stock_symbol order by closing_date)
        - closing_price) > 0
    when true then "higher"
    when false then "flat or lower"
  end as "trending"
from stock_ticker
  order by closing_date;
+--------------+---------------------+---------------+---------------+
| stock_symbol | closing_date        | closing_price | trending      |
+--------------+---------------------+---------------+---------------+
| JDR          | 2014-09-13 00:00:00 | 12.86         | higher        |
| JDR          | 2014-09-14 00:00:00 | 12.89         | higher        |
| JDR          | 2014-09-15 00:00:00 | 12.94         | flat or lower |
| JDR          | 2014-09-16 00:00:00 | 12.55         | higher        |
| JDR          | 2014-09-17 00:00:00 | 14.03         | higher        |
| JDR          | 2014-09-18 00:00:00 | 14.75         | flat or lower |
518|ApacheImpalaGuideImpalaSQLLanguageReference
| JDR          | 2014-09-19 00:00:00 | 13.98         | NULL          |
+--------------+---------------------+---------------+---------------+
Relatedinformation:
ThisfunctionistheconverseofLAGFunction onpage516.
MAXFunction -AnalyticContext
YoucanincludeanOVERclausewithacalltothisfunctiontouseitasananalyticfunction. SeeMAXFunction onpage
490fordetailsandexamples.
MINFunction -AnalyticContext
YoucanincludeanOVERclausewithacalltothisfunctiontouseitasananalyticfunction. SeeMINFunction onpage
493fordetailsandexamples.
NTILEFunction (CDH5.5orhigheronly)
Returnstheâbucketnumberâassociatedwitheachrow,between1andthevalueofanexpression.Forexample,
creating100bucketsputsthelowest1%ofvaluesinthefirstbucket,whilecreating10bucketsputsthelowest10%
ofvaluesinthefirstbucket.Eachpartition canhaveadifferentnumberofbuckets.
Syntax:
NTILE (expr [, offset ...]
  OVER ([ partition_by_clause ] order_by_clause )
TheORDER BY clauseisrequired.ThePARTITION BY clauseisoptional.Thewindowclauseisnotallowed.
Usagenotes:
Theântileânameisderivedfromthepracticeofdividingresultsetsintofourths(quartile), tenths(decile),andsoon.
TheNTILE() functiondividestheresultsetbasedonanarbitrarypercentilevalue.
Thenumberofbucketsmustbeapositiveinteger.
Thenumberofitemsineachbucketisidenticaloralmostso,varyingbyatmost1.Ifthenumberofitemsdoesnot
divideevenlybetweenthebuckets,theremaining NitemsaredividedevenlyamongthefirstNbuckets.
IfthenumberofbucketsNisgreaterthanthenumberofinputrowsinthepartition, thenthefirstNbucketseach
containoneitem,andtheremaining bucketsareempty.
Examples:
Thefollowingexampleshowsdividesgroupsofanimalsinto4bucketsbasedontheirweight.TheORDER BY ...
DESCclauseintheOVER()clausemeansthattheheaviest25%areinthefirstgroup,andthelightest25%areinthe
fourthgroup.(TheORDER BY intheoutermostpartofthequeryshowshowyoucanorderthefinalresultset
independen tlyfromtheorderinwhichtherowsareevaluatedbytheOVER()clause.)Becausethereare9rowsinthe
group,dividedinto4buckets,thefirstbucketreceivestheextraitem.
create table animals (name string, kind string, kilos decimal(9,3));
insert into animals values
  ('Elephant', 'Mammal', 4000), ('Giraffe', 'Mammal', 1200), ('Mouse', 'Mammal', 0.020),
  ('Condor', 'Bird', 15), ('Horse', 'Mammal', 500), ('Owl', 'Bird', 2.5),
  ('Ostrich', 'Bird', 145), ('Polar bear', 'Mammal', 700), ('Housecat', 'Mammal', 5);
select name, ntile(4) over (order by kilos desc) as quarter
  from animals
order by quarter desc;
+------------+---------+
| name       | quarter |
+------------+---------+
| Owl        | 4       |
ApacheImpalaGuide|519ImpalaSQLLanguageReference
| Mouse      | 4       |
| Condor     | 3       |
| Housecat   | 3       |
| Horse      | 2       |
| Ostrich    | 2       |
| Elephant   | 1       |
| Giraffe    | 1       |
| Polar bear | 1       |
+------------+---------+
ThefollowingexamplesshowhowthePARTITION clauseworksfortheNTILE() function. Here,wedivideeachkind
ofanimal(mammal orbird)into2buckets,theheavierhalfandthelighterhalf.
select name, kind, ntile(2) over (partition by kind order by kilos desc) as half
  from animals
order by kind;
+------------+--------+------+
| name       | kind   | half |
+------------+--------+------+
| Ostrich    | Bird   | 1    |
| Condor     | Bird   | 1    |
| Owl        | Bird   | 2    |
| Elephant   | Mammal | 1    |
| Giraffe    | Mammal | 1    |
| Polar bear | Mammal | 1    |
| Horse      | Mammal | 2    |
| Housecat   | Mammal | 2    |
| Mouse      | Mammal | 2    |
+------------+--------+------+
Again,theresultsetcanbeorderedindependen tlyfromtheanalyticevaluation.Thisnextexamplelistsalltheanimals
heaviesttolightest,showingthatelephantandgiraffeareintheâtophalfâofmammals byweight,whilehousecatand
mouseareintheâbottomhalfâ.
select name, kind, ntile(2) over (partition by kind order by kilos desc) as half
  from animals
order by kilos desc;
+------------+--------+------+
| name       | kind   | half |
+------------+--------+------+
| Elephant   | Mammal | 1    |
| Giraffe    | Mammal | 1    |
| Polar bear | Mammal | 1    |
| Horse      | Mammal | 2    |
| Ostrich    | Bird   | 1    |
| Condor     | Bird   | 1    |
| Housecat   | Mammal | 2    |
| Owl        | Bird   | 2    |
| Mouse      | Mammal | 2    |
+------------+--------+------+
PERCENT_RANK Function (CDH5.5orhigheronly)
Syntax:
PERCENT_RANK ( expr)
  OVER ([ partition_by_clause ] order_by_clause )
Calculatestherank,expressedasapercentage,ofeachrowwithinagroupofrows.Ifrankisthevalueforthatsame
rowfromtheRANK()function(from1tothetotalnumberofrowsinthepartitiongroup),thenthePERCENT_RANK()
valueiscalculatedas(rank - 1) / ( rows_in_group  - 1).Ifthereisonlyasingleiteminthepartition group,
itsPERCENT_RANK() valueis0.
TheORDER BY clauseisrequired.ThePARTITION BY clauseisoptional.Thewindowclauseisnotallowed.
Usagenotes:
520|ApacheImpalaGuideImpalaSQLLanguageReference
ThisfunctionissimilartotheRANKandCUME_DIST() functions: itreturnsanascending sequence representingthe
positionofeachrowwithintherowsofthesamepartitiongroup.Theactualnumericsequence iscalculateddifferently,
andthehandlingofduplicate(tied)valuesisdifferent.
Thereturnvaluesrangefrom0to1inclusive.Thefirstrowineachpartitiongroupalwayshasthevalue0.ANULLvalue
isconsideredthelowestpossiblevalue.Inthecaseofduplicateinputvalues,allthecorresponding rowsintheresult
sethaveanidenticalvalue:thelowestPERCENT_RANK() valueofthosetiedrows.(IncontrasttoCUME_DIST() ,
wherealltiedrowshavethehighestCUME_DIST() value.)
Examples:
ThefollowingexampleusesthesameANIMALS tableastheexamplesforCUME_DIST() andNTILE() ,withafew
additional rowstoillustratetheresultswheresomevaluesareNULLorthereisonlyasinglerowinapartition group.
insert into animals values ('Komodo dragon', 'Reptile', 70);
insert into animals values ('Unicorn', 'Mythical', NULL);
insert into animals values ('Fire-breathing dragon', 'Mythical', NULL);
AswithCUME_DIST() ,thereisanascending sequence foreachkindofanimal.Forexample,theâBirdsâandâMammalsâ
rowseachhaveaPERCENT_RANK() sequence thatrangesfrom0to1.TheâReptileârowhasaPERCENT_RANK() of
0becausethatpartition groupcontainsonlyasingleitem.BothâMythicalâanimalshaveaPERCENT_RANK() of0
becauseaNULLisconsideredthelowestvaluewithinitspartition group.
select name, kind, percent_rank() over (partition by kind order by kilos) from animals;
+-----------------------+----------+--------------------------+
| name                  | kind     | percent_rank() OVER(...) |
+-----------------------+----------+--------------------------+
| Mouse                 | Mammal   | 0                        |
| Housecat              | Mammal   | 0.2                      |
| Horse                 | Mammal   | 0.4                      |
| Polar bear            | Mammal   | 0.6                      |
| Giraffe               | Mammal   | 0.8                      |
| Elephant              | Mammal   | 1                        |
| Komodo dragon         | Reptile  | 0                        |
| Owl                   | Bird     | 0                        |
| California Condor     | Bird     | 0.25                     |
| Andean Condor         | Bird     | 0.25                     |
| Condor                | Bird     | 0.25                     |
| Ostrich               | Bird     | 1                        |
| Fire-breathing dragon | Mythical | 0                        |
| Unicorn               | Mythical | 0                        |
+-----------------------+----------+--------------------------+
RANKFunction
Returnsanascending sequence ofintegers,startingwith1.Theoutputsequence producesduplicateintegersfor
duplicatevaluesoftheORDER BY expressions.Aftergeneratingduplicateoutputvaluesfortheâtiedâinputvalues,
thefunctionincrementsthesequence bythenumberoftiedvalues.Therefore,thesequence containsbothduplicates
andgapswhentheinputcontainsduplicates.Startsthesequence overforeachgroupproducedbythePARTITIONED
BYclause.
Syntax:
RANK() OVER([ partition_by_clause ] order_by_clause )
ThePARTITION BY clauseisoptional.TheORDER BY clauseisrequired.Thewindowclauseisnotallowed.
Usagenotes:
Oftenusedfortop-Nandbottom-Nqueries.Forexample,itcouldproduceaâtop10âreportincluding severalitems
thatweretiedfor10thplace.
SimilartoROW_NUMBER andDENSE_RANK .Thesefunctions differinhowtheytreatduplicatecombinationsofvalues.
Addedin:CDH5.2.0/Impala2.0.0
ApacheImpalaGuide|521ImpalaSQLLanguageReference
Examples:
ThefollowingexampledemonstrateshowtheRANK()functionidentifieswhereeachvalueâplacesâintheresultset,
producingthesameresultforduplicatevalues,andskippingvaluesinthesequence toaccountforthenumberof
duplicates.Forexample,whenresultsareorderedbytheXcolumn,both1valuesaretiedforfirst;both2valuesare
tiedforthird;andsoon.
select x, rank() over(order by x) as rank, property from int_t;
+----+------+----------+
| x  | rank | property |
+----+------+----------+
| 1  | 1    | square   |
| 1  | 1    | odd      |
| 2  | 3    | even     |
| 2  | 3    | prime    |
| 3  | 5    | prime    |
| 3  | 5    | odd      |
| 4  | 7    | even     |
| 4  | 7    | square   |
| 5  | 9    | odd      |
| 5  | 9    | prime    |
| 6  | 11   | even     |
| 6  | 11   | perfect  |
| 7  | 13   | lucky    |
| 7  | 13   | lucky    |
| 7  | 13   | lucky    |
| 7  | 13   | odd      |
| 7  | 13   | prime    |
| 8  | 18   | even     |
| 9  | 19   | square   |
| 9  | 19   | odd      |
| 10 | 21   | round    |
| 10 | 21   | even     |
+----+------+----------+
ThefollowingexamplesshowhowtheRANK()functionisaffectedbythePARTITION propertywithintheORDER BY
clause.
Partitioning bythePROPERTY columngroupsalltheeven,odd,andsoonvaluestogether,andRANK()returnsthe
placeofeachvaluewithinthegroup,producingseveralascending sequences.
select x, rank() over(partition by property order by x) as rank, property from int_t;
+----+------+----------+
| x  | rank | property |
+----+------+----------+
| 2  | 1    | even     |
| 4  | 2    | even     |
| 6  | 3    | even     |
| 8  | 4    | even     |
| 10 | 5    | even     |
| 7  | 1    | lucky    |
| 7  | 1    | lucky    |
| 7  | 1    | lucky    |
| 1  | 1    | odd      |
| 3  | 2    | odd      |
| 5  | 3    | odd      |
| 7  | 4    | odd      |
| 9  | 5    | odd      |
| 6  | 1    | perfect  |
| 2  | 1    | prime    |
| 3  | 2    | prime    |
| 5  | 3    | prime    |
| 7  | 4    | prime    |
| 10 | 1    | round    |
| 1  | 1    | square   |
| 4  | 2    | square   |
| 9  | 3    | square   |
+----+------+----------+
522|ApacheImpalaGuideImpalaSQLLanguageReference
Partitioning bytheXcolumngroupsalltheduplicatenumberstogetherandreturnstheplaceeachvaluewithinthe
group;becauseeachvalueoccursonly1or2times,RANK()designateseachXvalueaseitherfirstorsecondwithin
itsgroup.
select x, rank() over(partition by x order by property) as rank, property from int_t;
+----+------+----------+
| x  | rank | property |
+----+------+----------+
| 1  | 1    | odd      |
| 1  | 2    | square   |
| 2  | 1    | even     |
| 2  | 2    | prime    |
| 3  | 1    | odd      |
| 3  | 2    | prime    |
| 4  | 1    | even     |
| 4  | 2    | square   |
| 5  | 1    | odd      |
| 5  | 2    | prime    |
| 6  | 1    | even     |
| 6  | 2    | perfect  |
| 7  | 1    | lucky    |
| 7  | 1    | lucky    |
| 7  | 1    | lucky    |
| 7  | 4    | odd      |
| 7  | 5    | prime    |
| 8  | 1    | even     |
| 9  | 1    | odd      |
| 9  | 2    | square   |
| 10 | 1    | even     |
| 10 | 2    | round    |
+----+------+----------+
Thefollowingexampleshowshowamagazinemightpreparealistofhistory'swealthiestpeople.CroesusandMidas
aretiedforsecond,thenCrassusisfourth.
select rank() over (order by net_worth desc) as rank, name, net_worth from wealth order
 by rank, name;
+------+---------+---------------+
| rank | name    | net_worth     |
+------+---------+---------------+
| 1    | Solomon | 2000000000.00 |
| 2    | Croesus | 1000000000.00 |
| 2    | Midas   | 1000000000.00 |
| 4    | Crassus | 500000000.00  |
| 5    | Scrooge | 80000000.00   |
+------+---------+---------------+
Relatedinformation:
DENSE_RANK Function onpage512,ROW_NUMBER Function onpage523
ROW_NUMBER Function
Returnsanascending sequence ofintegers,startingwith1.Startsthesequence overforeachgroupproducedbythe
PARTITIONED BY clause.Theoutputsequence includesdifferentvaluesforduplicateinputvalues.Therefore,the
sequence nevercontainsanyduplicatesorgaps,regardlessofduplicateinputvalues.
Syntax:
ROW_NUMBER() OVER([ partition_by_clause ] order_by_clause )
TheORDER BY clauseisrequired.ThePARTITION BY clauseisoptional.Thewindowclauseisnotallowed.
Usagenotes:
Oftenusedfortop-Nandbottom-Nquerieswheretheinputvaluesareknowntobeunique,orpreciselyNrowsare
neededregardlessofduplicatevalues.
ApacheImpalaGuide|523ImpalaSQLLanguageReference
Becauseitsresultvalueisdifferentforeachrowintheresultset(whenusedwithoutaPARTITION BY clause),
ROW_NUMBER() canbeusedtosynthesizeuniquenumericIDvalues,forexampleforresultsetsinvolvinguniquevalues
ortuples.
SimilartoRANKandDENSE_RANK .Thesefunctions differinhowtheytreatduplicatecombinationsofvalues.
Addedin:CDH5.2.0/Impala2.0.0
Examples:
ThefollowingexampledemonstrateshowROW_NUMBER() producesacontinuousnumericsequence, eventhough
somevaluesofXarerepeated.
select x, row_number() over(order by x, property) as row_number, property from int_t;
+----+------------+----------+
| x  | row_number | property |
+----+------------+----------+
| 1  | 1          | odd      |
| 1  | 2          | square   |
| 2  | 3          | even     |
| 2  | 4          | prime    |
| 3  | 5          | odd      |
| 3  | 6          | prime    |
| 4  | 7          | even     |
| 4  | 8          | square   |
| 5  | 9          | odd      |
| 5  | 10         | prime    |
| 6  | 11         | even     |
| 6  | 12         | perfect  |
| 7  | 13         | lucky    |
| 7  | 14         | lucky    |
| 7  | 15         | lucky    |
| 7  | 16         | odd      |
| 7  | 17         | prime    |
| 8  | 18         | even     |
| 9  | 19         | odd      |
| 9  | 20         | square   |
| 10 | 21         | even     |
| 10 | 22         | round    |
+----+------------+----------+
ThefollowingexampleshowshowafinancialinstitutionmightassigncustomerIDstosomeofhistory'swealthiest
figures.Although twoofthepeoplehaveidenticalnetworthfigures,uniqueIDsarerequiredforthispurpose.
ROW_NUMBER() producesasequence offivedifferentvaluesforthefiveinputrows.
select row_number() over (order by net_worth desc) as account_id, name, net_worth
  from wealth order by account_id, name;
+------------+---------+---------------+
| account_id | name    | net_worth     |
+------------+---------+---------------+
| 1          | Solomon | 2000000000.00 |
| 2          | Croesus | 1000000000.00 |
| 3          | Midas   | 1000000000.00 |
| 4          | Crassus | 500000000.00  |
| 5          | Scrooge | 80000000.00   |
+------------+---------+---------------+
Relatedinformation:
RANKFunction onpage521,DENSE_RANK Function onpage512
SUMFunction -AnalyticContext
YoucanincludeanOVERclausewithacalltothisfunctiontouseitasananalyticfunction. SeeSUMFunction onpage
501fordetailsandexamples.
524|ApacheImpalaGuideImpalaSQLLanguageReference
User-DefinedFunctions (UDFs)
User-definedfunctions (frequentlyabbreviatedasUDFs)letyoucodeyourownapplicationlogicforprocessingcolumn
valuesduringanImpalaquery.Forexample,aUDFcouldperformcalculationsusinganexternalmathlibrary,combine
severalcolumnvaluesintoone,dogeospatialcalculations,orotherkindsoftestsandtransformationsthatareoutside
thescopeofthebuilt-inSQLoperatorsandfunctions.
YoucanuseUDFstosimplifyquerylogicwhenproducingreports,ortotransformdatainflexiblewayswhencopying
fromonetabletoanotherwiththeINSERT ... SELECT syntax.
Youmightbefamiliarwiththisfeaturefromotherdatabaseproducts,undernamessuchasstoredfunctions orstored
routines.
ImpalasupportforUDFsisavailableinImpala1.2andhigher:
â¢InImpala1.1,usingUDFsinaqueryrequiredusingtheHiveshell.(BecauseImpalaandHivesharethesame
metastoredatabase,youcouldswitchtoHivetorunjustthosequeriesrequiringUDFs,thenswitchbacktoImpala.)
â¢StartinginImpala1.2,Impalacanrunbothhigh-performance nativecodeUDFswritteninC++,andJava-based
HiveUDFsthatyoumightalreadyhavewritten.
â¢ImpalacanrunscalarUDFsthatreturnasinglevalueforeachrowoftheresultset,anduser-definedaggregate
functions (UDAFs)thatreturnavaluebasedonasetofrows.Currently,Impaladoesnotsupportuser-defined
tablefunctions (UDTFs)orwindowfunctions.
UDFConcepts
Depending onyourusecase,youmightwriteall-newfunctions, reuseJavaUDFsthatyouhavealreadywrittenfor
Hive,orportHiveJavaUDFcodetohigher-perf ormance nativeImpalaUDFsinC++.Youcancodeeitherscalarfunctions
forproducingresultsonerowatatime,ormorecomplexaggregatefunctions fordoinganalysisacross.Thefollowing
sectionsdiscussthesedifferentaspectsofworkingwithUDFs.
UDFsandUDAFs
Depending onyourusecase,theuser-definedfunctions (UDFs)youwritemightacceptorproducedifferentnumbers
ofinputandoutputvalues:
â¢Themostgeneralkindofuser-definedfunction(theonetypicallyreferredtobytheabbreviationUDF)takesa
singleinputvalueandproducesasingleoutputvalue.Whenusedinaquery,itiscalledonceforeachrowinthe
resultset.Forexample:
select customer_name, is_frequent_customer(customer_id) from customers;
select obfuscate(sensitive_column) from sensitive_data;
â¢Auser-definedaggregatefunction(UDAF)acceptsagroupofvaluesandreturnsasinglevalue.YouuseUDAFsto
summariz eandcondensesetsofrows,inthesamestyleasthebuilt-inCOUNT,MAX(),SUM(),andAVG()functions.
WhencalledinaquerythatusestheGROUP BY clause,thefunctioniscalledonceforeachcombinationofGROUP
BYvalues.Forexample:
-- Evaluates multiple rows but returns a single value.
select closest_restaurant(latitude, longitude) from places;
-- Evaluates batches of rows and returns a separate value for each batch.
select most_profitable_location(store_id, sales, expenses, tax_rate, depreciation) from
 franchise_data group by year;
â¢Currently,Impaladoesnotsupportothercategoriesofuser-definedfunctions, suchasuser-definedtablefunctions
(UDTFs)orwindowfunctions.
ApacheImpalaGuide|525ImpalaSQLLanguageReference
NativeImpalaUDFs
ImpalasupportsUDFswritteninC++,inadditiontosupporting existingHiveUDFswritteninJava.Clouderarecommends
usingC++UDFsbecausethecompilednativecodecanyieldhigherperformance, withUDFexecutiontimeoften10x
fasterforaC++UDFthantheequivalentJavaUDF.
UsingHiveUDFswithImpala
ImpalacanrunJava-baseduser-definedfunctions (UDFs),originally writtenforHive,withnochanges,subjecttothe
followingconditions:
â¢TheparametersandreturnvaluemustallusescalardatatypessupportedbyImpala.Forexample,complexor
nestedtypesarenotsupported.
â¢Hive/JavaUDFsmustextendorg.apache.hadoop.hive.ql.exec.UDF class.
â¢Currently,HiveUDFsthatacceptorreturntheTIMESTAMP typearenotsupported.
â¢PriortoCDH5.7/Impala2.5thereturntypemustbeaâWritableâtypesuchasTextorIntWritable ,rather
thanaJavaprimitivetypesuchasStringorint.Otherwise,theUDFreturnsNULL.InCDH5.7/Impala2.5and
higher,thisrestrictionislifted,andbothUDFargumentsandreturnvaluescanbeJavaprimitivetypes.
â¢HiveUDAFsandUDTFsarenotsupported.
â¢Typically,aJavaUDFwillexecuteseveraltimesslowerinImpalathantheequivalentnativeUDFwritteninC++.
â¢InCDH5.7/Impala2.5andhigher,youcantransparentlycallHiveJavaUDFsthroughImpala,orcallImpalaJava
UDFsthroughHive.Thisfeaturedoesnotapplytobuilt-inHivefunctions. AnyImpalaJavaUDFscreatedwitholder
versionsmustbere-createdusingnewCREATE FUNCTION syntax,withoutanysignatureforargumentsorthe
returnvalue.
TotakefulladvantageoftheImpalaarchitectureandperformance features,youcanalsowriteImpala-specific UDFs
inC++.
ForbackgroundaboutJava-basedHiveUDFs,seetheHivedocumen tationforUDFs.Forexamplesortutorialsforwriting
suchUDFs,searchthewebforrelatedblogposts.
TheidealwaytounderstandhowtoreuseJava-basedUDFs(originally writtenforHive)withImpalaistotakesomeof
theHivebuilt-infunctions (implemen tedasJavaUDFs)andtaketheapplicableJARfilesthroughtheUDFdeployment
processforImpala,creatingnewUDFswithdifferentnames:
1.TakeacopyoftheHiveJARfilecontainingtheHivebuilt-infunctions. Forexample,thepathmightbelike
/usr/lib/hive/lib/hive-exec-0.10.0-cdh4.2.0.jar ,withdifferentversionnumberscorresponding to
yourspecificlevelofCDH.
2.Usejar tf jar_file toseealistoftheclassesinsidetheJAR.Youwillseenameslike
org/apache/hadoop/hive/ql/udf/UDFLower.class and
org/apache/hadoop/hive/ql/udf/UDFOPNegative.class .Makeanoteofthenamesofthefunctions you
wanttoexperimen twith.WhenyouspecifytheentrypointsfortheImpalaCREATE FUNCTION statement,change
theslashcharacterstodotsandstripoffthe.classsuffix,forexample
org.apache.hadoop.hive.ql.udf.UDFLower andorg.apache.hadoop.hive.ql.udf.UDFOPNegative .
3.CopythatfiletoanHDFSlocationthatImpalacanread.(Intheexampleshere,werenamedthefileto
hive-builtins.jar inHDFSforsimplicity .)
4.ForeachJava-basedUDFthatyouwanttocallthroughImpala,issueaCREATE FUNCTION statement,witha
LOCATION clausecontainingthefullHDFSpathoftheJARfile,andaSYMBOLclausewiththefullyqualified name
oftheclass,usingdotsasseparatorsandwithoutthe.classextension.Remember thatuser-definedfunctions
areassociatedwithaparticular database,soissueaUSEstatementfortheappropriatedatabasefirst,orspecify
theSQLfunctionnameasdb_name.function_name .UsecompletelynewnamesfortheSQLfunctions, because
ImpalaUDFscannothavethesamenameasImpalabuilt-infunctions.
5.Callthefunctionfromyourqueries,passingargumentsofthecorrecttypetomatchthefunctionsignature.These
argumentscouldbereferencestocolumns,arithmeticorotherkindsofexpressions,theresultsofCASTfunctions
toensurecorrectdatatypes,andsoon.
526|ApacheImpalaGuideImpalaSQLLanguageReference
Note:
InCDH5.12/Impala2.9andhigher,youcanrefreshtheuser-definedfunctions (UDFs)thatImpala
recognizes,atthedatabaselevel,byrunningtheREFRESH FUNCTIONS statementwiththedatabase
nameasanargument.Java-basedUDFscanbeaddedtothemetastoredatabasethroughHiveCREATE
FUNCTION statements,andmadevisibletoImpalabysubsequentlyrunningREFRESH FUNCTIONS .
Forexample:
CREATE DATABASE shared_udfs;
USE shared_udfs;
...use CREATE FUNCTION statements in Hive to create some Java-based UDFs
   that Impala is not initially aware of...
REFRESH FUNCTIONS shared_udfs;
SELECT udf_created_by_hive(c1) FROM ...
JavaUDFExample:Reusinglower()Function
Forexample,thefollowingimpala-shell sessioncreatesanImpalaUDFmy_lower() thatreusestheJavacodefor
theHivelower() :built-infunction. Wecannotcallitlower() becauseImpaladoesnotallowUDFstohavethesame
nameasbuilt-infunctions. FromSQL,wecallthefunctioninabasicway(inaquerywithnoWHEREclause),directlyon
acolumn,andontheresultsofastringexpression:
[localhost:21000] > create database udfs;
[localhost:21000] > use udfs;
localhost:21000] > create function lower(string) returns string location 
'/user/hive/udfs/hive.jar' symbol='org.apache.hadoop.hive.ql.udf.UDFLower';
ERROR: AnalysisException: Function cannot have the same name as a builtin: lower
[localhost:21000] > create function my_lower(string) returns string location 
'/user/hive/udfs/hive.jar' symbol='org.apache.hadoop.hive.ql.udf.UDFLower';
[localhost:21000] > select my_lower('Some String NOT ALREADY LOWERCASE');
+----------------------------------------------------+
| udfs.my_lower('some string not already lowercase') |
+----------------------------------------------------+
| some string not already lowercase                  |
+----------------------------------------------------+
Returned 1 row(s) in 0.11s
[localhost:21000] > create table t2 (s string);
[localhost:21000] > insert into t2 values ('lower'),('UPPER'),('Init cap'),('CamelCase');
Inserted 4 rows in 2.28s
[localhost:21000] > select * from t2;
+-----------+
| s         |
+-----------+
| lower     |
| UPPER     |
| Init cap  |
| CamelCase |
+-----------+
Returned 4 row(s) in 0.47s
[localhost:21000] > select my_lower(s) from t2;
+------------------+
| udfs.my_lower(s) |
+------------------+
| lower            |
| upper            |
| init cap         |
| camelcase        |
+------------------+
Returned 4 row(s) in 0.54s
[localhost:21000] > select my_lower(concat('ABC ',s,' XYZ')) from t2;
+------------------------------------------+
| udfs.my_lower(concat('abc ', s, ' xyz')) |
+------------------------------------------+
| abc lower xyz                            |
| abc upper xyz                            |
| abc init cap xyz                         |
ApacheImpalaGuide|527ImpalaSQLLanguageReference
| abc camelcase xyz                        |
+------------------------------------------+
Returned 4 row(s) in 0.22s
JavaUDFExample:Reusingnegative()Function
HereisanexamplethatreusestheHiveJavacodeforthenegative() built-infunction. Thisexampledemonstrates
howthedatatypesoftheargumentsmustmatchpreciselywiththefunctionsignature.Atfirst,wecreateanImpala
SQLfunctionthatcanonlyacceptanintegerargument.Impalacannotfindamatchingfunctionwhenthequerypasses
afloating-pointargument,although wecancalltheintegerversionofthefunctionbycastingtheargument.Thenwe
overloadthesamefunctionnametoalsoacceptafloating-pointargument.
[localhost:21000] > create table t (x int);
[localhost:21000] > insert into t values (1), (2), (4), (100);
Inserted 4 rows in 1.43s
[localhost:21000] > create function my_neg(bigint) returns bigint location 
'/user/hive/udfs/hive.jar' symbol='org.apache.hadoop.hive.ql.udf.UDFOPNegative';
[localhost:21000] > select my_neg(4);
+----------------+
| udfs.my_neg(4) |
+----------------+
| -4             |
+----------------+
[localhost:21000] > select my_neg(x) from t;
+----------------+
| udfs.my_neg(x) |
+----------------+
| -2             |
| -4             |
| -100           |
+----------------+
Returned 3 row(s) in 0.60s
[localhost:21000] > select my_neg(4.0);
ERROR: AnalysisException: No matching function with signature: udfs.my_neg(FLOAT).
[localhost:21000] > select my_neg(cast(4.0 as int));
+-------------------------------+
| udfs.my_neg(cast(4.0 as int)) |
+-------------------------------+
| -4                            |
+-------------------------------+
Returned 1 row(s) in 0.11s
[localhost:21000] > create function my_neg(double) returns double location 
'/user/hive/udfs/hive.jar' symbol='org.apache.hadoop.hive.ql.udf.UDFOPNegative';
[localhost:21000] > select my_neg(4.0);
+------------------+
| udfs.my_neg(4.0) |
+------------------+
| -4               |
+------------------+
Returned 1 row(s) in 0.11s
YoucanfindthesamplefilesmentionedhereintheImpalagithubrepo.
RuntimeEnvironmentforUDFs
Bydefault,ImpalacopiesUDFsinto/tmp,andyoucanconfigurethislocationthroughthe--local_library_dir
startupflagfortheimpalad daemon.
InstallingtheUDFDevelopmentPackage
TodevelopUDFsforImpala,downloadandinstalltheimpala-udf-devel package(RHEL-based distributions) or
impala-udf-dev (UbuntuandDebian).Thispackagecontainsheaderfiles,samplesource,andbuildconfiguration
files.
1.Startat:
â¢https://archive.clouder a.com/cdh5/forCDH5
â¢https://archive.clouder a.com/cdh6/forCDH6
528|ApacheImpalaGuideImpalaSQLLanguageReference
2.Locatetheappropriate.repoorlistfileforyouroperatingsystemversion,suchasthe.repofileforCDH5on
RHEL7.
3.Usetheyum,zypper,orapt-get commands depending onyouroperatingsystem.Forthepackagename,specify
impala-udf-devel (RHEL-based distributions) orimpala-udf-dev (UbuntuandDebian).
Note:TheUDFdevelopmentcodedoesnotrelyonImpalabeinginstalledonthesamemachine. You
canwriteandcompileUDFsonaminimaldevelopmentsystem,thendeploythemonadifferentone
forusewithImpala.IfyoudevelopUDFsonaservermanagedbyClouderaManagerthroughthe
parcelmechanism, youstillinstalltheUDFdevelopmentkitthroughthepackagemechanism; this
smallstandalone packagedoesnotinterferewiththeparcelscontainingthemainImpalacode.
WhenyouarereadytostartwritingyourownUDFs,downloadthesamplecodeandbuildscriptsfromtheCloudera
sampleUDFgithub.ThenseeWritingUser-DefinedFunctions (UDFs)onpage529forhowtocodeUDFs,andExamples
ofCreatingandUsingUDFsonpage535forhowtobuildandrunUDFs.
WritingUser-DefinedFunctions (UDFs)
BeforestartingUDFdevelopment,makesuretoinstallthedevelopmentpackageanddownloadtheUDFcodesamples,
asdescribed inInstallingtheUDFDevelopmentPackageonpage528.
WhenwritingUDFs:
â¢Keepinmindthedatatypedifferencesasyoutransfervaluesfromthehigh-levelSQLtoyourlower-levelUDF
code.Forexample,intheUDFcodeyoumightbemuchmoreawareofhowmanybytesdifferentkindsofintegers
require.
â¢Usebestpracticesforfunction-orien tedprogramming: chooseargumentscarefully,avoidsideeffects,makeeach
functiondoasinglething,andsoon.
GettingStartedwithUDFCoding
Tounderstandthelayoutandmembervariablesandfunctions ofthepredefinedUDFdatatypes,examinetheheader
file/usr/include/impala_udf/udf.h :
// This is the only Impala header required to develop UDFs and UDAs. This header
// contains the types that need to be used and the FunctionContext object. The context
// object serves as the interface object between the UDF/UDA and the impala process. 
ForthebasicdeclarationsneededtowriteascalarUDF,seetheheaderfileudf-sample.h withinthesamplebuild
environment,whichdefinesasimplefunctionnamedAddUdf() :
#ifndef IMPALA_UDF_SAMPLE_UDF_H
#define IMPALA_UDF_SAMPLE_UDF_H
#include <impala_udf/udf.h>
using namespace impala_udf;
IntVal AddUdf(FunctionContext* context, const IntVal& arg1, const IntVal& arg2);
#endif
ForsampleC++codeforasimplefunctionnamedAddUdf() ,seethesourcefileudf-sample.cc withinthesample
buildenvironment:
#include "udf-sample.h"
// In this sample we are declaring a UDF that adds two ints and returns an int.
IntVal AddUdf(FunctionContext* context, const IntVal& arg1, const IntVal& arg2) {
  if (arg1.is_null || arg2.is_null) return IntVal::null();
  return IntVal(arg1.val + arg2.val);
}
ApacheImpalaGuide|529ImpalaSQLLanguageReference
// Multiple UDFs can be defined in the same file
DataTypesforFunction ArgumentsandReturnValues
Eachvaluethatauser-definedfunctioncanacceptasanargumentorreturnasaresultvaluemustmaptoaSQLdata
typethatyoucouldspecifyforatablecolumn.
Currently,ImpalaUDFscannotacceptargumentsorreturnvaluesoftheImpalacomplextypes(STRUCT,ARRAY,or
MAP).
Eachdatatypehasacorresponding structuredefinedintheC++andJavaheaderfiles,withtwomemberfieldsand
somepredefinedcomparison operatorsandconstructors:
â¢is_null indicateswhetherthevalueisNULLornot.valholdstheactualargumentorreturnvaluewhenitis
non-NULL.
â¢Eachstructalsodefinesanull()memberfunctionthatconstructsaninstanceofthestructwiththeis_null
flagset.
â¢Thebuilt-inSQLcomparison operatorsandclausessuchas<,>=,BETWEEN ,andORDER BY allworkautomatically
basedontheSQLreturntypeofeachUDF.Forexample,ImpalaknowshowtoevaluateBETWEEN 1 AND
udf_returning_int(col1) orORDER BY udf_returning_string(col2) withoutyoudeclaring any
comparison operatorswithintheUDFitself.
ForconveniencewithinyourUDFcode,eachstructdefines==and!=operatorsforcomparisons withotherstructs
ofthesametype.ThesearefortypicalC++comparisons withinyourowncode,notnecessarily reproducingSQL
semantics.Forexample,iftheis_null flagissetinbothstructs,theycompareasequal.Thatbehaviorofnull
comparisons isdifferentfromSQL(whereNULL == NULL isNULLratherthantrue),butmoreinlinewithtypical
C++behavior.
â¢Eachkindofstructhasoneormoreconstructorsthatdefineafilled-ininstanceofthestruct,optionallywith
defaultvalues.
â¢ImpalacannotprocessUDFsthatacceptthecompositeornestedtypesasargumentsorreturnthemasresult
values.ThislimitationappliesbothtoImpalaUDFswritteninC++andJava-basedHiveUDFs.
â¢Youcanoverloadfunctions bycreatingmultiplefunctions withthesameSQLnamebutdifferentargumenttypes.
Foroverloaded functions, youmustusedifferentC++orJavaentrypointnamesintheunderlying functions.
ThedatatypesdefinedontheC++side(in/usr/include/impala_udf/udf.h )are:
â¢IntValrepresentsanINTcolumn.
â¢BigIntVal representsaBIGINTcolumn.EvenifyoudonotneedthefullrangeofaBIGINTvalue,itcanbe
usefultocodeyourfunctionargumentsasBigIntVal tomakeitconvenienttocallthefunctionwithdifferent
kindsofintegercolumnsandexpressionsasarguments.Impalaautomaticallycastssmallerintegertypestolarger
oneswhenappropriate,butdoesnotimplicitly castlargeintegertypestosmallerones.
â¢SmallIntVal representsaSMALLINT column.
â¢TinyIntVal representsaTINYINT column.
â¢StringVal representsaSTRINGcolumn.Ithasalenfieldrepresentingthelengthofthestring,andaptrfield
pointingtothestringdata.IthasconstructorsthatcreateanewStringVal structbasedonanull-terminated
C-stylestring,orapointerplusalength;thesenewstructsstillrefertotheoriginalstringdataratherthanallocating
anewbufferforthedata.ItalsohasaconstructorthattakesapointertoaFunctionContext structandalength,
thatdoesallocatespaceforanewcopyofthestringdata,foruseinUDFsthatreturnstringvalues.
â¢BooleanVal representsaBOOLEAN column.
â¢FloatVal representsaFLOATcolumn.
530|ApacheImpalaGuideImpalaSQLLanguageReference
â¢DoubleVal representsaDOUBLEcolumn.
â¢TimestampVal representsaTIMESTAMP column.Ithasadatefield,a32-bitintegerrepresentingtheGregorian
date,thatis,thedayspasttheepochdate.Italsohasatime_of_day field,a64-bitintegerrepresentingthe
currenttimeofdayinnanoseconds.
Variable-Leng thArgumentLists
UDFstypicallytakeafixednumberofarguments,witheachonenamedexplicitlyinthesignatureofyourC++function.
Yourfunctioncanalsoacceptadditional optionalarguments,allofthesametype.Forexample,youcanconcatenate
twostrings,threestrings,fourstrings,andsoon.Oryoucancomparetwonumbers,threenumbers,fournumbers,
andsoon.
Toacceptavariable-leng thargumentlist,codethesignatureofyourfunctionlikethis:
StringVal Concat(FunctionContext* context, const StringVal& separator,
  int num_var_args, const StringVal* args);
IntheCREATE FUNCTION statement,afterthetypeofthefirstoptionalargument,include...toindicateitcouldbe
followedbymoreargumentsofthesametype.Forexample,thefollowingfunctionacceptsaSTRINGargument,
followedbyoneormoreadditional STRINGarguments:
[localhost:21000] > create function my_concat(string, string ...) returns string location
 '/user/test_user/udfs/sample.so' symbol='Concat';
ThecallfromtheSQLquerymustpassatleastoneargumenttothevariable-leng thportionoftheargumentlist.
WhenImpalacallsthefunction,itfillsintheinitialsetofrequiredarguments,thenpassesthenumberofextraarguments
andapointertothefirstofthoseoptionalarguments.
Handling NULLValues
Forcorrectness,performance, andreliability,itisimportantforeachUDFtohandleallsituationswhereanyNULL
valuesarepassedtoyourfunction. Forexample,whenpassedaNULL,UDFstypicallyalsoreturnNULL.Inanaggregate
function, whichcouldbepassedacombinationofrealandNULLvalues,youmightmakethefinalvalueintoaNULL
(asinCONCAT() ),ignoretheNULLvalue(asinAVG()),ortreatitthesameasanumericzerooremptystring.
Eachparametertype,suchasIntValorStringVal ,hasanis_null Booleanmember.Testthisflagimmediately
foreachargumenttoyourfunction, andifitisset,donotrefertothevalfieldoftheargumentstructure.Theval
fieldisundefinedwhentheargumentisNULL,soyourfunctioncouldgointoaninfinitelooporproduceincorrect
resultsifyouskipthespecialhandlingforNULL.
IfyourfunctionreturnsNULLwhenpassedaNULLvalue,orinothercasessuchaswhenasearchstringisnotfound,
youcanconstructanullinstanceofthereturntypebyusingitsnull()memberfunction.
MemoryAllocationforUDFs
Bydefault,memoryallocatedwithinaUDFisdeallocatedwhenthefunctionexits,whichcouldbebeforethequeryis
finished.Theinputargumentsremainallocatedforthelifetimeofthefunction, soyoucanrefertotheminthe
expressionsforyourreturnvalues.Ifyouusetemporaryvariablestoconstructall-newstringvalues,usethe
StringVal() constructorthattakesaninitialFunctionContext* argumentfollowedbyalength,andcopythedata
intothenewlyallocatedmemorybuffer.
Thread-SafeWorkAreaforUDFs
Onewaytoimproveperformance ofUDFsistospecifytheoptionalPREPARE_FN andCLOSE_FN clausesontheCREATE
FUNCTION statement.Theâprepareâfunctionsetsupathread-safedatastructureinmemorythatyoucanuseasa
workarea.Theâcloseâfunctiondeallocatesthatmemory.EachsubsequentcalltotheUDFwithinthesamethreadcan
accessthatsamememoryarea.Theremightbeseveralsuchmemoryareasallocatedonthesamehost,asUDFsare
parallelizedusingmultiplethreads.
ApacheImpalaGuide|531ImpalaSQLLanguageReference
Withinthisworkarea,youcansetuppredefinedlookuptables,orrecordtheresultsofcomplexoperationsondata
typessuchasSTRINGorTIMESTAMP .Savingtheresultsofpreviouscomputationsratherthanrepeatingthecomputation
eachtimeisanoptimizationknownashttp://en.wikipedia.or g/wiki/Memoiz ation.Forexample,ifyourUDFperforms
aregularexpressionmatchordatemanipula tiononacolumnthatrepeatsthesamevalueoverandover,youcould
storethelast-computedvalueorahashtableofalready-computedvalues,anddoafastlookuptofindtheresultfor
subsequentiterationsoftheUDF.
Eachsuchfunctionmusthavethesignature:
void function_name (impala_udf::FunctionContext*, 
impala_udf::FunctionContext::FunctionScope)
Currently,onlyTHREAD_SCOPE isimplemen ted,notFRAGMENT_SCOPE .Seeudf.hfordetailsaboutthescopevalues.
ErrorHandling forUDFs
TohandleerrorsinUDFs,youcallfunctions thataremembersoftheinitialFunctionContext* argumentpassedto
yourfunction.
AUDFcanrecordoneormorewarnings,forconditions thatindicateminor,recoverableproblemsthatdonotcause
thequerytostop.Thesignatureforthisfunctionis:
bool AddWarning(const char* warning_msg);
Foraseriousproblemthatrequirescancelling thequery,aUDFcansetanerrorflagthatpreventsthequeryfrom
returninganyresults.Thesignatureforthisfunctionis:
void SetError(const char* error_msg);
WritingUser-DefinedAggregateFunctions (UDAFs)
User-definedaggregatefunctions (UDAFsorUDAs)areapowerfulandflexiblecategoryofuser-definedfunctions. If
aqueryprocessesNrows,callingaUDAFduringthequerycondenses theresultset,anywherefromasinglevalue
(suchaswiththeSUMorMAXfunctions), orsomenumberlessthanorequaltoN(asinqueriesusingtheGROUP BY or
HAVINGclause).
TheUnderlying Functions foraUDA
AUDAFmustmaintainastatevalueacrosssubsequentcalls,sothatitcanaccumula tearesultacrossasetofcalls,
ratherthanderiveitpurelyfromonesetofarguments.Forthatreason,aUDAFisrepresentedbymultipleunderlying
functions:
â¢Aninitializationfunctionthatsetsanycounterstozero,createsemptybuffers,anddoesanyotherone-time setup
foraquery.
â¢Anupdatefunctionthatprocessestheargumentsforeachrowinthequeryresultsetandaccumula tesan
intermediateresultforeachnode.Forexample,thisfunctionmightincrementacounter,appendtoastringbuffer,
orsetflags.
â¢Amergefunctionthatcombinestheintermediateresultsfromtwodifferentnodes.
â¢Aserializefunctionthatflattensanyintermediatevaluescontainingpointers,andfreesanymemoryallocated
duringtheinit,update,andmergephases.
â¢Afinalizefunctionthateitherpassesthroughthecombined resultunchanged,ordoesonefinaltransformation.
IntheSQLsyntax,youcreateaUDAFbyusingthestatementCREATE AGGREGATE FUNCTION .Youspecifytheentry
pointsoftheunderlying C++functions usingtheclausesINIT_FN ,UPDATE_FN ,MERGE_FN ,SERIALIZE_FN ,and
FINALIZE_FN .
Forconvenience,youcanuseanamingconventionfortheunderlying functions andImpalaautomaticallyrecognizes
thoseentrypoints.SpecifytheUPDATE_FN clause,usinganentrypointnamecontainingthestringupdateorUpdate.
Whenyouomittheother_FNclausesfromtheSQLstatement,Impalalooksforentrypointswithnamesformedby
substitutingtheupdateorUpdateportionofthespecified name.
532|ApacheImpalaGuideImpalaSQLLanguageReference
uda-sample.h :
Seethisfileonlineat:uda-sample.h
uda-sample.cc :
Seethisfileonlineat:uda-sample.cc
IntermediateResultsforUDAs
Auser-definedaggregatefunctionmightproduceandcombineintermediateresultsduringsomephasesofprocessing,
usingadifferentdatatypethanthefinalreturnvalue.Forexample,ifyouimplemen tafunctionsimilartothebuilt-in
AVG()function, itmustkeeptrackoftwovalues,thenumberofvaluescountedandthesumofthosevalues.Or,you
mightaccumula teastringvalueoverthecourseofaUDA,thenintheendreturnanumericorBooleanresult.
Insuchacase,specifythedatatypeoftheintermediateresultsusingtheoptionalINTERMEDIATE type_name clause
oftheCREATE AGGREGATE FUNCTION statement.Iftheintermediatedataisatypelessbytearray(forexample,to
representaC++structorarray),specifythetypenameasCHAR(n),withnrepresentingthenumberofbytesinthe
intermediateresultbuffer.
Foranexampleofthistechnique, seethetrunc_sum() aggregatefunction, whichaccumula tesintermediateresults
oftypeDOUBLEandreturnsBIGINTattheend.ViewtheappropriateCREATE FUNCTION statementandthe
implemen tationoftheunderlying TruncSum*() functions onGithub.
BuildingandDeployingUDFs
ThissectionexplainsthestepstocompileImpalaUDFsfromC++sourcecode,anddeploytheresultinglibrariesfor
useinImpalaqueries.
ImpalaUDFdevelopmentpackageshipswithasamplebuildenvironmentforUDFs,thatyoucanstudy,experimen t
with,andadaptforyourownuse.
Tobuildthesampleenvironment:
1.InstalltheImpalaUDFdevelopmentpackageasdescribed inInstallingtheUDFDevelopmentPackageonpage528
2.Runthefollowingcommands:
cmake .
make
Thecmakeconfigurationcommand readsthefileCMakeLists.txt andgeneratesaMakefile customizedforyour
particular directorypaths.Thenthemakecommand runstheactualbuildstepsbasedontherulesintheMakefile .
ImpalaloadsthesharedlibraryfromanHDFSlocation.AfterbuildingasharedlibrarycontainingoneormoreUDFs,
usehdfs dfs orhadoop fs commands tocopythebinaryfiletoanHDFSlocationreadablebyImpala.
ThefinalstepindeploymentistoissueaCREATE FUNCTION statementintheimpala-shell interpretertomake
Impalaawareofthenewfunction. SeeCREATEFUNCTIONStatementonpage228forsyntaxdetails.Becauseeach
functionisassociatedwithaparticular database,alwaysissueaUSEstatementtotheappropriatedatabasebefore
creatingafunction, orspecifyafullyqualified name,thatis,CREATE FUNCTION db_name.function_name .
AsyouupdatetheUDFcodeandredeployupdatedversionsofasharedlibrary,useDROP FUNCTION andCREATE
FUNCTION toletImpalapickupthelatestversionofthecode.
ApacheImpalaGuide|533ImpalaSQLLanguageReference
Note:
InCDH5.7/Impala2.5andhigher,ImpalaUDFsandUDAswritteninC++arepersistedinthemetastore
database.JavaUDFsarealsopersisted,iftheywerecreatedwiththenewCREATE FUNCTION syntax
forJavaUDFs,wheretheJavafunctionargumentandreturntypesareomitted.Java-basedUDFs
createdwiththeoldCREATE FUNCTION syntaxdonotpersistacrossrestartsbecausetheyareheld
inthememoryofthecatalogd daemon. Untilyoure-createsuchJavaUDFsusingthenewCREATE
FUNCTION syntax,youmustreloadthoseJava-basedUDFsbyrunningtheoriginalCREATE FUNCTION
statementsagaineachtimeyourestartthecatalogd daemon. PriortoCDH5.7/Impala2.5the
requirementtoreloadfunctions afterarestartappliedtobothC++andJavafunctions.
SeeCREATEFUNCTIONStatementonpage228andDROPFUNCTIONStatementonpage263forthe
newsyntaxforthepersistentJavaUDFs.
Prerequisitesforthebuildenvironmentare:
1.Installthepackagesusingtheappropriatepackageinstallationcommand foryourLinuxdistribution.
sudo yum install gcc-c++ cmake boost-devel
sudo yum install impala-udf-devel
# The package name on Ubuntu and Debian is impala-udf-dev.
2.DownloadtheUDFsamplecode:
git clone https://github.com/cloudera/impala-udf-samples
cd impala-udf-samples &amp;&amp; cmake . &amp;&amp; make
3.Unpackthesamplecodeinudf_samples.tar.gz andusethatasatemplatetosetupyourbuildenvironment.
Tobuildtheoriginalsamples:
# Process CMakeLists.txt and set up appropriate Makefiles.
cmake .
# Generate shared libraries from UDF and UDAF sample code,
# udf_samples/libudfsample.so and udf_samples/libudasample.so
make
Thesamplecodetoexamine,experimen twith,andadaptisinthesefiles:
â¢udf-sample.h :HeaderfilethatdeclaresthesignatureforascalarUDF(AddUDF).
â¢udf-sample.cc :SamplesourceforasimpleUDFthataddstwointegers.BecauseImpalacanreferencemultiple
functionentrypointsfromthesamesharedlibrary,youcouldaddotherUDFfunctions inthisfileandaddtheir
signaturestothecorresponding headerfile.
â¢udf-sample-test.cc :BasicunittestsforthesampleUDF.
â¢uda-sample.h :Headerfilethatdeclaresthesignatureforsampleaggregatefunctions. TheSQLfunctions will
becalledCOUNT,AVG,andSTRINGCONCAT .Becauseaggregatefunctions requiremoreelaboratecodingtohandle
theprocessingformultiplephases,thereareseveralunderlying C++functions suchasCountInit ,AvgUpdate ,
andStringConcatFinalize .
â¢uda-sample.cc :SamplesourceforsimpleUDAFsthatdemonstratehowtomanagethestatetransitions asthe
underlying functions arecalledduringthedifferentphasesofqueryprocessing.
âTheUDAFthatimitatestheCOUNTfunctionkeepstrackofasingleincrementingnumber;themergefunctions
combinetheintermediatecountvaluesfromeachImpalanode,andthecombined numberisreturned
verbatimbythefinalizefunction.
âTheUDAFthatimitatestheAVGfunctionkeepstrackoftwonumbers,acountofrowsprocessedandthe
sumofvaluesforacolumn.ThesenumbersareupdatedandmergedaswithCOUNT,thenthefinalizefunction
dividesthemtoproduceandreturnthefinalaveragevalue.
534|ApacheImpalaGuideImpalaSQLLanguageReference
âTheUDAFthatconcatenatesstringvaluesintoacomma-separ atedlistdemonstrateshowtomanagestorage
forastringthatincreasesinlengthasthefunctioniscalledformultiplerows.
â¢uda-sample-test.cc :basicunittestsforthesampleUDAFs.
Performance ConsiderationsforUDFs
BecauseaUDFtypicallyprocesseseachrowofatable,potentiallybeingcalledbillionsoftimes,theperformance of
eachUDFisacriticalfactorinthespeedoftheoverallETLorELTpipeline.Tinyoptimizationsyoucanmakewithinthe
functionbodycanpayoffinabigwaywhenthefunctioniscalledoverandoverwhenprocessingahugeresultset.
ExamplesofCreatingandUsingUDFs
Thissectiondemonstrateshowtocreateanduseallkindsofuser-definedfunctions (UDFs).
Fordownloadable examplesthatyoucanexperimen twith,adapt,anduseastemplatesforyourownfunctions, see
theClouderasampleUDFgithub.Youmusthavealreadyinstalledtheappropriateheaderfiles,asexplainedinInstalling
theUDFDevelopmentPackageonpage528.
SampleC++UDFs:HasVowels,CountVowels,StripVowels
Thisexampleshows3separateUDFsthatoperateonstringsandreturndifferentdatatypes.IntheC++code,the
functions areHasVowels() (checksifastringcontainsanyvowels),CountVowels() (returnsthenumberofvowels
inastring),andStripVowels() (returnsanewstringwithvowelsremoved).
First,weaddthesignaturesforthesefunctions toudf-sample.h inthedemobuildenvironment:
BooleanVal HasVowels(FunctionContext* context, const StringVal& input);
IntVal CountVowels(FunctionContext* context, const StringVal& arg1);
StringVal StripVowels(FunctionContext* context, const StringVal& arg1);
Then,weaddthebodiesofthesefunctions toudf-sample.cc :
BooleanVal HasVowels(FunctionContext* context, const StringVal& input)
{
        if (input.is_null) return BooleanVal::null();
        int index;
        uint8_t *ptr;
        for (ptr = input.ptr, index = 0; index <= input.len; index++, ptr++)
        {
                uint8_t c = tolower(*ptr);
                if (c == 'a' || c == 'e' || c == 'i' || c == 'o' || c == 'u')
                {
                        return BooleanVal(true);
                }
        }
        return BooleanVal(false);
}
IntVal CountVowels(FunctionContext* context, const StringVal& arg1)
{
        if (arg1.is_null) return IntVal::null();
        int count;
        int index;
        uint8_t *ptr;
        for (ptr = arg1.ptr, count = 0, index = 0; index <= arg1.len; index++, ptr++)
        {
                uint8_t c = tolower(*ptr);
                if (c == 'a' || c == 'e' || c == 'i' || c == 'o' || c == 'u')
                {
                        count++;
                }
        }
        return IntVal(count);
ApacheImpalaGuide|535ImpalaSQLLanguageReference
}
StringVal StripVowels(FunctionContext* context, const StringVal& arg1)
{
        if (arg1.is_null) return StringVal::null();
        int index;
        std::string original((const char *)arg1.ptr,arg1.len);
        std::string shorter("");
        for (index = 0; index < original.length(); index++)
        {
                uint8_t c = original[index];
                uint8_t l = tolower(c);
                if (l == 'a' || l == 'e' || l == 'i' || l == 'o' || l == 'u')
                {
                        ;
                }
                else
                {
                    shorter.append(1, (char)c);
                }
        }
// The modified string is stored in 'shorter', which is destroyed when this function 
ends. We need to make a string val
// and copy the contents.
        StringVal result(context, shorter.size()); // Only the version of the ctor that
 takes a context object allocates new memory
        memcpy(result.ptr, shorter.c_str(), shorter.size());
        return result;
}
Webuildasharedlibrary,libudfsample.so ,andputthelibraryfileintoHDFSwhereImpalacanreadit:
$ make
[  0%] Generating udf_samples/uda-sample.ll
[ 16%] Built target uda-sample-ir
[ 33%] Built target udasample
[ 50%] Built target uda-sample-test
[ 50%] Generating udf_samples/udf-sample.ll
[ 66%] Built target udf-sample-ir
Scanning dependencies of target udfsample
[ 83%] Building CXX object CMakeFiles/udfsample.dir/udf-sample.o
Linking CXX shared library udf_samples/libudfsample.so
[ 83%] Built target udfsample
Linking CXX executable udf_samples/udf-sample-test
[100%] Built target udf-sample-test
$ hdfs dfs -put ./udf_samples/libudfsample.so /user/hive/udfs/libudfsample.so
Finally,wegointotheimpala-shell interpreterwherewesetupsomesampledata,issueCREATE FUNCTION
statementstosetuptheSQLfunctionnames,andcallthefunctions insomequeries:
[localhost:21000] > create database udf_testing;
[localhost:21000] > use udf_testing;
[localhost:21000] > create function has_vowels (string) returns boolean location 
'/user/hive/udfs/libudfsample.so' symbol='HasVowels';
[localhost:21000] > select has_vowels('abc');
+------------------------+
| udfs.has_vowels('abc') |
+------------------------+
| true                   |
+------------------------+
Returned 1 row(s) in 0.13s
[localhost:21000] > select has_vowels('zxcvbnm');
+----------------------------+
| udfs.has_vowels('zxcvbnm') |
+----------------------------+
| false                      |
+----------------------------+
536|ApacheImpalaGuideImpalaSQLLanguageReference
Returned 1 row(s) in 0.12s
[localhost:21000] > select has_vowels(null);
+-----------------------+
| udfs.has_vowels(null) |
+-----------------------+
| NULL                  |
+-----------------------+
Returned 1 row(s) in 0.11s
[localhost:21000] > select s, has_vowels(s) from t2;
+-----------+--------------------+
| s         | udfs.has_vowels(s) |
+-----------+--------------------+
| lower     | true               |
| UPPER     | true               |
| Init cap  | true               |
| CamelCase | true               |
+-----------+--------------------+
Returned 4 row(s) in 0.24s
[localhost:21000] > create function count_vowels (string) returns int location 
'/user/hive/udfs/libudfsample.so' symbol='CountVowels';
[localhost:21000] > select count_vowels('cat in the hat');
+-------------------------------------+
| udfs.count_vowels('cat in the hat') |
+-------------------------------------+
| 4                                   |
+-------------------------------------+
Returned 1 row(s) in 0.12s
[localhost:21000] > select s, count_vowels(s) from t2;
+-----------+----------------------+
| s         | udfs.count_vowels(s) |
+-----------+----------------------+
| lower     | 2                    |
| UPPER     | 2                    |
| Init cap  | 3                    |
| CamelCase | 4                    |
+-----------+----------------------+
Returned 4 row(s) in 0.23s
[localhost:21000] > select count_vowels(null);
+-------------------------+
| udfs.count_vowels(null) |
+-------------------------+
| NULL                    |
+-------------------------+
Returned 1 row(s) in 0.12s
[localhost:21000] > create function strip_vowels (string) returns string location 
'/user/hive/udfs/libudfsample.so' symbol='StripVowels';
[localhost:21000] > select strip_vowels('abcdefg');
+------------------------------+
| udfs.strip_vowels('abcdefg') |
+------------------------------+
| bcdfg                        |
+------------------------------+
Returned 1 row(s) in 0.11s
[localhost:21000] > select strip_vowels('ABCDEFG');
+------------------------------+
| udfs.strip_vowels('abcdefg') |
+------------------------------+
| BCDFG                        |
+------------------------------+
Returned 1 row(s) in 0.12s
[localhost:21000] > select strip_vowels(null);
+-------------------------+
| udfs.strip_vowels(null) |
+-------------------------+
| NULL                    |
+-------------------------+
Returned 1 row(s) in 0.16s
[localhost:21000] > select s, strip_vowels(s) from t2;
+-----------+----------------------+
| s         | udfs.strip_vowels(s) |
+-----------+----------------------+
ApacheImpalaGuide|537ImpalaSQLLanguageReference
| lower     | lwr                  |
| UPPER     | PPR                  |
| Init cap  | nt cp                |
| CamelCase | CmlCs                |
+-----------+----------------------+
Returned 4 row(s) in 0.24s
SampleC++UDA:SumOfSquar es
Thisexampledemonstratesauser-definedaggregatefunction(UDA)thatproducesthesumofthesquaresofitsinput
values.
ThecodingforaUDAisalittlemoreinvolvedthanascalarUDF,becausetheprocessingissplitintoseveralphases,
eachimplemen tedbyadifferentfunction. Eachphaseisrelativelystraightforward:theâupdateâandâmergeâphases,
wheremostoftheworkisdone,readaninputvalueandcombineitwithsomeaccumula tedintermediatevalue.
AsinoursampleUDFfromthepreviousexample,weaddfunctionsignaturestoaheaderfile(inthiscase,
uda-sample.h ).Becausethisisamath-orientedUDA,wemaketwoversionsofeachfunction, oneacceptingan
integervalueandtheotheracceptingafloating-pointvalue.
void SumOfSquaresInit(FunctionContext* context, BigIntVal* val);
void SumOfSquaresInit(FunctionContext* context, DoubleVal* val);
void SumOfSquaresUpdate(FunctionContext* context, const BigIntVal& input, BigIntVal* 
val);
void SumOfSquaresUpdate(FunctionContext* context, const DoubleVal& input, DoubleVal* 
val);
void SumOfSquaresMerge(FunctionContext* context, const BigIntVal& src, BigIntVal* dst);
void SumOfSquaresMerge(FunctionContext* context, const DoubleVal& src, DoubleVal* dst);
BigIntVal SumOfSquaresFinalize(FunctionContext* context, const BigIntVal& val);
DoubleVal SumOfSquaresFinalize(FunctionContext* context, const DoubleVal& val);
WeaddthefunctionbodiestoaC++sourcefile(inthiscase,uda-sample.cc ):
void SumOfSquaresInit(FunctionContext* context, BigIntVal* val) {
  val->is_null = false;
  val->val = 0;
}
void SumOfSquaresInit(FunctionContext* context, DoubleVal* val) {
  val->is_null = false;
  val->val = 0.0;
}
void SumOfSquaresUpdate(FunctionContext* context, const BigIntVal& input, BigIntVal* 
val) {
  if (input.is_null) return;
  val->val += input.val * input.val;
}
void SumOfSquaresUpdate(FunctionContext* context, const DoubleVal& input, DoubleVal* 
val) {
  if (input.is_null) return;
  val->val += input.val * input.val;
}
void SumOfSquaresMerge(FunctionContext* context, const BigIntVal& src, BigIntVal* dst)
 {
  dst->val += src.val;
}
void SumOfSquaresMerge(FunctionContext* context, const DoubleVal& src, DoubleVal* dst)
 {
  dst->val += src.val;
}
BigIntVal SumOfSquaresFinalize(FunctionContext* context, const BigIntVal& val) {
  return val;
}
DoubleVal SumOfSquaresFinalize(FunctionContext* context, const DoubleVal& val) {
538|ApacheImpalaGuideImpalaSQLLanguageReference
  return val;
}
AswiththesampleUDF,webuildasharedlibraryandputitintoHDFS:
$ make
[  0%] Generating udf_samples/uda-sample.ll
[ 16%] Built target uda-sample-ir
Scanning dependencies of target udasample
[ 33%] Building CXX object CMakeFiles/udasample.dir/uda-sample.o
Linking CXX shared library udf_samples/libudasample.so
[ 33%] Built target udasample
Scanning dependencies of target uda-sample-test
[ 50%] Building CXX object CMakeFiles/uda-sample-test.dir/uda-sample-test.o
Linking CXX executable udf_samples/uda-sample-test
[ 50%] Built target uda-sample-test
[ 50%] Generating udf_samples/udf-sample.ll
[ 66%] Built target udf-sample-ir
[ 83%] Built target udfsample
[100%] Built target udf-sample-test
$ hdfs dfs -put ./udf_samples/libudasample.so /user/hive/udfs/libudasample.so
TocreatetheSQLfunction, weissueaCREATE AGGREGATE FUNCTION statementandspecifytheunderlying C++
functionnamesforthedifferentphases:
[localhost:21000] > use udf_testing;
[localhost:21000] > create table sos (x bigint, y double);
[localhost:21000] > insert into sos values (1, 1.1), (2, 2.2), (3, 3.3), (4, 4.4);
Inserted 4 rows in 1.10s
[localhost:21000] > create aggregate function sum_of_squares(bigint) returns bigint
  > location '/user/hive/udfs/libudasample.so'
  > init_fn='SumOfSquaresInit'
  > update_fn='SumOfSquaresUpdate'
  > merge_fn='SumOfSquaresMerge'
  > finalize_fn='SumOfSquaresFinalize';
[localhost:21000] > -- Compute the same value using literals or the UDA;
[localhost:21000] > select 1*1 + 2*2 + 3*3 + 4*4;
+-------------------------------+
| 1 * 1 + 2 * 2 + 3 * 3 + 4 * 4 |
+-------------------------------+
| 30                            |
+-------------------------------+
Returned 1 row(s) in 0.12s
[localhost:21000] > select sum_of_squares(x) from sos;
+------------------------+
| udfs.sum_of_squares(x) |
+------------------------+
| 30                     |
+------------------------+
Returned 1 row(s) in 0.35s
Untilwecreatetheoverloaded versionoftheUDA,itcanonlyhandleasingledatatype.ToallowittohandleDOUBLE
aswellasBIGINT,weissueanotherCREATE AGGREGATE FUNCTION statement:
[localhost:21000] > select sum_of_squares(y) from sos;
ERROR: AnalysisException: No matching function with signature: 
udfs.sum_of_squares(DOUBLE).
[localhost:21000] > create aggregate function sum_of_squares(double) returns double
  > location '/user/hive/udfs/libudasample.so'
  > init_fn='SumOfSquaresInit'
  > update_fn='SumOfSquaresUpdate'
  > merge_fn='SumOfSquaresMerge'
  > finalize_fn='SumOfSquaresFinalize';
[localhost:21000] > -- Compute the same value using literals or the UDA;
ApacheImpalaGuide|539ImpalaSQLLanguageReference
[localhost:21000] > select 1.1*1.1 + 2.2*2.2 + 3.3*3.3 + 4.4*4.4;
+-----------------------------------------------+
| 1.1 * 1.1 + 2.2 * 2.2 + 3.3 * 3.3 + 4.4 * 4.4 |
+-----------------------------------------------+
| 36.3                                          |
+-----------------------------------------------+
Returned 1 row(s) in 0.12s
[localhost:21000] > select sum_of_squares(y) from sos;
+------------------------+
| udfs.sum_of_squares(y) |
+------------------------+
| 36.3                   |
+------------------------+
Returned 1 row(s) in 0.35s
Typically,youuseaUDAinquerieswithGROUP BY clauses,toproducearesultsetwithaseparateaggregatevalue
foreachcombinationofvaluesfromtheGROUP BY clause.Let'schangeoursampletabletouse0toindicaterows
containingevenvalues,and1toflagrowscontainingoddvalues.ThentheGROUP BY querycanreturntwovalues,
thesumofthesquaresfortheevenvalues,andthesumofthesquaresfortheoddvalues:
[localhost:21000] > insert overwrite sos values (1, 1), (2, 0), (3, 1), (4, 0);
Inserted 4 rows in 1.24s
[localhost:21000] > -- Compute 1 squared + 3 squared, and 2 squared + 4 squared;
[localhost:21000] > select y, sum_of_squares(x) from sos group by y;
+---+------------------------+
| y | udfs.sum_of_squares(x) |
+---+------------------------+
| 1 | 10                     |
| 0 | 20                     |
+---+------------------------+
Returned 2 row(s) in 0.43s
SecurityConsiderationsforUser-DefinedFunctions
WhentheImpalaauthorizationfeatureisenabled:
â¢TocallaUDFinaquery,youmusthavetherequiredreadprivilegeforanydatabasesandtablesusedinthequery.
â¢TheCREATE FUNCTION statementrequires:
âTheCREATEprivilegeonthedatabase.
âTheALLprivilegeontwoURIswheretheURIsare:
âTheJARfileonthefilesystem.Forexample:
GRANT ALL ON URI 'file: ///path_to_my.jar ' TO ROLE my_role;
âTheJARonHDFS.Forexample:
GRANT ALL ON URI 'hdfs: ///path/to/jar ' TO ROLE my_role
SeeEnablingSentryAuthorizationforImpalaonpage87fordetailsaboutauthorizationinImpala.
LimitationsandRestrictionsforImpalaUDFs
ThefollowinglimitationsandrestrictionsapplytoImpalaUDFsinthecurrentrelease:
â¢ImpaladoesnotsupportHiveUDFsthatacceptorreturncompositeornestedtypes,orothertypesnotavailable
inImpalatables.
â¢TheHivecurrent_user() functioncannotbecalledfromaJavaUDFthroughImpala.
540|ApacheImpalaGuideImpalaSQLLanguageReference
â¢AllImpalaUDFsmustbedeterministic,thatis,producethesameoutputeachtimewhenpassedthesameargument
values.Forexample,anImpalaUDFmustnotcallfunctions suchasrand()toproducedifferentvaluesforeach
invocation.Itmustnotretrievedatafromexternalsources,suchasfromdiskoroverthenetwork.
â¢AnImpalaUDFmustnotspawnotherthreadsorprocesses.
â¢PriortoCDH5.7/Impala2.5whenthecatalogd processisrestarted,allUDFsbecomeundefinedandmustbe
reloaded.InCDH5.7/Impala2.5andhigher,thislimitationonlyappliestoolderJavaUDFs.Re-createthoseUDFs
usingthenewCREATE FUNCTION syntaxforJavaUDFs,whichexcludesthefunctionsignature,toremovethe
limitationentirely.
â¢Impalacurrentlydoesnotsupportuser-definedtablefunctions (UDTFs).
â¢TheCHARandVARCHAR typescannotbeusedasinputargumentsorreturnvaluesforUDFs.
ConvertingLegacyUDFsDuringUpgradetoCDH5.12orHigher
InCDH5.7/Impala2.5andhigher,theCREATEFUNCTIONStatementonpage228isavailableforcreatingJava-based
UDFs.UDFscreatedwiththenewsyntaxpersistacrossImpalarestarts,andaremorecompatiblewithHiveUDFs.
BecausethereplicationfeaturesinCDH5.12andhigheronlyworkwiththenew-stylesyntax,convertanyolderJava
UDFstousethenewsyntaxatthesametimeyouupgradetoCDH5.12orhigher.
Followthesestepstoconvertold-styleJavaUDFstothenewpersistentkind:
â¢UseSHOW FUNCTIONS toidentifyallUDFsandUDAs.
â¢Foreachfunction, useSHOW CREATE FUNCTION andsavethestatementinascriptfile.
â¢ForJavaUDFs,changetheoutputofSHOW CREATE FUNCTION tousethenewCREATE FUNCTION syntax(without
argumenttypes),whichmakestheUDFpersistent.
â¢Foreachfunction, dropitandre-createit,usingthenewCREATE FUNCTION syntaxforallJavaUDFs.
SQLDifferencesBetweenImpalaandHive
Impala'sSQLsyntaxfollowstheSQL-92standard,andincludesmanyindustryextensionsinareassuchasbuilt-in
functions. SeePortingSQLfromOtherDatabaseSystemstoImpalaonpage543forageneraldiscussion ofadapting
SQLcodefromavarietyofdatabasesystemstoImpala.
BecauseImpalaandHivesharethesamemetastoredatabaseandtheirtablesareoftenusedinterchangeably,the
followingsectioncoversdifferencesbetweenImpalaandHiveindetail.
HiveQLFeaturesnotAvailableinImpala
ThecurrentreleaseofImpaladoesnotsupportthefollowingSQLfeaturesthatyoumightbefamiliarwithfromHiveQL:
â¢Extensibility mechanisms suchasTRANSFORM ,customfileformats,orcustomSerDes.
â¢TheDATEdatatype.
â¢TheBINARYdatatype.
â¢XMLfunctions.
â¢Certainaggregatefunctions fromHiveQL:covar_pop ,covar_samp ,corr,percentile ,percentile_approx ,
histogram_numeric ,collect_set ;Impalasupports thesetofaggregatefunctions listedinImpalaAggregate
Functions onpage479andanalyticfunctions listedinImpalaAnalyticFunctions onpage506.
â¢Sampling.
â¢Lateralviews.InCDH5.5/Impala2.3andhigher,Impalasupports queriesoncomplextypes(STRUCT,ARRAY,or
MAP),usingjoinnotationratherthantheEXPLODE() keyword.SeeComplexTypes(CDH5.5orhigheronly)on
page139fordetailsaboutImpalasupportforcomplextypes.
User-definedfunctions (UDFs)aresupportedstartinginImpala1.2.SeeUser-DefinedFunctions (UDFs)onpage525for
fulldetailsonImpalaUDFs.
â¢Impalasupports high-performance UDFswritteninC++,aswellasreusingsomeJava-basedHiveUDFs.
â¢Impalasupports scalarUDFsanduser-definedaggregatefunctions (UDAFs).Impaladoesnotcurrentlysupport
user-definedtablegeneratingfunctions (UDTFs).
ApacheImpalaGuide|541ImpalaSQLLanguageReference
â¢OnlyImpala-support edcolumntypesaresupportedinJava-basedUDFs.
â¢TheHivecurrent_user() functioncannotbecalledfromaJavaUDFthroughImpala.
ImpaladoesnotcurrentlysupporttheseHiveQLstatements:
â¢ANALYZE TABLE (theImpalaequivalentisCOMPUTE STATS )
â¢DESCRIBE COLUMN
â¢DESCRIBE DATABASE
â¢EXPORT TABLE
â¢IMPORT TABLE
â¢SHOW TABLE EXTENDED
â¢SHOW TBLPROPERTIES
â¢SHOW INDEXES
â¢SHOW COLUMNS
â¢INSERT OVERWRITE DIRECTORY ;useINSERT OVERWRITE table_name orCREATE TABLE AS SELECT to
materializequeryresultsintotheHDFSdirectoryassociatedwithanImpalatable.
Impalarespectstheserialization.null.format tablepropertyonlyforTEXTtablesandignoresthepropertyfor
Parquetandotherformats.Hiverespectstheserialization.null.format propertyforParquetandotherformats
andconvertsmatchingvaluestoNULLduringthescan.SeeDataFilesforTextTablesonpage638forusingthetable
propertyinImpala.
SemanticDifferencesBetweenImpalaandHiveQLFeatures
ThissectioncoversinstanceswhereImpalaandHivehavesimilarfunctionality ,sometimesincluding thesamesyntax,
buttherearedifferencesintheruntimesemanticsofthosefeatures.
Security:
ImpalautilizestheApacheSentryauthorizationframework,whichprovidesfine-grainedrole-based accesscontrolto
protectdataagainstunauthoriz edaccessortampering.
TheHivecomponen tincludedinCDH5.1andhighernowincludesSentry-enabled GRANT,REVOKE,andCREATE/DROP
ROLEstatements.EarlierHivereleaseshadaprivilegesystemwithGRANTandREVOKEstatementsthatwereprimarily
intendedtopreventaccidentaldeletionofdata,ratherthanasecuritymechanism toprotectagainstmalicious users.
ImpalacanmakeuseofprivilegessetupthroughHiveGRANTandREVOKEstatements.ImpalahasitsownGRANTand
REVOKEstatementsinImpala2.0andhigher.SeeEnablingSentryAuthorizationforImpalaonpage87forthedetails
ofauthorizationinImpala,including howtoswitchfromtheoriginalpolicyfile-based privilegemodeltotheSentry
serviceusingprivilegesstoredinthemetastoredatabase.
SQLstatementsandclauses:
ThesemanticsofImpalaSQLstatementsvariesfromHiveQLinsomecaseswheretheyusesimilarSQLstatementand
clausenames:
â¢Impalausesdifferentsyntaxandnamesforqueryhints,[SHUFFLE] and[NOSHUFFLE] ratherthanMapJoin or
StreamJoin .SeeJoinsinImpalaSELECTStatementsonpage296fortheImpaladetails.
â¢ImpaladoesnotexposeMapReducespecificfeaturesofSORT BY ,DISTRIBUTE BY ,orCLUSTER BY .
â¢ImpaladoesnotrequirequeriestoincludeaFROMclause.
Datatypes:
â¢Impalasupports alimitedsetofimplicitcasts.Thiscanhelpavoidundesiredresultsfromunexpectedcasting
behavior.
âImpaladoesnotimplicitly castbetweenstringandnumericorBooleantypes.AlwaysuseCAST()forthese
conversions.
542|ApacheImpalaGuideImpalaSQLLanguageReference
âImpaladoesperformimplicitcastsamongthenumerictypes,whengoingfromasmallerorlessprecisetype
toalargerormorepreciseone.Forexample,Impalawillimplicitly convertaSMALLINT toaBIGINTorFLOAT,
buttoconvertfromDOUBLEtoFLOATorINTtoTINYINT requiresacalltoCAST()inthequery.
âImpaladoesperformimplicitcastsfromstringtotimestamp.Impalahasarestrictedsetofliteralformatsfor
theTIMESTAMP datatypeandthefrom_unixtime() formatstring;seeTIMESTAMPDataTypeonpage130
fordetails.
SeethetopicsunderDataTypesonpage101forfulldetailsonimplicitandexplicitcastingforeachdatatype,and
ImpalaTypeConversionFunctions onpage423fordetailsabouttheCAST()function.
â¢Impaladoesnotstoreorinterprettimestampsusingthelocaltimezone,toavoidundesiredresultsfromunexpected
timezoneissues.TimestampsarestoredandinterpretedrelativetoUTC.Thisdifferencecanproducedifferent
resultsforsomecallstosimilarlynameddate/timefunctions betweenImpalaandHive.SeeImpalaDateandTime
Functions onpage424fordetailsabouttheImpalafunctions. SeeTIMESTAMPDataTypeonpage130foradiscussion
ofhowImpalahandlestimezones,andconfigurationoptionsyoucanusetomakeImpalamatchtheHivebehavior
morecloselywhendealingwithParquet-encodedTIMESTAMP dataorwhenconvertingbetweenthelocaltime
zoneandUTC.
â¢TheImpalaTIMESTAMP typecanrepresentdatesrangingfrom1400-01-01 to9999-12-31. Thisisdifferentfrom
theHivedaterange,whichis0000-01-01 to9999-12-31.
â¢ImpaladoesnotreturncolumnoverflowsasNULL,sothatcustomerscandistinguishbetweenNULLdataand
overflowconditions similartohowtheydosowithtraditional databasesystems.Impalareturnsthelargestor
smallestvalueintherangeforthetype.Forexample,validvaluesforatinyint rangefrom-128to127.InImpala,
atinyint withavalueof-200returns-128ratherthanNULL.Atinyint withavalueof200returns127.
Miscellaneous features:
â¢Impaladoesnotprovidevirtualcolumns.
â¢Impaladoesnotexposelocking.
â¢Impaladoesnotexposesomeconfigurationproperties.
PortingSQLfromOtherDatabaseSystemstoImpala
Although ImpalausesstandardSQLforqueries,youmightneedtomodifySQLsourcewhenbringingapplicationsto
Impala,duetovariationsindatatypes,built-infunctions, vendorlanguageextensions,andHadoop-specific syntax.
EvenwhenSQLisworkingcorrectly,youmightmakefurtherminormodificationsforbestperformance.
PortingDDLandDMLStatements
WhenadaptingSQLcodefromatraditional databasesystemtoImpala,expecttofindanumberofdifferencesinthe
DDLstatementsthatyouusetosetuptheschema.Clausesrelatedtophysicallayoutoffiles,tablespaces, andindexes
havenoequivalentinImpala.YoumightrestructureyourschemaconsiderablytoaccountfortheImpalapartitioning
schemeandHadoopfileformats.
ExpectSQLqueriestohaveamuchhigherdegreeofcompatibility.Withmodestrewritingtoaddressvendorextensions
andfeaturesnotyetsupportedinImpala,youmightbeabletorunidenticaloralmost-identicalquerytextonboth
systems.
Therefore,considerseparatingouttheDDLintoaseparateImpala-specific setupscript.Focusyourreuseandongoing
tuningeffortsonthecodeforSQLqueries.
PortingDataTypesfromOtherDatabaseSystems
â¢ChangeanyVARCHAR ,VARCHAR2 ,andCHARcolumnstoSTRING.Removeanylengthconstraintsfromthecolumn
declarations;forexample,changeVARCHAR(32) orCHAR(1) toSTRING.Impalaisveryflexibleaboutthelength
ofstringvalues;itdoesnotimposeanylengthconstraintsordoanyspecialprocessing(suchasblank-padding)
forSTRINGcolumns.(InImpala2.0andhigher,therearedatatypesVARCHAR andCHAR,withlengthconstraints
forbothtypesandblank-padding forCHAR.However,forperformance reasons,itisstillpreferabletouseSTRING
columnswherepractical.)
ApacheImpalaGuide|543ImpalaSQLLanguageReference
â¢FornationallanguagecharactertypessuchasNCHAR,NVARCHAR ,orNCLOB,beawarethatwhileImpalacanstore
andqueryUTF-8characterdata,currentlysomestringmanipula tionoperationsonlyworkcorrectlywithASCII
data.SeeSTRINGDataTypeonpage123fordetails.
â¢ChangeanyDATE,DATETIME ,orTIMEcolumnstoTIMESTAMP .Removeanyprecisionconstraints.Removeany
timezoneclauses,andmakesureyourapplicationlogicorETLprocessaccountsforthefactthatImpalaexpects
allTIMESTAMP valuestobeinCoordinatedUniversalTime(UTC).SeeTIMESTAMPDataTypeonpage130for
informationabouttheTIMESTAMP datatype,andImpalaDateandTimeFunctions onpage424forconversion
functions fordifferentdateandtimeformats.
Youmightalsoneedtoadaptdate-andtime-relatedliteralvaluesandformatstringstousethesupportedImpala
dateandtimeformats.IfyouhavedateandtimeliteralswithdifferentseparatorsordifferentnumbersofYY,
MM,andsoonplaceholder sthanImpalaexpects,considerusingcallstoregexp_replace() totransformthose
valuestotheImpala-compatibleformat.SeeTIMESTAMPDataTypeonpage130forinformationabouttheallowed
formatsfordateandtimeliterals,andImpalaStringFunctions onpage462forstringconversionfunctions such
asregexp_replace() .
InsteadofSYSDATE ,callthefunctionNOW().
InsteadofaddingorsubtractingdirectlyfromadatevaluetoproduceavalueNdaysinthepastorfuture,usean
INTERVAL expression,forexampleNOW() + INTERVAL 30 DAYS .
â¢Although ImpalasupportsINTERVAL expressionsfordatetimearithmetic,asshowninTIMESTAMPDataTypeon
page130,INTERVAL isnotavailableasacolumndatatypeinImpala.ForanyINTERVAL valuesstoredintables,
convertthemtonumericvaluesthatyoucanaddorsubtractusingthefunctions inImpalaDateandTimeFunctions
onpage424.Forexample,ifyouhadatableDEADLINES withanINTcolumnTIME_PERIOD ,youcouldconstruct
datesNdaysinthefuturelikeso:
SELECT NOW() + INTERVAL time_period DAYS from deadlines;
â¢ForYEARcolumns,changetothesmallestImpalaintegertypethathassufficientrange.SeeDataTypesonpage
101fordetailsaboutranges,casting,andsoonforthevariousnumericdatatypes.
â¢ChangeanyDECIMAL andNUMBERtypes.Iffixed-pointprecisionisnotrequired,youcanuseFLOATorDOUBLE
ontheImpalasidedepending ontherangeofvalues.Forapplicationsthatrequireprecisedecimalvalues,such
asfinancialdata,youmightneedtomakemoreextensivechangestotablestructureandapplicationlogic,such
asusingseparateintegercolumnsfordollarsandcents,orencodingnumbersasstringvaluesandwritingUDFs
tomanipulatethem.SeeDataTypesonpage101fordetailsaboutranges,casting,andsoonforthevariousnumeric
datatypes.
â¢FLOAT,DOUBLE,andREALtypesaresupportedinImpala.Removeanyprecisionandscalespecifications.(In
Impala,REALisjustanaliasforDOUBLE;columnsdeclaredasREALareturnedintoDOUBLEbehindthescenes.)
SeeDataTypesonpage101fordetailsaboutranges,casting,andsoonforthevariousnumericdatatypes.
â¢MostintegertypesfromothersystemshaveequivalentsinImpala,perhapsunderdifferentnamessuchasBIGINT
insteadofINT8.Foranythatareunavailable,forexampleMEDIUMINT ,switchtothesmallestImpalaintegertype
thathassufficientrange.Removeanyprecisionspecifications.SeeDataTypesonpage101fordetailsaboutranges,
casting,andsoonforthevariousnumericdatatypes.
â¢RemoveanyUNSIGNED constraints.AllImpalanumerictypesaresigned.SeeDataTypesonpage101fordetails
aboutranges,casting,andsoonforthevariousnumericdatatypes.
â¢Foranytypesholdingbitwisevalues,useanintegertypewithenoughrangetoholdalltherelevantbitswithina
positiveinteger.SeeDataTypesonpage101fordetailsaboutranges,casting,andsoonforthevariousnumeric
datatypes.
Forexample,TINYINT hasamaximumpositivevalueof127,not256,sotomanipula te8-bitbitfieldsaspositive
numbersswitchtothenextlargesttypeSMALLINT .
[localhost:21000] > select cast(127*2 as tinyint);
+--------------------------+
544|ApacheImpalaGuideImpalaSQLLanguageReference
| cast(127 * 2 as tinyint) |
+--------------------------+
| -2                       |
+--------------------------+
[localhost:21000] > select cast(128 as tinyint);
+----------------------+
| cast(128 as tinyint) |
+----------------------+
| -128                 |
+----------------------+
[localhost:21000] > select cast(127*2 as smallint);
+---------------------------+
| cast(127 * 2 as smallint) |
+---------------------------+
| 254                       |
+---------------------------+
Impaladoesnotsupportnotationsuchasb'0101' forbitliterals.
â¢ForBLOBvalues,useSTRINGtorepresentCLOBorTEXTtypes(characterbasedlargeobjects)upto32KBinsize.
BinarylargeobjectssuchasBLOB,RAWBINARY,andVARBINARY donotcurrentlyhaveanequivalentinImpala.
â¢ForBoolean-lik etypessuchasBOOL,usetheImpalaBOOLEAN type.
â¢BecauseImpalacurrentlydoesnotsupportcompositeornestedtypes,anyspatialdatatypesinotherdatabase
systemsdonothavedirectequivalentsinImpala.Youcouldrepresentspatialvaluesinstringformatandwrite
UDFstoprocessthem.SeeUser-DefinedFunctions (UDFs)onpage525fordetails.Wherepractical,separatespatial
typesintoseparatetablessothatImpalacanstillworkwiththenon-spatialdata.
â¢TakeoutanyDEFAULT clauses.Impalacanusedatafilesproducedfrommanydifferentsources,suchasPig,Hive,
orMapReducejobs.Thefastimportmechanisms ofLOAD DATA andexternaltablesmeanthatImpalaisflexible
abouttheformatofdatafiles,andImpaladoesnotnecessarily validateorcleansedatabeforequeryingit.When
copyingdatathroughImpalaINSERTstatements,youcanuseconditional functions suchasCASEorNVLto
substitutesomeothervalueforNULLfields;seeImpalaConditional Functions onpage457fordetails.
â¢TakeoutanyconstraintsfromyourCREATE TABLE andALTER TABLE statements,forexamplePRIMARY KEY ,
FOREIGN KEY ,UNIQUE,NOT NULL ,UNSIGNED ,orCHECKconstraints.Impalacanusedatafilesproducedfrom
manydifferentsources,suchasPig,Hive,orMapReducejobs.Therefore,Impalaexpectsinitialdatavalidationto
happenearlierduringtheETLorELTcycle.AfterdataisloadedintoImpalatables,youcanperformqueriestotest
forNULLvalues.WhencopyingdatathroughImpalaINSERTstatements,youcanuseconditional functions such
asCASEorNVLtosubstitutesomeothervalueforNULLfields;seeImpalaConditional Functions onpage457for
details.
DoasmuchverificationaspracticalbeforeloadingdataintoImpala.AfterdataisloadedintoImpala,youcando
furtherverificationusingSQLqueriestocheckifvalueshaveexpectedranges,ifvaluesareNULLornot,andso
on.Ifthereisaproblemwiththedata,youwillneedtore-runearlierstagesoftheETLprocess,ordoanINSERT
... SELECT statementinImpalatocopythefaultydatatoanewtableandtransformorfilteroutthebadvalues.
â¢TakeoutanyCREATE INDEX ,DROP INDEX ,andALTER INDEX statements,andequivalentALTER TABLE
statements.RemoveanyINDEX,KEY,orPRIMARY KEY clausesfromCREATE TABLE andALTER TABLE statements.
Impalaisoptimizedforbulkreadoperationsfordatawarehouse-stylequeries,andthereforedoesnotsupport
indexesforitstables.
â¢Callstobuilt-infunctions without-of-rangeorotherwiseincorrectarguments,returnNULLinImpalaasopposed
toraisingexceptions.(ThisruleappliesevenwhentheABORT_ON_ERROR=true queryoptionisineffect.)Run
small-scalequeriesusingrepresentativedatatodoublecheck thatcallstobuilt-infunctions arereturningexpected
valuesratherthanNULL.Forexample,unsupport edCASToperationsdonotraiseanerrorinImpala:
select cast('foo' as int);
+--------------------+
| cast('foo' as int) |
+--------------------+
| NULL               |
+--------------------+
ApacheImpalaGuide|545ImpalaSQLLanguageReference
â¢ForanyothertypenotsupportedinImpala,youcouldrepresenttheirvaluesinstringformatandwriteUDFsto
processthem.SeeUser-DefinedFunctions (UDFs)onpage525fordetails.
â¢Todetectthepresenceofunsupport edorunconvertabledatatypesindatafiles,doinitialtestingwiththe
ABORT_ON_ERROR=true queryoptionineffect.Thisoptioncausesqueriestofailimmediatelyiftheyencounter
disallowedtypeconversions.SeeABORT_ON_ERR ORQueryOptiononpage323fordetails.Forexample:
set abort_on_error=true;
select count(*) from (select * from t1);
-- The above query will fail if the data files for T1 contain any
-- values that can't be converted to the expected Impala data types.
-- For example, if T1.C1 is defined as INT but the column contains
-- floating-point values like 1.1, the query will return an error.
SQLStatementstoRemoveorAdapt
ThefollowingSQLstatementsorclausesarenotcurrentlysupportedorsupportedwithlimitationsinImpala:
â¢Impalasupports theDELETEstatementonlyforKudutables.
Impalaisintendedfordatawarehouse-styleoperationswhereyoudobulkmovesandtransformsoflargequantities
ofdata.WhennotusingKudutables,insteadofDELETE,useINSERT OVERWRITE toentirelyreplacethecontents
ofatableorpartition, oruseINSERT ... SELECT tocopyasubsetofdata(everythingbuttherowsyouintended
todelete)fromonetabletoanother.SeeDMLStatementsonpage204foranoverviewofImpalaDMLstatements.
â¢Impalasupports theUPDATEstatementonlyforKudutables.
WhennotusingKudutables,insteadofUPDATE,doallnecessarytransformationsearlyintheETLprocess,such
asinthejobthatgeneratestheoriginaldata,orwhencopyingfromonetabletoanothertoconverttoaparticular
fileformatorpartitioning scheme.SeeDMLStatementsonpage204foranoverviewofImpalaDMLstatements.
â¢Impalahasnotransactional statements,suchasCOMMITorROLLBACK .
ImpalaeffectivelyworksliketheAUTOCOMMIT modeinsomedatabasesystems,wherechangestakeeffectas
soonastheyaremade.
â¢Ifyourdatabase,table,column,orothernamesconflictwithImpalareservedwords,usedifferentnamesorquote
thenameswithbackticks.
SeeImpalaReservedWordsonpage745forthecurrentlistofImpalareservedwords.
Conversely,ifyouuseakeywordthatImpaladoesnotrecognize,itmightbeinterpretedasatableorcolumn
alias.
Forexample,inSELECT * FROM t1 NATURAL JOIN t2 ,ImpaladoesnotrecognizetheNATURAL keywordand
interpretsitasanaliasforthetablet1.Ifyouexperience anyunexpectedbehaviorwithqueries,checkthelistof
reservedwordstomakesureallkeywordsinjoinandWHEREclausesaresupportedkeywordsinImpala.
â¢Impalahassomerestrictionsonsubquerysupport.SeeSubqueries inImpalaSELECTStatementsforthecurrent
details.
â¢ImpalasupportsUNIONandUNION ALL setoperators,butnotINTERSECT .
PreferUNION ALL overUNIONwhenyouknowthedatasetsaredisjointorduplicatevaluesarenotaproblem;
UNION ALL ismoreefficientbecauseitavoidsmaterializing andsortingtheentireresultsettoeliminateduplicate
values.
â¢Impalarequiresqueryaliasesforthesubqueries usedasinlineviewsintheFROMclause.
Forexample,withoutthealiascontents_of_t1 attheend,thefollowingquerygivesasyntaxerror:
SELECT COUNT(*) FROM (SELECT * FROM t1) contents_of_t1;
546|ApacheImpalaGuideImpalaSQLLanguageReference
Aliasesarenotrequiredforthesubqueries usedinotherpartsofqueries.Forexample:
SELECT * FROM functional.alltypes WHERE id = (SELECT MIN(id) FROM functional.alltypes);
â¢Whenanaliasisdeclaredforanexpressioninaquery,thataliascannotbereferencedagainwithinthesame
SELECTlist.
Forexample,theaverage aliascannotbereferencedtwiceintheSELECTlistasbelow.Youwillreceiveanerror:
SELECT AVG(x) AS average, average+1 FROM t1 GROUP BY x;
AnaliascanbereferencedagaininthesamequeryifnotintheSELECTlist.Forexample,theaverage aliascan
bereferencedtwiceasshownbelow:
SELECT AVG(x) AS average FROM t1 GROUP BY x HAVING average > 3;
â¢ImpaladoesnotsupportNATURAL JOIN ,anditdoesnotsupporttheUSINGclauseinjoins.SeeJoinsinImpala
SELECTStatementsonpage296fordetailsonthesyntaxforImpalajoinclauses.
â¢Impalasupports alimitedchoiceofpartitioning types.
Partitionsaredefinedbasedoneachdistinctcombinationofvaluesforoneormorepartitionkeycolumns.Impala
doesnotredistributeorcheckdatatocreateevenlydistributedpartitions. Youmustchoosepartitionkeycolumns
basedonyourknowledgeofthedatavolumeanddistribution. Adaptanytablesthatuserange,list,hash,orkey
partitioning tousetheImpalapartition syntaxforCREATE TABLE andALTER TABLE statements.
Impalapartitioning issimilartorangepartitioning whereeveryrangehasexactlyonevalue,orkeypartitioning
wherethehashfunctionproducesaseparatebucketforeverycombinationofkeyvalues.SeePartitioning for
ImpalaTablesonpage625forusagedetails,andCREATETABLEStatementonpage234andALTERTABLEStatement
onpage205forsyntax.
Note:Becausethenumberofseparatepartitions ispotentiallyhigherthaninotherdatabase
systems,keepacloseeyeonthenumberofpartitions andthevolumeofdataineachone;scale
backthenumberofpartition keycolumnsifyouendupwithtoomanypartitions withasmall
volumeofdataineachone.
Todistributeworkforaqueryacrossacluster,youneedatleastoneHDFSblockpernode.HDFS
blocksaretypicallymultiplemegabytes,especially forParquetfiles.Therefore,ifeachpartition
holdsonlyafewmegabytesofdata,youareunlikelytoseemuchparallelisminthequerybecause
suchasmallamountofdataistypicallyprocessedbyasinglenode.
â¢Fortheâtop-Nâqueries,ImpalausestheLIMITclauseratherthancomparing againstapseudocolumnnamed
ROWNUMorROW_NUM .
SeeLIMITClauseonpage308fordetails.
SQLConstructstoDouble-check
SomeSQLconstructsthataresupportedhavebehaviorordefaultsmoreorientedtowardsconveniencethanoptimal
performance. Also,sometimesmachine-g eneratedSQL,perhapsissuedthroughJDBCorODBCapplications,might
haveinefficiencies orexceedinternalImpalalimits.AsyouportSQLcode,examineandpossiblyupdatethefollowing
whereappropriate:
â¢ACREATE TABLE statementwithnoSTORED AS clausecreatesdatafilesinplaintextformat,whichisconvenient
fordatainterchangebutnotagoodchoiceforhigh-volumedatawithhigh-performance queries.SeeHowImpala
WorkswithHadoopFileFormatsonpage634forwhyandhowtousespecificfileformatsforcompactdataand
high-performance queries.Especially seeUsingtheParquetFileFormatwithImpalaTablesonpage643,fordetails
aboutthefileformatmostheavilyoptimizedforlarge-scaledatawarehousequeries.
ApacheImpalaGuide|547ImpalaSQLLanguageReference
â¢Adaptingtablesthatwerealreadypartitioned inadifferentdatabasesystemcouldproduceanImpalatablewith
ahighnumberofpartitions andnotenoughdataineachone,leadingtounderutiliz ationofImpala'sparallelquery
features.
SeePartitioning forImpalaTablesonpage625fordetailsaboutsettinguppartitioning andtuningtheperformance
ofqueriesonpartitioned tables.
â¢TheINSERT ... VALUES syntaxissuitableforsettinguptoytableswithafewrowsforfunctional testingwhen
usedwithHDFS.EachsuchstatementcreatesaseparatetinyfileinHDFS,anditisnotascalabletechnique for
loadingmegabytesorgigabytes(letalonepetabytes)ofdata.
Consider revisingyourdataloadprocesstoproducerawdatafilesoutsideofImpala,thensettingupImpala
externaltablesorusingtheLOAD DATA statementtousethosedatafilesinstantlyinImpalatables,withno
conversionorindexingstage.SeeExternalTablesonpage197andLOADDATAStatementonpage288fordetails
abouttheImpalatechniques forworkingwithdatafilesproducedoutsideofImpala;seeDataLoadingandQuerying
Examplesonpage52forexamplesofETLworkflowforImpala.
INSERTworksfineforKudutableseventhoughnotparticularly fast.
â¢IfyourETLprocessisnotoptimizedforHadoop,youmightendupwithhighlyfragmentedsmalldatafiles,ora
singlegiantdatafilethatcannottakeadvantageofdistributedparallelqueriesorpartitioning. Inthiscase,usean
INSERT ... SELECT statementtocopythedataintoanewtableandreorganizeintoamoreefficientlayoutin
thesameoperation.SeeINSERTStatementonpage277fordetailsabouttheINSERTstatement.
YoucandoINSERT ... SELECT intoatablewithamoreefficientfileformat(seeHowImpalaWorkswith
HadoopFileFormatsonpage634)orfromanunpartitioned tableintoapartitioned one.SeePartitioning forImpala
Tablesonpage625.
â¢Complexqueriesmayhavehighcodegentime.Asaworkaround,setthequeryoptionDISABLE_CODEGEN=true
ifqueriesfailforthisreason.SeeDISABLE_CODEGENQueryOptiononpage327fordetails.
â¢Ifpractical,rewriteUNIONqueriestousetheUNION ALL operatorinstead.PreferUNION ALL overUNIONwhen
youknowthedatasetsaredisjointorduplicatevaluesarenotaproblem;UNION ALL ismoreefficientbecause
itavoidsmaterializing andsortingtheentireresultsettoeliminateduplicatevalues.
NextPortingStepsafterVerifyingSyntaxandSemantics
Someofthedecisions youmakeduringtheportingprocesscanhaveanimpactonperformance. AfteryourSQLcode
isportedandworkingcorrectly,examinetheperformance-r elatedaspectsofyourschemadesign,physicallayout,and
queriestomakesurethattheportedapplicationistakingfulladvantageofImpala'sparallelism,performance-r elated
SQLfeatures,andintegrationwithHadoopcomponen ts.Thefollowingareafewoftheareasyoushouldexamine:
â¢Fortheoptimalperformance, werecommend thatyourunCOMPUTE STATS onalltables.
â¢Usethemostefficientfileformatforyourdatavolumes,tablestructure,andquerycharacteristics.
â¢PartitiononcolumnsthatareoftenusedforfilteringinWHEREclauses.
â¢YourETLprocessshouldproducearelativelysmallnumberofmulti-meg abytedatafilesratherthanahugenumber
ofsmallfiles.
SeeTuningImpalaforPerformance onpage565fordetailsabouttheperformance tuningprocess.
548|ApacheImpalaGuideImpalaSQLLanguageReference
ResourceManagement
ImpalaincludesthefeaturesthatbalanceandmaximizeresourcesinCDHclusters.Thistopicdescribes howyoucan
improveefficiencyofyourCDHclusterusingthosefeatures.
â¢Staticservicepools
UsethestaticservicepoolstoallocatededicatedresourcesforImpalatomanageandprioritizeworkloadson
clusters.
â¢Admission control
Withintheconstraintsofthestaticservicepool,youcanfurthersubdivide Impala'sresourcesusingdynamic
resourcepoolsandadmission control.
SeeAdmission ControlandQueryQueuingonpage549foranoverviewandguidelines onadmission control.
SeeConfiguringResourcePoolsandAdmission Controlonpage554forconfiguringresourcepoolsandmanaging
admission control.
Admission ControlandQueryQueuing
Admission controlisanImpalafeaturethatimposeslimitsonconcurrentSQLqueries,toavoidresourceusagespikes
andout-of-memor yconditions onbusyCDHclusters.Theadmission controlfeatureletsyousetanupperlimitonthe
numberofconcurrentImpalaqueriesandonthememoryusedbythosequeries.Anyadditional queriesarequeued
untiltheearlieronesfinish,ratherthanbeingcancelledorrunningslowlyandcausingcontention.Asotherqueries
finish,thequeuedqueriesareallowedtoproceed.
InCDH5.7/Impala2.5andhigher,youcanspecifytheselimitsandthresholdsforeachpoolratherthanglobally.That
way,youcanbalancetheresourceusageandthroughputbetweensteadywell-definedworkloads, rareresource-intensive
queries,andad-hocexploratoryqueries.
Inadditiontothethresholdvaluesforcurrentlyexecutingqueries,youcanplacelimitsonthemaximumnumberof
queriesthatarequeued(waiting)andalimitontheamountoftimetheymightwaitbeforereturningwithanerror.
Thesequeuesettingsletyouensurethatqueriesdonotwaitindefinitelysothatyoucandetectandcorrectâstarvationâ
scenarios.
Queries,DMLstatements,andsomeDDLstatements,includingCREATE TABLE AS SELECT andCOMPUTE STATS
areaffectedbyadmission control.
OnabusyCDHcluster,youmightfindthereisanoptimalnumberofImpalaqueriesthatrunconcurrently.Forexample,
whentheI/OcapacityisfullyutilizedbyI/O-intensivequeries,youmightnotfindanythroughputbenefitinrunning
moreconcurrentqueries.Byallowingsomequeriestorunatfullspeedwhileotherswait,ratherthanhavingallqueries
contendforresourcesandrunslowly,admission controlcanresultinhigheroverallthroughput.
Foranotherexample,consideramemory-boundworkloadsuchasmanylargejoinsoraggregationqueries.Eachsuch
querycouldbrieflyusemanygigabytesofmemorytoprocessintermediateresults.BecauseImpalabydefaultcancels
queriesthatexceedthespecified memorylimit,runningmultiplelarge-scalequeriesatoncemightrequirere-running
somequeriesthatarecancelled. Inthiscase,admission controlimprovesthereliabilityandstabilityoftheoverall
workloadbyonlyallowingasmanyconcurrentqueriesastheoverallmemoryoftheclustercanaccommodate.
ConcurrentQueriesandAdmission Control
Onewaytolimitresourceusagethroughadmission controlistosetanupperlimitonthenumberofconcurrentqueries.
Thisistheinitialtechnique youmightusewhenyoudonothaveextensiveinformationaboutmemoryusageforyour
workload.Thesettingscanbespecified separatelyforeachdynamicresourcepool.
ApacheImpalaGuide|549ResourceManagement
MaxRunningQueries
Maximumnumberofconcurrentlyrunningqueriesinthispool.ThedefaultvalueisunlimitedforCDH5.7orhigher.
(optional)
Themaximumnumberofqueriesthatcanrunconcurrentlyinthispool.Thedefaultvalueisunlimited.Anyqueries
forthispoolthatexceedMaxRunningQueriesareaddedtotheadmission controlqueueuntilotherqueriesfinish.
YoucanuseMaxRunningQueriesintheearlystagesofresourcemanagement,whenyoudonothaveextensive
dataaboutquerymemoryusage,todetermineiftheclusterperformsbetteroverallifthrottlingisappliedtoImpala
queries.
Foraworkloadwithmanysmallqueries,youtypicallyspecifyahighvalueforthissetting,orleavethedefaultsetting
ofâunlimitedâ.Foraworkloadwithexpensivequeries,wheresomenumberofconcurrentqueriessaturatethe
memory,I/O,CPU,ornetworkcapacityofthecluster,setthevaluelowenoughthattheclusterresourcesarenot
overcommittedforImpala.
Onceyouhaveenabledmemory-basedadmission controlusingotherpoolsettings,youcanstilluseMaxRunning
Queriesasasafeguard.Ifqueriesexceedeitherthetotalestimatedmemoryorthemaximumnumberofconcurrent
queries,theyareaddedtothequeue.
MaxQueuedQueries
Maximumnumberofqueriesthatcanbequeuedinthispool.Thedefaultvalueis200forCDH5.3orhigherand
50forpreviousversionsofImpala.(optional)
QueueTimeout
Theamountoftime,inmilliseconds,thataquerywaitsintheadmission controlqueueforthispoolbeforebeing
canceled.Thedefaultvalueis60,000milliseconds.
Inthefollowingcases,QueueTimeoutisnotsignificant,andyoucanspecifyahighvaluetoavoidcancelingqueries
unexpectedly:
â¢Inalow-concurrencyworkloadwherefewornoqueriesarequeued
â¢InanenvironmentwithoutastrictSLA,whereitdoesnotmatterifqueriesoccasionallytakelongerthanusual
becausetheyareheldinadmission control
YoumightalsoneedtoincreasethevaluetouseImpalawithsomebusinessintelligencetoolsthathavetheirown
timeoutintervalsforqueries.
Inahigh-concurrencyworkload,especially forquerieswithatightSLA,longwaittimesinadmission controlcan
causeaseriousproblem.Forexample,ifaqueryneedstorunin10seconds,andyouhavetuneditsothatitruns
in8seconds,itviolatesitsSLAifitwaitsintheadmission controlqueuelongerthan2seconds.Inacaselikethis,
setalowtimeoutvalueandmonitorhowmanyqueriesarecancelledbecauseoftimeouts. Thistechnique helps
youtodiscovercapacity,tuning,andscalingproblemsearly,andhelpsavoidwastingresourcesbyrunningexpensive
queriesthathavealreadymissedtheirSLA.
Ifyouidentifysomequeriesthatcanhaveahightimeoutvalue,andothersthatbenefitfromalowtimeoutvalue,
youcancreateseparatepoolswithdifferentvaluesforthissetting.
Youcancombinethesesettingswiththememory-basedapproachdescribed inMemoryLimitsandAdmission Control
onpage550.Ifeitherthemaximumnumberofortheexpectedmemoryusageoftheconcurrentqueriesisexceeded,
subsequentqueriesarequeueduntiltheconcurrentworkloadfallsbelowthethresholdagain.
MemoryLimitsandAdmission Control
Eachdynamicresourcepoolcanhaveanupperlimitonthecluster-widememoryusedbyqueriesexecutinginthat
pool.
Usethefollowingsettingstomanagememory-basedadmission control.
550|ApacheImpalaGuideResourceManagement
MaxMemory
Themaximumamountofaggregatememoryavailableacrosstheclustertoallqueriesexecutinginthispool.This
shouldbeaportionoftheaggregateconfiguredmemoryforImpaladaemons, whichwillbeshowninthesettings
dialognexttothisoptionforconvenience.Settingthistoanon-zerovalueenablesmemorybasedadmission control.
Impaladeterminestheexpectedmaximummemoryusedbyallqueriesinthepoolandholdsbackanyfurther
queriesthatwouldresultinMaxMemorybeingexceeded.
IfyouspecifyMaxMemory,youshouldspecifytheamountofmemorytoallocatetoeachqueryinthispool.You
candothisintwoways:
â¢BysettingMaximumQueryMemoryLimitandMinimum QueryMemoryLimit.ThisispreferredinCDH6.1
/Impala3.1andgreaterandgivesImpalaflexibilitytosetasidemorememorytoqueriesthatareexpectedto
bememory-hungry.
â¢BysettingDefaultQueryMemoryLimittotheexactamountofmemorythatImpalashouldsetasideforqueries
inthatpool.
Notethatinthefollowingcases,Impalawillrelyentirelyonmemoryestimatestodeterminehowmuchmemory
tosetasideforeachquery.Thisisnotrecommended becauseitcanresultinqueriesnotrunningorbeingstarved
formemoryiftheestimatesareinaccurate.Anditcanaffectotherqueriesrunningonthesamenode.
â¢MaxMemory,MaximumQueryMemoryLimit,andMinimum QueryMemoryLimitarenotset,andthe
MEM_LIMIT queryoptionisnotsetforthequery.
â¢DefaultQueryMemoryLimitissetto0,andtheMEM_LIMIT queryoptionisnotsetforthequery.
Minimum QueryMemoryLimitandMaximumQueryMemoryLimit
Thesetwooptionsdeterminetheminimum andmaximumper-hostmemorylimitthatwillbechosenbyImpala
Admission controlforqueriesinthisresourcepool.Ifset,Impalaadmission controlwillchooseamemorylimit
betweentheminimum andmaximumvaluesbasedontheper-hostmemoryestimateforthequery.Thememory
limitchosendeterminestheamountofmemorythatImpalaadmission controlwillsetasideforthisqueryoneach
hostthatthequeryisrunningon.Theaggregatememoryacrossallofthehoststhatthequeryisrunningonis
countedagainstthepoolâsMaxMemory.
Minimum QueryMemoryLimitmustbelessthanorequaltoMaximumQueryMemoryLimitandMaxMemory.
AusercanoverrideImpalaâschoiceofmemorylimitbysettingtheMEM_LIMIT queryoption.IftheClampMEM_LIMIT
QueryOptionsettingissettoTRUEandtheusersetsMEM_LIMIT toavaluethatisoutsideoftherangespecified
bythesetwooptions,thentheeffectivememorylimitwillbeeithertheminimum ormaximum,depending on
whetherMEM_LIMIT islowerthanorhighertherange.
Forexample,assumearesourcepoolwiththefollowingparametersset:
â¢Minimum QueryMemoryLimit=2GB
â¢MaximumQueryMemoryLimit=10GB
IfausertriestosubmitaquerywiththeMEM_LIMIT queryoptionsetto14GB,thefollowingwouldhappen:
â¢IfClampMEM_LIMIT QueryOption=true,admission controllerwouldoverrideMEM_LIMIT with10GBand
attemptadmission usingthatvalue.
â¢IfClampMEM_LIMIT QueryOption=false,theadmission controllerwillretaintheMEM_LIMIT of14GBset
bytheuserandwillattemptadmission usingthevalue.
DefaultQueryMemoryLimit
ThedefaultmemorylimitappliedtoqueriesexecutinginthispoolwhennoexplicitMEM_LIMIT queryoptionisset.
ThememorylimitchosendeterminestheamountofmemorythatImpalaAdmission controlwillsetasideforthis
queryoneachhostthatthequeryisrunningon.Theaggregatememoryacrossallofthehoststhatthequeryis
runningoniscountedagainstthepoolâsMaxMemory.ThisoptionisdeprecatedinCDH6.1/Impala3.1andhigher
andisreplacedbyMaximumQueryMemoryLimitandMinimum QueryMemoryLimit.
DonotsetthisifeitherMaximumQueryMemoryLimitorMinimum QueryMemoryLimitisset.
ApacheImpalaGuide|551ResourceManagement
ClampMEM_LIMIT QueryOption
Ifthisfieldisnotselected,theMEM_LIMIT queryoptionwillnotbebounded bytheMaximumQueryMemory
LimitandtheMinimum QueryMemoryLimitvaluesspecified forthisresourcepool.Bydefault,thisfieldisselected
inCDH6.1andhigher.ThefieldisdisabledifbothMinimum QueryMemoryLimitandMaximumQueryMemory
Limitarenotset.
Forexample,considerthefollowingscenario:
â¢Theclusterisrunningimpalad daemons onfivehosts.
â¢AdynamicresourcepoolhasMaxMemorysetto100GB.
â¢TheMaximumQueryMemoryLimitforthepoolis10GBandMinimum QueryMemoryLimitis2GB.Therefore,
anyqueryrunninginthispoolcoulduseupto50GBofmemory(MaximumQueryMemoryLimit*numberof
Impalanodes).
â¢Impalawillexecutevaryingnumbersofqueriesconcurrentlybecausequeriesmaybegivenmemorylimitsanywhere
between2GBand10GB,depending ontheestimatedmemoryrequirements.Forexample,Impalamayexecute
upto10smallquerieswith2GBmemorylimitsortwolargequerieswith10GBmemorylimitsbecausethatis
whatwillfitinthe100GBcluster-widelimitwhenexecutingonfivehosts.
â¢Theexecutingqueriesmayuselessmemorythantheper-hostmemorylimitortheMaxMemorycluster-wide
limitiftheydonotneedthatmuchmemory.Ingeneralthisisnotaproblemsolongasyouareabletoexecute
enoughqueriesconcurrentlytomeetyourneeds.
Youcancombinethememory-basedsettingswiththeupperlimitonconcurrentqueriesdescribed inConcurrent
QueriesandAdmission Controlonpage549.Ifeitherthemaximumnumberofortheexpectedmemoryusageofthe
concurrentqueriesisexceeded,subsequentqueriesarequeueduntiltheconcurrentworkloadfallsbelowthethreshold
again.
HowImpalaAdmission ControlRelatestoOtherResourceManagementTools
Theadmission controlfeatureissimilarinsomewaystotheClouderaManagerstaticpartitioning feature,aswellas
theYARNresourcemanagementframework.Thesefeaturescanbeusedseparatelyortogether.Thissectiondescribes
somesimilarities anddifferences,tohelpyoudecidewhichcombinationofresourcemanagementfeaturestousefor
Impala.
Admission controlisalightweight,decentralizedsystemthatissuitableforworkloadsconsistingprimarily ofImpala
queriesandotherSQLstatements.ItsetsâsoftâlimitsthatsmoothoutImpalamemoryusageduringtimesofheavy
load,ratherthantakinganall-or-nothing approachthatcancelsjobsthataretooresource-intensive.
Becausetheadmission controlsystemdoesnotinteractwithotherHadoopworkloadssuchasMapReducejobs,you
mightuseYARNwithstaticservicepoolsonCDHclusterswhereresourcesaresharedbetweenImpalaandother
Hadoopcomponen ts.Thisconfigurationisrecommended whenusingImpalainamultitenantcluster.Devotea
percentageofclusterresourcestoImpala,andallocateanotherpercentageforMapReduceandotherbatch-style
workloads. Letadmission controlhandletheconcurrencyandmemoryusagefortheImpalaworkwithinthecluster,
andletYARNmanagetheworkforothercomponen tswithinthecluster.Inthisscenario,Impala'sresourcesarenot
managedbyYARN.
TheImpalaadmission controlfeatureusesthesameconfigurationmechanism astheYARNresourcemanagertomap
userstopoolsandauthenticatethem.
Although theImpalaadmission controlfeatureusesafair-scheduler.xml configurationfilebehindthescenes,
thisfiledoesnotdependonwhichscheduler isusedforYARN.Youstillusethisfile,andClouderaManagercangenerate
itforyou,evenwhenYARNisusingthecapacityscheduler .
HowImpalaSchedules andEnforcesLimitsonConcurrentQueries
Theadmission controlsystemisdecentralized,embedded ineachImpaladaemonandcommunic atingthroughthe
statestoremechanism. Although thelimitsyousetformemoryusageandnumberofconcurrentqueriesapply
cluster-wide,eachImpaladaemonmakesitsowndecisions aboutwhethertoalloweachquerytorunimmediatelyor
toqueueitforaless-busytime.Thesedecisions arefast,meaningtheadmission controlmechanism islow-overhead,
butmightbeimpreciseduringtimesofheavyloadacrossmanycoordinators.Therecouldbetimeswhenthemore
552|ApacheImpalaGuideResourceManagement
querieswerequeued(inaggregateacrossthecluster)thanthespecified limit,orwhennumberofadmittedqueries
exceedstheexpectednumber.Thus,youtypicallyerronthehighsideforthesizeofthequeue,becausethereisnot
abigpenaltyforhavingalargenumberofqueuedqueries;andyoutypicallyerronthelowsideforconfiguringmemory
resources,toleavesomeheadroomincasemorequeriesareadmittedthanexpected,withoutrunningoutofmemory
andbeingcancelledasaresult.
Toavoidalargebacklogofqueuedrequests,youcansetanupperlimitonthesizeofthequeueforqueriesthatare
queued.Whenthenumberofqueuedqueriesexceedsthislimit,furtherqueriesarecancelledratherthanbeingqueued.
Youcanalsoconfigureatimeoutperiodperpool,afterwhichqueuedqueriesarecancelled, toavoidindefinitewaits.
Ifaclusterreachesthisstatewherequeriesarecancelledduetotoomanyconcurrentrequestsorlongwaitsforquery
executiontobegin,thatisasignalforanadministratortotakeaction,eitherbyprovisioningmoreresources,scheduling
workontheclustertosmoothouttheload,orbydoingImpalaperformance tuningtoenablehigherthroughput.
HowAdmission ControlworkswithImpalaClients(JDBC,ODBC,HiveServer2)
Mostaspectsofadmission controlworktransparentlywithclientinterfacessuchasJDBCandODBC:
â¢IfaSQLstatementisputintoaqueueratherthanrunningimmediately,theAPIcallblocksuntilthestatementis
dequeued andbeginsexecution.Atthatpoint,theclientprogramcanrequesttofetchresults,whichmightalso
blockuntilresultsbecomeavailable.
â¢IfaSQLstatementiscancelledbecauseithasbeenqueuedfortoolongorbecauseitexceededthememorylimit
duringexecution,theerrorisreturnedtotheclientprogramwithadescriptiveerrormessage.
InImpala2.0andhigher,youcansubmitaSQLSETstatementfromtheclientapplicationtochangetheREQUEST_POOL
queryoption.Thisoptionletsyousubmitqueriestodifferentresourcepools,asdescribed inREQUEST_POOLQuery
Optiononpage355.
Atanytime,thesetofqueuedqueriescouldincludequeriessubmittedthroughmultipledifferentImpaladaemon
hosts.Allthequeriessubmittedthroughaparticular hostwillbeexecutedinorder,soaCREATE TABLE followedby
anINSERTonthesametablewouldsucceed. Queriessubmittedthroughdifferenthostsarenotguaranteedtobe
executedintheordertheywerereceived.Therefore,ifyouareusingload-balancing orotherround-robinscheduling
wheredifferentstatementsaresubmittedthroughdifferenthosts,setupalltablestructuresaheadoftimesothat
thestatementscontrolledbythequeuingsystemareprimarily queries,whereorderisnotsignificant.Or,ifasequence
ofstatementsneedstohappeninstrictorder(suchasanINSERTfollowedbyaSELECT),submitallthosestatements
throughasinglesession,whileconnectedtothesameImpaladaemonhost.
Admission controlhasthefollowinglimitationsorspecialbehaviorwhenusedwithJDBCorODBCapplications:
â¢Theotherresource-relatedqueryoptions,RESERVATION_REQUEST_TIMEOUT andV_CPU_CORES ,arenolonger
used.ThosequeryoptionsonlyappliedtousingImpalawithLlama,whichisnolongersupported.
SQLandSchemaConsiderationsforAdmission Control
Whenqueriescompletequicklyandaretunedforoptimalmemoryusage,thereislesschanceofperformance or
capacityproblemsduringtimesofheavyload.Beforesettingupadmission control,tuneyourImpalaqueriestoensure
thatthequeryplansareefficientandthememoryestimatesareaccurate.Understandingthenatureofyourworkload,
andwhichqueriesarethemostresource-intensive,helpsyoutoplanhowtodividethequeriesintodifferentpools
anddecidewhatlimitstodefineforeachpool.
Forlargetables,especially thoseinvolvedinjoinqueries,keeptheirstatisticsuptodateafterloadingsubstantial
amountsofnewdataoraddingnewpartitions. UsetheCOMPUTE STATS statementforunpartitioned tables,and
COMPUTE INCREMENTAL STATS forpartitioned tables.
WhenyouusedynamicresourcepoolswithaMaxMemorysettingenabled, youtypicallyoverridethememory
estimatesthatImpalamakesbasedonthestatisticsfromtheCOMPUTE STATS statement.YoueithersettheMEM_LIMIT
queryoptionwithinaparticular sessiontosetanuppermemorylimitforquerieswithinthatsession,oradefault
MEM_LIMIT settingforallqueriesprocessedbytheimpalad instance,oradefaultMEM_LIMIT settingforallqueries
assignedtoaparticular dynamicresourcepool.Bydesignatingaconsistentmemorylimitforasetofsimilarqueries
thatusethesameresourcepool,youavoidunnecessar yqueryqueuingorout-of-memor yconditions thatcanarise
duringhigh-concurrencyworkloadswhenmemoryestimatesforsomequeriesareinaccurate.
ApacheImpalaGuide|553ResourceManagement
FollowotherstepsfromTuningImpalaforPerformance onpage565totuneyourqueries.
Guidelines forUsingAdmission Control
Thelimitsimposedbyadmission controlarede-centrallymanagedâsoftâlimits.EachImpalacoordinatornodemakes
itsowndecisions aboutwhethertoallowqueriestorunimmediatelyortoqueuethem.Thesedecisions relyon
informationpassedbackandforthbetweennodesbytheStateStoreservice.Ifasuddensurgeinrequestscausesmore
queriesthananticipatedtorunconcurrently,thenthethroughputcoulddecreaseduetoqueriesspillingtodiskor
contendingforresources.OrqueriescouldbecancellediftheyexceedtheMEM_LIMIT settingwhilerunning.
Inimpala-shell ,youcanalsospecifywhichresourcepooltodirectqueriestobysettingtheREQUEST_POOL query
option.
Ifyousetupdifferentresourcepoolsfordifferentusersandgroups,considerreusinganyclassificationsyoudeveloped
forusewithSentrysecurity.SeeEnablingSentryAuthorizationforImpalaonpage87fordetails.
Wherepractical,useClouderaManagertoconfiguretheadmission controlparameters.TheClouderaManagerGUIis
muchsimplerthaneditingtheconfigurationfilesdirectly.
Toseehowadmission controlworksforparticular queries,examinetheprofileoutputorthesummaryoutputforthe
query.
â¢Profile
TheinformationisavailablethroughthePROFILE statementinimpala-shell immediatelyafterrunningaquery
intheshell,onthequeriespageoftheImpaladebugwebUI,orintheImpalalogfile(basicinformationatlog
level1,moredetailedinformationatloglevel2).
Theprofileoutputcontainsdetailsabouttheadmission decision, suchaswhetherthequerywasqueuedornot
andwhichresourcepoolitwasassignedto.Italsoincludestheestimatedandactualmemoryusageforthequery,
soyoucanfine-tune theconfigurationforthememorylimitsoftheresourcepools.
â¢Summary
StartinginCDH6.1,theinformationisavailableinimpala-shell whentheLIVE_PROGRESS orLIVE_SUMMARY
queryoptionissettoTRUE.
Youcanalsostartanimpala-shell sessionwiththe--live_progress or--live_summary flagstomonitor
allqueriesinthatimpala-shell session.
Thesummaryoutputincludesthequeuingstatusconsistingofwhetherthequerywasqueuedandwhatwasthe
latestqueuingreason.
FordetailsaboutalltheFairScheduler configurationsettings,seeFairScheduler Configuration,inparticular thetags
suchas<queue> and<aclSubmitApps> tomapusersandgroupstoparticular resourcepools(queues).
ConfiguringResourcePoolsandAdmission Control
ImpalaincludesfeaturesthatbalanceandmaximizeresourcesinyourCDHcluster.Thistopicdescribes howyoucan
improveefficiencyofyouraCDHclusterusingthosefeatures.
Atypicaldeploymentusesthefollowing:
â¢CreatingStaticServicePools
â¢UsingAdmission Control
âSettingPer-queryMemoryLimits
âCreatingDynamicResourcePools
554|ApacheImpalaGuideResourceManagement
CreatingStaticServicePools
Tomanageandprioritizeworkloadsonclusters,usethestaticservicepoolstoallocatededicatedresourcesforImpala
forpredictableresourceavailability.Whenstaticservicepoolsareused,ClouderaManagercreatesacgroupinwhich
Impalaruns.Thiscgrouplimitsmemory,CPUandDiskI/Oaccordingtothestaticpartitioning policy.
ThefollowingisasampleconfigurationforStaticServicePoolsshowninClouderaManager.
â¢HDFSalwaysneedstohaveaminimum of5-10%oftheresources.
â¢Generally,YARNandImpalasplittherestoftheresources.
âFormostlybatchworkloads, youmightallocateYARN60%,Impala30%,andHDFS10%.
âFormostlyad-hocqueryworkloads, youmightallocateImpala60%,YARN30%,andHDFS10%.
UsingAdmission Control
Withintheconstraintsofthestaticservicepool,usingdynamicresourcepoolsandtheadmission control,youcan
furthersubdivide Impala'sresourceusageamongdynamicresourcepoolsinmultitenantusecases.
Allocatingresourcesjudiciously allowsyourmostimportantqueriestorunfasterandmorereliably.
Note:ImpaladynamicresourcepoolsaredifferentthanthedefaultYARNdynamicresourcepools.
YoucanturnondynamicresourcepoolsthatareexclusivelyforusebyImpala.
EnablingorDisabling ImpalaAdmission ControlinClouderaManager
Werecommend enablingadmission controlonallproduction clusterstoalleviatepossiblecapacityissues.Thecapacity
issuescouldbebecauseofahighvolumeofconcurrentqueries,becauseofheavy-dutyjoinandaggregationqueries
thatrequirelargeamountsofmemory,orbecauseImpalaisbeingusedalongside otherHadoopdatamanagement
componen tsandtheresourceusageofImpalamustbeconstrainedtoworkwellinamultitenantdeployment.
Important:
InCDH5.8andhigher,admission controlanddynamicresourcepoolsareenabledbydefault.However,
untilyouconfigurethesettingsforthedynamicresourcepools,theadmission controlfeatureis
effectivelynotenabledas,withthedefaultthesettings,eachdynamicpoolwillallowallqueriesof
anymemoryrequirementtoexecuteinthepool.
1.GototheImpalaservice.
ApacheImpalaGuide|555ResourceManagement
2.IntheConfigurationtab,selectCategory>Admission Control.
3.SelectorclearboththeEnableImpalaAdmission ControlcheckboxandtheEnableDynamic ResourcePools
checkbox.
4.EnteraReasonforchange,andthenclickSaveChangestocommitthechanges.
5.RestarttheImpalaservice.
Aftercompletingthistask,forfurtherconfigurationsettings,customizetheconfigurationsettingsforthedynamic
resourcepools,asdescribed inbelow.
CreatinganImpalaDynamicResourcePool
Thereisalwaysaresourcepooldesignatedasroot.default .Bydefault,allImpalaqueriesruninthispoolwhenthe
dynamicresourcepoolfeatureisenabledforImpala.Youcreateadditional poolswhenyourworkloadincludes
identifiablegroupsofqueries(suchasfromaparticular application,oraparticular groupwithinyourorganization)
thathavetheirownrequirementsforconcurrency,memoryuse,orservicelevelagreement(SLA).Eachpoolhasits
ownsettingsrelatedtomemory,numberofqueries,andtimeoutinterval.
1.SelectClusters>Clustername>Dynamic ResourcePoolConfiguration.IftheclusterhasanImpalaservice,the
ResourcePoolstabdisplaysundertheImpalaAdmission Controltab.
2.ClicktheImpalaAdmission Controltab.
3.ClickCreateResourcePool.
4.Specifyanameandresourcelimitsforthepool:
â¢IntheResourcePoolNamefield,typeauniquenamecontainingonlyalphanumeric characters.
â¢Optionally,clicktheSubmission AccessControltabtospecifywhichusersandgroupscansubmitqueries.
Bydefault,anyonecansubmitqueries.Torestrictthispermission, selecttheAllowtheseusersandgroups
optionandprovideacomma-delimit edlistofusersandgroupsintheUsersandGroupsfieldsrespectively.
5.ClickCreate.
6.ClickRefreshDynamic ResourcePools.
ConfigurationSettingsforImpalaDynamicResourcePool
Impaladynamicresourcepoolssupportthefollowingsettings.
MaxMemory
Maximumamountofaggregatememoryavailableacrosstheclustertoallqueriesexecutinginthispool.Thisshould
beaportionoftheaggregateconfiguredmemoryforImpaladaemons, whichwillbeshowninthesettingsdialog
nexttothisoptionforconvenience.Settingthistoanon-zerovalueenablesmemorybasedadmission control.
Impaladeterminestheexpectedmaximummemoryusedbyallqueriesinthepoolandholdsbackanyfurther
queriesthatwouldresultinMaxMemorybeingexceeded.
IfyouspecifyMaxMemory,youshouldspecifytheamountofmemorytoallocatetoeachqueryinthispool.You
candothisintwoways:
â¢BysettingMaximumQueryMemoryLimitandMinimum QueryMemoryLimit.ThisispreferredinCDH6.1
andhigherandgivesImpalaflexibilitytosetasidemorememorytoqueriesthatareexpectedtobe
memory-hungry.
â¢BysettingDefaultQueryMemoryLimittotheexactamountofmemorythatImpalashouldsetasideforqueries
inthatpool.
Notethatifyoudonotsetanyoftheaboveoptions,orsetDefaultQueryMemoryLimitto0,Impalawillrely
entirelyonmemoryestimatestodeterminehowmuchmemorytosetasideforeachquery.Thisisnotrecommended
becauseitcanresultinqueriesnotrunningorbeingstarvedformemoryiftheestimatesareinaccurate.
Forexample,considerthefollowingscenario:
â¢Theclusterisrunningimpalad daemons onfivehosts.
â¢AdynamicresourcepoolhasMaxMemorysetto100GB.
556|ApacheImpalaGuideResourceManagement
â¢TheMaximumQueryMemoryLimitforthepoolis10GBandMinimum QueryMemoryLimitis2GB.Therefore,
anyqueryrunninginthispoolcoulduseupto50GBofmemory(MaximumQueryMemoryLimit*number
ofImpalanodes).
â¢Impalawillexecutevaryingnumbersofqueriesconcurrentlybecausequeriesmaybegivenmemorylimits
anywherebetween2GBand10GB,depending ontheestimatedmemoryrequirements.Forexample,Impala
mayexecuteupto10smallquerieswith2GBmemorylimitsortwolargequerieswith10GBmemorylimits
becausethatiswhatwillfitinthe100GBcluster-widelimitwhenexecutingonfivehosts.
â¢Theexecutingqueriesmayuselessmemorythantheper-hostmemorylimitortheMaxMemorycluster-wide
limitiftheydonotneedthatmuchmemory.Ingeneralthisisnotaproblemsolongasyouareabletoexecute
enoughqueriesconcurrentlytomeetyourneeds.
Minimum QueryMemoryLimitandMaximumQueryMemoryLimit
Thesetwooptionsdeterminetheminimum andmaximumper-hostmemorylimitthatwillbechosenbyImpala
Admission controlforqueriesinthisresourcepool.Ifset,Impalaadmission controlwillchooseamemorylimit
betweentheminimum andmaximumvaluebasedontheper-hostmemoryestimateforthequery.Thememory
limitchosendeterminestheamountofmemorythatImpalaadmission controlwillsetasideforthisqueryoneach
hostthatthequeryisrunningon.Theaggregatememoryacrossallofthehoststhatthequeryisrunningonis
countedagainstthepoolâsMaxMemory.
Minimum QueryMemoryLimitmustbelessthanorequaltoMaximumQueryMemoryLimitandMaxMemory.
YoucanoverrideImpalaâschoiceofmemorylimitbysettingtheMEM_LIMIT queryoption.IftheClampMEM_LIMIT
QueryOptionisselectedandtheusersetsMEM_LIMIT toavaluethatisoutsideoftherangespecified bythese
twooptions,thentheeffectivememorylimitwillbeeithertheminimum ormaximum,depending onwhether
MEM_LIMIT islowerthanorhigherthantherange.
DefaultQueryMemoryLimit
ThedefaultmemorylimitappliedtoqueriesexecutinginthispoolwhennoexplicitMEM_LIMIT queryoptionisset.
ThememorylimitchosendeterminestheamountofmemorythatImpalaAdmission controlwillsetasideforthis
queryoneachhostthatthequeryisrunningon.Theaggregatememoryacrossallofthehoststhatthequeryis
runningoniscountedagainstthepoolâsMaxMemory.
ThisoptionisdeprecatedfromCDH6.1andhigherandisreplacedbyMaximumQueryMemoryLimitandMinimum
QueryMemoryLimit.DonotsetthisfieldifeitherMaximumQueryMemoryLimitorMinimum QueryMemory
Limitisset.
MaxRunningQueries
Maximumnumberofconcurrentlyrunningqueriesinthispool.ThedefaultvalueisunlimitedforCDH5.7orhigher.
(optional)
Themaximumnumberofqueriesthatcanrunconcurrentlyinthispool.Thedefaultvalueisunlimited.Anyqueries
forthispoolthatexceedMaxRunningQueriesareaddedtotheadmission controlqueueuntilotherqueriesfinish.
YoucanuseMaxRunningQueriesintheearlystagesofresourcemanagement,whenyoudonothaveextensive
dataaboutquerymemoryusage,todetermineiftheclusterperformsbetteroverallifthrottlingisappliedtoImpala
queries.
Foraworkloadwithmanysmallqueries,youtypicallyspecifyahighvalueforthissetting,orleavethedefaultsetting
ofâunlimitedâ.Foraworkloadwithexpensivequeries,wheresomenumberofconcurrentqueriessaturatethe
memory,I/O,CPU,ornetworkcapacityofthecluster,setthevaluelowenoughthattheclusterresourcesarenot
overcommittedforImpala.
Onceyouhaveenabledmemory-basedadmission controlusingotherpoolsettings,youcanstilluseMaxRunning
Queriesasasafeguard.Ifqueriesexceedeitherthetotalestimatedmemoryorthemaximumnumberofconcurrent
queries,theyareaddedtothequeue.
MaxQueuedQueries
Maximumnumberofqueriesthatcanbequeuedinthispool.Thedefaultvalueis200forCDH5.3orhigherand
50forpreviousversionsofImpala.(optional)
ApacheImpalaGuide|557ResourceManagement
QueueTimeout
Theamountoftime,inmilliseconds,thataquerywaitsintheadmission controlqueueforthispoolbeforebeing
canceled.Thedefaultvalueis60,000milliseconds.
Itthefollowingcases,QueueTimeoutisnotsignificant,andyoucanspecifyahighvaluetoavoidcancelingqueries
unexpectedly:
â¢Inalow-concurrencyworkloadwherefewornoqueriesarequeued
â¢InanenvironmentwithoutastrictSLA,whereitdoesnotmatterifqueriesoccasionallytakelongerthanusual
becausetheyareheldinadmission control
YoumightalsoneedtoincreasethevaluetouseImpalawithsomebusinessintelligencetoolsthathavetheirown
timeoutintervalsforqueries.
Inahigh-concurrencyworkload,especially forquerieswithatightSLA,longwaittimesinadmission controlcan
causeaseriousproblem.Forexample,ifaqueryneedstorunin10seconds,andyouhavetuneditsothatitruns
in8seconds,itviolatesitsSLAifitwaitsintheadmission controlqueuelongerthan2seconds.Inacaselikethis,
setalowtimeoutvalueandmonitorhowmanyqueriesarecancelledbecauseoftimeouts. Thistechnique helps
youtodiscovercapacity,tuning,andscalingproblemsearly,andhelpsavoidwastingresourcesbyrunningexpensive
queriesthathavealreadymissedtheirSLA.
Ifyouidentifysomequeriesthatcanhaveahightimeoutvalue,andothersthatbenefitfromalowtimeoutvalue,
youcancreateseparatepoolswithdifferentvaluesforthissetting.
ClampMEM_LIMIT QueryOption
Ifthisfieldisnotselected,theMEM_LIMIT queryoptionwillnotbebounded bytheMaximumQueryMemory
LimitandtheMinimum QueryMemoryLimitvaluesspecified forthisresourcepool.Bydefault,thisfieldisselected
inCDH6.1andhigher.ThefieldisdisabledifbothMinimum QueryMemoryLimitandMaximumQueryMemory
Limitarenotset.
SettingPer-queryMemoryLimits
Useper-querymemorylimitstopreventqueriesfromconsuming excessivememoryresourcesthatimpactother
queries.Clouderarecommends thatyousetthequerymemorylimitswheneverpossible.
IfyousettheMaxMemoryforaresourcepool,Impalaattemptstothrottlequeriesifthereisnotenoughmemoryto
runthemwithinthespecified resources.
Onlyuseadmission controlwithmaximummemoryresourcesifyoucanensuretherearequerymemorylimits.Set
thepoolMaximumQueryMemoryLimittobecertain.YoucanoverridethissettingwiththeMEM_LIMIT queryoption,
ifnecessary.
Typically,yousetquerymemorylimitsusingtheset MEM_LIMIT=Xg; queryoption.Whenyoufindtherightvalue
foryourbusinesscase,memory-basedadmission controlworkswell.Thepotentialdownsideisthatqueriesthat
attempttousemorememorymightperformpoorlyorevenbecancelled.
Tofindareasonable MaximumQueryMemoryLimit:
1.Runtheworkload.
2.InClouderaManager,gotoImpala>Queries.
3.ClickSelectAttributes.
4.SelectPerNodePeakMemoryUsageandclickUpdate.
5.Allowthesystemtimetogatherinformation,thenclicktheShowHistogramicontoseetheresults.
558|ApacheImpalaGuideResourceManagement
6.Usethehistogramtofindavaluethataccountsformostqueries.Queriesthatrequiremoreresourcesthanthis
limitshouldexplicitlysetthememorylimittoensuretheycanruntocompletion.
ConfiguringAdmission ControlinCommand LineInterface
Toconfigureadmission control,useacombinationofstartupoptionsfortheImpaladaemonandeditorcreatethe
configurationfilesfair-scheduler.xml andllama-site.xml .
Forastraightforwardconfigurationusingasingleresourcepoolnameddefault ,youcanspecifyconfigurationoptions
onthecommand lineandskipthefair-scheduler.xml andllama-site.xml configurationfiles.
Foranadvancedconfigurationwithmultipleresourcepoolsusingdifferentsettings:
1.Setupthefair-scheduler.xml andllama-site.xml configurationfilesmanually.
2.Providethepathstoeachoneusingtheimpalad command-line options,--fair_scheduler_allocation_path
and--llama_site_path respectively.
TheImpalaadmission controlfeatureonlyusestheFairScheduler configurationsettingstodeterminehowtomap
usersandgroupstodifferentresourcepools.Forexample,youmightsetupdifferentresourcepoolswithseparate
memorylimits,andmaximumnumberofconcurrentandqueuedqueries,fordifferentcategoriesofuserswithinyour
organization.FordetailsaboutalltheFairScheduler configurationsettings,seetheApachewiki.
TheImpalaadmission controlfeatureonlyusesasmallsubsetofpossiblesettingsfromthellama-site.xml
configurationfile:
llama.am.throttling.maximum.placed.reservations. queue_name
llama.am.throttling.maximum.queued.reservations. queue_name
impala.admission-control.pool-default-query-options. queue_name
impala.admission-control.pool-queue-timeout-ms. queue_name
Theimpala.admission-control.pool-queue-timeout-ms settingspecifiesthetimeoutvalueforthispool,in
milliseconds.
Theimpala.admission-control.pool-default-query-options settingsdesignatesthedefaultqueryoptions
forallqueriesthatruninthispool.Itsargumentvalueisacomma-delimit edstringof'key=value'pairs,for
example,'key1=val1,key2=val2' .Forexample,thisiswhereyoumightsetadefaultmemorylimitforallqueries
inthepool,usinganargumentsuchasMEM_LIMIT=5G .
Theimpala.admission-control.* configurationsettingsareavailableinCDH5.7/Impala2.5andhigher.
ExampleAdmission ControlConfigurationFiles
ForclustersnotmanagedbyClouderaManager,herearesamplefair-scheduler.xml andllama-site.xml files
thatdefineresourcepoolsroot.default ,root.development ,androot.production .Thesefilesdefineresource
poolsforImpalaadmission controlandareseparatefromthesimilarfair-scheduler.xml thatdefinesresource
poolsforYARN.
fair-scheduler .xml:
Although Impaladoesnotusethevcoresvalue,youmuststillspecifyittosatisfyYARNrequirementsforthefile
contents.
Each<aclSubmitApps> tag(otherthantheoneforroot)containsacomma-separ atedlistofusers,thenaspace,
thenacomma-separ atedlistofgroups;thesearetheusersandgroupsallowedtosubmitImpalastatementstothe
corresponding resourcepool.
Ifyouleavethe<aclSubmitApps> elementemptyforapool,nobodycansubmitdirectlytothatpool;childpools
canspecifytheirown<aclSubmitApps> valuestoauthorizeusersandgroupstosubmittothosepools.
<allocations>
    <queue name="root">
        <aclSubmitApps> </aclSubmitApps>
        <queue name="default">
            <maxResources>50000 mb, 0 vcores</maxResources>
ApacheImpalaGuide|559ResourceManagement
            <aclSubmitApps>*</aclSubmitApps>
        </queue>
        <queue name="development">
            <maxResources>200000 mb, 0 vcores</maxResources>
            <aclSubmitApps>user1,user2 dev,ops,admin</aclSubmitApps>
        </queue>
        <queue name="production">
            <maxResources>1000000 mb, 0 vcores</maxResources>
            <aclSubmitApps> ops,admin</aclSubmitApps>
        </queue>
    </queue>
    <queuePlacementPolicy>
        <rule name="specified" create="false"/>
        <rule name="default" />
    </queuePlacementPolicy>
</allocations>
llama-site.xml:
<?xml version="1.0" encoding="UTF-8"?>
<configuration>
  <property>
    <name>llama.am.throttling.maximum.placed.reservations.root.default</name>
    <value>10</value>
  </property>
  <property>
    <name>llama.am.throttling.maximum.queued.reservations.root.default</name>
    <value>50</value>
  </property>
  <property>
    <name>impala.admission-control.pool-default-query-options.root.default</name>
    <value>mem_limit=128m,query_timeout_s=20,max_io_buffers=10</value>
  </property>
  <property>
    <name>impala.admission-control.pool-queue-timeout-ms.root.default</name>
    <value>30000</value>
  </property>
  <property>
    <name>impala.admission-control.max-query-mem-limit.root.default.regularPool</name>
    <value>1610612736</value><!--1.5GB-->
  </property>
  <property>
    <name>impala.admission-control.min-query-mem-limit.root.default.regularPool</name>
    <value>52428800</value><!--50MB-->
  </property>
  <property>
<name>impala.admission-control.clamp-mem-limit-query-option.root.default.regularPool</name>
    <value>true</value>
  </property>
ConfiguringCluster-wideAdmission Control
Important:Although thefollowingoptionsarestillpresentintheClouderaManagerinterfaceunder
theAdmission Controlconfigurationsettingsdialog,avoidusingtheminCDH5.7/Impala2.5and
higher.Thesesettingsonlyapplyifyouenableadmission controlbutleavedynamicresourcepools
disabled. InCDH5.7/Impala2.5andhigher,werecommend thatyousetupdynamicresourcepools
andcustomizethesettingsforeachpoolasdescribed inUsingAdmission Controlonpage555.
ThefollowingImpalaconfigurationoptionsletyouadjustthesettingsoftheadmission controlfeature.Whensupplying
theoptionsontheimpalad command line,prependtheoptionnamewith--.
queue_wait_timeout_ms
Purpose: Maximumamountoftime(inmilliseconds)thatarequestwaitstobeadmittedbeforetimingout.
560|ApacheImpalaGuideResourceManagement
Type:int64
Default:60000
default_pool_max_requests
Purpose: Maximumnumberofconcurrentoutstandingrequestsallowedtorunbeforeincomingrequestsare
queued.Becausethislimitappliescluster-wide,buteachImpalanodemakesindependen tdecisions torunqueries
immediatelyorqueuethem,itisasoftlimit;theoverallnumberofconcurrentqueriesmightbeslightlyhigher
duringtimesofheavyload.Anegativevalueindicatesnolimit.Ignorediffair_scheduler_config_path and
llama_site_path areset.
Type:int64
Default:-1,meaningunlimited(priortoCDH5.7/Impala2.5thedefaultwas200)
default_pool_max_queued
Purpose: Maximumnumberofrequestsallowedtobequeuedbeforerejectingrequests.Becausethislimitapplies
cluster-wide,buteachImpalanodemakesindependen tdecisions torunqueriesimmediatelyorqueuethem,itis
asoftlimit;theoverallnumberofqueuedqueriesmightbeslightlyhigherduringtimesofheavyload.Anegative
valueor0indicatesrequestsarealwaysrejectedoncethemaximumconcurrentrequestsareexecuting.Ignoredif
fair_scheduler_config_path andllama_site_path areset.
Type:int64
Default:unlimited
default_pool_mem_limit
Purpose: Maximumamountofmemory(acrosstheentirecluster)thatalloutstandingrequestsinthispoolcanuse
beforenewrequeststothispoolarequeued.Specified inbytes,megabytes,orgigabytesbyanumberfollowedby
thesuffixb(optional),m,org,eitheruppercaseorlowercase.Youcanspecifyfloating-pointvaluesformegabytes
andgigabytes,torepresentfractionalnumberssuchas1.5.Youcanalsospecifyitasapercentageofthephysical
memorybyspecifyingthesuffix%.0ornosettingindicatesnolimit.Defaultstobytesifnounitisgiven.Because
thislimitappliescluster-wide,buteachImpalanodemakesindependen tdecisions torunqueriesimmediatelyor
queuethem,itisasoftlimit;theoverallmemoryusedbyconcurrentqueriesmightbeslightlyhigherduringtimes
ofheavyload.Ignorediffair_scheduler_config_path andllama_site_path areset.
Note:ImpalareliesonthestatisticsproducedbytheCOMPUTE STATS statementtoestimate
memoryusageforeachquery.SeeCOMPUTE STATSStatementonpage219forguidelines about
howandwhentousethisstatement.
Type:string
Default:""(emptystring,meaningunlimited)
disable_pool_max_requests
Purpose: Disablesallper-poollimitsonthemaximumnumberofrunningrequests.
Type:Boolean
Default:false
disable_pool_mem_limits
Purpose: Disablesallper-poolmemlimits.
Type:Boolean
Default:false
fair_scheduler_allocation_path
Purpose: Pathtothefairscheduler allocationfile(fair-scheduler.xml ).
Type:string
ApacheImpalaGuide|561ResourceManagement
Default:""(emptystring)
Usagenotes:Admission controlonlyusesasmallsubsetofthesettingsthatcangointhisfile,asdescribed below.
FordetailsaboutalltheFairScheduler configurationsettings,seetheApachewiki.
llama_site_path
Purpose: Pathtotheconfigurationfileusedbyadmission control(llama-site.xml ).Ifset,
fair_scheduler_allocation_path mustalsobeset.
Type:string
Default:""(emptystring)
Usagenotes:Admission controlonlyusesafewofthesettingsthatcangointhisfile,asdescribed below.
Admission ControlSampleScenario
AnneChangisadministratorforanenterprisedatahubthatrunsanumberofworkloads, including Impala.
Annehasa20-nodeclusterthatusesClouderaManagerstaticpartitioning. BecauseoftheheavyImpalaworkload,
AnneneedstomakesureImpalagetsenoughresources.Whilethebestconfigurationvaluesmightnotbeknownin
advance,shedecidestostartbyallocating50%ofresourcestoImpala.Eachnodehas128GiBdedicatedtoeach
impalad.Impalahas2560GiBinaggregatethatcanbesharedacrosstheresourcepoolsshecreates.
Next,Annestudiestheworkloadinmoredetail.Aftersomeresearch,shemightchoosetorevisittheseinitialvalues
forstaticpartitioning.
TofigureouthowtofurtherallocateImpalaâsresources,Anneneedstoconsidertheworkloadsandusers,anddetermine
theirrequirements.ThereareafewmainsourcesofImpalaqueries:
â¢Largereportingqueriesexecutedbyanexternalprocess/tool.Thesearecriticalbusinessintelligencequeriesthat
areimportantforbusinessdecisions. Itisimportantthattheygettheresourcestheyneedtorun.Theretypically
arenotmanyofthesequeriesatagiventime.
â¢Frequent,smallqueriesgeneratedbyawebUI.Thesequeriesscanalimitedamountofdataanddonotrequire
expensivejoinsoraggregations.Thesequeriesareimportant,butnotascritical,perhapstheclienttriesresending
thequeryortheenduserrefreshesthepage.
â¢Occasionally,expertusersmightrunad-hocqueries.Thequeriescanvarysignificantlyintheirresource
requirements.WhileAnnewantsagoodexperience fortheseusers,itishardtocontrolwhattheydo(forexample,
submittinginefficientorincorrectqueriesbymistake).Annerestrictsthesequeriesbydefaultandtellsusersto
reachouttoheriftheyneedmoreresources.
Tosetupadmission controlforthisworkload,Annefirstrunstheworkloadsindependen tly,sothatshecanobserve
theworkloadâsresourceusageinClouderaManager.Iftheycouldnoteasilyberunmanually,buthadbeenruninthe
past,AnneusesthehistoryinformationfromClouderaManager.Itcanbehelpfultouseothersearchcriteria(for
example,user)toisolatequeriesbyworkload.AnneusestheClouderaManagerchartforPer-NodePeakMemory
usagetoidentifythemaximummemoryrequirementsforthequeries.
Fromthisdata,Anneobservesthefollowingaboutthequeriesinthegroupsabove:
â¢Largereportingqueriesuseupto32GiBpernode.Therearetypically1or2queriesrunningatatime.Onone
occasion,sheobservedthat3ofthesequerieswererunningconcurrently.Queriescantake3minutestocomplete.
â¢WebUI-generatedqueriesusebetween100MiBpernodetousuallylessthan4GiBpernodeofmemory,but
occasionally asmuchas10GiBpernode.Queriestake,onaverage,5seconds,andtherecanbeasmanyas140
incomingqueriesperminute.
â¢Annehaslittledataonadhocqueries,butsomearetrivial(approximately100MiBpernode),othersjoinseveral
tables(requiringafewGiBpernode),andoneusersubmittedahugecrossjoinofalltablesthatusedallsystem
resources(thatwaslikelyamistake).
Basedontheseobservations,Annecreatestheadmission controlconfigurationwiththefollowingpools:
562|ApacheImpalaGuideResourceManagement
XL_Reporting
Value Property
1280GiB MaxMemory
32GiB MaximumQueryMemoryLimit
32GiB Minimum QueryMemoryLimit
2 MaxRunningQueries
5minutes QueueTimeout
Thispoolisforlargereportingqueries.Tosupportrunning2queriesatatime,thepoolmemoryresourcesaresetto
1280GiB(aggregateclustermemory).Thisisfor2queries,eachwith32GiBpernode,across20nodes.Annesetsthe
poolâsMaximumQueryMemoryLimitto32GiBsothatnoqueryusesmorethan32GiBonanygivennode.Shesets
MaxRunningQueriesto2(thoughitisnotnecessaryshedoso).Sheincreasesthepoolâsqueuetimeoutto5minutes
incaseathirdquerycomesinandhastowait.Shedoesnotexpectmorethan3concurrentqueries,andshedoesnot
wantthemtowaitthatlonganyway,soshedoesnotincreasethequeuetimeout.Iftheworkloadincreasesinthe
future,shemightchoosetoadjusttheconfigurationorbuymorehardware.
HighThroughput_UI
Value Property
960GiB(inferred) MaxMemory
4GiB MaximumQueryMemoryLimit
2GiB Minimum QueryMemoryLimit
12 MaxRunningQueries
5minutes QueueTimeout
Thispoolisusedforthesmall,highthroughputqueriesgeneratedbythewebtool.AnnesetstheMaximumQuery
MemoryLimitto4GiBpernode,andsetsMaxRunningQueriesto12.Thisimpliesamaximumamountofmemory
pernodeusedbythequeriesinthispool:48GiBpernode(12queries*4GiBpernodememorylimit).
NoticethatAnnedoesnotsetthepoolmemoryresources,butdoessetthepoolâsMaximumQueryMemoryLimit.
Thisisintentional:admission controlprocessesqueriesfasterwhenapoolusestheMaxRunningQuerieslimitinstead
ofthepeakmemoryresources.
Thisshouldbeenoughmemoryformostqueries,sinceonlyafewgoover4GiBpernode.Forthosethatdorequire
morememory,theycanprobablystillcompletewithlessmemory(spillingifnecessary).If,onoccasion,aquerycannot
runwiththismuchmemoryanditfails,Annemightreconsiderthisconfigurationlater,orperhapsshedoesnotneed
toworryaboutafewrarefailuresfromthiswebUI.
Withregardtothroughput, sincethesequeriestakearound5secondsandsheisallowing12concurrentqueries,the
poolshouldbeabletohandleapproximately144queriesperminute,whichisenoughforthepeakmaximumexpected
of140queriesperminute.Incasethereisalargeburstofqueries,Annewantsthemtoqueue.Thedefaultmaximum
sizeofthequeueisalready200,whichshouldbemorethanlargeenough.Annedoesnotneedtochangeit.
Default
Value Property
320GiB MaxMemory
4GiB MaximumQueryMemoryLimit
2GiB Minimum QueryMemoryLimit
ApacheImpalaGuide|563ResourceManagement
Value Property
Unlimited MaxRunningQueries
60Seconds QueueTimeout
Thedefaultpool(whichalreadyexists)isacatchallforad-hocqueries.Annewantstousetheremaining memorynot
usedbythefirsttwopools,16GiBpernode(XL_Reportinguses64GiBpernode,High_Throughput_UI uses48GiBper
node).Fortheotherpoolstogettheresourcestheyexpect,shemuststillsettheMaxMemoryresourcesandthe
MaximumQueryMemoryLimit.ShesetstheMaxMemoryresourcesto320GiB(16*20).ShesetstheMaximum
QueryMemoryLimitto4GiBpernodefornow.Thatissomewhatarbitrary,butsatisfiessomeoftheadhocqueries
sheobserved.Ifsomeone writesabadquerybymistake,shedoesnotactuallywantitusingallthesystemresources.
Ifauserhasalargequerytosubmit,anexpertusercanoverridetheMaximumQueryMemoryLimit(upto16GiBper
node,sincethatisboundbythepoolMaxMemoryresources).Ifthatisstillinsufficientforthisuserâsworkload,the
usershouldworkwithAnnetoadjustthesettingsandperhapscreateadedicatedpoolfortheworkload.
564|ApacheImpalaGuideResourceManagement
TuningImpalaforPerformance
Thefollowingsectionsexplainthefactorsaffectingtheperformance ofImpalafeatures,andproceduresfortuning,
monitoring,andbenchmarking ImpalaqueriesandotherSQLoperations.
Thissectionalsodescribes techniques formaximizingImpalascalability.Scalabilityistiedtoperformance: itmeans
thatperformance remainshighasthesystemworkloadincreases.Forexample,reducingthediskI/Operformedbya
querycanspeedupanindividual query,andatthesametimeimprovescalabilitybymakingitpracticaltorunmore
queriessimultaneously.Sometimes,anoptimizationtechnique improvesscalabilitymorethanperformance. For
example,reducingmemoryusageforaquerymightnotchangethequeryperformance much,butmightimprove
scalabilitybyallowingmoreImpalaqueriesorotherkindsofjobstorunatthesametimewithoutrunningoutof
memory.
Note:
Beforestartinganyperformance tuningorbenchmarking ,makesureyoursystemisconfiguredwith
alltherecommended minimum hardwarerequirementsfromHardwareRequirementsonpage24
andsoftwaresettingsfromPost-InstallationConfigurationforImpalaonpage36.
â¢Partitioning forImpalaTablesonpage625.Thistechnique physicallydividesthedatabasedonthedifferentvalues
infrequentlyqueriedcolumns,allowingqueriestoskipreadingalargepercentageofthedatainatable.
â¢Performance ConsiderationsforJoinQueriesonpage568.Joinsarethemainclassofqueriesthatyoucantuneat
theSQLlevel,asopposedtochanging physicalfactorssuchasthefileformatorthehardwareconfiguration.The
relatedtopicsOverviewofColumnStatisticsonpage576andOverviewofTableStatisticsonpage575arealso
importantprimarily forjoinperformance.
â¢OverviewofTableStatisticsonpage575andOverviewofColumnStatisticsonpage576.Gatheringtableandcolumn
statistics,usingtheCOMPUTE STATS statement,helpsImpalaautomaticallyoptimizetheperformance forjoin
queries,withoutrequiringchangestoSQLquerystatements.(Thisprocessisgreatlysimplified inImpala1.2.2and
higher,becausetheCOMPUTE STATS statementgathersbothkindsofstatisticsinoneoperation,anddoesnot
requireanysetupandconfigurationaswaspreviouslynecessaryfortheANALYZE TABLE statementinHive.)
â¢TestingImpalaPerformance onpage601.Dosomepost-setuptestingtoensureImpalaisusingoptimalsettings
forperformance, beforeconducting anybenchmark tests.
â¢Benchmarking ImpalaQueriesonpage588.Theconfigurationandsampledatathatyouuseforinitialexperimen ts
withImpalaisoftennotappropriatefordoingperformance tests.
â¢ControllingImpalaResourceUsageonpage588.ThemorememoryImpalacanutilize,thebetterqueryperformance
youcanexpect.Inaclusterrunningotherkindsofworkloadsaswell,youmustmaketradeoffstomakesureall
Hadoopcomponen tshaveenoughmemorytoperformwell,soyoumightcapthememorythatImpalacanuse.
â¢UsingImpalawiththeAmazonS3Filesystemonpage692.QueriesagainstdatastoredintheAmazonSimple
StorageService(S3)havedifferentperformance characteristicsthanwhenthedataisstoredinHDFS.
Agoodsourceoftipsrelatedtoscalabilityandperformance tuningistheImpalaCookbook presentation.Theseslides
areupdatedperiodicallyasnewfeaturescomeoutandnewbenchmark sareperformed.
ImpalaPerformance Guidelines andBestPractices
Hereareperformanceguidelines andbestpracticesthatyoucanuseduringplanning,experimen tation,andperformance
tuningforanImpala-enabled CDHcluster.AllofthisinformationisalsoavailableinmoredetailelsewhereintheImpala
documen tation;itisgatheredtogetherheretoserveasacookbook andemphasiz ewhichperformance techniques
typicallyprovidethehighestreturnoninvestment
ApacheImpalaGuide|565TuningImpalaforPerformance
Choosetheappropriatefileformatforthedata
Typically,forlargevolumesofdata(multiple gigabytespertableorpartition), theParquetfileformatperformsbest
becauseofitscombinationofcolumnarstoragelayout,largeI/Orequestsize,andcompressionandencoding.See
HowImpalaWorkswithHadoopFileFormatsonpage634forcomparisons ofallfileformatssupportedbyImpala,and
UsingtheParquetFileFormatwithImpalaTablesonpage643fordetailsabouttheParquetfileformat.
Note:Forsmallervolumesofdata,afewgigabytesorlessforeachtableorpartition, youmightnot
seesignificantperformance differencesbetweenfileformats.Atsmalldatavolumes,reducedI/O
fromanefficientcompressedfileformatcanbecounterbalanced byreducedopportunity forparallel
execution.Whenplanningforaproductiondeploymentorconducting benchmark s,alwaysuserealistic
datavolumestogetatruepictureofperformance andscalability.
Avoiddataingestionprocessesthatproducemanysmallfiles
WhenproducingdatafilesoutsideofImpala,prefereithertextformatorAvro,whereyoucanbuildupthefilesrow
byrow.OncethedataisinImpala,youcanconvertittothemoreefficientParquetformatandsplitintomultipledata
filesusingasingleINSERT ... SELECT statement.Or,ifyouhavetheinfrastructuretoproducemulti-meg abyte
Parquetfilesaspartofyourdatapreparationprocess,dothatandskiptheconversionstepinsideImpala.
AlwaysuseINSERT ... SELECT tocopysignificantvolumesofdatafromtabletotablewithinImpala.AvoidINSERT
... VALUES foranysubstantialvolumeofdataorperformance-critic altables,becauseeachsuchstatementproduces
aseparatetinydatafile.SeeINSERTStatementonpage277forexamplesoftheINSERT ... SELECT syntax.
Forexample,ifyouhavethousands ofpartitions inaParquettable,eachwithlessthan256MBofdata,consider
partitioning inalessgranularway,suchasbyyear/monthratherthanyear/month/day.Ifaninefficientdataingestion
processproducesthousands ofdatafilesinthesametableorpartition, considercompacting thedatabyperforming
anINSERT ... SELECT tocopyallthedatatoadifferenttable;thedatawillbereorganizedintoasmallernumber
oflargerfilesbythisprocess.
Choosepartitioning granularity basedonactualdatavolume
Partitioning isatechnique thatphysicallydividesthedatabasedonvaluesofoneormorecolumns,suchasbyyear,
month,day,region,city,sectionofawebsite,andsoon.Whenyouissuequeriesthatrequestaspecificvalueorrange
ofvaluesforthepartitionkeycolumns,Impalacanavoidreadingtheirrelevantdata,potentiallyyieldingahugesavings
indiskI/O.
Whendecidingwhichcolumn(s) touseforpartitioning ,choosetherightlevelofgranularity.Forexample,shouldyou
partition byyear,month,andday,oronlybyyearandmonth?Chooseapartitioning strategythatputsatleast256
MBofdataineachpartition, totakeadvantageofHDFSbulkI/OandImpaladistributedqueries.
Over-partitioning canalsocausequeryplanningtotakelongerthannecessary,asImpalaprunestheunnecessar y
partitions. Ideally,keepthenumberofpartitions inthetableunder30thousand.
Whenpreparingdatafilestogoinapartition directory,createseverallargefilesratherthanmanysmallones.Ifyou
receivedataintheformofmanysmallfilesandhavenocontrolovertheinputformat,considerusingtheINSERT
... SELECT syntaxtocopydatafromonetableorpartition toanother,whichcompactsthefilesintoarelatively
smallnumber(basedonthenumberofnodesinthecluster).
Ifyouneedtoreducetheoverallnumberofpartitions andincreasetheamountofdataineachpartition, firstlookfor
partition keycolumnsthatarerarelyreferencedorarereferencedinnon-critic alqueries(notsubjecttoanSLA).For
example,yourwebsitelogdatamightbepartitioned byyear,month,day,andhour,butifmostqueriesrollupthe
resultsbyday,perhapsyouonlyneedtopartition byyear,month,andday.
Ifyouneedtoreducethegranularity evenmore,considercreatingâbucketsâ,computedvaluescorresponding to
differentsetsofpartition keyvalues.Forexample,youcanusetheTRUNC() functionwithaTIMESTAMP columnto
groupdateandtimevaluesbasedonintervalssuchasweekorquarter.SeeImpalaDateandTimeFunctions onpage
424fordetails.
SeePartitioning forImpalaTablesonpage625forfulldetailsandperformance considerationsforpartitioning.
566|ApacheImpalaGuideTuningImpalaforPerformance
Usesmallestappropriateintegertypesforpartition keycolumns
Although itistemptingtousestringsforpartition keycolumns,sincethosevaluesareturnedintoHDFSdirectory
namesanyway,youcanminimizememoryusagebyusingnumericvaluesforcommonpartition keyfieldssuchas
YEAR,MONTH,andDAY.Usethesmallestintegertypethatholdstheappropriaterangeofvalues,typicallyTINYINT
forMONTHandDAY,andSMALLINT forYEAR.UsetheEXTRACT() functiontopulloutindividual dateandtimefields
fromaTIMESTAMP value,andCAST()thereturnvaluetotheappropriateintegertype.
ChooseanappropriateParquetblocksize
Bydefault,theImpalaINSERT ... SELECT statementcreatesParquetfileswitha256MBblocksize.(Thisdefault
waschangedinImpala2.0.Formerly,thelimitwas1GB,butImpalamadeconservativeestimatesaboutcompression,
resultinginfilesthatweresmallerthan1GB.)
EachParquetfilewrittenbyImpalaisasingleblock,allowingthewholefiletobeprocessedasaunitbyasinglehost.
AsyoucopyParquetfilesintoHDFSorbetweenHDFSfilesystems,usehdfs dfs -pb topreservetheoriginalblock
size.
IfthereisonlyoneorafewdatablockinyourParquettable,orinapartitionthatistheonlyoneaccessed byaquery,
thenyoumightexperience aslowdownforadifferentreason:notenoughdatatotakeadvantageofImpala'sparallel
distributedqueries.EachdatablockisprocessedbyasinglecoreononeoftheDataNodes.Ina100-node clusterof
16-coremachines, youcouldpotentiallyprocessthousands ofdatafilessimultaneously.Youwanttofindasweetspot
betweenâmanytinyfilesâandâsinglegiantfileâthatbalances bulkI/Oandparallelprocessing. Youcansetthe
PARQUET_FILE_SIZE queryoptionbeforedoinganINSERT ... SELECT statementtoreducethesizeofeach
generatedParquetfile.(Specifythefilesizeasanabsolutenumberofbytes,orinImpala2.0andlater,inunitsending
withmformegabytesorgforgigabytes.)Runbenchmark swithdifferentfilesizestofindtherightbalancepointfor
yourparticular datavolume.
Gatherstatisticsforalltablesusedinperformance-critic alorhigh-volumejoinqueries
GatherthestatisticswiththeCOMPUTE STATS statement.SeePerformance ConsiderationsforJoinQueriesonpage
568fordetails.
Minimizetheoverheadoftransmittingresultsbacktotheclient
Usetechniques suchas:
â¢Aggregation.Ifyouneedtoknowhowmanyrowsmatchacondition, thetotalvaluesofmatchingvaluesfrom
somecolumn,thelowestorhighestmatchingvalue,andsoon,callaggregatefunctions suchasCOUNT() ,SUM(),
andMAX()inthequeryratherthansendingtheresultsettoanapplicationanddoingthosecomputationsthere.
Remember thatthesizeofanunaggregatedresultsetcouldbehuge,requiringsubstantialtimetotransmitacross
thenetwork.
â¢Filtering.UseallapplicabletestsintheWHEREclauseofaquerytoeliminaterowsthatarenotrelevant,rather
thanproducingabigresultsetandfilteringitusingapplicationlogic.
â¢LIMITclause.Ifyouonlyneedtoseeafewsamplevaluesfromaresultset,orthetoporbottomvaluesfroma
queryusingORDER BY ,includetheLIMITclausetoreducethesizeoftheresultsetratherthanaskingforthe
fullresultsetandthenthrowingmostoftherowsaway.
â¢Avoidoverheadfrompretty-printingtheresultsetanddisplayingitonthescreen.Whenyouretrievetheresults
throughimpala-shell ,useimpala-shell optionssuchas-Band--output_delimiter toproduceresults
withoutspecialformatting,andredirectoutputtoafileratherthanprintingtothescreen.Consider usingINSERT
... SELECT towritetheresultsdirectlytonewfilesinHDFS.Seeimpala-shell ConfigurationOptionsonpage
714fordetailsabouttheimpala-shell command-line options.
Verifythatyourqueriesareplannedinanefficientlogicalmanner
ExaminetheEXPLAIN planforaquerybeforeactuallyrunningit.SeeEXPLAINStatementonpage271andUsingthe
EXPLAINPlanforPerformance Tuningonpage602fordetails.
ApacheImpalaGuide|567TuningImpalaforPerformance
Verifyperformance characteristicsofqueries
Verifythatthelow-levelaspectsofI/O,memoryusage,networkbandwidth, CPUutilization,andsoonarewithin
expectedrangesbyexaminingthequeryprofileforaqueryafterrunningit.SeeUsingtheQueryProfileforPerformance
Tuningonpage604fordetails.
Useappropriateoperatingsystemsettings
SeeOptimizingPerformance inCDHforrecommenda tionsaboutoperatingsystemsettingsthatyoucanchangeto
influenceImpalaperformance. Inparticular ,youmightfindthatchanging thevm.swappiness Linuxkernelsetting
toanon-zerovalueimprovesoverallperformance.
Hotspotanalysis
InthecontextofImpala,ahotspotisdefinedasâanImpaladaemonthatforasinglequeryoraworkloadisspending
afargreateramountoftimeprocessingdatarelativetoitsneighbour sâ.
Beforediscussing theoptionstotacklethisissuesomebackgroundisfirstrequiredtounderstandhowthisproblem
canoccur.
Bydefault,thescheduling ofscanbasedplanfragmentsisdeterministic.Thismeansthatformultiplequeriesneeding
toreadthesameblockofdata,thesamenodewillbepickedtohostthescan.Thedefaultscheduling logicdoesnot
takeintoaccountnodeworkloadfrompriorqueries.Thecomplexityofmaterializing atupledependsonafewfactors,
namely:decodinganddecompression.Ifthetuplesaredenselypackedintodatapagesduetogood
encoding/compressionratios,therewillbemoreworkrequiredwhenreconstructingthedata.Eachcompressioncodec
offersdifferentperformance tradeoffsandshouldbeconsideredbeforewritingthedata.Duetothedeterministic
natureofthescheduler ,singlenodescanbecomebottlenecksforhighlyconcurrentqueriesthatusethesametables.
If,forexample,aParquetbaseddatasetistiny,e.g.asmalldimension table,suchthatitfitsintoasingleHDFSblock
(Impalabydefaultwillcreate256MBblockswhenParquetisused,eachcontainingasinglerowgroup)thenthereare
anumberofoptionsthatcanbeconsideredtoresolvethepotentialscheduling hotspots whenqueryingthisdata:
â¢InCDH5.7andhigher,thescheduler âsdeterministicbehaviourcanbechangedusingthefollowingqueryoptions:
REPLICA_PREFERENCE andRANDOM_REPLICA .ForadetaileddescriptionofeachofthesemodesseeIMPALA-2696 .
â¢HDFScachingcanbeusedtocacheblockreplicas.ThiswillcausetheImpalascheduler torandomly pick(from
CDH5.4andhigher)anodethatishostingacachedblockreplicaforthescan.Note,although HDFScachinghas
benefits,itservesonlytohelpwiththereadingofrawblockdataandnotcachedtupledata,butwiththeright
numberofcachedreplicas(bydefault,HDFSonlycachesonereplica),evenloaddistribution canbeachievedfor
smallerdatasets.
â¢Donotcompressthetabledata.Theuncompressedtabledataspansmorenodesandeliminatesskewcausedby
compression.
â¢ReducetheParquetfilesizeviathePARQUET_FILE_SIZE queryoptionwhenwritingthetabledata.Usingthis
approachthedatawillspanmorenodes.Howeveritâsnotrecommended todropthesizebelow32MB.
Performance ConsiderationsforJoinQueries
Queriesinvolvingjoinoperationsoftenrequiremoretuningthanqueriesthatrefertoonlyonetable.Themaximum
sizeoftheresultsetfromajoinqueryistheproductofthenumberofrowsinallthejoinedtables.Whenjoiningseveral
tableswithmillionsorbillionsofrows,anymissedopportunity tofiltertheresultset,orotherinefficiencyinthequery,
couldleadtoanoperationthatdoesnotfinishinapracticaltimeandhastobecancelled.
Thesimplesttechnique fortuninganImpalajoinqueryistocollectstatisticsoneachtableinvolvedinthejoinusing
theCOMPUTE STATS statement,andthenletImpalaautomaticallyoptimizethequerybasedonthesizeofeachtable,
numberofdistinctvaluesofeachcolumn,andsoon.TheCOMPUTE STATS statementandthejoinoptimizationare
newfeaturesintroducedinImpala1.2.2.Foraccuratestatisticsabouteachtable,issuetheCOMPUTE STATS statement
afterloadingthedataintothattable,andagainiftheamountofdatachangessubstantiallyduetoanINSERT,LOAD
DATA,addingapartition, andsoon.
568|ApacheImpalaGuideTuningImpalaforPerformance
Ifstatisticsarenotavailableforallthetablesinthejoinquery,orifImpalachoosesajoinorderthatisnotthemost
efficient,youcanoverridetheautomaticjoinorderoptimizationbyspecifyingtheSTRAIGHT_JOIN keywordimmediately
aftertheSELECTandanyDISTINCT orALLkeywords.Inthiscase,Impalausestheorderthetablesappearinthe
querytoguidehowthejoinsareprocessed.
WhenyouusetheSTRAIGHT_JOIN technique, youmustorderthetablesinthejoinquerymanually insteadofrelying
ontheImpalaoptimizer.Theoptimizerusessophisticatedtechniques toestimatethesizeoftheresultsetateach
stageofthejoin.Formanualordering,usethisheuristicapproachtostartwith,andthenexperimen ttofine-tune the
order:
â¢Specifythelargesttablefirst.ThistableisreadfromdiskbyeachImpalanodeandsoitssizeisnotsignificantin
termsofmemoryusageduringthequery.
â¢Next,specifythesmallesttable.Thecontentsofthesecond,third,andsoontablesarealltransmittedacrossthe
network.Youwanttominimizethesizeoftheresultsetfromeachsubsequentstageofthejoinquery.Themost
likelyapproachinvolvesjoiningasmalltablefirst,sothattheresultsetremainssmallevenassubsequentlarger
tablesareprocessed.
â¢Jointhenextsmallesttable,thenthenextsmallest,andsoon.
Forexample,ifyouhadtablesBIG,MEDIUM,SMALL,andTINY,thelogicaljoinordertotrywouldbeBIG,TINY,SMALL,
MEDIUM.
Thetermsâlargestâandâsmallestâreferstothesizeoftheintermediateresultsetbasedonthenumberofrowsand
columnsfromeachtablethatarepartoftheresultset.Forexample,ifyoujoinonetablesaleswithanothertable
customers ,aquerymightfindresultsfrom100differentcustomerswhomadeatotalof5000purchases.Inthatcase,
youwouldspecifySELECT ... FROM sales JOIN customers ... ,puttingcustomers ontherightsidebecause
itissmallerinthecontextofthisquery.
TheImpalaqueryplannerchoosesbetweendifferenttechniques forperformingjoinqueries,depending ontheabsolute
andrelativesizesofthetables.Broadcastjoinsarethedefault,wheretheright-handtableisconsideredtobesmaller
thantheleft-handtable,anditscontentsaresenttoalltheothernodesinvolvedinthequery.Thealternativetechnique
isknownasapartitioned join(notrelatedtoapartitioned table),whichismoresuitableforlargetablesofroughly
equalsize.Withthistechnique, portionsofeachtablearesenttoappropriateothernodeswherethosesubsetsof
rowscanbeprocessedinparallel.Thechoiceofbroadcastorpartitioned joinalsodependsonstatisticsbeingavailable
foralltablesinthejoin,gatheredbytheCOMPUTE STATS statement.
Toseewhichjoinstrategyisusedforaparticular query,issueanEXPLAIN statementforthequery.Ifyoufindthata
queryusesabroadcastjoinwhenyouknowthroughbenchmarking thatapartitioned joinwouldbemoreefficient,or
viceversa,addahinttothequerytospecifytheprecisejoinmechanism touse.SeeOptimizerHintsinImpalaonpage
387fordetails.
HowJoinsAreProcessedwhenStatisticsAreUnavailable
Iftableorcolumnstatisticsarenotavailableforsometablesinajoin,Impalastillreordersthetablesusingthe
informationthatisavailable.Tableswithstatisticsareplacedontheleftsideofthejoinorder,indescending orderof
costbasedonoverallsizeandcardinality.Tableswithoutstatisticsaretreatedaszero-size,thatis,theyarealways
placedontherightsideofthejoinorder.
OverridingJoinReorderingwithSTRAIGHT_JOIN
IfanImpalajoinqueryisinefficientbecauseofoutdatedstatisticsorunexpecteddatadistribution, youcankeepImpala
fromreorderingthejoinedtablesbyusingtheSTRAIGHT_JOIN keywordimmediatelyaftertheSELECTandany
DISTINCT orALLkeywords.TheSTRAIGHT_JOIN keywordturnsoffthereorderingofjoinclausesthatImpaladoes
internally,andproducesaplanthatreliesonthejoinclausesbeingorderedoptimallyinthequerytext.
ApacheImpalaGuide|569TuningImpalaforPerformance
Note:
TheSTRAIGHT_JOIN hintaffectsthejoinorderoftablereferencesinthequeryblockcontainingthe
hint.Itdoesnotaffectthejoinorderofnestedqueries,suchasviews,inlineviews,orWHERE-clause
subqueries. Tousethishintforperformance tuningofcomplexqueries,applythehinttoallquery
blocksthatneedafixedjoinorder.
Inthisexample,thesubselectfromtheBIGtableproducesaverysmallresultset,butthetablemightstillbetreated
asifitwerethebiggestandplacedfirstinthejoinorder.UsingSTRAIGHT_JOIN forthelastjoinclausepreventsthe
finaltablefrombeingreordered,keepingitastherightmosttableinthejoinorder.
select straight_join x from medium join small join (select * from big where c1 < 10) as
 big
  where medium.id = small.id and small.id = big.id;
-- If the query contains [DISTINCT | ALL], the hint goes after those keywords.
select distinct straight_join x from medium join small join (select * from big where c1
 < 10) as big
  where medium.id = small.id and small.id = big.id;
ExamplesofJoinOrderOptimization
Hereareexamplesshowingjoinsbetweentableswith1billion,200million,and1millionrows.(Inthiscase,thetables
areunpartitioned andusingParquetformat.)Thesmallertablescontainsubsetsofdatafromthelargestone,for
convenienceofjoiningontheuniqueIDcolumn.Thesmallesttableonlycontainsasubsetofcolumnsfromtheothers.
[localhost:21000] > create table big stored as parquet as select * from raw_data;
+----------------------------+
| summary                    |
+----------------------------+
| Inserted 1000000000 row(s) |
+----------------------------+
Returned 1 row(s) in 671.56s
[localhost:21000] > desc big;
+-----------+---------+---------+
| name      | type    | comment |
+-----------+---------+---------+
| id        | int     |         |
| val       | int     |         |
| zfill     | string  |         |
| name      | string  |         |
| assertion | boolean |         |
+-----------+---------+---------+
Returned 5 row(s) in 0.01s
[localhost:21000] > create table medium stored as parquet as select * from big limit 
200 * floor(1e6);
+---------------------------+
| summary                   |
+---------------------------+
| Inserted 200000000 row(s) |
+---------------------------+
Returned 1 row(s) in 138.31s
[localhost:21000] > create table small stored as parquet as select id,val,name from big
 where assertion = true limit 1 * floor(1e6);
+-------------------------+
| summary                 |
+-------------------------+
| Inserted 1000000 row(s) |
+-------------------------+
Returned 1 row(s) in 6.32s
Foranykindofperformance experimen tation,usetheEXPLAIN statementtoseehowanyexpensivequerywillbe
performedwithoutactuallyrunningit,andenableverboseEXPLAIN planscontainingmoreperformance-orien ted
detail:Themostinterestingplanlinesarehighlightedinbold,showingthatwithoutstatisticsforthejoinedtables,
570|ApacheImpalaGuideTuningImpalaforPerformance
Impalacannotmakeagoodestimateofthenumberofrowsinvolvedateachstageofprocessing,andislikelytostick
withtheBROADCAST joinmechanism thatsendsacompletecopyofoneofthetablestoeachnode.
[localhost:21000] > set explain_level=verbose;
EXPLAIN_LEVEL set to verbose
[localhost:21000] > explain select count(*) from big join medium where big.id = medium.id;
+----------------------------------------------------------+
| Explain String                                           |
+----------------------------------------------------------+
| Estimated Per-Host Requirements: Memory=2.10GB VCores=2  |
|                                                          |
| PLAN FRAGMENT 0                                          |
|   PARTITION: UNPARTITIONED                               |
|                                                          |
|   6:AGGREGATE (merge finalize)                           |
|   |  output: SUM(COUNT(*))                               |
|   |  cardinality: 1                                      |
|   |  per-host memory: unavailable                        |
|   |  tuple ids: 2                                        |
|   |                                                      |
|   5:EXCHANGE                                             |
|      cardinality: 1                                      |
|      per-host memory: unavailable                        |
|      tuple ids: 2                                        |
|                                                          |
| PLAN FRAGMENT 1                                          |
|   PARTITION: RANDOM                                      |
|                                                          |
|   STREAM DATA SINK                                       |
|     EXCHANGE ID: 5                                       |
|     UNPARTITIONED                                        |
|                                                          |
|   3:AGGREGATE                                            |
|   |  output: COUNT(*)                                    |
|   |  cardinality: 1                                      |
|   |  per-host memory: 10.00MB                            |
|   |  tuple ids: 2                                        |
|   |                                                      |
|   2:HASH JOIN                                            |
|   |  join op: INNER JOIN (BROADCAST)                     |
|   |  hash predicates:                                    |
|   |    big.id = medium.id                                |
|   |  cardinality: unavailable                            |
|   |  per-host memory: 2.00GB                             |
|   |  tuple ids: 0 1                                      |
|   |                                                      |
|   |----4:EXCHANGE                                        |
|   |       cardinality: unavailable                       |
|   |       per-host memory: 0B                            |
|   |       tuple ids: 1                                   |
|   |                                                      |
|   0:SCAN HDFS                                            |
|      table=join_order.big #partitions=1/1 size=23.12GB   |
|      table stats: unavailable                            |
|      column stats: unavailable                           |
|      cardinality: unavailable                            |
|      per-host memory: 88.00MB                            |
|      tuple ids: 0                                        |
|                                                          |
| PLAN FRAGMENT 2                                          |
|   PARTITION: RANDOM                                      |
|                                                          |
|   STREAM DATA SINK                                       |
|     EXCHANGE ID: 4                                       |
|     UNPARTITIONED                                        |
|                                                          |
|   1:SCAN HDFS                                            |
|      table=join_order.medium #partitions=1/1 size=4.62GB |
|      table stats: unavailable                            |
|      column stats: unavailable                           |
|      cardinality: unavailable                            |
|      per-host memory: 88.00MB                            |
|      tuple ids: 1                                        |
ApacheImpalaGuide|571TuningImpalaforPerformance
+----------------------------------------------------------+
Returned 64 row(s) in 0.04s
Gatheringstatisticsforallthetablesisstraightforward,oneCOMPUTE STATS statementpertable:
[localhost:21000] > compute stats small;
+-----------------------------------------+
| summary                                 |
+-----------------------------------------+
| Updated 1 partition(s) and 3 column(s). |
+-----------------------------------------+
Returned 1 row(s) in 4.26s
[localhost:21000] > compute stats medium;
+-----------------------------------------+
| summary                                 |
+-----------------------------------------+
| Updated 1 partition(s) and 5 column(s). |
+-----------------------------------------+
Returned 1 row(s) in 42.11s
[localhost:21000] > compute stats big;
+-----------------------------------------+
| summary                                 |
+-----------------------------------------+
| Updated 1 partition(s) and 5 column(s). |
+-----------------------------------------+
Returned 1 row(s) in 165.44s
Withstatisticsinplace,Impalacanchooseamoreeffectivejoinorderratherthanfollowingtheleft-to-rightsequence
oftablesinthequery,andcanchooseBROADCAST orPARTITIONED joinstrategiesbasedontheoverallsizesand
numberofrowsinthetable:
[localhost:21000] > explain select count(*) from medium join big where big.id = medium.id;
Query: explain select count(*) from medium join big where big.id = medium.id
+-----------------------------------------------------------+
| Explain String                                            |
+-----------------------------------------------------------+
| Estimated Per-Host Requirements: Memory=937.23MB VCores=2 |
|                                                           |
| PLAN FRAGMENT 0                                           |
|   PARTITION: UNPARTITIONED                                |
|                                                           |
|   6:AGGREGATE (merge finalize)                            |
|   |  output: SUM(COUNT(*))                                |
|   |  cardinality: 1                                       |
|   |  per-host memory: unavailable                         |
|   |  tuple ids: 2                                         |
|   |                                                       |
|   5:EXCHANGE                                              |
|      cardinality: 1                                       |
|      per-host memory: unavailable                         |
|      tuple ids: 2                                         |
|                                                           |
| PLAN FRAGMENT 1                                           |
|   PARTITION: RANDOM                                       |
|                                                           |
|   STREAM DATA SINK                                        |
|     EXCHANGE ID: 5                                        |
|     UNPARTITIONED                                         |
|                                                           |
|   3:AGGREGATE                                             |
|   |  output: COUNT(*)                                     |
|   |  cardinality: 1                                       |
|   |  per-host memory: 10.00MB                             |
|   |  tuple ids: 2                                         |
|   |                                                       |
|   2:HASH JOIN                                             |
|   |  join op: INNER JOIN (BROADCAST)                      |
|   |  hash predicates:                                     |
|   |    big.id = medium.id                                 |
|   |  cardinality: 1443004441                              |
|   |  per-host memory: 839.23MB                            |
572|ApacheImpalaGuideTuningImpalaforPerformance
|   |  tuple ids: 1 0                                       |
|   |                                                       |
|   |----4:EXCHANGE                                         |
|   |       cardinality: 200000000                          |
|   |       per-host memory: 0B                             |
|   |       tuple ids: 0                                    |
|   |                                                       |
|   1:SCAN HDFS                                             |
|      table=join_order.big #partitions=1/1 size=23.12GB    |
|      table stats: 1000000000 rows total                   |
|      column stats: all                                    |
|      cardinality: 1000000000                              |
|      per-host memory: 88.00MB                             |
|      tuple ids: 1                                         |
|                                                           |
| PLAN FRAGMENT 2                                           |
|   PARTITION: RANDOM                                       |
|                                                           |
|   STREAM DATA SINK                                        |
|     EXCHANGE ID: 4                                        |
|     UNPARTITIONED                                         |
|                                                           |
|   0:SCAN HDFS                                             |
|      table=join_order.medium #partitions=1/1 size=4.62GB  |
|      table stats: 200000000 rows total                    |
|      column stats: all                                    |
|      cardinality: 200000000                               |
|      per-host memory: 88.00MB                             |
|      tuple ids: 0                                         |
+-----------------------------------------------------------+
Returned 64 row(s) in 0.04s
[localhost:21000] > explain select count(*) from small join big where big.id = small.id;
Query: explain select count(*) from small join big where big.id = small.id
+-----------------------------------------------------------+
| Explain String                                            |
+-----------------------------------------------------------+
| Estimated Per-Host Requirements: Memory=101.15MB VCores=2 |
|                                                           |
| PLAN FRAGMENT 0                                           |
|   PARTITION: UNPARTITIONED                                |
|                                                           |
|   6:AGGREGATE (merge finalize)                            |
|   |  output: SUM(COUNT(*))                                |
|   |  cardinality: 1                                       |
|   |  per-host memory: unavailable                         |
|   |  tuple ids: 2                                         |
|   |                                                       |
|   5:EXCHANGE                                              |
|      cardinality: 1                                       |
|      per-host memory: unavailable                         |
|      tuple ids: 2                                         |
|                                                           |
| PLAN FRAGMENT 1                                           |
|   PARTITION: RANDOM                                       |
|                                                           |
|   STREAM DATA SINK                                        |
|     EXCHANGE ID: 5                                        |
|     UNPARTITIONED                                         |
|                                                           |
|   3:AGGREGATE                                             |
|   |  output: COUNT(*)                                     |
|   |  cardinality: 1                                       |
|   |  per-host memory: 10.00MB                             |
|   |  tuple ids: 2                                         |
|   |                                                       |
|   2:HASH JOIN                                             |
|   |  join op: INNER JOIN (BROADCAST)                      |
|   |  hash predicates:                                     |
|   |    big.id = small.id                                  |
|   |  cardinality: 1000000000                              |
|   |  per-host memory: 3.15MB                              |
|   |  tuple ids: 1 0                                       |
ApacheImpalaGuide|573TuningImpalaforPerformance
|   |                                                       |
|   |----4:EXCHANGE                                         |
|   |       cardinality: 1000000                            |
|   |       per-host memory: 0B                             |
|   |       tuple ids: 0                                    |
|   |                                                       |
|   1:SCAN HDFS                                             |
|      table=join_order.big #partitions=1/1 size=23.12GB    |
|      table stats: 1000000000 rows total                   |
|      column stats: all                                    |
|      cardinality: 1000000000                              |
|      per-host memory: 88.00MB                             |
|      tuple ids: 1                                         |
|                                                           |
| PLAN FRAGMENT 2                                           |
|   PARTITION: RANDOM                                       |
|                                                           |
|   STREAM DATA SINK                                        |
|     EXCHANGE ID: 4                                        |
|     UNPARTITIONED                                         |
|                                                           |
|   0:SCAN HDFS                                             |
|      table=join_order.small #partitions=1/1 size=17.93MB  |
|      table stats: 1000000 rows total                      |
|      column stats: all                                    |
|      cardinality: 1000000                                 |
|      per-host memory: 32.00MB                             |
|      tuple ids: 0                                         |
+-----------------------------------------------------------+
Returned 64 row(s) in 0.03s
Whenqueriesliketheseareactuallyrun,theexecutiontimesarerelativelyconsistentregardlessofthetableorderin
thequerytext.HereareexamplesusingboththeuniqueIDcolumnandtheVALcolumncontainingduplicatevalues:
[localhost:21000] > select count(*) from big join small on (big.id = small.id);
Query: select count(*) from big join small on (big.id = small.id)
+----------+
| count(*) |
+----------+
| 1000000  |
+----------+
Returned 1 row(s) in 21.68s
[localhost:21000] > select count(*) from small join big on (big.id = small.id);
Query: select count(*) from small join big on (big.id = small.id)
+----------+
| count(*) |
+----------+
| 1000000  |
+----------+
Returned 1 row(s) in 20.45s
[localhost:21000] > select count(*) from big join small on (big.val = small.val);
+------------+
| count(*)   |
+------------+
| 2000948962 |
+------------+
Returned 1 row(s) in 108.85s
[localhost:21000] > select count(*) from small join big on (big.val = small.val);
+------------+
| count(*)   |
+------------+
| 2000948962 |
+------------+
Returned 1 row(s) in 100.76s
574|ApacheImpalaGuideTuningImpalaforPerformance
Note:Whenexaminingtheperformance ofjoinqueriesandtheeffectivenessofthejoinorder
optimization,makesurethequeryinvolvesenoughdataandclusterresourcestoseeadifference
depending onthequeryplan.Forexample,asingledatafileofjustafewmegabyteswillresideina
singleHDFSblockandbeprocessedonasinglenode.Likewise,ifyouuseasingle-node ortwo-node
cluster,theremightnotbemuchdifferenceinefficiencyforthebroadcastorpartitioned joinstrategies.
TableandColumnStatistics
Impalacandobetteroptimizationforcomplexormulti-tablequerieswhenithasaccesstostatisticsaboutthevolume
ofdataandhowthevaluesaredistributed.Impalausesthisinformationtohelpparallelizeanddistributetheworkfor
aquery.Forexample,optimizingjoinqueriesrequiresawayofdetermining ifonetableisâbiggerâthananother,which
isafunctionofthenumberofrowsandtheaveragerowsizeforeachtable.Thefollowingsectionsdescribethe
categoriesofstatisticsImpalacanworkwith,andhowtoproducethemandkeepthemuptodate.
OverviewofTableStatistics
TheImpalaqueryplannercanmakeuseofstatisticsaboutentiretablesandpartitions. Thisinformationincludes
physicalcharacteristicssuchasthenumberofrows,numberofdatafiles,thetotalsizeofthedatafiles,andthefile
format.Forpartitioned tables,thenumbersarecalculatedperpartition, andastotalsforthewholetable.Thismetadata
isstoredinthemetastoredatabase,andcanbeupdatedbyeitherImpalaorHive.Ifanumberisnotavailable,the
value-1isusedasaplaceholder .Somenumbers,suchasnumberandtotalsizesofdatafiles,arealwayskeptupto
datebecausetheycanbecalculatedcheaply,aspartofgatheringHDFSblockmetadata.
Thefollowingexampleshowstablestatsforanunpartitioned Parquettable.Thevaluesforthenumberandsizesof
filesarealwaysavailable.Initially,thenumberofrowsisnotknown,becauseitrequiresapotentiallyexpensivescan
throughtheentiretable,andsothatvalueisdisplayedas-1.TheCOMPUTE STATS statementfillsinanyunknown
tablestatsvalues.
show table stats parquet_snappy;
+-------+--------+---------+--------------+-------------------+---------+-------------------+...
| #Rows | #Files | Size    | Bytes Cached | Cache Replication | Format  | Incremental 
stats |...
+-------+--------+---------+--------------+-------------------+---------+-------------------+...
| -1    | 96     | 23.35GB | NOT CACHED   | NOT CACHED        | PARQUET | false       
      |...
+-------+--------+---------+--------------+-------------------+---------+-------------------+...
compute stats parquet_snappy;
+-----------------------------------------+
| summary                                 |
+-----------------------------------------+
| Updated 1 partition(s) and 6 column(s). |
+-----------------------------------------+
show table stats parquet_snappy;
+------------+--------+---------+--------------+-------------------+---------+-------------------+...
| #Rows      | #Files | Size    | Bytes Cached | Cache Replication | Format  | Incremental
 stats |...
+------------+--------+---------+--------------+-------------------+---------+-------------------+...
| 1000000000 | 96     | 23.35GB | NOT CACHED   | NOT CACHED        | PARQUET | false  
           |...
+------------+--------+---------+--------------+-------------------+---------+-------------------+...
Impalaperformssomeoptimizationsusingthismetadataonitsown,andotheroptimizationsbyusingacombination
oftableandcolumnstatistics.
Tocheckthattablestatisticsareavailableforatable,andseethedetailsofthosestatistics,usethestatementSHOW
TABLE STATS table_name .SeeSHOWStatementonpage363fordetails.
ApacheImpalaGuide|575TuningImpalaforPerformance
IfyouusetheHive-basedmethodsofgatheringstatistics,seetheHivewikiforinformationabouttherequired
configurationontheHiveside.Wherepractical,usetheImpalaCOMPUTE STATS statementtoavoidpotential
configurationandscalabilityissueswiththestatistics-gatheringprocess.
IfyouruntheHivestatementANALYZE TABLE COMPUTE STATISTICS FOR COLUMNS ,Impalacanonlyusethe
resultingcolumnstatisticsifthetableisunpartitioned. ImpalacannotuseHive-generatedcolumnstatisticsfora
partitioned table.
OverviewofColumnStatistics
TheImpalaqueryplannercanmakeuseofstatisticsaboutindividual columnswhenthatmetadataisavailableinthe
metastoredatabase.Thistechnique ismostvaluableforcolumnscomparedacrosstablesinjoinqueries,tohelp
estimatehowmanyrowsthequerywillretrievefromeachtable.Thesestatisticsarealsoimportantforcorrelated
subqueries usingtheEXISTS() orIN()operators,whichareprocessedinternallythesamewayasjoinqueries.
Thefollowingexampleshowscolumnstatsforanunpartitioned Parquettable.Thevaluesforthemaximumandaverage
sizesofsometypesarealwaysavailable,becausethosefiguresareconstantfornumericandotherfixed-sizetypes.
Initially,thenumberofdistinctvaluesisnotknown,becauseitrequiresapotentiallyexpensivescanthroughtheentire
table,andsothatvalueisdisplayedas-1.Thesameappliestomaximumandaveragesizesofvariable-siz edtypes,
suchasSTRING.TheCOMPUTE STATS statementfillsinmostunknowncolumnstatsvalues.(Itdoesnotrecordthe
numberofNULLvalues,becausecurrentlyImpaladoesnotusethatfigureforqueryoptimization.)
show column stats parquet_snappy;
+-------------+----------+------------------+--------+----------+----------+
| Column      | Type     | #Distinct Values | #Nulls | Max Size | Avg Size |
+-------------+----------+------------------+--------+----------+----------+
| id          | BIGINT   | -1               | -1     | 8        | 8        |
| val         | INT      | -1               | -1     | 4        | 4        |
| zerofill    | STRING   | -1               | -1     | -1       | -1       |
| name        | STRING   | -1               | -1     | -1       | -1       |
| assertion   | BOOLEAN  | -1               | -1     | 1        | 1        |
| location_id | SMALLINT | -1               | -1     | 2        | 2        |
+-------------+----------+------------------+--------+----------+----------+
compute stats parquet_snappy;
+-----------------------------------------+
| summary                                 |
+-----------------------------------------+
| Updated 1 partition(s) and 6 column(s). |
+-----------------------------------------+
show column stats parquet_snappy;
+-------------+----------+------------------+--------+----------+-------------------+
| Column      | Type     | #Distinct Values | #Nulls | Max Size | Avg Size          |
+-------------+----------+------------------+--------+----------+-------------------+
| id          | BIGINT   | 183861280        | -1     | 8        | 8                 |
| val         | INT      | 139017           | -1     | 4        | 4                 |
| zerofill    | STRING   | 101761           | -1     | 6        | 6                 |
| name        | STRING   | 145636240        | -1     | 22       | 13.00020027160645 |
| assertion   | BOOLEAN  | 2                | -1     | 1        | 1                 |
| location_id | SMALLINT | 339              | -1     | 2        | 2                 |
+-------------+----------+------------------+--------+----------+-------------------+
Note:
ForcolumnstatisticstobeeffectiveinImpala,youalsoneedtohavetablestatisticsfortheapplicable
tables,asdescribed inOverviewofTableStatisticsonpage575.WhenyouusetheImpalaCOMPUTE
STATSstatement,bothtableandcolumnstatisticsareautomaticallygatheredatthesametime,for
allcolumnsinthetable.
576|ApacheImpalaGuideTuningImpalaforPerformance
Note:PriortoImpala1.4.0,COMPUTE STATS countedthenumberofNULLvaluesineachcolumn
andrecordedthatfigureinthemetastoredatabase.BecauseImpaladoesnotcurrentlyusetheNULL
countduringqueryplanning,Impala1.4.0andhigherspeedsuptheCOMPUTE STATS statementby
skippingthisNULLcounting.
Tocheckwhethercolumnstatisticsareavailableforaparticular setofcolumns,usetheSHOW COLUMN STATS
table_name statement,orchecktheextendedEXPLAIN outputforaqueryagainstthattablethatreferstothose
columns.SeeSHOWStatementonpage363andEXPLAINStatementonpage271fordetails.
IfyouruntheHivestatementANALYZE TABLE COMPUTE STATISTICS FOR COLUMNS ,Impalacanonlyusethe
resultingcolumnstatisticsifthetableisunpartitioned. ImpalacannotuseHive-generatedcolumnstatisticsfora
partitioned table.
HowTableandColumnStatisticsWorkforPartitioned Tables
WhenyouuseImpalaforâbigdataâ,youarehighlylikelytousepartitioning foryourbiggesttables,theonesrepresenting
datathatcanbelogicallydividedbasedondates,geographicregions,orsimilarcriteria.Thetableandcolumnstatistics
areespecially usefulforoptimizingqueriesonsuchtables.Forexample,aqueryinvolvingoneyearmightinvolve
substantiallymoreorlessdatathanaqueryinvolvingadifferentyear,orarangeofseveralyears.Eachquerymight
beoptimizeddifferentlyasaresult.
Thefollowingexamplesshowhowtableandcolumnstatsworkwithapartitioned table.Thetableforthisexampleis
partitioned byyear,month,andday.Forsimplicity ,thesampledataconsistsof5partitions, allfromthesameyear
andmonth.Tablestatsarecollectedindependen tlyforeachpartition. (Infact,theSHOW PARTITIONS statement
displaysexactlythesameinformationasSHOW TABLE STATS forapartitioned table.)Columnstatsapplytotheentire
table,nottoindividual partitions. Becausethepartition keycolumnvaluesarerepresentedasHDFSdirectories,their
characteristicsaretypicallyknowninadvance,evenwhenthevaluesfornon-keycolumnsareshownas-1.
show partitions year_month_day;
+-------+-------+-----+-------+--------+---------+--------------+-------------------+---------+...
| year  | month | day | #Rows | #Files | Size    | Bytes Cached | Cache Replication | 
Format  |...
+-------+-------+-----+-------+--------+---------+--------------+-------------------+---------+...
| 2013  | 12    | 1   | -1    | 1      | 2.51MB  | NOT CACHED   | NOT CACHED        | 
PARQUET |...
| 2013  | 12    | 2   | -1    | 1      | 2.53MB  | NOT CACHED   | NOT CACHED        | 
PARQUET |...
| 2013  | 12    | 3   | -1    | 1      | 2.52MB  | NOT CACHED   | NOT CACHED        | 
PARQUET |...
| 2013  | 12    | 4   | -1    | 1      | 2.51MB  | NOT CACHED   | NOT CACHED        | 
PARQUET |...
| 2013  | 12    | 5   | -1    | 1      | 2.52MB  | NOT CACHED   | NOT CACHED        | 
PARQUET |...
| Total |       |     | -1    | 5      | 12.58MB | 0B           |                   | 
        |...
+-------+-------+-----+-------+--------+---------+--------------+-------------------+---------+...
show table stats year_month_day;
+-------+-------+-----+-------+--------+---------+--------------+-------------------+---------+...
| year  | month | day | #Rows | #Files | Size    | Bytes Cached | Cache Replication | 
Format  |...
+-------+-------+-----+-------+--------+---------+--------------+-------------------+---------+...
| 2013  | 12    | 1   | -1    | 1      | 2.51MB  | NOT CACHED   | NOT CACHED        | 
PARQUET |...
| 2013  | 12    | 2   | -1    | 1      | 2.53MB  | NOT CACHED   | NOT CACHED        | 
PARQUET |...
| 2013  | 12    | 3   | -1    | 1      | 2.52MB  | NOT CACHED   | NOT CACHED        | 
PARQUET |...
| 2013  | 12    | 4   | -1    | 1      | 2.51MB  | NOT CACHED   | NOT CACHED        | 
PARQUET |...
| 2013  | 12    | 5   | -1    | 1      | 2.52MB  | NOT CACHED   | NOT CACHED        | 
PARQUET |...
| Total |       |     | -1    | 5      | 12.58MB | 0B           |                   | 
        |...
ApacheImpalaGuide|577TuningImpalaforPerformance
+-------+-------+-----+-------+--------+---------+--------------+-------------------+---------+...
show column stats year_month_day;
+-----------+---------+------------------+--------+----------+----------+
| Column    | Type    | #Distinct Values | #Nulls | Max Size | Avg Size |
+-----------+---------+------------------+--------+----------+----------+
| id        | INT     | -1               | -1     | 4        | 4        |
| val       | INT     | -1               | -1     | 4        | 4        |
| zfill     | STRING  | -1               | -1     | -1       | -1       |
| name      | STRING  | -1               | -1     | -1       | -1       |
| assertion | BOOLEAN | -1               | -1     | 1        | 1        |
| year      | INT     | 1                | 0      | 4        | 4        |
| month     | INT     | 1                | 0      | 4        | 4        |
| day       | INT     | 5                | 0      | 4        | 4        |
+-----------+---------+------------------+--------+----------+----------+
compute stats year_month_day;
+-----------------------------------------+
| summary                                 |
+-----------------------------------------+
| Updated 5 partition(s) and 5 column(s). |
+-----------------------------------------+
show table stats year_month_day;
+-------+-------+-----+--------+--------+---------+--------------+-------------------+---------+...
| year  | month | day | #Rows  | #Files | Size    | Bytes Cached | Cache Replication |
 Format  |...
+-------+-------+-----+--------+--------+---------+--------------+-------------------+---------+...
| 2013  | 12    | 1   | 93606  | 1      | 2.51MB  | NOT CACHED   | NOT CACHED        |
 PARQUET |...
| 2013  | 12    | 2   | 94158  | 1      | 2.53MB  | NOT CACHED   | NOT CACHED        |
 PARQUET |...
| 2013  | 12    | 3   | 94122  | 1      | 2.52MB  | NOT CACHED   | NOT CACHED        |
 PARQUET |...
| 2013  | 12    | 4   | 93559  | 1      | 2.51MB  | NOT CACHED   | NOT CACHED        |
 PARQUET |...
| 2013  | 12    | 5   | 93845  | 1      | 2.52MB  | NOT CACHED   | NOT CACHED        |
 PARQUET |...
| Total |       |     | 469290 | 5      | 12.58MB | 0B           |                   |
         |...
+-------+-------+-----+--------+--------+---------+--------------+-------------------+---------+...
show column stats year_month_day;
+-----------+---------+------------------+--------+----------+-------------------+
| Column    | Type    | #Distinct Values | #Nulls | Max Size | Avg Size          |
+-----------+---------+------------------+--------+----------+-------------------+
| id        | INT     | 511129           | -1     | 4        | 4                 |
| val       | INT     | 364853           | -1     | 4        | 4                 |
| zfill     | STRING  | 311430           | -1     | 6        | 6                 |
| name      | STRING  | 471975           | -1     | 22       | 13.00160026550293 |
| assertion | BOOLEAN | 2                | -1     | 1        | 1                 |
| year      | INT     | 1                | 0      | 4        | 4                 |
| month     | INT     | 1                | 0      | 4        | 4                 |
| day       | INT     | 5                | 0      | 4        | 4                 |
+-----------+---------+------------------+--------+----------+-------------------+
IfyouruntheHivestatementANALYZE TABLE COMPUTE STATISTICS FOR COLUMNS ,Impalacanonlyusethe
resultingcolumnstatisticsifthetableisunpartitioned. ImpalacannotuseHive-generatedcolumnstatisticsfora
partitioned table.
GeneratingTableandColumnStatistics
UsetheCOMPUTE STATS familyofcommands tocollecttableandcolumnstatistics.TheCOMPUTE STATS variants
offerdifferenttradeoffsbetweencomputationcost,staleness,andmaintenanceworkflowswhichareexplainedbelow.
578|ApacheImpalaGuideTuningImpalaforPerformance
Important:
Foraparticular table,useeitherCOMPUTE STATS orCOMPUTE INCREMENTAL STATS .Thetwokinds
ofstatsdonotinteroperatewitheachotheratthetablelevel.Withoutdroppingthestats,ifyourun
COMPUTE INCREMENTAL STATS itwilloverwritethefullcomputestatsorifyourunCOMPUTE STATS
itwilldropallincrementalstatsforconsistency.
COMPUTE STATS
TheCOMPUTE STATS command collectsandsetsthetable-levelandpartition-le velrowcountsaswellasallcolumn
statisticsforagiventable.ThecollectionprocessisCPU-intensiveandcantakealongtimetocompleteforverylarge
tables.
TospeedupCOMPUTE STATS considerthefollowingoptionswhichcanbecombined.
â¢LimitthenumberofcolumnsforwhichstatisticsarecollectedtoincreasetheefficiencyofCOMPUTE STATS.
Queriesbenefitfromstatisticsforthosecolumnsinvolvedinfilters,joinconditions, groupbyorpartitionbyclauses.
OthercolumnsaregoodcandidatestoexcludefromCOMPUTE STATS.ThisfeatureisavailablesinceImpala2.12.
â¢SettheMT_DOP queryoptiontousemorethreadswithineachparticipatingimpaladtocomputethestatistics
faster-butnotmoreefficiently.Notethatcomputing statsonalargetablewithahighMT_DOP valuecannegatively
affectotherqueriesrunningatthesametimeiftheCOMPUTE STATSclaimsmostCPUcycles.Thisfeatureis
availablesinceImpala2.8.
â¢Consider theexperimen talextrapolationandsampling features(seebelow)tofurtherincreasetheefficiencyof
computing stats.
COMPUTE STATS isintendedtoberunperiodically,e.g.weekly,oron-demand whenthecontentsofatablehave
changedsignificantly.DuetothehighresourceutilizationandlongrepsonsetimeoftCOMPUTE STATS ,itismost
practicaltorunitinascheduled maintnancewindowwheretheImpalaclusterisidleenoughtoaccommodatethe
expensiveoperation.Thedegreeofchangethatqualifiesasâsignificantâdependsonthequeryworkload,buttypically,
if30%oftherowshavechangedthenitisrecommended torecomputestatistics.
Ifyoureloadacompletenewsetofdataforatable,butthenumberofrowsandnumberofdistinctvaluesforeach
columnisrelativelyunchangedfrombefore,youdonotneedtorecomputestatsforthetable.
Experimen tal:ExtrapolationandSampling
Impala2.12andhigherincludestwoexperimen talfeaturestoalleviatecommonissuesforcomputing andmaintaining
statisticsonverylargetables.Thefollowingshortcomingsareimprovedupon:
â¢Newlyaddedpartitions donothaverowcountstatistics.Tablescansthatonlyaccessthosenewpartitions are
treatedasnothavingstats.Similarly,tablescansthataccessbothnewandoldpartitions estimatethescan
cardinalitybasedonthoseoldpartitions thathavestats,andthenewpartitions withoutstatsaretreatedashaving
0rows.
â¢Therowcountsofexistingpartitions becomestalewhendataisaddedordropped.
â¢Computing statsfortableswitha100,000ormorepartitions mightfailorbeveryslowduetothehighcostof
updatingthepartition metadataintheHiveMetastore.
â¢Withtransientcomputeresourcesitisimportanttominimizethetimefromstartinganewclustertosuccessfully
runningqueries.Sincetheclustermightberelativelyshort-lived,usersmightprefertoquicklycollectstatsthat
are"goodenough"asopposedtospending alotoftimeandresoucesoncomputing full-fidelity stats.
Forverylargetables,itisoftenwastefulorimpracticaltorunafullCOMPUTE STATStoaddressthescenarios above
onafrequentbasis.
Thesampling featuremakesCOMPUTE STATSmoreefficientbyprocessingafractionofthetabledata,andthe
extrapolationfeatureaimstoreducethefrequencyatwhichCOMPUTE STATSneedstobere-runbyestimatingthe
rowcountofnewandmodified partitions.
ApacheImpalaGuide|579TuningImpalaforPerformance
Thesampling andextrapolationfeaturesaredisabledbydefault.Theycanbeenabledgloballyorforspecifictables,
asfollows.Settheimpaladstart-upconfiguration"--enable_s tats_extrapolation"toenablethefeaturesglobally.To
enablethemonlyforaspecifictable,setthe"impala.enable.s tats.extrapolation"tablepropertyto"true"forthedesired
table.Thetable-levelpropertyoverridestheglobalsetting,soitisalsopossibletoenablesampling andextrapolation
globally,butdisableitforspecifictablesbysettingthetablepropertyto"false".Example:ALTERTABLEmytable
test_tableSETTBLPROPERTIES("impala.enable.s tats.extrapolation"="true")
Note:Whyarethesefeaturesexperimen tal?Duetotheirprobabilisticnatureitispossiblethatthese
featuresperformpathologicallypoorlyontableswithextremedata/file/sizedistributions. Sinceitis
notfeasibleforustotestallpossiblescenarios weonlycautiously advertisethesenewcapabilities.
Thatsaid,thefeatureshavebeenthoroughlytestedandareconsideredfunctionally stable.Ifyou
decidetogivethesefeaturesatry,pleasetellusaboutyourexperience atuser@impala.apache.or g!
Werelyonuserfeedbacktoguidefutureinprovementsinstatisticscollection.
StatsExtrapolation
Themainideaofstatsextrapolationistoestimatetherowcountofnewandmodified partitions basedontheresult
ofthelastCOMPUTE STATS.EnablingstatsextrapolationchangesthebehaviorofCOMPUTE STATS,aswellasthe
cardinalityestimationoftablescans.COMPUTE STATSnolongercomputesandstoresper-partition rowcounts,and
instead,onlycomputesatable-levelrowcounttogetherwiththetotalnumberoffilebytesinthetableatthattime.
Nopartition metadataismodified. Theinputcardinalityofatablescanisestimatedbyconvertingthedatavolumeof
relevantpartitions toarowcount,basedonthetable-levelrowcountandfilebytesstatistics.Itisassumed thatwithin
thesametable,differentsetsoffileswiththesamedatavolumecorrespondtothesimilarnumberofrowsonaverage.
Withextrapolationenabled, thescancardinalityestimationignoresper-partition rowcounts.Itonlyreliesonthe
table-levelstatisticsandthescanneddatavolume.
TheSHOWTABLESTATSandEXPLAINcommands distinguishbetweenrowcountsstoredintheHiveMetastore,and
therowcountsextrapolatedbasedontheaboveprocess.ConsulttheSHOWTABLESTATSandEXPLAINdocumen tation
formoredetails.
Sampling
ATABLESAMPLEclausemaybeaddedtoCOMPUTE STATStolimitthepercentageofdatatobeprocessed.Thefinal
statisticsareobtainedbyextrapolatingthestatisticsfromthedatasampleovertheentiretable.Theextrapolated
statisticsarestoredintheHiveMetastore,justasifnosampling wasused.ThefollowingexamplerunsCOMPUTE
STATSovera10percentdatasample:COMPUTE STATStest_tableTABLESAMPLESYSTEM(10)
Wehavefoundthata10percentsampling ratetypicallyoffersagoodtradeoffbetweenstatisticsaccuracyandexecution
cost.Asampling ratewellbelow10percenthasshownpoorresultsandisnotrecommended.
Important:Sampling-based techniques sacrificeresultaccuracyforexecutionefficiency,soyour
mileagemayvaryfordifferenttablesandcolumnsdepending ontheirdatadistribution. The
extrapolationprocedureImpalausesforestimatingthenumberofdistinctvaluespercolumnis
inherentlynon-detetministic,soyourresultsmayevenvarybetweenrunsofCOMPUTE STATS
TABLESAMPLE,evenifnodatahaschanged.
COMPUTE INCREMENT ALSTATS
InImpala2.1.0andhigher,youcanusetheCOMPUTE INCREMENTAL STATS andDROP INCREMENTAL STATS
commands. TheINCREMENTAL clausesworkwithincrementalstatistics,aspecializedfeatureforpartitioned tables.
Whenyoucomputeincrementalstatisticsforapartitioned table,bydefaultImpalaonlyprocessesthosepartitions
thatdonotyethaveincrementalstatistics.Byprocessingonlynewlyaddedpartitions, youcankeepstatisticsupto
datewithoutincurring theoverheadofreprocessingtheentiretableeachtime.
Youcanalsocomputeordropstatisticsforaspecified subsetofpartitions byincluding aPARTITION clauseinthe
COMPUTE INCREMENTAL STATS orDROP INCREMENTAL STATS statement.
580|ApacheImpalaGuideTuningImpalaforPerformance
Important:
InImpala3.0andlower,approximately400bytesofmetadatapercolumnperpartition areneeded
forcaching.Tableswithabignumberofpartitions andmanycolumnscanadduptoasignificant
memoryoverheadasthemetadatamustbecachedonthecatalogd hostandoneveryimpalad
hostthatiseligibletobeacoordinator.Ifthismetadataforalltablesexceeds2GB,youmight
experience servicedowntime.InImpala3.1andhigher,theissuewasalleviatedwithanimproved
handlingofincrementalstats.
WhenyourunCOMPUTE INCREMENTAL STATS onatableforthefirsttime,thestatisticsarecomputed
againfromscratchregardlessofwhetherthetablealreadyhasstatistics.Therefore,expectaone-time
resource-intensiveoperationforscanningtheentiretablewhenrunningCOMPUTE INCREMENTAL
STATSforthefirsttimeonagiventable.
Themetadataforincrementalstatisticsishandleddifferentlyfromtheoriginalstyleofstatistics:
â¢IssuingaCOMPUTE INCREMENTAL STATS withoutapartitionclausecausesImpalatocomputeincrementalstats
forallpartitions thatdonotalreadyhaveincrementalstats.Thismightbetheentiretablewhenrunningthe
command forthefirsttime,butsubsequentrunsshouldonlyupdatenewpartitions. Youcanforceupdatinga
partition thatalreadyhasincrementalstatsbyissuingaDROP INCREMENTAL STATS beforerunningCOMPUTE
INCREMENTAL STATS .
â¢TheSHOW TABLE STATS andSHOW PARTITIONS statementsnowincludeanadditional columnshowingwhether
incrementalstatisticsareavailableforeachcolumn.Apartition couldalreadybecoveredbytheoriginaltypeof
statisticsbasedonapriorCOMPUTE STATS statement,asindicatedbyavalueotherthan-1underthe#Rows
column.Impalaqueryplanninguseseitherkindofstatisticswhenavailable.
â¢COMPUTE INCREMENTAL STATS takesmoretimethanCOMPUTE STATS forthesamevolumeofdata.Therefore
itismostsuitablefortableswithlargedatavolumewherenewpartitions areaddedfrequently,makingitimpractical
torunafullCOMPUTE STATS operationforeachnewpartition. Forunpartitioned tables,orpartitioned tables
thatareloadedonceandnotupdatedwithnewpartitions, usetheoriginalCOMPUTE STATS syntax.
â¢COMPUTE INCREMENTAL STATS usessomememoryinthecatalogd process,proportional tothenumberof
partitions andnumberofcolumnsintheapplicabletable.Thememoryoverheadisapproximately400bytesfor
eachcolumnineachpartition. Thismemoryisreservedinthecatalogd daemon, thestatestored daemon,
andineachinstanceoftheimpalad daemon.
â¢Incaseswherenewfilesareaddedtoanexistingpartition, issueaREFRESH statementforthetable,followedby
aDROP INCREMENTAL STATS andCOMPUTE INCREMENTAL STATS sequence forthechangedpartition.
â¢TheDROP INCREMENTAL STATS statementoperatesonlyonasinglepartition atatime.Toremovestatistics
(whetherincrementalornot)fromallpartitions ofatable,issueaDROP STATS statementwithnoINCREMENTAL
orPARTITION clauses.
Thefollowingconsiderationsapplytoincrementalstatisticswhenthestructureofanexistingtableischanged(known
asschemaevolution):
â¢IfyouuseanALTER TABLE statementtodropacolumn,theexistingstatisticsremainvalidandCOMPUTE
INCREMENTAL STATS doesnotrescananypartitions.
â¢IfyouuseanALTER TABLE statementtoaddacolumn,Impalarescansallpartitions andfillsintheappropriate
column-levelvaluesthenexttimeyourunCOMPUTE INCREMENTAL STATS .
â¢IfyouuseanALTER TABLE statementtochangethedatatypeofacolumn,Impalarescansallpartitions andfills
intheappropriatecolumn-levelvaluesthenexttimeyourunCOMPUTE INCREMENTAL STATS .
â¢IfyouuseanALTER TABLE statementtochangethefileformatofatable,theexistingstatisticsremainvalidand
asubsequentCOMPUTE INCREMENTAL STATS doesnotrescananypartitions.
SeeCOMPUTE STATSStatementonpage219andDROPSTATSStatementonpage265forsyntaxdetails.
ApacheImpalaGuide|581TuningImpalaforPerformance
MaximumSerializedStatsSize
InImpala3.0/CDH5.15andlower,whenexecutingCOMPUTE INCREMENTAL STATS onverylargetables,usethe
configurationsetting--inc_stats_size_limit_bytes topreventImpalafromrunningoutofmemorywhile
updatingtablemetadata.Ifthislimitisreached,Impalawillstoploadingthetableandreturnanerror.Theerrorserves
asanindicationthatCOMPUTE INCREMENTAL STATS shouldnotbeusedontheparticular table.Consider spitting
thetableandusingregularCOMPUTE STATS ]ifpossible.
The--inc_stats_size_limit_bytes limitissetasasafetycheck,topreventImpalafromhittingthemaximum
limitforthetablemetadata.Notethatthislimitisonlyonepartoftheentiretable'smetadataallofwhichtogether
mustbebelow2GB.
Thedefaultvaluefor--inc_stats_size_limit_bytes is209715200, 200MB.
Tochangethe--inc_stats_size_limit_bytes value,restartimpaladandcatalogdwiththenewvaluespecified
inbytes,forexample,1048576000 for1GB.SeeModifyingImpalaStartupOptionsforthestepstochangetheoption
andrestartImpaladaemons.
InImpala3.1/CDH5.16/CDH6.1andhigher,ImpalaimprovedhowmetadataisupdatedwhenexecutingCOMPUTE
INCREMENTAL STATS ,significantlyreducingtheneedfor--inc_stats_size_limit_bytes .
DetectingMissingStatistics
YoucancheckwhetheraspecifictablehasstatisticsusingtheSHOW TABLE STATS statement(foranytable)orthe
SHOW PARTITIONS statement(forapartitioned table).Bothstatementsdisplaythesameinformation.Ifatableora
partitiondoesnothaveanystatistics,the#Rowsfieldcontains-1.Onceyoucomputestatisticsforthetableorpartition,
the#Rowsfieldchangestoanaccuratevalue.
Thefollowingexampleshowsatablethatinitiallydoesnothaveanystatistics.TheSHOW TABLE STATS statement
displaysdifferentvaluesfor#RowsbeforeandaftertheCOMPUTE STATS operation.
[localhost:21000] > create table no_stats (x int);
[localhost:21000] > show table stats no_stats;
+-------+--------+------+--------------+--------+-------------------+
| #Rows | #Files | Size | Bytes Cached | Format | Incremental stats |
+-------+--------+------+--------------+--------+-------------------+
| -1    | 0      | 0B   | NOT CACHED   | TEXT   | false             |
+-------+--------+------+--------------+--------+-------------------+
[localhost:21000] > compute stats no_stats;
+-----------------------------------------+
| summary                                 |
+-----------------------------------------+
| Updated 1 partition(s) and 1 column(s). |
+-----------------------------------------+
[localhost:21000] > show table stats no_stats;
+-------+--------+------+--------------+--------+-------------------+
| #Rows | #Files | Size | Bytes Cached | Format | Incremental stats |
+-------+--------+------+--------------+--------+-------------------+
| 0     | 0      | 0B   | NOT CACHED   | TEXT   | false             |
+-------+--------+------+--------------+--------+-------------------+
Thefollowingexampleshowsasimilarprogressionwithapartitioned table.Initially,#Rowsis-1.AfteraCOMPUTE
STATSoperation,#Rowschangestoanaccuratevalue.Anynewlyaddedpartition startswithnostatistics,meaning
thatyoumustcollectstatisticsafteraddinganewpartition.
[localhost:21000] > create table no_stats_partitioned (x int) partitioned by (year 
smallint);
[localhost:21000] > show table stats no_stats_partitioned;
+-------+-------+--------+------+--------------+--------+-------------------+
| year  | #Rows | #Files | Size | Bytes Cached | Format | Incremental stats |
+-------+-------+--------+------+--------------+--------+-------------------+
| Total | -1    | 0      | 0B   | 0B           |        |                   |
+-------+-------+--------+------+--------------+--------+-------------------+
[localhost:21000] > show partitions no_stats_partitioned;
+-------+-------+--------+------+--------------+--------+-------------------+
| year  | #Rows | #Files | Size | Bytes Cached | Format | Incremental stats |
+-------+-------+--------+------+--------------+--------+-------------------+
582|ApacheImpalaGuideTuningImpalaforPerformance
| Total | -1    | 0      | 0B   | 0B           |        |                   |
+-------+-------+--------+------+--------------+--------+-------------------+
[localhost:21000] > alter table no_stats_partitioned add partition (year=2013);
[localhost:21000] > compute stats no_stats_partitioned;
+-----------------------------------------+
| summary                                 |
+-----------------------------------------+
| Updated 1 partition(s) and 1 column(s). |
+-----------------------------------------+
[localhost:21000] > alter table no_stats_partitioned add partition (year=2014);
[localhost:21000] > show partitions no_stats_partitioned;
+-------+-------+--------+------+--------------+--------+-------------------+
| year  | #Rows | #Files | Size | Bytes Cached | Format | Incremental stats |
+-------+-------+--------+------+--------------+--------+-------------------+
| 2013  | 0     | 0      | 0B   | NOT CACHED   | TEXT   | false             |
| 2014  | -1    | 0      | 0B   | NOT CACHED   | TEXT   | false             |
| Total | 0     | 0      | 0B   | 0B           |        |                   |
+-------+-------+--------+------+--------------+--------+-------------------+
Note:BecausethedefaultCOMPUTE STATS statementcreatesandupdatesstatisticsforallpartitions
inatable,ifyouexpecttofrequentlyaddnewpartitions, usetheCOMPUTE INCREMENTAL STATS
syntaxinstead,whichletsyoucomputestatsforasinglespecified partition, oronlyforthosepartitions
thatdonotalreadyhaveincrementalstats.
Ifchecking eachindividual tableisimpractical,duetoalargenumberoftablesorviewsthathidetheunderlying base
tables,youcanalsocheckformissingstatisticsforaparticular query.UsetheEXPLAIN statementtopreviewquery
efficiencybeforeactuallyrunningthequery.UsethequeryprofileoutputavailablethroughthePROFILE command
inimpala-shell orthewebUItoverifyqueryexecutionandtimingafterrunningthequery.BoththeEXPLAIN plan
andthePROFILE outputdisplayawarningifanytablesorpartitions involvedinthequerydonothavestatistics.
[localhost:21000] > create table no_stats (x int);
[localhost:21000] > explain select count(*) from no_stats;
+------------------------------------------------------------------------------------+
| Explain String                                                                     |
+------------------------------------------------------------------------------------+
| Estimated Per-Host Requirements: Memory=10.00MB VCores=1                           |
| WARNING: The following tables are missing relevant table and/or column statistics. |
| incremental_stats.no_stats                                                         |
|                                                                                    |
| 03:AGGREGATE [FINALIZE]                                                            |
| |  output: count:merge(*)                                                          |
| |                                                                                  |
| 02:EXCHANGE [UNPARTITIONED]                                                        |
| |                                                                                  |
| 01:AGGREGATE                                                                       |
| |  output: count(*)                                                                |
| |                                                                                  |
| 00:SCAN HDFS [incremental_stats.no_stats]                                          |
|    partitions=1/1 files=0 size=0B                                                  |
+------------------------------------------------------------------------------------+
BecauseImpalausesthepartition pruningtechnique whenpossibletoonlyevaluatecertainpartitions, ifyouhavea
partitioned tablewithstatisticsforsomepartitions andnotothers,whetherornottheEXPLAIN statementshowsthe
warningdependsontheactualpartitions usedbythequery.Forexample,youmightseewarningsornotfordifferent
queriesagainstthesametable:
-- No warning because all the partitions for the year 2012 have stats.
EXPLAIN SELECT ... FROM t1 WHERE year = 2012;
-- Missing stats warning because one or more partitions in this range
-- do not have stats.
EXPLAIN SELECT ... FROM t1 WHERE year BETWEEN 2006 AND 2009;
Toconfirmifanypartitions atallinthetablearemissingstatistics,youmightexplainaquerythatscanstheentire
table,suchasSELECT COUNT(*) FROM table_name .
ApacheImpalaGuide|583TuningImpalaforPerformance
Manually SettingTableandColumnStatisticswithALTERTABLE
SettingTableStatistics
Themostcrucialpieceofdatainallthestatisticsisthenumberofrowsinthetable(foranunpartitioned orpartitioned
table)andforeachpartition (forapartitioned table).TheCOMPUTE STATS statementalwaysgathersstatisticsabout
allcolumns,aswellasoveralltablestatistics.IfitisnotpracticaltodoafullCOMPUTE STATS orCOMPUTE INCREMENTAL
STATSoperationafteraddingapartitionorinsertingdata,orifyoucanseethatImpalawouldproduceamoreefficient
planifthenumberofrowswasdifferent,youcanmanually setthenumberofrowsthroughanALTER TABLE statement:
-- Set total number of rows. Applies to both unpartitioned and partitioned tables.
alter table table_name  set tblproperties('numRows'=' new_value ', 
'STATS_GENERATED_VIA_STATS_TASK'='true');
-- Set total number of rows for a specific partition. Applies to partitioned tables 
only.
-- You must specify all the partition key columns in the PARTITION clause.
alter table table_name  partition ( keycol1=val1,keycol2=val2...) set 
tblproperties('numRows'=' new_value ', 'STATS_GENERATED_VIA_STATS_TASK'='true');
Thisstatementavoidsre-scanninganydatafiles.(TherequirementtoincludetheSTATS_GENERATED_VIA_STATS_TASK
propertyisrelativelynew,asaresultoftheissueHIVE-8648 fortheHivemetastore.)
create table analysis_data stored as parquet as select * from raw_data;
Inserted 1000000000 rows in 181.98s
compute stats analysis_data;
insert into analysis_data select * from smaller_table_we_forgot_before;
Inserted 1000000 rows in 15.32s
-- Now there are 1001000000 rows. We can update this single data point in the stats.
alter table analysis_data set tblproperties('numRows'='1001000000', 
'STATS_GENERATED_VIA_STATS_TASK'='true');
Forapartitioned table,updateboththeper-partition numberofrowsandthenumberofrowsforthewholetable:
-- If the table originally contained 1 million rows, and we add another partition with
 30 thousand rows,
-- change the numRows property for the partition and the overall table.
alter table partitioned_data partition(year=2009, month=4) set tblproperties 
('numRows'='30000', 'STATS_GENERATED_VIA_STATS_TASK'='true');
alter table partitioned_data set tblproperties ('numRows'='1030000', 
'STATS_GENERATED_VIA_STATS_TASK'='true');
Inpractice,theCOMPUTE STATS statement,orCOMPUTE INCREMENTAL STATS forapartitioned table,shouldbe
fastandconvenientenoughthatthistechnique isonlyusefulfortheverylargestpartitioned tables.Becausethecolumn
statisticsmightbeleftinastalestate,donotusethistechnique asareplacemen tforCOMPUTE STATS .Onlyusethis
technique ifallothermeansofcollectingstatisticsareimpractical,orasalow-overheadoperationthatyourunin
betweenperiodicCOMPUTE STATS orCOMPUTE INCREMENTAL STATS operations.
SettingColumnStatistics
InCDH5.8/Impala2.6andhigher,youcanalsousetheSET COLUMN STATS clauseofALTER TABLE tomanually set
orchangecolumnstatistics.Onlyusethistechnique incaseswhereitisimpracticaltorunCOMPUTE STATS orCOMPUTE
INCREMENTAL STATS frequentlyenoughtokeepupwithdatachangesforahugetable.
Youspecifyacase-insensitiv esymbolicnameforthekindofstatistics:numDVs,numNulls ,avgSize ,maxSize .The
keynamesandvaluesarebothquoted.Thisoperationappliestoanentiretable,notaspecificpartition. Forexample:
create table t1 (x int, s string);
insert into t1 values (1, 'one'), (2, 'two'), (2, 'deux');
show column stats t1;
+--------+--------+------------------+--------+----------+----------+
| Column | Type   | #Distinct Values | #Nulls | Max Size | Avg Size |
+--------+--------+------------------+--------+----------+----------+
584|ApacheImpalaGuideTuningImpalaforPerformance
| x      | INT    | -1               | -1     | 4        | 4        |
| s      | STRING | -1               | -1     | -1       | -1       |
+--------+--------+------------------+--------+----------+----------+
alter table t1 set column stats x ('numDVs'='2','numNulls'='0');
alter table t1 set column stats s ('numdvs'='3','maxsize'='4');
show column stats t1;
+--------+--------+------------------+--------+----------+----------+
| Column | Type   | #Distinct Values | #Nulls | Max Size | Avg Size |
+--------+--------+------------------+--------+----------+----------+
| x      | INT    | 2                | 0      | 4        | 4        |
| s      | STRING | 3                | -1     | 4        | -1       |
+--------+--------+------------------+--------+----------+----------+
ExamplesofUsingTableandColumnStatisticswithImpala
Thefollowingexampleswalkthroughasequence ofSHOW TABLE STATS ,SHOW COLUMN STATS ,ALTER TABLE ,and
SELECTandINSERTstatementstoillustratevariousaspectsofhowImpalausesstatisticstohelpoptimizequeries.
ThisexampleshowstableandcolumnstatisticsfortheSTOREcolumnusedintheTPC-DSbenchmark sfordecision
supportsystems.Itisatinytableholdingdatafor12stores.Initially,beforeanystatisticsaregatheredbyaCOMPUTE
STATSstatement,mostofthenumericfieldsshowplaceholder valuesof-1,indicatingthatthefiguresareunknown.
Thefiguresthatarefilledinarevaluesthatareeasilycountableordeducible atthephysicallevel,suchasthenumber
offiles,totaldatasizeofthefiles,andthemaximumandaveragesizesfordatatypesthathaveaconstantsizesuch
asINT,FLOAT,andTIMESTAMP .
[localhost:21000] > show table stats store;
+-------+--------+--------+--------+
| #Rows | #Files | Size   | Format |
+-------+--------+--------+--------+
| -1    | 1      | 3.08KB | TEXT   |
+-------+--------+--------+--------+
Returned 1 row(s) in 0.03s
[localhost:21000] > show column stats store;
+--------------------+-----------+------------------+--------+----------+----------+
| Column             | Type      | #Distinct Values | #Nulls | Max Size | Avg Size |
+--------------------+-----------+------------------+--------+----------+----------+
| s_store_sk         | INT       | -1               | -1     | 4        | 4        |
| s_store_id         | STRING    | -1               | -1     | -1       | -1       |
| s_rec_start_date   | TIMESTAMP | -1               | -1     | 16       | 16       |
| s_rec_end_date     | TIMESTAMP | -1               | -1     | 16       | 16       |
| s_closed_date_sk   | INT       | -1               | -1     | 4        | 4        |
| s_store_name       | STRING    | -1               | -1     | -1       | -1       |
| s_number_employees | INT       | -1               | -1     | 4        | 4        |
| s_floor_space      | INT       | -1               | -1     | 4        | 4        |
| s_hours            | STRING    | -1               | -1     | -1       | -1       |
| s_manager          | STRING    | -1               | -1     | -1       | -1       |
| s_market_id        | INT       | -1               | -1     | 4        | 4        |
| s_geography_class  | STRING    | -1               | -1     | -1       | -1       |
| s_market_desc      | STRING    | -1               | -1     | -1       | -1       |
| s_market_manager   | STRING    | -1               | -1     | -1       | -1       |
| s_division_id      | INT       | -1               | -1     | 4        | 4        |
| s_division_name    | STRING    | -1               | -1     | -1       | -1       |
| s_company_id       | INT       | -1               | -1     | 4        | 4        |
| s_company_name     | STRING    | -1               | -1     | -1       | -1       |
| s_street_number    | STRING    | -1               | -1     | -1       | -1       |
| s_street_name      | STRING    | -1               | -1     | -1       | -1       |
| s_street_type      | STRING    | -1               | -1     | -1       | -1       |
| s_suite_number     | STRING    | -1               | -1     | -1       | -1       |
| s_city             | STRING    | -1               | -1     | -1       | -1       |
| s_county           | STRING    | -1               | -1     | -1       | -1       |
| s_state            | STRING    | -1               | -1     | -1       | -1       |
| s_zip              | STRING    | -1               | -1     | -1       | -1       |
| s_country          | STRING    | -1               | -1     | -1       | -1       |
| s_gmt_offset       | FLOAT     | -1               | -1     | 4        | 4        |
| s_tax_percentage   | FLOAT     | -1               | -1     | 4        | 4        |
+--------------------+-----------+------------------+--------+----------+----------+
Returned 29 row(s) in 0.04s
ApacheImpalaGuide|585TuningImpalaforPerformance
WiththeHiveANALYZE TABLE statementforcolumnstatistics,youhadtospecifyeachcolumnforwhichtogather
statistics.TheImpalaCOMPUTE STATS statementautomaticallygathersstatisticsforallcolumns,becauseitreads
throughtheentiretablerelativelyquicklyandcanefficientlycomputethevaluesforallthecolumns.Thisexample
showshowafterrunningtheCOMPUTE STATS statement,statisticsarefilledinforboththetableandallitscolumns:
[localhost:21000] > compute stats store;
+------------------------------------------+
| summary                                  |
+------------------------------------------+
| Updated 1 partition(s) and 29 column(s). |
+------------------------------------------+
Returned 1 row(s) in 1.88s
[localhost:21000] > show table stats store;
+-------+--------+--------+--------+
| #Rows | #Files | Size   | Format |
+-------+--------+--------+--------+
| 12    | 1      | 3.08KB | TEXT   |
+-------+--------+--------+--------+
Returned 1 row(s) in 0.02s
[localhost:21000] > show column stats store;
+--------------------+-----------+------------------+--------+----------+-------------------+
| Column             | Type      | #Distinct Values | #Nulls | Max Size | Avg Size    
      |
+--------------------+-----------+------------------+--------+----------+-------------------+
| s_store_sk         | INT       | 12               | -1     | 4        | 4           
      |
| s_store_id         | STRING    | 6                | -1     | 16       | 16          
      |
| s_rec_start_date   | TIMESTAMP | 4                | -1     | 16       | 16          
      |
| s_rec_end_date     | TIMESTAMP | 3                | -1     | 16       | 16          
      |
| s_closed_date_sk   | INT       | 3                | -1     | 4        | 4           
      |
| s_store_name       | STRING    | 8                | -1     | 5        | 4.25        
      |
| s_number_employees | INT       | 9                | -1     | 4        | 4           
      |
| s_floor_space      | INT       | 10               | -1     | 4        | 4           
      |
| s_hours            | STRING    | 2                | -1     | 8        | 
7.083300113677979 |
| s_manager          | STRING    | 7                | -1     | 15       | 12          
      |
| s_market_id        | INT       | 7                | -1     | 4        | 4           
      |
| s_geography_class  | STRING    | 1                | -1     | 7        | 7           
      |
| s_market_desc      | STRING    | 10               | -1     | 94       | 55.5        
      |
| s_market_manager   | STRING    | 7                | -1     | 16       | 14          
      |
| s_division_id      | INT       | 1                | -1     | 4        | 4           
      |
| s_division_name    | STRING    | 1                | -1     | 7        | 7           
      |
| s_company_id       | INT       | 1                | -1     | 4        | 4           
      |
| s_company_name     | STRING    | 1                | -1     | 7        | 7           
      |
| s_street_number    | STRING    | 9                | -1     | 3        | 
2.833300113677979 |
| s_street_name      | STRING    | 12               | -1     | 11       | 
6.583300113677979 |
| s_street_type      | STRING    | 8                | -1     | 9        | 
4.833300113677979 |
| s_suite_number     | STRING    | 11               | -1     | 9        | 8.25        
      |
| s_city             | STRING    | 2                | -1     | 8        | 6.5         
      |
| s_county           | STRING    | 1                | -1     | 17       | 17          
      |
586|ApacheImpalaGuideTuningImpalaforPerformance
| s_state            | STRING    | 1                | -1     | 2        | 2           
      |
| s_zip              | STRING    | 2                | -1     | 5        | 5           
      |
| s_country          | STRING    | 1                | -1     | 13       | 13          
      |
| s_gmt_offset       | FLOAT     | 1                | -1     | 4        | 4           
      |
| s_tax_percentage   | FLOAT     | 5                | -1     | 4        | 4           
      |
+--------------------+-----------+------------------+--------+----------+-------------------+
Returned 29 row(s) in 0.04s
Thefollowingexampleshowshowstatisticsarerepresentedforapartitioned table.Inthiscase,wehavesetupatable
toholdtheworld'smosttrivialcensusdata,asingleSTRINGfield,partitioned byaYEARcolumn.Thetablestatistics
includeaseparateentryforeachpartition, plusfinaltotalsforthenumericfields.Thecolumnstatisticsincludesome
easilydeducible factsforthepartitioning column,suchasthenumberofdistinctvalues(thenumberofpartition
subdirectories).
localhost:21000] > describe census;
+------+----------+---------+
| name | type     | comment |
+------+----------+---------+
| name | string   |         |
| year | smallint |         |
+------+----------+---------+
Returned 2 row(s) in 0.02s
[localhost:21000] > show table stats census;
+-------+-------+--------+------+---------+
| year  | #Rows | #Files | Size | Format  |
+-------+-------+--------+------+---------+
| 2000  | -1    | 0      | 0B   | TEXT    |
| 2004  | -1    | 0      | 0B   | TEXT    |
| 2008  | -1    | 0      | 0B   | TEXT    |
| 2010  | -1    | 0      | 0B   | TEXT    |
| 2011  | 0     | 1      | 22B  | TEXT    |
| 2012  | -1    | 1      | 22B  | TEXT    |
| 2013  | -1    | 1      | 231B | PARQUET |
| Total | 0     | 3      | 275B |         |
+-------+-------+--------+------+---------+
Returned 8 row(s) in 0.02s
[localhost:21000] > show column stats census;
+--------+----------+------------------+--------+----------+----------+
| Column | Type     | #Distinct Values | #Nulls | Max Size | Avg Size |
+--------+----------+------------------+--------+----------+----------+
| name   | STRING   | -1               | -1     | -1       | -1       |
| year   | SMALLINT | 7                | -1     | 2        | 2        |
+--------+----------+------------------+--------+----------+----------+
Returned 2 row(s) in 0.02s
ThefollowingexampleshowshowthestatisticsarefilledinbyaCOMPUTE STATS statementinImpala.
[localhost:21000] > compute stats census;
+-----------------------------------------+
| summary                                 |
+-----------------------------------------+
| Updated 3 partition(s) and 1 column(s). |
+-----------------------------------------+
Returned 1 row(s) in 2.16s
[localhost:21000] > show table stats census;
+-------+-------+--------+------+---------+
| year  | #Rows | #Files | Size | Format  |
+-------+-------+--------+------+---------+
| 2000  | -1    | 0      | 0B   | TEXT    |
| 2004  | -1    | 0      | 0B   | TEXT    |
| 2008  | -1    | 0      | 0B   | TEXT    |
| 2010  | -1    | 0      | 0B   | TEXT    |
| 2011  | 4     | 1      | 22B  | TEXT    |
| 2012  | 4     | 1      | 22B  | TEXT    |
| 2013  | 1     | 1      | 231B | PARQUET |
ApacheImpalaGuide|587TuningImpalaforPerformance
| Total | 9     | 3      | 275B |         |
+-------+-------+--------+------+---------+
Returned 8 row(s) in 0.02s
[localhost:21000] > show column stats census;
+--------+----------+------------------+--------+----------+----------+
| Column | Type     | #Distinct Values | #Nulls | Max Size | Avg Size |
+--------+----------+------------------+--------+----------+----------+
| name   | STRING   | 4                | -1     | 5        | 4.5      |
| year   | SMALLINT | 7                | -1     | 2        | 2        |
+--------+----------+------------------+--------+----------+----------+
Returned 2 row(s) in 0.02s
Forexamplesshowinghowsomequeriesworkdifferentlywhenstatisticsareavailable,seeExamplesofJoinOrder
Optimizationonpage570.YoucanseehowImpalaexecutesaquerydifferentlyineachcasebyobservingtheEXPLAIN
outputbeforeandaftercollectingstatistics.Measurethebeforeandafterquerytimes,andexaminethethroughput
numbersinbeforeandafterSUMMARY orPROFILE output,toverifyhowmuchtheimprovedplanspeedsupperformance.
Benchmarking ImpalaQueries
BecauseImpala,likeotherHadoopcomponen ts,isdesigned tohandlelargedatavolumesinadistributedenvironment,
conductanyperformance testsusingrealisticdataandclusterconfigurations.Useamulti-node clusterratherthana
singlenode;runqueriesagainsttablescontainingterabytesofdataratherthantensofgigabytes.Theparallelprocessing
techniques usedbyImpalaaremostappropriateforworkloadsthatarebeyondthecapacityofasingleserver.
Whenyourunqueriesreturninglargenumbersofrows,theCPUtimetopretty-printtheoutputcanbesubstantial,
givinganinaccuratemeasurementoftheactualquerytime.Consider usingthe-Boptionontheimpala-shell
command toturnoffthepretty-printing,andoptionallythe-ooptiontostorequeryresultsinafileratherthanprinting
tothescreen.Seeimpala-shell ConfigurationOptionsonpage714fordetails.
ControllingImpalaResourceUsage
Sometimes,balancing rawqueryperformance againstscalabilityrequireslimitingtheamountofresources,suchas
memoryorCPU,usedbyasinglequeryorgroupofqueries.Impalacanuseseveralmechanisms thathelptosmooth
outtheloadduringheavyconcurrentusage,resultinginfasteroverallquerytimesandsharingofresourcesacross
Impalaqueries,MapReducejobs,andotherkindsofworkloadsacrossaCDHcluster:
â¢TheImpalaadmission controlfeatureusesafast,distributedmechanism toholdbackqueriesthatexceedlimits
onthenumberofconcurrentqueriesortheamountofmemoryused.Thequeriesarequeued,andexecutedas
otherqueriesfinishandresourcesbecomeavailable.Youcancontroltheconcurrencylimits,andspecifydifferent
limitsfordifferentgroupsofuserstodivideclusterresourcesaccordingtothepriorities ofdifferentclassesof
users.ThisfeatureisnewinImpala1.3.SeeAdmission ControlandQueryQueuingonpage549fordetails.
â¢YoucanrestricttheamountofmemoryImpalareservesduringqueryexecutionbyspecifyingthe-mem_limit
optionfortheimpalad daemon. SeeModifyingImpalaStartupOptionsfordetails.Thislimitappliesonlytothe
memorythatisdirectlyconsumed byqueries;Impalareservesadditional memoryatstartup,forexampletohold
cachedmetadata.
â¢Forproduction deployment,Clouderarecommends thatyouimplemen tresourceisolationusingmechanisms such
ascgroups,whichyoucanconfigureusingClouderaManager.Fordetails,seeStaticResourcePoolsintheCloudera
Managerdocumen tation.
RuntimeFilteringforImpalaQueries(CDH5.7orhigheronly)
Runtimefilteringisawide-rangingoptimizationfeatureavailableinCDH5.7/Impala2.5andhigher.Whenonlya
fractionofthedatainatableisneededforaqueryagainstapartitioned tableortoevaluateajoincondition, Impala
determinestheappropriateconditions whilethequeryisrunning,andbroadcaststhatinformationtoalltheimpalad
588|ApacheImpalaGuideTuningImpalaforPerformance
nodesthatarereadingthetablesothattheycanavoidunnecessar yI/Otoreadpartitiondata,andavoidunnecessar y
networktransmission bysendingonlythesubsetofrowsthatmatchthejoinkeysacrossthenetwork.
Thisfeatureisprimarily usedtooptimizequeriesagainstlargepartitioned tables(underthenamedynamicpartition
pruning)andjoinsoflargetables.Theinformationinthissectionincludesconcepts,internals,andtroubleshooting
informationfortheentireruntimefilteringfeature.Forspecifictuningstepsforpartitioned tables,seeDynamicPartition
Pruningonpage628.
Important:
WhenthisfeaturemadeitsdebutinCDH5.7,thedefaultsettingwasRUNTIME_FILTER_MODE=LOCAL .
NowthedefaultisRUNTIME_FILTER_MODE=GLOBAL inCDH5.8/Impala2.6andhigher,whichenables
morewide-rangingandambitious queryoptimizationwithoutrequiringyoutoexplicitlysetanyquery
options.
BackgroundInformationforRuntimeFiltering
Tounderstandhowruntimefilteringworksatadetailedlevel,youmustbefamiliarwithsometerminology fromthe
fieldofdistributeddatabasetechnology:
â¢Whataplanfragmentis.Impaladecomposes eachqueryintosmallerunitsofworkthataredistributedacross
thecluster.Whereverpossible, adatablockisread,filtered,andaggregatedbyplanfragmentsexecutingonthe
samehost.Forsomeoperations,suchasjoinsandcombining intermediateresultsintoafinalresultset,datais
transmittedacrossthenetworkfromoneImpaladaemontoanother.
â¢WhatSCANandHASH JOIN plannodesare,andtheirroleincomputing queryresults:
IntheImpalaqueryplan,ascannodeperformstheI/Otoreadfromtheunderlying datafiles.Although thisisan
expensiveoperationfromthetraditional databaseperspective,HadoopclustersandImpalaareoptimizedtodo
thiskindofI/Oinahighlyparallelfashion.ThemajorpotentialcostsavingscomefromusingthecolumnarParquet
format(whereImpalacanavoidreadingdataforunneeded columns)andpartitioned tables(whereImpalacan
avoidreadingdataforunneeded partitions).
MostImpalajoinsusethehashjoinmechanism. (ItisonlyfairlyrecentlythatImpalastartedusingthenested-loop
jointechnique, forcertainkindsofnon-equijoin queries.) Inahashjoin,whenevaluatingjoinconditions fromtwo
tables,Impalaconstructsahashtableinmemorywithallthedifferentcolumnvaluesfromthetableononeside
ofthejoin.Then,foreachrowfromthetableontheothersideofthejoin,Impalatestswhethertherelevant
columnvaluesareinthishashtableornot.
Ahashjoinnodeconstructssuchanin-memor yhashtable,thenperformsthecomparisons toidentifywhichrows
matchtherelevantjoinconditions andshouldbeincludedintheresultset(oratleastsentontothesubsequent
intermediatestageofqueryprocessing). Becausesomeoftheinputforahashjoinmightbetransmittedacross
thenetworkfromanotherhost,itisespecially importantfromaperformance perspectivetopruneoutaheadof
timeanydatathatisknowntobeirrelevant.
Themoredistinctvaluesareinthecolumnsusedasjoinkeys,thelargerthein-memor yhashtableandthusthe
morememoryrequiredtoprocessthequery.
â¢Thedifferencebetweenabroadcastjoinandashufflejoin.(TheHadoopnotionofashufflejoinissometimes
referredtoinImpalaasapartitioned join.)Inabroadcastjoin,thetablefromonesideofthejoin(typicallythe
smallertable)issentinitsentiretytoallthehostsinvolvedinthequery.Theneachhostcancompareitsportion
ofthedatafromtheother(larger)tableagainstthefullsetofpossiblejoinkeys.Inashufflejoin,thereisno
obviousâsmallerâtable,andsothecontentsofbothtablesaredividedup,andcorresponding portionsofthedata
aretransmittedtoeachhostinvolvedinthequery.SeeOptimizerHintsinImpalaonpage387forinformation
abouthowthesedifferentkindsofjoinsareprocessed.
â¢ThenotionofthebuildphaseandprobephasewhenImpalaprocessesajoinquery.Thebuildphaseiswherethe
rowscontainingthejoinkeycolumns,typicallyforthesmallertable,aretransmittedacrossthenetworkandbuilt
intoanin-memor yhashtabledatastructureononeormoredestinationnodes.Theprobephaseiswheredata
isreadlocally(typicallyfromthelargertable)andthejoinkeycolumnsarecomparedtothevaluesinthein-memor y
ApacheImpalaGuide|589TuningImpalaforPerformance
hashtable.Thecorresponding inputsources(tables,subqueries, andsoon)forthesephasesarereferredtoas
thebuildsideandtheprobeside.
â¢HowtosetImpalaqueryoptions:interactivelywithinanimpala-shell sessionthroughtheSETcommand, for
aJDBCorODBCapplicationthroughtheSETstatement,orgloballyforallimpalad daemons throughthe
default_query_options configurationsetting.
RuntimeFilteringInternals
Thefilterthatistransmittedbetweenplanfragmentsisessentiallyalistofvaluesforjoinkeycolumns.Whenthislist
ofvaluesistransmittedintimetoascannode,Impalacanfilteroutnon-matchingvaluesimmediatelyafterreading
them,ratherthantransmittingtherawdatatoanotherhosttocompareagainstthein-memor yhashtableonthat
host.
ForHDFS-basedtables,thisdatastructureisimplemen tedasaBloomfilter,whichusesaprobability-based algorithm
todetermineallpossiblematchingvalues.(Theprobability-based aspectsmeansthatthefiltermightincludesome
non-matchingvalues,butifso,thatdoesnotcauseanyinaccuracyinthefinalresults.)
Anotherkindoffilteristheâmin-maxâfilter.ItcurrentlyonlyappliestoKudutables.Thefilterisadatastructure
representingaminimum andmaximumvalue.ThesefiltersarepassedtoKudutoreducethenumberofrowsreturned
toImpalawhenscanningtheprobesideofthejoin.
Therearedifferentkindsoffilterstomatchthedifferentkindsofjoins(partitioned andbroadcast).Abroadcastfilter
reflectsthecompletelistofrelevantvaluesandcanbeimmediatelyevaluatedbyascannode.Apartitioned filter
reflectsonlythevaluesprocessedbyonehostinthecluster;allthepartitioned filtersmustbecombined intoone(by
thecoordinatornode)beforethescannodescanusetheresultstoaccuratelyfilterthedataasitisreadfromstorage.
Broadcastfiltersarealsoclassified aslocalorglobal.Withalocalbroadcastfilter,theinformationinthefilterisused
byasubsequentqueryfragmentthatisrunningonthesamehostthatproducedthefilter.Anon-localbroadcastfilter
mustbetransmittedacrossthenetworktoaqueryfragmentthatisrunningonadifferenthost.Impaladesignates3
hoststoeachproducenon-localbroadcastfilters,toguardagainstthepossibility ofasingleslowhosttakingtoolong.
Depending onthesettingoftheRUNTIME_FILTER_MODE queryoption(LOCALorGLOBAL),Impalaeitherusesa
conservativeoptimizationstrategywherefiltersareonlyconsumed onthesamehostthatproducedthem,oramore
aggressivestrategywherefiltersareeligibletobetransmittedacrossthenetwork.
Note:InCDH5.8/Impala2.6andhigher,thedefaultforruntimefilteringistheGLOBALsetting.
FileFormatConsiderationsforRuntimeFiltering
Parquettablesgetthemostbenefitfromtheruntimefilteringoptimizations.Runtimefilteringcanspeedupjoinqueries
againstpartitioned orunpartitioned Parquettables,andsingle-tablequeriesagainstpartitioned Parquettables.See
UsingtheParquetFileFormatwithImpalaTablesonpage643forinformationaboutusingParquettableswithImpala.
Forotherfileformats(text,Avro,RCFile,andSequenceFile), runtimefilteringspeedsupqueriesagainstpartitioned
tablesonly.Becausepartitioned tablescanuseamixtureofformats,Impalaproducesthefiltersinallcases,evenif
theyarenotultimatelyusedtooptimizethequery.
WaitIntervalsforRuntimeFilters
Becauseittakestimetoproduceruntimefilters,especially forpartitioned filtersthatmustbecombined bythe
coordinatornode,thereisatimeintervalabovewhichitismoreefficientforthescannodestogoaheadandconstruct
theirintermediateresultsets,evenifthatintermediatedataislargerthanoptimal.Ifitonlytakesafewsecondsto
producethefilters,itisworththeextratimeifpruningtheunnecessar ydatacansaveminutesintheoverallquery
time.YoucanspecifythemaximumwaittimeinmillisecondsusingtheRUNTIME_FILTER_WAIT_TIME_MS query
option.
Bydefault,eachscannodewaitsforupto1second(1000milliseconds)forfilterstoarrive.Ifallfiltershavenotarrived
withinthespecified interval,thescannodeproceeds,usingwhateverfiltersdidarrivetohelpavoidreadingunnecessar y
590|ApacheImpalaGuideTuningImpalaforPerformance
data.Ifafilterarrivesafterthescannodebeginsreadingdata,thescannodeappliesthatfiltertothedatathatisread
afterthefilterarrives,butnottothedatathatwasalreadyread.
Iftheclusterisrelativelybusyandyourworkloadcontainsmanyresource-intensiveorlong-running queries,consider
increasingthewaittimesothatcomplicatedqueriesdonotmissopportunities foroptimization.Iftheclusterislightly
loadedandyourworkloadcontainsmanysmallqueriestakingonlyafewseconds,considerdecreasingthewaittime
toavoidthe1seconddelayforeachquery.
QueryOptionsforRuntimeFiltering
Seethefollowingsectionsforinformationaboutthequeryoptionsthatcontrolruntimefiltering:
â¢Thefirstqueryoptionadjuststheâsensitivity âofthisfeature.Bydefault,itissettothehighestlevel(GLOBAL).
(ThisdefaultappliestoCDH5.8/Impala2.6andhigher.Inpreviousreleases,thedefaultwasLOCAL.)
âRUNTIME_FIL TER_MODE QueryOption(CDH5.7orhigheronly)onpage358
â¢Theotherqueryoptionsaretuningknobsthatyoutypicallyonlyadjustafterdoingperformance testing,andthat
youmightwanttochangeonlyforthedurationofasingleexpensivequery:
âMAX_NUM_RUNTIME_FIL TERSQueryOption(CDH5.7orhigheronly)onpage339
âDISABLE_ROW_RUNTIME_FIL TERINGQueryOption(CDH5.7orhigheronly)onpage328
âRUNTIME_FIL TER_MAX_SIZE QueryOption(CDH5.8orhigheronly)onpage357
âRUNTIME_FIL TER_MIN_SIZE QueryOption(CDH5.8orhigheronly)onpage357
âRUNTIME_BL OOM_FILTER_SIZE QueryOption(CDH5.7orhigheronly)onpage356;inCDH5.8/Impala2.6
andhigher,thissettingactsasafallbackwhenstatisticsarenotavailable,ratherthanasadirective.
RuntimeFilteringandQueryPlans
InthesamewaythequeryplandisplayedbytheEXPLAIN statementincludesinformationaboutpredicatesusedby
eachplanfragment,italsoincludesannotationsshowingwhetheraplanfragmentproducesorconsumes aruntime
filter.Aplanfragmentthatproducesafilterincludesanannotationsuchasruntime filters: filter_id  <-
table.column,whileaplanfragmentthatconsumes afilterincludesanannotationsuchasruntime filters:
filter_id  -> table.column.SettingthequeryoptionEXPLAIN_LEVEL=2 addsadditional annotationsshowing
thetypeofthefilter,eitherfilter_id [bloom] (forHDFS-basedtables)orfilter_id [min_max] (forKudutables).
Thefollowingexampleshowsaquerythatusesasingleruntimefilter,labeledRF000,toprunethepartitions based
onevaluatingtheresultsetofasubqueryatruntime:
CREATE TABLE yy (s STRING) PARTITIONED BY (year INT);
INSERT INTO yy PARTITION (year) VALUES ('1999', 1999), ('2000', 2000),
  ('2001', 2001), ('2010', 2010), ('2018', 2018);
COMPUTE STATS yy;
CREATE TABLE yy2 (s STRING, year INT);
INSERT INTO yy2 VALUES ('1999', 1999), ('2000', 2000), ('2001', 2001);
COMPUTE STATS yy2;
-- The following query reads an unknown number of partitions, whose key values
-- are only known at run time. The runtime filters  line shows the
-- information used in query fragment 02 to decide which partitions to skip.
EXPLAIN SELECT s FROM yy WHERE year IN (SELECT year FROM yy2);
+--------------------------------------------------------------------------+
| PLAN-ROOT SINK                                                           |
| |                                                                        |
| 04:EXCHANGE [UNPARTITIONED]                                              |
| |                                                                        |
| 02:HASH JOIN [LEFT SEMI JOIN, BROADCAST]                                 |
| |  hash predicates: year = year                                          |
ApacheImpalaGuide|591TuningImpalaforPerformance
| |  runtime filters: RF000 <- year                                    |
| |                                                                        |
| |--03:EXCHANGE [BROADCAST]                                               |
| |  |                                                                     |
| |  01:SCAN HDFS [default.yy2]                                            |
| |     partitions=1/1 files=1 size=620B                                   |
| |                                                                        |
| 00:SCAN HDFS [default.yy]                                                |
|    partitions=5/5  files=5 size=1.71KB                               |
|    runtime filters: RF000 -> year                                        |
+--------------------------------------------------------------------------+
SELECT s FROM yy WHERE year IN (SELECT year FROM yy2); -- Returns 3 rows from yy
PROFILE;
Thequeryprofile(displayedbythePROFILE command inimpala-shell )containsboththeEXPLAIN planandmore
detailedinformationabouttheinternalworkingsofthequery.TheprofileoutputincludestheFilter routing
tablesectionwithinformationabouteachfilterbasedonitsID.
ExamplesofQueriesthatBenefitfromRuntimeFiltering
Inthisexample,Impalawouldnormally doextraworktointerpretthecolumnsC1,C2,C3,andIDforeachrowin
HUGE_T1 ,beforecheckingtheIDvalueagainstthein-memor yhashtableconstructedfromalltheTINY_T2.ID values.
ByproducingafiltercontainingalltheTINY_T2.ID valuesevenbeforethequerystartsscanningtheHUGE_T1 table,
Impalacanskiptheunnecessar yworktoparsethecolumninfoassoonasitdeterminesthatanIDvaluedoesnot
matchanyofthevaluesfromtheothertable.
TheexampleshowsCOMPUTE STATS statementsforboththetables(eventhoughthatisaone-time operationafter
loadingdataintothosetables)becauseImpalareliesonup-to-datestatisticstodeterminewhichonehasmoredistinct
IDvaluesthantheother.ThatinformationletsImpalamakeeffectivedecisions aboutwhichtabletousetoconstruct
thein-memor yhashtable,andwhichtabletoreadfromdiskandcompareagainsttheentriesinthehashtable.
COMPUTE STATS huge_t1;
COMPUTE STATS tiny_t2;
SELECT c1, c2, c3 FROM huge_t1 JOIN tiny_t2 WHERE huge_t1.id = tiny_t2.id;
Inthisexample,T1isatablepartitioned byyear.ThesubqueryonT2producesmultiplevalues,andtransmitsthose
valuesasafiltertotheplanfragmentsthatarereadingfromT1.Anynon-matchingpartitions inT1areskipped.
select c1 from t1 where year in (select distinct year from t2);
NowtheWHEREclausecontainsanadditional testthatdoesnotapplytothepartitionkeycolumn.Afilteronacolumn
thatisnotapartitionkeyiscalledaper-rowfilter.Becauseper-rowfiltersonlyapplyforParquet,T1mustbeaParquet
table.
Thesubqueries resultintwofiltersbeingtransmittedtothescannodesthatreadfromT1.ThefilteronYEARhelps
thequeryeliminateentirepartitions basedonnon-matchingyears.ThefilteronC2letsImpaladiscardrowswith
non-matchingC2valuesimmediatelyafterreadingthem.Withoutruntimefiltering,Impalawouldhavetokeepthe
non-matchingvaluesinmemory,assembleC1,C2,andC3intorowsintheintermediateresultset,andtransmitall
theintermediaterowsbacktothecoordinatornode,wheretheywouldbeeliminatedonlyattheveryendofthequery.
select c1, c2, c3 from t1
  where year in (select distinct year from t2)
    and c2 in (select other_column from t3);
592|ApacheImpalaGuideTuningImpalaforPerformance
Thisexampleinvolvesabroadcastjoin.ThefactthattheONclausewouldreturnasmallnumberofmatchingrows
(becausetherearenotverymanyrowsinTINY_T2 )meansthatthecorresponding filterisveryselective.Therefore,
runtimefilteringwillprobablybeeffectiveinoptimizingthisquery.
select c1 from huge_t1 join [broadcast] tiny_t2
  on huge_t1.id = tiny_t2.id
  where huge_t1.year in (select distinct year from tiny_t2)
    and c2 in (select other_column from t3);
Thisexampleinvolvesashuffleorpartitioned join.AssumethatmostrowsinHUGE_T1 haveacorresponding rowin
HUGE_T2 .ThefactthattheONclausecouldreturnalargenumberofmatchingrowsmeansthatthecorresponding
filterwouldnotbeveryselective.Therefore,runtimefilteringmightbelesseffectiveinoptimizingthisquery.
select c1 from huge_t1 join [shuffle] huge_t2
  on huge_t1.id = huge_t2.id
  where huge_t1.year in (select distinct year from huge_t2)
    and c2 in (select other_column from t3);
TuningandTroubleshooting QueriesthatUseRuntimeFiltering
Thesetuningandtroubleshooting proceduresapplytoqueriesthatareresource-intensiveenough,long-running
enough,andfrequentenoughthatyoucandevotespecialattentiontooptimizingthemindividually .
UsetheEXPLAIN statementandexaminetheruntime filters: linestodeterminewhetherruntimefiltersare
beingappliedtotheWHEREpredicatesandjoinclausesthatyouexpect.Forexample,runtimefilteringdoesnotapply
toqueriesthatusethenestedloopjoinmechanism duetonon-equijoin operators.
Makesurestatisticsareup-to-dateforalltablesinvolvedinthequeries.UsetheCOMPUTE STATS statementafter
loadingdataintonon-partitioned tables,andCOMPUTE INCREMENTAL STATS afteraddingnewpartitions topartitioned
tables.
Ifjoinqueriesinvolvinglargetablesuseuniquecolumnsasthejoinkeys,forexamplejoiningaprimarykeycolumn
withaforeignkeycolumn,theoverheadofproducingandtransmittingthefiltermightoutweightheperformance
benefitbecausenotmuchdatacouldbeprunedduringtheearlystagesofthequery.Forsuchqueries,considersetting
thequeryoptionRUNTIME_FILTER_MODE=OFF .
LimitationsandRestrictionsforRuntimeFiltering
TheruntimefilteringfeatureismosteffectivefortheParquetfileformats.Forotherfileformats,filteringonlyapplies
forpartitioned tables.SeeFileFormatConsiderationsforRuntimeFilteringonpage590.Forthewaysinwhichruntime
filteringworksforKudutables,seeImpalaQueryPerformance forKuduTablesonpage683.
Whenthespill-to-diskmechanism isactivatedonaparticular hostduringaquery,thathostdoesnotproduceany
filterswhileprocessingthatquery.Thislimitationdoesnotaffectthecorrectnessofresults;itonlyreducestheamount
ofoptimizationthatcanbeappliedtothequery.
UsingHDFSCachingwithImpala(CDH5.3orhigheronly)
HDFScachingprovidesperformance andscalabilitybenefitsinproduction environmentswhereImpalaqueriesand
otherHadoopjobsoperateonquantitiesofdatamuchlargerthanthephysicalRAMontheDataNodes,makingit
impracticaltorelyontheLinuxOScache,whichonlykeepsthemostrecentlyuseddatainmemory.Datareadfrom
theHDFScacheavoidstheoverheadofchecksumming andmemory-to-memor ycopyinginvolvedwhenusingdata
fromtheLinuxOScache.
ApacheImpalaGuide|593TuningImpalaforPerformance
Note:
Onasmallorlightlyloadedcluster,HDFScachingmightnotproduceanyspeedup. Itmightevenlead
toslowerqueries,ifI/Oreadoperationsthatwereperformedinparallelacrosstheentireclusterare
replacedbyin-memor yoperationsoperatingonasmallernumberofhosts.ThehostswheretheHDFS
blocksarecachedcanbecomebottlenecksbecausetheyexperience highCPUloadwhileprocessing
thecacheddatablocks,whileotherhostsremainidle.Therefore,alwayscompareperformance with
andwithoutthisfeatureenabled, usingarealisticworkload.
InCDH5.4/Impala2.2andhigher,youcanspreadtheCPUloadmoreevenlybyspecifyingtheWITH
REPLICATION clauseoftheCREATE TABLE andALTER TABLE statements.Thisclauseletsyou
controlthereplicationfactorforHDFScachingforaspecifictableorpartition. Bydefault,eachcached
blockisonlypresentonasinglehost,whichcanleadtoCPUcontentionifthesamehostprocesses
eachcachedblock.IncreasingthereplicationfactorletsImpalachoosedifferenthoststoprocess
differentcachedblocks,tobetterdistributetheCPUload.AlwaysuseaWITH REPLICATION setting
ofatleast3,andadjustupwardifnecessarytomatchthereplicationfactorfortheunderlying HDFS
datafiles.
InCDH5.7/Impala2.5andhigher,Impalaautomaticallyrandomizeswhichhostprocessesacached
HDFSblock,toavoidCPUhotspots. FortableswhereHDFScachingisnotapplied,Impaladesignates
whichhosttoprocessadatablockusinganalgorithmthatestimatestheloadoneachhost.IfCPU
hotspotsstillariseduringqueries,youcanenableadditional randomizationforthescheduling algorithm
fornon-HDFScacheddatabysettingtheSCHEDULE_RANDOM_REPLICA queryoption.
ForbackgroundinformationabouthowtosetupandmanageHDFScachingforaCDHcluster,seethedocumen tation
forHDFScaching.
OverviewofHDFSCachingforImpala
WithCDH5.1/Impala1.4andhigher,ImpalacanusetheHDFScachingfeaturetomakemoreeffectiveuseofRAM,
sothatrepeatedqueriescantakeadvantageofdataâpinnedâ inmemoryregardlessofhowmuchdataisprocessed
overall.TheHDFScachingfeatureletsyoudesignateasubsetoffrequentlyaccessed datatobepinnedpermanen tly
inmemory,remaining inthecacheacrossmultiplequeriesandneverbeingevicted.Thistechnique issuitablefortables
orpartitions thatarefrequentlyaccessed andaresmallenoughtofitentirelywithintheHDFSmemorycache.For
example,youmightdesignateseveraldimension tablestobepinnedinthecache,tospeedupmanydifferentjoin
queriesthatreferencethem.Orinapartitioned table,youmightpinapartition holdingdatafromthemostrecent
timeperiodbecausethatdatawillbequeriedintensively;thenwhenthenextsetofdataarrives,youcouldunpinthe
previouspartition andpinthepartition holdingthenewdata.
BecausethisImpalaperformance featurereliesonHDFSinfrastructure,itonlyappliestoImpalatablesthatuseHDFS
datafiles.HDFScachingforImpaladoesnotapplytoHBasetables,S3tables,Kudutables,orIsilontables.
SettingUpHDFSCachingforImpala
TouseHDFScachingwithImpala,firstsetupthatfeatureforyourCDHcluster:
â¢DecidehowmuchmemorytodevotetotheHDFScacheoneachhost.Remember thatthetotalmemoryavailable
forcacheddataisthesumofthecachesizesonallthehosts.Bydefault,anydatablockisonlycachedonone
host,although youcancacheablockacrossmultiplehostsbyincreasingthereplicationfactor.
â¢Issuehdfs cacheadmin commands tosetuponeormorecachepools,ownedbythesameuserastheimpalad
daemon(typicallyimpala).Forexample:
hdfs cacheadmin -addPool four_gig_pool -owner impala -limit 4000000000
Fordetailsaboutthehdfs cacheadmin command, seethedocumen tationforHDFScaching.
OnceHDFScachingisenabledandoneormorepoolsareavailable,seeEnablingHDFSCachingforImpalaTablesand
Partitionsonpage595forhowtochoosewhichImpaladatatoloadintotheHDFScache.OntheImpalaside,youspecify
594|ApacheImpalaGuideTuningImpalaforPerformance
thecachepoolnamedefinedbythehdfs cacheadmin command intheImpalaDDLstatementsthatenableHDFS
cachingforatableorpartition, suchasCREATE TABLE ... CACHED IN poolorALTER TABLE ... SET CACHED
IN pool.
EnablingHDFSCachingforImpalaTablesandPartitions
Beginbychoosing whichtablesorpartitions tocache.Forexample,thesemightbelookuptablesthatareaccessed by
manydifferentjoinqueries,orpartitions corresponding tothemostrecenttimeperiodthatareanalyzedbydifferent
reportsoradhocqueries.
InyourSQLstatements,youspecifylogicaldivisionssuchastablesandpartitions tobecached.Impalatranslatesthese
requestsintoHDFS-leveldirectivesthatapplytoparticular directoriesandfiles.Forexample,givenapartitioned table
CENSUSwithapartition keycolumnYEAR,youcouldchoosetocacheallorpartofthedataasfollows:
InCDH5.4/Impala2.2andhigher,theoptionalWITH REPLICATION clauseforCREATE TABLE andALTER TABLE
letsyouspecifyareplicationfactor,thenumberofhostsonwhichtocachethesamedatablocks.WhenImpala
processesacacheddatablock,wherethecachereplicationfactorisgreaterthan1,Impalarandomly selectsahost
thathasacachedcopyofthatdatablock.ThisoptimizationavoidsexcessiveCPUusageonasinglehostwhenthe
samecacheddatablockisprocessedmultipletimes.Clouderarecommends specifyingavaluegreaterthanorequal
totheHDFSblockreplicationfactor.
-- Cache the entire table (all partitions).
alter table census set cached in ' pool_name ';
-- Remove the entire table from the cache.
alter table census set uncached;
-- Cache a portion of the table (a single partition).
-- If the table is partitioned by multiple columns (such as year, month, day),
-- the ALTER TABLE command must specify values for all those columns.
alter table census partition (year=1960) set cached in ' pool_name ';
-- Cache the data from one partition on up to 4 hosts, to minimize CPU load on any
-- single host when the same data block is processed multiple times.
alter table census partition (year=1970)
  set cached in ' pool_name ' with replication = 4;
-- At each stage, check the volume of cached data.
-- For large tables or partitions, the background loading might take some time,
-- so you might have to wait and reissue the statement until all the data
-- has finished being loaded into the cache.
show table stats census;
+-------+-------+--------+------+--------------+--------+
| year  | #Rows | #Files | Size | Bytes Cached | Format |
+-------+-------+--------+------+--------------+--------+
| 1900  | -1    | 1      | 11B  | NOT CACHED   | TEXT   |
| 1940  | -1    | 1      | 11B  | NOT CACHED   | TEXT   |
| 1960  | -1    | 1      | 11B  | 11B          | TEXT   |
| 1970  | -1    | 1      | 11B  | NOT CACHED   | TEXT   |
| Total | -1    | 4      | 44B  | 11B          |        |
+-------+-------+--------+------+--------------+--------+
CREATETABLEconsiderations:
TheHDFScachingfeatureaffectstheImpalaCREATE TABLE statementasfollows:
â¢YoucanputaCACHED IN ' pool_name 'clauseandoptionallyaWITH REPLICATION = number_of_hosts
clauseattheendofaCREATE TABLE statementtoautomaticallycachetheentirecontentsofthetable,including
anypartitions addedlater.Thepool_name isapoolthatyoupreviouslysetupwiththehdfs cacheadmin
command.
â¢OnceatableisdesignatedforHDFScachingthroughtheCREATE TABLE statement,ifnewpartitions areadded
laterthroughALTER TABLE ... ADD PARTITION statements,thedatainthosenewpartitions isautomatically
cachedinthesamepool.
â¢Ifyouwanttoperformrepetitivequeriesonasubsetofdatafromalargetable,anditisnotpracticaltodesignate
theentiretableorspecificpartitions forHDFScaching,youcancreateanewcachedtablewithjustasubsetof
ApacheImpalaGuide|595TuningImpalaforPerformance
thedatabyusingCREATE TABLE ... CACHED IN ' pool_name ' AS SELECT ... WHERE ... .Whenyou
arefinishedwithgeneratingreportsfromthissubsetofdata,dropthetableandboththedatafilesandthedata
cachedinRAMareautomaticallydeleted.
SeeCREATETABLEStatementonpage234forthefullsyntax.
Othermemoryconsiderations:
CertainDDLoperations,suchasALTER TABLE ... SET LOCATION ,areblockedwhiletheunderlying HDFSdirectories
containcachedfiles.Youmustuncachethefilesfirst,beforechanging thelocation,droppingthetable,andsoon.
Whendataisrequestedtobepinnedinmemory,thatprocesshappensinthebackgroundwithoutblockingaccessto
thedatawhilethecachingisinprogress.Loadingthedatafromdiskcouldtakesometime.ImpalareadseachHDFS
datablockfrommemoryifithasbeenpinnedalready,orfromdiskifithasnotbeenpinnedyet.
TheamountofdatathatyoucanpinoneachnodethroughtheHDFScachingmechanism issubjecttoaquotathatis
enforcedbytheunderlying HDFSservice.BeforerequestingtopinanImpalatableorpartition inmemory,checkthat
itssizedoesnotexceedthisquota.
Note:BecausetheHDFScacheconsistsofcombined memoryfromalltheDataNodesinthecluster,
cachedtablesorpartitions canbebiggerthantheamountofHDFScachememoryonanysinglehost.
LoadingandRemovingDatawithHDFSCachingEnabled
WhenHDFScachingisenabled, extraprocessinghappensinthebackgroundwhenyouaddorremovedatathrough
statementssuchasINSERTandDROP TABLE .
Inserting orloadingdata:
â¢WhenImpalaperformsanINSERTorLOAD DATA statementforatableorpartition thatiscached,thenewdata
filesareautomaticallycachedandImpalarecognizesthatfactautomatically.
â¢IfyouperformanINSERTorLOAD DATA throughHive,asalways,Impalaonlyrecognizesthenewdatafilesafter
aREFRESH table_name statementinImpala.
â¢Ifthecachepoolisentirelyfull,orbecomesfullbeforealltherequesteddatacanbecached,theImpalaDDL
statementreturnsanerror.Thisistoavoidsituationswhereonlysomeoftherequesteddatacouldbecached.
â¢WhenHDFScachingisenabledforatableorpartition, newdatafilesarecachedautomaticallywhentheyare
addedtotheappropriatedirectoryinHDFS,withouttheneedforaREFRESH statementinImpala.Impala
automaticallyperformsaREFRESH oncethenewdataisloadedintotheHDFScache.
Droppingtables,partitions, orcachepools:
TheHDFScachingfeatureinteractswiththeImpalaDROP TABLE andALTER TABLE ... DROP PARTITION statements
asfollows:
â¢WhenyouissueaDROP TABLE foratablethatisentirelycached,orhassomepartitions cached,theDROP TABLE
succeeds andallthecachedirectivesImpalasubmittedforthattableareremovedfromtheHDFScachesystem.
â¢ThesameappliestoALTER TABLE ... DROP PARTITION .Theoperationsucceeds andanycachedirectives
areremoved.
â¢Asalways,theunderlying datafilesareremovedifthedroppedtableisaninternaltable,orthedroppedpartition
isinitsdefaultlocationundernea thaninternaltable.Thedatafilesareleftaloneifthedroppedtableisanexternal
table,orifthedroppedpartition isinanon-defaultlocation.
â¢Ifyoudesignatedthedatafilesascachedthroughthehdfs cacheadmin command, andthedatafilesareleft
behindasdescribed inthepreviousitem,thedatafilesremaincached.Impalaonlyremovesthecachedirectives
submittedbyImpalathroughtheCREATE TABLE orALTER TABLE statements.ItisOKtohavemultipleredundant
cachedirectivespertainingtothesamefiles;thedirectivesallhaveuniqueIDsandownerssothatthesystemcan
tellthemapart.
â¢IfyoudropanHDFScachepoolthroughthehdfs cacheadmin command, alltheImpaladatafilesarepreserved,
justnolongercached.AfterasubsequentREFRESH,SHOW TABLE STATS reports0bytescachedforeachassociated
Impalatableorpartition.
596|ApacheImpalaGuideTuningImpalaforPerformance
Relocatingatableorpartition:
TheHDFScachingfeatureinteractswiththeImpalaALTER TABLE ... SET LOCATION statementasfollows:
â¢Ifyouhavedesignatedatableorpartition ascachedthroughtheCREATE TABLE orALTER TABLE statements,
subsequentattemptstorelocatethetableorpartitionthroughanALTER TABLE ... SET LOCATION statement
willfail.YoumustissueanALTER TABLE ... SET UNCACHED statementforthetableorpartitionfirst.Otherwise,
Impalawouldlosetrackofsomecacheddatafilesandhavenowaytouncachethemlater.
AdministrationforHDFSCachingwithImpala
Herearetheguidelines andstepstocheckorchangethestatusofHDFScachingforImpaladata:
hdfscacheadmin command:
â¢Ifyoudropacachepoolwiththehdfs cacheadmin command, Impalaqueriesagainsttheassociateddatafiles
willstillwork,byfallingbacktoreadingthefilesfromdisk.AfterperformingaREFRESH onthetable,Impala
reportsthenumberofbytescachedas0forallassociatedtablesandpartitions.
â¢Youmightusehdfs cacheadmin togetalistofexistingcachepools,ordetailedinformationaboutthepools,
asfollows:
hdfs cacheadmin -listDirectives         # Basic info
Found 122 entries
  ID POOL       REPL EXPIRY  PATH
 123 testPool      1 never   /user/hive/warehouse/tpcds.store_sales
 124 testPool      1 never   /user/hive/warehouse/tpcds.store_sales/ss_date=1998-01-15
 125 testPool      1 never   /user/hive/warehouse/tpcds.store_sales/ss_date=1998-02-01
...
hdfs cacheadmin -listDirectives -stats  # More details
Found 122 entries
  ID POOL       REPL EXPIRY  PATH                                                        BYTES_NEEDED  BYTES_CACHED  FILES_NEEDED
  FILES_CACHED
 123 testPool      1 never   /user/hive/warehouse/tpcds.store_sales                                 0             0             0
             0
 124 testPool      1 never   /user/hive/warehouse/tpcds.store_sales/ss_date=1998-01-15         143169        143169             1
             1
 125 testPool      1 never   /user/hive/warehouse/tpcds.store_sales/ss_date=1998-02-01         112447        112447             1
             1
...
ImpalaSHOWstatement:
â¢Foreachtableorpartition, theSHOW TABLE STATS orSHOW PARTITIONS statementdisplaysthenumberof
bytescurrentlycachedbytheHDFScachingfeature.Iftherearenocachedirectivesinplaceforthattableor
partition, theresultsetdisplaysNOT CACHED .Avalueof0,orasmallernumberthantheoverallsizeofthetable
orpartition, indicatesthatthecacherequesthasbeensubmittedbutthedatahasnotbeenentirelyloadedinto
memoryyet.SeeSHOWStatementonpage363fordetails.
ClouderaManager:
â¢YoucanenableordisableHDFScachingthroughClouderaManager,usingtheconfigurationsettingMaximum
MemoryUsedforCachingfortheHDFSservice.ThiscontrolsetstheHDFSconfigurationparameter
dfs_datanode_max_locked_memory ,whichspecifiestheupperlimitofHDFScachesizeoneachnode.
â¢AlltheothermanipulationoftheHDFScachingsettings,suchaswhatfilesarecached,isdonethroughthecommand
line,eitherImpalaDDLstatementsortheLinuxhdfs cacheadmin command.
Impalamemorylimits:
TheImpalaHDFScachingfeatureinteractswiththeImpalamemorylimitsasfollows:
â¢ThemaximumsizeofeachHDFScachepoolisspecified externallytoImpala,throughthehdfs cacheadmin
command.
â¢AllthememoryusedforHDFScachingisseparatefromtheimpalad daemonaddressspaceanddoesnotcount
towardsthelimitsofthe--mem_limit startupoption,MEM_LIMIT queryoption,orfurtherlimitsimposed
throughYARNresourcemanagementortheLinuxcgroups mechanism.
â¢Becauseaccessing HDFScacheddataavoidsamemory-to-memor ycopyoperation,queriesinvolvingcacheddata
requirelessmemoryontheImpalasidethantheequivalentqueriesonuncacheddata.Inadditiontoany
performance benefitsinasingle-user environment,thereducedmemoryhelpstoimprovescalabilityunder
high-concurrencyworkloads.
ApacheImpalaGuide|597TuningImpalaforPerformance
Performance ConsiderationsforHDFSCachingwithImpala
InImpala1.4.0andhigher,Impalasupports efficientreadsfromdatathatispinnedinmemorythroughHDFScaching.
ImpalatakesadvantageoftheHDFSAPIandreadsthedatafrommemoryratherthanfromdiskwhetherthedatafiles
arepinnedusingImpalaDDLstatements,orusingthecommand-line mechanism whereyouspecifyHDFSpaths.
Whenyouexaminetheoutputoftheimpala-shell SUMMARY command, orlookinthemetricsreportfortheimpalad
daemon, youseehowmanybytesarereadfromtheHDFScache.Forexample,thisexcerptfromaqueryprofile
illustratesthatallthedatareadduringaparticular phaseofthequerycamefromtheHDFScache,becausethe
BytesRead andBytesReadDataNodeCache valuesareidentical.
HDFS_SCAN_NODE (id=0):(Total: 11s114ms, non-child: 11s114ms, % non-child: 100.00%)
        - AverageHdfsReadThreadConcurrency: 0.00
        - AverageScannerThreadConcurrency: 32.75
        - BytesRead: 10.47 GB (11240756479)
        - BytesReadDataNodeCache: 10.47 GB (11240756479)
        - BytesReadLocal: 10.47 GB (11240756479)
        - BytesReadShortCircuit: 10.47 GB (11240756479)
        - DecompressionTime: 27s572ms
Forqueriesinvolvingsmalleramountsofdata,orinsingle-user workloads, youmightnotnoticeasignificantdifference
inqueryresponsetimewithorwithoutHDFScaching.EvenwithHDFScachingturnedoff,thedataforthequerymight
stillbeintheLinuxOSbuffercache.Thebenefitsbecomeclearerasdatavolumeincreases,andespecially asthesystem
processesmoreconcurrentqueries.HDFScachingimprovesthescalabilityoftheoverallsystem.Thatis,itprevents
queryperformance fromdeclining whentheworkloadoutstripsthecapacityoftheLinuxOScache.
DuetoalimitationofHDFS,zero-copyreadsarenotsupportedwithencryption.Clouderarecommends notusingHDFS
cachingforImpaladatafilesinencryptionzones.Thequeriesfallbacktothenormalreadpathduringqueryexecution,
whichmightcausesomeperformance overhead.
SELECTconsiderations:
TheImpalaHDFScachingfeatureinteractswiththeSELECTstatementandqueryperformance asfollows:
â¢Impalaautomaticallyreadsfrommemoryanydatathathasbeendesignatedascachedandactuallyloadedinto
theHDFScache.(Itcouldtakesometimeaftertheinitialrequesttofullypopulatethecacheforatablewithlarge
sizeormanypartitions.) Thespeedupcomesfromtwoaspects:readingfromRAMinsteadofdisk,andaccessing
thedatastraightfromthecacheareainsteadofcopyingfromoneRAMareatoanother.Thissecondaspectyields
furtherperformance improvementoverthestandardOScachingmechanism, whichstillresultsin
memory-to-memor ycopyingofcacheddata.
â¢Forsmallamountsofdata,thequeryspeedupmightnotbenoticeable intermsofwallclocktime.Theperformance
mightberoughlythesamewithHDFScachingturnedonoroff,duetorecentlyuseddatabeingheldintheLinux
OScache.Thedifferenceismorepronounced with:
âDatavolumes(forallqueriesrunningconcurrently)thatexceedthesizeoftheLinuxOScache.
âAbusyclusterrunningmanyconcurrentqueries,wherethereduction inmemory-to-memor ycopyingand
overallmemoryusageduringqueriesresultsingreaterscalabilityandthroughput.
âThus,toreallyexerciseandbenchmark thisfeatureinadevelopmentenvironment,youmightneedtosimulate
realisticworkloadsandconcurrentqueriesthatmatchyourproduction environment.
âOnewaytosimulateaheavyworkloadonalightlyloadedsystemistoflushtheOSbuffercache(oneach
DataNode)betweeniterationsofqueriesagainstthesametablesorpartitions:
sync
echo 1 > /proc/sys/vm/drop_caches
â¢ImpalaqueriestakeadvantageofHDFScacheddataregardlessofwhetherthecachedirectivewasissuedby
Impalaorexternallythroughthehdfs cacheadmin command, forexampleforanexternaltablewherethe
cacheddatafilesmightbeaccessed byseveraldifferentHadoopcomponen ts.
â¢Ifyourqueryreturnsalargeresultset,thetimereportedforthequerycouldbedominatedbythetimeneeded
toprinttheresultsonthescreen.Tomeasurethetimefortheunderlying queryprocessing,querytheCOUNT()
ofthebigresultset,whichdoesallthesameprocessingbutonlyprintsasinglelinetothescreen.
598|ApacheImpalaGuideTuningImpalaforPerformance
DetectingandCorrectingHDFSBlockSkewConditions
Forbestperformance ofImpalaparallelqueries,theworkisdividedequallyacrosshostsinthecluster,andallhosts
takeapproximatelyequaltimetofinishtheirwork.Ifonehosttakessubstantiallylongerthanothers,theextratime
neededfortheslowhostcanbecomethedominantfactorinqueryperformance. Therefore,oneofthefirststepsin
performance tuningforImpalaistodetectandcorrectsuchconditions.
Themaincauseofunevenperformance thatyoucancorrectwithinImpalaisskewinthenumberofHDFSdatablocks
processedbyeachhost,wheresomehostsprocesssubstantiallymoredatablocksthanothers.Thisconditioncan
occurbecauseofunevendistribution ofthedatavaluesthemselves,forexamplecausingcertaindatafilesorpartitions
tobelargewhileothersareverysmall.(Although itispossibletohaveunevenlydistributeddatawithoutanyproblems
withthedistribution ofHDFSblocks.)Blockskewcouldalsobeduetotheunderlying blockallocationpolicieswithin
HDFS,thereplicationfactorofthedatafiles,andthewaythatImpalachoosesthehosttoprocesseachdatablock.
Themostconvenientwaytodetectblockskew,orslow-hostissuesingeneral,istoexaminetheâexecutivesummaryâ
informationfromthequeryprofileafterrunningaquery:
â¢Inimpala-shell ,issuetheSUMMARY command immediatelyafterthequeryiscomplete,toseejustthesummary
information.Ifyoudetectissuesinvolvingskew,youmightswitchtoissuingthePROFILE command, whichdisplays
thesummaryinformationfollowedbyadetailedperformance analysis.
â¢IntheClouderaManagerinterfaceortheImpaladebugwebUI,clickontheProfilelinkassociatedwiththequery
afteritiscomplete.Theexecutivesummaryinformationisdisplayedearlyintheprofileoutput.
Foreachphaseofthequery,youseeanAvgTimeandaMaxTimevalue,alongwith#Hostsindicatinghowmanyhosts
areinvolvedinthatqueryphase.Forallthephaseswith#Hostsgreaterthanone,lookforcaseswherethemaximum
timeissubstantiallygreaterthantheaveragetime.Focusonthephasesthattookthelongest,forexample,those
takingmultiplesecondsratherthanmillisecondsormicroseconds.
Ifyoudetectthatsomehoststakelongerthanothers,firstruleoutnon-Impala causes.Onereasonthatsomehosts
couldbeslowerthanothersisifthosehostshavelesscapacitythantheothers,oriftheyaresubstantiallybusierdue
tounevenlydistributednon-Impala workloads:
â¢ForclustersrunningImpala,keeptherelativecapacities ofallhostsroughlyequal.Anycostsavingsfromincluding
someunderpoweredhostsintheclusterwilllikelybeoutweighedbypoororunevenperformance, andthetime
spentdiagnosing performance issues.
â¢Ifnon-Impala workloadscauseslowdownsonsomehostsbutnotothers,usetheappropriateload-balancing
techniques forthenon-Impala componen tstosmoothouttheloadacrossthecluster.
Ifthehostsonyourclusterareevenlypoweredandevenlyloaded,examinethedetailedprofileoutputtodetermine
whichhostistakinglongerthanothersforthequeryphaseinquestion.Examinehowmanybytesareprocessedduring
thatphaseonthathost,howmuchmemoryisused,andhowmanybytesaretransmittedacrossthenetwork.
Themostcommonsymptomisahighernumberofbytesreadononehostthanothers,duetoonehostbeingrequested
toprocessahighernumberofHDFSdatablocks.Thisconditionismorelikelytooccurwhenthenumberofblocks
accessed bythequeryisrelativelysmall.Forexample,ifyouhavea10-nodeclusterandthequeryprocesses10HDFS
blocks,eachnodemightnotprocessexactlyoneblock.Ifonenodesitsidlewhileanothernodeprocessestwoblocks,
thequerycouldtaketwiceaslongasifthedatawasperfectlydistributed.
Possiblesolutions inthiscaseinclude:
â¢Ifthequeryisartificially small,perhapsforbenchmarking purposes, scaleituptoprocessalargerdataset.For
example,ifsomenodesread10HDFSdatablockswhileothersread11,theoveralleffectoftheunevendistribution
ismuchlowerthanwhensomenodesdidtwiceasmuchworkasothers.Asaguideline, aimforaâsweetspotâ
whereeachnodereads2GBormorefromHDFSperquery.Queriesthatprocesslowervolumesthanthatcould
experience inconsistentperformance thatsmoothsoutasqueriesbecomemoredata-intensive.
â¢Ifthequeryprocessesonlyafewlargeblocks,sothatmanynodessitidleandcannothelptoparallelizethequery,
considerreducingtheoverallblocksize.Forexample,youmightadjustthePARQUET_FILE_SIZE queryoption
ApacheImpalaGuide|599TuningImpalaforPerformance
beforecopyingorconvertingdataintoaParquettable.Oryoumightadjustthegranularity ofdatafilesproduced
earlierintheETLpipelinebynon-Impala componen ts.InImpala2.0andlater,thedefaultParquetblocksizeis
256MB,reducedfrom1GB,toimproveparallelismforcommonclustersizesanddatavolumes.
â¢Reducetheamountofcompressionappliedtothedata.Fortextdatafiles,thehighestdegreeofcompression
(gzip)producesunsplittablefilesthataremoredifficultforImpalatoprocessinparallel,andrequireextramemory
duringprocessingtoholdthecompressedanduncompresseddatasimultaneously.Forbinaryformatssuchas
ParquetandAvro,compressioncanresultinfewerdatablocksoverall,butremember thatwhenqueriesprocess
relativelyfewblocks,thereislessopportunity forparallelexecutionandmanynodesintheclustermightsitidle.
NotethatwhenImpalawritesParquetdatawiththequeryoptionCOMPRESSION_CODEC=NONE enabled,thedata
isstilltypicallycompactduetotheencodingschemesusedbyParquet,independen tofthefinalcompression
step.
DataCacheforRemoteReads
WhenImpalacomputenodesanditsstoragearenotco-located,thenetworkbandwidth requirementgoesupasthe
networktrafficincludesthedatafetchaswellastheshufflingexchangetrafficofintermediateresults.
Note:Thisisanexperimen talfeatureinImpala3.3/CDH6.3andisnotgenerallysupported.
Tomitigatethepressureonthenetwork,youcanenablethecomputenodestocachetheworkingsetreadfromremote
filesystems,suchas,remoteHDFSdatanode,S3,ABFS,ADLS.
Toenableremotedatacache:
1.InClouderaManager,navigatetoClusters>ImpalaService>.
2.IntheConfigurationtab,selectImpalaDaemoninScope,andselectAdvancedinCategory.
3.EnterthefollowingintheImpalaDaemonCommand LineArgumentAdvancedConfigurationSnippet(Safety
Valve)field,setthe--data_cache ImpalaDaemonstart-upflagasbelow:
--data_cache=dir1,dir2,dir3,...:quota
Theflagissettoalistofdirectories,separatedby,,followedbya:,andacapacityquotaperdirectory.
Thedirectoriesmustbespecified inabsolutepath.
4.ClickSaveChangesandrestarttheImpalaservice.
Ifsettoanemptystring,datacachingisdisabled.
Cacheddataisstoredinthespecified directories.
Thespecified directoriesmustexistinthelocalfilesystemofeachImpalaDaemon, orImpalawillfailtostart.
Inaddition, thefilesystemwhichthedirectoryresidesinmustsupportholepunching.
Thecachecanconsumeuptothequotabytesforeachofthedirectoriesspecified.
Thedefaultsettingfor--data_cache isanemptystring.
Forexample,withthefollowingsetting,thedatacachemayuseupto2TB,with1TBmaxin/data/0 and/data/1
respectively.
--data_cache=/data/0,/data/1:1TB
600|ApacheImpalaGuideTuningImpalaforPerformance
TestingImpalaPerformance
TesttoensurethatImpalaisconfiguredforoptimalperformance. IfyouhaveinstalledImpalawithoutCloudera
Manager,completetheprocessesdescribed inthistopictohelpensureaproperconfiguration.Evenifyouinstalled
ImpalawithClouderaManager,whichautomaticallyappliesappropriateconfigurations,theseprocedurescanbeused
toverifythatImpalaissetupcorrectly.
Checking ImpalaConfigurationValues
YoucaninspectImpalaconfigurationvaluesbyconnecting toyourImpalaserverusingabrowser.
TocheckImpalaconfigurationvalues:
1.Useabrowsertoconnecttooneofthehostsrunningimpalad inyourenvironment.Connectusinganaddress
oftheformhttp://hostname :port/varz.
Note:Intheprecedingexample,replacehostname andportwiththenameandportofyour
Impalaserver.Thedefaultportis25000.
2.Reviewtheconfiguredvalues.
Forexample,tocheckthatyoursystemisconfiguredtouseblocklocalitytrackinginformation,youwouldcheck
thatthevaluefordfs.datanode.hdfs-blocks-metadata.enabled istrue.
Tocheckdatalocality:
1.Executeaqueryonadatasetthatisavailableacrossmultiplenodes.Forexample,foratablenamedMyTable
thathasareasonable chanceofbeingspreadacrossmultipleDataNodes:
[impalad-host:21000] > SELECT COUNT (*) FROM MyTable
2.Afterthequerycompletes,reviewthecontentsoftheImpalalogs.Youshouldfindarecentmessagesimilarto
thefollowing:
Total remote scan volume = 0
Thepresenceofremotescansmayindicateimpalad isnotrunningonthecorrectnodes.Thiscanbebecausesome
DataNodesdonothaveimpalad runningoritcanbebecausetheimpalad instancethatisstartingthequeryisunable
tocontactoneormoreoftheimpalad instances.
Tounderstandthecausesofthisissue:
1.Connecttothedebuggingwebserver.Bydefault,thisserverrunsonport25000.Thispagelistsallimpalad
instancesrunninginyourcluster.Iftherearefewerinstancesthanyouexpect,thisoftenindicatessomeDataNodes
arenotrunningimpalad .Ensureimpalad isstartedonallDataNodes.
2.Ifyouareusingmulti-homed hosts,ensurethattheImpaladaemon's hostnameresolvestotheinterfaceonwhich
impalad isrunning.ThehostnameImpalaisusingisdisplayedwhenimpalad starts.Toexplicitlysetthehostname,
usethe--hostname flag.
3.Checkthatstatestored isrunningasexpected.Reviewthecontentsofthestatestorelogtoensureallinstances
ofimpalad arelistedashavingconnectedtothestatestore.
ReviewingImpalaLogs
YoucanreviewthecontentsoftheImpalalogsforsignsthatshort-circuitreadsorblocklocationtrackingarenot
functioning. Beforechecking logs,executeasimplequeryagainstasmallHDFSdataset.Completingaquerytask
generateslogmessagesusingcurrentsettings.InformationonexecutingqueriescanbefoundinUsingtheImpala
ApacheImpalaGuide|601TuningImpalaforPerformance
Shell(impala-shell Command) onpage713.InformationonloggingcanbefoundinUsingImpalaLoggingonpage709.
Logmessagesandtheirinterpretationsareasfollows:
Interpretation LogMessage
Trackingblocklocalityisnot
enabled.Unknown disk id. This will negatively affect performance. Check 
your hdfs settings to enable block location metadata
Nativechecksumming isnot
enabled.Unable to load native-hadoop library for your platform... using 
builtin-java classes where applicable
UnderstandingImpalaQueryPerformance -EXPLAINPlansandQueryProfiles
Tounderstandthehigh-levelperformanceconsiderationsforImpalaqueries,readtheoutputoftheEXPLAIN statement
forthequery.YoucangettheEXPLAIN planwithoutactuallyrunningthequeryitself.
Foranoverviewofthephysicalperformancecharacteristicsforaquery,issuetheSUMMARY statementinimpala-shell
immediatelyafterexecutingaquery.Thiscondensed informationshowswhichphasesofexecutiontookthemost
time,andhowtheestimatesformemoryusageandnumberofrowsateachphasecomparetotheactualvalues.
Tounderstandthedetailedperformance characteristicsforaquery,issuethePROFILE statementinimpala-shell
immediatelyafterexecutingaquery.Thislow-levelinformationincludesphysicaldetailsaboutmemory,CPU,I/O,and
networkusage,andthusisonlyavailableafterthequeryisactuallyrun.
Also,seePerformance ConsiderationsfortheImpala-HBase Integrationonpage685andUnderstandingandTuning
ImpalaQueryPerformance forS3Dataonpage697forexamplesofinterpretingEXPLAIN plansforqueriesagainst
HBasetablesanddatastoredintheAmazonSimpleStorageSystem(S3).
UsingtheEXPLAINPlanforPerformance Tuning
TheEXPLAIN statementgivesyouanoutlineofthelogicalstepsthataquerywillperform,suchashowtheworkwill
bedistributedamongthenodesandhowintermediateresultswillbecombined toproducethefinalresultset.You
canseethesedetailsbeforeactuallyrunningthequery.Youcanusethisinformationtocheckthatthequerywillnot
operateinsomeveryunexpectedorinefficientway.
[impalad-host:21000] > explain select count(*) from customer_address;
+----------------------------------------------------------+
| Explain String                                           |
+----------------------------------------------------------+
| Estimated Per-Host Requirements: Memory=42.00MB VCores=1 |
|                                                          |
| 03:AGGREGATE [MERGE FINALIZE]                            |
| |  output: sum(count(*))                                 |
| |                                                        |
| 02:EXCHANGE [PARTITION=UNPARTITIONED]                    |
| |                                                        |
| 01:AGGREGATE                                             |
| |  output: count(*)                                      |
| |                                                        |
| 00:SCAN HDFS [default.customer_address]                  |
|    partitions=1/1 size=5.25MB                            |
+----------------------------------------------------------+
ReadtheEXPLAIN planfrombottomtotop:
â¢Thelastpartoftheplanshowsthelow-leveldetailssuchastheexpectedamountofdatathatwillberead,where
youcanjudgetheeffectivenessofyourpartitioning strategyandestimatehowlongitwilltaketoscanatable
basedontotaldatasizeandthesizeofthecluster.
â¢Asyouworkyourwayup,nextyouseetheoperationsthatwillbeparallelizedandperformedoneachImpala
node.
â¢Atthehigherlevels,youseehowdataflowswhenintermediateresultsetsarecombined andtransmittedfrom
onenodetoanother.
602|ApacheImpalaGuideTuningImpalaforPerformance
â¢SeeEXPLAIN_LEVEL QueryOptiononpage331fordetailsabouttheEXPLAIN_LEVEL queryoption,whichletsyou
customizehowmuchdetailtoshowintheEXPLAIN plandepending onwhetheryouaredoinghigh-levelor
low-leveltuning,dealingwithlogicalorphysicalaspectsofthequery.
TheEXPLAIN planisalsoprintedatthebeginning ofthequeryprofilereportdescribed inUsingtheQueryProfilefor
Performance Tuningonpage604,forconvenienceinexaminingboththelogicalandphysicalaspectsofthequery
side-by-side.
TheamountofdetaildisplayedintheEXPLAIN outputiscontrolledbytheEXPLAIN_LEVEL queryoption.Youtypically
increasethissettingfromstandard toextended (orfrom1to2)whendoublechecking thepresenceoftableand
columnstatisticsduringperformancetuning,orwhenestimatingqueryresourceusageinconjunction withtheresource
managementfeaturesinCDH5.
UsingtheSUMMAR YReportforPerformance Tuning
TheSUMMARY command withintheimpala-shell interpretergivesyouaneasy-to-digestoverviewofthetimings
forthedifferentphasesofexecutionforaquery.LiketheEXPLAIN plan,itiseasytoseepotentialperformance
bottlenecks.LikethePROFILE output,itisavailableafterthequeryisrunandsodisplaysactualtimingnumbers.
TheSUMMARY reportisalsoprintedatthebeginning ofthequeryprofilereportdescribed inUsingtheQueryProfile
forPerformance Tuningonpage604,forconvenienceinexamininghigh-levelandlow-levelaspectsofthequery
side-by-side.
Forexample,hereisaqueryinvolvinganaggregatefunction, onasingle-node VM.Thedifferentstagesofthequery
andtheirtimingsareshown(rolledupforallnodes),alongwithestimatedandactualvaluesusedinplanningthequery.
Inthiscase,theAVG()functioniscomputedforasubsetofdataoneachnode(stage01)andthentheaggregated
resultsfromallnodesarecombined attheend(stage03).Youcanseewhichstagestookthemosttime,andwhether
anyestimatesweresubstantiallydifferentthantheactualdatadistribution. (Whenexaminingthetimevalues,besure
toconsiderthesuffixessuchasusformicrosecondsandmsformilliseconds,ratherthanjustlookingforthelargest
numbers.)
[localhost:21000] > select avg(ss_sales_price) from store_sales where ss_coupon_amt = 
0;
+---------------------+
| avg(ss_sales_price) |
+---------------------+
| 37.80770926328327   |
+---------------------+
[localhost:21000] > summary;
+--------------+--------+----------+----------+-------+------------+----------+---------------+-----------------+
| Operator     | #Hosts | Avg Time | Max Time | #Rows | Est. #Rows | Peak Mem | Est. 
Peak Mem | Detail          |
+--------------+--------+----------+----------+-------+------------+----------+---------------+-----------------+
| 03:AGGREGATE | 1      | 1.03ms   | 1.03ms   | 1     | 1          | 48.00 KB | -1 B  
        | MERGE FINALIZE  |
| 02:EXCHANGE  | 1      | 0ns      | 0ns      | 1     | 1          | 0 B      | -1 B  
        | UNPARTITIONED   |
| 01:AGGREGATE | 1      | 30.79ms  | 30.79ms  | 1     | 1          | 80.00 KB | 10.00 
MB      |                 |
| 00:SCAN HDFS | 1      | 5.45s    | 5.45s    | 2.21M | -1         | 64.05 MB | 432.00
 MB     | tpc.store_sales |
+--------------+--------+----------+----------+-------+------------+----------+---------------+-----------------+
Noticehowthelongestinitialphaseofthequeryismeasuredinseconds(s),whilelaterphasesworkingonsmaller
intermediateresultsaremeasuredinmilliseconds(ms)orevennanoseconds(ns).
Hereisanexamplefromamorecomplicatedquery,asitwouldappearinthePROFILE output:
Operator              #Hosts   Avg Time   Max Time    #Rows  Est. #Rows  Peak Mem  Est.
 Peak Mem  Detail
------------------------------------------------------------------------------------------------------------------------
09:MERGING-EXCHANGE        1   79.738us   79.738us        5           5         0     
   -1.00 B  UNPARTITIONED
05:TOP-N                   3   84.693us   88.810us        5           5  12.00 KB     
  120.00 B
ApacheImpalaGuide|603TuningImpalaforPerformance
04:AGGREGATE               3    5.263ms    6.432ms        5           5  44.00 KB     
  10.00 MB  MERGE FINALIZE
08:AGGREGATE               3   16.659ms   27.444ms   52.52K     600.12K   3.20 MB     
  15.11 MB  MERGE
07:EXCHANGE                3    2.644ms      5.1ms   52.52K     600.12K         0     
         0  HASH(o_orderpriority)
03:AGGREGATE               3  342.913ms  966.291ms   52.52K     600.12K  10.80 MB     
  15.11 MB
02:HASH JOIN               3    2s165ms    2s171ms  144.87K     600.12K  13.63 MB     
 941.01 KB  INNER JOIN, BROADCAST
|--06:EXCHANGE             3    8.296ms    8.692ms   57.22K      15.00K         0     
         0  BROADCAST
|  01:SCAN HDFS            2    1s412ms    1s978ms   57.22K      15.00K  24.21 MB     
 176.00 MB  tpch.orders o
00:SCAN HDFS               3    8s032ms    8s558ms    3.79M     600.12K  32.29 MB     
 264.00 MB  tpch.lineitem l
UsingtheQueryProfileforPerformance Tuning
ThePROFILE command, availableintheimpala-shell interpreter,producesadetailedlow-levelreportshowing
howthemostrecentquerywasexecuted.UnliketheEXPLAIN plandescribed inUsingtheEXPLAINPlanforPerformance
Tuningonpage602,thisinformationisonlyavailableafterthequeryhasfinished.Itshowsphysicaldetailssuchasthe
numberofbytesread,maximummemoryusage,andsoonforeachnode.Youcanusethisinformationtodetermine
ifthequeryisI/O-bound orCPU-bound, whethersomenetworkconditionisimposing abottleneck,whetheraslowdown
isaffectingsomenodesbutnotothers,andtocheckthatrecommended configurationsettingssuchasshort-circuit
localreadsareineffect.
Bydefault,timevaluesintheprofileoutputreflectthewall-clocktimetakenbyanoperation.Forvaluesdenoting
systemtimeorusertime,themeasurementunitisreflectedinthemetricname,suchasScannerThreadsSysTime
orScannerThreadsUserTime .Forexample,amulti-threadedI/Ooperationmightshowasmallfigureforwall-clock
time,whilethecorresponding systemtimeislarger,representingthesumoftheCPUtimetakenbyeachthread.Or
awall-clocktimefiguremightbelargerbecauseitcountstimespentwaiting,whilethecorresponding systemanduser
timefiguresonlymeasurethetimewhiletheoperationisactivelyusingCPUcycles.
TheEXPLAIN planisalsoprintedatthebeginning ofthequeryprofilereport,forconvenienceinexaminingboththe
logicalandphysicalaspectsofthequeryside-by-side.TheEXPLAIN_LEVEL queryoptionalsocontrolstheverbosityof
theEXPLAIN outputprintedbythePROFILE command.
InCDH6.2/Impala3.2,anewPer Node Profiles sectionwasaddedtotheprofileoutput.Thenewsectionincludes
thefollowingmetricsthatcanbecontrolledbytheRESOURCE_TRACE_RATIO queryoption.
â¢CpuIoWaitPercentage
â¢CpuSysPercentage
â¢CpuUserPercentage
â¢HostDiskReadThroughput :Alldatareadbythehostaspartoftheexecutionofthisquery(spilling), bythe
HDFSdatanode,andbyotherprocessesrunningonthesamesystem.
â¢HostDiskWriteThroughput :Alldatawrittenbythehostaspartoftheexecutionofthisquery(spilling), bythe
HDFSdatanode,andbyotherprocessesrunningonthesamesystem.
â¢HostNetworkRx :Alldatareceivedbythehostaspartoftheexecutionofthisquery,otherqueries,andother
processesrunningonthesamesystem.
â¢HostNetworkTx :Alldatatransmittedbythehostaspartoftheexecutionofthisquery,otherqueries,andother
processesrunningonthesamesystem.
SeeQueryDetailsforthestepstodownloadthequeryprofileinthetextformatinClouderaManager.
604|ApacheImpalaGuideTuningImpalaforPerformance
ScalabilityConsiderationsforImpala
ThissectionexplainshowthesizeofyourclusterandthevolumeofdatainfluencesSQLperformance andschema
designforImpalatables.Typically,addingmoreclustercapacityreducesproblemsduetomemorylimitsordisk
throughput. Ontheotherhand,largerclustersaremorelikelytohaveotherkindsofscalabilityissues,suchasasingle
slownodethatcausesperformance problemsforqueries.
Agoodsourceoftipsrelatedtoscalabilityandperformance tuningistheImpalaCookbook presentation.Theseslides
areupdatedperiodicallyasnewfeaturescomeoutandnewbenchmark sareperformed.
ImpactofManyTablesorPartitionsonImpalaCatalogPerformance andMemoryUsage
BecauseHadoopI/Oisoptimizedforreadingandwritinglargefiles,Impalaisoptimizedfortablescontainingrelatively
few,largedatafiles.Schemascontainingthousands oftables,ortablescontainingthousands ofpartitions, canencounter
performance issuesduringstartuporduringDDLoperationssuchasALTER TABLE statements.
Important:
Becauseofachangeinthedefaultheapsizeforthecatalogd daemoninCDH5.7/Impala2.5and
higher,thefollowingproceduretoincreasethecatalogd memorylimitmightberequiredfollowing
anupgradetoCDH5.7/Impala2.5evenifnotneededpreviously.
Forschemaswithlargenumbersoftables,partitions, anddatafiles,thecatalogd daemonmightencounteran
out-of-memor yerror.Topreventtheerror,increasethememorylimitforthecatalogd daemon:
1.Checkcurrentmemoryusageforthecatalogd daemonbyrunningthefollowingcommands onthehostwhere
thatdaemonrunsonyourcluster:
  jcmd catalogd_pid  VM.flags
  jmap -heap catalogd_pid
2.Decideonalargeenoughvalueforthecatalogd heap.
â¢OnsystemsmanagedbyClouderaManager,includethisvalueintheconfigurationfieldJavaHeapSizeof
CatalogServerinBytes(ClouderaManager5.7andhigher),orImpalaCatalogServerEnvironmentAdvanced
ConfigurationSnippet(SafetyValve)(priortoClouderaManager5.7).ThenrestarttheImpalaservice.
â¢OnsystemsnotmanagedbyClouderaManager,puttheJAVA_TOOL_OPTIONS environmentvariablesetting
intothestartupscriptforthecatalogd daemon, thenrestartthecatalogd daemon.
Forexample,thefollowingenvironmentvariablesettingspecifiesthemaximumheapsizeof8GB.
  JAVA_TOOL_OPTIONS="-Xmx8g"
3.Usethesamejcmdandjmapcommands asearliertoverifythatthenewsettingsareineffect.
ScalabilityConsiderationforLargeClusters
Whenprocessingqueries,Impaladaemons (Impalads )frequentlyexchangelargevolumesofdatawithotherImpala
daemons inthecluster,forexampleduringapartitioned hashjoin.Thiscommunic ationbetweentheImpaladaemons
ApacheImpalaGuide|605ScalabilityConsiderationsforImpala
happensthroughremoteprocedurecalls(RPCs).InCDH5.14/CDH6.0andlower,intercommunic ationwasdone
exclusivelyusingtheApacheThriftlibrary.WithThriftRPC,thenumberofnetworkconnections perhostsharply
increasesasthenumberofnodesgoesup:
numberofconnections perhost=(numberofnodes)x(average numberofqueryfragmentsperhost)
Forexample,ina100-node clusterwith32concurrentqueries,eachofwhichhad50fragments,therewouldbe100
x32x50=160,000connections andthreadsperhost.Acrosstheentirecluster,therewouldbe16millionconnections.
AsmorenodesareaddedtoaCDHclusterduetoincreaseindataandworkloads, theexcessivenumberofRPCthreads
andnetworkconnections canleadtoinstabilityandpoorperformance inImpalainCDH5.14/CDH6.0andlower.
InCDH5.15.0/CDH6.1andhigher,ImpalacanuseanalternateRPCoptionviaKRPCthatprovidesimprovementsin
throughputandreliabilitywhilereducingtheresourceusagesignificantly.UsingKRPC,Impalacanreliablyhandle
concurrentcomplexqueriesonlargedatasets.SeethisblogfordetailinformationonKRPCforcommunic ations
amongImpaladaemons.
Ifyouareexperiencing thescalabilityissuewithconnections butunabletoupgradetoCDH5.15/CDH6.1,theseare
someofthealternateoptionsyoucanconsidertoalleviatetheissues:
â¢Usededicatedcoordinators.
â¢Isolatesomeworkloads.
â¢Increasethestatusreportingintervalbysettingthestartupflag--status_report_interval toalargervalue.
Bydefault,it'ssetto5seconds.
â¢UseWorkloadExperience Manageranalysistoidentifyanyotherimprovements.
ScalabilityConsiderationsfortheImpalaStatestore
BeforeCDH5.5/Impala2.3,thestatestoresentonlyonekindofmessagetoitssubscribers.Thismessagecontained
allupdatesforanytopicsthatasubscriberhadsubscribedto.Italsoservedtoletsubscribersknowthatthestatestore
hadnotfailed,andconverselythestatestoreusedthesuccessofsendingaheartbeattoasubscribertodecidewhether
ornotthesubscriberhadfailed.
Combining topicupdatesandfailuredetectioninasinglemessageledtobottlenecksinclusterswithlargenumbers
oftables,partitions, andHDFSdatablocks.Whenthestatestorewasoverloaded withmetadataupdatestotransmit,
heartbeatmessagesweresentlessfrequently,sometimescausingsubscriberstotimeouttheirconnection withthe
statestore.Increasingthesubscribertimeoutanddecreasingthefrequencyofstatestoreheartbeatsworkedaround
theproblem,butreducedresponsivenesswhenthestatestorefailedorrestarted.
AsofCDH5.5/Impala2.3,thestatestorenowsendstopicupdatesandheartbeatsinseparatemessages.Thisallows
thestatestoretosendandreceiveasteadystreamoflightweightheartbeats,andremovestherequirementtosend
topicupdatesaccordingtoafixedschedule, reducingstatestorenetworkoverhead.
Thestatestorenowhasthefollowingrelevantconfigurationflagsforthestatestored daemon:
-statestore_num_update_threads
Thenumberofthreadsinsidethestatestorededicatedtosendingtopicupdates.Youshouldnottypicallyneedto
changethisvalue.
Default:10
-statestore_update_frequency_ms
Thefrequency,inmilliseconds,withwhichthestatestoretriestosendtopicupdatestoeachsubscriber.Thisisa
best-effortvalue;ifthestatestoreisunabletomeetthisfrequency,itsendstopicupdatesasfastasitcan.You
shouldnottypicallyneedtochangethisvalue.
Default:2000
-statestore_num_heartbeat_threads
Thenumberofthreadsinsidethestatestorededicatedtosendingheartbeats.Youshouldnottypicallyneedto
changethisvalue.
606|ApacheImpalaGuideScalabilityConsiderationsforImpala
Default:10
-statestore_heartbeat_frequency_ms
Thefrequency,inmilliseconds,withwhichthestatestoretriestosendheartbeatstoeachsubscriber.Thisvalue
shouldbegoodforlargecatalogsandclustersuptoapproximately150nodes.Beyondthat,youmightneedto
increasethisvaluetomaketheintervallongerbetweenheartbeatmessages.
Default:1000(oneheartbeatmessageeverysecond)
AsofCDH5.5/Impala2.3,notalloftheseflagsarepresentintheClouderaManageruserinterface.Somemustbe
setusingtheAdvancedConfigurationSnippetfieldsforthestatestorecomponen t.
Ifittakesaverylongtimeforaclustertostartup,andimpala-shell consistentlydisplaysThis Impala daemon
is not ready to accept user requests ,thestatestoremightbetakingtoolongtosendtheentirecatalog
topictothecluster.Inthiscase,consideradding--load_catalog_in_background=false toyourcatalogservice
configuration.Thissettingstopsthestatestorefromloadingtheentirecatalogintomemoryatclusterstartup.Instead,
metadataforeachtableisloadedwhenthetableisaccessed forthefirsttime.
EffectofBufferPoolonMemoryUsage(CDH5.13andhigher)
Thebufferpoolfeature,availableinCDH5.13andhigher,changesthewayImpalaallocatesmemoryduringaquery.
Mostofthememoryneededisreservedatthebeginning ofthequery,avoidingcaseswhereaquerymightrunfora
longtimebeforefailingwithanout-of-memor yerror.Theactualmemoryestimatesandmemorybuffersaretypically
smallerthanbefore,sothatmorequeriescanrunconcurrentlyorprocesslargervolumesofdatathanpreviously.
Thebufferpoolfeatureincludessomequeryoptionsthatyoucanfine-tune: BUFFER_POOL_LIMIT QueryOptionon
page324,DEFAULT_SPILLABLE_BUFFER_SIZE QueryOptiononpage327,MAX_ROW_SIZEQueryOptiononpage340,
andMIN_SPILLABLE_BUFFER_SIZE QueryOptiononpage345.
MostoftheeffectsofthebufferpoolaretransparenttoyouasanImpalauser.Memoryuseduringspillingisnow
steadierandmorepredictable,insteadofincreasingrapidlyasmoredataisspilledtodisk.Themainchangefroma
userperspectiveistheneedtoincreasetheMAX_ROW_SIZE queryoptionsettingwhenqueryingtableswithcolumns
containinglongstrings,manycolumns,orothercombinationsoffactorsthatproduceverylargerows.IfImpala
encountersrowsthataretoolargetoprocesswiththedefaultqueryoptionsettings,thequeryfailswithanerror
messagesuggestingtoincreasetheMAX_ROW_SIZE setting.
SQLOperationsthatSpilltoDisk
Certainmemory-intensiveoperationswritetemporarydatatodisk(knownasspillingtodisk)whenImpalaiscloseto
exceedingitsmemorylimitonaparticular host.
Note:
InCDH5.13andhigher,alsoseeEffectofBufferPoolonMemoryUsage(CDH5.13andhigher)on
page607forchangestoImpalamemoryallocationthatmightchangethedetailsofwhichqueriesspill
todisk,andhowmuchmemoryanddiskspaceisinvolvedinthespillingoperation.
Theresultisaquerythatcompletessuccessfully,ratherthanfailingwithanout-of-memor yerror.Thetradeoffis
decreasedperformance duetotheextradiskI/Otowritethetemporarydataandreaditbackin.Theslowdowncould
bepotentiallybesignificant.Thus,whilethisfeatureimprovesreliability,youshouldoptimizeyourqueries,system
parameters,andhardwareconfigurationtomakethisspillingarareoccurrence.
Whatkindsofqueriesmightspilltodisk:
SeveralSQLclausesandconstructsrequirememoryallocationsthatcouldactivatthespillingmechanism:
â¢whenaqueryusesaGROUP BY clauseforcolumnswithmillionsorbillionsofdistinctvalues,Impalakeepsasimilar
numberoftemporaryresultsinmemory,toaccumula tetheaggregateresultsforeachvalueinthegroup.
ApacheImpalaGuide|607ScalabilityConsiderationsforImpala
â¢Whenlargetablesarejoinedtogether,Impalakeepsthevaluesofthejoincolumnsfromonetableinmemory,
tocomparethemtoincomingvaluesfromtheothertable.
â¢WhenalargeresultsetissortedbytheORDER BY clause,eachnodesortsitsportionoftheresultsetinmemory.
â¢TheDISTINCT andUNIONoperatorsbuildin-memor ydatastructurestorepresentallvaluesfoundsofar,to
eliminateduplicatesasthequeryprogresses.
Whenthespill-to-diskfeatureisactivatedforajoinnodewithinaquery,Impaladoesnotproduceanyruntimefilters
forthatjoinoperationonthathost.Otherjoinnodeswithinthequeryarenotaffected.
InCDH5.13/Impala2.10andhigher,thewaySQLoperatorssuchasGROUP BY ,DISTINCT ,andjoins,transition
betweenusingadditional memoryoractivatingthespill-to-diskfeatureischanged.Thememoryrequiredtospillto
diskisreservedupfront,andyoucanexamineitintheEXPLAIN planwhentheEXPLAIN_LEVEL queryoptionisset
to2orhigher.
TheinfrastructureofthespillingfeatureaffectsthewaytheaffectedSQLoperators,suchasGROUP BY ,DISTINCT ,
andjoins,usememory.Oneachhostthatparticipatesinthequery,eachsuchoperatorinaqueryrequiresmemory
tostorerowsofdataandotherdatastructures.Impalareservesacertainamountofmemoryupfrontforeachoperator
thatsupports spill-to-diskthatissufficienttoexecutetheoperator.Ifanoperatoraccumula tesmoredatathancanfit
inthereservedmemory,itcaneitherreservemorememorytocontinueprocessingdatainmemoryorstartspilling
datatotemporaryscratchfilesondisk.Thus,operatorswithspill-to-disksupportcanadapttodifferentmemory
constraintsbyusinghowevermuchmemoryisavailabletospeedupexecution,yettoleratelowmemoryconditions
byspillingdatatodisk.
Theamountdatadependsontheportionofthedatabeinghandledbythathost,andthustheoperatormayendup
consuming differentamountsofmemoryondifferenthosts.
HowImpalahandlesscratchdiskspaceforspilling:
Bydefault,intermediatefilesusedduringlargesort,join,aggregation,oranalyticfunctionoperationsarestoredin
thedirectory/tmp/impala-scratch .Thesefilesareremovedwhentheoperationfinishes.(Multiple concurrent
queriescanperformoperationsthatusetheâspilltodiskâtechnique, withoutanynameconflictsforthesetemporary
files.)Youcanspecifyadifferentlocationbystartingtheimpalad daemonwiththe
--scratch_dirs=" path_to_directory "configurationoptionortheequivalentconfigurationoptionintheCloudera
Manageruserinterface.Youcanspecifyasingledirectory,oracomma-separ atedlistofdirectories.Thescratch
directoriesmustbeonthelocalfilesystem,notinHDFS.Youmightspecifydifferentdirectorypathsfordifferenthosts,
depending onthecapacityandspeedoftheavailablestoragedevices.InCDH5.5/Impala2.3orhigher,Impala
successfullystarts(withawarningwrittentothelog)ifitcannotcreateorreadandwritefilesinoneofthescratch
directories.Ifthereislessthan1GBfreeonthefilesystemwherethatdirectoryresides,Impalastillruns,butwritesa
warningmessagetoitslog.IfImpalaencountersanerrorreadingorwritingfilesinascratchdirectoryduringaquery,
Impalalogstheerrorandthequeryfails.
MemoryusageforSQLoperators:
InCDH5.13/Impala2.10andhigher,thewaySQLoperatorssuchasGROUP BY ,DISTINCT ,andjoins,transition
betweenusingadditional memoryoractivatingthespill-to-diskfeatureischanged.Thememoryrequiredtospillto
diskisreservedupfront,andyoucanexamineitintheEXPLAIN planwhentheEXPLAIN_LEVEL queryoptionisset
to2orhigher.
TheinfrastructureofthespillingfeatureaffectsthewaytheaffectedSQLoperators,suchasGROUP BY ,DISTINCT ,
andjoins,usememory.Oneachhostthatparticipatesinthequery,eachsuchoperatorinaqueryrequiresmemory
tostorerowsofdataandotherdatastructures.Impalareservesacertainamountofmemoryupfrontforeachoperator
thatsupports spill-to-diskthatissufficienttoexecutetheoperator.Ifanoperatoraccumula tesmoredatathancanfit
inthereservedmemory,itcaneitherreservemorememorytocontinueprocessingdatainmemoryorstartspilling
datatotemporaryscratchfilesondisk.Thus,operatorswithspill-to-disksupportcanadapttodifferentmemory
constraintsbyusinghowevermuchmemoryisavailabletospeedupexecution,yettoleratelowmemoryconditions
byspillingdatatodisk.
Theamountofdatadependsontheportionofthedatabeinghandledbythathost,andthustheoperatormayend
upconsuming differentamountsofmemoryondifferenthosts.
608|ApacheImpalaGuideScalabilityConsiderationsforImpala
Addedin:ThisfeaturewasaddedtotheORDER BY clauseinCDH5.1/Impala1.4.Thisfeaturewasextendedtocover
joinqueries,aggregationfunctions, andanalyticfunctions inCDH5.2/Impala2.0.Thesizeofthememoryworkarea
requiredbyeachoperatorthatspillswasreducedfrom512megabytesto256megabytesinCDH5.4/Impala2.2.The
spillingmechanism wasreworkedtotakeadvantageoftheImpalabufferpoolfeatureandbemorepredictableand
stableinCDH5.13/Impala2.10.
Avoidingqueriesthatspilltodisk:
BecausetheextraI/Ocanimposesignificantperformance overheadonthesetypesofqueries,trytoavoidthissituation
byusingthefollowingsteps:
1.Detecthowoftenqueriesspilltodisk,andhowmuchtemporarydataiswritten.Refertothefollowingsources:
â¢TheoutputofthePROFILE command intheimpala-shell interpreter.Thisdatashowsthememoryusage
foreachhostandintotalacrossthecluster.TheWriteIoBytes counterreportshowmuchdatawaswritten
todiskforeachoperatorduringthequery.(InCDH5.12/Impala2.9,thecounterwasnamed
ScratchBytesWritten ;inCDH5.10/Impala2.8andearlier,itwasnamedBytesWritten .)
â¢TheImpalaQueriesdialoginClouderaManager.Youcanseethepeakmemoryusageforaquery,combined
acrossallnodesinthecluster.
â¢TheQueriestabintheImpaladebugwebuserinterface.Selectthequerytoexamineandclickthe
corresponding Profilelink.Thisdatabreaksdownthememoryusageforasinglehostwithinthecluster,the
hostwhosewebinterfaceyouareconnectedto.
2.Useoneormoretechniques toreducethepossibility ofthequeriesspillingtodisk:
â¢IncreasetheImpalamemorylimitifpractical,forexample,ifyoucanincreasetheavailablememorybymore
thantheamountoftemporarydatawrittentodiskonaparticular node.Remember thatinImpala2.0and
later,youcanissueSET MEM_LIMIT asaSQLstatement,whichletsyoufine-tune thememoryusagefor
queriesfromJDBCandODBCapplications.
â¢Increasethenumberofnodesinthecluster,toincreasetheaggregatememoryavailabletoImpalaandreduce
theamountofmemoryrequiredoneachnode.
â¢AddmorememorytothehostsrunningImpaladaemons.
â¢OnaclusterwithresourcessharedbetweenImpalaandotherHadoopcomponen ts,useresourcemanagement
featurestoallocatemorememoryforImpala.SeeResourceManagementonpage549fordetails.
â¢Ifthememorypressureisduetorunningmanyconcurrentqueriesratherthanafewmemory-intensiveones,
considerusingtheImpalaadmission controlfeaturetolowerthelimitonthenumberofconcurrentqueries.
Byspacingoutthemostresource-intensivequeries,youcanavoidspikesinmemoryusageandimprove
overallresponsetimes.SeeAdmission ControlandQueryQueuingonpage549fordetails.
â¢Tunethequerieswiththehighestmemoryrequirements,usingoneormoreofthefollowingtechniques:
âRuntheCOMPUTE STATS statementforalltablesinvolvedinlarge-scalejoinsandaggregationqueries.
âMinimizeyouruseofSTRINGcolumnsinjoincolumns.Prefernumericvaluesinstead.
âExaminetheEXPLAIN plantounderstandtheexecutionstrategybeingusedforthemost
resource-intensivequeries.SeeUsingtheEXPLAINPlanforPerformance Tuningonpage602fordetails.
âIfImpalastillchoosesasuboptimalexecutionstrategyevenwithstatisticsavailable,orifitisimpractical
tokeepthestatisticsuptodateforhugeorrapidlychanging tables,addhintstothemost
resource-intensivequeriestoselecttherightexecutionstrategy.SeeOptimizerHintsinImpalaonpage
387fordetails.
â¢Ifyourqueriesexperience substantialperformance overheadduetospilling,enablethe
DISABLE_UNSAFE_SPILLS queryoption.Thisoptionpreventsquerieswhosememoryusageislikelytobe
exorbitantfromspillingtodisk.SeeDISABLE_UNS AFE_SPILLS QueryOption(CDH5.2orhigheronly)onpage
329fordetails.Asyoutuneproblematicqueriesusingtheprecedingsteps,fewerandfewerwillbecancelled
bythisoptionsetting.
Testingperformance implicationsofspillingtodisk:
Toartificially provokespilling,totestthisfeatureandunderstandtheperformance implications,useatestenvironment
withamemorylimitofatleast2GB.IssuetheSETcommand withnoargumentstocheckthecurrentsettingforthe
ApacheImpalaGuide|609ScalabilityConsiderationsforImpala
MEM_LIMIT queryoption.SetthequeryoptionDISABLE_UNSAFE_SPILLS=true .Thisoptionlimitsthespill-to-disk
featuretopreventrunawaydiskusagefromqueriesthatareknowninadvancetobesuboptimal.Withinimpala-shell ,
runaquerythatyouexpecttobememory-intensive,basedonthecriteriaexplainedearlier.Aself-joinofalargetable
isagoodcandidate:
select count(*) from big_table a join big_table b using (column_with_many_values);
IssuethePROFILE command togetadetailedbreakdownofthememoryusageoneachnodeduringthequery.
SettheMEM_LIMIT queryoptiontoavaluethatissmallerthanthepeakmemoryusagereportedintheprofileoutput.
Donotspecifyamemorylimitlowerthanreportedintheprofileoutput.Nowtrythememory-intensivequeryagain.
Checkifthequeryfailswithamessagelikethefollowing:
WARNINGS: Spilling has been disabled for plans that do not have stats and are not hinted
to prevent potentially bad plans from using too many cluster resources. Compute stats 
on
these tables, hint the plan or disable this behavior via query options to enable spilling.
Ifso,thequerycouldhaveconsumed substantialtemporarydiskspace,slowingdownsomuchthatitwouldnot
completeinanyreasonable time.Ratherthanrelyonthespill-to-diskfeatureinthiscase,issuetheCOMPUTE STATS
statementforthetableortablesinyoursamplequery.Thenrunthequeryagain,checkthepeakmemoryusageagain
inthePROFILE output,andadjustthememorylimitagainifnecessarytobelowerthanthepeakmemoryusage.
Atthispoint,youhaveaquerythatismemory-intensive,butImpalacanoptimizeitefficientlysothatthememory
usageisnotexorbitant.YouhavesetanartificialconstraintthroughtheMEM_LIMIT optionsothatthequerywould
normally failwithanout-of-memor yerror.Buttheautomaticspill-to-diskfeaturemeansthatthequeryshouldactually
succeed, attheexpenseofsomeextradiskI/Otoreadandwritetemporaryworkdata.
Trythequeryagain,andconfirmthatitsucceeds. ExaminethePROFILE outputagain.Thistime,lookforlinesofthis
form:
- SpilledPartitions: N
IfyouseeanysuchlineswithNgreaterthan0,thatindicatesthequerywouldhavefailedinImpalareleasespriorto
2.0,butnowitsucceeded becauseofthespill-to-diskfeature.ExaminethetotaltimetakenbytheAGGREGATION_NODE
orotherqueryfragmentscontainingnon-zeroSpilledPartitions values.Comparethetimestosimilarfragments
thatdidnotspill,forexampleinthePROFILE outputwhenthesamequeryisrunwithahighermemorylimit.This
givesyouanideaoftheperformance penaltyofthespilloperationforaparticular querywithaparticular memory
limit.Ifyoumakethememorylimitjustalittlelowerthanthepeakmemoryusage,thequeryonlyneedstowritea
smallamountoftemporarydatatodisk.Theloweryousetthememorylimit,themoretemporarydataiswrittenand
theslowerthequerybecomes.
Nowrepeatthisprocedureforactualqueriesusedinyourenvironment.UsetheDISABLE_UNSAFE_SPILLS setting
toidentifycaseswherequeriesusedmorememorythannecessaryduetolackofstatisticsontherelevanttablesand
columns,andissueCOMPUTE STATS wherenecessary.
WhentouseDISABLE_UNS AFE_SPILLS:
Youmightwonder,whynotleaveDISABLE_UNSAFE_SPILLS turnedonallthetime.Whetherandhowfrequentlyto
usethisoptiondependsonyoursystemenvironmentandworkload.
DISABLE_UNSAFE_SPILLS issuitableforanenvironmentwithadhocquerieswhoseperformance characteristics
andmemoryusagearenotknowninadvance.Itpreventsâworst-casescenarioâ queriesthatuselargeamountsof
memoryunnecessarily .Thus,youmightturnthisoptiononwithinasessionwhiledevelopingnewSQLcode,even
thoughitisturnedoffforexistingapplications.
Organizationswheretableandcolumnstatisticsaregenerallyup-to-datemightleavethisoptionturnedonallthe
time,againtoavoidworst-casescenarios foruntestedqueriesorifaproblemintheETLpipelineresultsinatablewith
nostatistics.TurningonDISABLE_UNSAFE_SPILLS letsyouâfailfastâinthiscaseandimmediatelygatherstatistics
ortunetheproblematicqueries.
610|ApacheImpalaGuideScalabilityConsiderationsforImpala
Someorganizationsmightleavethisoptionturnedoff.Forexample,youmighthavetableslargeenoughthatthe
COMPUTE STATS takessubstantialtimetorun,makingitimpracticaltore-runafterloadingnewdata.Ifyouhave
examinedtheEXPLAIN plansofyourqueriesandknowthattheyareoperatingefficiently,youmightleave
DISABLE_UNSAFE_SPILLS turnedoff.Inthatcase,youknowthatanyqueriesthatspillwillnotgooverboardwith
theirmemoryconsumption.
LimitsonQuerySizeandComplexity
Therearehardcodedlimitsonthemaximumsizeandcomplexityofqueries.Currently,themaximumnumberof
expressionsinaqueryis2000.Youmightexceedthelimitswithlargeordeeplynestedqueriesproducedbybusiness
intelligencetoolsorotherquerygenerators.
Ifyouhavetheabilitytocustomizesuchqueriesorthequerygenerationlogicthatproducesthem,replacesequences
ofrepetitiveexpressionswithsingleoperatorssuchasINorBETWEEN thatcanrepresentmultiplevaluesorranges.
Forexample,insteadofalargenumberofORclauses:
WHERE val = 1 OR val = 2 OR val = 6 OR val = 100 ...
useasingleINclause:
WHERE val IN (1,2,6,100,...)
ScalabilityConsiderationsforImpalaI/O
ImpalaparallelizesitsI/Ooperationsaggressively,thereforethemoredisksyoucanattachtoeachhost,thebetter.
Impalaretrievesdatafromdisksoquicklyusingbulkreadoperationsonlargeblocks,thatmostqueriesareCPU-bound
ratherthanI/O-bound.
BecausethekindofsequentialscanningtypicallydonebyImpalaqueriesdoesnotbenefitmuchfromtherandom-access
capabilities ofSSDs,spinningdiskstypicallyprovidethemostcost-effectivekindofstorageforImpaladata,withlittle
ornoperformance penaltyascomparedtoSSDs.
ResourcemanagementfeaturessuchasYARN,Llama,andadmission controltypicallyconstraintheamountofmemory,
CPU,oroverallnumberofqueriesinahigh-concurrencyenvironment.Currently,thereisnothrottlingmechanism for
ImpalaI/O.
ScalabilityConsiderationsforTableLayout
Duetotheoverheadofretrievingandupdatingtablemetadatainthemetastoredatabase,trytolimitthenumberof
columnsinatabletoamaximumofapproximately2000.Although Impalacanhandlewidertablesthanthis,the
metastoreoverheadcanbecomesignificant,leadingtoqueryperformance thatisslowerthanexpectedbasedonthe
actualdatavolume.
TominimizeoverheadrelatedtothemetastoredatabaseandImpalaqueryplanning,trytolimitthenumberofpartitions
foranypartitioned tabletoafewtensofthousands.
Ifthevolumeofdatawithinatablemakesitimpracticaltorunexploratoryqueries,considerusingtheTABLESAMPLE
clausetolimitqueryprocessingtoonlyapercentageofdatawithinthetable.Thistechnique reducestheoverhead
forquerystartup,I/Otoreadthedata,andtheamountofnetwork,CPU,andmemoryneededtoprocessintermediate
resultsduringthequery.SeeTABLESAMPLEClauseonpage315fordetails.
Kerberos-RelatedNetworkOverheadforLargeClusters
WhenImpalastartsup,oraftereachkinitrefresh,ImpalasendsanumberofsimultaneousrequeststotheKDC.For
aclusterwith100hosts,theKDCmightbeabletoprocessalltherequestswithinroughly5seconds.Foraclusterwith
ApacheImpalaGuide|611ScalabilityConsiderationsforImpala
1000hosts,thetimetoprocesstherequestswouldberoughly500seconds.ImpalaalsomakesanumberofDNS
requestsatthesametimeastheseKerberos-relatedrequests.
Whiletheseauthenticationrequestsarebeingprocessed,anysubmittedImpalaquerieswillfail.Duringthisperiod,
theKDCandDNSmaybeslowtorespondtorequestsfromcomponen tsotherthanImpala,soothersecureservices
mightbeaffectedtemporarily.
InCDH5.15/Impala2.12orearlier,toreducethefrequencyofthekinitrenewalthatinitiatesanewsetof
authenticationrequests,increasethekerberos_reinit_interval configurationsettingfortheimpalad daemons.
Currently,thedefaultis60minutes.Consider usingahighervaluesuchas360(6hours).
Thekerberos_reinit_interval configurationsettingisremovedinCDH6.0/Impala3.0,andtheabovestepis
nolongerneeded.
AvoidingCPUHotspots forHDFSCachedData
YoucanusetheHDFScachingfeature,described inUsingHDFSCachingwithImpala(CDH5.3orhigheronly)onpage
593,withImpalatoreduceI/Oandmemory-to-memor ycopyingforfrequentlyaccessed tablesorpartitions.
Intheearlydaysofthisfeature,youmighthavefoundthatenablingHDFScachingresultedinlittleornoperformance
improvement,becauseitcouldresultinâhotspotsâ :insteadoftheI/Otoreadthetabledatabeingparallelizedacross
thecluster,theI/OwasreducedbuttheCPUloadtoprocessthedatablocksmightbeconcentratedonasinglehost.
Toavoidhotspots, includetheWITH REPLICATION clausewiththeCREATE TABLE orALTER TABLE statementsfor
tablesthatuseHDFScaching.Thisclauseallowsmorethanonehosttocachetherelevantdatablocks,sotheCPUload
canbeshared,reducingtheloadonanyonehost.SeeCREATETABLEStatementonpage234andALTERTABLEStatement
onpage205fordetails.
Hotspots withhighCPUloadforHDFScacheddatacouldstillariseinsomecases,duetothewaythatImpalaschedules
theworkofprocessingdatablocksondifferenthosts.InCDH5.7/Impala2.5andhigher,scheduling improvements
meanthattheworkforHDFScacheddataisdividedbetteramongallthehoststhathavecachedreplicasforaparticular
datablock.Whenmorethanonehosthasacachedreplicaforadatablock,Impalaassignstheworkofprocessingthat
blocktowhicheverhosthasdonetheleastwork(intermsofnumberofbytesread)forthecurrentquery.Ifhotspots
persistevenwiththisload-based scheduling algorithm,youcanenablethequeryoption
SCHEDULE_RANDOM_REPLICA=TRUE tofurtherdistributetheCPUload.ThissettingcausesImpalatorandomly pick
ahosttoprocessacacheddatablockifthescheduling algorithmencountersatiewhendecidingwhichhosthasdone
theleastwork.
ScalabilityConsiderationsforFileHandleCaching
Onescalabilityaspectthataffectsheavilyloadedclustersistheloadonthemetadatalayerfromlookingupthedetails
aseachfileisopened.OnHDFS,thatcanleadtoincreasedloadontheNameNode, andonS3,thiscanleadtoan
excessivenumberofS3metadatarequests.Forexample,aquerythatdoesafulltablescanonapartitioned tablemay
needtoreadthousands ofpartitions, eachpartitioncontainingmultipledatafiles.Accessing eachcolumnofaParquet
filealsoinvolvesaseparateâopenâcall,furtherincreasingtheloadontheNameNode. HighNameNode overheadcan
addstartuptime(thatis,increaselatency)toImpalaqueries,andreduceoverallthroughputfornon-Impala workloads
thatalsorequireaccessing HDFSfiles.
Youcanreducethenumberofcallsmadetoyourfilesystem'smetadatalayerbyenablingthefilehandlecaching
feature.Datafilesthatareaccessed bydifferentqueries,orevenmultipletimeswithinthesamequery,canbeaccessed
withoutanewâopenâcallandwithoutfetchingthefiledetailsmultipletimes.
Impalasupports filehandlecachingforthefollowingfilesystems:
â¢HDFSinCDH5.13/Impala2.10andhigher
InImpala3.2andhigher,filehandlecachingalsoappliestoremoteHDFSfilehandles.Thisiscontrolledbythe
cache_remote_file_handles flagforanimpalad .Itisrecommended thatyouusethedefaultvalueoftrue
asthiscachingpreventsyourNameNode fromoverloading whenyourclusterhasmanyremoteHDFSreads.
612|ApacheImpalaGuideScalabilityConsiderationsforImpala
â¢S3inCDH6.3/Impala3.3andhigher
Thecache_s3_file_handles impalad flagcontrolstheS3filehandlecaching.Thefeatureisenabledbydefault
withtheflagsettotrue.
Thefeatureisenabledbydefaultwith20,000filehandlestobecached.Tochangethevalue,settheconfiguration
optionmax_cached_file_handles toanon-zerovalueforeachimpalad daemon. Fromtheinitialdefaultvalue
of20000,adjustupwardifNameNode requestloadisstillsignificant,ordownwardifitismoreimportanttoreduce
theextramemoryusageoneachhost.Eachcacheentryconsumes 6KB,meaningthatcaching20,000filehandles
requiresupto120MBoneachImpalaexecutor.Theexactmemoryusagevariesdepending onhowmanyfilehandles
haveactuallybeencached;memoryisfreedasfilehandlesareevictedfromthecache.
Ifamanualoperationmovesafiletothetrashcanwhilethefilehandleiscached,Impalastillaccessesthecontentsof
thatfile.Thisisachangefrompriorbehavior.Previously,accessing afilethatwasinthetrashcanwouldcauseanerror.
Thisbehavioronlyappliestonon-Impala methodsofremovingfiles,nottheImpalamechanisms suchasTRUNCATE
TABLEorDROP TABLE .
Iffilesareremoved,replaced,orappended byoperationsoutsideofImpala,thewaytobringthefileinformationup
todateistoruntheREFRESH statementonthetable.
Filehandlecacheentriesareevictedasthecachefillsup,orbasedonatimeoutperiodwhentheyhavenotbeen
accessed forsometime.
Toevaluatetheeffectivenessoffilehandlecachingforaparticular workload,issuethePROFILE statementin
impala-shell orexaminequeryprofilesintheImpalaWebUI.LookfortheratioofCachedFileHandlesHitCount
(ideally,shouldbehigh)toCachedFileHandlesMissCount (ideally,shouldbelow).Beforestartinganyevaluation,
runseveralrepresentativequeriestoâwarmupâthecachebecausethefirsttimeeachdatafileisaccessed isalways
recordedasacachemiss.
Toseemetricsaboutfilehandlecachingforeachimpalad instance,examinethefollowingfieldsonthe/metricspage
intheImpalaWebUI:
â¢impala-ser ver.io.mgr.cached-file-handles-miss-c ount
â¢impala-ser ver.io.mgr.num-cached-file-handles
ScalingLimitsandGuidelines
ThistopicliststhescalabilitylimitationinImpala.Foragivenfunctional feature,itisrecommended thatyourespect
theselimitationstoachieveoptimalscalabilityandperformance. Forexample,whileyoumightbeabletocreatea
tablewith2000columns,youwillexperience performance problemswhilequeryingthetable.Thistopicdoesnot
coverfunctional limitationsinImpala.
Unlessnotedotherwise,thelimitsweretestedandcertified.
Thelimitsnotedas"generally safe"arenotcertified, butrecommended asgenerallysafe.Asaferangeisnotahard
limitasunforeseenerrorsortroublesinyourparticular environmentcanaffecttherange.
DeploymentLimits
â¢NumberofImpaladExecutors
â80nodesinCDH5.14andlower
â150nodesinCDH5.15andhigher
â¢NumberofImpaladCoordinators:1coordinatorforatmostevery50executors
SeeDedicatedCoordinatorsfordetails.
â¢ThenumberofImpalaclustersperdeployment
â1ImpalaclusterinImpala3.1andlower
âMultipleclustersinImpala3.2andhigherisgenerally safe.
ApacheImpalaGuide|613ScalabilityConsiderationsforImpala
DataStorageLimits
Therearenohardlimitsforthefollowing,butyouwillexperience gradualperformance degradationasyouincrease
thesenumbers.
â¢Numberofdatabases
â¢Numberoftables-total,perdatabase
â¢Numberofpartitions -total,pertable
â¢Numberoffiles-total,pertable,pertableperpartition
â¢Numberofviews-total,perdatabase
â¢Numberofuser-definedfunctions -total,perdatabase
â¢Parquet
âNumberofcolumnsperrowgroup
âNumberofrowgroupsperblock
âNumberofHDFSblocksperfile
SchemaDesignLimits
â¢Numberofcolumns
â300forKudutables
SeeKuduUsageLimitationsformoreinformation.
â1000forothertypesoftables
SecurityLimits
â¢Numberofroles:10,000forSentry
QueryLimits-CompileTime
â¢Maximumnumberofcolumnsinaquery,includedinaSELECTlist,INSERT,andinanexpression:nolimit
â¢Numberoftablesreferenced:nolimit
â¢Numberofplannodes:nolimit
â¢Numberofplanfragments:nolimit
â¢Depthofexpressiontree:1000hardlimit
â¢Widthofexpressiontree:10,000hardlimit
QueryLimits-RuntimeTime
â¢Codegen
âVerydeeplynestedexpressionswithinqueriescanexceedinternalImpalalimits,leadingtoexcessivememory
usage.Settingthequeryoptiondisable_codegen=true mayreducetheimpact,atacostoflongerquery
runtime.
HowtoConfigureImpalawithDedicatedCoordinators
EachhostthatrunstheImpalaDaemonactsasbothacoordinatorandasanexecutor,bydefault,managing metadata
caching,querycompilation,andqueryexecution.Inthisconfiguration,ImpalaclientscanconnecttoanyImpaladaemon
andsendqueryrequests.
Duringhighlyconcurrentworkloadsforlarge-scalequeries,thedualrolescancausescalabilityissuesbecause:
â¢Theextraworkrequiredforahosttoactasthecoordinatorcouldinterferewithitscapacitytoperformother
workforthelaterphasesofthequery.Forexample,coordinatorscanexperience significantnetworkandCPU
614|ApacheImpalaGuideScalabilityConsiderationsforImpala
overheadwithqueriescontainingalargenumberofqueryfragments.Eachcoordinatorcachesmetadataforall
tablepartitions anddatafiles,whichrequirescoordinatorstobeconfiguredwithalargeJVMheap.Executor-only
Impaladaemons shouldbeconfiguredwiththedefaultJVMheaps,whichleavesmorememoryavailabletoprocess
joins,aggregations,andotheroperationsperformedbyqueryexecutors.
â¢Havingalargenumberofhostsactascoordinatorscancauseunnecessar ynetworkoverhead,oreventimeout
errors,aseachofthosehostscommunic ateswiththeStatestoreddaemonformetadataupdates.
â¢The"softlimits"imposedbytheadmission controlfeaturearemorelikelytobeexceededwhentherearealarge
numberofheavilyloadedhostsactingascoordinators.CheckIMPALA-3649 andIMPALA-6437 toseethestatus
oftheenhancemen tstomitigatethisissue.
Thefollowingfactorscanfurtherexacerbatetheaboveissues:
â¢Highnumberofconcurrentqueryfragmentsduetoqueryconcurrencyand/orquerycomplexity
â¢Largemetadatatopicsizerelatedtothenumberofpartitions/files/block s
â¢Highnumberofcoordinatornodes
â¢Highnumberofcoordinatorsusedinthesameresourcepool
Ifsuchscalabilitybottlenecksoccur,inCDH5.12/Impala2.9andhigher,youcanassignonededicatedroletoeach
Impaladaemonhost,eitherasacoordinatororasanexecutor,toaddresstheissues.
â¢Allexplicitorload-balanced clientconnections mustgotothecoordinatorhosts.Thesehostsperformthenetwork
communic ationtokeepmetadataup-to-dateandroutequeryresultstotheappropriateclients.Thededicated
coordinatorhostsdonotparticipateinI/O-intensiveoperationssuchasscans,andCPU-intensiveoperationssuch
asaggregations.
â¢TheexecutorhostsperformtheintensiveI/O,CPU,andmemoryoperationsthatmakeupthebulkofthework
foreachquery.Theexecutorsdocommunic atewiththeStatestoreddaemonformembershipstatus,butthe
dedicatedexecutorhostsdonotprocessthefinalresultsetsforqueries.
Usingdedicatedcoordinatorsoffersthefollowingbenefits:
â¢ReducesmemoryusagebylimitingthenumberofImpalanodesthatneedtocachemetadata.
â¢Providesbetterconcurrencybyavoidingcoordinatorbottleneck.
â¢Eliminatesqueryover-admission.
â¢Reducesresource,especially network,utilizationontheStatestoreddaemonbylimitingmetadatabroadcastto
asubsetofnodes.
â¢Improvesreliabilityandperformanceforhighlyconcurrentworkloadsbyreducingworkloadstressoncoordinators.
Dedicatedcoordinatorsrequire50%orfewerconnections andthreads.
â¢Reducesthenumberofexplicitmetadatarefreshesrequired.
â¢Improvesdiagnosability ifabottleneckorotherperformance issuearisesonaspecifichost,youcannarrowdown
thecausemoreeasilybecauseeachhostisdedicatedtospecificoperationswithintheoverallImpalaworkload.
Inthisconfigurationwithdedicatedcoordinators/executors,youcannotconnecttothededicatedexecutorhosts
throughclientssuchasimpala-shell orbusinessintelligencetoolsasonlythecoordinatornodessupportclient
connections.
Determining theOptimalNumberofDedicatedCoordinators
Youshouldhavethesmallestnumberofcoordinatorsthatwillstillsatisfyyourworkloadrequirementsinacluster.A
roughestimationis1coordinatorforevery50executors.
ApacheImpalaGuide|615ScalabilityConsiderationsforImpala
Tomaintainahealthystateandoptimalperformance, itisrecommended thatyoukeepthepeakutilizationofall
resourcesusedbyImpala,including CPU,thenumberofthreads,thenumberofconnections, andRPCs,under80%.
Consider thefollowingfactorstodeterminetherightnumberofcoordinatorsinyourcluster:
â¢Whatisthenumberofconcurrentqueries?
â¢WhatpercentageoftheworkloadisDDL?
â¢Whatistheaveragequeryresourceusageatthevariousstages(merge,runtimefilter,resultsetsize,etc.)?
â¢HowmanyImpalaDaemons (impalad) isinthecluster?
â¢Isthereahighavailabilityrequirement?
â¢Compute/storagecapacityreduction factor
Startwiththebelowsetofstepstodeterminetheinitialnumberofcoordinators:
1.Ifyourclusterhaslessthan10nodes,werecommend thatyouconfigureonededicatedcoordinator.Deploythe
dedicatedcoordinatoronaDataNodetoavoidlosingstoragecapacity.Inmostofthecases,onededicated
coordinatorisenoughtosupportallworkloadsonacluster.
2.AddmorecoordinatorsifthededicatedcoordinatorCPUornetworkpeakutilizationis80%orhigher.Youmight
need1coordinatorforevery50executors.
3.IftheImpalaserviceissharedbymultipleworkgroupswithadynamicresourcepoolassigned, useonecoordinator
perpooltoavoidadmission controloveradmission.
4.Ifhighavailabilityisrequired,doublethenumberofcoordinators.Onesetasanactivesetandtheotherasa
backupset.
AdvancedTuning
Usethefollowingguidelines tofurthertunethethroughputandstability.
1.TheconcurrencyofDMLstatementsdoesnottypicallydependonthenumberofcoordinatorsorsizeofthecluster.
Queriesthatreturnlargeresultsets(10,000+rows)consumemoreCPUandmemoryresourcesonthecoordinator.
Addoneortwocoordinatorsiftheworkloadhasmanysuchqueries.
2.DDLqueries,excludingCOMPUTE STATS andCREATE TABLE AS SELECT ,areexecutedonlyoncoordinators.
IfyourworkloadcontainsmanyDDLqueriesrunningconcurrently,youcouldaddonecoordinator.
3.TheCPUcontentiononcoordinatorscanslowdownqueryexecutionswhenconcurrencyishigh,especially for
veryshortqueries(<10s).AddmorecoordinatorstoavoidCPUcontention.
4.Onalargeclusterwith50+nodes,thenumberofnetworkconnections fromacoordinatortoexecutorscangrow
quicklyasquerycomplexityincreases.Thegrowthismuchgreateroncoordinatorsthanexecutors.Addafew
morecoordinatorsifworkloadsarecomplex,i.e.(anaveragenumberoffragments*numberofImpalad) >500,
butwiththelowmemory/CPUusagetosharetheload.WatchIMPALA-4603 andIMPALA-7213 totracktheprogress
onfixingthisissue.
5.WhenusingmultiplecoordinatorsforDMLstatements,dividequeriestodifferentgroups(numberofgroups=
numberofcoordinators).Configureaseparatedynamicresourcepoolforeachgroupanddirecteachgroupof
queryrequeststoaspecificcoordinator.Thisistoavoidqueryoveradmission.
6.Thefront-endconnection requirementisnotafactorindetermining thenumberofdedicatedcoordinators.
Consider settingupaconnection poolattheclientsideinsteadofaddingcoordinators.Forashort-termsolution,
youcouldincreasethevalueoffe_service_threads oncoordinatorstoallowmoreclientconnections.
7.Ingeneral,youshouldhaveaverysmallnumberofcoordinatorssostoragecapacityreduction isnotaconcern.
Onaverysmallcluster(lessthan10nodes),deployadedicatedcoordinatoronaDataNodetoavoidstorage
capacityreduction.
EstimatingCoordinatorResourceUsage
Notes/CMtsquerytomonitor Saferange Resource
Memoryusage: (MaxJVMheapsetting+ Memory
616|ApacheImpalaGuideScalabilityConsiderationsforImpala
SELECTmem_rssWHEREentityName
="CoordinatorInstanceID"AND
category=ROLEqueryconcurrency*
querymem_limit)
<=JVMheapusage(metadatacache):
80%ofImpalaprocessmemory
allocationSELECT
impala_jvm_heap_curr ent_usage_bytes
WHEREentityName ="Coordinator
InstanceID"ANDcategory=ROLE
(onlyinrelease5.15andabove)
Incomingconnection usage: Incoming+outgoing<16K TCPConnection
SELECT
thrift_server_backend_connections_in_use
WHEREentityName ="Coordinator
InstanceID"ANDcategory=ROLE
Outgoingconnection usage:
SELECT
backends_clien t_cache_clien ts_in_use
WHEREentityName ="Coordinator
InstanceID"ANDcategory=ROLE
SELECT
thread_manag er_running_thr eads<32K Threads
WHEREentityName ="Coordinator
InstanceID"ANDcategory=ROLE
CPUusageestimationshouldbebased
onhowmanycoresareallocatedtoConcurrency=
non-DDL queryconcurrency<=CPU
Impalapernode,notasumofallcores
ofthecluster. numberofvirtualcoresallocatedto
ImpalapernodeItisrecommended thatconcurrency
shouldnotbemorethanthenumber
ofvirtualcoresallocatedtoImpalaper
node.
Queryconcurrency:
SELECT
total_impala_num_queries_r egistered_across_impalads
WHEREentityName ="IMPALA-1"AND
category=SERVICE
Ifusageofanyoftheaboveresourcesexceedsthesaferange,addonemorecoordinator.
MonitoringCoordinatorResourceUsage
UsingClouderaManager,monitorthecoordinatorresourceusagetounderstandyourworkloadandadjustthenumber
ofcoordinatorsaccordingtotheguidelines above.Theavailableoptionsare:
â¢ImpalaQueriestab:MonitorsuchattributesasDDLqueriesandRowsproduced.SeeMonitoringImpalaQueries
fordetailinformation.
â¢Customcharts:Monitoractivities, suchasquerycomplexitywhichisanaveragefragmentcountperquery(total
fragments/totalqueries).
â¢tsquery:Buildthecustomchartstomonitorandestimatetheamountofresourcethecoordinatorneeds.See
tsqueryLanguageformoreinformation.
ApacheImpalaGuide|617ScalabilityConsiderationsforImpala
Thefollowingaresamplequeriesforcommonresourceusagemonitoring.ReplaceentityName valueswithyour
coordinatorinstanceid.
Percoordinatortsquery
Tsquery ResourceUsage
SELECTimpala_memor y_total_used,
mem_tracker_process_limit WHEREentityName =
"CoordinatorInstanceID"ANDcategory=ROLEMemoryusage
SELECTimpala_jvm_heap_curr ent_usage_bytesWHERE
entityName ="CoordinatorInstanceID"ANDcategory=
ROLE(onlyinrelease5.15andabove)JVMheapusage(metadatacache)
SELECTcpu_user_r ate/getHostFact(numCor es,1)*100,
cpu_system_rate/getHostFact(numCor es,1)*100WHERE
entityName="Coor dinatorInstanceID"CPUusage
SELECT
total_bytes_receive_rate_across_network_interfaces,Networkusage(hostlevel)
total_bytes_transmit_rate_across_network_interfaces
WHEREentityName="Coor dinatorInstanceID"
SELECTthrift_server_backend_connections_in_use WHERE
entityName ="CoordinatorInstanceID"ANDcategory=
ROLEIncomingconnection usage
SELECTbackends_clien t_cache_clien ts_in_use WHERE
entityName ="CoordinatorInstanceID"ANDcategory=
ROLEOutgoingconnection usage
SELECTthread_manag er_running_thr eadsWHERE
entityName ="CoordinatorInstanceID"ANDcategory=
ROLEThreadusage
Clusterwidetsquery
Tsquery Resourceusage
SELECT
total_thrift_server_beeswax_frontend_connections_in_use_acr oss_impalads,
total_thrift_server_hiveserver2_frontend_connections_in_use_acr oss_impaladsFront-endconnection usage
SELECT
total_impala_num_queries_r egistered_across_impalads
WHEREentityName ="IMPALA-1"ANDcategory=SERVICEQueryconcurrency
DeployingDedicatedCoordinatorsandExecutorsinClouderaManager
Thissectiondescribes theprocesstoconfigureadedicatedcoordinatorandadedicatedexecutorrolesforImpala.
â¢Dedicatedcoordinator:
âShouldbeonanedgenodewithnootherservicesrunningonit.
âDoesnotneedlargelocaldisksbutstillneedssomethatcanbeusedforSpilling.
âRequireatleastthesameorevenlargermemoryallocationthanexecutors.
â¢(Dedicated)Executors:
â¢ShouldbecolocatedwithDataNodes.
â¢Thenumberofhostswithdedicatedexecutorstypicallyincreasesastheclustergrowslargerandhandles
moretablepartitions, datafiles,andconcurrentqueries.
618|ApacheImpalaGuideScalabilityConsiderationsforImpala
Toconfiguringdedicatedcoordinators/executors:
1.NavigatetoClusters>Impala>Configuration>RoleGroups.
2.ClickCreatetocreatetworolegroupswiththefollowingvalues.
a.GroupforCoordinators
a.GroupName:Coordinators
b.RoleType:ImpalaDaemon
c.Copyfrom:
â¢SelectImpalaDaemonDefaultGroupifyouwanttheexistingconfigurationgetscarriedoverto
theCoordinators.
â¢SelectNoneifyouwanttostartwithablankconfiguration.
b.GroupforExecutors
a.GroupName:Executors
b.RoleType:ImpalaDaemon
c.Copyfrom:
â¢SelectImpalaDaemonDefaultGroupifyouwanttheexistingconfigurationgetscarriedoverto
theExecutors.
â¢SelectNoneifyouwanttostartwithablankconfiguration.
3.IntheRoleGroupspage,clickImpalaDaemonDefaultGroup.
a.Selectthesetofnodesintendedtobecoordinators.
a.ClickActionforSelectedandselectMoveToDifferentRoleGroupâ¦.
b.SelecttheCoordinators.
b.SelectthesetofnodesintendedtobeExecutors.
a.ClickActionforSelectedandselectMoveToDifferentRoleGroupâ¦.
b.SelectExecutors.
4.ClickConfiguration.Inthesearchfield,typeImpalaDaemonSpecialization.
5.ClickEditIndividual Values.
6.ForCoordinatorsrolegroup,selectCOORDINA TOR_ONLY.
7.ForExecutorsrolegroup,selectEXECUTOR_ONLY.
8.ClickSaveChangesandthenrestarttheImpalaservice.
DeployingDedicatedCoordinatorsandExecutorsfromCommand Line
Toconfiguringdedicatedcoordinators/executors,youspecifyoneofthefollowingstartupflagsfortheimpalad
daemononeachhost:
â¢--is_executor=false foreachhostthatdoesnotactasanexecutorforImpalaqueries.Thesehostsact
exclusivelyasquerycoordinators.Thissettingtypicallyappliestoarelativelysmallnumberofhosts,becausethe
mostcommontopologyistohavenearlyallDataNodesdoingworkforqueryexecution.
â¢--is_coordinator=false foreachhostthatdoesnotactasacoordinatorforImpalaqueries.Thesehostsact
exclusivelyasexecutors.Thenumberofhostswiththissettingtypicallyincreasesastheclustergrowslargerand
handlesmoretablepartitions, datafiles,andconcurrentqueries.Astheoverheadforquerycoordinationincreases,
itbecomesmoreimportanttocentralizethatworkondedicatedhosts.
ApacheImpalaGuide|619ScalabilityConsiderationsforImpala
MetadataManagement
Thistopicdescribes variousknobsyoucanusetocontrolhowImpalamanagesitsmetadatainordertoimprove
performance andscalability.
On-demand Metadata
InpreviousversionsofImpala,everycoordinatorkeptareplicaofallthecacheincatalogd ,consuming largememory
oneachcoordinatorwithnooptiontoevict.Metadataalwayspropagatedthroughthestatestored andsuffersfrom
head-of-line blocking,forexample,oneuserloadingabigtableblockinganotheruserloadingasmalltable.
Withthisnewfeature,thecoordinatorspullmetadataasneededfromcatalogd andcacheitlocally.Thecached
metadatagetsevictedautomaticallyundermemorypressure.
Thegranularity ofon-demand metadatafetchesisnowatthepartitionlevelbetweenthecoordinatorandcatalogd .
Common usecaseslikeadd/droppartitions donottriggerunnecessar yserialization/deserializ ationoflargemetadata.
Thisfeatureisdisabledbydefault.
Thefeaturecanbeusedineitherofthefollowingmodes.
Metadataon-demand mode
Inthismode,allcoordinatorsusethemetadataon-demand.
Setthefollowingoncatalogd :
--catalog_topic_mode=minimal
Setthefollowingonallimpalad coordinators:
--use_local_catalog=true
Mixedmode
Inthismode,onlysomecoordinatorsareenabledtousethemetadataon-demand.
Werecommend thatyouusethemixedmodeonlyfortestinglocalcatalogâsimpactonheapusage.
Setthefollowingoncatalogd :
--catalog_topic_mode=mixed
Setthefollowingonimpalad coordinatorswithmetdadataon-demand:
--use_local_catalog=true 
Limitation:
GlobalINVALIDATES arenotsupportedwhenthisfeatureisenabled.IfyourworkloadrequiresglobalINVALIDATES ,
donotusethisfeature.
AutomaticInvalidationofMetadataCache
Tokeepthesizeofmetadatabounded, catalogd periodicallyscansallthetablesandinvalidatesthosenotrecently
used.Therearetwotypesofconfigurationsincatalogd .
Time-based cacheinvalidation
Catalogd invalidatestablesthatarenotrecentlyusedinthespecified timeperiod(inseconds).
The--invalidate_tables_timeout_s flagneedstobeappliedtobothimpalad andcatalogd .
Memory-basedcacheinvalidation
Whenthememorypressurereaches60%ofJVMheapsizeafteraJavagarbagecollectionincatalogd ,Impala
invalidates10%oftheleastrecentlyusedtables.
620|ApacheImpalaGuideScalabilityConsiderationsforImpala
The--invalidate_tables_on_memory_pressure flagneedstobeappliedtobothimpalad andcatalogd .
Automaticinvalidationofmetadataprovidesmorestabilitywithlowerchancesofrunningoutofmemory,butthe
featurecouldpotentiallycauseperformance issuesandmayrequiretuning.
AutomaticInvalidation/RefreshofMetadata
WhentoolssuchasHiveandSparkareusedtoprocesstherawdataingestedintoHivetables,newHMSmetadata
(database,tables,partitions) andfilesystemmetadata(newfilesinexistingpartitions/t ables)isgenerated.Inprevious
versionsofImpala,inordertopickupthisnewinformation,Impalausersneededtomanually issueanINVALIDATE
orREFRESH commands.
Whenautomaticinvalidate/refreshofmetadataisenabled,catalogd pollsHiveMetastore(HMS)notificationevents
ataconfigurableintervalandprocessesthefollowingchanges:
Note:ThisisapreviewfeatureinCDH6.3/Impala3.3andnotgenerallyavailable.
â¢InvalidatesthetableswhenitreceivestheALTER TABLE event.
â¢Refreshesthepartition whenitreceivestheALTER,ADD,orDROPpartitions.
â¢AddsthetablesordatabaseswhenitreceivestheCREATE TABLE orCREATE DATABASE events.
â¢Removesthetablesfromcatalogd whenitreceivestheDROP TABLE orDROP DATABASE events.
â¢Refreshesthetableandpartitions whenitreceivestheINSERTevents.
IfthetableisnotloadedatthetimeofprocessingtheINSERTevent,theeventprocessordoesnotneedtorefresh
thetableandskipsit.
Thisfeatureiscontrolledbythe--hms_event_polling_interval_s flag.Startthecatalogd withthe
--hms_event_polling_interval_s flagsettoapositiveintegertoenablethefeatureandsetthepollingfrequency
inseconds.Werecommend thevaluetobelessthan5seconds.
Thefollowingusecasesarenotsupported:
â¢WhenyoubypassHMSandaddorremovedataintotablebyaddingfilesdirectlyonthefilesystem,HMSdoes
notgeneratetheINSERTevent,andtheeventprocessorwillnotinvalidatethecorresponding tableorrefresh
thecorresponding partition.
Itisrecommended thatyouusetheLOAD DATA command todothedataloadinsuchcases,sothateventprocessor
canactontheeventsgeneratedbytheLOADcommand.
â¢TheSparkAPIthatsavesdatatoaspecified locationdoesnotgenerateeventsinHMS,thusisnotsupported.For
example:
Seq((1, 2)).toDF("i", 
"j").write.save("/user/hive/warehouse/spark_etl.db/customers/date=01012019")
Thisfeatureisturnedoffbydefaultwiththe--hms_event_polling_interval_s flagsetto0.
ConfigureHMSforEventBasedAutomaticMetadataSync
AsthefirststeptousetheHMSeventbasedmetadatasync,enableandconfigureHMSnotificationsinCloudera
Manager.
1.NavigatetoClusters>Hive>Configuration>Filters>SCOPE>HiveMetastoreServer.
2.SelectEnableStoredNotificationsinDatabase.
3.InHiveMetastoreServerAdvancedConfigurationSnippet(SafetyValve)forhive-site.xml,click+toexpandand
enterthefollowing:
â¢Name:hive.metastore.notifications.add. thrift.objects
â¢Value:true
ApacheImpalaGuide|621ScalabilityConsiderationsforImpala
â¢Name:hive.metastore.alter.notifications.basic
â¢Value:false
4.ClickSaveChanges.
5.IfyouwantINSERTeventsaregeneratedwhentheSpark(andothernon-hive)applicationsinsertdatainto
existingtablesandpartitions:
a.InHiveClientAdvancedConfigurationSnippet(SafetyValve)forhive-site.xml,click+toexpandandenter
thefollowing:
â¢Name:hive.metastore.dml.events
â¢Value:true
b.InHiveServiceAdvancedConfigurationSnippet(SafetyValve)forhive-site.xml,click+toexpandandenter
thefollowing:
â¢Name:hive.metastore.dml.events
â¢Value:true
c.ClickSaveChanges.
6.Restartstaleservices.
ConfigureCatalogServerforEvent-BasedAutomaticMetadataSync
1.NavigatetoClusters>Impala>Configuration>Filters>SCOPE>ImpalaCatalogServer.
2.InCatalogServerCommand LineArgumen tAdvancedConfigurationSnippet(SafetyValve),click+toexpand
andenterthefollowing:
â¢Name:--hms_event_polling_interval_s
â¢Value:4
3.ClickSaveChanges.
4.RestarttheCatalogserverwhenappropriate.
DisableEventBasedAutomaticMetadataSync
Whenthe--hms_event_polling_interval_s flagissettoanon-zerovalueforyourcatalogd ,theevent-based
automaticinvalidationisenabledforalldatabasesandtables.Ifyouwishtohavethefine-grainedcontrolonwhich
tablesordatabasesneedtobesyncedusingevents,youcanusetheimpala.disableHmsSync propertytodisable
theeventprocessingatthetableordatabaselevel.
WhenyouaddtheDBPROPERTIES orTBLPROPERTIES withtheimpala.disableHmsSync key,theHMSeventbased
syncisturnedonoroff.Thevalueoftheimpala.disableHmsSync propertydeterminesiftheeventprocessing
needstobedisabledforaparticular tableordatabase.
â¢If'impala.disableHmsSync'='true' ,theeventsforthattableordatabaseareignoredandnotsyncedwith
HMS.
â¢If'impala.disableHmsSync'='false' orifimpala.disableHmsSync isnotset,theautomaticsyncwith
HMSisenabledifthe--hms_event_polling_interval_s globalflagissettonon-zero.
â¢TodisabletheeventbasedHMSsyncforanewdatabase,settheimpala.disableHmsSync databaseproperties
inHiveascurrently,Impaladoesnotsupportsettingdatabaseproperties:
CREATE DATABASE <name> WITH DBPROPERTIES ('impala.disableHmsSync'='true');
â¢ToenableordisabletheeventbasedHMSsyncforatable:
CREATE TABLE <name> ... TBLPROPERTIES ('impala.disableHmsSync'='true' | 'false');
622|ApacheImpalaGuideScalabilityConsiderationsforImpala
â¢TochangetheeventbasedHMSsyncatthetablelevel:
ALTER TABLE <name> SET TBLPROPERTIES ('impala.disableHmsSync'='true' | 'false');
Whenbothtableanddatabaselevelpropertiesareset,thetablelevelpropertytakesprecedence. Ifthetablelevel
propertyisnotset,thenthedatabaselevelpropertyisusedtoevaluateiftheeventneedstobeprocessedornot.
Ifthepropertyischangedfromtrue(meaning eventsareskipped)tofalse(meaning eventsarenotskipped), you
needtoissueamanualINVALIDATE METADATA command toreseteventprocessorbecauseitdoesn'tknowhow
manyeventshavebeenskippedinthepastandcannotknowiftheobjectintheeventisthelatest.Insuchacase,the
statusoftheeventprocessorchangestoNEEDS_INVALIDATE .
MetricsforEventBasedAutomaticMetadataSync
YoucanusethewebUIofthecatalogd tocheckthestateoftheautomaticinvalidateeventprocessor.
Bydefault,thedebugwebUIofcatalogd isathttp://impala-server-hostname :25020(non-secur ecluster)
orhttps:// impala-server-hostname :25020(securecluster).
UnderthewebUI,therearetwopagesthatpresentsthemetricsforHMSeventprocessorthatisresponsible forthe
eventbasedautomaticmetadatasync.
â¢/metrics#events
â¢/events
Thisprovidesadetailedviewofthemetricsoftheeventprocessor,including min,max,mean,median,ofthe
durationsandratemetricsforallthecounterslistedonthe/metrics#eventspage.
/metrics#eventsPage
The/metrics#eventspageprovidesthefollowingmetricsabouttheHMSeventprocessor.
Description Name
Averagedurationtofetchabatchofeventsandprocessit. events-processor.
avg-events-fetch-duration
AveragetimetakentoprocessabatchofeventsreceivedfromtheMetastore. events-processor.
avg-events-process-dur ation
TotalnumberoftheMetastoreeventsreceived. events-processor.
events-received
Exponentiallyweightedmovingaverage(EWMA)ofnumberofeventsreceivedin
last15min.
Thisrateofeventscanbeusedtodetermineiftherearespikesineventprocessor
activityduringcertainhoursoftheday.events-processor.
events-received-15min-r ate
Exponentiallyweightedmovingaverage(EWMA)ofnumberofeventsreceivedin
last1min.
Thisrateofeventscanbeusedtodetermineiftherearespikesineventprocessor
activityduringcertainhoursoftheday.events-processor.
events-received-1min-r ate
Exponentiallyweightedmovingaverage(EWMA)ofnumberofeventsreceivedin
last5min.
Thisrateofeventscanbeusedtodetermineiftherearespikesineventprocessor
activityduringcertainhoursoftheday.events-processor.
events-received-5min-r ate
ApacheImpalaGuide|623ScalabilityConsiderationsforImpala
Description Name
TotalnumberoftheMetastoreeventsskipped.
Eventscanbeskippedbasedoncertainflagsaretableanddatabaselevel.Youcan
usethismetrictomakedecisions, suchas:events-processor.
events-skipped
â¢Ifmostoftheeventsarebeingskipped,seeifyoumightjustturnofftheevent
processing.
â¢Ifmostoftheeventsarenotskipped,seeifyouneedtoaddflagsoncertain
databases.
Metastoreeventprocessorstatustoseeifthereareeventsbeingreceivedornot.
Possiblestatesare:events-processor.status
â¢PAUSED
Theeventprocessorispausedbecausecatalogisbeingresetconcurrently.
â¢ACTIVE
Theeventprocessorisscheduled atagivenfrequency.
â¢ERROR
â¢Theeventprocessorisinerrorstateandeventprocessinghasstopped.
â¢NEEDS_INVALIDATE
Theeventprocessorcouldnotresolvecertaineventsandneedsamanual
INVALIDATE command toresetthestate.
â¢STOPPED
Theeventprocessinghasbeenshutdown.Noeventswillbeprocessed.
â¢DISABLED
Theeventprocessorisnotconfiguredtorun.
624|ApacheImpalaGuideScalabilityConsiderationsforImpala
Partitioning forImpalaTables
Bydefault,allthedatafilesforatablearelocatedinasingledirectory.Partitioning isatechnique forphysicallydividing
thedataduringloading,basedonvaluesfromoneormorecolumns,tospeedupqueriesthattestthosecolumns.For
example,withaschool_records tablepartitioned onayearcolumn,thereisaseparatedatadirectoryforeach
differentyearvalue,andallthedataforthatyearisstoredinadatafileinthatdirectory.AquerythatincludesaWHERE
conditionsuchasYEAR=1966 ,YEAR IN (1989,1999) ,orYEAR BETWEEN 1984 AND 1989 canexamineonlythe
datafilesfromtheappropriatedirectoryordirectories,greatlyreducingtheamountofdatatoreadandtest.
SeeAttachinganExternalPartitioned TabletoanHDFSDirectoryStructureonpage54foranexamplethatillustrates
thesyntaxforcreatingpartitioned tables,theunderlying directorystructureinHDFS,andhowtoattachapartitioned
ImpalaexternaltabletodatafilesstoredelsewhereinHDFS.
Parquetisapopularformatforpartitioned Impalatablesbecauseitiswellsuitedtohandlehugedatavolumes.See
QueryPerformance forImpalaParquetTablesonpage645forperformance considerationsforpartitioned Parquet
tables.
SeeNULLonpage170fordetailsabouthowNULLvaluesarerepresentedinpartitioned tables.
SeeUsingImpalawiththeAmazonS3Filesystemonpage692fordetailsaboutsettinguptableswheresomeorall
partitions resideontheAmazonSimpleStorageService(S3).
WhentoUsePartitioned Tables
Partitioning istypicallyappropriatefor:
â¢Tablesthatareverylarge,wherereadingtheentiredatasettakesanimpracticalamountoftime.
â¢Tablesthatarealwaysoralmostalwaysqueriedwithconditions onthepartitioning columns.Inourexampleof
atablepartitioned byyear,SELECT COUNT(*) FROM school_records WHERE year = 1985 isefficient,
onlyexaminingasmallfractionofthedata;butSELECT COUNT(*) FROM school_records hastoprocessa
separatedatafileforeachyear,resultinginmoreoverallworkthaninanunpartitioned table.Youwouldprobably
notpartitionthiswayifyoufrequentlyqueriedthetablebasedonlastname,studentID,andsoonwithouttesting
theyear.
â¢Columns thathavereasonable cardinality(numberofdifferentvalues).Ifacolumnonlyhasasmallnumberof
values,forexampleMaleorFemale,youdonotgainmuchefficiencybyeliminatingonlyabout50%ofthedata
toreadforeachquery.Ifacolumnhasonlyafewrowsmatchingeachvalue,thenumberofdirectoriestoprocess
canbecomealimitingfactor,andthedatafileineachdirectorycouldbetoosmalltotakeadvantageoftheHadoop
mechanism fortransmittingdatainmulti-meg abyteblocks.Forexample,youmightpartitioncensusdatabyyear,
storesalesdatabyyearandmonth,andwebtrafficdatabyyear,month,andday.(Someuserswithhighvolumes
ofincomingdatamightevenpartition downtotheindividual hourandminute.)
â¢Datathatalreadypassesthroughanextract,transform,andload(ETL)pipeline.Thevaluesofthepartitioning
columnsarestrippedfromtheoriginaldatafilesandrepresentedbydirectorynames,soloadingdataintoa
partitioned tableinvolvessomesortoftransformationorpreprocessing.
SQLStatementsforPartitioned Tables
IntermsofImpalaSQLsyntax,partitioning affectsthesestatements:
â¢CREATE TABLE :youspecifyaPARTITIONED BY clausewhencreatingthetabletoidentifynamesanddatatypes
ofthepartitioning columns.Thesecolumnsarenotincludedinthemainlistofcolumnsforthetable.
â¢InCDH5.7/Impala2.5andhigher,youcanalsousethePARTITIONED BY clauseinaCREATE TABLE AS SELECT
statement.Thissyntaxletsyouuseasinglestatementtocreateapartitioned table,copydataintoit,andcreate
newpartitions basedonthevaluesintheinserteddata.
ApacheImpalaGuide|625Partitioning forImpalaTables
â¢ALTER TABLE :youcanaddordroppartitions, toworkwithdifferentportionsofahugedataset.Youcandesignate
theHDFSdirectorythatholdsthedatafilesforaspecificpartition. Withdatapartitioned bydatevalues,youmight
âageoutâdatathatisnolongerrelevant.
Note:Ifyouarecreatingapartition forthefirsttimeandspecifyingitslocation,formaximum
efficiency,useasingleALTER TABLE statementincluding boththeADD PARTITION and
LOCATION clauses,ratherthanseparatestatementswithADD PARTITION andSET LOCATION
clauses.
â¢INSERT:Whenyouinsertdataintoapartitioned table,youidentifythepartitioning columns.Oneormorevalues
fromeachinsertedrowarenotstoredindatafiles,butinsteaddeterminethedirectorywherethatrowvalueis
stored.Youcanalsospecifywhichpartition toloadasetofdatainto,withINSERT OVERWRITE statements;you
canreplacethecontentsofaspecificpartition butyoucannotappenddatatoaspecificpartition.
Bydefault,ifanINSERTstatementcreatesanynewsubdirectoriesundernea thapartitioned table,those
subdirectoriesareassigneddefaultHDFSpermissions fortheimpalauser.Tomakeeachsubdirectoryhavethe
samepermissions asitsparentdirectoryinHDFS,specifythe--insert_inherit_permissions startupoption
fortheimpalad daemon.
â¢Although thesyntaxoftheSELECTstatementisthesamewhetherornotthetableispartitioned, thewayqueries
interactwithpartitioned tablescanhaveadramaticimpactonperformance andscalability.Themechanism that
letsqueriesskipcertainpartitions duringaqueryisknownaspartitionpruning;seePartitionPruningforQueries
onpage627fordetails.
â¢InImpala1.4andlater,thereisaSHOW PARTITIONS statementthatdisplaysinformationabouteachpartition
inatable.SeeSHOWStatementonpage363fordetails.
StaticandDynamicPartitioning Clauses
Specifyingallthepartition columnsinaSQLstatementiscalledstaticpartitioning ,becausethestatementaffectsa
singlepredictablepartition. Forexample,youusestaticpartitioning withanALTER TABLE statementthataffectsonly
onepartition, orwithanINSERTstatementthatinsertsallvaluesintothesamepartition:
insert into t1 partition(x=10, y='a')  select c1 from some_other_table;
Whenyouspecifysomepartition keycolumnsinanINSERTstatement,butleaveoutthevalues,Impaladetermines
whichpartition toinsert.Thistechnique iscalleddynamicpartitioning :
insert into t1 partition(x, y='b')  select c1, c2 from some_other_table;
-- Create new partition if necessary based on variable year, month, and day; insert a 
single value.
insert into weather partition (year, month, day)  select 'cloudy',2014,4,21;
-- Create new partition if necessary for specified year and month but variable day; 
insert a single value.
insert into weather partition (year=2014, month=04, day)  select 'sunny',22;
ThemorekeycolumnsyouspecifyinthePARTITION clause,thefewercolumnsyouneedintheSELECTlist.The
trailingcolumnsintheSELECTlistaresubstitutedinorderforthepartition keycolumnswithnospecified value.
RefreshingaSinglePartition
TheREFRESH statementistypicallyusedwithpartitioned tableswhennewdatafilesareloadedintoapartition by
somenon-Impala mechanism, suchasaHiveorSparkjob.TheREFRESH statementmakesImpalaawareofthenew
datafilessothattheycanbeusedinImpalaqueries.Becausepartitioned tablestypicallycontainahighvolumeof
data,theREFRESH operationforafullpartitioned tablecantakesignificanttime.
InCDH5.9/Impala2.7andhigher,youcanincludeaPARTITION ( partition_spec )clauseintheREFRESH
statementsothatonlyasinglepartitionisrefreshed.Forexample,REFRESH big_table PARTITION (year=2017,
626|ApacheImpalaGuidePartitioning forImpalaTables
month=9, day=30) .Thepartition specmustincludeallthepartition keycolumns.SeeREFRESHStatementonpage
291formoredetailsandexamplesofREFRESH syntaxandusage.
Permissions forPartitionSubdirectories
Bydefault,ifanINSERTstatementcreatesanynewsubdirectoriesundernea thapartitioned table,thosesubdirectories
areassigneddefaultHDFSpermissions fortheimpalauser.Tomakeeachsubdirectoryhavethesamepermissions
asitsparentdirectoryinHDFS,specifythe--insert_inherit_permissions startupoptionfortheimpalad
daemon.
PartitionPruningforQueries
Partitionpruningreferstothemechanism whereaquerycanskipreadingthedatafilescorresponding tooneormore
partitions. Ifyoucanarrangeforqueriestoprunelargenumbersofunnecessar ypartitions fromthequeryexecution
plan,thequeriesusefewerresourcesandarethusproportionally fasterandmorescalable.
Forexample,ifatableispartitioned bycolumnsYEAR,MONTH,andDAY,thenWHEREclausessuchasWHERE year =
2013,WHERE year < 2010 ,orWHERE year BETWEEN 1995 AND 1998 allowImpalatoskipthedatafilesinall
partitions outsidethespecified range.Likewise,WHERE year = 2013 AND month BETWEEN 1 AND 3 couldprune
evenmorepartitions, readingthedatafilesforonlyaportionofoneyear.
Checking ifPartitionPruningHappens foraQuery
Tochecktheeffectivenessofpartition pruningforaquery,checktheEXPLAIN outputforthequerybeforerunning
it.Forexample,thisexampleshowsatablewith3partitions, wherethequeryonlyreads1ofthem.Thenotation
#partitions=1/3 intheEXPLAIN planconfirmsthatImpalacandotheappropriatepartition pruning.
[localhost:21000] > insert into census partition (year=2010) values ('Smith'),('Jones');
[localhost:21000] > insert into census partition (year=2011) values 
('Smith'),('Jones'),('Doe');
[localhost:21000] > insert into census partition (year=2012) values ('Smith'),('Doe');
[localhost:21000] > select name from census where year=2010;
+-------+
| name  |
+-------+
| Smith |
| Jones |
+-------+
[localhost:21000] > explain select name from census where year=2010 ;
+------------------------------------------------------------------+
| Explain String                                                   |
+------------------------------------------------------------------+
| PLAN FRAGMENT 0                                                  |
|   PARTITION: UNPARTITIONED                                       |
|                                                                  |
|   1:EXCHANGE                                                     |
|                                                                  |
| PLAN FRAGMENT 1                                                  |
|   PARTITION: RANDOM                                              |
|                                                                  |
|   STREAM DATA SINK                                               |
|     EXCHANGE ID: 1                                               |
|     UNPARTITIONED                                                |
|                                                                  |
|   0:SCAN HDFS                                                    |
|      table=predicate_propagation.census #partitions=1/3  size=12B |
+------------------------------------------------------------------+
Forareportofthevolumeofdatathatwasactuallyreadandprocessedateachstageofthequery,checktheoutput
oftheSUMMARY command immediatelyafterrunningthequery.Foramoredetailedanalysis,lookattheoutputof
thePROFILE command; itincludesthissamesummaryreportnearthestartoftheprofileoutput.
ApacheImpalaGuide|627Partitioning forImpalaTables
WhatSQLConstructsWorkwithPartitionPruning
Impalacanevendopartition pruningincaseswherethepartition keycolumnisnotdirectlycomparedtoaconstant,
byapplyingthetransitivepropertytootherpartsoftheWHEREclause.Thistechnique isknownaspredicatepropagation,
andisavailableinImpala1.2.2andlater.Inthisexample,thecensustableincludesanothercolumnindicatingwhen
thedatawascollected,whichhappensin10-yearintervals.Eventhoughthequerydoesnotcomparethepartitionkey
column(YEAR)toaconstantvalue,ImpalacandeducethatonlythepartitionYEAR=2010 isrequired,andagainonly
reads1outof3partitions.
[localhost:21000] > drop table census;
[localhost:21000] > create table census (name string, census_year int) partitioned by 
(year int);
[localhost:21000] > insert into census partition (year=2010) values 
('Smith',2010),('Jones',2010);
[localhost:21000] > insert into census partition (year=2011) values 
('Smith',2020),('Jones',2020),('Doe',2020);
[localhost:21000] > insert into census partition (year=2012) values 
('Smith',2020),('Doe',2020);
[localhost:21000] > select name from census where year = census_year and census_year=2010;
+-------+
| name  |
+-------+
| Smith |
| Jones |
+-------+
[localhost:21000] > explain select name from census where year = census_year and 
census_year=2010 ;
+------------------------------------------------------------------+
| Explain String                                                   |
+------------------------------------------------------------------+
| PLAN FRAGMENT 0                                                  |
|   PARTITION: UNPARTITIONED                                       |
|                                                                  |
|   1:EXCHANGE                                                     |
|                                                                  |
| PLAN FRAGMENT 1                                                  |
|   PARTITION: RANDOM                                              |
|                                                                  |
|   STREAM DATA SINK                                               |
|     EXCHANGE ID: 1                                               |
|     UNPARTITIONED                                                |
|                                                                  |
|   0:SCAN HDFS                                                    |
|      table=predicate_propagation.census #partitions=1/3  size=22B |
|      predicates: census_year = 2010, year = census_year          |
+------------------------------------------------------------------+
Ifaviewappliestoapartitioned table,anypartition pruningconsiderstheclausesonboththeoriginalqueryandany
additional WHEREpredicatesinthequerythatreferstotheview.PriortoImpala1.4,onlytheWHEREclausesonthe
originalqueryfromtheCREATE VIEW statementwereusedforpartition pruning.
Inqueriesinvolvingbothanalyticfunctions andpartitioned tables,partition pruningonlyoccursforcolumnsnamed
inthePARTITION BY clauseoftheanalyticfunctioncall.Forexample,ifananalyticfunctionqueryhasaclausesuch
asWHERE year=2016 ,thewaytomakethequerypruneallotherYEARpartitions istoincludePARTITION BY year
intheanalyticfunctioncall;forexample,OVER (PARTITION BY year, other_columns
other_analytic_clauses ).
DynamicPartitionPruning
Theoriginalmechanism usestoprunepartitions isstaticpartition pruning,inwhichtheconditions intheWHEREclause
areanalyzedtodetermineinadvancewhichpartitions canbesafelyskipped.InImpala2.5/CDH5.7andhigher,Impala
canperformdynamicpartition pruning,whereinformationaboutthepartitions iscollectedduringthequery,and
Impalaprunesunnecessar ypartitions inwaysthatwereimpracticaltopredictinadvance.
628|ApacheImpalaGuidePartitioning forImpalaTables
Forexample,ifpartition keycolumnsarecomparedtoliteralvaluesinaWHEREclause,Impalacanperformstatic
partition pruningduringtheplanningphasetoonlyreadtherelevantpartitions:
-- The query only needs to read 3 partitions whose key values are known ahead of time.
-- That's static partition pruning.
SELECT COUNT(*) FROM sales_table WHERE year IN (2005, 2010, 2015);
Dynamicpartition pruninginvolvesusinginformationonlyavailableatruntime,suchastheresultofasubquery.The
followingexampleshowsasimpledynamicpartition pruning.
CREATE TABLE yy (s STRING) PARTITIONED BY (year INT);
INSERT INTO yy PARTITION (year) VALUES ('1999', 1999), ('2000', 2000),
  ('2001', 2001), ('2010', 2010), ('2018', 2018);
COMPUTE STATS yy;
CREATE TABLE yy2 (s STRING, year INT);
INSERT INTO yy2 VALUES ('1999', 1999), ('2000', 2000), ('2001', 2001);
COMPUTE STATS yy2;
-- The following query reads an unknown number of partitions, whose key values
-- are only known at run time. The runtime filters  line shows the
-- information used in query fragment 02 to decide which partitions to skip.
EXPLAIN SELECT s FROM yy WHERE year IN (SELECT year FROM yy2);
+--------------------------------------------------------------------------+
| PLAN-ROOT SINK                                                           |
| |                                                                        |
| 04:EXCHANGE [UNPARTITIONED]                                              |
| |                                                                        |
| 02:HASH JOIN [LEFT SEMI JOIN, BROADCAST]                                 |
| |  hash predicates: year = year                                          |
| |  runtime filters: RF000 <- year                                    |
| |                                                                        |
| |--03:EXCHANGE [BROADCAST]                                               |
| |  |                                                                     |
| |  01:SCAN HDFS [default.yy2]                                            |
| |     partitions=1/1 files=1 size=620B                                   |
| |                                                                        |
| 00:SCAN HDFS [default.yy]                                                |
|    partitions=5/5  files=5 size=1.71KB                               |
|    runtime filters: RF000 -> year                                        |
+--------------------------------------------------------------------------+
SELECT s FROM yy WHERE year IN (SELECT year FROM yy2); -- Returns 3 rows from yy
PROFILE;
Intheaboveexample,Impalaevaluatesthesubquery,sendsthesubqueryresultstoallImpalanodesparticipatingin
thequery,andtheneachimpalad daemonusesthedynamicpartitionpruningoptimizationtoreadonlythepartitions
withtherelevantkeyvalues.
TheoutputqueryplanfromtheEXPLAIN statementshowsthatruntimefiltersareenabled. Theplanalsoshowsthat
itexpectstoreadall5partitions oftheyytable,indicatingthatstaticpartition pruningwillnothappen.
TheFiltersummaryinthePROFILE outputshowsthatthescannodefilteredoutbasedonaruntimefilterofdynamic
partition pruning.
Filter 0 (1.00 MB):
 - Files processed: 3
 - Files rejected: 1 (1)
 - Files total: 3 (3)
Dynamicpartitionpruningisespecially effectiveforqueriesinvolvingjoinsofseverallargepartitioned tables.Evaluating
theONclausesofthejoinpredicatesmightnormally requirereadingdatafromallpartitions ofcertaintables.Ifthe
WHEREclausesofthequeryrefertothepartitionkeycolumns,Impalacannowoftenskipreadingmanyofthepartitions
whileevaluatingtheONclauses.ThedynamicpartitionpruningoptimizationreducestheamountofI/Oandtheamount
ofintermediatedatastoredandtransmittedacrossthenetworkduringthequery.
ApacheImpalaGuide|629Partitioning forImpalaTables
Whenthespill-to-diskfeatureisactivatedforajoinnodewithinaquery,Impaladoesnotproduceanyruntimefilters
forthatjoinoperationonthathost.Otherjoinnodeswithinthequeryarenotaffected.
Dynamicpartition pruningispartoftheruntimefilteringfeature,whichappliestootherkindsofqueriesinaddition
toqueriesagainstpartitioned tables.SeeRuntimeFilteringforImpalaQueries(CDH5.7orhigheronly)onpage588for
fulldetailsaboutthisfeature.
PartitionKeyColumns
Thecolumnsyouchooseasthepartitionkeysshouldbeonesthatarefrequentlyusedtofilterqueryresultsinimportant,
large-scalequeries.Popularexamplesaresomecombinationofyear,month,anddaywhenthedatahasassociated
timevalues,andgeographicregionwhenthedataisassociatedwithsomeplace.
â¢Fortime-based data,splitouttheseparatepartsintotheirowncolumns,becauseImpalacannotpartition based
onaTIMESTAMP column.
â¢Thedatatypeofthepartition columnsdoesnothaveasignificanteffectonthestoragerequired,becausethe
valuesfromthosecolumnsarenotstoredinthedatafiles,rathertheyarerepresentedasstringsinsideHDFS
directorynames.
â¢InCDH5.7/Impala2.5andhigher,youcanenabletheOPTIMIZE_PARTITION_KEY_SCANS queryoptionto
speedupqueriesthatonlyrefertopartitionkeycolumns,suchasSELECT MAX(year) .Thissettingisnotenabled
bydefaultbecausethequerybehaviorisslightlydifferentifthetablecontainspartitiondirectorieswithoutactual
datainside.SeeOPTIMIZE_PARTITION_KEY_SCANS QueryOption(CDH5.7orhigheronly)onpage348fordetails.
â¢Partitioned tablescancontaincomplextypecolumns.Allthepartition keycolumnsmustbescalartypes.
â¢Remember thatwhenImpalaqueriesdatastoredinHDFS,itismostefficienttousemulti-meg abytefilestotake
advantageoftheHDFSblocksize.ForParquettables,theblocksize(andidealsizeofthedatafiles)is256MBin
Impala2.0andlater.Therefore,avoidspecifyingtoomanypartitionkeycolumns,whichcouldresultinindividual
partitions containingonlysmallamountsofdata.Forexample,ifyoureceive1GBofdataperday,youmight
partitionbyyear,month,andday;whileifyoureceive5GBofdataperminute,youmightpartitionbyyear,month,
day,hour,andminute.Ifyouhavedatawithageographiccomponen t,youmightpartition basedonpostalcode
ifyouhavemanymegabytesofdataforeachpostalcode,butifnot,youmightpartition bysomelargerregion
suchascity,state,orcountry.state
Ifyoufrequentlyrunaggregatefunctions suchasMIN(),MAX(),andCOUNT(DISTINCT) onpartition keycolumns,
considerenablingtheOPTIMIZE_PARTITION_KEY_SCANS queryoption,whichoptimizessuchqueries.Thisfeature
isavailableinCDH5.7/Impala2.5andhigher.SeeOPTIMIZE_PARTITION_KEY_SCANS QueryOption(CDH5.7orhigher
only)onpage348forthekindsofqueriesthatthisoptionappliesto,andslightdifferencesinhowpartitions areevaluated
whenthisqueryoptionisenabled.
SettingDifferentFileFormatsforPartitions
Partitioned tableshavetheflexibilitytousedifferentfileformatsfordifferentpartitions. (Forbackgroundinformation
aboutthedifferentfileformatsImpalasupports, seeHowImpalaWorkswithHadoopFileFormatsonpage634.)For
example,ifyouoriginally receiveddataintextformat,thenreceivednewdatainRCFileformat,andeventuallybegan
receivingdatainParquetformat,allthatdatacouldresideinthesametableforqueries.Youjustneedtoensurethat
thetableisstructuredsothatthedatafilesthatusedifferentfileformatsresideinseparatepartitions.
Forexample,hereishowyoumightswitchfromtexttoParquetdataasyoureceivedatafordifferentyears:
[localhost:21000] > create table census (name string) partitioned by (year smallint);
[localhost:21000] > alter table census add partition (year=2012); -- Text format;
[localhost:21000] > alter table census add partition (year=2013); -- Text format switches
 to Parquet before data loaded;
[localhost:21000] > alter table census partition (year=2013) set fileformat parquet;
630|ApacheImpalaGuidePartitioning forImpalaTables
[localhost:21000] > insert into census partition (year=2012) values 
('Smith'),('Jones'),('Lee'),('Singh');
[localhost:21000] > insert into census partition (year=2013) values 
('Flores'),('Bogomolov'),('Cooper'),('Appiah');
Atthispoint,theHDFSdirectoryforyear=2012 containsatext-formatdatafile,whiletheHDFSdirectoryforyear=2013
containsaParquetdatafile.Asalways,whenloadingnon-trivial data,youwoulduseINSERT ... SELECT orLOAD
DATAtoimportdatainlargebatches,ratherthanINSERT ... VALUES whichproducessmallfilesthatareinefficient
forreal-worldqueries.
ForotherfiletypesthatImpalacannotcreatenatively,youcanswitchintoHiveandissuetheALTER TABLE ...
SET FILEFORMAT statementsandINSERTorLOAD DATA statementsthere.AfterswitchingbacktoImpala,issuea
REFRESH table_name statementsothatImpalarecognizesanypartitions ornewdataaddedthroughHive.
Managing Partitions
Youcanadd,drop,settheexpectedfileformat,orsettheHDFSlocationofthedatafilesforindividual partitions within
anImpalatable.SeeALTERTABLEStatementonpage205forsyntaxdetails,andSettingDifferentFileFormatsfor
Partitionsonpage630fortipsonmanaging tablescontainingpartitions withdifferentfileformats.
Note:Ifyouarecreatingapartitionforthefirsttimeandspecifyingitslocation,formaximumefficiency,
useasingleALTER TABLE statementincluding boththeADD PARTITION andLOCATION clauses,
ratherthanseparatestatementswithADD PARTITION andSET LOCATION clauses.
Whathappenstothedatafileswhenapartition isdroppeddependsonwhetherthepartitioned tableisdesignated
asinternalorexternal.Foraninternal(managed)table,thedatafilesaredeleted.Forexample,ifdatainthepartitioned
tableisacopyofrawdatafilesstoredelsewhere,youmightsavediskspacebydroppingolderpartitions thatareno
longerrequiredforreporting,knowingthattheoriginaldataisstillavailableifneededlater.Foranexternaltable,the
datafilesareleftalone.Forexample,droppingapartition withoutdeletingtheassociatedfilesletsImpalaconsidera
smallersetofpartitions, improvingqueryefficiencyandreducingoverheadforDDLoperationsonthetable;ifthedata
isneededagainlater,youcanaddthepartition again.SeeOverviewofImpalaTablesonpage196fordetailsand
examples.
UsingPartitioning withKuduTables
Kudutablesuseamorefine-grainedpartitioning schemethantablescontainingHDFSdatafiles.YouspecifyaPARTITION
BYclausewiththeCREATE TABLE statementtoidentifyhowtodividethevaluesfromthepartition keycolumns.
SeePartitioning forKuduTablesonpage675fordetailsandexamplesofthepartitioning techniques forKudutables.
KeepingStatisticsUptoDateforPartitioned Tables
BecausetheCOMPUTE STATS statementcanberesource-intensivetorunonapartitioned tableasnewpartitions are
added,Impalaincludesavariationofthisstatementthatallowscomputing statisticsonaper-partition basissuchthat
statscanbeincrementallyupdatedwhennewpartitions areadded.
ApacheImpalaGuide|631Partitioning forImpalaTables
Important:
Foraparticular table,useeitherCOMPUTE STATS orCOMPUTE INCREMENTAL STATS .Thetwokinds
ofstatsdonotinteroperatewitheachotheratthetablelevel.Withoutdroppingthestats,ifyourun
COMPUTE INCREMENTAL STATS itwilloverwritethefullcomputestatsorifyourunCOMPUTE STATS
itwilldropallincrementalstatsforconsistency.
WhenyourunCOMPUTE INCREMENTAL STATS onatableforthefirsttime,thestatisticsarecomputed
againfromscratchregardlessofwhetherthetablealreadyhasstatistics.Therefore,expectaone-time
resource-intensiveoperationforscanningtheentiretablewhenrunningCOMPUTE INCREMENTAL
STATSforthefirsttimeonagiventable.
InImpala3.0andlower,approximately400bytesofmetadatapercolumnperpartition areneeded
forcaching.Tableswithabignumberofpartitions andmanycolumnscanadduptoasignificant
memoryoverheadasthemetadatamustbecachedonthecatalogd hostandoneveryimpalad
hostthatiseligibletobeacoordinator.Ifthismetadataforalltablesexceeds2GB,youmight
experience servicedowntime.InImpala3.1andhigher,theissuewasalleviatedwithanimproved
handlingofincrementalstats.
TheCOMPUTE INCREMENTAL STATS variationcomputesstatisticsonlyforpartitions thatwereaddedorchanged
sincethelastCOMPUTE INCREMENTAL STATS statement,ratherthantheentiretable.Itistypicallyusedfortables
whereafullCOMPUTE STATS operationtakestoolongtobepracticaleachtimeapartition isaddedordropped.See
GeneratingTableandColumnStatisticsonpage578forfullusagedetails.
-- Initially the table has no incremental stats, as indicated
-- 'false' under Incremental stats.
show table stats item_partitioned;
+-------------+-------+--------+----------+--------------+---------+------------------
| i_category  | #Rows | #Files | Size     | Bytes Cached | Format  | Incremental stats
+-------------+-------+--------+----------+--------------+---------+------------------
| Books       | -1    | 1      | 223.74KB | NOT CACHED   | PARQUET | false
| Children    | -1    | 1      | 230.05KB | NOT CACHED   | PARQUET | false
| Electronics | -1    | 1      | 232.67KB | NOT CACHED   | PARQUET | false
| Home        | -1    | 1      | 232.56KB | NOT CACHED   | PARQUET | false
| Jewelry     | -1    | 1      | 223.72KB | NOT CACHED   | PARQUET | false
| Men         | -1    | 1      | 231.25KB | NOT CACHED   | PARQUET | false
| Music       | -1    | 1      | 237.90KB | NOT CACHED   | PARQUET | false
| Shoes       | -1    | 1      | 234.90KB | NOT CACHED   | PARQUET | false
| Sports      | -1    | 1      | 227.97KB | NOT CACHED   | PARQUET | false
| Women       | -1    | 1      | 226.27KB | NOT CACHED   | PARQUET | false
| Total       | -1    | 10     | 2.25MB   | 0B           |         |
+-------------+-------+--------+----------+--------------+---------+------------------
-- After the first COMPUTE INCREMENTAL STATS,
-- all partitions have stats. The first
-- COMPUTE INCREMENTAL STATS scans the whole
-- table, discarding any previous stats from
-- a traditional COMPUTE STATS statement.
compute incremental stats item_partitioned;
+-------------------------------------------+
| summary                                   |
+-------------------------------------------+
| Updated 10 partition(s) and 21 column(s). |
+-------------------------------------------+
show table stats item_partitioned;
+-------------+-------+--------+----------+--------------+---------+------------------
| i_category  | #Rows | #Files | Size     | Bytes Cached | Format  | Incremental stats
+-------------+-------+--------+----------+--------------+---------+------------------
| Books       | 1733  | 1      | 223.74KB | NOT CACHED   | PARQUET | true
| Children    | 1786  | 1      | 230.05KB | NOT CACHED   | PARQUET | true
| Electronics | 1812  | 1      | 232.67KB | NOT CACHED   | PARQUET | true
| Home        | 1807  | 1      | 232.56KB | NOT CACHED   | PARQUET | true
| Jewelry     | 1740  | 1      | 223.72KB | NOT CACHED   | PARQUET | true
| Men         | 1811  | 1      | 231.25KB | NOT CACHED   | PARQUET | true
| Music       | 1860  | 1      | 237.90KB | NOT CACHED   | PARQUET | true
| Shoes       | 1835  | 1      | 234.90KB | NOT CACHED   | PARQUET | true
632|ApacheImpalaGuidePartitioning forImpalaTables
| Sports      | 1783  | 1      | 227.97KB | NOT CACHED   | PARQUET | true
| Women       | 1790  | 1      | 226.27KB | NOT CACHED   | PARQUET | true
| Total       | 17957 | 10     | 2.25MB   | 0B           |         |
+-------------+-------+--------+----------+--------------+---------+------------------
-- Add a new partition...
alter table item_partitioned add partition (i_category='Camping');
-- Add or replace files in HDFS outside of Impala,
-- rendering the stats for a partition obsolete.
!import_data_into_sports_partition.sh
refresh item_partitioned;
drop incremental stats item_partitioned partition (i_category='Sports');
-- Now some partitions have incremental stats
-- and some do not.
show table stats item_partitioned;
+-------------+-------+--------+----------+--------------+---------+------------------
| i_category  | #Rows | #Files | Size     | Bytes Cached | Format  | Incremental stats
+-------------+-------+--------+----------+--------------+---------+------------------
| Books       | 1733  | 1      | 223.74KB | NOT CACHED   | PARQUET | true
| Camping     | -1    | 1      | 408.02KB | NOT CACHED   | PARQUET | false
| Children    | 1786  | 1      | 230.05KB | NOT CACHED   | PARQUET | true
| Electronics | 1812  | 1      | 232.67KB | NOT CACHED   | PARQUET | true
| Home        | 1807  | 1      | 232.56KB | NOT CACHED   | PARQUET | true
| Jewelry     | 1740  | 1      | 223.72KB | NOT CACHED   | PARQUET | true
| Men         | 1811  | 1      | 231.25KB | NOT CACHED   | PARQUET | true
| Music       | 1860  | 1      | 237.90KB | NOT CACHED   | PARQUET | true
| Shoes       | 1835  | 1      | 234.90KB | NOT CACHED   | PARQUET | true
| Sports      | -1    | 1      | 227.97KB | NOT CACHED   | PARQUET | false
| Women       | 1790  | 1      | 226.27KB | NOT CACHED   | PARQUET | true
| Total       | 17957 | 11     | 2.65MB   | 0B           |         |
+-------------+-------+--------+----------+--------------+---------+------------------
-- After another COMPUTE INCREMENTAL STATS,
-- all partitions have incremental stats, and only the 2
-- partitions without incremental stats were scanned.
compute incremental stats item_partitioned;
+------------------------------------------+
| summary                                  |
+------------------------------------------+
| Updated 2 partition(s) and 21 column(s). |
+------------------------------------------+
show table stats item_partitioned;
+-------------+-------+--------+----------+--------------+---------+------------------
| i_category  | #Rows | #Files | Size     | Bytes Cached | Format  | Incremental stats
+-------------+-------+--------+----------+--------------+---------+------------------
| Books       | 1733  | 1      | 223.74KB | NOT CACHED   | PARQUET | true
| Camping     | 5328  | 1      | 408.02KB | NOT CACHED   | PARQUET | true
| Children    | 1786  | 1      | 230.05KB | NOT CACHED   | PARQUET | true
| Electronics | 1812  | 1      | 232.67KB | NOT CACHED   | PARQUET | true
| Home        | 1807  | 1      | 232.56KB | NOT CACHED   | PARQUET | true
| Jewelry     | 1740  | 1      | 223.72KB | NOT CACHED   | PARQUET | true
| Men         | 1811  | 1      | 231.25KB | NOT CACHED   | PARQUET | true
| Music       | 1860  | 1      | 237.90KB | NOT CACHED   | PARQUET | true
| Shoes       | 1835  | 1      | 234.90KB | NOT CACHED   | PARQUET | true
| Sports      | 1783  | 1      | 227.97KB | NOT CACHED   | PARQUET | true
| Women       | 1790  | 1      | 226.27KB | NOT CACHED   | PARQUET | true
| Total       | 17957 | 11     | 2.65MB   | 0B           |         |
+-------------+-------+--------+----------+--------------+---------+------------------
ApacheImpalaGuide|633Partitioning forImpalaTables
HowImpalaWorkswithHadoopFileFormats
Impalasupports severalfamiliarfileformatsusedinApacheHadoop.Impalacanloadandquerydatafilesproduced
byotherHadoopcomponen tssuchasSpark,anddatafilesproducedbyImpalacanbeusedbyothercomponen tsalso.
Thefollowingsectionsdiscusstheprocedures,limitations,andperformance considerationsforusingeachfileformat
withImpala.
ThefileformatusedforanImpalatablehassignificantperformance consequences. Somefileformatsinclude
compressionsupportthataffectsthesizeofdataonthediskand,consequen tly,theamountofI/OandCPUresources
requiredtodeserializedata.TheamountsofI/OandCPUresourcesrequiredcanbealimitingfactorinqueryperformance
sincequeryingoftenbeginswithmovinganddecompressingdata.Toreducethepotentialimpactofthispartofthe
process,dataisoftencompressed.Bycompressingdata,asmallertotalnumberofbytesaretransferredfromdiskto
memory.Thisreducestheamountoftimetakentotransferthedata,butatradeoffoccurswhentheCPUdecompresses
thecontent.
ForthefileformatsthatImpalacannotwriteto,createthetablefromwithinImpalawheneverpossibleandinsertdata
usinganothercomponen tsuchasHiveorSpark.Seethetablebelowforspecificfileformats.
ThefollowingtableliststhefileformatsthatImpalasupports.
ImpalaCanINSERT? ImpalaCanCREATE? CompressionCodecs Format FileType
Yes:CREATE TABLE ,INSERT,
LOAD DATA ,andquery.Yes. Snappy,gzip,zstd;
currentlySnappyby
defaultStructured Parquet
No.ImportdatabyusingLOAD
DATAondatafilesalreadyintheTheORCsupportisan
experimen talfeaturesinceCDH
6.1/Impala3.1&Impala2.12.gzip,Snappy,LZO,LZ4;
currentlygzipby
defaultStructured ORC
rightformat,oruseINSERTin
HivefollowedbyREFRESH
table_name inImpala.Todisableit,set
--enable_orc_scanner to
falsewhenstartingthecluster.
Yesifuncompressed.
Noifcompressed.Yes.ForCREATE TABLE withno
STORED AS clause,thedefaultfile
formatisuncompressedtext,withLZO,gzip,bzip2,
SnappyUnstructured Text
valuesseparatedbyASCII0x01IfLZOcompressionisused,you
mustcreatethetableandload
datainHive.characters(typicallyrepresented
asCtrl-A).
Ifotherkindsofcompressionare
used,youmustloaddatathrough
LOAD DATA ,Hive,ormanually in
HDFS.
No.ImportdatabyusingLOAD
DATAondatafilesalreadyintheYes,inImpala1.4.0andhigher.In
lowerversions,createthetable
usingHive.Snappy,gzip,deflate Structured Avro
rightformat,oruseINSERTin
HivefollowedbyREFRESH
table_name inImpala.
No.ImportdatabyusingLOAD
DATAondatafilesalreadyintheYes. Snappy,gzip,deflate,
bzip2Structured RCFile
rightformat,oruseINSERTin
HivefollowedbyREFRESH
table_name inImpala.
634|ApacheImpalaGuideHowImpalaWorkswithHadoopFileFormats
ImpalaCanINSERT? ImpalaCanCREATE? CompressionCodecs Format FileType
No.ImportdatabyusingLOAD
DATAondatafilesalreadyintheYes. Snappy,gzip,deflate,
bzip2Structured SequenceFile
rightformat,oruseINSERTin
HivefollowedbyREFRESH
table_name inImpala.
Impalasupports thefollowingcompressioncodecs:
Snappy
Recommended foritseffectivebalancebetweencompressionratioanddecompressionspeed.Snappycompression
isveryfast,butgzipprovidesgreaterspacesavings.Supportedfortext,RC,Sequence, andAvrofilesinImpala2.0
andhigher.
Gzip
Recommended whenachievingthehighestlevelofcompression(andthereforegreatestdisk-space savings)is
desired.Supportedfortext,RC,Sequence andAvrofilesinImpala2.0andhigher.
Deflate
Notsupportedfortextfiles.
Bzip2
Supportedfortext,RC,andSequence filesinImpala2.0andhigher.
LZO
Fortextfilesonly.ImpalacanqueryLZO-compressedtexttables,butcurrentlycannotcreatethemorinsertdata
intothem.YouneedtoperformtheseoperationsinHive.
Zstd
ForParquetfilesonly.
Choosing theFileFormatforaTable
Differentfileformatsandcompressioncodecsworkbetterfordifferentdatasets.Choosing theproperformatforyour
datacanyieldperformance improvements.Usethefollowingconsiderationstodecidewhichcombinationoffileformat
andcompressiontouseforaparticular table:
â¢Ifyouareworkingwithexistingfilesthatarealreadyinasupportedfileformat,usethesameformatfortheImpala
tableifperformance isacceptable.Iftheoriginalformatdoesnotyieldacceptablequeryperformance orresource
usage,considercreatinganewImpalatablewithdifferentfileformatorcompressioncharacteristics,anddoing
aone-time conversionbyrewritingthedatatothenewtable.
â¢Textfilesareconvenienttoproducethroughmanydifferenttools,andarehuman-readableforeaseofverification
anddebugging.ThosecharacteristicsarewhytextisthedefaultformatforanImpalaCREATE TABLE statement.
However,whenperformance andresourceusagearetheprimaryconsiderations,useoneofthestructuredfile
formatsthatincludemetadataandbuilt-incompression.
AtypicalworkflowmightinvolvebringingdataintoanImpalatablebycopyingCSVorTSVfilesintotheappropriate
datadirectory,andthenusingtheINSERT ... SELECT syntaxtorewritethedataintoatableusingadifferent,
morecompactfileformat.
ApacheImpalaGuide|635HowImpalaWorkswithHadoopFileFormats
UsingTextDataFileswithImpalaTables
Impalasupports usingtextfilesasthestorageformatforinputandoutput.Textfilesareaconvenientformattouse
forinterchangewithotherapplicationsorscriptsthatproduceorreaddelimitedtextfiles,suchasCSVorTSVwith
commasortabsfordelimiters.
Textfilesarealsoveryflexibleintheircolumndefinitions. Forexample,atextfilecouldhavemorefieldsthanthe
Impalatable,andthoseextrafieldsareignoredduringqueries;oritcouldhavefewerfieldsthantheImpalatable,and
thosemissingfieldsaretreatedasNULLvaluesinqueries.Youcouldhavefieldsthatweretreatedasnumbersor
timestampsinatable,thenuseALTER TABLE ... REPLACE COLUMNS toswitchthemtostrings,orthereverse.
Table2:TextFormatSupportinImpala
ImpalaCanINSERT? ImpalaCanCREATE? CompressionCodecs Format FileType
Yesifuncompressed.
Noifcompressed.Yes.ForCREATE TABLE withno
STORED AS clause,thedefaultfile
formatisuncompressedtext,withLZO,gzip,bzip2,
SnappyUnstructured Text
valuesseparatedbyASCII0x01IfLZOcompressionisused,you
mustcreatethetableandload
datainHive.characters(typicallyrepresented
asCtrl-A).
Ifotherkindsofcompressionare
used,youmustloaddatathrough
LOAD DATA ,Hive,ormanually in
HDFS.
QueryPerformance forImpalaTextTables
Datastoredintextformatisrelativelybulky,andnotasefficienttoqueryasbinaryformatssuchasParquet.You
typicallyusetexttableswithImpalaifthatistheformatyoureceivethedataandyoudonothavecontroloverthat
process,orifyouarearelativelynewHadoopuserandnotfamiliarwithtechniques togeneratefilesinotherformats.
(BecausethedefaultformatforCREATE TABLE istext,youmightcreateyourfirstImpalatablesastextwithoutgiving
performance muchthought.)Eitherway,lookforopportunities tousemoreefficientfileformatsforthetablesused
inyourmostperformance-critic alqueries.
Forfrequentlyquerieddata,youmightloadtheoriginaltextdatafilesintooneImpalatable,thenuseanINSERT
statementtotransferthedatatoanothertablethatusestheParquetfileformat;thedataisconvertedautomatically
asitisstoredinthedestinationtable.
Formorecompactdata,considerusingLZOcompressionforthetextfiles.LZOistheonlycompressioncodecthat
Impalasupports fortextdata,becausetheâsplittableânatureofLZOdatafilesletsdifferentnodesworkondifferent
partsofthesamefileinparallel.SeeUsingLZO-CompressedTextFilesonpage640fordetails.
InImpala2.0andlater,youcanalsousetextdatacompressedinthegzip,bzip2,orSnappyformats.Becausethese
compressedformatsarenotâsplittableâinthewaythatLZOis,thereislessopportunity forImpalatoparallelizequeries
onthem.Therefore,usethesetypesofcompresseddataonlyforconvenienceifthatistheformatinwhichyoureceive
thedata.PrefertouseLZOcompressionfortextdataifyouhavethechoice,orconvertthedatatoParquetusingan
INSERT ... SELECT statementtocopytheoriginaldataintoaParquettable.
Note:
Impalasupports bzipfilescreatedbythebzip2command, butnotbzipfileswithmultiplestreams
createdbythepbzip2command. Impaladecodesonlythedatafromthefirstpartofsuchfiles,
leadingtoincompleteresults.
ThemaximumsizethatImpalacanaccommodateforanindividual bzipfileis1GB(after
uncompression).
636|ApacheImpalaGuideHowImpalaWorkswithHadoopFileFormats
InCDH5.8/Impala2.6andhigher,ImpalaqueriesareoptimizedforfilesstoredinAmazonS3.ForImpalatablesthat
usethefileformatsParquet,ORC,RCFile,SequenceFile, Avro,anduncompressedtext,thesettingfs.s3a.block.size
inthecore-site.xml configurationfiledetermineshowImpaladividestheI/Oworkofreadingthedatafiles.This
configurationsettingisspecified inbytes.Bydefault,thisvalueis33554432 (32MB),meaningthatImpalaparallelizes
S3readoperationsonthefilesasiftheyweremadeupof32MBblocks.Forexample,ifyourS3queriesprimarily
accessParquetfileswrittenbyMapReduceorHive,increasefs.s3a.block.size to134217728 (128MB)tomatch
therowgroupsizeofthosefiles.IfmostS3queriesinvolveParquetfileswrittenbyImpala,increase
fs.s3a.block.size to268435456 (256MB)tomatchtherowgroupsizeproducedbyImpala.
CreatingTextTables
Tocreateatableusingtextdatafiles:
Iftheexactformatofthetextdatafiles(suchasthedelimitercharacter)isnotsignificant,usetheCREATE TABLE
statementwithnoextraclausesattheendtocreateatext-formattable.Forexample:
create table my_table(id int, s string, n int, t timestamp, b boolean);
ThedatafilescreatedbyanyINSERTstatementswillusetheCtrl-Acharacter(hex01)asaseparatorbetweeneach
columnvalue.
AcommonusecaseistoimportexistingtextfilesintoanImpalatable.Thesyntaxismoreverbose;thesignificantpart
istheFIELDS TERMINATED BY clause,whichmustbeprecededbytheROW FORMAT DELIMITED clause.Thestatement
canendwithaSTORED AS TEXTFILE clause,butthatclauseisoptionalbecausetextformattablesarethedefault.
Forexample:
create table csv(id int, s string, n int, t timestamp, b boolean)
  row format delimited
fields terminated by ',';
create table tsv(id int, s string, n int, t timestamp, b boolean)
  row format delimited
fields terminated by '\t';
create table pipe_separated(id int, s string, n int, t timestamp, b boolean)
  row format delimited
fields terminated by '|'
  stored as textfile;
YoucancreatetableswithspecificseparatorcharacterstoimporttextfilesinfamiliarformatssuchasCSV,TSV,or
pipe-separ ated.Youcanalsousethesetablestoproduceoutputdatafiles,bycopyingdataintothemthroughthe
INSERT ... SELECT syntaxandthenextractingthedatafilesfromtheImpaladatadirectory.
InImpala1.3.1andhigher,youcanspecifyadelimitercharacter'\0'tousetheASCII0(nul)characterfortexttables:
create table nul_separated(id int, s string, n int, t timestamp, b boolean)
  row format delimited
  fields terminated by '\0'
  stored as textfile;
Note:
Donotsurroundstringvalueswithquotationmarksintextdatafilesthatyouconstruct.Ifyouneed
toincludetheseparatorcharacterinsideafieldvalue,forexampletoputastringvaluewithacomma
insideaCSV-formatdatafile,specifyanescapecharacterontheCREATE TABLE statementwiththe
ESCAPED BY clause,andinsertthatcharacterimmediatelybeforeanyseparatorcharactersthatneed
escaping.
IssueaDESCRIBE FORMATTED table_name statementtoseethedetailsofhoweachtableisrepresentedinternally
inImpala.
ApacheImpalaGuide|637HowImpalaWorkswithHadoopFileFormats
Complextypeconsiderations:Although youcancreatetablesinthisfileformatusingthecomplextypes(ARRAY,
STRUCT,andMAP)availableinCDH5.5/Impala2.3andhigher,currently,ImpalacanquerythesetypesonlyinParquet
tables.TheoneexceptiontotheprecedingruleisCOUNT(*) queriesonRCFiletablesthatincludecomplextypes.Such
queriesareallowedinCDH5.8/Impala2.6andhigher.
DataFilesforTextTables
WhenImpalaqueriesatablewithdataintextformat,itconsultsallthedatafilesinthedatadirectoryforthattable,
withsomeexceptions:
â¢Impalaignoresanyhiddenfiles,thatis,fileswhosenamesstartwithadotoranunderscore.
â¢Impalaqueriesignorefileswithextensionscommonly usedfortemporaryworkfilesbyHadooptools.Anyfiles
withextensions.tmpor.copying arenotconsideredpartoftheImpalatable.Thesuffixmatchingis
case-insensitiv e,soforexampleImpalaignoresboth.copying and.COPYING suffixes.
â¢Impalausessuffixestorecognizewhentextdatafilesarecompressedtext.ForImpalatorecognizethecompressed
textfiles,theymusthavetheappropriatefileextensioncorresponding tothecompressioncodec,either.gz,
.bz2,or.snappy .Theextensionscanbeinuppercaseorlowercase.
â¢Otherwise,thefilenamesarenotsignificant.WhenyouputfilesintoanHDFSdirectorythroughETLjobs,orpoint
ImpalatoanexistingHDFSdirectorywiththeCREATE EXTERNAL TABLE statement,ormovedatafilesunder
externalcontrolwiththeLOAD DATA statement,Impalapreservestheoriginalfilenames.
FilenamesfordataproducedthroughImpalaINSERTstatementsaregivenuniquenamestoavoidfilenameconflicts.
AnINSERT ... SELECT statementproducesonedatafilefromeachnodethatprocessestheSELECTpartofthe
statement.AnINSERT ... VALUES statementproducesaseparatedatafileforeachstatement;becauseImpalais
moreefficientqueryingasmallnumberofhugefilesthanalargenumberoftinyfiles,theINSERT ... VALUES syntax
isnotrecommended forloadingasubstantialvolumeofdata.Ifyoufindyourselfwithatablethatisinefficientdueto
toomanysmalldatafiles,reorganizethedataintoafewlargefilesbydoingINSERT ... SELECT totransferthedata
toanewtable.
Specialvalueswithintextdatafiles:
â¢ImpalarecognizestheliteralstringsinfforinfinityandnanforâNotaNumberâ,forFLOATandDOUBLEcolumns.
â¢Impalarecognizestheliteralstring\NtorepresentNULL.WhenusingSqoop,specifytheoptions
--null-non-string and--null-string toensureallNULLvaluesarerepresentedcorrectlyintheSqoop
outputfiles.\Nneedstobeescapedasinthebelowexample:
--null-string '\\N' --null-non-string '\\N'
â¢Bydefault,SqoopwritesNULLvaluesusingthestringnull,whichcausesaconversionerrorwhensuchrowsare
evaluatedbyImpala.Aworkaroundforexistingtablesanddatafilesistochangethetablepropertiesthrough
ALTER TABLE name SET TBLPROPERTIES("serialization.null.format"="null") .
â¢InCDH5.8/Impala2.6andhigher,Impalacanoptionallyskipanarbitrarynumberofheaderlinesfromtextinput
filesonHDFSbasedontheskip.header.line.count valueintheTBLPROPERTIES fieldofthetablemetadata.
Forexample:
create table header_line(first_name string, age int)
  row format delimited fields terminated by ',';
-- Back in the shell, load data into the table with commands such as:
-- cat >data.csv
-- Name,Age
-- Alice,25
-- Bob,19
-- hdfs dfs -put data.csv /user/hive/warehouse/header_line
refresh header_line;
-- Initially, the Name,Age header line is treated as a row of the table.
638|ApacheImpalaGuideHowImpalaWorkswithHadoopFileFormats
select * from header_line limit 10;
+------------+------+
| first_name | age  |
+------------+------+
| Name       | NULL |
| Alice      | 25   |
| Bob        | 19   |
+------------+------+
alter table header_line set tblproperties('skip.header.line.count'='1');
-- Once the table property is set, queries skip the specified number of lines
-- at the beginning of each text data file. Therefore, all the files in the table
-- should follow the same convention for header lines.
select * from header_line limit 10;
+------------+-----+
| first_name | age |
+------------+-----+
| Alice      | 25  |
| Bob        | 19  |
+------------+-----+
LoadingDataintoImpalaTextTables
ToloadanexistingtextfileintoanImpalatexttable,usetheLOAD DATA statementandspecifythepathofthefilein
HDFS.ThatfileismovedintotheappropriateImpaladatadirectory.
ToloadmultipleexistingtextfilesintoanImpalatexttable,usetheLOAD DATA statementandspecifytheHDFSpath
ofthedirectorycontainingthefiles.Allnon-hidden filesaremovedintotheappropriateImpaladatadirectory.
ToconvertdatatotextfromanyotherfileformatsupportedbyImpala,useaSQLstatementsuchas:
-- Text table with default delimiter, the hex 01 character.
CREATE TABLE text_table AS SELECT * FROM other_file_format_table;
-- Text table with user-specified delimiter. Currently, you cannot specify
-- the delimiter as part of CREATE TABLE LIKE or CREATE TABLE AS SELECT.
-- But you can change an existing text table to have a different delimiter.
CREATE TABLE csv LIKE other_file_format_table;
ALTER TABLE csv SET SERDEPROPERTIES ('serialization.format'=',', 'field.delim'=',');
INSERT INTO csv SELECT * FROM other_file_format_table;
Thiscanbeausefultechnique toseehowImpalarepresentsspecialvalueswithinatext-formatdatafile.Usethe
DESCRIBE FORMATTED statementtoseetheHDFSdirectorywherethedatafilesarestored,thenuseLinuxcommands
suchashdfs dfs -ls hdfs_directory andhdfs dfs -cat hdfs_file todisplaythecontentsofan
Impala-cr eatedtextfile.
Tocreateafewrowsinatexttablefortestpurposes, youcanusetheINSERT ... VALUES syntax:
INSERT INTO text_table  VALUES ('string_literal',100,hex('hello world'));
Note:BecauseImpalaandtheHDFSinfrastructureareoptimizedformulti-meg abytefiles,avoidthe
INSERT ... VALUES notationwhenyouareinserting manyrows.EachINSERT ... VALUES
statementproducesanewtinyfile,leadingtofragmentationandreducedperformance. Whencreating
anysubstantialvolumeofnewdata,useoneofthebulkloadingtechniques suchasLOAD DATA or
INSERT ... SELECT .Or,useanHBasetableforsingle-rowINSERToperations,becauseHBase
tablesarenotsubjecttothesamefragmentationissuesastablesstoredonHDFS.
WhenyoucreateatextfileforusewithanImpalatexttable,specify\NtorepresentaNULLvalue.Forthedifferences
betweenNULLandemptystrings,seeNULLonpage170.
Ifatextfilehasfewerfieldsthanthecolumnsinthecorresponding Impalatable,allthecorresponding columnsare
settoNULLwhenthedatainthatfileisreadbyanImpalaquery.
ApacheImpalaGuide|639HowImpalaWorkswithHadoopFileFormats
Ifatextfilehasmorefieldsthanthecolumnsinthecorresponding Impalatable,theextrafieldsareignoredwhenthe
datainthatfileisreadbyanImpalaquery.
YoucanalsousemanualHDFSoperationssuchashdfs dfs -put orhdfs dfs -cp toputdatafilesinthedata
directoryforanImpalatable.WhenyoucopyormovenewdatafilesintotheHDFSdirectoryfortheImpalatable,issue
aREFRESH table_name statementinimpala-shell beforeissuingthenextqueryagainstthattable,tomakeImpala
recognizethenewlyaddedfiles.
UsingLZO-CompressedTextFiles
Impalasupports usingtextdatafilesthatemployLZOcompression.Clouderarecommends compressingtextdatafiles
whenpractical.ImpalaqueriesareusuallyI/O-bound; reducingtheamountofdatareadfromdisktypicallyspeedsup
aquery,despitetheextraCPUworktouncompressthedatainmemory.
ImpalacanworkwithLZO-compressedtextfiles.LZO-compressedfilesarepreferabletotextfilescompressedbyother
codecs,becauseLZO-compressedfilesareâsplittableâ,meaningthatdifferentportionsofafilecanbeuncompressed
andprocessedindependen tlybydifferentnodes.
ImpaladoesnotcurrentlysupportwritingLZO-compressedtextfiles.
BecauseImpalacanqueryLZO-compressedfilesbutcurrentlycannotwritethem,youuseHivetodotheinitialCREATE
TABLEandloadthedata,thenswitchbacktoImpalatorunqueries.Forinstructions onsettingupLZOcompression
forHiveCREATE TABLE andINSERTstatements,seetheLZOpageontheHivewiki.OnceyouhavecreatedanLZO
texttable,youcanalsomanually addLZO-compressedtextfilestoit,producedbythelzopcommand orsimilar
method.
PreparingtoUseLZO-CompressedTextFiles
BeforeusingLZO-compressedtablesinImpala,dothefollowingone-time setupforeachmachineinthecluster.Install
thenecessarypackagesusingeithertheClouderapublicrepository,aprivaterepositoryyouestablish,orbyusing
packages.Youmustdothesestepsmanually,whetherornottheclusterismanagedbytheClouderaManagerproduct.
1.PrepareyoursystemstoworkwithLZObydownloading andinstallingtheappropriatelibraries:
OnsystemsmanagedbyClouderaManagerusingparcels:
Seethesetupinstructions fortheLZOparcelintheClouderaManagerdocumen tationforClouderaManager.
2.ConfigureImpalatouseLZO:
Useoneofthefollowingsetsofcommands torefreshyourpackagemanagementsystem'srepositoryinformation,
installthebaseLZOsupportforHadoop,andinstalltheLZOsupportforImpala.
ForRHEL/Cen tOSsystems:
sudo yum update
sudo yum install hadoop-lzo
sudo yum install impala-lzo
ForSUSEsystems:
$ sudo apt-get update
$ sudo zypper install hadoop-lzo
$ sudo zypper install impala-lzo
ForDebian/Ubun tusystems:
sudo zypper update
sudo apt-get install hadoop-lzo
sudo apt-get install impala-lzo
640|ApacheImpalaGuideHowImpalaWorkswithHadoopFileFormats
Note:
Theleveloftheimpala-lzo packageiscloselytiedtotheversionofImpalayouuse.Anytime
youupgradeImpala,re-dotheinstallationcommand forimpala-lzo oneachapplicablemachine
tomakesureyouhavetheappropriateversionofthatpackage.
3.Forcore-site.xml ontheclientandserver(thatis,intheconfigurationdirectoriesforbothImpalaandHadoop),
appendcom.hadoop.compression.lzo.LzopCodec tothecomma-separ atedlistofcodecs.Forexample:
<property>
  <name>io.compression.codecs</name>
<value>org.apache.hadoop.io.compress.DefaultCodec,org.apache.hadoop.io.compress.GzipCodec,
org.apache.hadoop.io.compress.BZip2Codec,org.apache.hadoop.io.compress.DeflateCodec,
org.apache.hadoop.io.compress.SnappyCodec,com.hadoop.compression.lzo.LzopCodec</value>
</property>
Note:
IfthisisthefirsttimeyouhaveeditedtheHadoopcore-site.xml file,notethatthe
/etc/hadoop/conf directoryistypicallyasymboliclink,sothecanonicalcore-site.xml
mightresideinadifferentdirectory:
$ ls -l /etc/hadoop
total 8
lrwxrwxrwx. 1 root root   29 Feb 26  2013 conf -> 
/etc/alternatives/hadoop-conf
lrwxrwxrwx. 1 root root   10 Feb 26  2013 conf.dist -> conf.empty
drwxr-xr-x. 2 root root 4096 Feb 26  2013 conf.empty
drwxr-xr-x. 2 root root 4096 Oct 28 15:46 conf.pseudo
Iftheio.compression.codecs propertyismissingfromcore-site.xml ,onlyadd
com.hadoop.compression.lzo.LzopCodec tothenewpropertyvalue,notallthenames
fromtheprecedingexample.
4.RestarttheMapReduceandImpalaservices.
CreatingLZOCompressedTextTables
AtablecontainingLZO-compressedtextfilesmustbecreatedinHivewiththefollowingstorageclause:
STORED AS
    INPUTFORMAT 'com.hadoop.mapred.DeprecatedLzoTextInputFormat'
    OUTPUTFORMAT 'org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat'
Also,certainHivesettingsneedtobeineffect.Forexample:
hive> SET mapreduce.output.fileoutputformat.compress=true;
hive> SET hive.exec.compress.output=true;
hive> SET 
mapreduce.output.fileoutputformat.compress.codec=com.hadoop.compression.lzo.LzopCodec;
hive> CREATE TABLE lzo_t (s string) STORED AS
  > INPUTFORMAT 'com.hadoop.mapred.DeprecatedLzoTextInputFormat'
  > OUTPUTFORMAT 'org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat';
hive> INSERT INTO TABLE lzo_t SELECT col1, col2 FROM uncompressed_text_table;
OnceyouhavecreatedLZO-compressedtexttables,youcanconvertdatastoredinothertables(regardlessoffile
format)byusingtheINSERT ... SELECT statementinHive.
ApacheImpalaGuide|641HowImpalaWorkswithHadoopFileFormats
FilesinanLZO-compressedtablemustusethe.lzoextension.ExaminethefilesintheHDFSdatadirectoryafterdoing
theINSERTinHive,tomakesurethefileshavetherightextension.Iftherequiredsettingsarenotinplace,youend
upwithregularuncompressedfiles,andImpalacannotaccessthetablebecauseitfindsdatafileswiththewrong
(uncompressed)format.
AfterloadingdataintoanLZO-compressedtexttable,indexthefilessothattheycanbesplit.Youindexthefilesby
runningaJavaclass,com.hadoop.compression.lzo.DistributedLzoIndexer ,throughtheLinuxcommand
line.ThisJavaclassisincludedinthehadoop-lzo package.
Runtheindexerusingacommand likethefollowing:
$ hadoop jar /usr/lib/hadoop/lib/hadoop-lzo- version-gplextras.jar
  com.hadoop.compression.lzo.DistributedLzoIndexer /hdfs_location_of_table/
Note:IfthepathoftheJARfileintheprecedingexampleisnotrecognized,doafindcommand to
locatehadoop-lzo-*-gplextras.jar andusethatpath.
Indexedfileshavethesamenameasthefiletheyindex,withthe.indexextension.Ifthedatafilesarenotindexed,
Impalaqueriesstillwork,butthequeriesreadthedatafromremoteDataNodes,whichisveryinefficient.
OncetheLZO-compressedtablesarecreated,anddataisloadedandindexed,youcanquerythemthroughImpala.
Asalways,thefirsttimeyoustartimpala-shell aftercreatingatableinHive,issueanINVALIDATE METADATA
statementsothatImpalarecognizesthenewtable.(InImpala1.2andhigher,youonlyhavetorunINVALIDATE
METADATA ononenode,ratherthanonalltheImpalanodes.)
Usinggzip,bzip2,orSnappy-CompressedTextFiles
InImpala2.0andlater,Impalasupports usingtextdatafilesthatemploygzip,bzip2,orSnappycompression.These
compressiontypesareprimarily forconveniencewithinanexistingETLpipelineratherthanmaximumperformance.
Although itrequireslessI/Otoreadcompressedtextthantheequivalentuncompressedtext,filescompressedby
thesecodecsarenotâsplittableâandthereforecannottakefulladvantageoftheImpalaparallelquerycapability.
Aseachbzip2-orSnappy-compressedtextfileisprocessed,thenodedoingtheworkreadstheentirefileintomemory
andthendecompressesit.Therefore,thenodemusthaveenoughmemorytoholdboththecompressedand
uncompresseddatafromthetextfile.Thememoryrequiredtoholdtheuncompresseddataisdifficulttoestimatein
advance,potentiallycausingproblemsonsystemswithlowmemorylimitsorwithresourcemanagementenabled. In
Impala2.1andhigher,thismemoryoverheadisreducedforgzip-compressedtextfiles.Thegzippeddataisdecompressed
asitisread,ratherthanallatonce.
Tocreateatabletoholdgzip,bzip2,orSnappy-compressedtext,createatexttablewithnospecialcompression
options.Specifythedelimiterandescapecharacterifrequired,usingtheROW FORMAT clause.
BecauseImpalacanquerycompressedtextfilesbutcurrentlycannotwritethem,producethecompressedtextfiles
outsideImpalaandusetheLOAD DATA statement,manualHDFScommands tomovethemtotheappropriateImpala
datadirectory.(Or,youcanuseCREATE EXTERNAL TABLE andpointtheLOCATION attributeatadirectorycontaining
existingcompressedtextfiles.)
ForImpalatorecognizethecompressedtextfiles,theymusthavetheappropriatefileextensioncorresponding tothe
compressioncodec,either.gz,.bz2,or.snappy .Theextensionscanbeinuppercaseorlowercase.
Thefollowingexampleshowshowyoucancreatearegulartexttable,putdifferentkindsofcompressedand
uncompressedfilesintoit,andImpalaautomaticallyrecognizesanddecompresseseachonebasedontheirfile
extensions:
create table csv_compressed (a string, b string, c string)
  row format delimited fields terminated by ",";
insert into csv_compressed values
  ('one - uncompressed', 'two - uncompressed', 'three - uncompressed'),
  ('abc - uncompressed', 'xyz - uncompressed', '123 - uncompressed');
...make equivalent .gz, .bz2, and .snappy files and load them into same table directory...
642|ApacheImpalaGuideHowImpalaWorkswithHadoopFileFormats
select * from csv_compressed;
+--------------------+--------------------+----------------------+
| a                  | b                  | c                    |
+--------------------+--------------------+----------------------+
| one - snappy       | two - snappy       | three - snappy       |
| one - uncompressed | two - uncompressed | three - uncompressed |
| abc - uncompressed | xyz - uncompressed | 123 - uncompressed   |
| one - bz2          | two - bz2          | three - bz2          |
| abc - bz2          | xyz - bz2          | 123 - bz2            |
| one - gzip         | two - gzip         | three - gzip         |
| abc - gzip         | xyz - gzip         | 123 - gzip           |
+--------------------+--------------------+----------------------+
$ hdfs dfs -ls 
'hdfs://127.0.0.1:8020/user/hive/warehouse/file_formats.db/csv_compressed/';
...truncated for readability...
75 
hdfs://127.0.0.1:8020/user/hive/warehouse/file_formats.db/csv_compressed/csv_compressed.snappy
79 
hdfs://127.0.0.1:8020/user/hive/warehouse/file_formats.db/csv_compressed/csv_compressed_bz2.csv.bz2
80 
hdfs://127.0.0.1:8020/user/hive/warehouse/file_formats.db/csv_compressed/csv_compressed_gzip.csv.gz
116 
hdfs://127.0.0.1:8020/user/hive/warehouse/file_formats.db/csv_compressed/dd414df64d67d49b_data.0.
UsingtheParquetFileFormatwithImpalaTables
Impalaallowsyoutocreate,manage,andqueryParquettables.Parquetisacolumn-orien tedbinaryfileformatintended
tobehighlyefficientforthetypesoflarge-scalequeriesthatImpalaisbestat.Parquetisespecially goodforqueries
scanningparticular columnswithinatable,forexample,toqueryâwideâtableswithmanycolumns,ortoperform
aggregationoperationssuchasSUM()andAVG()thatneedtoprocessmostorallofthevaluesfromacolumn.Each
ParquetdatafilewrittenbyImpalacontainsthevaluesforasetofrows(referredtoastheârowgroupâ).Withinadata
file,thevaluesfromeachcolumnareorganizedsothattheyarealladjacent,enablinggoodcompressionforthevalues
fromthatcolumn.QueriesagainstaParquettablecanretrieveandanalyzethesevaluesfromanycolumnquicklyand
withminimalI/O.
SeeHowImpalaWorkswithHadoopFileFormatsonpage634forthesummaryofParquetformatsupport.
CreatingParquetTablesinImpala
TocreateatablenamedPARQUET_TABLE thatusestheParquetformat,youwoulduseacommand likethefollowing,
substitutingyourowntablename,columnnames,anddatatypes:
[impala-host:21000] > create table parquet_table_name  (x INT, y STRING) STORED AS PARQUET;
Or,toclonethecolumnnamesanddatatypesofanexistingtable:
[impala-host:21000] > create table parquet_table_name  LIKE other_table_name  STORED AS 
PARQUET;
InImpala1.4.0andhigher,youcanderivecolumndefinitionsfromarawParquetdatafile,evenwithoutanexisting
Impalatable.Forexample,youcancreateanexternaltablepointingtoanHDFSdirectory,andbasethecolumn
definitionsononeofthefilesinthatdirectory:
CREATE EXTERNAL TABLE ingest_existing_files LIKE PARQUET 
'/user/etl/destination/datafile1.dat'
  STORED AS PARQUET
  LOCATION '/user/etl/destination';
ApacheImpalaGuide|643HowImpalaWorkswithHadoopFileFormats
Or,youcanrefertoanexistingdatafileandcreateanewemptytablewithsuitablecolumndefinitions. Thenyoucan
useINSERTtocreatenewdatafilesorLOAD DATA totransferexistingdatafilesintothenewtable.
CREATE TABLE columns_from_data_file LIKE PARQUET '/user/etl/destination/datafile1.dat'
  STORED AS PARQUET;
ThedefaultpropertiesofthenewlycreatedtablearethesameasforanyotherCREATE TABLE statement.Forexample,
thedefaultfileformatistext;ifyouwantthenewtabletousetheParquetfileformat,includetheSTORED AS PARQUET
filealso.
Inthisexample,thenewtableispartitioned byyear,month,andday.Thesepartition keycolumnsarenotpartofthe
datafile,soyouspecifythemintheCREATE TABLE statement:
CREATE TABLE columns_from_data_file LIKE PARQUET '/user/etl/destination/datafile1.dat'
  PARTITION (year INT, month TINYINT, day TINYINT)
  STORED AS PARQUET;
SeeCREATETABLEStatementonpage234formoredetailsabouttheCREATE TABLE LIKE PARQUET syntax.
Onceyouhavecreatedatable,toinsertdataintothattable,useacommand similartothefollowing,againwithyour
owntablenames:
[impala-host:21000] > insert overwrite table parquet_table_name  select * from 
other_table_name ;
IftheParquettablehasadifferentnumberofcolumnsordifferentcolumnnamesthantheothertable,specifythe
namesofcolumnsfromtheothertableratherthan*intheSELECTstatement.
LoadingDataintoParquetTables
Choosefromthefollowingtechniques forloadingdataintoParquettables,depending onwhethertheoriginaldatais
alreadyinanImpalatable,orexistsasrawdatafilesoutsideImpala.
IfyoualreadyhavedatainanImpalaorHivetable,perhapsinadifferentfileformatorpartitioning scheme,youcan
transferthedatatoaParquettableusingtheImpalaINSERT...SELECT syntax.Youcanconvert,filter,repartition,
anddootherthingstothedataaspartofthissameINSERTstatement.SeeCompressionsforParquetDataFileson
page647forsomeexamplesshowinghowtoinsertdataintoParquettables.
Wheninserting intopartitioned tables,especially usingtheParquetfileformat,youcanincludeahintintheINSERT
statementtofine-tune theoverallperformance oftheoperationanditsresourceusage.SeeOptimizerHintsinImpala
forusinghintsintheINSERTstatements.
AnyINSERTstatementforaParquettablerequiresenoughfreespaceintheHDFSfilesystemtowriteoneblock.
BecauseParquetdatafilesuseablocksizeof1GBbydefault,anINSERTmightfail(evenforaverysmallamountof
data)ifyourHDFSisrunninglowonspace.
AvoidtheINSERT...VALUES syntaxforParquettables,becauseINSERT...VALUES producesaseparatetinydata
fileforeachINSERT...VALUES statement,andthestrengthofParquetisinitshandlingofdata(compressing,
parallelizing,andsoon)inlargechunks.
IfyouhaveoneormoreParquetdatafilesproducedoutsideofImpala,youcanquicklymakethedataqueryable
throughImpalabyoneofthefollowingmethods:
â¢TheLOAD DATA statementmovesasingledatafileoradirectoryfullofdatafilesintothedatadirectoryforan
Impalatable.Itdoesnovalidationorconversionofthedata.TheoriginaldatafilesmustbesomewhereinHDFS,
notthelocalfilesystem.
â¢TheCREATE TABLE statementwiththeLOCATION clausecreatesatablewherethedatacontinuestoreside
outsidetheImpaladatadirectory.TheoriginaldatafilesmustbesomewhereinHDFS,notthelocalfilesystem.
Forextrasafety,ifthedataisintendedtobelong-livedandreusedbyotherapplications,youcanusetheCREATE
EXTERNAL TABLE syntaxsothatthedatafilesarenotdeletedbyanImpalaDROP TABLE statement.
â¢IftheParquettablealreadyexists,youcancopyParquetdatafilesdirectlyintoit,thenusetheREFRESH statement
tomakeImpalarecognizethenewlyaddeddata.Remember topreservetheblocksizeoftheParquetdatafiles
644|ApacheImpalaGuideHowImpalaWorkswithHadoopFileFormats
byusingthehadoop distcp -pb command ratherthana-putor-cpoperationontheParquetfiles.See
ExampleofCopyingParquetDataFilesonpage648foranexampleofthiskindofoperation.
Note:
Currently,ImpalaalwaysdecodesthecolumndatainParquetfilesbasedontheordinalpositionof
thecolumns,notbylookingupthepositionofeachcolumnbasedonitsname.Parquetfilesproduced
outsideofImpalamustwritecolumndatainthesameorderasthecolumnsaredeclaredintheImpala
table.Anyoptionalcolumnsthatareomittedfromthedatafilesmustbetherightmostcolumnsin
theImpalatabledefinition.
IfyoucreatedcompressedParquetfilesthroughsometoolotherthanImpala,makesurethatany
compressioncodecsaresupportedinParquetbyImpala.Forexample,Impaladoesnotcurrently
supportLZOcompressioninParquetfiles.Alsodoublecheck thatyouusedanyrecommended
compatibilitysettingsintheothertool,suchasspark.sql.parquet.binaryAsString when
writingParquetfilesthroughSpark.
RecentversionsofSqoopcanproduceParquetoutputfilesusingthe--as-parquetfile option.
IfthedataexistsoutsideImpalaandisinsomeotherformat,combinebothoftheprecedingtechniques. First,usea
LOAD DATA orCREATE EXTERNAL TABLE ... LOCATION statementtobringthedataintoanImpalatablethat
usestheappropriatefileformat.Then,useanINSERT...SELECT statementtocopythedatatotheParquettable,
convertingtoParquetformataspartoftheprocess.
LoadingdataintoParquettablesisamemory-intensiveoperation,becausetheincomingdataisbuffereduntilitreaches
onedatablockinsize,thenthatchunkofdataisorganizedandcompressedinmemorybeforebeingwrittenout.The
memoryconsumptioncanbelargerwheninserting dataintopartitioned Parquettables,becauseaseparatedatafile
iswrittenforeachcombinationofpartition keycolumnvalues,potentiallyrequiringseverallargechunkstobe
manipula tedinmemoryatonce.
Wheninserting intoapartitioned Parquettable,Impalaredistributesthedataamongthenodestoreducememory
consumption.YoumightstillneedtotemporarilyincreasethememorydedicatedtoImpaladuringtheinsertoperation,
orbreakuptheloadoperationintoseveralINSERTstatements,orboth.
Note:Alltheprecedingtechniques assumethatthedatayouareloadingmatchesthestructureof
thedestinationtable,including columnorder,columnnames,andpartition layout.Totransformor
reorganizethedata,startbyloadingthedataintoaParquettablethatmatchestheunderlying structure
ofthedata,thenuseoneofthetable-copyingtechniques suchasCREATE TABLE AS SELECT or
INSERT ... SELECT toreorderorrenamecolumns,dividethedataamongmultiplepartitions, and
soon.ForexampletotakeasinglecomprehensiveParquetdatafileandloaditintoapartitioned
table,youwoulduseanINSERT ... SELECT statementwithdynamicpartitioning toletImpala
createseparatedatafileswiththeappropriatepartitionvalues;foranexample,seeINSERTStatement
onpage277.
QueryPerformance forImpalaParquetTables
Queryperformance forParquettablesdependsonthenumberofcolumnsneededtoprocesstheSELECTlistand
WHEREclausesofthequery,thewaydataisdividedintolargedatafileswithblocksizeequaltofilesize,thereduction
inI/Obyreadingthedataforeachcolumnincompressedformat,whichdatafilescanbeskipped(forpartitioned
tables),andtheCPUoverheadofdecompressingthedataforeachcolumn.
Forexample,thefollowingisanefficientqueryforaParquettable:
select avg(income) from census_data where state = 'CA';
Thequeryprocessesonly2columnsoutofalargenumberoftotalcolumns.Ifthetableispartitioned bytheSTATE
column,itisevenmoreefficientbecausethequeryonlyhastoreadanddecode1columnfromeachdatafile,andit
ApacheImpalaGuide|645HowImpalaWorkswithHadoopFileFormats
canreadonlythedatafilesinthepartition directoryforthestate'CA',skippingthedatafilesforalltheotherstates,
whichwillbephysicallylocatedinotherdirectories.
ThefollowingisarelativelyinefficientqueryforaParquettable:
select * from census_data;
Impalawouldhavetoreadtheentirecontentsofeachlargedatafile,anddecompressthecontentsofeachcolumn
foreachrowgroup,negatingtheI/Ooptimizationsofthecolumn-orien tedformat.Thisquerymightstillbefasterfor
aParquettablethanatablewithsomeotherfileformat,butitdoesnottakeadvantageoftheuniquestrengthsof
Parquetdatafiles.
ImpalacanoptimizequeriesonParquettables,especially joinqueries,betterwhenstatisticsareavailableforallthe
tables.IssuetheCOMPUTE STATS statementforeachtableaftersubstantialamountsofdataareloadedintoor
appended toit.SeeCOMPUTE STATSStatementonpage219fordetails.
Theruntimefilteringfeature,availableinCDH5.7/Impala2.5andhigher,worksbestwithParquettables.Theper-row
filteringaspectonlyappliestoParquettables.SeeRuntimeFilteringforImpalaQueries(CDH5.7orhigheronly)on
page588fordetails.
InCDH5.8/Impala2.6andhigher,ImpalaqueriesareoptimizedforfilesstoredinAmazonS3.ForImpalatablesthat
usethefileformatsParquet,ORC,RCFile,SequenceFile, Avro,anduncompressedtext,thesettingfs.s3a.block.size
inthecore-site.xml configurationfiledetermineshowImpaladividestheI/Oworkofreadingthedatafiles.This
configurationsettingisspecified inbytes.Bydefault,thisvalueis33554432 (32MB),meaningthatImpalaparallelizes
S3readoperationsonthefilesasiftheyweremadeupof32MBblocks.Forexample,ifyourS3queriesprimarily
accessParquetfileswrittenbyMapReduceorHive,increasefs.s3a.block.size to134217728 (128MB)tomatch
therowgroupsizeofthosefiles.IfmostS3queriesinvolveParquetfileswrittenbyImpala,increase
fs.s3a.block.size to268435456 (256MB)tomatchtherowgroupsizeproducedbyImpala.
InCDH5.12andhigher,ParquetfileswrittenbyImpalaincludeembedded metadataspecifyingtheminimum and
maximumvaluesforeachcolumn,withineachrowgroupandeachdatapagewithintherowgroup.Impala-writ ten
Parquetfilestypicallycontainasinglerowgroup;arowgroupcancontainmanydatapages.Impalausesthisinformation
(currently,onlythemetadataforeachrowgroup)whenreadingeachParquetdatafileduringaquery,toquickly
determinewhethereachrowgroupwithinthefilepotentiallyincludesanyrowsthatmatchtheconditions intheWHERE
clause.Forexample,ifthecolumnXwithinaparticular Parquetfilehasaminimum valueof1andamaximumvalue
of100,thenaqueryincluding theclauseWHERE x > 200 canquicklydeterminethatitissafetoskipthatparticular
file,insteadofscanningalltheassociatedcolumnvalues.Thisoptimizationtechnique isespecially effectivefortables
thatusetheSORT BY clauseforthecolumnsmostfrequentlycheckedinWHEREclauses,becauseanyINSERToperation
onsuchtablesproducesParquetdatafileswithrelativelynarrowrangesofcolumnvalueswithineachfile.
Partitioning forParquetTables
AsexplainedinPartitioning forImpalaTablesonpage625,partitioning isanimportantperformance technique for
Impalagenerally.Thissectionexplainssomeoftheperformance considerationsforpartitioned Parquettables.
TheParquetfileformatisidealfortablescontainingmanycolumns,wheremostqueriesonlyrefertoasmallsubset
ofthecolumns.AsexplainedinHowParquetDataFilesAreOrganizedonpage652,thephysicallayoutofParquetdata
filesletsImpalareadonlyasmallfractionofthedataformanyqueries.Theperformance benefitsofthisapproachare
amplified whenyouuseParquettablesincombinationwithpartitioning. Impalacanskipthedatafilesforcertain
partitions entirely,basedonthecomparisons intheWHEREclausethatrefertothepartitionkeycolumns.Forexample,
queriesonpartitioned tablesoftenanalyzedatafortimeintervalsbasedoncolumnssuchasYEAR,MONTH,and/or
DAY,orforgeographicregions.Remember thatParquetdatafilesusealargeblocksize,sowhendecidinghowfinely
topartition thedata,trytofindagranularity whereeachpartition contains256MBormoreofdata,ratherthan
creatingalargenumberofsmallerfilessplitamongmanypartitions.
Inserting intoapartitioned Parquettablecanbearesource-intensiveoperation,becauseeachImpalanodecould
potentiallybewritingaseparatedatafiletoHDFSforeachcombinationofdifferentvaluesforthepartitionkeycolumns.
ThelargenumberofsimultaneousopenfilescouldexceedtheHDFSâtransceiversâlimit.Toavoidexceedingthislimit,
considerthefollowingtechniques:
646|ApacheImpalaGuideHowImpalaWorkswithHadoopFileFormats
â¢LoaddifferentsubsetsofdatausingseparateINSERTstatementswithspecificvaluesforthePARTITION clause,
suchasPARTITION (year=2010) .
â¢IncreasetheâtransceiversâvalueforHDFS,sometimesspelledâxcieversâ(sic).Thepropertyvalueinthe
hdfs-site.xml configurationfileisdfs.datanode.max.transfer.threads .Forexample,ifyouwereloading
12yearsofdatapartitioned byyear,month,andday,evenavalueof4096mightnotbehighenough.Thisblog
postexplorestheconsiderationsforsettingthisvaluehigherorlower,usingHBaseexamplesforillustration.
â¢UsetheCOMPUTE STATS statementtocollectcolumnstatisticsonthesourcetablefromwhichdataisbeing
copied,sothattheImpalaquerycanestimatethenumberofdifferentvaluesinthepartition keycolumnsand
distributetheworkaccordingly.
CompressionsforParquetDataFiles
WhenImpalawritesParquetdatafilesusingtheINSERTstatement,theunderlying compressioniscontrolledbythe
COMPRESSION_CODEC queryoption.(PriortoImpala2.0,thequeryoptionnamewasPARQUET_COMPRESSION_CODEC .)
Theallowedvaluesforthisqueryoptionaresnappy(thedefault),gzip,zstd,andnone.Theoptionvalueisnot
case-sensitiv e.Iftheoptionissettoanunrecognizedvalue,allkindsofquerieswillfailduetotheinvalidoptionsetting,
notjustqueriesinvolvingParquettables.
ExampleofParquetTablewithSnappyCompression
Bydefault,theunderlying datafilesforaParquettablearecompressedwithSnappy.Thecombinationoffastcompression
anddecompressionmakesitagoodchoiceformanydatasets.ToensureSnappycompressionisused,forexample
afterexperimen tingwithothercompressioncodecs,settheCOMPRESSION_CODEC queryoptiontosnappybefore
inserting thedata:
[localhost:21000] > create database parquet_compression;
[localhost:21000] > use parquet_compression;
[localhost:21000] > create table parquet_snappy like raw_text_data;
[localhost:21000] > set COMPRESSION_CODEC=snappy;
[localhost:21000] > insert into parquet_snappy select * from raw_text_data;
Inserted 1000000000 rows in 181.98s
ExampleofParquetTablewithGZipCompression
Ifyouneedmoreintensivecompression(attheexpenseofmoreCPUcyclesforuncompressingduringqueries), set
theCOMPRESSION_CODEC queryoptiontogzipbeforeinserting thedata:
[localhost:21000] > create table parquet_gzip like raw_text_data;
[localhost:21000] > set COMPRESSION_CODEC=gzip;
[localhost:21000] > insert into parquet_gzip select * from raw_text_data;
Inserted 1000000000 rows in 1418.24s
ExampleofUncompressedParquetTable
Ifyourdatacompressesverypoorly,oryouwanttoavoidtheCPUoverheadofcompressionanddecompression
entirely,settheCOMPRESSION_CODEC queryoptiontononebeforeinserting thedata:
[localhost:21000] > create table parquet_none like raw_text_data;
[localhost:21000] > set COMPRESSION_CODEC=none;
[localhost:21000] > insert into parquet_none select * from raw_text_data;
Inserted 1000000000 rows in 146.90s
ExamplesofSizesandSpeedsforCompressedParquetTables
Herearesomeexamplesshowingdifferencesindatasizesandqueryspeedsfor1billionrowsofsyntheticdata,
compressedwitheachkindofcodec.Asalways,runsimilartestswithrealisticdatasetsofyourown.Theactual
compressionratios,andrelativeinsertandqueryspeeds,willvarydepending onthecharacteristicsoftheactualdata.
ApacheImpalaGuide|647HowImpalaWorkswithHadoopFileFormats
Inthiscase,switchingfromSnappytoGZipcompressionshrinksthedatabyanadditional 40%orso,whileswitching
fromSnappycompressiontonocompressionexpandsthedataalsobyabout40%:
$ hdfs dfs -du -h /user/hive/warehouse/parquet_compression.db
23.1 G  /user/hive/warehouse/parquet_compression.db/parquet_snappy
13.5 G  /user/hive/warehouse/parquet_compression.db/parquet_gzip
32.8 G  /user/hive/warehouse/parquet_compression.db/parquet_none
BecauseParquetdatafilesaretypicallylarge,eachdirectorywillhaveadifferentnumberofdatafilesandtherow
groupswillbearrangeddifferently.
Atthesametime,thelessaggressivethecompression,thefasterthedatacanbedecompressed.Inthiscaseusinga
tablewithabillionrows,aquerythatevaluatesallthevaluesforaparticular columnrunsfasterwithnocompression
thanwithSnappycompression,andfasterwithSnappycompressionthanwithGzipcompression.Queryperformance
dependsonseveralotherfactors,soasalways,runyourownbenchmark swithyourowndatatodeterminetheideal
tradeoffbetweendatasize,CPUefficiency,andspeedofinsertandqueryoperations.
[localhost:21000] > desc parquet_snappy;
Query finished, fetching results ...
+-----------+---------+---------+
| name      | type    | comment |
+-----------+---------+---------+
| id        | int     |         |
| val       | int     |         |
| zfill     | string  |         |
| name      | string  |         |
| assertion | boolean |         |
+-----------+---------+---------+
Returned 5 row(s) in 0.14s
[localhost:21000] > select avg(val) from parquet_snappy;
Query finished, fetching results ...
+-----------------+
| _c0             |
+-----------------+
| 250000.93577915 |
+-----------------+
Returned 1 row(s) in 4.29s
[localhost:21000] > select avg(val) from parquet_gzip;
Query finished, fetching results ...
+-----------------+
| _c0             |
+-----------------+
| 250000.93577915 |
+-----------------+
Returned 1 row(s) in 6.97s
[localhost:21000] > select avg(val) from parquet_none;
Query finished, fetching results ...
+-----------------+
| _c0             |
+-----------------+
| 250000.93577915 |
+-----------------+
Returned 1 row(s) in 3.67s
ExampleofCopyingParquetDataFiles
Hereisafinalexample,toillustratehowthedatafilesusingthevariouscompressioncodecsareallcompatiblewith
eachotherforreadoperations.Themetadataaboutthecompressionformatiswrittenintoeachdatafile,andcanbe
decodedduringqueriesregardlessoftheCOMPRESSION_CODEC settingineffectatthetime.Inthisexample,wecopy
datafilesfromthePARQUET_SNAPPY ,PARQUET_GZIP ,andPARQUET_NONE tablesusedinthepreviousexamples,
eachcontaining1billionrows,alltothedatadirectoryofanewtablePARQUET_EVERYTHING .Acoupleofsample
queriesdemonstratethatthenewtablenowcontains3billionrowsfeaturingavarietyofcompressioncodecsforthe
datafiles.
648|ApacheImpalaGuideHowImpalaWorkswithHadoopFileFormats
First,wecreatethetableinImpalasothatthereisadestinationdirectoryinHDFStoputthedatafiles:
[localhost:21000] > create table parquet_everything like parquet_snappy;
Query: create table parquet_everything like parquet_snappy
Thenintheshell,wecopytherelevantdatafilesintothedatadirectoryforthisnewtable.Ratherthanusinghdfs
dfs -cp aswithtypicalfiles,weusehadoop distcp -pb toensurethatthespecialblocksizeoftheParquetdata
filesispreserved.
$ hadoop distcp -pb /user/hive/warehouse/parquet_compression.db/parquet_snappy \
  /user/hive/warehouse/parquet_compression.db/parquet_everything
...MapReduce output ...
$ hadoop distcp -pb /user/hive/warehouse/parquet_compression.db/parquet_gzip  \
  /user/hive/warehouse/parquet_compression.db/parquet_everything
...MapReduce output ...
$ hadoop distcp -pb /user/hive/warehouse/parquet_compression.db/parquet_none  \
  /user/hive/warehouse/parquet_compression.db/parquet_everything
...MapReduce output ...
Backintheimpala-shell interpreter,weusetheREFRESH statementtoalerttheImpalaservertothenewdata
filesforthistable,thenwecanrunqueriesdemonstratingthatthedatafilesrepresent3billionrows,andthevalues
foroneofthenumericcolumnsmatchwhatwasintheoriginalsmallertables:
[localhost:21000] > refresh parquet_everything;
Query finished, fetching results ...
Returned 0 row(s) in 0.32s
[localhost:21000] > select count(*) from parquet_everything;
Query finished, fetching results ...
+------------+
| _c0        |
+------------+
| 3000000000 |
+------------+
Returned 1 row(s) in 8.18s
[localhost:21000] > select avg(val) from parquet_everything;
Query finished, fetching results ...
+-----------------+
| _c0             |
+-----------------+
| 250000.93577915 |
+-----------------+
Returned 1 row(s) in 13.35s
ParquetTablesforImpalaComplexTypes
InCDH5.5/Impala2.3andhigher,Impalasupports thecomplextypesARRAY,STRUCT,andMAPSeeComplexTypes
(CDH5.5orhigheronly)onpage139fordetails.BecausethesedatatypesarecurrentlysupportedonlyfortheParquet
fileformat,ifyouplantousethem,becomefamiliarwiththeperformance andstorageaspectsofParquetfirst.
Exchanging ParquetDataFileswithOtherHadoopComponen ts
YoucanreadandwriteParquetdatafilesfromotherCDHcomponen ts.
Originally ,itwasnotpossibletocreateParquetdatathroughImpalaandreusethattablewithinHive.NowthatParquet
supportisavailableforHive,reusingexistingImpalaParquetdatafilesinHiverequiresupdatingthetablemetadata.
Usethefollowingcommand ifyouarealreadyrunningImpala1.1.1orhigher:
ALTER TABLE table_name  SET FILEFORMAT PARQUET;
IfyouarerunningalevelofImpalathatisolderthan1.1.1,dothemetadataupdatethroughHive:
ALTER TABLE table_name  SET SERDE 'parquet.hive.serde.ParquetHiveSerDe';
ALTER TABLE table_name  SET FILEFORMAT
ApacheImpalaGuide|649HowImpalaWorkswithHadoopFileFormats
  INPUTFORMAT "parquet.hive.DeprecatedParquetInputFormat"
  OUTPUTFORMAT "parquet.hive.DeprecatedParquetOutputFormat";
Impala1.1.1andhighercanreuseParquetdatafilescreatedbyHive,withoutanyactionrequired.
Impalasupports thescalardatatypesthatyoucanencodeinaParquetdatafile,butnotcompositeornestedtypes
suchasmapsorarrays.InCDH5.4/Impala2.2andhigher,ImpalacanqueryParquetdatafilesthatincludecomposite
ornestedtypes,aslongasthequeryonlyreferstocolumnswithscalartypes.
IfyoucopyParquetdatafilesbetweennodes,orevenbetweendifferentdirectoriesonthesamenode,makesureto
preservetheblocksizebyusingthecommandhadoop distcp -pb .Toverifythattheblocksizewaspreserved,issue
thecommandhdfs fsck -blocks HDFS_path_of_impala_table_dir andcheckthattheaverageblocksizeis
atornear256MB(orwhateverothersizeisdefinedbythePARQUET_FILE_SIZE queryoption)..(Thehadoop distcp
operationtypicallyleavessomedirectoriesbehind,withnamesmatching_distcp_logs_* ,thatyoucandeletefrom
thedestinationdirectoryafterward.)Issuethecommandhadoop distcp fordetailsaboutdistcpcommand syntax.
ImpalacanqueryParquetfilesthatusethePLAIN,PLAIN_DICTIONARY ,BIT_PACKED ,andRLEencodings.Currently,
ImpaladoesnotsupportRLE_DICTIONARY encoding.WhencreatingfilesoutsideofImpalaforusebyImpala,make
suretouseoneofthesupportedencodings.Inparticular ,forMapReducejobs,parquet.writer.version mustnot
bedefined(especially asPARQUET_2_0 )forwritingtheconfigurationsofParquetMRjobs.Datausingtheversion2.0
ofParquetwritermightnotbeconsumable byImpala,duetouseoftheRLE_DICTIONARY encoding.Usethedefault
versionoftheParquetwriterandrefrainfromoverridingthedefaultwriterversionbysettingthe
parquet.writer.version propertyorviaWriterVersion.PARQUET_2_0 intheParquetAPI.
ToexaminetheinternalstructureanddataofParquetfiles,youcanusetheparquet-tools command thatcomes
withCDH.Makesurethiscommand isinyour$PATH.(Typically,itissymlinkedfrom/usr/bin ;sometimes,depending
onyourinstallationsetup,youmightneedtolocateitunderaCDH-specific bindirectory.)Theargumentstothis
command letyouperformoperationssuchas:
â¢cat:Printafile'scontentstostandardout.InCDH5.5andhigher,youcanusethe-joptiontooutputJSON.
â¢head:Printthefirstfewrecordsofafiletostandardoutput.
â¢schema:PrinttheParquetschemaforthefile.
â¢meta:Printthefilefootermetadata,including key-valueproperties(likeAvroschema), compressionratios,
encodings,compressionused,androwgroupinformation.
â¢dump:Printalldataandmetadata.
Useparquet-tools -h toseeusageinformationforallthearguments.Herearesomeexamplesshowing
parquet-tools usage:
$ # Be careful doing this for a big file! Use parquet-tools head to be safe.
$ parquet-tools cat sample.parq
year = 1992
month = 1
day = 2
dayofweek = 4
dep_time = 748
crs_dep_time = 750
arr_time = 851
crs_arr_time = 846
carrier = US
flight_num = 53
actual_elapsed_time = 63
crs_elapsed_time = 56
arrdelay = 5
depdelay = -2
origin = CMH
dest = IND
distance = 182
cancelled = 0
diverted = 0
year = 1992
month = 1
650|ApacheImpalaGuideHowImpalaWorkswithHadoopFileFormats
day = 3
...
$ parquet-tools head -n 2 sample.parq
year = 1992
month = 1
day = 2
dayofweek = 4
dep_time = 748
crs_dep_time = 750
arr_time = 851
crs_arr_time = 846
carrier = US
flight_num = 53
actual_elapsed_time = 63
crs_elapsed_time = 56
arrdelay = 5
depdelay = -2
origin = CMH
dest = IND
distance = 182
cancelled = 0
diverted = 0
year = 1992
month = 1
day = 3
...
$ parquet-tools schema sample.parq
message schema {
  optional int32 year;
  optional int32 month;
  optional int32 day;
  optional int32 dayofweek;
  optional int32 dep_time;
  optional int32 crs_dep_time;
  optional int32 arr_time;
  optional int32 crs_arr_time;
  optional binary carrier;
  optional int32 flight_num;
...
$ parquet-tools meta sample.parq
creator:             impala version 2.2.0-cdh5.4.3 (build 
517bb0f71cd604a00369254ac6d88394df83e0f6)
file schema:         schema
-------------------------------------------------------------------
year:                OPTIONAL INT32 R:0 D:1
month:               OPTIONAL INT32 R:0 D:1
day:                 OPTIONAL INT32 R:0 D:1
dayofweek:           OPTIONAL INT32 R:0 D:1
dep_time:            OPTIONAL INT32 R:0 D:1
crs_dep_time:        OPTIONAL INT32 R:0 D:1
arr_time:            OPTIONAL INT32 R:0 D:1
crs_arr_time:        OPTIONAL INT32 R:0 D:1
carrier:             OPTIONAL BINARY R:0 D:1
flight_num:          OPTIONAL INT32 R:0 D:1
...
row group 1:         RC:20636601 TS:265103674
-------------------------------------------------------------------
year:                 INT32 SNAPPY DO:4 FPO:35 SZ:10103/49723/4.92 VC:20636601 
ApacheImpalaGuide|651HowImpalaWorkswithHadoopFileFormats
ENC:PLAIN_DICTIONARY,RLE,PLAIN
month:                INT32 SNAPPY DO:10147 FPO:10210 SZ:11380/35732/3.14 VC:20636601 
ENC:PLAIN_DICTIONARY,RLE,PLAIN
day:                  INT32 SNAPPY DO:21572 FPO:21714 SZ:3071658/9868452/3.21 VC:20636601
 ENC:PLAIN_DICTIONARY,RLE,PLAIN
dayofweek:            INT32 SNAPPY DO:3093276 FPO:3093319 SZ:2274375/5941876/2.61 
VC:20636601 ENC:PLAIN_DICTIONARY,RLE,PLAIN
dep_time:             INT32 SNAPPY DO:5367705 FPO:5373967 SZ:28281281/28573175/1.01 
VC:20636601 ENC:PLAIN_DICTIONARY,RLE,PLAIN
crs_dep_time:         INT32 SNAPPY DO:33649039 FPO:33654262 SZ:10220839/11574964/1.13 
VC:20636601 ENC:PLAIN_DICTIONARY,RLE,PLAIN
arr_time:             INT32 SNAPPY DO:43869935 FPO:43876489 SZ:28562410/28797767/1.01 
VC:20636601 ENC:PLAIN_DICTIONARY,RLE,PLAIN
crs_arr_time:         INT32 SNAPPY DO:72432398 FPO:72438151 SZ:10908972/12164626/1.12 
VC:20636601 ENC:PLAIN_DICTIONARY,RLE,PLAIN
carrier:              BINARY SNAPPY DO:83341427 FPO:83341558 SZ:114916/128611/1.12 
VC:20636601 ENC:PLAIN_DICTIONARY,RLE,PLAIN
flight_num:           INT32 SNAPPY DO:83456393 FPO:83488603 SZ:10216514/11474301/1.12 
VC:20636601 ENC:PLAIN_DICTIONARY,RLE,PLAIN
...
HowParquetDataFilesAreOrganized
Although Parquetisacolumn-orien tedfileformat,donotexpecttofindonedatafileforeachcolumn.Parquetkeeps
allthedataforarowwithinthesamedatafile,toensurethatthecolumnsforarowarealwaysavailableonthesame
nodeforprocessing. WhatParquetdoesistosetalargeHDFSblocksizeandamatchingmaximumdatafilesize,to
ensurethatI/Oandnetworktransferrequestsapplytolargebatchesofdata.
Withinthatdatafile,thedataforasetofrowsisrearrangedsothatallthevaluesfromthefirstcolumnareorganized
inonecontiguousblock,thenallthevaluesfromthesecondcolumn,andsoon.Puttingthevaluesfromthesame
columnnexttoeachotherletsImpalauseeffectivecompressiontechniques onthevaluesinthatcolumn.
Note:
ImpalaINSERTstatementswriteParquetdatafilesusinganHDFSblocksizethatmatchesthedata
filesize,toensurethateachdatafileisrepresentedbyasingleHDFSblock,andtheentirefilecanbe
processedonasinglenodewithoutrequiringanyremotereads.
IfyoucreateParquetdatafilesoutsideofImpala,suchasthroughaMapReduceorPigjob,ensure
thattheHDFSblocksizeisgreaterthanorequaltothefilesize,sothattheâonefileperblockâ
relationshipismaintained.Setthedfs.block.size orthedfs.blocksize propertylargeenough
thateachfilefitswithinasingleHDFSblock,evenifthatsizeislargerthanthenormalHDFSblocksize.
Iftheblocksizeisresettoalowervalueduringafilecopy,youwillseelowerperformance forqueries
involvingthosefiles,andthePROFILE statementwillrevealthatsomeI/Oisbeingdonesuboptimally,
throughremotereads.SeeExampleofCopyingParquetDataFilesonpage648foranexampleshowing
howtopreservetheblocksizewhencopyingParquetdatafiles.
WhenImpalaretrievesorteststhedataforaparticular column,itopensallthedatafiles,butonlyreadstheportion
ofeachfilecontainingthevaluesforthatcolumn.Thecolumnvaluesarestoredconsecutiv ely,minimizing theI/O
requiredtoprocessthevalueswithinasinglecolumn.IfothercolumnsarenamedintheSELECTlistorWHEREclauses,
thedataforallcolumnsinthesamerowisavailablewithinthatsamedatafile.
IfanINSERTstatementbringsinlessthanoneParquetblock'sworthofdata,theresultingdatafileissmallerthan
ideal.Thus,ifyoudosplitupanETLjobtousemultipleINSERTstatements,trytokeepthevolumeofdataforeach
INSERTstatementtoapproximately256MB,oramultipleof256MB.
RLEandDictionaryEncodingforParquetDataFiles
Parquetusessomeautomaticcompressiontechniques, suchasrun-lengthencoding(RLE)anddictionaryencoding,
basedonanalysisoftheactualdatavalues.Oncethedatavaluesareencodedinacompactform,theencodeddata
canoptionallybefurthercompressedusingacompressionalgorithm.ParquetdatafilescreatedbyImpalacanuse
652|ApacheImpalaGuideHowImpalaWorkswithHadoopFileFormats
Snappy,GZip,ornocompression;theParquetspecalsoallowsLZOcompression,butcurrentlyImpaladoesnotsupport
LZO-compressedParquetfiles.
RLEanddictionaryencodingarecompressiontechniques thatImpalaappliesautomaticallytogroupsofParquetdata
values,inadditiontoanySnappyorGZipcompressionappliedtotheentiredatafiles.Theseautomaticoptimizations
cansaveyoutimeandplanningthatarenormally neededforatraditional datawarehouse.Forexample,dictionary
encodingreducestheneedtocreatenumericIDsasabbreviationsforlongerstringvalues.
Run-lengthencodingcondenses sequences ofrepeateddatavalues.Forexample,ifmanyconsecutiv erowsallcontain
thesamevalueforacountrycode,thoserepeatingvaluescanberepresentedbythevaluefollowedbyacountofhow
manytimesitappearsconsecutiv ely.
Dictionaryencodingtakesthedifferentvaluespresentinacolumn,andrepresentseachoneincompact2-byteform
ratherthantheoriginalvalue,whichcouldbeseveralbytes.(Additional compressionisappliedtothecompacted
values,forextraspacesavings.)Thistypeofencodingapplieswhenthenumberofdifferentvaluesforacolumnisless
than2**16(16,384). ItdoesnotapplytocolumnsofdatatypeBOOLEAN ,whicharealreadyveryshort.TIMESTAMP
columnssometimeshaveauniquevalueforeachrow,inwhichcasetheycanquicklyexceedthe2**16limitondistinct
values.The2**16limitondifferentvalueswithinacolumnisresetforeachdatafile,soifseveraldifferentdatafiles
eachcontained10,000differentcitynames,thecitynamecolumnineachdatafilecouldstillbecondensed using
dictionaryencoding.
Compacting DataFilesforParquetTables
IfyoureuseexistingtablestructuresorETLprocessesforParquettables,youmightencounteraâmanysmallfilesâ
situation,whichissuboptimalforqueryefficiency.Forexample,statementslikethesemightproduceinefficiently
organizeddatafiles:
-- In an N-node cluster, each node produces a data file
-- for the INSERT operation. If you have less than
-- N GB of data to copy, some files are likely to be
-- much smaller than the default Parquet  block size.
insert into parquet_table select * from text_table;
-- Even if this operation involves an overall large amount of data,
-- when split up by year/month/day, each partition might only
-- receive a small amount of data. Then the data files for
-- the partition might be divided between the N nodes in the cluster.
-- A multi-gigabyte copy operation might produce files of only
-- a few MB each.
insert into partitioned_parquet_table partition (year, month, day)
  select year, month, day, url, referer, user_agent, http_code, response_time
  from web_stats;
Herearetechniques tohelpyouproducelargedatafilesinParquetINSERToperations,andtocompactexisting
too-smalldatafiles:
â¢Wheninsertingintoapartitioned Parquettable,usestaticallypartitioned INSERTstatementswherethepartition
keyvaluesarespecified asconstantvalues.Ideally,useaseparateINSERTstatementforeachpartition.
â¢YoumightsettheNUM_NODES optionto1briefly,duringINSERTorCREATE TABLE AS SELECT statements.
Normally,thosestatementsproduceoneormoredatafilesperdatanode.Ifthewriteoperationinvolvessmall
amountsofdata,aParquettable,and/orapartitioned table,thedefaultbehaviorcouldproducemanysmallfiles
whenintuitivelyyoumightexpectonlyasingleoutputfile.SET NUM_NODES=1 turnsofftheâdistributedâaspect
ofthewriteoperation,makingitmorelikelytoproduceonlyoneorafewdatafiles.
â¢Bepreparedtoreducethenumberofpartition keycolumnsfromwhatyouareusedtowithtraditional analytic
databasesystems.
â¢DonotexpectImpala-writ tenParquetfilestofilluptheentireParquetblocksize.Impalaestimatesonthe
conservativesidewhenfiguringouthowmuchdatatowritetoeachParquetfile.Typically,theofuncompressed
datainmemoryissubstantiallyreducedondiskbythecompressionandencodingtechniques intheParquetfile
format.Thefinaldatafilesizevariesdepending onthecompressibilityofthedata.Therefore,itisnotanindication
ofaproblemif256MBoftextdataisturnedinto2Parquetdatafiles,eachlessthan256MB.
ApacheImpalaGuide|653HowImpalaWorkswithHadoopFileFormats
â¢Ifyouaccidentallyendupwithatablewithmanysmalldatafiles,considerusingoneormoreofthepreceding
techniques andcopyingallthedataintoanewParquettable,eitherthroughCREATE TABLE AS SELECT or
INSERT ... SELECT statements.
Toavoidrewritingqueriestochangetablenames,youcanadoptaconventionofalwaysrunningimportantqueries
againstaview.Changing theviewdefinitionimmediatelyswitchesanysubsequentqueriestousethenewunderlying
tables:
create view production_table as select * from table_with_many_small_files;
-- CTAS or INSERT...SELECT all the data into a more efficient layout...
alter view production_table as select * from table_with_few_big_files;
select * from production_table where c1 = 100 and c2 < 50 and ...;
SchemaEvolutionforParquetTables
SchemaevolutionreferstousingthestatementALTER TABLE ... REPLACE COLUMNS tochangethenames,data
type,ornumberofcolumnsinatable.YoucanperformschemaevolutionforParquettablesasfollows:
â¢TheImpalaALTER TABLE statementneverchangesanydatafilesinthetables.FromtheImpalaside,schema
evolutioninvolvesinterpretingthesamedatafilesintermsofanewtabledefinition.Sometypesofschema
changesmakesenseandarerepresentedcorrectly.Othertypesofchangescannotberepresentedinasensible
way,andproducespecialresultvaluesorconversionerrorsduringqueries.
â¢TheINSERTstatementalwayscreatesdatausingthelatesttabledefinition.Youmightendupwithdatafileswith
differentnumbersofcolumnsorinternaldatarepresentationsifyoudoasequence ofINSERTandALTER TABLE
... REPLACE COLUMNS statements.
â¢IfyouuseALTER TABLE ... REPLACE COLUMNS todefineadditional columnsattheend,whentheoriginal
datafilesareusedinaquery,thesefinalcolumnsareconsideredtobeallNULLvalues.
â¢IfyouuseALTER TABLE ... REPLACE COLUMNS todefinefewercolumnsthanbefore,whentheoriginaldata
filesareusedinaquery,theunusedcolumnsstillpresentinthedatafileareignored.
â¢ParquetrepresentstheTINYINT ,SMALLINT ,andINTtypesthesameinternally,allstoredin32-bitintegers.
âThatmeansitiseasytopromoteaTINYINT columntoSMALLINT orINT,oraSMALLINT columntoINT.
Thenumbersarerepresentedexactlythesameinthedatafile,andthecolumnsbeingpromotedwouldnot
containanyout-of-rangevalues.
âIfyouchangeanyofthesecolumntypestoasmallertype,anyvaluesthatareout-of-rangeforthenewtype
arereturnedincorrectly,typicallyasnegativenumbers.
âYoucannotchangeaTINYINT ,SMALLINT ,orINTcolumntoBIGINT,ortheotherwayaround.Although
theALTER TABLE succeeds, anyattempttoquerythosecolumnsresultsinconversionerrors.
âAnyothertypeconversionforcolumnsproducesaconversionerrorduringqueries.Forexample,INTto
STRING,FLOATtoDOUBLE,TIMESTAMP toSTRING,DECIMAL(9,0) toDECIMAL(5,2) ,andsoon.
YoumightfindthatyouhaveParquetfileswherethecolumnsdonotlineupinthesameorderasinyourImpalatable.
Forexample,youmighthaveaParquetfilethatwaspartofatablewithcolumnsC1,C2,C3,C4 ,andnowyouwant
toreusethesameParquetfileinatablewithcolumnsC4,C2.Bydefault,Impalaexpectsthecolumnsinthedatafile
toappearinthesameorderasthecolumnsdefinedforthetable,makingitimpracticaltodosomekindsoffilereuse
orschemaevolution.InCDH5.8/Impala2.6andhigher,thequeryoption
PARQUET_FALLBACK_SCHEMA_RESOLUTION=name letsImpalaresolvecolumnsbyname,andthereforehandle
out-of-orderorextracolumnsinthedatafile.Forexample:
create database schema_evolution;
use schema_evolution;
create table t1 (c1 int, c2 boolean, c3 string, c4 timestamp)
  stored as parquet;
654|ApacheImpalaGuideHowImpalaWorkswithHadoopFileFormats
insert into t1 values
  (1, true, 'yes', now()),
  (2, false, 'no', now() + interval 1 day);
select * from t1;
+----+-------+-----+-------------------------------+
| c1 | c2    | c3  | c4                            |
+----+-------+-----+-------------------------------+
| 1  | true  | yes | 2016-06-28 14:53:26.554369000 |
| 2  | false | no  | 2016-06-29 14:53:26.554369000 |
+----+-------+-----+-------------------------------+
desc formatted t1;
...
| Location:   | /user/hive/warehouse/schema_evolution.db/t1 |
...
-- Make T2 have the same data file as in T1, including 2
-- unused columns and column order different than T2 expects.
load data inpath '/user/hive/warehouse/schema_evolution.db/t1'
  into table t2;
+----------------------------------------------------------+
| summary                                                  |
+----------------------------------------------------------+
| Loaded 1 file(s). Total files in destination location: 1 |
+----------------------------------------------------------+
-- 'position' is the default setting.
-- Impala cannot read the Parquet file if the column order does not match.
set PARQUET_FALLBACK_SCHEMA_RESOLUTION=position;
PARQUET_FALLBACK_SCHEMA_RESOLUTION set to position
select * from t2;
WARNINGS:
File 'schema_evolution.db/t2/45331705_data.0.parq'
has an incompatible Parquet schema for column 'schema_evolution.t2.c4'.
Column type: TIMESTAMP, Parquet schema: optional int32 c1 [i:0 d:1 r:0]
File 'schema_evolution.db/t2/45331705_data.0.parq'
has an incompatible Parquet schema for column 'schema_evolution.t2.c4'.
Column type: TIMESTAMP, Parquet schema: optional int32 c1 [i:0 d:1 r:0]
-- With the 'name' setting, Impala can read the Parquet data files
-- despite mismatching column order.
set PARQUET_FALLBACK_SCHEMA_RESOLUTION=name;
PARQUET_FALLBACK_SCHEMA_RESOLUTION set to name
select * from t2;
+-------------------------------+-------+
| c4                            | c2    |
+-------------------------------+-------+
| 2016-06-28 14:53:26.554369000 | true  |
| 2016-06-29 14:53:26.554369000 | false |
+-------------------------------+-------+
SeePARQUET_FALLBACK_SCHEMA_RE SOLUTIONQueryOption(CDH5.8orhigheronly)onpage353formoredetails.
DataTypeConsiderationsforParquetTables
TheParquetformatdefinesasetofdatatypeswhosenamesdifferfromthenamesofthecorresponding Impaladata
types.IfyouarepreparingParquetfilesusingotherHadoopcomponen tssuchasPigorMapReduce,youmightneed
toworkwiththetypenamesdefinedbyParquet.ThefollowingtableslisttheParquet-definedtypesandtheequivalent
typesinImpala.
Primitivetypes
Impalatype Parquettype
STRING BINARY
ApacheImpalaGuide|655HowImpalaWorkswithHadoopFileFormats
Impalatype Parquettype
BOOLEAN BOOLEAN
DOUBLE DOUBLE
FLOAT FLOAT
INT INT32
BIGINT INT64
TIMESTAMP INT96
Logicaltypes
Parquetusestypeannotationstoextendthetypesthatitcanstore,byspecifyinghowtheprimitivetypesshouldbe
interpreted.
Impalatype Parquetprimitivetypeandannotation
STRING BINARYannotatedwiththeUTF8OriginalType
STRING BINARYannotatedwiththeSTRINGLogicalType
STRING BINARYannotatedwiththeENUMOriginalType
DECIMAL BINARYannotatedwiththeDECIMALOriginalType
TIMESTAMP(inCDH6.2orhigher)
orINT64annotatedwiththeTIMESTAMP_MILLIS OriginalType
BIGINT(forbackwardcompatibility)
TIMESTAMP(inCDH6.2orhigher)
orINT64annotatedwiththeTIMESTAMP_MICR OSOriginalType
BIGINT(forbackwardcompatibility)
TIMESTAMP(inCDH6.2orhigher)
orINT64annotatedwiththeTIMESTAMPLogicalType
BIGINT(forbackwardcompatibility)
Complextypes:
Forthecomplextypes(ARRAY,MAP,andSTRUCT)availableinCDH5.5/Impala2.3andhigher,Impalaonlysupports
queriesagainstthosetypesinParquettables.
UsingtheORCFileFormatwithImpalaTables
ImpalacanreadORCdatafilesasanexperimen talfeaturesinceImpala3.1.
Toenablethefeature,set--enable_orc_scanner totruewhenstartingthecluster.
Note:Impala'sORCsupportisnotyetproduction quality.Parquetremainsthepreferredfileformat
forusewithImpalaandofferssignificantlybetterperformance andamorecompletesetoffeatures.
656|ApacheImpalaGuideHowImpalaWorkswithHadoopFileFormats
Table3:ORCFormatSupportinImpala
ImpalaCanINSERT? ImpalaCanCREATE? CompressionCodecs Format FileType
No.ImportdatabyusingLOAD
DATAondatafilesalreadyintheTheORCsupportisan
experimen talfeaturesinceCDH
6.1/Impala3.1&Impala2.12.gzip,Snappy,LZO,LZ4;
currentlygzipby
defaultStructured ORC
rightformat,oruseINSERTin
HivefollowedbyREFRESH
table_name inImpala.Todisableit,set
--enable_orc_scanner to
falsewhenstartingthecluster.
CreatingORCTablesandLoadingData
Ifyoudonothaveanexistingdatafiletouse,beginbycreatingoneintheappropriateformat.
TocreateanORCtable:
Intheimpala-shell interpreter,issueacommand similarto:
CREATE TABLE orc_table ( column_specs ) STORED AS ORC;
BecauseImpalacanquerysomekindsoftablesthatitcannotcurrentlywriteto,aftercreatingtablesofcertainfile
formats,youmightusetheHiveshelltoloadthedata.SeeHowImpalaWorkswithHadoopFileFormatsonpage634
fordetails.AfterloadingdataintoatablethroughHiveorothermechanism outsideofImpala,issueaREFRESH
table_name statementthenexttimeyouconnecttotheImpalanode,beforequeryingthetable,tomakeImpala
recognizethenewdata.
Forexample,hereishowyoumightcreatesomeORCtablesinImpala(byspecifyingthecolumnsexplicitly,orcloning
thestructureofanothertable),loaddatathroughHive,andquerythemthroughImpala:
$ impala-shell -i localhost
[localhost:21000] default> CREATE TABLE orc_table (x INT) STORED AS ORC;
[localhost:21000] default> CREATE TABLE orc_clone LIKE some_other_table STORED AS ORC;
[localhost:21000] default> quit;
$ hive
hive> INSERT INTO TABLE orc_table SELECT x FROM some_other_table;
3 Rows loaded to orc_table
Time taken: 4.169 seconds
hive> quit;
$ impala-shell -i localhost
[localhost:21000] default> SELECT * FROM orc_table;
Fetched 0 row(s) in 0.11s
[localhost:21000] default> -- Make Impala recognize the data loaded through Hive;
[localhost:21000] default> REFRESH orc_table;
[localhost:21000] default> SELECT * FROM orc_table;
+---+
| x |
+---+
| 1 |
| 2 |
| 3 |
+---+
Fetched 3 row(s) in 0.11s
EnablingCompressionforORCTables
ORCtablesareinzlib(DeflateinImpala)compressionindefault.YoumaywanttouseSnappyorLZOcompressionon
existingtablesfordifferentbalancebetweencompressionratioanddecompressionspeed.InHive-1.1.0,thesupported
ApacheImpalaGuide|657HowImpalaWorkswithHadoopFileFormats
compressionsforORCtablesareNONE,ZLIB,SNAPPYandLZO.Forexample,toenableSnappycompression,youwould
specifythefollowingadditional settingswhenloadingdatathroughtheHiveshell:
hive> SET hive.exec.compress.output=true;
hive> SET orc.compress=SNAPPY;
hive> INSERT OVERWRITE TABLE new_table  SELECT * FROM old_table ;
Ifyouareconvertingpartitioned tables,youmustcompleteadditional steps.Insuchacase,specifyadditional settings
similartothefollowing:
hive> CREATE TABLE new_table  (your_cols ) PARTITIONED BY ( partition_cols ) STORED AS 
new_format ;
hive> SET hive.exec.dynamic.partition.mode=nonstrict;
hive> SET hive.exec.dynamic.partition=true;
hive> INSERT OVERWRITE TABLE new_table  PARTITION( comma_separated_partition_cols ) SELECT
 * FROM old_table ;
Remember thatHivedoesnotrequirethatyouspecifyasourceformatforit.Consider thecaseofconvertingatable
withtwopartition columnscalledyearandmonthtoaSnappycompressedORCtable.Combining thecomponen ts
outlinedpreviouslytocompletethistableconversion,youwouldspecifysettingssimilartothefollowing:
hive> CREATE TABLE tbl_orc (int_col INT, string_col STRING) STORED AS ORC;
hive> SET hive.exec.compress.output=true;
hive> SET orc.compress=SNAPPY;
hive> SET hive.exec.dynamic.partition.mode=nonstrict;
hive> SET hive.exec.dynamic.partition=true;
hive> INSERT OVERWRITE TABLE tbl_orc SELECT * FROM tbl;
Tocompleteasimilarprocessforatablethatincludespartitions, youwouldspecifysettingssimilartothefollowing:
hive> CREATE TABLE tbl_orc (int_col INT, string_col STRING) PARTITIONED BY (year INT) 
STORED AS ORC;
hive> SET hive.exec.compress.output=true;
hive> SET orc.compress=SNAPPY;
hive> SET hive.exec.dynamic.partition.mode=nonstrict;
hive> SET hive.exec.dynamic.partition=true;
hive> INSERT OVERWRITE TABLE tbl_orc PARTITION(year) SELECT * FROM tbl;
Note:
Thecompressiontypeisspecified inthefollowingcommand:
SET orc.compress=SNAPPY;
YoucouldelecttospecifyalternativecodecssuchasNONE, GZIP, LZO here.
QueryPerformance forImpalaORCTables
Ingeneral,expectqueryperformance withORCtablestobefasterthanwithtablesusingtextdata,butslowerthan
withParquettablessincethere'rebunchofoptimizationsforParquet.SeeUsingtheParquetFileFormatwithImpala
Tablesonpage643forinformationaboutusingtheParquetfileformatforhigh-performance analyticqueries.
InCDH5.8/Impala2.6andhigher,ImpalaqueriesareoptimizedforfilesstoredinAmazonS3.ForImpalatablesthat
usethefileformatsParquet,ORC,RCFile,SequenceFile, Avro,anduncompressedtext,thesettingfs.s3a.block.size
inthecore-site.xml configurationfiledetermineshowImpaladividestheI/Oworkofreadingthedatafiles.This
configurationsettingisspecified inbytes.Bydefault,thisvalueis33554432 (32MB),meaningthatImpalaparallelizes
S3readoperationsonthefilesasiftheyweremadeupof32MBblocks.Forexample,ifyourS3queriesprimarily
accessParquetfileswrittenbyMapReduceorHive,increasefs.s3a.block.size to134217728 (128MB)tomatch
therowgroupsizeofthosefiles.IfmostS3queriesinvolveParquetfileswrittenbyImpala,increase
fs.s3a.block.size to268435456 (256MB)tomatchtherowgroupsizeproducedbyImpala.
658|ApacheImpalaGuideHowImpalaWorkswithHadoopFileFormats
DataTypeConsiderationsforORCTables
TheORCformatdefinesasetofdatatypeswhosenamesdifferfromthenamesofthecorresponding Impaladata
types.IfyouarepreparingORCfilesusingotherHadoopcomponen tssuchasPigorMapReduce,youmightneedto
workwiththetypenamesdefinedbyORC.ThefollowingfigureliststheORC-definedtypesandtheequivalenttypes
inImpala.
Primitivetypes:
BINARY -> STRING
BOOLEAN -> BOOLEAN
DOUBLE -> DOUBLE
FLOAT -> FLOAT
TINYINT -> TINYINT
SMALLINT -> SMALLINT
INT -> INT
BIGINT -> BIGINT
TIMESTAMP -> TIMESTAMP
DATE (not supported)
Complextypes:
ComplextypesarecurrentlynotsupportedonORC.However,queriesmaterializing onlyscalartypecolumnsare
allowed:
$ hive
hive> CREATE TABLE orc_nested_table (id INT, a ARRAY<INT>) STORED AS ORC;
hive> INSERT INTO TABLE orc_nested_table SELECT 1, ARRAY(1,2,3);
OK
Time taken: 2.629 seconds
hive> quit;
$ impala-shell -i localhost
[localhost:21000] default> INVALIDATE METADATA orc_nested_table;
[localhost:21000] default> SELECT 1 FROM orc_nested_table t, t.a;
ERROR: NotImplementedException: Scan of table 't' in format 'ORC' is not supported 
because the table has a column 'a' with a complex type 'ARRAY<INT>'.
Complex types are supported for these file formats: PARQUET.
[localhost:21000] default> SELECT COUNT(*) FROM orc_nested_table;
+----------+
| count(*) |
+----------+
| 1        |
+----------+
Fetched 1 row(s) in 0.12s
[localhost:21000] default> SELECT id FROM orc_nested_table;
+----+
| id |
+----+
| 1  |
+----+
Fetched 1 row(s) in 0.12s
UsingtheAvroFileFormatwithImpalaTables
Impalasupports usingtableswhosedatafilesusetheAvrofileformat.ImpalacanqueryAvrotables.InImpala1.4.0
andhigher,ImpalacancreateAvrotables,butcannotinsertdataintothem.Forinsertoperations,useHive,thenswitch
backtoImpalatorunqueries.
ApacheImpalaGuide|659HowImpalaWorkswithHadoopFileFormats
Table4:AvroFormatSupportinImpala
ImpalaCanINSERT? ImpalaCanCREATE? CompressionCodecs Format FileType
No.ImportdatabyusingLOAD
DATAondatafilesalreadyintheYes,inImpala1.4.0andhigher.In
lowerversions,createthetable
usingHive.Snappy,gzip,deflate Structured Avro
rightformat,oruseINSERTin
HivefollowedbyREFRESH
table_name inImpala.
CreatingAvroTables
TocreateanewtableusingtheAvrofileformat,issuetheCREATE TABLE statementthroughImpalawiththeSTORED
AS AVRO clause,orthroughHive.IfyoucreatethetablethroughImpala,youmustincludecolumndefinitionsthat
matchthefieldsspecified intheAvroschema.WithHive,youcanomitthecolumnsandjustspecifytheAvroschema.
InCDH5.5/Impala2.3andhigher,theCREATE TABLE forAvrotablescanincludeSQL-stylecolumndefinitionsrather
thanspecifyingAvronotationthroughtheTBLPROPERTIES clause.Impalaissueswarningmessagesifthereareany
mismatchesbetweenthetypesspecified intheSQLcolumndefinitionsandtheunderlying types;forexample,any
TINYINT orSMALLINT columnsaretreatedasINTintheunderlying Avrofiles,andthereforearedisplayedasINTin
anyDESCRIBE orSHOW CREATE TABLE output.
Note:
Currently,AvrotablescannotcontainTIMESTAMP columns.Ifyouneedtostoredateandtimevalues
inAvrotables,asaworkaroundyoucanuseaSTRINGrepresentationofthevalues,convertthevalues
toBIGINTwiththeUNIX_TIMESTAMP() function, orcreateseparatenumericcolumnsforindividual
dateandtimefieldsusingtheEXTRACT() function.
ThefollowingexamplesdemonstratecreatinganAvrotableinImpala,usingeitheraninlinecolumnspecificationor
onetakenfromaJSONfilestoredinHDFS:
[localhost:21000] > CREATE TABLE avro_only_sql_columns
                  > (
                  >   id INT,
                  >   bool_col BOOLEAN,
                  >   tinyint_col TINYINT, /* Gets promoted to INT */
                  >   smallint_col SMALLINT, /* Gets promoted to INT */
                  >   int_col INT,
                  >   bigint_col BIGINT,
                  >   float_col FLOAT,
                  >   double_col DOUBLE,
                  >   date_string_col STRING,
                  >   string_col STRING
                  > )
                  > STORED AS AVRO;
[localhost:21000] > CREATE TABLE impala_avro_table
                  > (bool_col BOOLEAN, int_col INT, long_col BIGINT, float_col FLOAT, 
double_col DOUBLE, string_col STRING, nullable_int INT)
                  > STORED AS AVRO
                  > TBLPROPERTIES ('avro.schema.literal'='{
                  >    "name": "my_record",
                  >    "type": "record",
                  >    "fields": [
                  >       {"name":"bool_col", "type":"boolean"},
                  >       {"name":"int_col", "type":"int"},
                  >       {"name":"long_col", "type":"long"},
                  >       {"name":"float_col", "type":"float"},
                  >       {"name":"double_col", "type":"double"},
                  >       {"name":"string_col", "type":"string"},
                  >       {"name": "nullable_int", "type": ["null", "int"]}]}');
660|ApacheImpalaGuideHowImpalaWorkswithHadoopFileFormats
[localhost:21000] > CREATE TABLE avro_examples_of_all_types (
                  >     id INT,
                  >     bool_col BOOLEAN,
                  >     tinyint_col TINYINT,
                  >     smallint_col SMALLINT,
                  >     int_col INT,
                  >     bigint_col BIGINT,
                  >     float_col FLOAT,
                  >     double_col DOUBLE,
                  >     date_string_col STRING,
                  >     string_col STRING
                  >   )
                  >   STORED AS AVRO
                  >   TBLPROPERTIES 
('avro.schema.url'='hdfs://localhost:8020/avro_schemas/alltypes.json');
ThefollowingexampledemonstratescreatinganAvrotableinHive:
hive> CREATE TABLE hive_avro_table
    > ROW FORMAT SERDE 'org.apache.hadoop.hive.serde2.avro.AvroSerDe'
    > STORED AS INPUTFORMAT 'org.apache.hadoop.hive.ql.io.avro.AvroContainerInputFormat'
    > OUTPUTFORMAT 'org.apache.hadoop.hive.ql.io.avro.AvroContainerOutputFormat'
    > TBLPROPERTIES ('avro.schema.literal'='{
    >    "name": "my_record",
    >    "type": "record",
    >    "fields": [
    >       {"name":"bool_col", "type":"boolean"},
    >       {"name":"int_col", "type":"int"},
    >       {"name":"long_col", "type":"long"},
    >       {"name":"float_col", "type":"float"},
    >       {"name":"double_col", "type":"double"},
    >       {"name":"string_col", "type":"string"},
    >       {"name": "nullable_int", "type": ["null", "int"]}]}');
Eachfieldoftherecordbecomesacolumnofthetable.Notethatanyotherinformation,suchastherecordname,is
ignored.
Note:FornullableAvrocolumns,makesuretoputthe"null"entrybeforetheactualtypename.
InImpala,allcolumnsarenullable;ImpalacurrentlydoesnothaveaNOT NULL clause.Anynon-nullable
propertyisonlyenforcedontheAvroside.
MostcolumntypesmapdirectlyfromAvrotoImpalaunderthesamenames.Thesearetheexceptionsandspecial
casestoconsider:
â¢TheDECIMAL typeisdefinedinAvroasaBYTEtypewiththelogicalType propertysetto"decimal" anda
specified precisionandscale.
â¢TheAvrolongtypemapstoBIGINTinImpala.
IfyoucreatethetablethroughHive,switchbacktoimpala-shell andissueanINVALIDATE METADATA table_name
statement.Thenyoucanrunqueriesforthattablethroughimpala-shell .
Inrareinstances,amismatchcouldoccurbetweentheAvroschemaandthecolumndefinitionsinthemetastore
database.InCDH5.5/Impala2.3andhigher,ImpalachecksforsuchinconsistenciesduringaCREATE TABLE statement
andeachtimeitloadsthemetadataforatable(forexample,afterINVALIDATE METADATA ).Impalausesthefollowing
rulestodeterminehowtotreatmismatchingcolumns,aprocessknownasschemareconciliation :
â¢Ifthereisamismatchinthenumberofcolumns,ImpalausesthecolumndefinitionsfromtheAvroschema.
â¢Ifthereisamismatchincolumnnameortype,ImpalausesthecolumndefinitionfromtheAvroschema.Because
aCHARorVARCHAR columninImpalamapstoanAvroSTRING,thiscaseisnotconsideredamismatchandthe
columnispreservedasCHARorVARCHAR inthereconciledschema.PriortoCDH5.9/Impala2.7thecolumnname
andcommentforsuchCHARandVARCHAR columnswasalsotakenfromtheSQLcolumndefinition.InCDH5.9/
ApacheImpalaGuide|661HowImpalaWorkswithHadoopFileFormats
Impala2.7andhigher,thecolumnnameandcommentfromtheAvroschemafiletakeprecedence forsuch
columns,andonlytheCHARorVARCHAR typeispreservedfromtheSQLcolumndefinition.
â¢AnImpalaTIMESTAMP columndefinitionmapstoanAvroSTRINGandispresentedasaSTRINGinthereconciled
schema,becauseAvrohasnobinaryTIMESTAMP representation.Asaresult,noAvrotablecanhaveaTIMESTAMP
column;thisrestrictionisthesameasinearlierImpalareleases.
Complextypeconsiderations:Although youcancreatetablesinthisfileformatusingthecomplextypes(ARRAY,
STRUCT,andMAP)availableinCDH5.5/Impala2.3andhigher,currently,ImpalacanquerythesetypesonlyinParquet
tables.TheoneexceptiontotheprecedingruleisCOUNT(*) queriesonRCFiletablesthatincludecomplextypes.Such
queriesareallowedinCDH5.8/Impala2.6andhigher.
UsingaHive-CreatedAvroTableinImpala
IfyouhaveanAvrotablecreatedthroughHive,youcanuseitinImpalaaslongasitcontainsonlyImpala-compatible
datatypes.Itcannotcontain:
â¢Complextypes:array,map,record,struct,unionotherthan[supported_type ,null]or
[null,supported_type ]
â¢TheAvro-specific typesenum,bytes,andfixed
â¢AnyscalartypeotherthanthoselistedinDataTypesonpage101
BecauseImpalaandHivesharethesamemetastoredatabase,Impalacandirectlyaccessthetabledefinitionsanddata
fortablesthatwerecreatedinHive.
IfyoucreateanAvrotableinHive,issueanINVALIDATE METADATA thenexttimeyouconnecttoImpalathrough
impala-shell .Thisisaone-time operationtomakeImpalaawareofthenewtable.Youcanissuethestatement
whileconnectedtoanyImpalanode,andthecatalogservicebroadcaststhechangetoallotherImpalanodes.
IfyouloadnewdataintoanAvrotablethroughHive,eitherthroughaHiveLOAD DATA orINSERTstatement,orby
manually copyingormovingfilesintothedatadirectoryforthetable,issueaREFRESH table_name statementthe
nexttimeyouconnecttoImpalathroughimpala-shell .YoucanissuethestatementwhileconnectedtoanyImpala
node,andthecatalogservicebroadcaststhechangetoallotherImpalanodes.IfyouissuetheLOAD DATA statement
throughImpala,youdonotneedaREFRESH afterward.
Impalaonlysupports fieldsoftypeboolean ,int,long,float,double,andstring,orunionsofthesetypeswith
null;forexample,["string", "null"] .Unionswithnullessentiallycreateanullabletype.
SpecifyingtheAvroSchemathroughJSON
WhileyoucanembedaschemadirectlyinyourCREATE TABLE statement,asshownabove,columnwidthrestrictions
intheHivemetastorelimitthelengthofschemayoucanspecify.Ifyouencounterproblemswithlongschemaliterals,
trystoringyourschemaasaJSONfileinHDFSinstead.SpecifyyourschemainHDFSusingtablepropertiessimilarto
thefollowing:
tblproperties ('avro.schema.url'='hdfs//your-name-node:port/path/to/schema.json');
LoadingDataintoanAvroTable
Currently,ImpalacannotwriteAvrodatafiles.Therefore,anAvrotablecannotbeusedasthedestinationofanImpala
INSERTstatementorCREATE TABLE AS SELECT .
Tocopydatafromanothertable,issueanyINSERTstatementsthroughHive.Forinformationaboutloadingdatainto
AvrotablesthroughHive,seetheAvropageontheHivewiki.
IfyoualreadyhavedatafilesinAvroformat,youcanalsoissueLOAD DATA ineitherImpalaorHive.Impalacanmove
existingAvrodatafilesintoanAvrotable,itjustcannotcreatenewAvrodatafiles.
662|ApacheImpalaGuideHowImpalaWorkswithHadoopFileFormats
EnablingCompressionforAvroTables
ToenablecompressionforAvrotables,specifysettingsintheHiveshelltoenablecompressionandtospecifyacodec,
thenissueaCREATE TABLE statementasintheprecedingexamples.Impalasupports thesnappyanddeflate
codecsforAvrotables.
Forexample:
hive> set hive.exec.compress.output=true;
hive> set avro.output.codec=snappy;
HowImpalaHandlesAvroSchemaEvolution
StartinginImpala1.1,ImpalacandealwithAvrodatafilesthatemployschemaevolution,wheredifferentdatafiles
withinthesametableuseslightlydifferenttypedefinitions. (Youwouldperformtheschemaevolutionoperationby
issuinganALTER TABLE statementintheHiveshell.)Theoldandnewtypesforanychangedcolumnsmustbe
compatible,forexampleacolumnmightstartasanintandlaterchangetoabigintorfloat.
Aswithanyothertableswherethedefinitionsarechangedordataisaddedoutsideofthecurrentimpalad node,
ensurethatImpalaloadsthelatestmetadataforthetableiftheAvroschemaismodified throughHive.IssueaREFRESH
table_name orINVALIDATE METADATA table_name statement.REFRESH reloadsthemetadataimmediately,
INVALIDATE METADATA reloadsthemetadatathenexttimethetableisaccessed.
WhenAvrodatafilesorcolumnsarenotconsultedduringaquery,Impaladoesnotcheckforconsistency.Thus,ifyou
issueSELECT c1, c2 FROM t1 ,Impaladoesnotreturnanyerrorifthecolumnc3changedinanincompatibleway.
Ifaqueryretrievesdatafromsomepartitions butnotothers,Impaladoesnotcheckthedatafilesfortheunused
partitions.
IntheHiveDDLstatements,youcanspecifyanavro.schema.literal tableproperty(iftheschemadefinitionis
short)oranavro.schema.url property(iftheschemadefinitionislong,ortoallowconvenienteditingforthe
definition).
Forexample,runningthefollowingSQLcodeintheHiveshellcreatesatableusingtheAvrofileformatandputssome
sampledataintoit:
CREATE TABLE avro_table (a string, b string)
ROW FORMAT SERDE 'org.apache.hadoop.hive.serde2.avro.AvroSerDe'
STORED AS INPUTFORMAT 'org.apache.hadoop.hive.ql.io.avro.AvroContainerInputFormat'
OUTPUTFORMAT 'org.apache.hadoop.hive.ql.io.avro.AvroContainerOutputFormat'
TBLPROPERTIES (
  'avro.schema.literal'='{
    "type": "record",
    "name": "my_record",
    "fields": [
      {"name": "a", "type": "int"},
      {"name": "b", "type": "string"}
    ]}');
INSERT OVERWRITE TABLE avro_table SELECT 1, "avro" FROM functional.alltypes LIMIT 1;
OncetheAvrotableiscreatedandcontainsdata,youcanqueryitthroughtheimpala-shell command:
[localhost:21000] > select * from avro_table;
+---+------+
| a | b    |
+---+------+
| 1 | avro |
+---+------+
NowintheHiveshell,youchangethetypeofacolumnandaddanewcolumnwithadefaultvalue:
-- Promote column "a" from INT to FLOAT (no need to update Avro schema)
ALTER TABLE avro_table CHANGE A A FLOAT;
ApacheImpalaGuide|663HowImpalaWorkswithHadoopFileFormats
-- Add column "c" with default
ALTER TABLE avro_table ADD COLUMNS (c int);
ALTER TABLE avro_table SET TBLPROPERTIES (
  'avro.schema.literal'='{
    "type": "record",
    "name": "my_record",
    "fields": [
      {"name": "a", "type": "int"},
      {"name": "b", "type": "string"},
      {"name": "c", "type": "int", "default": 10}
    ]}');
Onceagaininimpala-shell ,youcanquerytheAvrotablebasedonitslatestschemadefinition.Becausethetable
metadatawaschangedoutsideofImpala,youissueaREFRESH statementfirstsothatImpalahasup-to-datemetadata
forthetable.
[localhost:21000] > refresh avro_table;
[localhost:21000] > select * from avro_table;
+---+------+----+
| a | b    | c  |
+---+------+----+
| 1 | avro | 10 |
+---+------+----+
DataTypeConsiderationsforAvroTables
TheAvroformatdefinesasetofdatatypeswhosenamesdifferfromthenamesofthecorresponding Impaladata
types.IfyouarepreparingAvrofilesusingotherHadoopcomponen tssuchasPigorMapReduce,youmightneedto
workwiththetypenamesdefinedbyAvro.ThefollowingfigureliststheAvro-definedtypesandtheequivalenttypes
inImpala.
Primitive Types (Avro -> Impala)
--------------------------------
STRING -> STRING
STRING -> CHAR
STRING -> VARCHAR
INT -> INT
BOOLEAN -> BOOLEAN
LONG ->  BIGINT
FLOAT ->  FLOAT
DOUBLE -> DOUBLE
Logical Types
-------------
BYTES + logicalType = "decimal" -> DECIMAL
Avro Types with No Impala Equivalent
------------------------------------
RECORD, MAP, ARRAY, UNION,  ENUM, FIXED, NULL
Impala Types with No Avro Equivalent
------------------------------------
TIMESTAMP
TheAvrospecificationallowsstringvaluesupto2**64bytesinlength.ImpalaqueriesforAvrotablesuse32-bitintegers
toholdstringlengths.InCDH5.7/Impala2.5andhigher,ImpalatruncatesCHARandVARCHAR valuesinAvrotables
to(2**31)-1 bytes.IfaqueryencountersaSTRINGvaluelongerthan(2**31)-1 bytesinanAvrotable,thequeryfails.
Inearlierreleases,encounteringsuchlongvaluesinanAvrotablecouldcauseacrash.
QueryPerformance forImpalaAvroTables
Ingeneral,expectqueryperformance withAvrotablestobefasterthanwithtablesusingtextdata,butslowerthan
withParquettables.SeeUsingtheParquetFileFormatwithImpalaTablesonpage643forinformationaboutusingthe
Parquetfileformatforhigh-performance analyticqueries.
664|ApacheImpalaGuideHowImpalaWorkswithHadoopFileFormats
InCDH5.8/Impala2.6andhigher,ImpalaqueriesareoptimizedforfilesstoredinAmazonS3.ForImpalatablesthat
usethefileformatsParquet,ORC,RCFile,SequenceFile, Avro,anduncompressedtext,thesettingfs.s3a.block.size
inthecore-site.xml configurationfiledetermineshowImpaladividestheI/Oworkofreadingthedatafiles.This
configurationsettingisspecified inbytes.Bydefault,thisvalueis33554432 (32MB),meaningthatImpalaparallelizes
S3readoperationsonthefilesasiftheyweremadeupof32MBblocks.Forexample,ifyourS3queriesprimarily
accessParquetfileswrittenbyMapReduceorHive,increasefs.s3a.block.size to134217728 (128MB)tomatch
therowgroupsizeofthosefiles.IfmostS3queriesinvolveParquetfileswrittenbyImpala,increase
fs.s3a.block.size to268435456 (256MB)tomatchtherowgroupsizeproducedbyImpala.
UsingtheRCFileFileFormatwithImpalaTables
Impalasupports usingRCFiledatafiles.
Table5:RCFileFormatSupportinImpala
ImpalaCanINSERT? ImpalaCanCREATE? CompressionCodecs Format FileType
No.ImportdatabyusingLOAD
DATAondatafilesalreadyintheYes. Snappy,gzip,deflate,
bzip2Structured RCFile
rightformat,oruseINSERTin
HivefollowedbyREFRESH
table_name inImpala.
CreatingRCFileTablesandLoadingData
Ifyoudonothaveanexistingdatafiletouse,beginbycreatingoneintheappropriateformat.
TocreateanRCFiletable:
Intheimpala-shell interpreter,issueacommand similarto:
create table rcfile_table ( column_specs ) stored as rcfile;
BecauseImpalacanquerysomekindsoftablesthatitcannotcurrentlywriteto,aftercreatingtablesofcertainfile
formats,youmightusetheHiveshelltoloadthedata.SeeHowImpalaWorkswithHadoopFileFormatsonpage634
fordetails.AfterloadingdataintoatablethroughHiveorothermechanism outsideofImpala,issueaREFRESH
table_name statementthenexttimeyouconnecttotheImpalanode,beforequeryingthetable,tomakeImpala
recognizethenewdata.
Forexample,hereishowyoumightcreatesomeRCFiletablesinImpala(byspecifyingthecolumnsexplicitly,orcloning
thestructureofanothertable),loaddatathroughHive,andquerythemthroughImpala:
$ impala-shell -i localhost
[localhost:21000] > create table rcfile_table (x int) stored as rcfile;
[localhost:21000] > create table rcfile_clone like some_other_table stored as rcfile;
[localhost:21000] > quit;
$ hive
hive> insert into table rcfile_table select x from some_other_table;
3 Rows loaded to rcfile_table
Time taken: 19.015 seconds
hive> quit;
$ impala-shell -i localhost
[localhost:21000] > select * from rcfile_table;
Returned 0 row(s) in 0.23s
[localhost:21000] > -- Make Impala recognize the data loaded through Hive;
[localhost:21000] > refresh rcfile_table;
[localhost:21000] > select * from rcfile_table;
+---+
| x |
+---+
ApacheImpalaGuide|665HowImpalaWorkswithHadoopFileFormats
| 1 |
| 2 |
| 3 |
+---+
Returned 3 row(s) in 0.23s
Complextypeconsiderations:Although youcancreatetablesinthisfileformatusingthecomplextypes(ARRAY,
STRUCT,andMAP)availableinCDH5.5/Impala2.3andhigher,currently,ImpalacanquerythesetypesonlyinParquet
tables.TheoneexceptiontotheprecedingruleisCOUNT(*) queriesonRCFiletablesthatincludecomplextypes.Such
queriesareallowedinCDH5.8/Impala2.6andhigher.
EnablingCompressionforRCFileTables
Youmaywanttoenablecompressiononexistingtables.Enablingcompressionprovidesperformance gainsinmost
casesandissupportedforRCFiletables.Forexample,toenableSnappycompression,youwouldspecifythefollowing
additional settingswhenloadingdatathroughtheHiveshell:
hive> SET hive.exec.compress.output=true;
hive> SET mapred.max.split.size=256000000;
hive> SET mapred.output.compression.type=BLOCK;
hive> SET mapred.output.compression.codec=org.apache.hadoop.io.compress.SnappyCodec;
hive> INSERT OVERWRITE TABLE new_table  SELECT * FROM old_table ;
Ifyouareconvertingpartitioned tables,youmustcompleteadditional steps.Insuchacase,specifyadditional settings
similartothefollowing:
hive> CREATE TABLE new_table  (your_cols ) PARTITIONED BY ( partition_cols ) STORED AS 
new_format ;
hive> SET hive.exec.dynamic.partition.mode=nonstrict;
hive> SET hive.exec.dynamic.partition=true;
hive> INSERT OVERWRITE TABLE new_table  PARTITION( comma_separated_partition_cols ) SELECT
 * FROM old_table ;
Remember thatHivedoesnotrequirethatyouspecifyasourceformatforit.Consider thecaseofconvertingatable
withtwopartitioncolumnscalledyearandmonthtoaSnappycompressedRCFile.Combining thecomponen tsoutlined
previouslytocompletethistableconversion,youwouldspecifysettingssimilartothefollowing:
hive> CREATE TABLE tbl_rc (int_col INT, string_col STRING) STORED AS RCFILE;
hive> SET hive.exec.compress.output=true;
hive> SET mapred.max.split.size=256000000;
hive> SET mapred.output.compression.type=BLOCK;
hive> SET mapred.output.compression.codec=org.apache.hadoop.io.compress.SnappyCodec;
hive> SET hive.exec.dynamic.partition.mode=nonstrict;
hive> SET hive.exec.dynamic.partition=true;
hive> INSERT OVERWRITE TABLE tbl_rc SELECT * FROM tbl;
Tocompleteasimilarprocessforatablethatincludespartitions, youwouldspecifysettingssimilartothefollowing:
hive> CREATE TABLE tbl_rc (int_col INT, string_col STRING) PARTITIONED BY (year INT) 
STORED AS RCFILE;
hive> SET hive.exec.compress.output=true;
hive> SET mapred.max.split.size=256000000;
hive> SET mapred.output.compression.type=BLOCK;
hive> SET mapred.output.compression.codec=org.apache.hadoop.io.compress.SnappyCodec;
hive> SET hive.exec.dynamic.partition.mode=nonstrict;
hive> SET hive.exec.dynamic.partition=true;
hive> INSERT OVERWRITE TABLE tbl_rc PARTITION(year) SELECT * FROM tbl;
666|ApacheImpalaGuideHowImpalaWorkswithHadoopFileFormats
Note:
Thecompressiontypeisspecified inthefollowingcommand:
SET 
mapred.output.compression.codec=org.apache.hadoop.io.compress.SnappyCodec;
YoucouldelecttospecifyalternativecodecssuchasGzipCodec here.
QueryPerformance forImpalaRCFileTables
Ingeneral,expectqueryperformance withRCFiletablestobefasterthanwithtablesusingtextdata,butslowerthan
withParquettables.SeeUsingtheParquetFileFormatwithImpalaTablesonpage643forinformationaboutusingthe
Parquetfileformatforhigh-performance analyticqueries.
InCDH5.8/Impala2.6andhigher,ImpalaqueriesareoptimizedforfilesstoredinAmazonS3.ForImpalatablesthat
usethefileformatsParquet,ORC,RCFile,SequenceFile, Avro,anduncompressedtext,thesettingfs.s3a.block.size
inthecore-site.xml configurationfiledetermineshowImpaladividestheI/Oworkofreadingthedatafiles.This
configurationsettingisspecified inbytes.Bydefault,thisvalueis33554432 (32MB),meaningthatImpalaparallelizes
S3readoperationsonthefilesasiftheyweremadeupof32MBblocks.Forexample,ifyourS3queriesprimarily
accessParquetfileswrittenbyMapReduceorHive,increasefs.s3a.block.size to134217728 (128MB)tomatch
therowgroupsizeofthosefiles.IfmostS3queriesinvolveParquetfileswrittenbyImpala,increase
fs.s3a.block.size to268435456 (256MB)tomatchtherowgroupsizeproducedbyImpala.
UsingtheSequenceFile FileFormatwithImpalaTables
Impalasupports usingSequenceFile datafiles.
Table6:SequenceFile FormatSupportinImpala
ImpalaCanINSERT? ImpalaCanCREATE? CompressionCodecs Format FileType
No.ImportdatabyusingLOAD
DATAondatafilesalreadyintheYes. Snappy,gzip,deflate,
bzip2Structured SequenceFile
rightformat,oruseINSERTin
HivefollowedbyREFRESH
table_name inImpala.
CreatingSequenceFile TablesandLoadingData
Ifyoudonothaveanexistingdatafiletouse,beginbycreatingoneintheappropriateformat.
TocreateaSequenceFile table:
Intheimpala-shell interpreter,issueacommand similarto:
create table sequencefile_table ( column_specs ) stored as sequencefile;
BecauseImpalacanquerysomekindsoftablesthatitcannotcurrentlywriteto,aftercreatingtablesofcertainfile
formats,youmightusetheHiveshelltoloadthedata.SeeHowImpalaWorkswithHadoopFileFormatsonpage634
fordetails.AfterloadingdataintoatablethroughHiveorothermechanism outsideofImpala,issueaREFRESH
table_name statementthenexttimeyouconnecttotheImpalanode,beforequeryingthetable,tomakeImpala
recognizethenewdata.
ApacheImpalaGuide|667HowImpalaWorkswithHadoopFileFormats
Forexample,hereishowyoumightcreatesomeSequenceFile tablesinImpala(byspecifyingthecolumnsexplicitly,
orcloningthestructureofanothertable),loaddatathroughHive,andquerythemthroughImpala:
$ impala-shell -i localhost
[localhost:21000] > create table seqfile_table (x int) stored as sequencefile;
[localhost:21000] > create table seqfile_clone like some_other_table stored as 
sequencefile;
[localhost:21000] > quit;
$ hive
hive> insert into table seqfile_table select x from some_other_table;
3 Rows loaded to seqfile_table
Time taken: 19.047 seconds
hive> quit;
$ impala-shell -i localhost
[localhost:21000] > select * from seqfile_table;
Returned 0 row(s) in 0.23s
[localhost:21000] > -- Make Impala recognize the data loaded through Hive;
[localhost:21000] > refresh seqfile_table;
[localhost:21000] > select * from seqfile_table;
+---+
| x |
+---+
| 1 |
| 2 |
| 3 |
+---+
Returned 3 row(s) in 0.23s
Complextypeconsiderations:Although youcancreatetablesinthisfileformatusingthecomplextypes(ARRAY,
STRUCT,andMAP)availableinCDH5.5/Impala2.3andhigher,currently,ImpalacanquerythesetypesonlyinParquet
tables.TheoneexceptiontotheprecedingruleisCOUNT(*) queriesonRCFiletablesthatincludecomplextypes.Such
queriesareallowedinCDH5.8/Impala2.6andhigher.
EnablingCompressionforSequenceFile Tables
Youmaywanttoenablecompressiononexistingtables.Enablingcompressionprovidesperformance gainsinmost
casesandissupportedforSequenceFile tables.Forexample,toenableSnappycompression,youwouldspecifythe
followingadditional settingswhenloadingdatathroughtheHiveshell:
hive> SET hive.exec.compress.output=true;
hive> SET mapred.max.split.size=256000000;
hive> SET mapred.output.compression.type=BLOCK;
hive> SET mapred.output.compression.codec=org.apache.hadoop.io.compress.SnappyCodec;
hive> insert overwrite table new_table  select * from old_table ;
Ifyouareconvertingpartitioned tables,youmustcompleteadditional steps.Insuchacase,specifyadditional settings
similartothefollowing:
hive> create table new_table  (your_cols ) partitioned by ( partition_cols ) stored as 
new_format ;
hive> SET hive.exec.dynamic.partition.mode=nonstrict;
hive> SET hive.exec.dynamic.partition=true;
hive> insert overwrite table new_table  partition( comma_separated_partition_cols ) select
 * from old_table ;
Remember thatHivedoesnotrequirethatyouspecifyasourceformatforit.Consider thecaseofconvertingatable
withtwopartitioncolumnscalledyearandmonthtoaSnappycompressedSequenceFile. Combining thecomponen ts
outlinedpreviouslytocompletethistableconversion,youwouldspecifysettingssimilartothefollowing:
hive> create table TBL_SEQ (int_col int, string_col string) STORED AS SEQUENCEFILE;
hive> SET hive.exec.compress.output=true;
hive> SET mapred.max.split.size=256000000;
hive> SET mapred.output.compression.type=BLOCK;
hive> SET mapred.output.compression.codec=org.apache.hadoop.io.compress.SnappyCodec;
668|ApacheImpalaGuideHowImpalaWorkswithHadoopFileFormats
hive> SET hive.exec.dynamic.partition.mode=nonstrict;
hive> SET hive.exec.dynamic.partition=true;
hive> INSERT OVERWRITE TABLE tbl_seq SELECT * FROM tbl;
Tocompleteasimilarprocessforatablethatincludespartitions, youwouldspecifysettingssimilartothefollowing:
hive> CREATE TABLE tbl_seq (int_col INT, string_col STRING) PARTITIONED BY (year INT) 
STORED AS SEQUENCEFILE;
hive> SET hive.exec.compress.output=true;
hive> SET mapred.max.split.size=256000000;
hive> SET mapred.output.compression.type=BLOCK;
hive> SET mapred.output.compression.codec=org.apache.hadoop.io.compress.SnappyCodec;
hive> SET hive.exec.dynamic.partition.mode=nonstrict;
hive> SET hive.exec.dynamic.partition=true;
hive> INSERT OVERWRITE TABLE tbl_seq PARTITION(year) SELECT * FROM tbl;
Note:
Thecompressiontypeisspecified inthefollowingcommand:
SET 
mapred.output.compression.codec=org.apache.hadoop.io.compress.SnappyCodec;
YoucouldelecttospecifyalternativecodecssuchasGzipCodec here.
QueryPerformance forImpalaSequenceFile Tables
Ingeneral,expectqueryperformance withSequenceFile tablestobefasterthanwithtablesusingtextdata,butslower
thanwithParquettables.SeeUsingtheParquetFileFormatwithImpalaTablesonpage643forinformationabout
usingtheParquetfileformatforhigh-performance analyticqueries.
InCDH5.8/Impala2.6andhigher,ImpalaqueriesareoptimizedforfilesstoredinAmazonS3.ForImpalatablesthat
usethefileformatsParquet,ORC,RCFile,SequenceFile, Avro,anduncompressedtext,thesettingfs.s3a.block.size
inthecore-site.xml configurationfiledetermineshowImpaladividestheI/Oworkofreadingthedatafiles.This
configurationsettingisspecified inbytes.Bydefault,thisvalueis33554432 (32MB),meaningthatImpalaparallelizes
S3readoperationsonthefilesasiftheyweremadeupof32MBblocks.Forexample,ifyourS3queriesprimarily
accessParquetfileswrittenbyMapReduceorHive,increasefs.s3a.block.size to134217728 (128MB)tomatch
therowgroupsizeofthosefiles.IfmostS3queriesinvolveParquetfileswrittenbyImpala,increase
fs.s3a.block.size to268435456 (256MB)tomatchtherowgroupsizeproducedbyImpala.
ApacheImpalaGuide|669HowImpalaWorkswithHadoopFileFormats
UsingImpalatoQueryKuduTables
YoucanuseImpalatoquerytablesstoredbyApacheKudu.Thiscapabilityallowsconvenientaccesstoastoragesystem
thatistunedfordifferentkindsofworkloadsthanthedefaultwithImpala.
Bydefault,ImpalatablesarestoredonHDFSusingdatafileswithvariousfileformats.HDFSfilesareidealforbulk
loads(appendoperations)andqueriesusingfull-tablescans,butdonotsupportin-placeupdatesordeletes.Kuduis
analternativestorageengineusedbyImpalawhichcandobothin-placeupdates(formixedread/writeworkloads)
andfastscans(fordata-warehouse/analyticoperations).UsingKudutableswithImpalacansimplifytheETLpipeline
byavoidingextrastepstosegregateandreorganizenewlyarriveddata.
CertainImpalaSQLstatementsandclauses,suchasDELETE,UPDATE,UPSERT,andPRIMARY KEY workonlywith
Kudutables.Otherstatementsandclauses,suchasLOAD DATA ,TRUNCATE TABLE ,andINSERT OVERWRITE ,are
notapplicabletoKudutables.
BenefitsofUsingKuduTableswithImpala
ThecombinationofKuduandImpalaworksbestfortableswherescanperformance isimportant,butdataarrives
continuously,insmallbatches,orneedstobeupdatedwithoutbeingcompletelyreplaced.HDFS-backedtablescan
requiresubstantialoverheadtoreplaceorreorganizedatafilesasnewdataarrives.Impalacanperformefficient
lookupsandscanswithinKudutables,andImpalacanalsoperformupdateordeleteoperationsefficiently.Youcan
alsousetheKuduJava,C++,andPythonAPIstodoingestionortransformationoperationsoutsideofImpala,and
Impalacanquerythecurrentdataatanytime.
ConfiguringImpalaforUsewithKudu
The-kudu_master_hosts configurationpropertymustbesetcorrectlyfortheimpalad daemon,forCREATE TABLE
... STORED AS KUDU statementstoconnecttotheappropriateKuduserver.Typically,therequiredvalueforthis
settingiskudu_host :7051.Inahigh-availabilityKududeployment,specifythenamesofmultipleKuduhostsseparated
bycommas.
Ifthe-kudu_master_hosts configurationpropertyisnotset,youcanstillassociatetheappropriatevalueforeach
tablebyspecifyingaTBLPROPERTIES('kudu.master_addresses') clauseintheCREATE TABLE statementor
changing theTBLPROPERTIES('kudu.master_addresses') valuewithanALTER TABLE statement.
IfyouareusingClouderaManager,foreachImpalaservice,navigatetotheConfigurationtabandspecifytheKudu
serviceyouwanttouseintheKuduServicefield.
ClusterTopologyforKuduTables
WithHDFS-backedtables,youaretypicallyconcerned withthenumberofDataNodesinthecluster,howmanyand
howlargeHDFSdatafilesarereadduringaquery,andthereforetheamountofworkperformedbyeachDataNode
andthenetworkcommunic ationtocombineintermediateresultsandproducethefinalresultset.
WithKudutables,thetopologyconsiderationsaredifferent,because:
â¢Theunderlying storageismanagedandorganizedbyKudu,notrepresentedasHDFSdatafiles.
â¢Kuduhandlessomeoftheunderlying mechanics ofpartitioning thedata.Youcanspecifythepartitioning scheme
withcombinationsofhashandrangepartitioning ,sothatyoucandecidehowmuchefforttoexpendtomanage
thepartitions asnewdataarrives.Forexample,youcanconstructpartitions thatapplytodaterangesratherthan
aseparatepartition foreachdayoreachhour.
â¢Dataisphysicallydividedbasedonunitsofstoragecalledtablets.Tabletsarestoredbytabletservers.Eachtablet
servercanstoremultipletablets,andeachtabletisreplicatedacrossmultipletabletservers,managedautomatically
670|ApacheImpalaGuideUsingImpalatoQueryKuduTables
byKudu.Wherepractical,co-locatethetabletserversonthesamehostsastheImpaladaemons, although that
isnotrequired.
KuduReplicationFactor
Bydefault,KudutablescreatedthroughImpalauseatabletreplicationfactorof3.Tochangethereplicationfactor
foraKudutable,specifythereplicationfactorusingtheTBLPROPERTIESintheCREATETABLEStatementstatement
asbelowwherenisthereplicationfactoryouwanttouse:
TBLPROPERTIES ('kudu.num_tablet_replicas' = ' n')
ThenumberofreplicasforaKudutablemustbeodd.
Alteringthekudu.num_tablet_replicas propertyaftertablecreationcurrentlyhasnoeffect.
ImpalaDDLEnhancemen tsforKuduTables(CREATETABLEandALTERTABLE)
YoucanusetheImpalaCREATE TABLE andALTER TABLE statementstocreateandfine-tune thecharacteristicsof
Kudutables.BecauseKudutableshavefeaturesandpropertiesthatdonotapplytootherkindsofImpalatables,
familiarizeyourselfwithKudu-relatedconceptsandsyntaxfirst.ForthegeneralsyntaxoftheCREATE TABLE statement
forKudutables,seeCREATETABLEStatementonpage234.
PrimaryKeyColumns forKuduTables
KudutablesintroducethenotionofprimarykeystoImpalaforthefirsttime.Theprimarykeyismadeupofoneor
morecolumns,whosevaluesarecombined andusedasalookupkeyduringqueries.Thetuplerepresentedbythese
columnsmustbeuniqueandcannotcontainanyNULLvalues,andcanneverbeupdatedonceinserted.ForaKudu
table,allthepartition keycolumnsmustcomefromthesetofprimarykeycolumns.
Theprimarykeyhasbothphysicalandlogicalaspects:
â¢Onthephysicalside,itisusedtomapthedatavaluestoparticular tabletsforfastretrieval.Becausethetuples
formedbytheprimarykeyvaluesareunique,theprimarykeycolumnsaretypicallyhighlyselective.
â¢Onthelogicalside,theuniqueness constraintallowsyoutoavoidduplicatedatainatable.Forexample,ifan
INSERToperationfailspartwaythrough,onlysomeofthenewrowsmightbepresentinthetable.Youcanre-run
thesameINSERT,andonlythemissingrowswillbeadded.Orifdatainthetableisstale,youcanrunanUPSERT
statementthatbringsthedatauptodate,withoutthepossibility ofcreatingduplicatecopiesofexistingrows.
Note:
ImpalaonlyallowsPRIMARY KEY clausesandNOT NULL constraintsoncolumnsforKudutables.
TheseconstraintsareenforcedontheKuduside.
Kudu-Specific ColumnAttributesforCREATETABLE
ForthegeneralsyntaxoftheCREATE TABLE statementforKudutables,seeCREATETABLEStatementonpage234.
ThefollowingsectionsprovidemoredetailforsomeoftheKudu-specific keywordsyoucanuseincolumndefinitions.
ThecolumnlistinaCREATE TABLE statementcanincludethefollowingattributes,whichonlyapplytoKudutables:
  PRIMARY KEY
| [NOT] NULL
| ENCODING codec
| COMPRESSION algorithm
ApacheImpalaGuide|671UsingImpalatoQueryKuduTables
| DEFAULT constant_expression
| BLOCK_SIZE number
Seethefollowingsectionsfordetailsabouteachcolumnattribute.
PRIMARYKEYAttribute
TheprimarykeyforaKudutableisacolumn,orsetofcolumns,thatuniquelyidentifieseveryrow.Theprimarykey
valuealsoisusedasthenaturalsortorderforthevaluesfromthetable.Theprimarykeyvalueforeachrowisbased
onthecombinationofvaluesforthecolumns.
Becausealloftheprimarykeycolumnsmusthavenon-nullvalues,specifyingacolumninthePRIMARY KEY clause
implicitly addstheNOT NULL attributetothatcolumn.
Theprimarykeycolumnsmustbethefirstonesspecified intheCREATE TABLE statement.Forasingle-columnprimary
key,youcanincludeaPRIMARY KEY attributeinlinewiththecolumndefinition.Foramulti-columnprimarykey,you
includeaPRIMARY KEY ( c1, c2, ...)clauseasaseparateentryattheendofthecolumnlist.
YoucanspecifythePRIMARY KEY attributeeitherinlineinasinglecolumndefinition,orasaseparateclauseatthe
endofthecolumnlist:
CREATE TABLE pk_inline
(
  col1 BIGINT PRIMARY KEY,
  col2 STRING,
  col3 BOOLEAN
) PARTITION BY HASH(col1) PARTITIONS 2 STORED AS KUDU;
CREATE TABLE pk_at_end
(
  col1 BIGINT,
  col2 STRING,
  col3 BOOLEAN,
  PRIMARY KEY (col1)
) PARTITION BY HASH(col1) PARTITIONS 2 STORED AS KUDU;
Whentheprimarykeyisasinglecolumn,thesetwoformsareequivalent.Iftheprimarykeyconsistsofmorethanone
column,youmustspecifytheprimarykeyusingaseparateentryinthecolumnlist:
CREATE TABLE pk_multiple_columns
(
  col1 BIGINT,
  col2 STRING,
  col3 BOOLEAN,
PRIMARY KEY (col1, col2)
) PARTITION BY HASH(col2) PARTITIONS 2 STORED AS KUDU;
TheSHOW CREATE TABLE statementalwaysrepresentsthePRIMARY KEY specificationasaseparateiteminthe
columnlist:
CREATE TABLE inline_pk_rewritten (id BIGINT PRIMARY KEY , s STRING)
  PARTITION BY HASH(id) PARTITIONS 2 STORED AS KUDU;
SHOW CREATE TABLE inline_pk_rewritten;
+------------------------------------------------------------------------------+
| result                                                                       |
+------------------------------------------------------------------------------+
| CREATE TABLE user.inline_pk_rewritten (                                      |
|   id BIGINT NOT NULL ENCODING AUTO_ENCODING COMPRESSION DEFAULT_COMPRESSION, |
|   s STRING NULL ENCODING AUTO_ENCODING COMPRESSION DEFAULT_COMPRESSION,      |
|   PRIMARY KEY (id)                                                            |
| )                                                                            |
| PARTITION BY HASH (id) PARTITIONS 2                                          |
| STORED AS KUDU                                                               |
672|ApacheImpalaGuideUsingImpalatoQueryKuduTables
| TBLPROPERTIES ('kudu.master_addresses'='host.example.com')                   |
+------------------------------------------------------------------------------+
ThenotionofprimarykeyonlyappliestoKudutables.EveryKudutablerequiresaprimarykey.Theprimarykeyconsists
ofoneormorecolumns.Youmustspecifyanyprimarykeycolumnsfirstinthecolumnlist.
ThecontentsoftheprimarykeycolumnscannotbechangedbyanUPDATEorUPSERTstatement.Including toomany
columnsintheprimarykey(morethan5or6)canalsoreducetheperformance ofwriteoperations.Therefore,pick
themostselectiveandmostfrequentlytestednon-nullcolumnsfortheprimarykeyspecification.Ifacolumnmust
alwayshaveavalue,butthatvaluemightchangelater,leaveitoutoftheprimarykeyanduseaNOT NULL clausefor
thatcolumninstead.Ifanexistingrowhasanincorrectoroutdatedkeycolumnvalue,deletetheoldrowandinsert
anentirelynewrowwiththecorrectprimarykey.
NULL|NOTNULLAttribute
ForKudutables,youcanspecifywhichcolumnscancontainnullsornot.Thisconstraintoffersanextralevelof
consistencyenforcementforKudutables.Ifanapplicationrequiresafieldtoalwaysbespecified, includeaNOT NULL
clauseinthecorresponding columndefinition,andKudupreventsrowsfrombeinginsertedwithaNULLinthatcolumn.
Forexample,atablecontaininggeographicinformationmightrequirethelatitudeandlongitude coordinatestoalways
bespecified. OtherattributesmightbeallowedtobeNULL.Forexample,alocationmightnothaveadesignatedplace
name,itsaltitudemightbeunimport ant,anditspopulationmightbeinitiallyunknown,tobefilledinlater.
Becausealloftheprimarykeycolumnsmusthavenon-nullvalues,specifyingacolumninthePRIMARY KEY clause
implicitly addstheNOT NULL attributetothatcolumn.
Fornon-Kudutables,ImpalaallowsanycolumntocontainNULLvalues,becauseitisnotpracticaltoenforceaânot
nullâconstraintonHDFSdatafilesthatcouldbepreparedusingexternaltoolsandETLprocesses.
CREATE TABLE required_columns
(
  id BIGINT PRIMARY KEY,
  latitude DOUBLE NOT NULL,
  longitude DOUBLE NOT NULL,
  place_name STRING,
  altitude DOUBLE,
  population BIGINT
) PARTITION BY HASH(id) PARTITIONS 2 STORED AS KUDU;
Duringperformance optimization,Kuducanusetheknowledgethatnullsarenotallowedtoskipcertaincheckson
eachinputrow,speeding upqueriesandjoinoperations.Therefore,specifyNOT NULL constraintswhenappropriate.
TheNULLclauseisthedefaultconditionforallcolumnsthatarenotpartoftheprimarykey.Youcanomitit,orspecify
ittoclarifythatyouhavemadeaconscious designdecisiontoallownullsinacolumn.
BecauseprimarykeycolumnscannotcontainanyNULLvalues,theNOT NULL clauseisnotrequiredfortheprimary
keycolumns,butyoumightstillspecifyittomakeyourcodeself-describing.
DEFAULTAttribute
YoucanspecifyadefaultvalueforcolumnsinKudutables.Thedefaultvaluecanbeanyconstantexpression,for
example,acombinationofliteralvalues,arithmeticandstringoperations.Itcannotcontainreferencestocolumnsor
non-deterministicfunctioncalls.
ThefollowingexampleshowsdifferentkindsofexpressionsfortheDEFAULT clause.Therequirementtouseaconstant
valuemeansthatyoucanfillinaplaceholder valuesuchasNULL,emptystring,0,-1,'N/A'andsoon,butyoucannot
referencefunctions orcolumnnames.Therefore,youcannotuseDEFAULT todothingssuchasautomaticallymaking
anuppercasecopyofastringvalue,storingBooleanvaluesbasedontestsofothercolumns,oraddorsubtractone
fromanothercolumnrepresentingasequence number.
CREATE TABLE default_vals
ApacheImpalaGuide|673UsingImpalatoQueryKuduTables
(
  id BIGINT PRIMARY KEY,
  name STRING NOT NULL DEFAULT 'unknown',
  address STRING DEFAULT upper('no fixed address'),
  age INT DEFAULT -1,
  earthling BOOLEAN DEFAULT TRUE,
  planet_of_origin STRING DEFAULT 'Earth',
  optional_col STRING DEFAULT NULL
) PARTITION BY HASH(id) PARTITIONS 2 STORED AS KUDU;
Note:
Whendesigning anentirelynewschema,prefertouseNULLastheplaceholder foranyunknownor
missingvalues,becausethatistheuniversalconventionamongdatabasesystems.Nullvaluescanbe
storedefficiently,andeasilycheckedwiththeIS NULL orIS NOT NULL operators.TheDEFAULT
attributeisappropriatewheningestingdatathatalreadyhasanestablishedconventionforrepresenting
unknownormissingvalues,orwherethevastmajorityofrowshavesomecommonnon-nullvalue.
ENCODINGAttribute
EachcolumninaKudutablecanoptionallyuseanencoding,alow-overheadformofcompressionthatreducesthe
sizeondisk,thenrequiresadditional CPUcyclestoreconstructtheoriginalvaluesduringqueries.Typically,highly
compressibledatabenefitsfromthereducedI/Otoreadthedatabackfromdisk.
TheencodingkeywordsthatImpalarecognizesare:
â¢AUTO_ENCODING :usethedefaultencodingbasedonthecolumntype,whicharebitshuffleforthenumerictype
columnsanddictionaryforthestringtypecolumns.
â¢PLAIN_ENCODING :leavethevalueinitsoriginalbinaryformat.
â¢RLE:compressrepeatedvalues(whensortedinprimarykeyorder)byincluding acount.
â¢DICT_ENCODING :whenthenumberofdifferentstringvaluesislow,replacetheoriginalstringwithanumericID.
â¢BIT_SHUFFLE :rearrangethebitsofthevaluestoefficientlycompresssequences ofvaluesthatareidenticalor
varyonlyslightlybasedonprimarykeyorder.TheresultingencodeddataisalsocompressedwithLZ4.
â¢PREFIX_ENCODING :compresscommonprefixesinstringvalues;mainlyforuseinternallywithinKudu.
ThefollowingexampleshowstheImpalakeywordsrepresentingtheencodingtypes.(TheImpalakeywordsmatchthe
symbolicnamesusedwithinKudu.)Forusageguidelines onthedifferentkindsofencoding,seetheKududocumen tation.
TheDESCRIBE outputshowshowtheencodingisreportedafterthetableiscreated,andthatomittingtheencoding
(inthiscase,fortheIDcolumn)isthesameasspecifyingDEFAULT_ENCODING .
CREATE TABLE various_encodings
(
  id BIGINT PRIMARY KEY,
  c1 BIGINT ENCODING PLAIN_ENCODING,
  c2 BIGINT ENCODING AUTO_ENCODING,
  c3 TINYINT ENCODING BIT_SHUFFLE,
  c4 DOUBLE ENCODING BIT_SHUFFLE,
  c5 BOOLEAN ENCODING RLE,
  c6 STRING ENCODING DICT_ENCODING,
  c7 STRING ENCODING PREFIX_ENCODING
) PARTITION BY HASH(id) PARTITIONS 2 STORED AS KUDU;
-- Some columns are omitted from the output for readability.
describe various_encodings;
+------+---------+-------------+----------+-----------------+
| name | type    | primary_key | nullable | encoding        |
+------+---------+-------------+----------+-----------------+
| id   | bigint  | true        | false    | AUTO_ENCODING   |
674|ApacheImpalaGuideUsingImpalatoQueryKuduTables
| c1   | bigint  | false       | true     | PLAIN_ENCODING  |
| c2   | bigint  | false       | true     | AUTO_ENCODING   |
| c3   | tinyint | false       | true     | BIT_SHUFFLE     |
| c4   | double  | false       | true     | BIT_SHUFFLE     |
| c5   | boolean | false       | true     | RLE             |
| c6   | string  | false       | true     | DICT_ENCODING   |
| c7   | string  | false       | true     | PREFIX_ENCODING |
+------+---------+-------------+----------+-----------------+
COMPRESSIONAttribute
YoucanspecifyacompressionalgorithmtouseforeachcolumninaKudutable.ThisattributeimposesmoreCPU
overheadwhenretrievingthevaluesthantheENCODING attributedoes.Therefore,useitprimarily forcolumnswith
longstringsthatdonotbenefitmuchfromtheless-expensiveENCODING attribute.
ThechoicesforCOMPRESSION areLZ4,SNAPPY,andZLIB.
Note:
Columns thatusetheBITSHUFFLE encodingarealreadycompressedusingLZ4,andsotypicallydo
notneedanyadditional COMPRESSION attribute.
ThefollowingexampleshowsdesignconsiderationsforseveralSTRINGcolumnswithdifferentdistributioncharacteristics,
leadingtochoicesforboththeENCODING andCOMPRESSION attributes.Thecountry valuescomefromaspecificset
ofstrings,thereforethiscolumnisagoodcandidatefordictionaryencoding.Thepost_id columncontainsanascending
sequence ofintegers,whereseveralleadingbitsarelikelytobeallzeroes,thereforethiscolumnisagoodcandidate
forbitshuffleencoding.Thebodycolumnandthecorresponding columnsfortranslatedversionstendtobelongunique
stringsthatarenotpracticaltousewithanyoftheencodingschemes, thereforetheyemploytheCOMPRESSION
attributeinstead.Theidealcompressioncodecineachcasewouldrequiresomeexperimen tationtodeterminehow
muchspacesavingsitprovidedandhowmuchCPUoverheaditadded,basedonreal-worlddata.
CREATE TABLE blog_posts
(
  user_id STRING ENCODING DICT_ENCODING,
  post_id BIGINT ENCODING BIT_SHUFFLE,
  subject STRING ENCODING PLAIN_ENCODING,
  body STRING COMPRESSION LZ4,
  spanish_translation STRING COMPRESSION SNAPPY,
  esperanto_translation STRING COMPRESSION ZLIB,
  PRIMARY KEY (user_id, post_id)
) PARTITION BY HASH(user_id, post_id) PARTITIONS 2 STORED AS KUDU;
BLOCK_SIZE Attribute
Although KududoesnotuseHDFSfilesinternally,andthusisnotaffectedbytheHDFSblocksize,itdoeshavean
underlying unitofI/Ocalledtheblocksize.TheBLOCK_SIZE attributeletsyousettheblocksizeforanycolumn.
Note:Theblocksizeattributeisarelativelyadvancedfeature.Thisisanunsupport edfeatureandis
consideredexperimen tal.
Partitioning forKuduTables
Kudutablesusespecialmechanisms todistributedataamongtheunderlying tabletservers.Although werefertosuch
tablesaspartitioned tables,theyaredistinguished fromtraditionalImpalapartitioned tablesbyuseofdifferentclauses
ontheCREATE TABLE statement.KudutablesusePARTITION BY ,HASH,RANGE,andrangespecificationclauses
ratherthanthePARTITIONED BY clauseforHDFS-backedtables,whichspecifiesonlyacolumnnameandcreatesa
newpartition foreachdifferentvalue.
ApacheImpalaGuide|675UsingImpalatoQueryKuduTables
ForbackgroundinformationandarchitecturaldetailsabouttheKudupartitioning mechanism, seetheKuduwhite
paper,section3.2.
Note:
TheImpalaDDLsyntaxforKudutablesisdifferentthaninearlyKuduversions,whichusedan
experimen talforkoftheImpalacode.Forexample,theDISTRIBUTE BY clauseisnowPARTITION
BY,theINTO n BUCKETS clauseisnowPARTITIONS nandtherangepartitioning syntaxisreworked
toreplacetheSPLIT ROWS clausewithmoreexpressivesyntaxinvolvingcomparison operators.
HashPartitioning
Hashpartitioning isthesimplesttypeofpartitioning forKudutables.Forhash-partitioned Kudutables,insertedrows
aredividedupbetweenafixednumberofâbucketsâbyapplyingahashfunctiontothevaluesofthecolumnsspecified
intheHASHclause.Hashingensuresthatrowswithsimilarvaluesareevenlydistributed,insteadofclumping together
allinthesamebucket.Spreadingnewrowsacrossthebucketsthiswayletsinsertion operationsworkinparallelacross
multipletabletservers.Separatingthehashedvaluescanimposeadditional overheadonqueries,wherequerieswith
range-basedpredicatesmighthavetoreadmultipletabletstoretrievealltherelevantvalues.
-- 1M rows with 50 hash partitions = approximately 20,000 rows per partition.
-- The values in each partition are not sequential, but rather based on a hash function.
-- Rows 1, 99999, and 123456 might be in the same partition.
CREATE TABLE million_rows (id string primary key, s string)
  PARTITION BY HASH(id) PARTITIONS 50
  STORED AS KUDU;
-- Because the ID values are unique, we expect the rows to be roughly
-- evenly distributed between the buckets in the destination table.
INSERT INTO million_rows SELECT * FROM billion_rows ORDER BY id LIMIT 1e6;
Note:
ThelargestnumberofbucketsthatyoucancreatewithaPARTITIONS clausevariesdepending on
thenumberoftabletserversinthecluster,whilethesmallestis2.Forsimplicity ,someofthesimple
CREATE TABLE statementsthroughoutthissectionusePARTITIONS 2 toillustratetheminimum
requirementsforaKudutable.Forlargetables,prefertouseroughly10partitions perserverinthe
cluster.
RangePartitioning
Rangepartitioning letsyouspecifypartitioning precisely,basedonsinglevaluesorrangesofvalueswithinoneormore
columns.YouaddoneormoreRANGEclausestotheCREATE TABLE statement,followingthePARTITION BY clause.
Range-partitioned Kudutablesuseoneormorerangeclauses,whichincludeacombinationofconstantexpressions,
VALUEorVALUESkeywords,andcomparison operators.(ThissyntaxreplacestheSPLIT ROWS clauseusedwithearly
Kuduversions.)Forthefullsyntax,seeCREATETABLEStatementonpage234.
-- 50 buckets, all for IDs beginning with a lowercase letter.
-- Having only a single range enforces the allowed range of values
-- but does not add any extra parallelism.
create table million_rows_one_range (id string primary key, s string)
  partition by hash(id) partitions 50,
  range (partition 'a' <= values < '{')
  stored as kudu;
-- 50 buckets for IDs beginning with a lowercase letter
-- plus 50 buckets for IDs beginning with an uppercase letter.
-- Total number of buckets = number in the PARTITIONS clause x number of ranges.
-- We are still enforcing constraints on the primary key values
676|ApacheImpalaGuideUsingImpalatoQueryKuduTables
-- allowed in the table, and the 2 ranges provide better parallelism
-- as rows are inserted or the table is scanned.
create table million_rows_two_ranges (id string primary key, s string)
  partition by hash(id) partitions 50,
  range (partition 'a' <= values < '{', partition 'A' <= values < '[')
  stored as kudu;
-- Same as previous table, with an extra range covering the single key value '00000'.
create table million_rows_three_ranges (id string primary key, s string)
  partition by hash(id) partitions 50,
  range (partition 'a' <= values < '{', partition 'A' <= values < '[', partition value
 = '00000')
  stored as kudu;
-- The range partitioning can be displayed with a SHOW command in impala-shell.
show range partitions million_rows_three_ranges;
+---------------------+
| RANGE (id)          |
+---------------------+
| VALUE = "00000"     |
| "A" <= VALUES < "[" |
| "a" <= VALUES < "{" |
+---------------------+
Note:
Whendefiningranges,becarefultoavoidâfenceposterrorsâwherevaluesattheextremeendsmight
beincludedoromittedbyaccident.Forexample,inthetablesdefinedintheprecedingcodelistings,
therange "a" <= VALUES < "{" ensuresthatanyvaluesstartingwithz,suchaszaorzzzor
zzz-ZZZ ,areallincluded, byusingaless-than operatorforthesmallestvalueafterallthevalues
startingwithz.
Forrange-partitioned Kudutables,anappropriaterangemustexistbeforeadatavaluecanbecreatedinthetable.
AnyINSERT,UPDATE,orUPSERTstatementsfailiftheytrytocreatecolumnvaluesthatfalloutsidethespecified
ranges.Theerrorchecking forrangesisperformedontheKuduside;Impalapassesthespecified rangeinformation
toKudu,andpassesbackanyerrororwarningiftherangesarenotvalid.(Anonsensic alrangespecificationcausesan
errorforaDDLstatement,butonlyawarningforaDMLstatement.)
Rangescanbenon-contiguous:
partition by range (year) (partition 1885 <= values <= 1889, partition 1893 <= values 
<= 1897)
partition by range (letter_grade) (partition value = 'A', partition value = 'B',
  partition value = 'C', partition value = 'D', partition value = 'F')
TheALTER TABLE statementwiththeADD PARTITION orDROP PARTITION clausescanbeusedtoaddorremove
rangesfromanexistingKudutable.
ALTER TABLE foo ADD PARTITION 30 <= VALUES < 50;
ALTER TABLE foo DROP PARTITION 1 <= VALUES < 5;
Whenarangeisadded,thenewrangemustnotoverlapwithanyofthepreviousranges;thatis,itcanonlyfillingaps
withinthepreviousranges.
alter table test_scores add range partition value = 'E';
ApacheImpalaGuide|677UsingImpalatoQueryKuduTables
alter table year_ranges add range partition 1890 <= values < 1893;
Whenarangeisremoved,alltheassociatedrowsinthetablearedeleted.(Thisistruewhetherthetableisinternal
orexternal.)
alter table test_scores drop range partition value = 'E';
alter table year_ranges drop range partition 1890 <= values < 1893;
Kudutablescanalsouseacombinationofhashandrangepartitioning.
partition by hash (school) partitions 10,
  range (letter_grade) (partition value = 'A', partition value = 'B',
    partition value = 'C', partition value = 'D', partition value = 'F')
WorkingwithPartitioning inKuduTables
Toseethecurrentpartitioning schemeforaKudutable,youcanusetheSHOW CREATE TABLE statementortheSHOW
PARTITIONS statement.TheCREATE TABLE syntaxdisplayedbythisstatementincludesallthehash,range,orboth
clausesthatreflecttheoriginaltablestructureplusanysubsequentALTER TABLE statementsthatchangedthetable
structure.
Toseetheunderlying bucketsandpartitions foraKudutable,usetheSHOW TABLE STATS orSHOW PARTITIONS
statement.
Handling Date,Time,orTimestampDatawithKudu
InCDH5.12/Impala2.9andhigher,youcanincludeTIMESTAMP columnsinKudutables,insteadofrepresentingthe
dateandtimeasaBIGINTvalue.ThebehaviorofTIMESTAMP forKudutableshassomespecialconsiderations:
â¢Anynanosecondsintheoriginal96-bitvalueproducedbyImpalaarenotstored,becauseKudurepresentsdate/time
columnsusing64-bitvalues.Thenanosecondportionofthevalueisrounded,nottruncated.Therefore,a
TIMESTAMP valuethatyoustoreinaKudutablemightnotbebit-for-bitidenticaltothevaluereturnedbyaquery.
â¢TheconversionbetweentheImpala96-bitrepresentationandtheKudu64-bitrepresentationintroducessome
performance overheadwhenreadingorwritingTIMESTAMP columns.Youcanminimizetheoverheadduring
writesbyperforminginsertsthroughtheKuduAPI.Becausetheoverheadduringreadsappliestoeachquery,you
mightcontinuetouseaBIGINTcolumntorepresentdate/timevaluesinperformance-critic alapplications.
â¢TheImpalaTIMESTAMP typehasanarrowerrangeforyearsthantheunderlying Kududatatype.Impalacan
representyears1400-9999. IfyearvaluesoutsidethisrangearewrittentoaKudutablebyanon-Impala client,
ImpalareturnsNULLbydefaultwhenreadingthoseTIMESTAMP valuesduringaquery.Or,iftheABORT_ON_ERROR
queryoptionisenabled, thequeryfailswhenitencountersavaluewithanout-of-rangeyear.
--- Make a table representing a date/time value as TIMESTAMP.
-- The strings representing the partition bounds are automatically
-- cast to TIMESTAMP values.
create table native_timestamp(id bigint, when_exactly timestamp, event string, primary
 key (id, when_exactly))
  partition by hash (id) partitions 20,
  range (when_exactly)
  (
    partition '2015-01-01' <= values < '2016-01-01',
    partition '2016-01-01' <= values < '2017-01-01',
    partition '2017-01-01' <= values < '2018-01-01'
  )
  stored as kudu;
678|ApacheImpalaGuideUsingImpalatoQueryKuduTables
insert into native_timestamp values (12345, now(), 'Working on doc examples');
select * from native_timestamp;
+-------+-------------------------------+-------------------------+
| id    | when_exactly                  | event                   |
+-------+-------------------------------+-------------------------+
| 12345 | 2017-05-31 16:27:42.667542000 | Working on doc examples |
+-------+-------------------------------+-------------------------+
BecauseKudutableshavesomeperformance overheadtoconvertTIMESTAMP columnstotheImpala96-bitinternal
representation,forperformance-critic alapplicationsyoumightstoredate/timeinformationasthenumberofseconds,
milliseconds,ormicrosecondssincetheUnixepochdateofJanuary1,1970.SpecifythecolumnasBIGINTinthe
ImpalaCREATE TABLE statement,corresponding toan8-byteinteger(anint64)intheunderlying Kudutable).Then
useImpaladate/timeconversionfunctions asnecessarytoproduceanumeric,TIMESTAMP ,orSTRINGvaluedepending
onthecontext.
Forexample,theunix_timestamp() functionreturnsanintegerresultrepresentingthenumberofsecondspastthe
epoch.Thenow()functionproducesaTIMESTAMP representingthecurrentdateandtime,whichcanbepassedas
anargumenttounix_timestamp() .Andstringliteralsrepresentingdatesanddate/timescanbecasttoTIMESTAMP ,
andfromthereconvertedtonumericvalues.Thefollowingexamplesshowhowyoumightstoreadate/timecolumn
asBIGINTinaKudutable,butstillusestringliteralsandTIMESTAMP valuesforconvenience.
-- now() returns a TIMESTAMP and shows the format for string literals you can cast to 
TIMESTAMP.
select now();
+-------------------------------+
| now()                         |
+-------------------------------+
| 2017-01-25 23:50:10.132385000 |
+-------------------------------+
-- unix_timestamp() accepts either a TIMESTAMP or an equivalent string literal.
select unix_timestamp(now());
+------------------+
| unix_timestamp() |
+------------------+
| 1485386670       |
+------------------+
select unix_timestamp('2017-01-01');
+------------------------------+
| unix_timestamp('2017-01-01') |
+------------------------------+
| 1483228800                   |
+------------------------------+
-- Make a table representing a date/time value as BIGINT.
-- Construct 1 range partition and 20 associated hash partitions for each year.
-- Use date/time conversion functions to express the ranges as human-readable dates.
create table time_series(id bigint, when_exactly bigint, event string, primary key (id,
 when_exactly))
  partition by hash (id) partitions 20,
  range (when_exactly)
  (
    partition unix_timestamp('2015-01-01') <= values < unix_timestamp('2016-01-01'),
    partition unix_timestamp('2016-01-01') <= values < unix_timestamp('2017-01-01'),
    partition unix_timestamp('2017-01-01') <= values < unix_timestamp('2018-01-01')
  )
  stored as kudu;
-- On insert, we can transform a human-readable date/time into a numeric value.
insert into time_series values (12345, unix_timestamp('2017-01-25 23:24:56'), 'Working
 on doc examples');
-- On retrieval, we can examine the numeric date/time value or turn it back into a string
 for readability.
select id, when_exactly, from_unixtime(when_exactly) as 'human-readable date/time', 
ApacheImpalaGuide|679UsingImpalatoQueryKuduTables
event
  from time_series order by when_exactly limit 100;
+-------+--------------+--------------------------+-------------------------+
| id    | when_exactly | human-readable date/time | event                   |
+-------+--------------+--------------------------+-------------------------+
| 12345 | 1485386696   | 2017-01-25 23:24:56      | Working on doc examples |
+-------+--------------+--------------------------+-------------------------+
Note:
Ifyoudohigh-precisionarithmeticinvolvingnumericdate/timevalues,whendividingmillisecond
valuesby1000,ormicrosecondvaluesby1million,alwayscasttheintegernumeratortoaDECIMAL
withsufficientprecisionandscaletoavoidanyroundingorlossofprecision.
-- 1 million and 1 microseconds = 1.000001 seconds.
select microseconds,
  cast (microseconds as decimal(20,7)) / 1e6 as fractional_seconds
  from table_with_microsecond_column;
+--------------+----------------------+
| microseconds | fractional_seconds   |
+--------------+----------------------+
| 1000001      | 1.000001000000000000 |
+--------------+----------------------+
HowImpalaHandlesKuduMetadata
Note:ThissectiononlyappliestheKuduservicesthatarenotintegratedwiththeHiveMetastore
(HMS).
Bydefault,muchofthemetadataforKudutablesishandledbytheunderlying storagelayer.Kudutableshaveless
relianceontheMetastoredatabase,andrequirelessmetadatacachingontheImpalaside.Forexample,information
aboutpartitions inKudutablesismanagedbyKudu,andImpaladoesnotcacheanyblocklocalitymetadataforKudu
tables.IftheKuduserviceisnotintegratedwiththeHiveMetastore,ImpalawillmanageKudutablemetadatainthe
HiveMetastore.
TheREFRESH andINVALIDATE METADATA statementsareneededlessfrequentlyforKudutablesthanforHDFS-backed
tables.Neitherstatementisneededwhendataisaddedto,removed,orupdatedinaKudutable,evenifthechanges
aremadedirectlytoKuduthroughaclientprogramusingtheKuduAPI.RunREFRESH table_name orINVALIDATE
METADATA table_name foraKudutableonlyaftermakingachangetotheKudutableschema,suchasaddingor
droppingacolumn.
BecauseKudumanagesthemetadataforitsowntablesseparatelyfromthemetastoredatabase,thereisatablename
storedinthemetastoredatabaseforImpalatouse,andatablenameontheKuduside,andthesenamescanbe
modified independen tlythroughALTER TABLE statements.
Toavoidpotentialnameconflicts,theprefiximpala:: andtheImpaladatabasenameareencodedintotheunderlying
Kudutablename:
create database some_database;
use some_database;
create table table_name_demo (x int primary key, y int)
  partition by hash (x) partitions 2 stored as kudu;
describe formatted table_name_demo;
...
680|ApacheImpalaGuideUsingImpalatoQueryKuduTables
kudu.table_name  | impala::some_database.table_name_demo
SeeKuduTablesonpage198forexamplesofhowtochangethenameoftheImpalatableinthemetastoredatabase,
thenameoftheunderlying Kudutable,orboth.
WorkingwithKuduIntegratedwithHiveMetastore
StartingfromKudu1.10andImpala3.3inCDH6.3,Impalasupports KuduservicesintegratedwiththeHiveMetastore
(HMS).SeetheHMSintegrationdocumen tationformoredetailsonKuduâsHiveMetastoreintegration.
ThefollowingaresomeofthechangesyouneedtoconsiderwhenworkingwithKuduservicesintegratedwiththe
HMS.
â¢WhenKuduisintegratedwiththeHiveMetastore,ImpalamustbeconfiguredtousethesameHMSasKudu.
â¢Sincetheremaybenoone-to-onemapping betweenKudutablesandexternaltables,onlyinternaltablesare
automaticallysynchronized.
â¢WhenyoucreateatableinKudu,KuduwillcreateanHMSentryforthattablewiththeinternaltabletype.
â¢WhentheKuduserviceisintegratedwiththeHMS,internaltableentrieswillbecreatedautomaticallyintheHMS
whentablesarecreatedinKuduwithoutImpala.ToaccessthesetablesthroughImpala,runINVALIDATE
METADATA statementsoImpalapicksupthelatestmetadata.
LoadingDataintoKuduTables
Kudutablesarewell-suitedtousecaseswheredataarrivescontinuously,insmallormoderatevolumes.Tobringdata
intoKudutables,usetheImpalaINSERTandUPSERTstatements.TheLOAD DATA statementdoesnotapplytoKudu
tables.
BecauseKudumanagesitsownstoragelayerthatisoptimizedforsmallerblocksizesthanHDFS,andperformsitsown
housekeepingtokeepdataevenlydistributed,itisnotsubjecttotheâmanysmallfilesâissueanddoesnotneedexplicit
reorganizationandcompaction asthedatagrowsovertime.Thepartitions withinaKudutablecanbespecified to
coveravarietyofpossibledatadistributions, insteadofhardcodinganewpartitionforeachnewday,hour,andsoon,
whichcanleadtoinefficient,hard-to-scale,andhard-to-managepartition schemeswithHDFStables.
YourstrategyforperformingETLorbulkupdatesonKudutablesshouldtakeintoaccountthelimitationsonconsistency
forDMLoperations.
MakeINSERT,UPDATE,andUPSERToperationsidempotent:thatis,abletobeappliedmultipletimesandstillproduce
anidenticalresult.
Ifabulkoperationisindangerofexceedingcapacitylimitsduetotimeouts orhighmemoryusage,splititintoaseries
ofsmalleroperations.
AvoidrunningconcurrentETLoperationswheretheendresultsdependonpreciseordering.Inparticular ,donotrely
onanINSERT ... SELECT statementthatselectsfromthesametableintowhichitisinserting,unlessyouinclude
extraconditions intheWHEREclausetoavoidreadingthenewlyinsertedrowswithinthesamestatement.
BecauserelationshipsbetweentablescannotbeenforcedbyImpalaandKudu,andcannotbecommittedorrolled
backtogether,donotexpecttransactional semanticsformulti-tableoperations.
ImpalaDMLSupportforKuduTables(INSERT,UPDATE,DELETE,UPSERT)
Impalasupports certainDMLstatementsforKudutablesonly.TheUPDATEandDELETEstatementsletyoumodify
datawithinKudutableswithoutrewritingsubstantialamountsoftabledata.TheUPSERTstatementactsasacombination
ofINSERTandUPDATE,inserting rowswheretheprimarykeydoesnotalreadyexist,andupdatingthenon-primar y
keycolumnswheretheprimarykeydoesalreadyexistinthetable.
ApacheImpalaGuide|681UsingImpalatoQueryKuduTables
TheINSERTstatementforKudutableshonorstheuniqueandNOT NULL requirementsfortheprimarykeycolumns.
BecauseImpalaandKududonotsupporttransactions, theeffectsofanyINSERT,UPDATE,orDELETEstatementare
immediatelyvisible.Forexample,youcannotdoasequence ofUPDATEstatementsandonlymakethechangesvisible
afterallthestatementsarefinished.Also,ifaDMLstatementfailspartwaythrough,anyrowsthatwerealready
inserted,deleted,orchangedremaininthetable;thereisnorollbackmechanism toundothechanges.
Inparticular ,anINSERT ... SELECT statementthatreferstothetablebeinginsertedintomightinsertmorerows
thanexpected,becausetheSELECTpartofthestatementseessomeofthenewrowsbeinginsertedandprocesses
themagain.
Note:
TheLOAD DATA statement,whichinvolvesmanipula tionofHDFSdatafiles,doesnotapplytoKudu
tables.
StartingfromCDH5.12/Impala2.9,theINSERTorUPSERToperationsintoKudutablesautomaticallyaddanexchange
andasortnodetotheplanthatpartitions andsortstherowsaccordingtothepartitioning /primarykeyschemeofthe
targettable(unlessthenumberofrowstobeinsertedissmallenoughtotriggersinglenodeexecution). SinceKudu
partitions andsortsrowsonwrite,pre-partitioning andsortingtakessomeoftheloadoffofKuduandhelpslarge
INSERToperationstocompletewithouttimingout.However,thisdefaultbehaviormayslowdowntheend-to-end
performance oftheINSERTorUPSERToperations.StartingfromCDH5.13/Impala2.10,youcanusethe /*
+NOCLUSTERED */ and/* +NOSHUFFLE */ hintstogethertodisablepartitioning andsortingbeforetherowsare
senttoKudu.Additionally ,sincesortingmayconsumealargeamountofmemory,considersettingtheMEM_LIMIT
queryoptionforthosequeries.
ConsistencyConsiderationsforKuduTables
Kudutableshaveconsistencycharacteristicssuchasuniqueness, controlledbytheprimarykeycolumns,andnon-nullable
columns.Theemphasis forconsistencyisonpreventingduplicateorincompletedatafrombeingstoredinatable.
Currently,Kududoesnotenforcestrongconsistencyfororderofoperations,totalsuccessortotalfailureofamulti-row
statement,ordatathatisreadwhileawriteoperationisinprogress.Changesareappliedatomicallytoeachrow,but
notappliedasasingleunittoallrowsaffectedbyamulti-rowDMLstatement.Thatis,Kududoesnotcurrentlyhave
atomicmulti-rowstatementsorisolationbetweenstatements.
IfsomerowsarerejectedduringaDMLoperationbecauseofamismatchwithduplicateprimarykeyvalues,NOT NULL
constraints,andsoon,thestatementsucceeds withawarning.Impalastillinserts,deletes,orupdatestheotherrows
thatarenotaffectedbytheconstraintviolation.
Consequen tly,thenumberofrowsaffectedbyaDMLoperationonaKudutablemightbedifferentthanyouexpect.
Becausethereisnostrongconsistencyguaranteeforinformationbeinginsertedinto,deletedfrom,orupdatedacross
multipletablessimultaneously,considerdenormalizing thedatawherepractical.Thatis,ifyourunseparateINSERT
statementstoinsertrelatedrowsintotwodifferenttables,oneINSERTmightfailwhiletheothersucceeds, leaving
thedatainaninconsistentstate.Evenifbothinsertssucceed, ajoinquerymighthappenduringtheintervalbetween
thecompletionofthefirstandsecondstatements,andthequerywouldencounterincompleteinconsistentdata.
Denormalizing thedataintoasinglewidetablecanreducethepossibility ofinconsistencyduetomulti-tableoperations.
InformationaboutthenumberofrowsaffectedbyaDMLoperationisreportedinimpala-shell output,andinthe
PROFILE output,butisnotcurrentlyreportedtoHiveServer2clientssuchasJDBCorODBCapplications.
SecurityConsiderationsforKuduTables
SecurityforKudutablesinvolves:
â¢Sentryauthorization.
682|ApacheImpalaGuideUsingImpalatoQueryKuduTables
AccesstoKudutablesmustbegrantedtoandrevokedfromroleswiththefollowingconsiderations:
â¢OnlyuserswiththeALLprivilegeonSERVERcancreateexternalKudutables.
â¢TheALLprivilegesonSERVERisrequiredtospecifythekudu.master_addresses propertyintheCREATE
TABLEstatementsformanagedtablesaswellasexternaltables.
â¢AccesstoKudutablesisenforcedatthetablelevelandatthecolumnlevel.
â¢TheSELECT-andINSERT-specificpermissions aresupported.
â¢TheDELETE,UPDATE,andUPSERToperationsrequiretheALLprivilege.
Becausenon-SQLAPIscanaccessKududatawithoutgoingthroughSentryauthorization,currentlytheSentry
supportisconsideredpreliminaryandsubjecttochange.
â¢Kerberosauthentication.Seefordetails.
â¢TLSencryption.Seefordetails.
â¢Lineagetracking.
â¢Auditing.
â¢Redaction ofsensitiveinformationfromlogfiles.
ImpalaQueryPerformance forKuduTables
ForqueriesinvolvingKudutables,ImpalacandelegatemuchoftheworkoffilteringtheresultsettoKudu,avoiding
someoftheI/OinvolvedinfulltablescansoftablescontainingHDFSdatafiles.Thistypeofoptimizationisespecially
effectiveforpartitioned Kudutables,wheretheImpalaqueryWHEREclausereferstooneormoreprimarykeycolumns
thatarealsousedaspartition keycolumns.Forexample,ifapartitioned KudutableusesaHASHclauseforcol1and
aRANGEclauseforcol2,aqueryusingaclausesuchasWHERE col1 IN (1,2,3) AND col2 > 100 candetermine
exactlywhichtabletserverscontainrelevantdata,andthereforeparallelizethequeryveryefficiently.
InCDH5.14/Impala2.11andhigher,Impalacanpushdownadditional informationtooptimizejoinqueriesinvolving
Kudutables.Ifthejoinclausecontainspredicatesoftheformcolumn = expression ,afterImpalaconstructsahash
tableofpossiblematchingvaluesforthejoincolumnsfromthebiggertable(eitheranHDFStableoraKudutable),
Impalacanâpushdownâtheminimum andmaximummatchingcolumnvaluestoKudu,sothatKuducanmoreefficiently
locatematchingrowsinthesecond(smaller)table.Thesemin/maxfiltersareaffectedbytheRUNTIME_FILTER_MODE ,
RUNTIME_FILTER_WAIT_TIME_MS ,andDISABLE_ROW_RUNTIME_FILTERING queryoptions;themin/maxfilters
arenotaffectedbytheRUNTIME_BLOOM_FILTER_SIZE ,RUNTIME_FILTER_MIN_SIZE ,RUNTIME_FILTER_MAX_SIZE ,
andMAX_NUM_RUNTIME_FILTERS queryoptions.
SeeEXPLAINStatementonpage271forexamplesofevaluatingtheeffectivenessofthepredicatepushdownfora
specificqueryagainstaKudutable.
TheTABLESAMPLE clauseoftheSELECTstatementdoesnotapplytoatablereferencederivedfromaview,asubquery,
oranythingotherthanarealbasetable.ThisclauseonlyworksfortablesbackedbyHDFSorHDFS-likedatafiles,
thereforeitdoesnotapplytoKuduorHBasetables.
ApacheImpalaGuide|683UsingImpalatoQueryKuduTables
UsingImpalatoQueryHBaseTables
YoucanuseImpalatoqueryHBasetables.Thisisusefulforaccessing anyofyourexistingHBasetablesviaSQLand
performinganalyticsoverthem.HDFSandKudutablesarepreferredoverHBaseforanalyticworkloadsandoffer
superiorperformance. Kudusupports efficientinserts,updatesanddeletesofsmallnumbersofrowsandcanreplace
HBaseformostanalytics-orien tedusecases.SeeUsingImpalatoQueryKuduTablesonpage670forinformationon
usingImpalawithKudu.
FromtheperspectiveofanImpalauser,comingfromanRDBMSbackground,HBaseisakindofkey-valuestorewhere
thevalueconsistsofmultiplefields.ThekeyismappedtoonecolumnintheImpalatable,andthevariousfieldsof
thevaluearemappedtotheothercolumnsintheImpalatable.
ForbackgroundinformationonHBase,seetheApacheHBasedocumen tation.ThisisasnapshotoftheApacheHBase
site(including documen tation)forthelevelofHBasethatcomeswithCDH.
OverviewofUsingHBasewithImpala
WhenyouuseImpalawithHBase:
â¢YoucreatethetablesontheImpalasideusingtheHiveshell,becausetheImpalaCREATE TABLE statement
currentlydoesnotsupportcustomSerDesandsomeothersyntaxneededforthesetables:
âYoudesignateitasanHBasetableusingtheSTORED BY
'org.apache.hadoop.hive.hbase.HBaseStorageHandler' clauseontheHiveCREATE TABLE
statement.
âYoumapthesespeciallycreatedtablestocorresponding tablesthatexistinHBase,withtheclause
TBLPROPERTIES("hbase.table.name" = " table_name_in_hbase ")ontheHiveCREATE TABLE
statement.
âSeeExamplesofQueryingHBaseTablesfromImpalaonpage690forafullexample.
â¢Youdefinethecolumncorresponding totheHBaserowkeyasastringwiththe#string keyword,ormapitto
aSTRINGcolumn.
â¢BecauseImpalaandHivesharethesamemetastoredatabase,onceyoucreatethetableinHive,youcanquery
orinsertintoitthroughImpala.(AftercreatinganewtablethroughHive,issuetheINVALIDATE METADATA
statementinimpala-shell tomakeImpalaawareofthenewtable.)
â¢YouissuequeriesagainsttheImpalatables.Forefficientqueries,useWHEREclausetofindasinglekeyvalueora
rangeofkeyvalueswhereverpractical,bytestingtheImpalacolumncorresponding totheHBaserowkey.Avoid
queriesthatdofull-tablescans,whichareefficientforregularImpalatablesbutinefficientinHBase.
ToworkwithanHBasetablefromImpala,ensurethattheimpalauserhasread/writeprivilegesfortheHBasetable,
usingtheGRANTcommand intheHBaseshell.FordetailsaboutHBasesecurity,seetheSecuritychapterintheApache
HBasedocumen tation.
ConfiguringHBaseforUsewithImpala
HBaseworksoutoftheboxwithImpala.Thereisnomandatoryconfigurationneededtousethesetwocomponen ts
together.
ToavoiddelaysifHBaseisunavailableduringImpalastartuporafteranINVALIDATE METADATA statement,set
timeoutvaluessimilartothefollowingin/etc/impala/conf/hbase-site.xml (forenvironmentsnotmanaged
byClouderaManager):
<property>
  <name>hbase.client.retries.number</name>
  <value>3</value>
684|ApacheImpalaGuideUsingImpalatoQueryHBaseTables
</property>
<property>
  <name>hbase.rpc.timeout</name>
  <value>3000</value>
</property>
Currently,ClouderaManagerdoesnothaveanImpala-only overrideforHBasesettings,soanyHBaseconfiguration
changeyoumakethroughClouderaManagerwouldtakeaffectforallHBaseapplications.Therefore,thischangeis
notrecommended onsystemsmanagedbyClouderaManager.
SupportedDataTypesforHBaseColumns
TounderstandhowImpalacolumndatatypesaremappedtofieldsinHBase,youshouldhavesomebackground
knowledgeaboutHBasefirst.Yousetupthemapping byrunningtheCREATE TABLE statementintheHiveshell.See
theHivewikiforastartingpoint,andExamplesofQueryingHBaseTablesfromImpalaonpage690forexamples.
HBaseworksasakindofzâbitbucketâ,inthesensethatHBasedoesnotenforceanytypingforthekeyorvaluefields.
AllthetypeenforcementisdoneontheImpalaside.
Forbestperformance ofImpalaqueriesagainstHBasetables,mostquerieswillperformcomparisons intheWHERE
clauseagainstthecolumnthatcorrespondstotheHBaserowkey.WhencreatingthetablethroughtheHiveshell,use
theSTRINGdatatypeforthecolumnthatcorrespondstotheHBaserowkey.Impalacantranslatepredicates(through
operatorssuchas=,<,andBETWEEN )againstthiscolumnintofastlookupsinHBase,butthisoptimization(âpredicate
pushdownâ)onlyworkswhenthatcolumnisdefinedasSTRING.
StartinginImpala1.1,ImpalaalsosupportsreadingandwritingtocolumnsthataredefinedintheHiveCREATE TABLE
statementusingbinarydatatypes,representedintheHivetabledefinitionusingthe#binary keyword,often
abbreviatedas#b.DefiningnumericcolumnsasbinarycanreducetheoveralldatavolumeintheHBasetables.You
shouldstilldefinethecolumnthatcorrespondstotheHBaserowkeyasaSTRING,toallowfastlookupsusingthose
columns.
Performance ConsiderationsfortheImpala-HBase Integration
Tounderstandtheperformance characteristicsofSQLqueriesagainstdatastoredinHBase,youshouldhavesome
backgroundknowledgeabouthowHBaseinteractswithSQL-orien tedsystemsfirst.SeetheHivewikiforastarting
point;becauseImpalasharesthesamemetastoredatabaseasHive,theinformationaboutmapping columnsfrom
HivetablestoHBasetablesisgenerallyapplicabletoImpalatoo.
ImpalausestheHBaseclientAPIviaJavaNativeInterface(JNI)toquerydatastoredinHBase.Thisqueryingdoesnot
readHFilesdirectly.Theextracommunic ationoverheadmakesitimportanttochoosewhatdatatostoreinHBaseor
inHDFS,andconstructefficientqueriesthatcanretrievetheHBasedataefficiently:
â¢UseHBasetableforqueriesthatreturnasingleroworasmallrangeofrows,notqueriesthatperformafulltable
scanofanentiretable.(IfaqueryhasaHBasetableandnoWHEREclausereferencingthattable,thatisastrong
indicatorthatitisaninefficientqueryforanHBasetable.)
â¢HBasemayofferacceptableperformance forstoringsmalldimension tableswherethetableissmallenoughthat
executingafulltablescanforeveryqueryisefficientenough.However,Kuduisalmostalwaysasuperioralternative
forstoringdimension tables.HDFStablesarealsoappropriatefordimension tablesthatdonotneedtosupport
updatequeries,deletequeriesorinsertquerieswithsmallnumbersofrows.
Querypredicatesareappliedtorowkeysasstartandstopkeys,therebylimitingthescopeofaparticular lookup.If
rowkeysarenotmappedtostringcolumns,thenorderingistypicallyincorrectandcomparison operationsdonot
work.Forexample,ifrowkeysarenotmappedtostringcolumns,evaluatingforgreaterthan(>)orlessthan(<)cannot
becompleted.
Predicatesonnon-keycolumnscanbesenttoHBasetoscanasSingleColumnValueFilters ,providingsome
performance gains.Insuchacase,HBasereturnsfewerrowsthanifthosesamepredicateswereappliedusingImpala.
Whilethereissomeimprovement,itisnotasgreatwhenstartandstoprowsareused.Thisisbecausethenumberof
ApacheImpalaGuide|685UsingImpalatoQueryHBaseTables
rowsthatHBasemustexamineisnotlimitedasitiswhenstartandstoprowsareused.Aslongastherowkeypredicate
onlyappliestoasinglerow,HBasewilllocateandreturnthatrow.Conversely,ifanon-keypredicateisused,evenif
itonlyappliestoasinglerow,HBasemuststillscantheentiretabletofindthecorrectresult.
InterpretingEXPLAINOutputforHBaseQueries
Forexample,herearesomequeriesagainstthefollowingImpalatable,whichismappedtoanHBasetable.The
examplesshowexcerptsfromtheoutputoftheEXPLAIN statement,demonstratingwhatthingstolookfortoindicate
anefficientorinefficientqueryagainstanHBasetable.
Thefirstcolumn(cust_id )wasspecified asthekeycolumnintheCREATE EXTERNAL TABLE statement;for
performance, itisimportanttodeclarethiscolumnasSTRING.Othercolumns,suchasBIRTH_YEAR and
NEVER_LOGGED_ON ,arealsodeclaredasSTRING,ratherthantheirânaturalâtypesofINTorBOOLEAN ,becauseImpala
canoptimizethosetypesmoreeffectivelyinHBasetables.Forcomparison, weleaveonecolumn,YEAR_REGISTERED ,
asINTtoshowthatfilteringonthiscolumnisinefficient.
describe hbase_table;
Query: describe hbase_table
+-----------------------+--------+---------+
| name                  | type   | comment |
+-----------------------+--------+---------+
| cust_id               | string |         |
| birth_year            | string |         |
| never_logged_on       | string |         |
| private_email_address | string |         |
| year_registered       | int    |         |
+-----------------------+--------+---------+
Thebestcaseforperformance involvesasinglerowlookupusinganequalitycomparison onthecolumndefinedas
therowkey:
explain select count(*) from hbase_table where cust_id = 'some_user@example.com';
+------------------------------------------------------------------------------------+
| Explain String                                                                     |
+------------------------------------------------------------------------------------+
| Estimated Per-Host Requirements: Memory=1.01GB VCores=1                            |
| WARNING: The following tables are missing relevant table and/or column statistics. |
| hbase.hbase_table                                                                  |
|                                                                                    |
| 03:AGGREGATE [MERGE FINALIZE]                                                      |
| |  output: sum(count(*))                                                           |
| |                                                                                  |
| 02:EXCHANGE [PARTITION=UNPARTITIONED]                                              |
| |                                                                                  |
| 01:AGGREGATE                                                                       |
| |  output: count(*)                                                                |
| |                                                                                  |
| 00:SCAN HBASE [hbase.hbase_table]                                                  |
|    start key: some_user@example.com                                                |
|    stop key: some_user@example.com\0                                               |
+------------------------------------------------------------------------------------+
Anothertypeofefficientqueryinvolvesarangelookupontherowkeycolumn,usingSQLoperatorssuchasgreater
than(orequal),lessthan(orequal),orBETWEEN .Thisexamplealsoincludesanequalitytestonanon-keycolumn;
becausethatcolumnisaSTRING,ImpalacanletHBaseperformthattest,indicatedbythehbase filters: linein
theEXPLAIN output.DoingthefilteringwithinHBaseismoreefficientthantransmittingallthedatatoImpalaand
doingthefilteringontheImpalaside.
explain select count(*) from hbase_table where cust_id between 'a' and 'b'
  and never_logged_on = 'true';
+------------------------------------------------------------------------------------+
| Explain String                                                                     |
+------------------------------------------------------------------------------------+
...
| 01:AGGREGATE                                                                       |
| |  output: count(*)                                                                |
686|ApacheImpalaGuideUsingImpalatoQueryHBaseTables
| |                                                                                  |
| 00:SCAN HBASE [hbase.hbase_table]                                                  |
|    start key: a                                                                    |
|    stop key: b\0                                                                   |
|    hbase filters: cols:never_logged_on EQUAL 'true'                                |
+------------------------------------------------------------------------------------+
ThequeryislessefficientifImpalahastoevaluateanyofthepredicates,becauseImpalamustscantheentireHBase
table.ImpalacanonlypushdownpredicatestoHBaseforcolumnsdeclaredasSTRING.Thisexampletestsacolumn
declaredasINT,andthepredicates: lineintheEXPLAIN outputindicatesthatthetestisperformedafterthedata
istransmittedtoImpala.
explain select count(*) from hbase_table where year_registered = 2010;
+------------------------------------------------------------------------------------+
| Explain String                                                                     |
+------------------------------------------------------------------------------------+
...
| 01:AGGREGATE                                                                       |
| |  output: count(*)                                                                |
| |                                                                                  |
| 00:SCAN HBASE [hbase.hbase_table]                                                  |
|    predicates: year_registered = 2010                                              |
+------------------------------------------------------------------------------------+
Thesameinefficiencyappliesifthekeycolumniscomparedtoanynon-constantvalue.Here,eventhoughthekey
columnisaSTRING,andistestedusinganequalityoperator,ImpalamustscantheentireHBasetablebecausethe
keycolumniscomparedtoanothercolumnvalueratherthanaconstant.
explain select count(*) from hbase_table where cust_id = private_email_address;
+------------------------------------------------------------------------------------+
| Explain String                                                                     |
+------------------------------------------------------------------------------------+
...
| 01:AGGREGATE                                                                       |
| |  output: count(*)                                                                |
| |                                                                                  |
| 00:SCAN HBASE [hbase.hbase_table]                                                  |
|    predicates: cust_id = private_email_address                                    |
+------------------------------------------------------------------------------------+
Currently,testsontherowkeyusingORorINclausesarenotoptimizedintodirectlookupseither.Suchlimitations
mightbeliftedinthefuture,soalwayschecktheEXPLAIN outputtobesurewhetheraparticular SQLconstructresults
inanefficientqueryornotforHBasetables.
explain select count(*) from hbase_table where
  cust_id = 'some_user@example.com' or cust_id = 'other_user@example.com';
+----------------------------------------------------------------------------------------+
| Explain String                                                                      
   |
+----------------------------------------------------------------------------------------+
...
| 01:AGGREGATE                                                                        
   |
| |  output: count(*)                                                                 
   |
| |                                                                                   
   |
| 00:SCAN HBASE [hbase.hbase_table]                                                   
   |
|    predicates: cust_id = 'some_user@example.com' OR cust_id = 'other_user@example.com'
 |
+----------------------------------------------------------------------------------------+
explain select count(*) from hbase_table where
  cust_id in ('some_user@example.com', 'other_user@example.com');
ApacheImpalaGuide|687UsingImpalatoQueryHBaseTables
+------------------------------------------------------------------------------------+
| Explain String                                                                     |
+------------------------------------------------------------------------------------+
...
| 01:AGGREGATE                                                                       |
| |  output: count(*)                                                                |
| |                                                                                  |
| 00:SCAN HBASE [hbase.hbase_table]                                                  |
|    predicates: cust_id IN ('some_user@example.com', 'other_user@example.com')      |
+------------------------------------------------------------------------------------+
Eitherrewriteintoseparatequeriesforeachvalueandcombinetheresultsintheapplication,orcombinethesingle-row
queriesusingUNIONALL:
select count(*) from hbase_table where cust_id = 'some_user@example.com';
select count(*) from hbase_table where cust_id = 'other_user@example.com';
explain
  select count(*) from hbase_table where cust_id = 'some_user@example.com'
  union all
  select count(*) from hbase_table where cust_id = 'other_user@example.com';
+------------------------------------------------------------------------------------+
| Explain String                                                                     |
+------------------------------------------------------------------------------------+
...
| |  04:AGGREGATE                                                                    |
| |  |  output: count(*)                                                             |
| |  |                                                                               |
| |  03:SCAN HBASE [hbase.hbase_table]                                               |
| |     start key: other_user@example.com                                            |
| |     stop key: other_user@example.com\0                                           |
| |                                                                                  |
| 10:MERGE                                                                           |
...
| 02:AGGREGATE                                                                       |
| |  output: count(*)                                                                |
| |                                                                                  |
| 01:SCAN HBASE [hbase.hbase_table]                                                  |
|    start key: some_user@example.com                                                |
|    stop key: some_user@example.com\0                                               |
+------------------------------------------------------------------------------------+
ConfigurationOptionsforJavaHBaseApplications
IfyouhaveanHBaseJavaapplicationthatcallsthesetCacheBlocks orsetCaching methodsoftheclass
org.apache.hadoop.hbase.clien t.Scan,youcansetthesesamecachingbehaviorsthroughImpalaqueryoptions,to
controlthememorypressureontheHBaseRegionServer.Forexample,whendoingqueriesinHBasethatresultin
full-tablescans(whichbydefaultareinefficientforHBase),youcanreducememoryusageandspeedupthequeries
byturningofftheHBASE_CACHE_BLOCKS settingandspecifyingalargenumberfortheHBASE_CACHING setting.
Tosettheseoptions,issuecommands likethefollowinginimpala-shell :
-- Same as calling setCacheBlocks(true) or setCacheBlocks(false).
set hbase_cache_blocks=true;
set hbase_cache_blocks=false;
-- Same as calling setCaching(rows).
set hbase_caching=1000;
Orupdatetheimpalad defaultsfile/etc/default/impala andincludesettingsforHBASE_CACHE_BLOCKS and/or
HBASE_CACHING inthe-default_query_options settingforIMPALA_SERVER_ARGS .SeeModifyingImpalaStartup
Optionsfordetails.
688|ApacheImpalaGuideUsingImpalatoQueryHBaseTables
Note:InImpala2.0andlater,theseoptionsaresettablethroughtheJDBCorODBCinterfacesusing
theSETstatement.
UseCasesforQueryingHBasethroughImpala
ThefollowingarerepresentativeusecasesforusingImpalatoqueryHBasetables:
â¢UsingHBasetostorerapidlyincrementingcounters,suchashowmanytimesawebpagehasbeenviewed,oron
asocialnetwork,howmanyconnections auserhasorhowmanyvotesapostreceived.HBaseisefficientfor
capturingsuchchangeabledata:theappend-only storagemechanism isefficientforwritingeachchangetodisk,
andaqueryalwaysreturnsthelatestvalue.AnapplicationcouldqueryspecifictotalslikethesefromHBase,and
combinetheresultswithabroadersetofdataqueriedfromImpala.
â¢StoringverywidetablesinHBase.Widetableshavemanycolumns,possiblythousands, typicallyrecordingmany
attributesforanimportantsubjectsuchasauserofanonlineservice.Thesetablesarealsooftensparse,thatis,
mostofthecolumnsvaluesareNULL,0,false,emptystring,orotherblankorplaceholder value.(Forexample,
anyparticular websiteusermighthaveneverusedsomesitefeature,filledinacertainfieldintheirprofile,visited
aparticular partofthesite,andsoon.)Atypicalqueryagainstthiskindoftableistolookupasinglerowtoretrieve
alltheinformationaboutaspecificsubject,ratherthansumming,averaging,orfilteringmillionsofrowsasin
typicalImpala-manag edtables.
LoadingDataintoanHBaseTable
TheImpalaINSERTstatementworksforHBasetables.TheINSERT ... VALUES syntaxisideallysuitedtoHBase
tables,becauseinserting asinglerowisanefficientoperationforanHBasetable.(ForregularImpalatables,withdata
filesinHDFS,thetinydatafilesproducedbyINSERT ... VALUES areextremelyinefficient,soyouwouldnotuse
thattechnique withtablescontaininganysignificantdatavolume.)
WhenyouusetheINSERT ... SELECT syntax,theresultintheHBasetablecouldbefewerrowsthanyouexpect.
HBaseonlystoresthemostrecentversionofeachuniquerowkey,soifanINSERT ... SELECT statementcopies
overmultiplerowscontainingthesamevalueforthekeycolumn,subsequentquerieswillonlyreturnonerowwith
eachkeycolumnvalue:
Although ImpaladoesnothaveanUPDATEstatement,youcanachievethesameeffectbydoingsuccessiveINSERT
statementsusingthesamevalueforthekeycolumneachtime:
LimitationsandRestrictionsoftheImpalaandHBaseIntegration
TheImpalaintegrationwithHBasehasthefollowinglimitationsandrestrictions, someinheritedfromtheintegration
betweenHBaseandHive,andsomeuniquetoImpala:
â¢IfyouissueaDROP TABLE foraninternal(Impala-manag ed)tablethatismappedtoanHBasetable,theunderlying
tableisnotremovedinHBase.TheHiveDROP TABLE statementalsoremovestheHBasetableinthiscase.
â¢TheINSERT OVERWRITE statementisnotavailableforHBasetables.Youcaninsertnewdata,ormodifyan
existingrowbyinserting anewrowwiththesamekeyvalue,butnotreplacetheentirecontentsofthetable.You
candoanINSERT OVERWRITE inHiveifyouneedthiscapability.
â¢IfyouissueaCREATE TABLE LIKE statementforatablemappedtoanHBasetable,thenewtableisalsoan
HBasetable,butinheritsthesameunderlying HBasetablenameastheoriginal.Thenewtableiseffectivelyan
aliasfortheoldone,notanewtablewithidenticalcolumnstructure.AvoidusingCREATE TABLE LIKE forHBase
tables,toavoidanyconfusion.
â¢CopyingdataintoanHBasetableusingtheImpalaINSERT ... SELECT syntaxmightproducefewernewrows
thanareinthequeryresultset.Iftheresultsetcontainsmultiplerowswiththesamevalueforthekeycolumn,
ApacheImpalaGuide|689UsingImpalatoQueryHBaseTables
eachrowsupercedesanypreviousrowswiththesamekeyvalue.Becausetheorderoftheinsertedrowsis
unpredictable,youcannotrelyonthistechnique topreservetheâlatestâversionofaparticular keyvalue.
â¢Becausethecomplexdatatypes(ARRAY,STRUCT,andMAP)availableinCDH5.5/Impala2.3andhigherare
currentlyonlysupportedinParquettables,youcannotusethesetypesinHBasetablesthatarequeriedthrough
Impala.
â¢TheLOAD DATA statementcannotbeusedwithHBasetables.
â¢TheTABLESAMPLE clauseoftheSELECTstatementdoesnotapplytoatablereferencederivedfromaview,a
subquery,oranythingotherthanarealbasetable.ThisclauseonlyworksfortablesbackedbyHDFSorHDFS-like
datafiles,thereforeitdoesnotapplytoKuduorHBasetables.
ExamplesofQueryingHBaseTablesfromImpala
ThefollowingexamplescreateanHBasetablewithfourcolumnfamilies,createacorresponding tablethroughHive,
theninsertandquerythetablethroughImpala.
InHBaseshell,thetablenameisquotedinCREATEandDROPstatements.TablescreatedinHBasebegininâenabledâ
state;beforedroppingthemthroughtheHBaseshell,youmustissueadisable ' table_name 'statement.
$ hbase shell
15/02/10 16:07:45
HBase Shell; enter 'help<RETURN>' for list of supported commands.
Type "exit<RETURN>" to leave the HBase Shell
Version 0.94.2-cdh4.2.0, rUnknown, Fri Feb 15 11:51:18 PST 2013
hbase(main):001:0> create 'hbasealltypessmall', 'boolsCF', 'intsCF', 'floatsCF', 
'stringsCF'
0 row(s) in 4.6520 seconds
=> Hbase::Table - hbasealltypessmall
hbase(main):006:0> quit
IssuethefollowingCREATE TABLE statementintheHiveshell.(TheImpalaCREATE TABLE statementcurrentlydoes
notsupporttheSTORED BY clause,soyouswitchintoHivetocreatethetable,thenbacktoImpalaandthe
impala-shell interpretertoissuethequeries.)
ThisexamplecreatesanexternaltablemappedtotheHBasetable,usablebybothImpalaandHive.Itisdefinedasan
externaltablesothatwhendroppedbyImpalaorHive,theoriginalHBasetableisnottouchedatall.
TheWITH SERDEPROPERTIES clausespecifiesthatthefirstcolumn(ID)representstherowkey,andmapsthe
remaining columnsoftheSQLtabletoHBasecolumnfamilies.Themapping reliesontheordinalorderofthecolumns
inthetable,notthecolumnnamesintheCREATE TABLE statement.Thefirstcolumnisdefinedtobethelookupkey;
theSTRINGdatatypeproducesthefastestkey-basedlookupsforHBasetables.
Note:ForImpalawithHBasetables,themostimportantaspecttoensuregoodperformance isto
useaSTRINGcolumnastherowkey,asshowninthisexample.
$ hive
...
hive> use hbase;
OK
Time taken: 4.095 seconds
hive> CREATE EXTERNAL TABLE hbasestringids (
    >   id string,
    >   bool_col boolean,
    >   tinyint_col tinyint,
    >   smallint_col smallint,
    >   int_col int,
    >   bigint_col bigint,
    >   float_col float,
690|ApacheImpalaGuideUsingImpalatoQueryHBaseTables
    >   double_col double,
    >   date_string_col string,
    >   string_col string,
    >   timestamp_col timestamp)
    > STORED BY 'org.apache.hadoop.hive.hbase.HBaseStorageHandler'
    > WITH SERDEPROPERTIES (
    >   "hbase.columns.mapping" =
    >   
":key,boolsCF:bool_col,intsCF:tinyint_col,intsCF:smallint_col,intsCF:int_col,intsCF:\
    >   bigint_col,floatsCF:float_col,floatsCF:double_col,stringsCF:date_string_col,\
    >   stringsCF:string_col,stringsCF:timestamp_col"
    > )
    > TBLPROPERTIES("hbase.table.name" = "hbasealltypessmall");
OK
Time taken: 2.879 seconds
hive> quit;
Onceyouhaveestablishedthemapping toanHBasetable,youcanissueDMLstatementsandqueriesfromImpala.
ThefollowingexampleshowsaseriesofINSERTstatementsfollowedbyaquery.Theidealkindofqueryfroma
performance standpointretrievesarowfromthetablebasedonarowkeymappedtoastringcolumn.Aninitial
INVALIDATE METADATA table_name statementmakesthetablecreatedthroughHivevisibletoImpala.
$ impala-shell -i localhost -d hbase
Starting Impala Shell without Kerberos authentication
Connected to localhost:21000
...
Query: use `hbase`
[localhost:21000] > invalidate metadata hbasestringids;
Fetched 0 row(s) in 0.09s
[localhost:21000] > desc hbasestringids;
+-----------------+-----------+---------+
| name            | type      | comment |
+-----------------+-----------+---------+
| id              | string    |         |
| bool_col        | boolean   |         |
| double_col      | double    |         |
| float_col       | float     |         |
| bigint_col      | bigint    |         |
| int_col         | int       |         |
| smallint_col    | smallint  |         |
| tinyint_col     | tinyint   |         |
| date_string_col | string    |         |
| string_col      | string    |         |
| timestamp_col   | timestamp |         |
+-----------------+-----------+---------+
Fetched 11 row(s) in 0.02s
[localhost:21000] > insert into hbasestringids values 
('0001',true,3.141,9.94,1234567,32768,4000,76,'2014-12-31','Hello world',now());
Inserted 1 row(s) in 0.26s
[localhost:21000] > insert into hbasestringids values 
('0002',false,2.004,6.196,1500,8000,129,127,'2014-01-01','Foo bar',now());
Inserted 1 row(s) in 0.12s
[localhost:21000] > select * from hbasestringids where id = '0001';
+------+----------+------------+-------------------+------------+---------+--------------+-------------+-----------------+-------------+-------------------------------+
| id   | bool_col | double_col | float_col         | bigint_col | int_col | smallint_col
 | tinyint_col | date_string_col | string_col  | timestamp_col                 |
+------+----------+------------+-------------------+------------+---------+--------------+-------------+-----------------+-------------+-------------------------------+
| 0001 | true     | 3.141      | 9.939999580383301 | 1234567    | 32768   | 4000      
   | 76          | 2014-12-31      | Hello world | 2015-02-10 16:36:59.764838000 |
+------+----------+------------+-------------------+------------+---------+--------------+-------------+-----------------+-------------+-------------------------------+
Fetched 1 row(s) in 0.54s
Note:AfteryoucreateatableinHive,suchastheHBasemapping tableinthisexample,issuean
INVALIDATE METADATA table_name statementthenexttimeyouconnecttoImpala,makeImpala
awareofthenewtable.(PriortoImpala1.2.4,youcouldnotspecifythetablenameifImpalawasnot
awareofthetableyet;inImpala1.2.4andhigher,specifyingthetablenameavoidsreloadingthe
metadataforothertablesthatarenotchanged.)
ApacheImpalaGuide|691UsingImpalatoQueryHBaseTables
UsingImpalawiththeAmazonS3Filesystem
Important:
InCDH5.8/Impala2.6andhigher,Impalasupports bothqueries(SELECT)andDML(INSERT,LOAD
DATA,CREATE TABLE AS SELECT )fordataresidingonAmazonS3.Withtheinclusion ofwrite
support,theImpalasupportforS3isnowconsideredreadyforproduction use.
YoucanuseImpalatoquerydataresidingontheAmazonS3filesystem.Thiscapabilityallowsconvenientaccesstoa
storagesystemthatisremotelymanaged,accessible fromanywhere,andintegratedwithvariouscloud-based services.
ImpalacanqueryfilesinanysupportedfileformatfromS3.TheS3storagelocationcanbeforanentiretable,or
individual partitions inapartitioned table.
ThedefaultImpalatablesusedatafilesstoredonHDFS,whichareidealforbulkloadsandqueriesusingfull-table
scans.Incontrast,queriesagainstS3dataarelessperformant,makingS3suitableforholdingâcoldâdatathatisonly
queriedoccasionally,whilemorefrequentlyaccessed âhotâdataresidesinHDFS.Inapartitioned table,youcanset
theLOCATION attributeforindividual partitions toputsomepartitions onHDFSandothersonS3,typicallydepending
ontheageofthedata.
SeeSpecifyingImpalaCredentialstoAccessDatainS3forinformationaboutconfiguringImpalatouseAmazonS3
filesystem.
HowImpalaSQLStatementsWorkwithS3
ImpalaSQLstatementsworkwithdataonS3asfollows:
â¢TheCREATETABLEStatementonpage234orALTERTABLEStatementonpage205statementscanspecifythata
tableresidesontheS3filesystembyencodingans3a://prefixfortheLOCATION property.ALTER TABLE can
alsosettheLOCATION propertyforanindividual partition, sothatsomedatainatableresidesonS3andother
datainthesametableresidesonHDFS.
â¢OnceatableorpartitionisdesignatedasresidingonS3,theSELECTStatementonpage295statementtransparently
accessesthedatafilesfromtheappropriatestoragelayer.
â¢IftheS3tableisaninternaltable,theDROPTABLEStatementonpage268statementremovesthecorresponding
datafilesfromS3whenthetableisdropped.
â¢TheTRUNCATETABLEStatement(CDH5.5orhigheronly)onpage381statementalwaysremovesthecorresponding
datafilesfromS3whenthetableistruncated.
â¢TheLOADDATAStatementonpage288canmovedatafilesresidinginHDFSintoanS3table.
â¢TheINSERTStatementonpage277statement,ortheCREATE TABLE AS SELECT formoftheCREATE TABLE
statement,cancopydatafromanHDFStableoranotherS3tableintoanS3table.TheS3_SKIP_INSER T_STAGING
QueryOption(CDH5.8orhigheronly)onpage358queryoptionchooseswhetherornottouseafastcodepath
forthesewriteoperationstoS3,withthetradeoffofpotentialinconsistencyinthecaseofafailureduringthe
statement.
ForusageinformationaboutImpalaSQLstatementswithS3tables,seeCreatingImpalaDatabases,Tables,andPartitions
forDataStoredonS3onpage694andUsingImpalaDMLStatementsforS3Dataonpage693.
692|ApacheImpalaGuideUsingImpalawiththeAmazonS3Filesystem
LoadingDataintoS3forImpalaQueries
IfyourETLpipelineinvolvesmovingdataintoS3andthenqueryingthroughImpala,youcaneitheruseImpalaDML
statementstocreate,move,orcopythedata,orusethesamedataloadingtechniques asyouwouldfornon-Impala
data.
UsingImpalaDMLStatementsforS3Data
InCDH5.8/Impala2.6andhigher,theImpalaDMLstatements(INSERT,LOAD DATA ,andCREATE TABLE AS
SELECT)canwritedataintoatableorpartition thatresidesintheAmazonSimpleStorageService(S3).Thesyntaxof
theDMLstatementsisthesameasforanyothertables,becausetheS3locationfortablesandpartitions isspecified
byans3a://prefixintheLOCATION attributeofCREATE TABLE orALTER TABLE statements.Ifyoubringdatainto
S3usingthenormalS3transfermechanisms insteadofImpalaDMLstatements,issueaREFRESH statementforthe
tablebeforeusingImpalatoquerytheS3data.
BecauseofdifferencesbetweenS3andtraditional filesystems,DMLoperationsforS3tablescantakelongerthanfor
tablesonHDFS.Forexample,boththeLOAD DATA statementandthefinalstageoftheINSERTandCREATE TABLE
AS SELECT statementsinvolvemovingfilesfromonedirectorytoanother.(InthecaseofINSERTandCREATE TABLE
AS SELECT ,thefilesaremovedfromatemporarystagingdirectorytothefinaldestinationdirectory.)BecauseS3
doesnotsupportaârenameâoperationforexistingobjects,inthesecasesImpalaactuallycopiesthedatafilesfrom
onelocationtoanotherandthenremovestheoriginalfiles.InCDH5.8/Impala2.6,theS3_SKIP_INSERT_STAGING
queryoptionprovidesawaytospeedupINSERTstatementsforS3tablesandpartitions, withthetradeoffthata
problemduringstatementexecutioncouldleavedatainaninconsistentstate.ItdoesnotapplytoINSERT OVERWRITE
orLOAD DATA statements.SeeS3_SKIP_INSER T_STAGINGQueryOption(CDH5.8orhigheronly)onpage358for
details.
Manually LoadingDataintoImpalaTablesonS3
Asanalternative,oronearlierImpalareleaseswithoutDMLsupportforS3,youcanusetheAmazon-providedmethods
tobringdatafilesintoS3forqueryingthroughImpala.SeetheAmazonS3websitefordetails.
Important:
ForbestcompatibilitywiththeS3writesupportinCDH5.8/Impala2.6andhigher:
â¢UsenativeHadooptechniques tocreatedatafilesinS3forqueryingthroughImpala.
â¢UsethePURGEclauseofDROP TABLE whendroppinginternal(managed)tables.
Bydefault,whenyoudropaninternal(managed)table,thedatafilesaremovedtotheHDFStrashcan.
ThisoperationisexpensivefortablesthatresideontheAmazonS3filesystem.Therefore,forS3tables,
prefertouseDROP TABLE table_name  PURGEratherthanthedefaultDROP TABLE statement.
ThePURGEclausemakesImpaladeletethedatafilesimmediately,skippingtheHDFStrashcan.For
thePURGEclausetoworkeffectively,youmustoriginally createthedatafilesonS3usingoneofthe
toolsfromtheHadoopecosystem,suchashadoop fs -cp ,orINSERTinImpalaorHive.
Alternativefilecreationtechniques (lesscompatiblewiththePURGEclause)include:
â¢TheAmazonAWS/S3webinterfacetouploadfromawebbrowser.
â¢TheAmazonAWSCLItomanipula tefilesfromthecommand line.
â¢OtherS3-enabled software,suchastheS3Toolsclientsoftware.
AfteryouuploaddatafilestoalocationalreadymappedtoanImpalatableorpartition, orifyoudeletefilesinS3from
suchalocation,issuetheREFRESH table_name statementtomakeImpalaawareofthenewsetofdatafiles.
ApacheImpalaGuide|693UsingImpalawiththeAmazonS3Filesystem
CreatingImpalaDatabases,Tables,andPartitionsforDataStoredonS3
Impalareadsdataforatableorpartition fromS3basedontheLOCATION attributeforthetableorpartition. Specify
theS3detailsintheLOCATION clauseofaCREATE TABLE orALTER TABLE statement.ThenotationfortheLOCATION
clauseiss3a://bucket_name /path/to/file .Thefilesystemprefixisalwayss3a://becauseImpaladoesnot
supportthes3://ors3n://prefixes.
Forapartitioned table,eitherspecifyaseparateLOCATION clauseforeachnewpartition, orspecifyabaseLOCATION
forthetableandsetupadirectorystructureinS3tomirrorthewayImpalapartitioned tablesarestructuredinHDFS.
Although, strictlyspeaking,S3filenames donothavedirectorypaths,ImpalatreatsS3filenames with/charactersthe
sameasHDFSpathnames thatincludedirectories.
Youpointanonpartitioned tableoranindividual partitionatS3byspecifyingasingledirectorypathinS3,whichcould
beanyarbitrarydirectory.ToreplicatethestructureofanentireImpalapartitioned tableordatabaseinS3requires
morecare,withdirectoriesandsubdirectoriesnestedandnamedtomatchtheequivalentdirectorytreeinHDFS.
Consider settingupanemptystagingareaifnecessaryinHDFS,andrecordingthecompletedirectorystructuresothat
youcanreplicateitinS3.
ForconveniencewhenworkingwithmultipletableswithdatafilesstoredinS3,youcancreateadatabasewitha
LOCATION attributepointingtoanS3path.SpecifyaURLoftheforms3a://bucket/root/path/for/database
fortheLOCATION attributeofthedatabase.Anytablescreatedinsidethatdatabaseautomaticallycreatedirectories
undernea ththeonespecified bythedatabaseLOCATION attribute.
Forexample,thefollowingsessioncreatesapartitioned tablewhereonlyasinglepartitionresidesonS3.Thepartitions
foryears2013and2014arelocatedonHDFS.Thepartition foryear2015includesaLOCATION attributewithan
s3a://URL,andsoreferstodataresidingonS3,underaspecificpathundernea ththebucketimpala-demo .
[localhost:21000] > create database db_on_hdfs;
[localhost:21000] > use db_on_hdfs;
[localhost:21000] > create table mostly_on_hdfs (x int) partitioned by (year int);
[localhost:21000] > alter table mostly_on_hdfs add partition (year=2013);
[localhost:21000] > alter table mostly_on_hdfs add partition (year=2014);
[localhost:21000] > alter table mostly_on_hdfs add partition (year=2015)
                  >   location 's3a://impala-demo/dir1/dir2/dir3/t1';
Thefollowingsessioncreatesadatabaseandtwopartitioned tablesresidingentirelyonS3,onepartitioned byasingle
columnandtheotherpartitioned bymultiplecolumns.BecauseaLOCATION attributewithans3a://URLisspecified
forthedatabase,thetablesinsidethatdatabaseareautomaticallycreatedonS3undernea ththedatabasedirectory.
Toseethenamesoftheassociatedsubdirectories,including thepartitionkeyvalues,weuseanS3clienttooltoexamine
howthedirectorystructureisorganizedonS3.Forexample,Impalapartition directoriessuchasmonth=1 donot
includeleadingzeroes,whichsometimesappearinpartition directoriescreatedthroughHive.
[localhost:21000] > create database db_on_s3 location 's3a://impala-demo/dir1/dir2/dir3';
[localhost:21000] > use db_on_s3;
[localhost:21000] > create table partitioned_on_s3 (x int) partitioned by (year int);
[localhost:21000] > alter table partitioned_on_s3 add partition (year=2013);
[localhost:21000] > alter table partitioned_on_s3 add partition (year=2014);
[localhost:21000] > alter table partitioned_on_s3 add partition (year=2015);
[localhost:21000] > !aws s3 ls s3://impala-demo/dir1/dir2/dir3 --recursive;
2015-03-17 13:56:34          0 dir1/dir2/dir3/
2015-03-17 16:43:28          0 dir1/dir2/dir3/partitioned_on_s3/
2015-03-17 16:43:49          0 dir1/dir2/dir3/partitioned_on_s3/year=2013/
2015-03-17 16:43:53          0 dir1/dir2/dir3/partitioned_on_s3/year=2014/
2015-03-17 16:43:58          0 dir1/dir2/dir3/partitioned_on_s3/year=2015/
[localhost:21000] > create table partitioned_multiple_keys (x int)
                  >   partitioned by (year smallint, month tinyint, day tinyint);
[localhost:21000] > alter table partitioned_multiple_keys
                  >   add partition (year=2015,month=1,day=1);
[localhost:21000] > alter table partitioned_multiple_keys
                  >   add partition (year=2015,month=1,day=31);
[localhost:21000] > alter table partitioned_multiple_keys
694|ApacheImpalaGuideUsingImpalawiththeAmazonS3Filesystem
                  >   add partition (year=2015,month=2,day=28);
[localhost:21000] > !aws s3 ls s3://impala-demo/dir1/dir2/dir3 --recursive;
2015-03-17 13:56:34          0 dir1/dir2/dir3/
2015-03-17 16:47:13          0 dir1/dir2/dir3/partitioned_multiple_keys/
2015-03-17 16:47:44          0 
dir1/dir2/dir3/partitioned_multiple_keys/year=2015/month=1/day=1/
2015-03-17 16:47:50          0 
dir1/dir2/dir3/partitioned_multiple_keys/year=2015/month=1/day=31/
2015-03-17 16:47:57          0 
dir1/dir2/dir3/partitioned_multiple_keys/year=2015/month=2/day=28/
2015-03-17 16:43:28          0 dir1/dir2/dir3/partitioned_on_s3/
2015-03-17 16:43:49          0 dir1/dir2/dir3/partitioned_on_s3/year=2013/
2015-03-17 16:43:53          0 dir1/dir2/dir3/partitioned_on_s3/year=2014/
2015-03-17 16:43:58          0 dir1/dir2/dir3/partitioned_on_s3/year=2015/
TheCREATE DATABASE andCREATE TABLE statementscreatetheassociateddirectorypathsiftheydonotalready
exist.Youcanspecifymultiplelevelsofdirectories,andtheCREATEstatementcreatesallappropriatelevels,similar
tousingmkdir -p .
UsethestandardS3fileuploadmethodstoactuallyputthedatafilesintotherightlocations.Youcanalsoputthe
directorypathsanddatafilesinplacebeforecreatingtheassociatedImpaladatabasesortables,andImpalaautomatically
usesthedatafromtheappropriatelocationaftertheassociateddatabasesandtablesarecreated.
Youcanswitchwhetheranexistingtableorpartition pointstodatainHDFSorS3.Forexample,ifyouhaveanImpala
tableorpartition pointingtodatafilesinHDFSorS3,andyoulatertransferthosedatafilestotheotherfilesystem,
useanALTER TABLE statementtoadjusttheLOCATION attributeofthecorresponding tableorpartition toreflect
thatchange.BecauseImpaladoesnothaveanALTER DATABASE statement,thislocation-switchingtechnique isnot
practicalforentiredatabasesthathaveacustomLOCATION attribute.
InternalandExternalTablesLocatedonS3
JustaswithtableslocatedonHDFSstorage,youcandesignateS3-based tablesaseitherinternal(managedbyImpala)
orexternal,byusingthesyntaxCREATE TABLE orCREATE EXTERNAL TABLE respectively.Whenyoudropaninternal
table,thefilesassociatedwiththetableareremoved,eveniftheyareonS3storage.Whenyoudropanexternaltable,
thefilesassociatedwiththetableareleftalone,andarestillavailableforaccessbyothertoolsorcomponen ts.See
OverviewofImpalaTablesonpage196fordetails.
IfthedataonS3isintendedtobelong-livedandaccessed byothertoolsinadditiontoImpala,createanyassociated
S3tableswiththeCREATE EXTERNAL TABLE syntax,sothatthefilesarenotdeletedfromS3whenthetableis
dropped.
IfthedataonS3isonlyneededforqueryingbyImpalaandcanbesafelydiscardedoncetheImpalaworkflowis
complete,createtheassociatedS3tablesusingtheCREATE TABLE syntax,sothatdroppingthetablealsodeletesthe
corresponding datafilesonS3.
Forexample,thissessioncreatesatableinS3withthesamecolumnlayoutasatableinHDFS,thenexaminestheS3
tableandqueriessomedatafromit.ThetableinS3worksthesameasatableinHDFSasfarastheexpectedfileformat
ofthedata,tableandcolumnstatistics,andothertableproperties. TheonlyindicationthatitisnotanHDFStableis
thes3a://URLintheLOCATION property.ManydatafilescanresideintheS3directory,andtheircombined contents
formthetabledata.Becausethedatainthisexampleisuploaded afterthetableiscreated,aREFRESH statement
promptsImpalatoupdateitscachedinformationaboutthedatafiles.
[localhost:21000] > create table usa_cities_s3 like usa_cities location 
's3a://impala-demo/usa_cities';
[localhost:21000] > desc usa_cities_s3;
+-------+----------+---------+
| name  | type     | comment |
+-------+----------+---------+
| id    | smallint |         |
| city  | string   |         |
| state | string   |         |
+-------+----------+---------+
ApacheImpalaGuide|695UsingImpalawiththeAmazonS3Filesystem
-- Now from a web browser, upload the same data file(s) to S3 as in the HDFS table,
-- under the relevant bucket and path. If you already have the data in S3, you would
-- point the table LOCATION at an existing path.
[localhost:21000] > refresh usa_cities_s3;
[localhost:21000] > select count(*) from usa_cities_s3;
+----------+
| count(*) |
+----------+
| 289      |
+----------+
[localhost:21000] > select distinct state from sample_data_s3 limit 5;
+----------------------+
| state                |
+----------------------+
| Louisiana            |
| Minnesota            |
| Georgia              |
| Alaska               |
| Ohio                 |
+----------------------+
[localhost:21000] > desc formatted usa_cities_s3;
+------------------------------+------------------------------+---------+
| name                         | type                         | comment |
+------------------------------+------------------------------+---------+
| # col_name                   | data_type                    | comment |
|                              | NULL                         | NULL    |
| id                           | smallint                     | NULL    |
| city                         | string                       | NULL    |
| state                        | string                       | NULL    |
|                              | NULL                         | NULL    |
| # Detailed Table Information | NULL                         | NULL    |
| Database:                    | s3_testing                   | NULL    |
| Owner:                       | jrussell                     | NULL    |
| CreateTime:                  | Mon Mar 16 11:36:25 PDT 2015 | NULL    |
| LastAccessTime:              | UNKNOWN                      | NULL    |
| Protect Mode:                | None                         | NULL    |
| Retention:                   | 0                            | NULL    |
| Location:                    | s3a://impala-demo/usa_cities | NULL    |
| Table Type:                  | MANAGED_TABLE                | NULL    |
...
+------------------------------+------------------------------+---------+
Inthiscase,wehavealreadyuploaded aParquetfilewithamillionrowsofdatatothesample_data directory
undernea ththeimpala-demo bucketonS3.Thissessioncreatesatablewithmatchingcolumnsettingspointingto
thecorresponding locationinS3,thenqueriesthetable.BecausethedataisalreadyinplaceonS3whenthetableis
created,noREFRESH statementisrequired.
[localhost:21000] > create table sample_data_s3
                  > (id int, id bigint, val int, zerofill string,
                  > name string, assertion boolean, city string, state string)
                  > stored as parquet location 's3a://impala-demo/sample_data';
[localhost:21000] > select count(*) from sample_data_s3;;
+----------+
| count(*) |
+----------+
| 1000000  |
+----------+
[localhost:21000] > select count(*) howmany, assertion from sample_data_s3 group by 
assertion;
+---------+-----------+
| howmany | assertion |
+---------+-----------+
| 667149  | true      |
| 332851  | false     |
+---------+-----------+
696|ApacheImpalaGuideUsingImpalawiththeAmazonS3Filesystem
RunningandTuningImpalaQueriesforDataStoredonS3
OncetheappropriateLOCATION attributesaresetupatthetableorpartitionlevel,youquerydatastoredinS3exactly
thesameasdatastoredonHDFSorinHBase:
â¢QueriesagainstS3datasupportallthesamefileformatsasforHDFSdata.
â¢Tablescanbeunpartitioned orpartitioned. Forpartitioned tables,eithermanually constructpathsinS3
corresponding totheHDFSdirectoriesrepresentingpartition keyvalues,oruseALTER TABLE ... ADD
PARTITION tosetuptheappropriatepathsinS3.
â¢HDFSandHBasetablescanbejoinedtoS3tables,orS3tablescanbejoinedwitheachother.
â¢AuthorizationusingtheSentryframeworktocontrolaccesstodatabases,tables,orcolumnsworksthesame
whetherthedataisinHDFSorinS3.
â¢Thecatalogd daemoncachesmetadataforbothHDFSandS3tables.UseREFRESH andINVALIDATE METADATA
forS3tablesinthesamesituationswhereyouwouldissuethosestatementsforHDFStables.
â¢QueriesagainstS3tablesaresubjecttothesamekindsofadmission controlandresourcemanagementasHDFS
tables.
â¢MetadataaboutS3tablesisstoredinthesamemetastoredatabaseasforHDFStables.
â¢YoucansetupviewsreferringtoS3tables,thesameasforHDFStables.
â¢TheCOMPUTE STATS ,SHOW TABLE STATS ,andSHOW COLUMN STATS statementsworkforS3tablesalso.
UnderstandingandTuningImpalaQueryPerformance forS3Data
Although ImpalaqueriesfordatastoredinS3mightbelessperformantthanqueriesagainsttheequivalentdatastored
inHDFS,youcanstilldosometuning.Herearetechniques youcanusetointerpretexplainplansandprofilesforqueries
againstS3data,andtipstoachievethebestperformance possibleforsuchqueries.
Allelsebeingequal,performance isexpectedtobelowerforqueriesrunningagainstdataonS3ratherthanHDFS.
Theactualmechanics oftheSELECTstatementaresomewhatdifferentwhenthedataisinS3.Although theworkis
stilldistributedacrossthedatanodesofthecluster,Impalamightparallelizetheworkforadistributedquerydifferently
fordataonHDFSandS3.S3doesnothavethesameblocknotionasHDFS,soImpalausesheuristicstodeterminehow
tosplituplargeS3filesforprocessinginparallel.BecauseallhostscanaccessanyS3datafilewithequalefficiency,
thedistribution ofworkmightbedifferentthanforHDFSdata,wherethedatablocksarephysicallyreadusing
short-circuitlocalreadsbyhoststhatcontaintheappropriateblockreplicas.Although theI/OtoreadtheS3datamight
bespreadevenlyacrossthehostsofthecluster,thefactthatalldataisinitiallyretrievedacrossthenetworkmeans
thattheoverallqueryperformance islikelytobelowerforS3datathanforHDFSdata.
InCDH5.8/Impala2.6andhigher,ImpalaqueriesareoptimizedforfilesstoredinAmazonS3.ForImpalatablesthat
usethefileformatsParquet,ORC,RCFile,SequenceFile, Avro,anduncompressedtext,thesettingfs.s3a.block.size
inthecore-site.xml configurationfiledetermineshowImpaladividestheI/Oworkofreadingthedatafiles.This
configurationsettingisspecified inbytes.Bydefault,thisvalueis33554432 (32MB),meaningthatImpalaparallelizes
S3readoperationsonthefilesasiftheyweremadeupof32MBblocks.Forexample,ifyourS3queriesprimarily
accessParquetfileswrittenbyMapReduceorHive,increasefs.s3a.block.size to134217728 (128MB)tomatch
therowgroupsizeofthosefiles.IfmostS3queriesinvolveParquetfileswrittenbyImpala,increase
fs.s3a.block.size to268435456 (256MB)tomatchtherowgroupsizeproducedbyImpala.
BecauseofdifferencesbetweenS3andtraditional filesystems,DMLoperationsforS3tablescantakelongerthanfor
tablesonHDFS.Forexample,boththeLOAD DATA statementandthefinalstageoftheINSERTandCREATE TABLE
AS SELECT statementsinvolvemovingfilesfromonedirectorytoanother.(InthecaseofINSERTandCREATE TABLE
AS SELECT ,thefilesaremovedfromatemporarystagingdirectorytothefinaldestinationdirectory.)BecauseS3
doesnotsupportaârenameâoperationforexistingobjects,inthesecasesImpalaactuallycopiesthedatafilesfrom
onelocationtoanotherandthenremovestheoriginalfiles.InCDH5.8/Impala2.6,theS3_SKIP_INSERT_STAGING
queryoptionprovidesawaytospeedupINSERTstatementsforS3tablesandpartitions, withthetradeoffthata
problemduringstatementexecutioncouldleavedatainaninconsistentstate.ItdoesnotapplytoINSERT OVERWRITE
orLOAD DATA statements.SeeS3_SKIP_INSER T_STAGINGQueryOption(CDH5.8orhigheronly)onpage358for
details.
ApacheImpalaGuide|697UsingImpalawiththeAmazonS3Filesystem
Whenoptimizingaspectsofforcomplexqueriessuchasthejoinorder,ImpalatreatstablesonHDFSandS3thesame
way.Therefore,followallthesametuningrecommenda tionsforS3tablesasforHDFSones,suchasusingtheCOMPUTE
STATSstatementtohelpImpalaconstructaccurateestimatesofrowcountsandcardinality.SeeTuningImpalafor
Performance onpage565fordetails.
Inqueryprofilereports,thenumbersforBytesReadLocal ,BytesReadShortCircuit ,BytesReadDataNodeCached ,
andBytesReadRemoteUnexpected areblankbecausethosemetricscomefromHDFS.Ifyoudoseeanyindications
thataqueryagainstanS3tableperformedâremotereadâoperations,donotbealarmed. Thatisexpectedbecause,
bydefinition,alltheI/OforS3tablesinvolvesremotereads.
RestrictionsonImpalaSupportforS3
ImpalarequiresthatthedefaultfilesystemfortheclusterbeHDFS.YoucannotuseS3astheonlyfilesysteminthe
cluster.
PriortoCDH5.8/Impala2.6ImpalacouldnotperformDMLoperations(INSERT,LOAD DATA ,orCREATE TABLE AS
SELECT)wherethedestinationisatableorpartition locatedonanS3filesystem.ThisrestrictionisliftedinCDH5.8/
Impala2.6andhigher.
Impaladoesnotsupporttheolds3://block-based ands3n://filesystemschemes, onlys3a://.
Although S3isoftenusedtostoreJSON-formatteddata,thecurrentImpalasupportforS3doesnotincludedirectly
queryingJSONdata.ForImpalaqueries,usedatafilesinoneofthefileformatslistedinHowImpalaWorkswithHadoop
FileFormatsonpage634.IfyouhavedatainJSONformat,youcanprepareaflattenedversionofthatdataforquerying
byImpalaaspartofyourETLcycle.
YoucannotusetheALTER TABLE ... SET CACHED statementfortablesorpartitions thatarelocatedinS3.
BestPracticesforUsingImpalawithS3
Thefollowingguidelines representbestpracticesderivedfromtestingandfieldexperience withImpalaonS3:
â¢AnyreferencetoanS3locationmustbefullyqualified. (ThisruleapplieswhenS3isnotdesignatedasthedefault
filesystem.)
â¢Setthesafetyvalvefs.s3a.connection.maximum to1500forimpalad .
â¢Setsafetyvalvefs.s3a.block.size to134217728 (128MBinbytes)ifmostParquetfilesqueriedbyImpala
werewrittenbyHiveorParquetMRjobs.Settheblocksizeto268435456 (256MBinbytes)ifmostParquetfiles
queriedbyImpalawerewrittenbyImpala.
â¢DROP TABLE .. PURGE ismuchfasterthanthedefaultDROP TABLE .ThesameappliestoALTER TABLE ...
DROP PARTITION PURGE versusthedefaultDROP PARTITION operation.However,duetotheeventually
consistentnatureofS3,thefilesforthattableorpartition couldremainforsomeunbounded timewhenusing
PURGE.ThedefaultDROP TABLE/PARTITION isslowbecauseImpalacopiesthefilestotheHDFStrashfolder,
andImpalawaitsuntilallthedataismoved.DROP TABLE/PARTITION .. PURGE isafastdeleteoperation,and
theImpalastatementfinishesquicklyeventhoughthechangemightnothavepropagatedfullythroughoutS3.
â¢INSERTstatementsarefasterthanINSERT OVERWRITE forS3.ThequeryoptionS3_SKIP_INSERT_STAGING ,
whichissettotruebydefault,skipsthestagingstepforregularINSERT(butnotINSERT OVERWRITE ).This
makestheoperationmuchfaster,butconsistencyisnotguaranteed:ifanodefailsduringexecution,thetable
couldendupwithinconsistentdata.Setthisoptiontofalseifstrongerconsistencyisrequired,howeverthis
settingwillmaketheINSERToperationsslower.
â¢ToomanyfilesinatablecanmakemetadataloadingandupdatingslowonS3.Iftoomanyrequestsaremadeto
S3,S3hasaback-offmechanism andrespondsslowerthanusual.Youmighthavemanysmallfilesbecauseof:
âToomanypartitions duetoover-granularpartitioning. Preferpartitions withmanymegabytesofdata,so
thatevenaqueryagainstasinglepartition canbeparallelizedeffectively.
698|ApacheImpalaGuideUsingImpalawiththeAmazonS3Filesystem
âManysmallINSERTqueries.PreferbulkINSERTssothatmoredataiswrittentofewerfiles.
SpecifyingImpalaCredentialstoAccessDatainS3withClouderaManager
Clouderarecommends thatyouuseClouderaManagertospecifyImpalacredentialstoaccessdatainAmazonS3.If
youarenotusingClouderaManager,seeSpecifyingImpalaCredentialstoAccessDatainS3fromthecommand line.
ToconfigureaccesstodatastoredinS3forImpalawithClouderaManager,useoneofthefollowingauthentication
types:
â¢IAMRole-based Authentication
AmazonIdentity&AccessManagement(IAM).YoumustsetupIAMrole-based authenticationinAmazon.See
Amazondocumen tation.Thisauthenticationmethodisbestsuitedforenvironmentswherethereisasingleuser,
orwhereallclusteruserscanhavethesameprivilegestodatainS3.SeeHowtoConfigureAWSCredentialsfor
informationaboutusingIAMrole-based authenticationwithClouderaManager.
â¢AccessKeyAuthentication
Forenvironmentswhereyouhavemultipleusersormulti-tenancy,useanAWSaccesskeyandanAWSsecretkey
thatyouobtainfromAmazon.SeeAmazondocumen tation.Forthisscenario,youmustenabletheSentryservice
andKerberostousetheS3Connectorservice.ClouderaManagerstoresyourAWScredentialssecurelyanddoes
notstoretheminworld-readablelocations.IfyoucanusetheSentryserviceandKerberos,seethefollowing
sectionstoaddyourAWScredentialstoClouderaManagerandtomanagethem:
âAddingAWSCredentials
âManaging AWSCredentials
Note:IfyoucannotusetheSentryserviceorKerberosinyourenvironment,seethenextsection,
SpecifyingImpalaCredentialsonClustersNotSecuredbySentryorKerberosonpage699.
SpecifyingImpalaCredentialsonClustersNotSecuredbySentryorKerberos
IfyoucannotusetheSentryserviceorKerberosinyourenvironment,specifyImpalacredentialsintheCluster-wide
AdvancedConfigurationSnippet(SafetyValve)forcore-site.xml.Forexample:
<property>
   <name>fs.s3a.access.key</name>
   <value> your_access_key </value>
</property>
<property>
   <name>fs.s3a.secret.key</name>
   <value> your_secret_key </value>
</property>
SpecifyingyourcredentialsinthissafetyvalvedoesnotrequireKerberosortheSentryservice,butitisnotassecure.
Afterspecifyingthecredentials,restartboththeImpalaandHiveservices.RestartingHiveisrequiredbecauseoperations
suchasImpalaqueriesandCREATE TABLE statementsgothroughtheHivemetastore.
SpecifyingImpalaCredentialstoAccessDatainS3
ToallowImpalatoaccessdatainS3,specifyvaluesforthefollowingconfigurationsettingsinyourcore-site.xml
file:
<property>
ApacheImpalaGuide|699UsingImpalawiththeAmazonS3Filesystem
   <name>fs.s3a.access.key</name>
   <value> your_access_key </value>
</property>
<property>
   <name>fs.s3a.secret.key</name>
   <value> your_secret_key </value>
</property>
Afterspecifyingthecredentials,restartboththeImpalaandHiveservices.RestartingHiveisrequiredbecauseoperations
suchasImpalaqueriesandCREATE TABLE statementsgothroughtheHivemetastore.
Important:
Although youcanspecifytheaccesskeyIDandsecretkeyaspartofthes3a://URLintheLOCATION
attribute,doingsomakesthissensitiveinformationvisibleinmanyplaces,suchasDESCRIBE
FORMATTED outputandImpalalogfiles.Therefore,specifythisinformationcentrallyinthe
core-site.xml file,andrestrictreadaccesstothatfiletoonlytrustedusers.
700|ApacheImpalaGuideUsingImpalawiththeAmazonS3Filesystem
UsingImpalawiththeAzureDataLakeStore(ADLS)
YoucanuseImpalatoquerydataresidingontheAzureDataLakeStore(ADLS)filesystem.Thiscapabilityallows
convenientaccesstoastoragesystemthatisremotelymanaged,accessible fromanywhere,andintegratedwith
variouscloud-based services.ImpalacanqueryfilesinanysupportedfileformatfromADLS.TheADLSstoragelocation
canbeforanentiretableorindividual partitions inapartitioned table.
ThedefaultImpalatablesusedatafilesstoredonHDFS,whichareidealforbulkloadsandqueriesusingfull-table
scans.Incontrast,queriesagainstADLSdataarelessperformant,makingADLSsuitableforholdingâcoldâdatathatis
onlyqueriedoccasionally,whilemorefrequentlyaccessed âhotâdataresidesinHDFS.Inapartitioned table,youcan
settheLOCATION attributeforindividual partitions toputsomepartitions onHDFSandothersonADLS,typically
depending ontheageofthedata.
StartinginCDH6.1,Impalasupports ADLSGen2filesystem,AzureBlobFileSystem(ABFS).
Prerequisites
TheseprocedurespresumethatyouhavealreadysetupanAzureaccount,configuredanADLSstore,andconfigured
yourHadoopclusterwithappropriatecredentialstobeabletoaccessADLS.Seethefollowingresourcesforinformation:
â¢GetstartedwithAzureDataLakeStoreusingtheAzurePortal
â¢AzureDataLakeStorageGen2
â¢HadoopAzureDataLakeSupport
HowImpalaSQLStatementsWorkwithADLS
ImpalaSQLstatementsworkwithdataonADLSasfollows.
â¢TheCREATETABLEStatementonpage234orALTERTABLEStatementonpage205statementscanspecifythata
tableresidesontheADLSfilesystembyusingoneofthefollowingADLSprefixesintheLOCATION property.
â¢ForADLSGen1:adl://
â¢ForADLSGen2:abfs:// orabfss://
ALTER TABLE canalsosettheLOCATION propertyforanindividual partition, sothatsomedatainatableresides
onADLSandotherdatainthesametableresidesonHDFS.
SeeCreatingImpalaDatabases,Tables,andPartitionsforDataStoredonADLSonpage703forusageinformation.
â¢Onceatableorpartition isdesignatedasresidingonADLS,theSELECTStatementonpage295statement
transparentlyaccessesthedatafilesfromtheappropriatestoragelayer.
â¢IftheADLStableisaninternaltable,theDROPTABLEStatementonpage268statementremovesthecorresponding
datafilesfromADLSwhenthetableisdropped.
â¢TheTRUNCATETABLEStatement(CDH5.5orhigheronly)onpage381statementalwaysremovesthecorresponding
datafilesfromADLSwhenthetableistruncated.
â¢TheLOADDATAStatementonpage288canmovedatafilesresidinginHDFSintoanADLStable.
â¢TheINSERTStatementonpage277,ortheCREATE TABLE AS SELECT formoftheCREATE TABLE statement,
cancopydatafromanHDFStableoranotherADLStableintoanADLStable.
ForusageinformationaboutImpalaSQLstatementswithADLStables,seeUsingImpalaDMLStatementsforADLS
Dataonpage703.
ApacheImpalaGuide|701UsingImpalawiththeAzureDataLakeStore(ADLS)
SpecifyingImpalaCredentialstoAccessDatainADLS
YoucanconfigurecredentialstoaccessADLSinClouderaManagerorinplaintext.
WhenyouconfigurecredentialsusingClouderaManager,itprovidesamoresecurewaytoaccessADLSusingcredentials
thatarenotstoredinplain-textfiles.SeeConfiguringADLSAccessUsingClouderaManagerforthestepstoconfigure
ADLScredentialsusingClouderaManager.
Important:Clouderarecommends thatyouonlyusetheplaintextmethodforaccessing ADLSin
developmentenvironmentsorotherenvironmentswheresecurityisnotaconcern.
ToallowImpalatoaccessdatainADLSusingcredentialsinplaintext,specifyvaluesforthefollowingconfiguration
settingsinyourcore-site.xml file:
ForADLSGen1:
<property>
   <name>dfs.adls.oauth2.access.token.provider.type</name>
   <value>ClientCredential</value>
</property>
<property>
   <name>dfs.adls.oauth2.client.id</name>
   <value> your_client_id </value>
</property>
<property>
   <name>dfs.adls.oauth2.credential</name>
   <value> your_client_secret </value>
</property>
<property>
   <name>dfs.adls.oauth2.refresh.url</name>
   <value>https://login.windows.net/ your_azure_tenant_id /oauth2/token</value>
</property>
ForADLSGen2:
 <property>
    <name>fs.azure.account.auth.type</name>
    <value>OAuth</value>
  </property>
  <property>
    <name>fs.azure.account.oauth.provider.type</name>
    <value>org.apache.hadoop.fs.azurebfs.oauth2.ClientCredsTokenProvider</value>
  </property>
  <property>
    <name>fs.azure.account.oauth2.client.id</name>
    <value> your_client_id </value>
  </property>
  <property>
    <name>fs.azure.account.oauth2.client.secret</name>
    <value> your_client_secret </value>
  </property>
  <property>
    <name>fs.azure.account.oauth2.client.endpoint</name>
    <value>https://login.microsoftonline.com/ your_azure_tenant_id /oauth2/token</value>
  </property>
Note:
CheckifyourHadoopdistribution orclustermanagementtoolincludessupportforfillinginand
distributingcredentialsacrosstheclusterinanautomatedway.
702|ApacheImpalaGuideUsingImpalawiththeAzureDataLakeStore(ADLS)
Afterspecifyingthecredentials,restartboththeImpalaandHiveservices.RestartingHiveisrequiredbecauseImpala
DDLstatements,suchastheCREATE TABLE statements,gothroughtheHivemetastore.
LoadingDataintoADLSforImpalaQueries
IfyourETLpipelineinvolvesmovingdataintoADLSandthenqueryingthroughImpala,youcaneitheruseImpalaDML
statementstocreate,move,orcopythedata,orusethesamedataloadingtechniques asyouwouldfornon-Impala
data.
UsingImpalaDMLStatementsforADLSData
InCDH5.12/Impala2.9andhigher,theImpalaDMLstatements(INSERT,LOAD DATA ,andCREATE TABLE AS
SELECT)canwritedataintoatableorpartitionthatresidesintheAzureDataLakeStore(ADLS).ADLSGen2issupported
inCDH6.1andhigher.
IntheCREATE TABLE orALTER TABLE statements,specifytheADLSlocationfortablesandpartitions withtheadl://
prefixforADLSGen1andabfs:// orabfss:// forADLSGen2intheLOCATION attribute.
IfyoubringdataintoADLSusingthenormalADLStransfermechanisms insteadofImpalaDMLstatements,issuea
REFRESH statementforthetablebeforeusingImpalatoquerytheADLSdata.
Manually LoadingDataintoImpalaTablesonADLS
Asanalternative,youcanusetheMicrosoft-providedmethodstobringdatafilesintoADLSforqueryingthrough
Impala.SeetheMicrosoftADLSdocumen tationfordetails.
AfteryouuploaddatafilestoalocationalreadymappedtoanImpalatableorpartition, orifyoudeletefilesinADLS
fromsuchalocation,issuetheREFRESH table_name statementtomakeImpalaawareofthenewsetofdatafiles.
CreatingImpalaDatabases,Tables,andPartitionsforDataStoredonADLS
ImpalareadsdataforatableorpartitionfromADLSbasedontheLOCATION attributeforthetableorpartition. Specify
theADLSdetailsintheLOCATION clauseofaCREATE TABLE orALTER TABLE statement.ThesyntaxfortheLOCATION
clauseis:
â¢ForADLSGen1:
adl://account.azuredatalakestore.net/ path/file
â¢ForADLSGen2:
abfs://container @account.dfs.core.windows.net/ path/file
or
abfss:// container @account.dfs.core.windows.net/ path/file
container denotestheparentlocationthatholdsthefilesandfolders,whichistheContainersintheAzureStorage
Blobsservice.
account isthenamegivenforyourstorageaccount.
Note:
Bydefault,TLSisenabledbothwithabfs:// andabfss:// .
Whenyousetthefs.azure.always.use.https=false property,TLSisdisabledwithabfs:// ,
andTLSisenabledwithabfss://
ApacheImpalaGuide|703UsingImpalawiththeAzureDataLakeStore(ADLS)
Forapartitioned table,eitherspecifyaseparateLOCATION clauseforeachnewpartition, orspecifyabaseLOCATION
forthetableandsetupadirectorystructureinADLStomirrorthewayImpalapartitioned tablesarestructuredin
HDFS.Although, strictlyspeaking,ADLSfilenames donothavedirectorypaths,ImpalatreatsADLSfilenames with/
charactersthesameasHDFSpathnames thatincludedirectories.
Topointanonpartitioned tableoranindividual partition atADLS,specifyasingledirectorypathinADLS,whichcould
beanyarbitrarydirectory.ToreplicatethestructureofanentireImpalapartitioned tableordatabaseinADLSrequires
morecare,withdirectoriesandsubdirectoriesnestedandnamedtomatchtheequivalentdirectorytreeinHDFS.
Consider settingupanemptystagingareaifnecessaryinHDFS,andrecordingthecompletedirectorystructuresothat
youcanreplicateitinADLS.
Forexample,thefollowingsessioncreatesapartitioned tablewhereonlyasinglepartition residesonADLS.The
partitions foryears2013and2014arelocatedonHDFS.Thepartition foryear2015includesaLOCATION attribute
withanadl://URL,andsoreferstodataresidingonADLS,underaspecificpathundernea ththestoreimpalademo .
[localhost:21000] > create database db_on_hdfs;
[localhost:21000] > use db_on_hdfs;
[localhost:21000] > create table mostly_on_hdfs (x int) partitioned by (year int);
[localhost:21000] > alter table mostly_on_hdfs add partition (year=2013);
[localhost:21000] > alter table mostly_on_hdfs add partition (year=2014);
[localhost:21000] > alter table mostly_on_hdfs add partition (year=2015)
                  >   location 
'adl://impalademo.azuredatalakestore.net/dir1/dir2/dir3/t1';
ForconveniencewhenworkingwithmultipletableswithdatafilesstoredinADLS,youcancreateadatabasewitha
LOCATION attributepointingtoanADLSpath.SpecifyaURLoftheformasshownabove.Anytablescreatedinside
thatdatabaseautomaticallycreatedirectoriesundernea ththeonespecified bythedatabaseLOCATION attribute.
Thefollowingsessioncreatesadatabaseandtwopartitioned tablesresidingentirelyonADLS,onepartitioned bya
singlecolumnandtheotherpartitioned bymultiplecolumns.BecauseaLOCATION attributewithanadl://URLis
specified forthedatabase,thetablesinsidethatdatabaseareautomaticallycreatedonADLSundernea ththedatabase
directory.Toseethenamesoftheassociatedsubdirectories,including thepartition keyvalues,weuseanADLSclient
tooltoexaminehowthedirectorystructureisorganizedonADLS.Forexample,Impalapartition directoriessuchas
month=1 donotincludeleadingzeroes,whichsometimesappearinpartition directoriescreatedthroughHive.
[localhost:21000] > create database db_on_adls location 
'adl://impalademo.azuredatalakestore.net/dir1/dir2/dir3';
[localhost:21000] > use db_on_adls;
[localhost:21000] > create table partitioned_on_adls (x int) partitioned by (year int);
[localhost:21000] > alter table partitioned_on_adls add partition (year=2013);
[localhost:21000] > alter table partitioned_on_adls add partition (year=2014);
[localhost:21000] > alter table partitioned_on_adls add partition (year=2015);
[localhost:21000] > ! hadoop fs -ls adl://impalademo.azuredatalakestore.net/dir1/dir2/dir3
 --recursive;
2015-03-17 13:56:34          0 dir1/dir2/dir3/
2015-03-17 16:43:28          0 dir1/dir2/dir3/partitioned_on_adls/
2015-03-17 16:43:49          0 dir1/dir2/dir3/partitioned_on_adls/year=2013/
2015-03-17 16:43:53          0 dir1/dir2/dir3/partitioned_on_adls/year=2014/
2015-03-17 16:43:58          0 dir1/dir2/dir3/partitioned_on_adls/year=2015/
[localhost:21000] > create table partitioned_multiple_keys (x int)
                  >   partitioned by (year smallint, month tinyint, day tinyint);
[localhost:21000] > alter table partitioned_multiple_keys
                  >   add partition (year=2015,month=1,day=1);
[localhost:21000] > alter table partitioned_multiple_keys
                  >   add partition (year=2015,month=1,day=31);
[localhost:21000] > alter table partitioned_multiple_keys
                  >   add partition (year=2015,month=2,day=28);
[localhost:21000] > ! hadoop fs -ls adl://impalademo.azuredatalakestore.net/dir1/dir2/dir3
 --recursive;
2015-03-17 13:56:34          0 dir1/dir2/dir3/
2015-03-17 16:47:13          0 dir1/dir2/dir3/partitioned_multiple_keys/
2015-03-17 16:47:44          0 
dir1/dir2/dir3/partitioned_multiple_keys/year=2015/month=1/day=1/
704|ApacheImpalaGuideUsingImpalawiththeAzureDataLakeStore(ADLS)
2015-03-17 16:47:50          0 
dir1/dir2/dir3/partitioned_multiple_keys/year=2015/month=1/day=31/
2015-03-17 16:47:57          0 
dir1/dir2/dir3/partitioned_multiple_keys/year=2015/month=2/day=28/
2015-03-17 16:43:28          0 dir1/dir2/dir3/partitioned_on_adls/
2015-03-17 16:43:49          0 dir1/dir2/dir3/partitioned_on_adls/year=2013/
2015-03-17 16:43:53          0 dir1/dir2/dir3/partitioned_on_adls/year=2014/
2015-03-17 16:43:58          0 dir1/dir2/dir3/partitioned_on_adls/year=2015/
TheCREATE DATABASE andCREATE TABLE statementscreatetheassociateddirectorypathsiftheydonotalready
exist.Youcanspecifymultiplelevelsofdirectories,andtheCREATEstatementcreatesallappropriatelevels,similar
tousingmkdir -p .
UsethestandardADLSfileuploadmethodstoactuallyputthedatafilesintotherightlocations.Youcanalsoputthe
directorypathsanddatafilesinplacebeforecreatingtheassociatedImpaladatabasesortables,andImpalaautomatically
usesthedatafromtheappropriatelocationaftertheassociateddatabasesandtablesarecreated.
YoucanswitchwhetheranexistingtableorpartitionpointstodatainHDFSorADLS.Forexample,ifyouhaveanImpala
tableorpartitionpointingtodatafilesinHDFSorADLS,andyoulatertransferthosedatafilestotheotherfilesystem,
useanALTER TABLE statementtoadjusttheLOCATION attributeofthecorresponding tableorpartition toreflect
thatchange.Thislocation-switchingtechnique isnotpracticalforentiredatabasesthathaveacustomLOCATION
attribute.
InternalandExternalTablesLocatedonADLS
JustaswithtableslocatedonHDFSstorage,youcandesignateADLS-based tablesaseitherinternal(managedby
Impala)orexternal,byusingthesyntaxCREATE TABLE orCREATE EXTERNAL TABLE respectively.Whenyoudrop
aninternaltable,thefilesassociatedwiththetableareremoved,eveniftheyareonADLSstorage.Whenyoudrop
anexternaltable,thefilesassociatedwiththetableareleftalone,andarestillavailableforaccessbyothertoolsor
componen ts.SeeOverviewofImpalaTablesonpage196fordetails.
IfthedataonADLSisintendedtobelong-livedandaccessed byothertoolsinadditiontoImpala,createanyassociated
ADLStableswiththeCREATE EXTERNAL TABLE syntax,sothatthefilesarenotdeletedfromADLSwhenthetable
isdropped.
IfthedataonADLSisonlyneededforqueryingbyImpalaandcanbesafelydiscardedoncetheImpalaworkflowis
complete,createtheassociatedADLStablesusingtheCREATE TABLE syntax,sothatdroppingthetablealsodeletes
thecorresponding datafilesonADLS.
Forexample,thissessioncreatesatableinADLSwiththesamecolumnlayoutasatableinHDFS,thenexaminesthe
ADLStableandqueriessomedatafromit.ThetableinADLSworksthesameasatableinHDFSasfarastheexpected
fileformatofthedata,tableandcolumnstatistics,andothertableproperties. TheonlyindicationthatitisnotanHDFS
tableistheadl://URLintheLOCATION property.ManydatafilescanresideintheADLSdirectory,andtheircombined
contentsformthetabledata.Becausethedatainthisexampleisuploaded afterthetableiscreated,aREFRESH
statementpromptsImpalatoupdateitscachedinformationaboutthedatafiles.
[localhost:21000] > create table usa_cities_adls like usa_cities location 
'adl://impalademo.azuredatalakestore.net/usa_cities';
[localhost:21000] > desc usa_cities_adls;
+-------+----------+---------+
| name  | type     | comment |
+-------+----------+---------+
| id    | smallint |         |
| city  | string   |         |
| state | string   |         |
+-------+----------+---------+
-- Now from a web browser, upload the same data file(s) to ADLS as in the HDFS table,
-- under the relevant store and path. If you already have the data in ADLS, you would
-- point the table LOCATION at an existing path.
[localhost:21000] > refresh usa_cities_adls;
[localhost:21000] > select count(*) from usa_cities_adls;
ApacheImpalaGuide|705UsingImpalawiththeAzureDataLakeStore(ADLS)
+----------+
| count(*) |
+----------+
| 289      |
+----------+
[localhost:21000] > select distinct state from sample_data_adls limit 5;
+----------------------+
| state                |
+----------------------+
| Louisiana            |
| Minnesota            |
| Georgia              |
| Alaska               |
| Ohio                 |
+----------------------+
[localhost:21000] > desc formatted usa_cities_adls;
+------------------------------+----------------------------------------------------+---------+
| name                         | type                                               | 
comment |
+------------------------------+----------------------------------------------------+---------+
| # col_name                   | data_type                                          | 
comment |
|                              | NULL                                               | 
NULL    |
| id                           | smallint                                           | 
NULL    |
| city                         | string                                             | 
NULL    |
| state                        | string                                             | 
NULL    |
|                              | NULL                                               | 
NULL    |
| # Detailed Table Information | NULL                                               | 
NULL    |
| Database:                    | adls_testing                                       | 
NULL    |
| Owner:                       | jrussell                                           | 
NULL    |
| CreateTime:                  | Mon Mar 16 11:36:25 PDT 2017                       | 
NULL    |
| LastAccessTime:              | UNKNOWN                                            | 
NULL    |
| Protect Mode:                | None                                               | 
NULL    |
| Retention:                   | 0                                                  | 
NULL    |
| Location:                    | adl://impalademo.azuredatalakestore.net/usa_cities | 
NULL    |
| Table Type:                  | MANAGED_TABLE                                      | 
NULL    |
...
+------------------------------+----------------------------------------------------+---------+
Inthiscase,wehavealreadyuploaded aParquetfilewithamillionrowsofdatatothesample_data directory
undernea ththeimpalademo storeonADLS.Thissessioncreatesatablewithmatchingcolumnsettingspointingto
thecorresponding locationinADLS,thenqueriesthetable.BecausethedataisalreadyinplaceonADLSwhenthe
tableiscreated,noREFRESH statementisrequired.
[localhost:21000] > create table sample_data_adls
                  > (id int, id bigint, val int, zerofill string,
                  > name string, assertion boolean, city string, state string)
                  > stored as parquet location 
'adl://impalademo.azuredatalakestore.net/sample_data';
[localhost:21000] > select count(*) from sample_data_adls;
+----------+
| count(*) |
+----------+
| 1000000  |
+----------+
[localhost:21000] > select count(*) howmany, assertion from sample_data_adls group by 
706|ApacheImpalaGuideUsingImpalawiththeAzureDataLakeStore(ADLS)
assertion;
+---------+-----------+
| howmany | assertion |
+---------+-----------+
| 667149  | true      |
| 332851  | false     |
+---------+-----------+
RunningandTuningImpalaQueriesforDataStoredonADLS
OncetheappropriateLOCATION attributesaresetupatthetableorpartition level,youquerydatastoredinADLS
exactlythesameasdatastoredonHDFSorinHBase:
â¢QueriesagainstADLSdatasupportallthesamefileformatsasforHDFSdata.
â¢Tablescanbeunpartitioned orpartitioned. Forpartitioned tables,eithermanually constructpathsinADLS
corresponding totheHDFSdirectoriesrepresentingpartition keyvalues,oruseALTER TABLE ... ADD
PARTITION tosetuptheappropriatepathsinADLS.
â¢HDFS,Kudu,andHBasetablescanbejoinedtoADLStables,orADLStablescanbejoinedwitheachother.
â¢AuthorizationusingtheSentryframeworktocontrolaccesstodatabases,tables,orcolumnsworksthesame
whetherthedataisinHDFSorinADLS.
â¢Thecatalogd daemoncachesmetadataforbothHDFSandADLStables.UseREFRESH andINVALIDATE
METADATA forADLStablesinthesamesituationswhereyouwouldissuethosestatementsforHDFStables.
â¢QueriesagainstADLStablesaresubjecttothesamekindsofadmission controlandresourcemanagementas
HDFStables.
â¢MetadataaboutADLStablesisstoredinthesamemetastoredatabaseasforHDFStables.
â¢YoucansetupviewsreferringtoADLStables,thesameasforHDFStables.
â¢TheCOMPUTE STATS ,SHOW TABLE STATS ,andSHOW COLUMN STATS statementsworkforADLStablesalso.
UnderstandingandTuningImpalaQueryPerformance forADLSData
Although ImpalaqueriesfordatastoredinADLSmightbelessperformantthanqueriesagainsttheequivalentdata
storedinHDFS,youcanstilldosometuning.Herearetechniques youcanusetointerpretexplainplansandprofiles
forqueriesagainstADLSdata,andtipstoachievethebestperformance possibleforsuchqueries.
Allelsebeingequal,performance isexpectedtobelowerforqueriesrunningagainstdataonADLSratherthanHDFS.
Theactualmechanics oftheSELECTstatementaresomewhatdifferentwhenthedataisinADLS.Although thework
isstilldistributedacrossthedatanodesofthecluster,Impalamightparallelizetheworkforadistributedquerydifferently
fordataonHDFSandADLS.ADLSdoesnothavethesameblocknotionasHDFS,soImpalausesheuristicstodetermine
howtosplituplargeADLSfilesforprocessinginparallel.BecauseallhostscanaccessanyADLSdatafilewithequal
efficiency,thedistribution ofworkmightbedifferentthanforHDFSdata,wherethedatablocksarephysicallyread
usingshort-circuitlocalreadsbyhoststhatcontaintheappropriateblockreplicas.Although theI/OtoreadtheADLS
datamightbespreadevenlyacrossthehostsofthecluster,thefactthatalldataisinitiallyretrievedacrossthenetwork
meansthattheoverallqueryperformance islikelytobelowerforADLSdatathanforHDFSdata.
BecausedatafileswrittentoADLSdonothaveadefaultblocksizethewayHDFSdatafilesdo,anyImpalaINSERTor
CREATE TABLE AS SELECT statementsusethePARQUET_FILE_SIZE queryoptionsettingtodefinethesizeof
Parquetdatafiles.(UsingalargeblocksizeismoreimportantforParquettablesthanfortablesthatuseotherfile
formats.)
Whenoptimizingaspectsofforcomplexqueriessuchasthejoinorder,ImpalatreatstablesonHDFSandADLSthe
sameway.Therefore,followallthesametuningrecommenda tionsforADLStablesasforHDFSones,suchasusingthe
COMPUTE STATS statementtohelpImpalaconstructaccurateestimatesofrowcountsandcardinality.SeeTuning
ImpalaforPerformance onpage565fordetails.
Inqueryprofilereports,thenumbersforBytesReadLocal ,BytesReadShortCircuit ,BytesReadDataNodeCached ,
andBytesReadRemoteUnexpected areblankbecausethosemetricscomefromHDFS.Ifyoudoseeanyindications
thataqueryagainstanADLStableperformedâremotereadâoperations,donotbealarmed. Thatisexpectedbecause,
bydefinition,alltheI/OforADLStablesinvolvesremotereads.
ApacheImpalaGuide|707UsingImpalawiththeAzureDataLakeStore(ADLS)
RestrictionsonImpalaSupportforADLS
ImpalarequiresthatthedefaultfilesystemfortheclusterbeHDFS.YoucannotuseADLSastheonlyfilesysteminthe
cluster.
Although ADLSisoftenusedtostoreJSON-formatteddata,thecurrentImpalasupportforADLSdoesnotinclude
directlyqueryingJSONdata.ForImpalaqueries,usedatafilesinoneofthefileformatslistedinHowImpalaWorks
withHadoopFileFormatsonpage634.IfyouhavedatainJSONformat,youcanprepareaflattenedversionofthat
dataforqueryingbyImpalaaspartofyourETLcycle.
YoucannotusetheALTER TABLE ... SET CACHED statementfortablesorpartitions thatarelocatedinADLS.
BestPracticesforUsingImpalawithADLS
Thefollowingguidelines representbestpracticesderivedfromtestingandreal-worldexperience withImpalaonADLS:
â¢AnyreferencetoanADLSlocationmustbefullyqualified. (ThisruleapplieswhenADLSisnotdesignatedasthe
defaultfilesystem.)
â¢Setanyappropriateconfigurationsettingsforimpalad .
708|ApacheImpalaGuideUsingImpalawiththeAzureDataLakeStore(ADLS)
UsingImpalaLogging
TheImpalalogsrecordinformationabout:
â¢AnyerrorsImpalaencountered.IfImpalaexperienced aseriouserrorduringstartup,youmustdiagnose and
troubleshoot thatproblembeforeyoucandoanythingfurtherwithImpala.
â¢HowImpalaisconfigured.
â¢JobsImpalahascompleted.
Note:
Formerly,thelogscontainedthequeryprofileforeachquery,showinglow-leveldetailsofhowthe
workisdistributedamongnodesandhowintermediateandfinalresultsaretransmittedacrossthe
network.Tosavespace,thosequeryprofilesarenowstoredinzlib-compressedfilesin
/var/log/impala/profiles .YoucanaccessthemthroughtheImpalawebuserinterface.For
example,athttp://impalad-node-hostname :25000/queries ,eachqueryisfollowedbya
Profile linkleadingtoapageshowingextensiveanalyticaldataforthequeryexecution.
TheauditingfeatureintroducedinImpala1.1.1producesaseparatesetofauditlogfileswhenenabled.
SeeAuditingImpalaOperationsonpage78fordetails.
InCDH5.12/Impala2.9andhigher,youcancontrolhowmanyauditeventlogfilesarekeptoneach
hostthroughthe--max_audit_event_log_files startupoptionfortheimpalad daemon, similar
tothe--max_log_files optionforregularlogfiles.
ThelineagefeatureintroducedinImpala2.2.0producesaseparatelineagelogfilewhenenabled.See
ViewingLineageInformationforImpalaDataonpage80fordetails.
LocationsandNamesofImpalaLogFiles
â¢Bydefault,thelogfilesareunderthedirectory/var/log/impala .Tochangelogfilelocations,editthelogfile
propertiesintheImpalaserviceinClouderaManager(Impalaservice>Configuration).
â¢Thesignificantfilesfortheimpalad processareimpalad.INFO ,impalad.WARNING ,andimpalad.ERROR .You
mightalsoseeafileimpalad.FATAL ,although thisisonlypresentinrareconditions.
â¢Thesignificantfilesforthestatestored processarestatestored.INFO ,statestored.WARNING ,and
statestored.ERROR .Youmightalsoseeafilestatestored.FATAL ,although thisisonlypresentinrare
conditions.
â¢Thesignificantfilesforthecatalogd processarecatalogd.INFO ,catalogd.WARNING ,andcatalogd.ERROR .
Youmightalsoseeafilecatalogd.FATAL ,although thisisonlypresentinrareconditions.
â¢Examinethe.INFOfilestoseeconfigurationsettingsfortheprocesses.
â¢Examinethe.WARNING filestoseeallkindsofprobleminformation,including suchthingsassuboptimalsettings
andalsoseriousruntimeerrors.
â¢Examinethe.ERRORand/or.FATALfilestoseeonlythemostseriouserrors,iftheprocessescrash,orqueries
failtocomplete.Thesemessagesarealsointhe.WARNING file.
â¢Anewsetoflogfilesisproducedeachtimetheassociateddaemonisrestarted.Theselogfileshavelongnames
including atimestamp.The.INFO,.WARNING ,and.ERRORfilesarephysicallyrepresentedassymboliclinksto
thelatestapplicablelogfiles.
â¢Theinitscriptfortheimpala-server servicealsoproducesaconsolidatedlogfile
/var/log/impalad/impala-server.log ,withallthesameinformationasthecorresponding .INFO,.WARNING ,
and.ERRORfiles.
â¢Theinitscriptfortheimpala-state-store servicealsoproducesaconsolidatedlogfile
/var/log/impalad/impala-state-store.log ,withallthesameinformationasthecorresponding .INFO,
.WARNING ,and.ERRORfiles.
ApacheImpalaGuide|709UsingImpalaLogging
Impalastoresinformationusingtheglog_vloggingsystem.YouwillseesomemessagesreferringtoC++filenames.
Loggingisaffectedby:
â¢TheGLOG_venvironmentvariablespecifieswhichtypesofmessagesarelogged.SeeSettingLoggingLevelson
page711fordetails.
â¢The--logbuflevel startupflagfortheimpalad daemonspecifieshowoftentheloginformationiswrittento
disk.Thedefaultis0,meaningthatthelogisimmediatelyflushedtodiskwhenImpalaoutputsanimportant
messagessuchasawarningoranerror,butlessimportantmessagessuchasinformationalonesarebufferedin
memoryratherthanbeingflushedtodiskimmediately.
â¢ClouderaManagerhasanImpalaconfigurationsettingthatsetsthe-logbuflevel startupoption.
Managing ImpalaLogsthroughClouderaManagerorManually
Clouderarecommends installingImpalathroughtheClouderaManageradministrationinterface.Toassistwith
troubleshooting ,ClouderaManagercollectsfront-endandback-end logstogetherintoasingleview,andletyoudoa
searchacrosslogdataforallthemanagednodesratherthanexaminingthelogsoneachnodeseparately.Ifyouinstalled
ImpalausingClouderaManager,refertothetopicsonMonitoringServicesorLogs.
IfyouareusingImpalainanenvironmentnotmanagedbyClouderaManager,reviewImpalalogfilesoneachhost,
whenyouhavetracedanissuebacktoaspecificsystem.
RotatingImpalaLogs
Impalaperiodicallyrotateslogs.Itswitchesthephysicalfilesrepresentingthecurrentlogfilesandremovesolderlog
filesthatarenolongerneeded.
InImpala2.2andhigher,the--max_log_files configurationoptionspecifieshowmanylogfilestokeepateach
severitylevel(INFO,WARNING ,ERROR,andFATAL).YoucanspecifyanappropriatesettingforeachImpala-related
daemon(impalad ,statestored ,andcatalogd ).
â¢Avalueof0preservesalllogfiles,inwhichcaseyouwouldsetupsetupmanuallogrotationusingyourLinuxtool
ortechnique ofchoice.
â¢Avalueof1preservesonlytheverylatestlogfile.
â¢Thedefaultvalueis10.
Forsomeloglevels,Impalalogsarefirsttemporarilybufferedinmemoryandonlywrittentodiskperiodically.The
--logbufsecs settingcontrolsthemaximumtimethatlogmessagesarebufferedfor.Forexample,withthedefault
valueof5seconds,theremaybeuptoa5seconddelaybeforealoggedmessageshowsupinthelogfile.
Itisnotrecommended thatyouset--logbufsecs to0asthesettingmakestheImpaladaemontospininthethread
thattriestodeleteoldlogfiles.
TosetuplogrotationonasystemmanagedbyClouderaManager:
1.IntheImpalaConfigurationtab,typemax_log_files .
2.SettheappropriatevaluefortheMaximumLogFilesfieldforeachImpalaconfigurationcategory,Impala,Catalog
Server,andStateStore.
3.RestarttheImpalaservice.
InearlierClouderaManagerreleases,specifythe-max_log_files= maximum optionintheCommand LineArgument
AdvancedConfigurationSnippet(SafetyValve)fieldforeachImpalaconfigurationcategory.
ReviewingImpalaLogs
Bydefault,theImpalalogisstoredat/var/log/impalad/ .Themostcomprehensivelog,showinginformational,
warning,anderrormessages,isinthefilenameimpalad.INFO .Viewlogfilecontentsbyusingthewebinterfaceor
byexaminingthecontentsofthelogfile.(Whenyouexaminethelogsthroughthefilesystem,youcantroubleshoot
710|ApacheImpalaGuideUsingImpalaLogging
problemsbyreadingtheimpalad.WARNING and/orimpalad.ERROR files,whichcontainthesubsetsofmessages
indicatingpotentialproblems.)
Onamachinenamedimpala.example.com withdefaultsettings,youcouldviewtheImpalalogsonthatmachine
byusingabrowsertoaccesshttp://impala.example.com:25000/logs .
Note:
Thewebinterfacelimitstheamountoflogginginformationdisplayed.Tovieweverylogentry,access
thelogfilesdirectlythroughthefilesystem.
Youcanviewthecontentsoftheimpalad.INFO logfileinthefilesystem.Withthedefaultconfigurationsettings,
thestartofthelogfileappearsasfollows:
[user@example impalad]$ pwd
/var/log/impalad
[user@example impalad]$ more impalad.INFO
Log file created at: 2013/01/07 08:42:12
Running on machine: impala.example.com
Log line format: [IWEF]mmdd hh:mm:ss.uuuuuu threadid file:line] msg
I0107 08:42:12.292155 14876 daemon.cc:34] impalad version 0.4 RELEASE (build 
9d7fadca0461ab40b9e9df8cdb47107ec6b27cff)
Built on Fri, 21 Dec 2012 12:55:19 PST
I0107 08:42:12.292484 14876 daemon.cc:35] Using hostname: impala.example.com
I0107 08:42:12.292706 14876 logging.cc:76] Flags (see also /varz are on debug webserver):
--dump_ir=false
--module_output=
--be_port=22000
--classpath=
--hostname=impala.example.com
Note:Theprecedingexampleshowsonlyasmallpartofthelogfile.Impalalogfilesareoftenseveral
megabytesinsize.
UnderstandingImpalaLogContents
ThelogsstoreinformationaboutImpalastartupoptions.ThisinformationappearsonceforeachtimeImpalaisstarted
andmayinclude:
â¢Machine name.
â¢Impalaversionnumber.
â¢FlagsusedtostartImpala.
â¢CPUinformation.
â¢Thenumberofavailabledisks.
ThereisinformationabouteachjobImpalahasrun.BecauseeachImpalajobcreatesanadditional setofdataabout
queries,theamountofjobspecificdatamaybeverylarge.Logsmaycontaineddetailedinformationonjobs.These
detailedlogentriesmayinclude:
â¢Thecomposition ofthequery.
â¢Thedegreeofdatalocality.
â¢Statisticsondatathroughputandresponsetimes.
SettingLoggingLevels
ImpalausestheGLOGsystem,whichsupports threelogginglevels.YoucanadjustthelogginglevelsusingtheCloudera
ManagerAdminConsole.YoucanadjustlogginglevelswithoutgoingthroughtheClouderaManagerAdminConsole
ApacheImpalaGuide|711UsingImpalaLogging
byexportingvariablesettings.Tochangeloggingsettingsmanually,useacommand similartothefollowingoneach
nodebeforestartingimpalad :
export GLOG_v=1
Note:Forperformance reasons,Clouderahighlyrecommends notenablingthemostverboselogging
levelof3.
FormoreinformationonhowtoconfigureGLOG,including howtosetvariablelogginglevelsfordifferentsystem
componen ts,seedocumen tationfortheglogprojectongithub.
UnderstandingWhatisLoggedatDifferentLoggingLevels
Aslogginglevelsincrease,thecategoriesofinformationloggedarecumulative.Forexample,GLOG_v=2records
everythingGLOG_v=1records,aswellasadditional information.
Increasinglogginglevelsimposesperformanceoverheadandincreaseslogsize.Clouderarecommends usingGLOG_v=1
formostcases:thislevelhasminimalperformance impactbutstillcapturesusefultroubleshooting information.
Additional informationloggedateachlevelisasfollows:
â¢GLOG_v=1-Thedefaultlevel.Logsinformationabouteachconnection andquerythatisinitiatedtoanimpalad
instance,including runtimeprofiles.
â¢GLOG_v=2-EverythingfromthepreviouslevelplusinformationforeachRPCinitiated.Thislevelalsorecords
queryexecutionprogressinformation,including detailsoneachfilethatisread.
â¢GLOG_v=3-Everythingfromthepreviouslevelplusloggingofeveryrowthatisread.Thislevelisonlyapplicable
forthemostserioustroubleshooting andtuningscenarios, becauseitcanproduceexceptionallylargeanddetailed
logfiles,potentiallyleadingtoitsownsetofperformance andcapacityproblems.
RedactingSensitiveInformationfromImpalaLogFiles
Logredaction isasecurityfeaturethatpreventssensitiveinformationfrombeingdisplayedinlocationsusedby
administratorsformonitoringandtroubleshooting ,suchaslogfiles,theClouderaManageruserinterface,andthe
Impaladebugwebuserinterface.Youconfigureregularexpressionsthatmatchsensitivetypesofinformationprocessed
byyoursystem,suchascreditcardnumbersortaxIDs,andliteralsmatchingthesepatternsareobfuscatedwherever
theywouldnormally berecordedinlogfilesordisplayedinadministrationordebugginguserinterfaces.
Inasecuritycontext,thelogredactionfeatureiscomplemen tarytotheSentryauthorizationframework.Sentryprevents
unauthoriz edusersfrombeingabletodirectlyaccesstabledata.Redactionpreventsadministratorsorsupportpersonnel
fromseeingthesmalleramountsofsensitiveorpersonallyidentifyinginformation(PII)thatmightappearinqueries
issuedbythoseauthorizedusers.
SeetheCDHSecurityGuidefordetailsabouthowtoenablethisfeatureandsetuptheregularexpressionstodetect
andredactsensitiveinformationwithinSQLstatementtext.
712|ApacheImpalaGuideUsingImpalaLogging
ImpalaClientAccess
ApplicationdevelopershaveanumberofoptionstointerfacewithImpala.ThecoredevelopmentlanguagewithImpala
isSQL.YoucanalsouseJavaorotherlanguagestointeractwithImpalathroughthestandardJDBCandODBCinterfaces
usedbymanybusinessintelligencetools.Forspecializedkindsofanalysis,youcansupplemen ttheImpalabuilt-in
functions bywritinguser-definedfunctions inC++orJava.
YoucanconnectandsubmitrequeststotheImpalathrough:
â¢Theimpala-shell interactivecommand interpreter
â¢TheHueweb-based userinterface
â¢JDBC
â¢ODBC
Eachimpalad daemonprocess,runningonseparatenodesinacluster,listenstoseveralportsforincomingrequests:
â¢Requestsfromimpala-shell andHueareroutedtotheimpalad daemons throughthesameport.
â¢Theimpalad daemons listenonseparateportsforJDBCandODBCrequests.
ImpalaStartupOptionsforClientConnections
Thefollowingoptionscontrolclientconnections toImpala.
--fe_service_threads
Specifies themaximumnumberofconcurrentclientconnections allowed.Thedefaultvalueis64withwhich64
queriescanrunsimultaneously.
IfyouhavemoreclientstryingtoconnecttoImpalathanthevalueofthissetting,thelaterarrivingclientshaveto
waitforthedurationspecified by--accepted_client_cnxn_timeout .Youcanincreasethisvaluetoallow
moreclientconnections. However,alargevaluemeansmorethreadstobemaintainedevenifmostofthe
connections areidle,anditcouldnegativelyimpactquerylatency.Clientapplicationsshouldusetheconnection
pooltoavoidneedforlargenumberofsessions.
--accepted_client_cnxn_timeout
ControlshowImpalatreatsnewconnection requestsifithasrunoutofthenumberofthreadsconfiguredby
--fe_service_threads
If--accepted_client_cnxn_timeout > 0 ,newconnection requestsarerejectedifImpalacan'tgetaserver
threadwithinthespecified (inseconds)timeout.
If--accepted_client_cnxn_timeout=0 ,i.e.notimeout,clientswaitindefinitelytoopenthenewsessionuntil
morethreadsareavailable.
Thedefaulttimeoutis5minutes.
Thetimeoutappliesonlytoclientfacingthriftservers,i.e.,HS2andBeeswaxservers.
UsingtheImpalaShell(impala-shell Command)
YoucanusetheImpalashelltool(impala-shell )tosetupdatabasesandtables,insertdata,andissuequeries.For
adhocqueriesandexploration,youcansubmitSQLstatementsinaninteractivesession.Toautomateyourwork,you
canspecifycommand-line optionstoprocessasinglestatementorascriptfile.Theimpala-shell interpreteraccepts
allthesameSQLstatementslistedinImpalaSQLStatementsonpage202,plussomeshell-only commands thatyou
canusefortuningperformance anddiagnosing problems.
Theimpala-shell command fitsintothefamiliarUnixtoolchain:
ApacheImpalaGuide|713ImpalaClientAccess
â¢The-qoptionletsyouissueasinglequeryfromthecommand line,withoutstartingtheinteractiveinterpreter.
Youcouldusethisoptiontorunimpala-shell frominsideashellscriptorwiththecommand invocationsyntax
fromaPython,Perl,orotherkindofscript.
â¢The-foptionletsyouprocessafilecontainingmultipleSQLstatements,suchasasetofreportsorDDLstatements
tocreateagroupoftablesandviews.
â¢The--varoptionletsyoupasssubstitutionvariablestothestatementsthatareexecutedbythatimpala-shell
session,forexamplethestatementsinascriptfileprocessedbythe-foption.Youencodethesubstitutionvariable
onthecommand lineusingthenotation--var=variable_name =value.WithinaSQLstatement,yousubstitute
thevaluebyusingthenotation${var:variable_name }.ThisfeatureisavailableinCDH5.7/Impala2.5and
higher.
â¢The-ooptionletsyousavequeryoutputtoafile.
â¢The-Boptionturnsoffpretty-printing,sothatyoucanproducecomma-separ ated,tab-separated,orother
delimitedtextfilesasoutput.(Usethe--output_delimiter optiontochoosethedelimitercharacter;the
defaultisthetabcharacter.)
â¢Innon-interactivemode,queryoutputisprintedtostdoutortothefilespecifiedbythe-ooption,whileincidental
outputisprintedtostderr,sothatyoucanprocessjustthequeryoutputaspartofaUnixpipeline.
â¢Ininteractivemode,impala-shell usesthereadline facilitytorecallandeditpreviouscommands.
ClouderaManagerinstallsimpala-shell automatically.Youmightinstallimpala-shell manually onothersystems
notmanagedbyClouderaManager,sothatyoucanissuequeriesfromclientsystemsthatarenotalsorunningthe
ImpaladaemonorotherApacheHadoopcomponen ts.
Forinformationaboutestablishingaconnection toacoordinatorImpaladaemonthroughtheimpala-shell command,
seeConnecting toimpaladthroughimpala-shell onpage718.
Foralistoftheimpala-shell command-line options,seeimpala-shell ConfigurationOptionsonpage714.Forreference
informationabouttheimpala-shell interactivecommands, seeimpala-shell Command Referenceonpage721.
impala-shell ConfigurationOptions
Youcanspecifythefollowingoptionswhenstartingtheimpala-shell command tochangehowshellcommands
areexecuted.Thetableshowstheformattousewhenspecifyingeachoptiononthecommand line,orthroughthe
$HOME/.impalarc configurationfile.
Note:
Theseoptionsaredifferentthantheconfigurationoptionsfortheimpalad daemonitself.Forthe
impalad options,seeModifyingImpalaStartupOptions.
Summaryofimpala-shell ConfigurationOptions
Thefollowingtableshowsthenamesandallowedargumentsfortheimpala-shell configurationoptions.Youcan
specifyoptionsonthecommand line,orinaconfigurationfileasdescribed inimpala-shell ConfigurationFileonpage
717.
Explanation ConfigurationFileSetting Command-Line Option
Causesallqueryresultstobeprintedinplainformatasa
delimitedtextfile.Usefulforproducingdatafilestobewrite_delimit ed=true -Bor--delimited
usedwithotherHadoopcomponen ts.Alsousefulfor
avoidingtheperformance overheadofpretty-printingall
output,especially whenrunningbenchmark testsusing
queriesreturninglargeresultsets.Specifythedelimiter
characterwiththe--output_delimiter option.Store
allqueryresultsinafileratherthanprintingtothescreen
withthe-Boption.AddedinImpala1.0.1.
714|ApacheImpalaGuideImpalaClientAccess
Explanation ConfigurationFileSetting Command-Line Option
Ifset,thesettingoverridestheexpectedhostnameofthe
Impaladaemon's Kerberosserviceprincipal.kerberos_host_fqdn=
load-balanc er-hostname-bor
--kerberos_host_fqdnimpala-shell willcheckthattheserver'sprincipal
matchesthishostname.Thismaybeusedwhenimpalad
isconfiguredtobeaccessed viaaload-balancer ,butitis
desiredforimpala-shell totalktoaspecificimpalad
directly.
print_header=true --print_header
Storesallqueryresultsinthespecified file.Typicallyused
tostoretheresultsofasinglequeryissuedfromtheoutput_file= filename -ofilename or--output_file
filename
command linewiththe-qoption.Alsoworksfor
interactivesessions;youseethemessagessuchasnumber
ofrowsfetched,butnottheactualresultset.Tosuppress
theseincidentalmessageswhencombining the-qand-o
options,redirectstderrto/dev/null .AddedinImpala
1.0.1.
Specifiesthecharactertouseasadelimiterbetweenfields
whenqueryresultsareprintedinplainformatbythe-Boutput_delimit er=character --output_delimit er=character
option.Defaultstotab('\t').Ifanoutputvaluecontains
thedelimitercharacter,thatfieldisquoted,escapedby
doublingquotationmarks,orboth.AddedinImpala1.0.1.
Displaysthequeryexecutionplan(sameoutputasthe
EXPLAIN statement)andamoredetailedlow-levelshow_profiles=true -por--show_profiles
breakdownofexecutionsteps,foreveryqueryexecuted
bytheshell.
Displayshelpinformation. N/A -hor--help
Setsthemaximumnumberofqueriestostoreinthe
historyfile.history_max=1000 N/A
Connects totheimpalad daemononthespecified host.
Thedefaultportof21000isassumed unlessyouprovideimpalad=hostname[:portnum] -ihostnameor
--impalad= hostname[:portnum]
anothervalue.Youcanconnecttoanyhostinyourcluster
thatisrunningimpalad .Ifyouconnecttoaninstanceof
impalad thatwasstartedwithanalternateportspecified
bythe--fe_port flag,providethatalternativeport.
Passesaqueryorotherimpala-shell command from
thecommand line.Theimpala-shell interpreterquery=query -qqueryor--query=query
immediatelyexitsafterprocessingthestatement.Itis
limitedtoasinglestatement,whichcouldbeaSELECT,
CREATE TABLE ,SHOW TABLES ,oranyotherstatement
recognizedinimpala-shell .Becauseyoucannotpass
aUSEstatementandanotherquery,fullyqualifythe
namesforanytablesoutsidethedefault database.(Or
usethe-foptiontopassafilewithaUSEstatement
followedbyotherqueries.)
PassesaSQLqueryfromafile.Multiplestatementsmust
besemicolon(;)delimited.InCDH5.5/Impala2.3andquery_file=path_to_query_file -fquery_fileor
--query_file=query_file
higher,youcanspecifyafilename of-torepresent
ApacheImpalaGuide|715ImpalaClientAccess
Explanation ConfigurationFileSetting Command-Line Option
standardinput.Thisfeaturemakesitconvenienttouse
impala-shell aspartofaUnixpipelinewhereSQL
statementsaregenerateddynamicallybyothertools.
Kerberosauthenticationisusedwhentheshellconnects
toimpalad .IfKerberosisnotenabledontheinstanceofuse_kerberos=true -kor--kerberos
impalad towhichyouareconnecting ,errorsare
displayed.
SeeEnablingKerberosAuthenticationforImpalaforthe
stepstosetupanduseKerberosauthenticationinImpala.
Setsdefaultqueryoptionsforaninvocationofthe
impala-shell command. TosetmultiplequeryoptionsHeaderline
[impala.query_options] ,--query_option="option=value"
-Q"option=value"
atonce,usemorethanoneinstanceofthiscommand-line
option.Thequeryoptionnamesarenotcase-sensitiv e.followedonsubsequent
linesbyoption=value,one
optionperline.
Instructsimpala-shell toauthenticatetoaparticular
impalad serviceprincipal. Ifakerberos_ser vice_nameiskerberos_service_name= name -skerberos_ser vice_nameor
--kerberos_service_name= name
notspecified, impalaisusedbydefault.Ifthisoptionis
usedinconjunction withaconnection inwhichKerberos
isnotsupported,errorsarereturned.
Enablesverboseoutput. verbose=true -Vor--verbose
Disablesverboseoutput. verbose=false --quiet
Displaysversioninformation. version=true -vor--version
Continuesonqueryfailure. ignore_query_failure=true -c
Specifies thedatabasetobeusedonstartup.Sameas
runningtheUSEstatementafterconnecting. Ifnot
specified, adatabasenamedDEFAULT isused.default_db=default_db -ddefault_dbor
--database=default_db
EnablesTLS/SSLforimpala-shell . ssl=true --ssl
Thelocalpathnamepointingtothethird-partyCA
certificate,ortoacopyoftheservercertificateforca_cert=path_to_certificate --ca_cert=path_to_certificate
self-signed servercertificates.If--ca_cert isnotset,
impala-shell enablesTLS/SSL,butdoesnotvalidate
theservercertificate.Thisisusefulforconnecting toa
known-goodImpalathatisonlyrunningoverTLS/SSL,
whenacopyofthecertificateisnotavailable(suchas
whendebuggingcustomerinstallations).
EnablesLDAPauthentication. use_ldap=true -l
Suppliestheusername, whenLDAPauthenticationis
enabledbythe-loption.(Specifytheshortusername,user=user_name -u
notthefullLDAPdistinguished name.)Theshellthen
promptsinteractivelyforthepassword.
Specifiesacommand toruntoretrievetheLDAPpassword,
whenLDAPauthenticationisenabledbythe-loption.IfN/A --ldap_password_cmd=command
thecommand includesspace-separ atedarguments,
enclosethecommand anditsargumentsinquotation
marks.
716|ApacheImpalaGuideImpalaClientAccess
Explanation ConfigurationFileSetting Command-Line Option
Specifies thepathofthefilecontainingimpala-shell
configurationsettings.Thedefaultis$HOME/.impalarc .
Thissettingcanonlybespecified onthecommand line.N/A --config_file=path_to_config_file
Printsaprogressbarshowingroughlythepercentage
completeforeachquery.TheinformationisupdatedN/A --live_progress
interactivelyasthequeryprogresses.SeeLIVE_PROGRESS
QueryOption(CDH5.5orhigheronly)onpage336.
Printsadetailedreport,similartotheSUMMARY command,
showingprogressdetailsforeachphaseofqueryN/A --live_summar y
execution.Theinformationisupdatedinteractivelyasthe
queryprogresses.SeeLIVE_SUMMAR YQueryOption(CDH
5.5orhigheronly)onpage337.
Definesasubstitutionvariablethatcanbeusedwithinthe
impala-shell session.ThevariablecanbesubstitutedN/A --var=variable_name =value
intostatementsprocessedbythe-qor-foptions,orin
aninteractiveshellsession.WithinaSQLstatement,you
substitutethevaluebyusingthenotation
${var:variable_name }.ThisfeatureisavailableinCDH
5.7/Impala2.5andhigher.
AllowsLDAPauthenticationtobeusedwithaninsecure
connection totheshell.WARNING: ThiswillallowN/A --auth_creds_ok_in_clear
authenticationcredentialstobesentunencrypted,and
hencemaybevulnerabletoanattack.
impala-shell ConfigurationFile
Youcandefineasetofdefaultoptionsforyourimpala-shell environment,storedinthefile$HOME/.impalarc .
Thisfileconsistsofkey-valuepairs,oneoptionperline.Everythingaftera#characteronalineistreatedasacomment
andignored.
Theconfigurationfilemustcontainaheaderlabel[impala] ,followedbytheoptionsspecifictoimpala-shell .(This
standardconventionforconfigurationfilesletsyouuseasinglefiletoholdconfigurationoptionsformultiple
applications.)
Tospecifyadifferentfilename orpathfortheconfigurationfile,specifytheargument
--config_file= path_to_config_file ontheimpala-shell command line.
Thenamesoftheoptionsintheconfigurationfilearesimilar(although notnecessarily identical)tothelong-form
command-line argumentstotheimpala-shell command. Forthenamestouse,seeSummaryofimpala-shell
ConfigurationOptionsonpage714.
Anyoptionsyouspecifyontheimpala-shell command lineoverrideanycorresponding optionswithinthe
configurationfile.
Thefollowingexampleshowsaconfigurationfilethatyoumightuseduringbenchmarking tests.Itsetsverbosemode,
sothattheoutputfromeachSQLqueryisfollowedbytiminginformation.impala-shell startsinsidethedatabase
containingthetableswiththebenchmark data,avoidingtheneedtoissueaUSEstatementorusefullyqualified table
names.
Inthisexample,thequeryoutputisformattedasdelimitedtextratherthanenclosed inASCIIartboxes,andisstored
inafileratherthanprintedtothescreen.Thoseoptionsareappropriateforbenchmark situations,sothattheoverhead
ofimpala-shell formattingandprintingtheresultsetdoesnotfactorintothetimingmeasurements.Italsoenables
ApacheImpalaGuide|717ImpalaClientAccess
theshow_profiles option.Thatoptionprintsdetailedperformance informationaftereachquery,whichmightbe
valuableinunderstandingtheperformance ofbenchmark queries.
[impala]
verbose=true
default_db=tpc_benchmarking
write_delimited=true
output_delimiter=,
output_file=/home/tester1/benchmark_results.csv
show_profiles=true
ThefollowingexampleshowsaconfigurationfilethatconnectstoaspecificremoteImpalanode,runsasinglequery
withinaparticular database,thenexits.Anyqueryoptionspredefinedunderthe[impala.query_options] section
intheconfigurationfiletakeeffectduringthesession.
Youwouldtypicallyusethiskindofsingle-purpose configurationsettingwiththeimpala-shell command-line option
--config_file= path_to_config_file ,toeasilyselectbetweenmanypredefinedqueriesthatcouldberun
againstdifferentdatabases,hosts,orevendifferentclusters.Torunasequence ofstatementsinsteadofasinglequery,
specifytheconfigurationoptionquery_file= path_to_query_file instead.
[impala]
impalad=impala-test-node1.example.com
default_db=site_stats
# Issue a predefined query and immediately exit.
query=select count(*) from web_traffic where event_date = trunc(now(),'dd')
[impala.query_options]
mem_limit=32g
Connecting toimpaladthroughimpala-shell
Withinanimpala-shell session,youcanonlyissuequerieswhileconnectedtoaninstanceoftheimpalad daemon.
Youcanspecifytheconnection information:
â¢Throughcommand-line optionswhenyouruntheimpala-shell command.
â¢Throughaconfigurationfilethatisreadwhenyouruntheimpala-shell command.
â¢Duringanimpala-shell session,byissuingaCONNECT command.
Seeimpala-shell ConfigurationOptionsonpage714forthecommand-line andconfigurationfileoptionsyoucanuse.
YoucanconnecttoanyImpaladaemon(impalad ),andthatdaemoncoordinatestheexecutionofallqueriessentto
it.
Forsimplicity duringdevelopment,youmightalwaysconnecttothesamehost,perhapsrunningimpala-shell on
thesamehostasimpalad andspecifyingthehostnameaslocalhost .
Inaproduction environment,youmightenableloadbalancing ,inwhichyouconnecttospecifichost/portcombination
butqueriesareforwardedtoarbitraryhosts.Thistechnique spreadstheoverheadofactingasthecoordinatornode
amongalltheImpaladaemons inthecluster.SeeUsingImpalathroughaProxyforHighAvailabilityonpage72for
details.
ToconnecttheImpalashellduringshellstartup:
1.Locatethehostnamethatisrunninganinstanceoftheimpalad daemon. Ifthatimpalad usesanon-default
port(somethingotherthanport21000)forimpala-shell connections, findouttheportnumberalso.
2.Usethe-ioptiontotheimpala-shell interpretertospecifytheconnection informationforthatinstanceof
impalad :
# When you are logged into the same machine running impalad.
# The prompt will reflect the current hostname.
$ impala-shell
# When you are logged into the same machine running impalad.
# The host will reflect the hostname 'localhost'.
718|ApacheImpalaGuideImpalaClientAccess
$ impala-shell -i localhost
# When you are logged onto a different host, perhaps a client machine
# outside the Hadoop cluster.
$ impala-shell -i some.other.hostname
# When you are logged onto a different host, and impalad is listening
# on a non-default port. Perhaps a load balancer is forwarding requests
# to a different host/port combination behind the scenes.
$ impala-shell -i some.other.hostname :port_number
ToconnecttheImpalashellaftershellstartup:
1.StarttheImpalashellwithnoconnection:
impala-shell
Youshouldseeapromptlikethefollowing:
Welcome to the Impala shell. Press TAB twice to see a list of available commands.
Copyright (c) year Cloudera, Inc. All rights reserved.
(Shell
      build version: Impala Shell v3.3.x ( hash) built on
date)
[Not connected] > 
2.Locatethehostnamethatisrunningtheimpalad daemon. Ifthatimpalad usesanon-defaultport(something
otherthanport21000)forimpala-shell connections, findouttheportnumberalso.
3.Usetheconnect command toconnecttoanImpalainstance.Enteracommand oftheform:
[Not connected] > connect impalad-host
[impalad-host :21000] >
Note:Replaceimpalad-hos twiththehostnameyouhaveconfiguredtorunImpalainyour
environment.Thechangedpromptindicatesasuccessfulconnection.
Tostartimpala-shell inaspecificdatabase:
Youcanuseallthesameconnection optionsasinpreviousexamples.Forsimplicity ,theseexamplesassumethatyou
areloggedintooneoftheImpaladaemons.
1.Findthenameofthedatabasecontainingtherelevanttables,views,andsoonthatyouwanttooperateon.
2.Usethe-doptiontotheimpala-shell interpretertoconnectandimmediatelyswitchtothespecified database,
withouttheneedforaUSEstatementorfullyqualified names:
# Subsequent queries with unqualified names operate on
# tables, views, and so on inside the database named 'staging'.
$ impala-shell -i localhost -d staging
# It is common during development, ETL, benchmarking, and so on
# to have different databases containing the same table names
# but with different contents or layouts.
$ impala-shell -i localhost -d parquet_snappy_compression
$ impala-shell -i localhost -d parquet_gzip_compression
Torunoneorseveralstatementsinnon-interactivemode:
Youcanuseallthesameconnection optionsasinpreviousexamples.Forsimplicity ,theseexamplesassumethatyou
areloggedintooneoftheImpaladaemons.
ApacheImpalaGuide|719ImpalaClientAccess
1.Constructastatement,orafilecontainingasequence ofstatements,thatyouwanttoruninanautomatedway,
withouttypingorcopyingandpastingeachtime.
2.Invokeimpala-shell withthe-qoptiontorunasinglestatement,orthe-foptiontorunasequence of
statementsfromafile.Theimpala-shell command returnsimmediately,withoutgoingintotheinteractive
interpreter.
# A utility command that you might run while developing shell scripts
# to manipulate HDFS files.
$ impala-shell -i localhost -d database_of_interest -q 'show tables'
# A sequence of CREATE TABLE, CREATE VIEW, and similar DDL statements
# can go into a file to make the setup process repeatable.
$ impala-shell -i localhost -d database_of_interest -f recreate_tables.sql
RunningCommands andSQLStatementsinimpala-shell
Thefollowingareafewofthekeysyntaxandusagerulesforrunningcommands andSQLstatementsinimpala-shell .
â¢Toseethefullsetofavailablecommands, pressTABtwice.
â¢Tocyclethroughandeditpreviouscommands, clicktheup-arrowanddown-arrowkeys.
â¢UsethestandardsetofkeyboardshortcutsinGNUReadlinelibraryforeditingandcursormovement,suchas
Ctrl-Aforthebeginning oflineandCtrl-Efortheendofline.
â¢Commands andSQLstatementsmustbeterminatedbyasemi-colon.
â¢Commands andSQLstatementscanspanmultiplelines.
â¢Use--todenoteasingle-line commentand/**/todenoteamulti-line comment.
Acommentisconsideredpartofthestatementitprecedes,sowhenyouentera--or/* */comment,youget
acontinuationpromptuntilyoufinishenteringastatementendingwithasemicolon.Forexample:
[impala] > -- This is a test comment
                  > SHOW TABLES LIKE 't*';
â¢Ifacommentcontainsthe${variable_name }anditisnotforavariablesubstitution,the$charactermustbe
escaped,e.g.-- \${hello} .
Forinformationonavailableimpala-shell commands, seeimpala-shell Command Referenceonpage721.
VariableSubstitutioninimpala-shell
InCDH5.7/Impala2.5andhigher,youcandefinesubstitutionvariablestobeusedwithinSQLstatementsprocessed
byimpala-shell .
1.Youspecifythevariableanditsvalueasbelow.
â¢Onthecommand line,youspecifytheoption--var=variable_name =value
â¢Withinaninteractivesessionorascriptfileprocessedbythe-foption,usetheSET
VAR:variable_name =valuecommand.
2.UsetheabovevariableinSQLstatementsintheimpala-shell sessionusingthenotation:
${VAR:variable_name }.
Note:Becausethisfeatureispartofimpala-shell ratherthantheimpalad backend,makesure
theclientsystemyouareconnecting fromhasthemostrecentimpala-shell .Youcanusethis
featurewithanewimpala-shell connecting toanolderimpalad ,butnotthereverse.
Forexample,herearesomeimpala-shell commands thatdefinesubstitutionvariablesandthenusetheminSQL
statementsexecutedthroughthe-qand-foptions.Noticehowthe-qargumentstringsaresingle-quot edtoprevent
720|ApacheImpalaGuideImpalaClientAccess
shellexpansion ofthe${var:value} notation,andanystringliteralswithinthequeriesareenclosed bydouble
quotationmarks.
$ impala-shell --var=tname=table1 --var=colname=x --var=coltype=string -q 'CREATE TABLE
 ${var:tname} (${var:colname} ${var:coltype}) STORED AS PARQUET'
Query: CREATE TABLE table1 (x STRING) STORED AS PARQUET
Thebelowexampleshowsasubstitutionvariablepassedinbythe--varoption,andthenreferencedbystatements
issuedinteractively.ThenthevariableisresetwiththeSETcommand.
$ impala-shell --quiet --var=tname=table1
[impala] > SELECT COUNT(*) FROM ${var:tname};
[impala] > SET VAR:tname=table2;
[impala] > SELECT COUNT(*) FROM ${var:tname};
impala-shell Command Reference
Usethefollowingcommands withinimpala-shell topassrequeststotheimpalad daemonthattheshellisconnected
to.Youcanenteracommand interactivelyattheprompt,orpassitastheargumenttothe-qoptionofimpala-shell .
Mostofthesecommands arepassedtotheImpaladaemonasSQLstatements;refertothecorresponding SQLlanguage
referencesectionsforfullsyntaxdetails.
Explanation Command
Changestheunderlying structureorsettingsofanImpalatable,oratablesharedbetween
ImpalaandHive.SeeALTERTABLEStatementonpage205andALTERVIEWStatementonpage
218fordetails.alter
Gathersimportantperformance-r elatedinformationforatable,usedbyImpalatooptimize
queries.SeeCOMPUTE STATSStatementonpage219fordetails.compute stats
Connects tothespecified instanceofimpalad .Thedefaultportof21000isassumed unless
youprovideanothervalue.Youcanconnecttoanyhostinyourclusterthatisrunningimpalad.connect
Ifyouconnecttoaninstanceofimpalad thatwasstartedwithanalternateportspecified
bythe--fe_port flag,youmustprovidethatalternateport.SeeConnecting toimpalad
throughimpala-shell onpage718forexamples.
TheSETstatementhasnoeffectuntiltheimpala-shell interpreterisconnectedtoan
Impalaserver.Onceyouareconnected,anyqueryoptionsyousetremainineffectasyou
issueasubsequentCONNECT command toconnecttoadifferentImpalahost.
Showsthecolumns,columndatatypes,andanycolumncommentsforaspecified table.
DESCRIBE FORMATTED showsadditional informationsuchastheHDFSdatadirectory,describe
partitions, andinternalpropertiesforthetable.SeeDESCRIBEStatementonpage251for
detailsaboutthebasicDESCRIBE outputandtheDESCRIBE FORMATTED variant.Youcan
useDESCasshorthand fortheDESCRIBE command.
Removesaschemaobject,andinsomecasesitsassociateddatafiles.SeeDROPTABLE
Statementonpage268,DROPVIEWStatementonpage270,DROPDATABASEStatementon
page262,andDROPFUNCTIONStatementonpage263fordetails.drop
Providestheexecutionplanforaquery.EXPLAIN representsaqueryasaseriesofsteps.For
example,thesestepsmightbemap/reducestages,metastoreoperations,orfilesystemexplain
operationssuchasmoveorrename.SeeEXPLAINStatementonpage271andUsingtheEXPLAIN
PlanforPerformance Tuningonpage602fordetails.
Helpprovidesalistofallavailablecommands andoptions. help
ApacheImpalaGuide|721ImpalaClientAccess
Explanation Command
Maintainsanenumeratedcross-session command history.Thishistoryisstoredinthe~/
.impalahistory file.history
Writestheresultsofaquerytoaspecified table.Thiseitheroverwritestabledataorappends
datatotheexistingtablecontent.SeeINSERTStatementonpage277fordetails.insert
Updatesimpalad metadatafortableexistenceandstructure.Usethiscommand aftercreating,
dropping,oralteringdatabases,tables,orpartitions inHive.SeeINVALIDATEMETADATA
Statementonpage286fordetails.invalidate
metadata
Displayslow-levelinformationaboutthemostrecentquery.Usedforperformance diagnosis
andtuning.ThereportstartswiththesameinformationasproducedbytheEXPLAINprofile
statementandtheSUMMARY command. SeeUsingtheQueryProfileforPerformance Tuning
onpage604fordetails.
Exitstheshell.Remember toincludethefinalsemicolonsothattheshellrecognizestheend
ofthecommand.quit
Refreshesimpalad metadataforthelocationsofHDFSblockscorresponding toImpaladata
files.Usethiscommand afterloadingnewdatafilesintoanImpalatablethroughHiveor
throughHDFScommands. SeeREFRESHStatementonpage291fordetails.refresh
Executesapreviousimpala-shell command again,fromthelistofcommands displayed
bythehistory command. ThesecouldbeSQLstatements,orcommands specificto
impala-shell suchasquitorprofile .rerunor@
Specifyanintegerargument.ApositiveintegerNrepresentsthecommand labelledNinthe
outputoftheHISTORY command. Anegativeinteger-NrepresentstheNthcommand from
theendofthelist,suchas-1forthemostrecentcommand. Commands thatareexecuted
againdonotproducenewentriesintheHISTORY outputlist.
Specifies thedatasetonwhichtocompletesomeaction.Allinformationreturnedfrom
selectcanbesenttosomeoutputsuchastheconsoleorafileorcanbeusedtocomplete
someotherelementofquery.SeeSELECTStatementonpage295fordetails.select
Managesqueryoptionsforanimpala-shell session.Theavailableoptionsaretheones
listedinQueryOptionsfortheSETStatementonpage322.Theseoptionsareusedforqueryset
tuningandtroubleshooting. IssueSETwithnoargumentstoseethecurrentqueryoptions,
eitherbasedontheimpalad defaults,asspecified byyouatimpalad startup,orbasedon
earlierSETstatementsinthesamesession.Tomodifyoptionvalues,issuecommands with
thesyntaxset option=value.Torestoreanoptiontoitsdefault,usetheunsetcommand.
TheSETstatementhasnoeffectuntiltheimpala-shell interpreterisconnectedtoan
Impalaserver.Onceyouareconnected,anyqueryoptionsyousetremainineffectasyou
issueasubsequentCONNECT command toconnecttoadifferentImpalahost.
InImpala2.0andlater,SETisavailableasaSQLstatementforanykindofapplicationaswell
asinimpala-shell .SeeSETStatementonpage321fordetails.
Executesthespecifiedcommand intheoperatingsystemshellwithoutexitingimpala-shell .
Youcanusethe!characterasshorthand fortheshellcommand.shell
Note:Quoteanyinstancesofthe--or/*tokenstoavoidthembeing
interpretedasthestartofacomment.Toembedcommentswithinsource
or!commands, usetheshellcommentcharacter#beforethecomment
portionoftheline.
722|ApacheImpalaGuideImpalaClientAccess
Explanation Command
Displaysmetastoredataforschemaobjectscreatedandaccessed throughImpala,Hive,or
both.showcanbeusedtogatherinformationaboutobjectssuchasdatabases,tables,and
functions. SeeSHOWStatementonpage363fordetails.show
Executesoneormorestatementsresidinginaspecified filefromthelocalfilesystem.Allows
youtoperformthesamekindsofbatchoperationsaswiththe-foption,butinteractivelysourceorsrc
withintheinterpreter.ThefilecancontainSQLstatementsandotherimpala-shell
commands, including additional SOURCEcommands toperformaflexiblesequence ofactions.
Eachcommand orstatement,exceptthelastoneinthefile,mustendwithasemicolon.See
RunningCommands andSQLStatementsinimpala-shell onpage720forexamples.
Summariz estheworkperformedinvariousstagesofaquery.Itprovidesahigher-levelview
oftheinformationdisplayedbytheEXPLAIN command. AddedinImpala1.4.0.SeeUsingsummary
theSUMMAR YReportforPerformance Tuningonpage603fordetailsaboutthereportformat
andhowtointerpretit.
Thetime,memoryusage,andsoonreportedbySUMMARY onlyincludetheportionsofthe
statementthatreaddata,notwhendataiswritten.Therefore,thePROFILE command is
betterforchecking theperformance andscalabilityofINSERTstatements.
InCDH5.5/Impala2.3andhigher,youcanseeacontinuously updatedreportofthesummary
informationwhileaqueryisinprogress.SeeLIVE_SUMMAR YQueryOption(CDH5.5orhigher
only)onpage337fordetails.
Removesanyuser-specified valueforaqueryoptionandreturnstheoptiontoitsdefault
value.SeeQueryOptionsfortheSETStatementonpage322fortheavailablequeryoptions.unset
InCDH5.7/Impala2.5andhigher,itcanalsoremoveuser-specified substitutionvariables
usingthenotationUNSET VAR: variable_name .
Indicatesthedatabaseagainstwhichtoexecutesubsequentcommands. Letsyouavoidusing
fullyqualified nameswhenreferringtotablesindatabasesotherthandefault .SeeUSEuse
Statementonpage385fordetails.Noteffectivewiththe-qoption,becausethatoptiononly
allowsasinglestatementintheargument.
ReturnsImpalaversioninformation. version
ConfiguringImpalatoWorkwithODBC
Third-partyproductscanbedesigned tointegratewithImpalausingODBC.Forthebestexperience, ensureany
third-partyproductyouintendtouseissupported.Verifyingsupportincludeschecking thattheversionsofImpala,
ODBC,theoperatingsystem,andthethird-partyproducthaveallbeenapprovedforusetogether.Beforeconfiguring
yoursystemstouseODBC,downloadaconnector.Youmayneedtosigninandacceptlicenseagreementsbefore
accessing thepagesrequiredfordownloading ODBCconnectors.
Downloading theODBCDriver
Important:Asoflate2015,mostbusinessintelligenceapplicationsarecertifiedwiththe2.xODBC
drivers.Although theinstructions onthispagecoverboththe2.xand1.xdrivers,expecttousethe
2.xdriversexclusivelyformostODBCapplicationsconnecting toImpala.CDH6.0hasbeentestedwith
theImpalaODBCdriverversion2.5.42,andClouderarecommends thatyouusethisversionwhenyou
startusingCDH6.0.
SeethedatabasedriverssectionontheClouderadownloadswebpagetodownloadandinstallthedriver.
ApacheImpalaGuide|723ImpalaClientAccess
ConfiguringtheODBCPort
Versions2.5and2.0oftheClouderaODBCConnector,currentlycertifiedforsomebutnotallBIapplications,usethe
HiveServer2protocol,corresponding toImpalaport21050.Impalasupports Kerberosauthenticationwithallthe
supportedversionsofthedriver,andrequiresODBC2.05.13forImpalaorhigherforLDAPusername/pass word
authentication.
Version1.xoftheClouderaODBCConnectorusestheoriginalHiveServer1protocol,corresponding toImpalaport
21000.
ExampleofSettingUpanODBCApplicationforImpala
Toillustratetheoutlineofthesetupprocess,hereisatranscriptofasessiontosetupallrequireddriversandabusiness
intelligenceapplicationthatusestheODBCdriver,underMacOSX.Each.dmgfilerunsaGUI-based installer,firstfor
theunderlying IODBCdriverneededfornon-Windo wssystems,thenfortheClouderaODBCConnector,andfinallyfor
theBItoolitself.
$ ls -1
Cloudera-ODBC-Driver-for-Impala-Install-Guide.pdf
BI_Tool_Installer.dmg
iodbc-sdk-3.52.7-macosx-10.5.dmg
ClouderaImpalaODBC.dmg
$ open iodbc-sdk-3.52.7-macosx-10.dmg
Install the IODBC driver using its installer
$ open ClouderaImpalaODBC.dmg
Install the Cloudera ODBC Connector using its installer
$ installer_dir=$(pwd)
$ cd /opt/cloudera/impalaodbc
$ ls -1
Cloudera ODBC Driver for Impala Install Guide.pdf
Readme.txt
Setup
lib
ErrorMessages
Release Notes.txt
Tools
$ cd Setup
$ ls
odbc.ini    odbcinst.ini
$ cp odbc.ini ~/.odbc.ini
$ vi ~/.odbc.ini
$ cat ~/.odbc.ini
[ODBC]
# Specify any global ODBC configuration here such as ODBC tracing.
[ODBC Data Sources]
Sample Cloudera Impala DSN=Cloudera ODBC Driver for Impala
[Sample Cloudera Impala DSN]
# Description: DSN Description.
# This key is not necessary and is only to give a description of the data source.
Description=Cloudera ODBC Driver for Impala DSN
# Driver: The location where the ODBC driver is installed to.
Driver=/opt/cloudera/impalaodbc/lib/universal/libclouderaimpalaodbc.dylib
# The DriverUnicodeEncoding setting is only used for SimbaDM
# When set to 1, SimbaDM runs in UTF-16 mode.
# When set to 2, SimbaDM runs in UTF-8 mode.
#DriverUnicodeEncoding=2
# Values for HOST, PORT, KrbFQDN, and KrbServiceName should be set here.
# They can also be specified on the connection string.
HOST=hostname.sample.example.com
PORT=21050
Schema=default
# The authentication mechanism.
# 0 - No authentication (NOSASL)
724|ApacheImpalaGuideImpalaClientAccess
# 1 - Kerberos authentication (SASL)
# 2 - Username authentication (SASL)
# 3 - Username/password authentication (SASL)
# 4 - Username/password authentication with SSL (SASL)
# 5 - No authentication with SSL (NOSASL)
# 6 - Username/password authentication (NOSASL)
AuthMech=0
# Kerberos related settings.
KrbFQDN=
KrbRealm=
KrbServiceName=
# Username/password authentication with SSL settings.
UID=
PWD
CAIssuedCertNamesMismatch=1
TrustedCerts=/opt/cloudera/impalaodbc/lib/universal/cacerts.pem
# Specify the proxy user ID to use.
#DelegationUID=
# General settings
TSaslTransportBufSize=1000
RowsFetchedPerBlock=10000
SocketTimeout=0
StringColumnLength=32767
UseNativeQuery=0
$ pwd
/opt/cloudera/impalaodbc/Setup
$ cd $installer_dir
$ open BI_Tool_Installer.dmg
Install the BI tool using its installer
$ ls /Applications | grep BI_Tool
BI_Tool.app
$ open -a BI_Tool.app
In the BI tool, connect to a data source using port 21050
NotesaboutJDBCandODBCInteractionwithImpalaSQLFeatures
MostImpalaSQLfeaturesworkequivalentlythroughtheimpala-shell interpreteroftheJDBCorODBCAPIs.The
followingaresomeexceptionstokeepinmindwhenswitchingbetweentheinteractiveshellandapplicationsusing
theAPIs:
Note:IfyourJDBCorODBCapplicationconnectstoImpalathroughaloadbalancersuchashaproxy ,
becautiousaboutreusingtheconnections. Iftheloadbalancerhassetupconnection timeoutvalues,
eitherchecktheconnection frequentlysothatitneversitsidlelongerthantheloadbalancertimeout
value,orchecktheconnection validitybeforeusingitandcreateanewoneiftheconnection has
beenclosed.
ConfiguringImpalatoWorkwithJDBC
Impalasupports thestandardJDBCinterface,allowingaccessfromcommercialBusinessIntelligencetoolsandcustom
softwarewritteninJavaorotherprogramminglanguages.TheJDBCdriverallowsyoutoaccessImpalafromaJava
programthatyouwrite,oraBusinessIntelligenceorsimilartoolthatusesJDBCtocommunic atewithvariousdatabase
products.
SettingupaJDBCconnection toImpalainvolvesthefollowingsteps:
â¢Verifyingthecommunic ationportwheretheImpaladaemons inyourclusterarelisteningforincomingJDBC
requests.
â¢InstallingtheJDBCdriveroneverysystemthatrunstheJDBC-enabled application.
â¢Specifyingaconnection stringfortheJDBCapplicationtoaccessoneoftheserversrunningtheimpalad daemon,
withtheappropriatesecuritysettings.
ApacheImpalaGuide|725ImpalaClientAccess
ConfiguringtheJDBCPort
ThedefaultportusedbyJDBC2.0andlater(aswellasODBC2.x)is21050.ImpalaserveracceptsJDBCconnections
throughthissameport21050bydefault.Makesurethisportisavailableforcommunic ationwithotherhostsonyour
network,forexample,thatitisnotblockedbyfirewallsoftware.IfyourJDBCclientsoftwareconnectstoadifferent
port,specifythatalternativeportnumberwiththe--hs2_port optionwhenstartingimpalad .SeeImpalaStartup
OptionsfordetailsaboutImpalastartupoptions.SeePortsUsedbyImpalaonpage743forinformationaboutallports
usedforcommunic ationbetweenImpalaandclientsorbetweenImpalacomponen ts.
Choosing theJDBCDriver
InImpala2.0andlater,youhavethechoicebetweentheClouderaJDBCConnectorandtheHive0.13orhigherJDBC
driver.Clouderarecommends usingtheClouderaJDBCConnectorwherepractical.
IfyouarealreadyusingJDBCapplicationswithanearlierImpalarelease,youmustupdateyourJDBCdrivertooneof
thesechoices,becausetheHive0.12driverthatwasformerlytheonlychoiceisnotcompatiblewithImpala2.0and
later.
BoththeClouderaJDBCConnectorandtheHiveJDBCdriverprovideasubstantialspeedincreaseforJDBCapplications
withImpala2.0andhigher,forqueriesthatreturnlargeresultsets.
EnablingImpalaJDBCSupportonClientSystems
UsingtheClouderaJDBCConnector(recommended)
DownloadandinstalltheClouderaJDBCconnectoronanyLinux,Windows,orMacsystemwhereyouintendtorun
JDBC-enabled applications.FromtheClouderaDownloadspage,navigatetotheDatabaseDriverssectionofthepage
andchoosetheappropriateprotocol(JDBCorODBC)andtargetproduct(ImpalaorHive).Theeaseofdownloading
andinstallingonawidevarietyofsystemsmakesthisconnectoraconvenientchoicefororganizationswith
heterogeneousenvironments.ThisisthedownloadpagefortheImpalaJDBCConnector.
UsingtheHiveJDBCDriver
InstalltheHiveJDBCdriver(hive-jdbc package)throughtheLinuxpackagemanager,onhostswithintheCDHcluster.
ThedriverconsistsofseveralJARfiles.ThesamedrivercanbeusedbyImpalaandHive.
TogettheJARfiles,installtheHiveJDBCdriveroneachhostintheclusterthatwillrunJDBCapplications.Followthe
instructions forInstallingClouderaJDBCandODBCDriversonClientsinCDH.
Note:ThelatestJDBCdriver,corresponding toHive0.13,providessubstantialperformance
improvementsforImpalaqueriesthatreturnlargeresultsets.Impala2.0andlaterarecompatible
withtheHive0.13driver.IfyoualreadyhaveanolderJDBCdriverinstalled,andarerunningImpala
2.0orhigher,considerupgradingtothelatestHiveJDBCdriverforbestperformance withJDBC
applications.
IfyouareusingJDBC-enabled applicationsonhostsoutsidetheCDHcluster,youcannotusetheCDHinstallprocedure
onthenon-CDH hosts.InstalltheJDBCdriveronatleastoneCDHhostusingtheprecedingprocedure.Thendownload
theJARfilestoeachclientmachinethatwilluseJDBCwithImpala:
commons-logging-X.X.X.jar
  hadoop-common.jar
  hive-common-X.XX.X-cdhX.X.X.jar
  hive-jdbc-X.XX.X-cdhX.X.X.jar
  hive-metastore-X.XX.X-cdhX.X.X.jar
  hive-service-X.XX.X-cdhX.X.X.jar
  httpclient-X.X.X.jar
  httpcore-X.X.X.jar
  libfb303-X.X.X.jar
  libthrift-X.X.X.jar
  log4j-X.X.XX.jar
  slf4j-api-X.X.X.jar
726|ApacheImpalaGuideImpalaClientAccess
  slf4j-logXjXX-X.X.X.jar
ToenableJDBCsupportforImpalaonthesystemwhereyouruntheJDBCapplication:
1.DownloadtheJARfileslistedabovetoeachclientmachine.
Note:ForMavenusers,seethissamplegithubpageforanexampleofthedependencies you
couldaddtoapomfileinsteadofdownloading theindividual JARs.
2.StoretheJARfilesinalocationofyourchoosing,ideallyadirectoryalreadyreferencedinyourCLASSPATH setting.
Forexample:
â¢OnLinux,youmightusealocationsuchas/opt/jars/.
â¢OnWindows,youmightuseasubdirectoryundernea thC:\Program Files .
3.TosuccessfullyloadtheImpalaJDBCdriver,clientprogramsmustbeabletolocatetheassociatedJARfiles.This
oftenmeanssettingtheCLASSPATH fortheclientprocesstoincludetheJARs.Consultthedocumen tationfor
yourJDBCclientformoredetailsonhowtoinstallnewJDBCdrivers,butsomeexamplesofhowtosetCLASSPATH
variablesinclude:
â¢OnLinux,ifyouextractedtheJARsto/opt/jars/ ,youmightissuethefollowingcommand toprependthe
JARfilespathtoanexistingclasspath:
export CLASSPATH=/opt/jars/*.jar:$CLASSPATH
â¢OnWindows,usetheSystemPropertiescontrolpanelitemtomodifytheEnvironmentVariablesforyour
system.Modifytheenvironmentvariablestoincludethepathtowhichyouextractedthefiles.
Note:IftheexistingCLASSPATH onyourclientmachinereferstosomeolderversionofthe
HiveJARs,ensurethatthenewJARsarethefirstoneslisted.EitherputthenewJARfiles
earlierinthelistings,ordeletetheotherreferencestoHiveJARfiles.
Establishing JDBCConnections
TheJDBCdriverclassdependsonwhichdriveryouselect.
Note:IfyourJDBCorODBCapplicationconnectstoImpalathroughaloadbalancersuchashaproxy ,
becautiousaboutreusingtheconnections. Iftheloadbalancerhassetupconnection timeoutvalues,
eitherchecktheconnection frequentlysothatitneversitsidlelongerthantheloadbalancertimeout
value,orchecktheconnection validitybeforeusingitandcreateanewoneiftheconnection has
beenclosed.
UsingtheClouderaJDBCConnector(recommended)
Depending ontheleveloftheJDBCAPIyourapplicationistargeting,youcanusethefollowingfully-qualified class
names(FQCNs):
â¢com.cloudera.impala.jdbc41.Driver
â¢com.cloudera.impala.jdbc41.DataSource
â¢com.cloudera.impala.jdbc4.Driver
â¢com.cloudera.impala.jdbc4.DataSource
â¢com.cloudera.impala.jdbc3.Driver
â¢com.cloudera.impala.jdbc3.DataSource
ApacheImpalaGuide|727ImpalaClientAccess
Theconnection stringhasthefollowingformat:
jdbc:impala:// Host:Port[/Schema];Property1 =Value;Property2 =Value;...
Theportvalueistypically21050forImpala.
Forfulldetailsabouttheclassesandtheconnection string(especially thepropertyvaluesavailablefortheconnection
string),downloadtheappropriatedriverdocumen tationforyourplatformfromtheImpalaJDBCConnectordownload
page.
UsingtheHiveJDBCDriver
Forexample,withtheHiveJDBCdriver,theclassnameisorg.apache.hive.jdbc.HiveDriver .Onceyouhave
configuredImpalatoworkwithJDBC,youcanestablishconnections betweenthetwo.Todosoforaclusterthatdoes
notuseKerberosauthentication,useaconnection stringoftheformjdbc:hive2:// host:port/;auth=noSasl .
Forexample,youmightuse:
jdbc:hive2://myhost.example.com:21050/;auth=noSasl
ToconnecttoaninstanceofImpalathatrequiresKerberosauthentication,useaconnection stringoftheform
jdbc:hive2:// host:port/;principal= principal_name .Theprincipalmustbethesameuserprincipalyou
usedwhenstartingImpala.Forexample,youmightuse:
jdbc:hive2://myhost.example.com:21050/;principal=impala/myhost.example.com@H2.EXAMPLE.COM
ToconnecttoaninstanceofImpalathatrequiresLDAPauthentication,useaconnection stringoftheform
jdbc:hive2:// host:port/db_name;user=ldap_userid ;password= ldap_password .Forexample,youmight
use:
jdbc:hive2://myhost.example.com:21050/test_db;user=fred;password=xyz123
Note:
PriortoCDH5.7/Impala2.5,theHiveJDBCdriverdidnotsupportconnections thatusebothKerberos
authenticationandSSLencryption.Ifyourclusterisrunninganolderreleasethathasthisrestriction,
tousebothofthesesecurityfeatureswithImpalathroughaJDBCapplication,usetheClouderaJDBC
ConnectorastheJDBCdriver.
NotesaboutJDBCandODBCInteractionwithImpalaSQLFeatures
MostImpalaSQLfeaturesworkequivalentlythroughtheimpala-shell interpreteroftheJDBCorODBCAPIs.The
followingaresomeexceptionstokeepinmindwhenswitchingbetweentheinteractiveshellandapplicationsusing
theAPIs:
â¢Complextypeconsiderations:
âQueriesinvolvingthecomplextypes(ARRAY,STRUCT,andMAP)requirenotationthatmightnotbeavailable
inalllevelsofJDBCandODBCdrivers.Ifyouhavetroublequeryingsuchatableduetothedriverlevelor
inabilitytoeditthequeriesusedbytheapplication,youcancreateaviewthatexposesaâflattenedâversion
ofthecomplexcolumnsandpointtheapplicationattheview.SeeComplexTypes(CDH5.5orhigheronly)
onpage139fordetails.
âThecomplextypesavailableinCDH5.5/Impala2.3andhigheraresupportedbytheJDBCgetColumns()
API.BothMAPandARRAYarereportedastheJDBCSQLTypeARRAY,becausethisistheclosestmatchingJava
SQLtype.ThisbehaviorisconsistentwithHive.STRUCTtypesarereportedastheJDBCSQLTypeSTRUCT.
TobeconsistentwithHive'sbehavior,theTYPE_NAME fieldispopulatedwiththeprimitivetypenamefor
scalartypes,andwiththefulltoSql() forcomplextypes.Theresultingtypenamesaresomewhatinconsistent,
728|ApacheImpalaGuideImpalaClientAccess
becausenestedtypesareprinteddifferentlythantop-leveltypes.Forexample,thefollowinglistshowshow
toSQL() forImpalatypesaretranslatedtoTYPE_NAME values:
DECIMAL(10,10)         becomes  DECIMAL
CHAR(10)               becomes  CHAR
VARCHAR(10)            becomes  VARCHAR
ARRAY<DECIMAL(10,10)>  becomes  ARRAY<DECIMAL(10,10)>
ARRAY<CHAR(10)>        becomes  ARRAY<CHAR(10)>
ARRAY<VARCHAR(10)>     becomes  ARRAY<VARCHAR(10)>
KuduConsiderationsforDMLStatements
Currently,ImpalaINSERT,UPDATE,orotherDMLstatementsissuedthroughtheJDBCinterfaceagainstaKudutable
donotreturnJDBCerrorcodesforconditions suchasduplicateprimarykeycolumns.Therefore,forapplicationsthat
issueahighvolumeofDMLstatements,prefertousetheKuduJavaAPIdirectlyratherthanaJDBCapplication.
ApacheImpalaGuide|729ImpalaClientAccess
Troubleshooting Impala
Troubleshooting forImpalarequiresbeingabletodiagnoseanddebugproblemswithperformance, networkconnectivity ,
out-of-memor yconditions, diskspaceusage,andcrashorhangconditions inanyoftheImpala-relateddaemons.
Troubleshooting ImpalaSQLSyntaxIssues
Ingeneral,ifqueriesissuedagainstImpalafail,youcantryrunningthesesamequeriesagainstHive.
â¢IfaqueryfailsagainstbothImpalaandHive,itislikelythatthereisaproblemwithyourqueryorotherelements
ofyourCDHenvironment:
âReviewtheLanguageReferencetoensureyourqueryisvalid.
âCheckImpalaReservedWordsonpage745toseeifanydatabase,table,column,orotherobjectnamesin
yourqueryconflictwithImpalareservedwords.Quotethosenameswithbackticks(``)ifso.
âCheckImpalaBuilt-InFunctions onpage391toconfirmwhetherImpalasupports allthebuilt-infunctions
beingusedbyyourquery,andwhetherargumentandreturntypesarethesameasyouexpect.
âReviewthecontentsoftheImpalalogsforanyinformationthatmaybeusefulinidentifyingthesourceof
theproblem.
â¢IfaqueryfailsagainstImpalabutnotHive,itislikelythatthereisaproblemwithyourImpalainstallation.
Troubleshooting CrashesCausedbyMemoryResourceLimit
Underveryhighconcurrency,Impalacouldencounteraseriouserrorduetousageofvariousoperatingsystemresources.
Errorssimilartothefollowingmaybecausedbyoperatingsystemresourceexhaustion:
F0629 08:20:02.956413 29088 llvm-codegen.cc:111] LLVM hit fatal error: Unable to allocate
 section memory!
terminate called after throwing an instance of 
'boost::exception_detail::clone_impl<boost::exception_detail::error_info_injector<boost::thread_resource_error>
 >'
TheKRPCimplemen tationinCDH6.1greatlyreducesthreadcountsandthechancesofhittingaresourcelimitinCDH
6.1andhigher.
IfyoustillgetanerrorsimilartotheaboveinImpala3.0andhigher,tryincreasingthemax_map_count OSvirtual
memoryparameter.max_map_count definesthemaximumnumberofmemorymapareasthataprocesscanuse.
Configureeachhostrunninganimpalad daemonwiththecommand toincreasemax_map_count to8GB.
echo 8000000 > /proc/sys/vm/max_map_count
Tomaketheabovesettingsdurable,refertoyourOSdocumen tation.Forexample,onRHEL6.x:
1.Addthefollowinglineto/etc/sysctl.conf :
vm.max_map_count=8000000
2.Runthefollowingcommand:
sysctl -p
730|ApacheImpalaGuideTroubleshooting Impala
Troubleshooting I/OCapacityProblems
ImpalaqueriesaretypicallyI/O-intensive.IfthereisanI/Oproblemwithstoragedevices,orwithHDFSitself,Impala
queriescouldshowslowresponsetimeswithnoobviouscauseontheImpalaside.SlowI/OonevenasingleImpala
daemoncouldresultinanoverallslowdown,becausequeriesinvolvingclausessuchasORDER BY ,GROUP BY ,orJOIN
donotstartreturningresultsuntilallexecutorImpaladaemons havefinishedtheirwork.
TotestwhethertheLinuxI/Osystemitselfisperformingasexpected,runLinuxcommands likethefollowingoneach
hostImpaladaemonisrunning:
$ sudo sysctl -w vm.drop_caches=3 vm.drop_caches=0
vm.drop_caches = 3
vm.drop_caches = 0
$ sudo dd if=/dev/sda bs=1M of=/dev/null count=1k
1024+0 records in
1024+0 records out
1073741824 bytes (1.1 GB) copied, 5.60373 s, 192 MB/s
$ sudo dd if=/dev/sdb bs=1M of=/dev/null count=1k
1024+0 records in
1024+0 records out
1073741824 bytes (1.1 GB) copied, 5.51145 s, 195 MB/s
$ sudo dd if=/dev/sdc bs=1M of=/dev/null count=1k
1024+0 records in
1024+0 records out
1073741824 bytes (1.1 GB) copied, 5.58096 s, 192 MB/s
$ sudo dd if=/dev/sdd bs=1M of=/dev/null count=1k
1024+0 records in
1024+0 records out
1073741824 bytes (1.1 GB) copied, 5.43924 s, 197 MB/s
Onmodernhardware,athroughputrateoflessthan100MB/stypicallyindicatesaperformance issuewiththestorage
device.CorrectthehardwareproblembeforecontinuingwithImpalatuningorbenchmarking.
ImpalaTroubleshooting QuickReference
Thefollowingtablelistscommonproblemsandpotentialsolutions.
Recommenda tion Explanation Symptom
Adjusttimeoutandsynchronicitysettings. Impalainstanceswithlargenumbersoftables,
partitions, ordatafilestakelongertostartImpalatakesa
longtimeto
start. becausethemetadatafortheseobjectsis
broadcasttoallimpalad nodesandcached.
StartbygatheringstatisticswiththeCOMPUTE
STATSstatementforeachtableinvolvedintheTheremaybeinsufficientmemory.Duringajoin,
datafromthesecond,third,andsoonsetstobeJoinsfailto
complete.
join.Consider specifyingthe[SHUFFLE] hintso joinedisloadedintomemory.IfImpalachooses
thatdatafromthejoinedtablesissplitup aninefficientjoinorderorjoinmechanism, the
querycouldexceedthetotalmemoryavailable. betweennodesratherthanbroadcasttoeach
node.IftuningattheSQLlevelisnotsufficient,
addmorememorytoyoursystemorjoinsmaller
datasets.
Wherepossible, usetheappropriateImpala
statement(INSERT,LOAD DATA ,CREATE TABLE ,Impalametadatamaybeoutdatedafterchanges
areperformedinHive.Queriesreturn
incorrect
results. ALTER TABLE ,COMPUTE STATS ,andsoon)
ratherthanswitchingbackandforthbetween
ImpalaandHive.Impalaautomaticallybroadcasts
theresultsofDDLandDMLoperationstoall
Impalanodesinthecluster,butdoesnot
ApacheImpalaGuide|731Troubleshooting Impala
Recommenda tion Explanation Symptom
automaticallyrecognizewhensuchchangesare
madethroughHive.Afterinserting data,adding
apartition, orotheroperationinHive,refreshthe
metadataforthetableasdescribed inREFRESH
Statementonpage291.
EnsureImpalaisinstalledonallDataNodes.Start
anyimpalad instancesthatarenotrunning.Someimpalad instancesmaynothavestarted.
Usingabrowser,connecttothehostrunningthe
Impalastatestore.Connectusinganaddressof
theformhttp://hostname :port/metrics .Queriesare
slowtoreturn
results.
Note:Replacehostnameandport
withthehostnameandportofyour
Impalastatestorehostmachine
andwebserverport.Thedefault
portis25010.
Thenumberofimpalad instanceslistedshould
matchtheexpectednumberofimpalad instances
installedinthecluster.Thereshouldalsobeone
impalad instanceinstalledoneachDataNode.
EnsureImpalaisconfiguredtousenative
checksumming asdescribed inPost-Installation
ConfigurationforImpalaonpage36.Impalamaynotbeconfiguredtousenative
checksumming. Nativechecksumming uses
machine-specific instructions tocompute
checksumsoverHDFSdataveryquickly.ReviewQueriesare
slowtoreturn
results.
Impalalogs.Ifyoufindinstancesof"INFO
util.NativeCodeLoader: Loaded the
native-hadoop "messages,native
checksumming isnotenabled.
TestImpalafordatalocalitytrackingandmake
configurationchangesasnecessary.InformationImpalamaynotbeconfiguredtousedatalocality
tracking.Queriesare
slowtoreturn
results. onthisprocesscanbefoundinPost-Installation
ConfigurationforImpalaonpage36.
Ingeneral,ensuretheImpalauserhassufficient
permissions. Intheprecedingexample,ensureThiscanbetheresultofpermissions issues.For
example,youcouldusetheHiveshellasthehiveAttemptsto
complete
theImpalauserhassufficientpermissions tothe
tablethattheHiveusercreated.usertocreateatable.Aftercreatingthistable,
youcouldattempttocompletesomeaction,such
asanINSERT-SELECTonthetable.BecausetheImpalatasks
suchas
executing
tablewascreatedusingoneuserandthe INSERT-SELECT
INSERT-SELECTisattemptedbyanother,this
actionmayfailduetopermissions issues.actionsfail.The
Impalalogs
includenotes
thatfilescould
notbeopened
dueto
permission
denied.
Configurethestatestoretimeoutvalueand
possiblyothersettingsrelatedtothefrequencyAlargenumberofdatabases,tables,partitions,
andsooncanrequiremetadatasynchronization,Impalafailsto
startup,with
ofstatestoreupdatesandmetadataloading.See particularly onstartup,thattakeslongerthanthe
defaulttimeoutforthestatestoreservice.theimpalad
logsreferring
732|ApacheImpalaGuideTroubleshooting Impala
Recommenda tion Explanation Symptom
toerrors
connecting toIncreasingtheStatestoreTimeoutonpage70and
ScalabilityConsiderationsfortheImpala
Statestoreonpage606. thestatestore
serviceand
attemptsto
re-register.
ImpalaWebUserInterfaceforDebugging
EachoftheImpaladaemons (impalad ,statestored ,andcatalogd )includesabuilt-inwebserverthatdisplays
diagnosticandstatusinformation.
impaladWebUI
Theimpalad WebUIincludesinformationaboutconfigurationsettings,runningandcompletedqueries,and
associatedperformance andresourceusageforqueries.Inparticular ,theDetailslinkforeachquerydisplays
alternativeviewsofthequeryincluding agraphicalrepresentationoftheplan,andtheoutputoftheEXPLAIN ,
SUMMARY ,andPROFILE statementsfromimpala-shell .Eachhostthatrunstheimpalad daemonhasitsown
instanceoftheWebUI,withdetailsaboutthosequeriesforwhichthathostservedasthecoordinator.Theimpalad
WebUIisprimarily usedfordiagnosing queryproblemsthatcanbetracedtoaparticular node.
statestoredWebUI
Thestatestored WebUIincludesinformationaboutmemoryusage,configurationsettings,andongoinghealth
checksperformedbystatestored .Becausethereisonlyasingleinstanceofthestatestored withinanyImpala
cluster,youaccesstheWebUIonlyontheparticular hostthatservesastheImpalaStateStore.
catalogdWebUI
Thecatalogd WebUIincludesinformationaboutthedatabases,tables,andotherobjectsmanagedbyImpala,in
additiontotheresourceusageandconfigurationsettingsofthecatalogd .Becausethereisonlyasingleinstance
ofthecatalogd withinanyImpalacluster,youaccesstheWebUIonlyontheparticular hostthatservesasthe
ImpalaCatalogServer.
DebugWebUIforimpalad
Todebugandtroubleshoot animpalad usingaweb-based interface,opentheURL
http://impala-server-hostname :25000/ inabrowser.(Forsecureclusters,usetheprefixhttps:// instead
ofhttp:// .)
BecauseeachImpalanodeproducesitsownsetofdebuginformation,youshouldchooseaspecificnodethatyou
wanttoinvestigateanissueon.
TurningofftheWebUIforimpalad
TodisableWebUIforanimpalad :
1.Stoptheimpalad .
2.Restarttheimpalad withthe--enable_webserver=false startupflag.
MainPage
Themainimpalad WebUIpageat/liststhefollowinginformationabouttheimpalad :
â¢Theversionoftheimpalad daemon
TheVersionsectionalsocontainsotherinformation,suchaswhenImpalawasbuiltandwhatbuildflagswere
used.
â¢Processstarttime
ApacheImpalaGuide|733Troubleshooting Impala
â¢Hardwareinformation
â¢OSinformation
â¢Processinformation
â¢CGroupinformation
Admission ControllerPage
TheAdmission Controllerimpalad debugWebUIisat/admission pageunderthemainimpalad WebUI.
Usethe/admission pagetotroubleshoot queuedqueriesandtheadmission control.
Theadmission pageprovidesthefollowinginformationabouteachresourcepooltowhichquerieshavebeensubmitted
atleastonce:
â¢Timesincethestatestored receivedthelastupdate
â¢Awarningifthisimpalad isconsidereddisconnectedfromthestatestored andthustheinformationonthis
pagecouldbestale.
â¢Poolconfiguration
â¢Queuedqueriessubmittedtothiscoordinator,intheorderofsubmission
â¢Runningqueriessubmittedtothiscoordinator
â¢Poolstats
âAverageoftimeinqueue:Anexponentialmovingaveragewhichrepresentstheaveragetimeinqueueover
thelast10to12queries.Ifaqueryisadmittedimmediately,thewaittimeof0isusedincalculatingthis
averagewaittime.
â¢Histogramofthedistribution ofpeakmemoryusedbyqueriesadmittedtothepool
Usethehistogramtofigureoutsettingsfortheminimum andmaximumqueryMEM_LIMIT rangesforthispool.
Thehistogramdisplaysdataforallqueriesadmittedtothepool,including thequeriesthatfinished,gotcanceled,
orhitanerror.
Clickonthepoolnametoonlydisplayinformationrelevanttothatpool.Youcanthenrefreshthedebugpagetosee
onlytheinformationforthatspecificpool.
ClickResetinformationalstatsforallpoolstoresetthestatsthatkeeptrackofhistoricaldata,suchasTotalsstats,
Timeinqueue(exponentialmovingaverage),andthehistogram.
TheaboveinformationisalsoavailableasaJSONobjectfromthefollowingHTTPendpoint:
http://impala-server-hostname :port/admission?json
SeeAdmission ControlandQueryQueuingonpage549forthedescriptionofthepropertiesinadmission control.
KnownBackendsPage
TheKnownbackendspageoftheimpalad debugWebUIisat/backendsunderthemainimpalad WebUI.
Thispageliststhefollowinginfoforeachoftheimpalad nodesinthecluster.Becauseeachimpalad daemonknows
abouteveryotherimpalad daemonthroughtheStateStore,thisinformationshouldbethesameregardlessofwhich
nodeyouselect.
â¢Addressofthenode:Hostnameandport
â¢KRPCaddress:TheKRPCaddressoftheimpalad .UsethisaddresswhenyouissuetheSHUTDOWN command for
thisimpalad .
â¢Whetheractingasacoordinator
â¢Whetheractingasanexecutor
â¢Quiescing status:Specifywhetherthegracefulshutdownprocesshasbeeninitiatedonthisimpalad .
â¢Memorylimitforadmission: Theamountofmemorythatcanbeadmittedtothisbackendbytheadmission
controller.
734|ApacheImpalaGuideTroubleshooting Impala
â¢Memoryreserved:Theamountofmemoryreservedbyqueriesthatareactive,eithercurrentlyexecutingor
finishedbutnotyetclosed,onthisbackend.
Thememoryreservedforaquerythatiscurrentlyexecutingisitsmemorylimit,ifset.Otherwise,ifthequeryhas
nolimitorifthequeryfinishedexecuting,thecurrentconsumptionisused.
â¢Memoryofthequeriesadmittedtothiscoordinator:Thememorysubmittedtothisparticular hostbythequeries
admittedbythiscoordinator.
CatalogPage
TheCatalogpageoftheimpalad debugWebUIisat/catalogunderthemainimpalad WebUI.
Thispagedisplaysalistofdatabasesandassociatedtablesrecognizedbythisinstanceofimpalad .Youcanusethis
pagetolocatewhichdatabaseatableisin,checktheexactspellingofadatabaseortablename,lookforidentical
tablenamesinmultipledatabases.Theprimarydebuggingusecasewouldbetocheckifanimpalad instancehas
knowledgeofaparticular tablethatsomeone expectstobeinaparticular database.
HadoopConfiguration
TheHadoopConfigurationpageoftheimpalad debugWebUIisat/hadoop-v arzunderthemainimpalad WebUI.
ThispagedisplaystheHadoopcommonconfigurationsthatImpalaisrunningwith.
JMX
TheJMXpageoftheimpalad debugWebUIisat/jmxunderthemainimpalad WebUI.
ThispagedisplaysmonitoringinformationaboutvariousJVMsubsystems,suchasmemorypools,threadmanagement,
runtime.etc.
JavaLogLevel
TheChangeloglevelpageoftheimpalad debugWebUIisat/log_levelunderthemainimpalad WebUI.
ThispagedisplaysthecurrentJavaandbackendloglevels,anditallowsyoutochangetheloglevelsdynamically
withouthavingtorestarttheimpalad .
LogsPage
TheINFOlogspageoftheimpalad debugWebUIisat/logsunderthemainimpalad WebUI.
Thispageshowsthelastportionoftheimpalad.INFO logfile,including theinfo,warning,anderrorlogsforthe
impalad .Youcanseethedetailsofthemostrecentoperations,whethertheoperationssucceeded orencountered
errors.Thispageprovidesonecentralplaceforthelogfilesandsavesyoufromlookingaroundthefilesystemforthe
logfiles,whichcouldbeindifferentlocationsonclustersthatuseclustermanagementsoftware.
MemzPage
TheMemoryUsagepageoftheimpalad debugWebUIisat/memzunderthemainimpalad WebUI.
Thispagedisplaysthesummaryanddetailedinformationaboutmemoryusagebytheimpalad .
MetricsPage
TheMetricspageoftheimpalad debugWebUIisat/metricsunderthemainimpalad WebUI.
Thispagedisplaysthecurrentsetofmetrics,countersandflagsrepresentingvariousaspectsofimpalad internal
operations.
QueriesPage
TheQueriespageoftheimpalad debugWebUIisat/queriesunderthemainimpalad WebUI.
Thispagelists:
â¢Currentlyrunningqueries
ApacheImpalaGuide|735Troubleshooting Impala
â¢Queriesthathavecompletedtheirexecution,buthavenotbeenclosedyet
â¢Completedquerieswhosedetailsstillresideinmemory
Thequeriesarelistedinreversechronologicalorder,withthemostrecentatthetop.Youcancontroltheamountof
memorydevotedtocompletedqueriesbyspecifyingthe----query_log_size startupoptionforimpalad .
Thispageprovides:
â¢HowmanySQLstatementsarefailing(StatevalueofEXCEPTION )
â¢Howlargetheresultsetsare(# rows fetched )
â¢Howlongeachstatementtook(Start Time andEnd Time )
ClicktheDetailslinkforaquerytodisplaythedetailedperformance characteristicsofthatquery,suchastheprofile
output.
Onthequerydetailpage,intheProfiletab,youhaveoptionstoexportthequeryprofileoutputtotheThrif,text,or
Jsonformat.
TheQueriespagealsoincludestheQueryLocationssectionthatliststhenumberofrunningquerieswithfragments
onthishost.
RPCServicesPage
TheRPCdurationspageoftheimpalad debugWebUIisat/rpczunderthemainimpalad WebUI.
Thispagedisplaysinformation,suchastheduration,abouttheRPCcommunic ationsofthisimpalad withotherImpala
daemons.
SessionsPage
TheSessionspageoftheimpalad debugWebUIisat/sessionunderthemainimpalad WebUI.
Thispagedisplaysinformationaboutthesessionscurrentlyconnectedtothisimpalad instance.Forexample,sessions
couldincludeconnections fromtheimpala-shell command, JDBCorODBCapplications,ortheImpalaQueryUIin
theHuewebinterface.
ThreadzPage
TheThreadspageoftheimpalad debugWebUIisat/threadzunderthemainimpalad WebUI.
Thispagedisplaysinformationaboutthethreadsusedbythisinstanceofimpalad ,anditshowswhichcategories
theyaregroupedinto.MakinguseofthisinformationrequiressubstantialknowledgeaboutImpalainternals.
VarzPage
TheVarzpageoftheimpalad debugWebUIisat/varzunderthemainimpalad WebUI.
Thispageshowstheconfigurationsettingsineffectwhenthisinstanceofimpalad communic ateswithotherHadoop
componen tssuchasHDFSandYARN.Thesesettingsarecollectedfromasetofconfigurationfiles.
Thebottomofthispagealsolistsallthecommand-line settingsineffectforthisinstanceofimpalad .SeeModifying
ImpalaStartupOptionsforinformationaboutmodifyingthesevalues.
PrometheusMetricsPage
At/metrics_prometheusunderthemainimpalad WebUI,themetricsaregeneratedinPrometheusexposition format
thatPrometheuscanconsumeforeventmonitoringandalerting.The/metrics_prometheusisnotshownintheWeb
UIlistofpages.
DebugWebUIforstatestored
Todebugandtroubleshoot thestatestored daemonusingaweb-based interface,opentheURL
http://impala-server-hostname :25010/ inabrowser.(Forsecureclusters,usetheprefixhttps:// instead
ofhttp:// .)
736|ApacheImpalaGuideTroubleshooting Impala
TurningofftheWebUIforstatestored
TodisableWebUIforthestatestored :
1.Stopthestatestored .
2.Restartthestatestored withthe--enable_webserver=false startupflag.
MainPage
Themainstatestored WebUIpageat/liststhefollowinginformationaboutthestatestored :
â¢Theversionofthestatestored daemon
â¢Processstarttime
â¢Hardwareinformation
â¢OSinformation
â¢Processinformation
â¢CGroupinformation
LogsPage
TheINFOlogspageofthedebugWebUIisat/logsunderthemainstatestored WebUI.
Thispageshowsthelastportionofthestatestored.INFO logfile,including theinfo,warning,anderrorlogsforthe
statestored .Youcanreferheretoseethedetailsofthemostrecentoperations,whethertheoperationssucceeded
orencounterederrors.Thispageprovidesonecentralplaceforthelogfilesandsavesyoufromlookingaroundthe
filesystemforthelogfiles,whichcouldbeindifferentlocationsonclustersthatuseclustermanagementsoftware.
MemzPage
TheMemoryUsagepageofthedebugWebUIisat/memzunderthemainstatestored WebUI.
Thispagedisplayssummaryanddetailedinformationaboutmemoryusagebythestatestored .Youcanseethe
memorylimitineffectforthenode,andhowmuchofthatmemoryImpalaiscurrentlyusing.
MetricsPage
TheMetricspageofthedebugWebUIisat/metricsunderthemainstatestored WebUI.
Thispagedisplaysthecurrentsetofmetrics:countersandflagsrepresentingvariousaspectsofstatestored internal
operation.
RPCServicesPage
TheRPCdurationspageofthestatestored debugWebUIisat/rpczunderthemainstatestored WebUI.
Thispagedisplaysinformation,suchasthedurations,abouttheRPCcommunic ationsofthisstatestored withother
Impaladaemons.
SubscribersPage
TheSubscriberspageofthedebugWebUIisat/subscribersunderthemainstatestored WebUI.
ThispagedisplaysinformationabouttheotherImpaladaemons thathaveregisteredwiththestatestored toreceive
andsendupdates.
ThreadzPage
TheThreadspageofthedebugWebUIisat/threadzunderthemainstatestored WebUI.
Thispagedisplaysinformationaboutthethreadsusedbythisinstanceofstatestored ,andshowswhichcategories
theyaregroupedinto.MakinguseofthisinformationrequiressubstantialknowledgeaboutImpalainternals.
TopicsPage
TheTopicspageofthedebugWebUIisat/topicsunderthemainstatestored WebUI.
ApacheImpalaGuide|737Troubleshooting Impala
ThispagedisplaysinformationaboutthetopicstowhichtheotherImpaladaemons haveregisteredtoreceiveupdates.
VarzPage
TheVarzpageofthedebugWebUIisat/varzunderthemainstatestored WebUI.
Thispageshowstheconfigurationsettingsineffectwhenthisinstanceofstatestored communic ateswithother
Hadoopcomponen tssuchasHDFSandYARN.Thesesettingsarecollectedfromasetofconfigurationfiles.
Thebottomofthispagealsolistsallthecommand-line settingsineffectforthisinstanceofstatestored .See
ModifyingImpalaStartupOptionsforinformationaboutmodifyingthesevalues.
PrometheusMetricsPage
At/metrics_prometheusunderthemainstatestored WebUI,themetricsaregeneratedinPrometheusexposition
formatthatPrometheuscanconsumes foreventmonitoringandalerting.The/metrics_prometheusisnotshownin
theWebUIlistofpages.
DebugWebUIforcatalogd
ThemainpageofthedebugWebUIisathttp://impala-server-hostname :25020/ (non-secur ecluster)or
https:// impala-server-hostname :25020/ (securecluster).
TurningofftheWebUIforcatalogd
TodisableWebUIforthecatalogd :
1.Stopthecatalogd .
2.Restartthecatalogd withthe--enable_webserver=false startupflag.
MainPage
Themaincatalogd WebUIpageat/liststhefollowinginformationaboutthecatalogd :
â¢Theversionofthecatalogd daemon
â¢Processstarttime
â¢Hardwareinformation
â¢OSinformation
â¢Processinformation
â¢CGroupinformation
CatalogPage
TheCatalogpageofthedebugWebUIisat/catalogunderthemaincatalogd WebUI.
Thispagedisplaysalistofdatabasesandassociatedtablesrecognizedbythisinstanceofcatalogd .Youcanusethis
pagetolocatewhichdatabaseatableisin,checktheexactspellingofadatabaseortablename,lookforidentical
tablenamesinmultipledatabases.Thecataloginformationisrepresentedastheunderlying Thriftdatastructures.
JMX
TheJMXpageofthecatalogd debugWebUIisat/jmxunderthemaincatalogd WebUI.
ThispagedisplaysmonitoringinformationaboutvariousJVMsubsystems,suchasmemorypools,threadmanagement,
runtime.etc.
JavaLogLevel
TheChangeloglevelpageofthecatalogd debugWebUIisat/log_levelunderthemaincatalogd WebUI.
ThepagedisplaysthecurrentJavaandbackendloglevelsandallowsyoutochangetheloglevelsdynamicallywithout
havingtorestartthecatalogd
738|ApacheImpalaGuideTroubleshooting Impala
LogsPage
TheINFOlogspageofthedebugWebUIisat/logsunderthemaincatalogd WebUI.
Thispageshowsthelastportionofthecatalogd.INFO logfile,including theinfo,warning,anderrorlogsforthe
catalogd daemon. Youcanreferheretoseethedetailsofthemostrecentoperations,whethertheoperations
succeeded orencounterederrors.Thispageprovidesonecentralplaceforthelogfilesandsavesyoufromlooking
aroundthefilesystemforthelogfiles,whichcouldbeindifferentlocationsonclustersthatuseclustermanagement
software.
MemzPage
TheMemoryUsagepageofthedebugWebUIisat/memzunderthemaincatalogd WebUI.
Thispagedisplayssummaryanddetailedinformationaboutmemoryusagebythecatalogd .Youcanseethememory
limitineffectforthenode,andhowmuchofthatmemoryImpalaiscurrentlyusing.
MetricsPage
TheMetricspageofthedebugWebUIisat/metricsunderthemaincatalogd WebUI.
Thispagedisplaysthecurrentsetofmetrics:countersandflagsrepresentingvariousaspectsofcatalogd internal
operation.
RPCServicesPage
TheRPCdurationspageofthecatalogd debugWebUIisat/rpczunderthemaincatalogd WebUI.
Thispagedisplaysinformation,suchasthedurations,abouttheRPCcommunic ationsofthiscatalogd withother
Impaladaemons.
ThreadzPage
TheThreadspageofthedebugWebUIisat/threadzunderthemaincatalogd WebUI.
Thispagedisplaysinformationaboutthethreadsusedbythisinstanceofcatalogd ,andshowswhichcategoriesthey
aregroupedinto.MakinguseofthisinformationrequiressubstantialknowledgeaboutImpalainternals.
VarzPage
TheVarzpageofthedebugWebUIisat/varzunderthemaincatalogd WebUI.
Thispageshowstheconfigurationsettingsineffectwhenthisinstanceofcatalogd communic ateswithotherHadoop
componen tssuchasHDFSandYARN.Thesesettingsarecollectedfromasetofconfigurationfiles.
Thebottomofthispagealsolistsallthecommand-line settingsineffectforthisinstanceofcatalogd .SeeModifying
ImpalaStartupOptionsforinformationaboutmodifyingthesevalues.
PrometheusMetricsPage
At/metrics_prometheusunderthemainimpalad WebUI,themetricsaregeneratedinPrometheusexposition format
thatPrometheuscanconsumeforeventmonitoringandalerting.The/metrics_prometheusisnotshownintheWeb
UIlistofpages.
BreakpadMinidump sforImpala(CDH5.8orhigheronly)
Thebreakpadprojectisanopen-sour ceframeworkforcrashreporting. InCDH5.8/Impala2.6andhigher,Impalacan
usebreakpad torecordstackinformationandregistervalueswhenanyoftheImpala-relateddaemons crashdueto
anerrorsuchasSIGSEGV orunhandled exceptions.Thedumpfilesaremuchsmallerthantraditional coredumpfiles.
Thedumpmechanism itselfusesverylittlememory,whichimprovesreliabilityifthecrashoccurswhilethesystemis
lowonmemory.
ApacheImpalaGuide|739Troubleshooting Impala
Important:Becauseoftheinternalmechanisms involvingImpalamemoryallocationandLinux
signalling forout-of-memor y(OOM)errors,ifanImpala-relateddaemonexperiences acrashdueto
anOOMcondition, itdoesnotgenerateaminidump forthaterror.
EnablingorDisabling Minidump Generation
Bydefault,aminidump fileisgeneratedwhenanImpala-relateddaemoncrashes.
Toturnoffgenerationoftheminidump files,useoneofthefollowingoptions:
â¢Setthe--enable_minidumps configurationsettingtofalse.Restartthecorresponding servicesordaemons.
â¢Setthe--minidump_path configurationsettingtoanemptystring.Restartthecorresponding servicesordaemons.
InCDH5.9/Impala2.7andhigher,youcansendaSIGUSR1 signaltoanyImpala-relateddaemontowriteaBreakpad
minidump. Foradvancedtroubleshooting ,youcannowproduceaminidump withouttriggeringacrash.
SpecifyingtheLocationforMinidump Files
Bydefault,allminidump filesarewrittentothefollowinglocationonthehostwhereacrashoccurs:
â¢ClustersmanagedbyClouderaManager:/var/log/impala-minidumps/ daemon_name
â¢ClustersnotmanagedbyClouderaManager:impala_log_dir /daemon_name /minidumps/ daemon_name
Theminidump filesforimpalad ,catalogd ,andstatestored areeachwrittentoaseparatedirectory.
Tospecifyadifferentlocation,settheminidump_pa thconfigurationsettingofoneormoreImpala-relateddaemons,
andrestartthecorresponding servicesordaemons.
Ifyouspecifyarelativepathforthissetting,thevalueisinterpretedrelativetothedefaultminidump_pa thdirectory.
ControllingtheNumberofMinidump Files
Likeanyfilesusedforloggingortroubleshooting ,considerlimitingthenumberofminidump files,orremovingunneeded
ones,depending ontheamountoffreestoragespaceonthehostsinthecluster.
Becausetheminidump filesareonlyusedforproblemresolution, youcanremoveanysuchfilesthatarenotneeded
todebugcurrentissues.
Tocontrolhowmanyminidump filesImpalakeepsaroundatanyonetime,setthemax_minidump sconfiguration
settingforofoneormoreImpala-relateddaemon, andrestartthecorresponding servicesordaemons. Thedefault
forthissettingis9.Azeroornegativevalueisinterpretedasâunlimitedâ.
DetectingCrashEvents
YoucanseeintheImpalalogfilesorintheClouderaManagerchartsforImpalawhencrasheventsoccurthatgenerate
minidump files.Becauseeachrestartbeginsanewlogfile,theâcrashedâmessageisalwaysatornearthebottomof
thelogfile.(Theremightbeanotherlatermessageifcoredumpsarealsoenabled.)
UsingtheMinidump FilesforProblemResolution
Typically,youprovideminidump filestoClouderaSupportaspartofproblemresolution, inthesamewaythatyou
mightprovideacoredump.TheSendDiagnosticDataundertheSupportmenuinClouderaManagerguidesyou
throughtheprocessofselecting atimeperiodandvolumeofdiagnosticdata,thencollectsthedatafromallhostsand
transmitstherelevantinformationforyou.
740|ApacheImpalaGuideTroubleshooting Impala
Figure6:SendDiagnosticDatachoiceunderSupportmenu
Youmightgetadditional instructions fromClouderaSupportaboutcollectingminidump stobetterisolateaspecific
problem.Becausetheinformationintheminidump filesislimitedtostacktracesandregistercontents,thepossibility
ofincluding sensitiveinformationismuchlowerthanwithcoredumpfiles.Ifanysensitiveinformationisincludedin
theminidump, ClouderaSupportpreservestheconfidentialityofthatinformation.
DemonstrationofBreakpadFeature
Thefollowingexampleusesthecommandkill -11 tosimulateaSIGSEGV crashforanimpalad processonasingle
DataNode,thenexaminestherelevantlogfilesandminidump file.
First,asrootonaworkernode,wekilltheimpalad processwithaSIGSEGV error.TheoriginalprocessIDwas23114.
(ClouderaManagerrestartstheprocesswithanewpid,asshownbythesecondpscommand.)
# ps ax | grep impalad
23114 ?        Sl     0:18 
/opt/cloudera/parcels/<parcel_version>/lib/impala/sbin-retail/impalad 
--flagfile=/var/run/cloudera-scm-agent/process/114-impala-IMPALAD/impala-conf/impalad_flags
31259 pts/0    S+     0:00 grep impalad
#
# kill -11 23114
#
# ps ax | grep impalad
31374 ?        Rl     0:04 
/opt/cloudera/parcels/<parcel_version>/lib/impala/sbin-retail/impalad 
--flagfile=/var/run/cloudera-scm-agent/process/114-impala-IMPALAD/impala-conf/impalad_flags
31475 pts/0    S+     0:00 grep impalad
ApacheImpalaGuide|741Troubleshooting Impala
Welocatethelogdirectoryundernea th/var/log .Thereisa.INFO,.WARNING ,and.ERRORlogfileforthe23114
processID.Theminidump messageiswrittentothe.INFOfileandthe.ERRORfile,butnotthe.WARNING file.Inthis
case,alargecorefilewasalsoproduced.
# cd /var/log/impalad
# ls -la | grep 23114
-rw-------   1 impala impala 3539079168 Jun 23 15:20 core.23114
-rw-r--r--   1 impala impala      99057 Jun 23 15:20 hs_err_pid23114.log
-rw-r--r--   1 impala impala        351 Jun 23 15:20 
impalad.worker_node_123.impala.log.ERROR.20160623-140343.23114
-rw-r--r--   1 impala impala      29101 Jun 23 15:20 
impalad.worker_node_123.impala.log.INFO.20160623-140343.23114
-rw-r--r--   1 impala impala        228 Jun 23 14:03 
impalad.worker_node_123.impala.log.WARNING.20160623-140343.23114
The.INFOlogincludesthelocationoftheminidump file,followedbyareportofacoredump.Withthebreakpad
minidump featureenabled, nowwemightdisablecoredumpsorkeepfewerofthemaround.
# cat impalad.worker_node_123.impala.log.INFO.20160623-140343.23114
...
Wrote minidump to 
/var/log/impala-minidumps/impalad/0980da2d-a905-01e1-25ff883a-04ee027a.dmp
#
# A fatal error has been detected by the Java Runtime Environment:
#
#  SIGSEGV (0xb) at pc=0x00000030c0e0b68a, pid=23114, tid=139869541455968
#
# JRE version: Java(TM) SE Runtime Environment (7.0_67-b01) (build 1.7.0_67-b01)
# Java VM: Java HotSpot(TM) 64-Bit Server VM (24.65-b04 mixed mode linux-amd64 compressed
 oops)
# Problematic frame:
# C  [libpthread.so.0+0xb68a]  pthread_cond_wait+0xca
#
# Core dump written. Default location: /var/log/impalad/core or core.23114
#
# An error report file with more information is saved as:
# /var/log/impalad/hs_err_pid23114.log
#
# If you would like to submit a bug report, please visit:
#   http://bugreport.sun.com/bugreport/crash.jsp
# The crash happened outside the Java Virtual Machine in native code.
# See problematic frame for where to report the bug.
...
# cat impalad.worker_node_123.impala.log.ERROR.20160623-140343.23114
Log file created at: 2016/06/23 14:03:43
Running on machine:.worker_node_123
Log line format: [IWEF]mmdd hh:mm:ss.uuuuuu threadid file:line] msg
E0623 14:03:43.911002 23114 logging.cc:118] stderr will be logged to this file.
Wrote minidump to 
/var/log/impala-minidumps/impalad/0980da2d-a905-01e1-25ff883a-04ee027a.dmp
Theresultingminidump fileismuchsmallerthanthecorresponding corefile,makingitmucheasiertosupplydiagnostic
informationtoClouderaSupport.Thetransmission processfortheminidump filesisautomatedthroughCloudera
Manager.
# pwd
/var/log/impalad
# cd ../impala-minidumps/impalad
# ls
0980da2d-a905-01e1-25ff883a-04ee027a.dmp
# du -kh *
2.4M  0980da2d-a905-01e1-25ff883a-04ee027a.dmp
742|ApacheImpalaGuideTroubleshooting Impala
PortsUsedbyImpala
ImpalausestheTCPportslistedinthefollowingtable.BeforedeployingImpala,ensuretheseportsareopenoneach
system.
Comment Default
PortSettinginClouderaManager Scope/Role
Usedtotransmitcommands and
receiveresultsbyimpala-shell and21000 ImpalaDaemonFrontendPort ImpalaDaemon
version1.2oftheClouderaODBC
driver.
Usedtotransmitcommands and
receiveresultsbyapplications,such21050 ImpalaDaemonFrontendPort ImpalaDaemon
asBusinessIntelligencetools,using
JDBC,theBeeswaxqueryeditorin
Hue,andversion2.0orhigherofthe
ClouderaODBCdriver.
Internaluseonly.Impaladaemons use
thisporttocommunic atewitheach
other.22000 ImpalaDaemonBackendPort ImpalaDaemon
Internaluseonly.Impaladaemons
listenonthisportforupdatesfrom
thestatestoredaemon.23000 StateStoreSubscriberServicePort ImpalaDaemon
Internaluseonly.Thecatalogdaemon
listensonthisportforupdatesfrom
thestatestoredaemon.23020 StateStoreSubscriberServicePort CatalogDaemon
Impalawebinterfacefor
administratorstomonitorand
troubleshoot.25000 ImpalaDaemonHTTPServerPort ImpalaDaemon
StateStorewebinterfacefor
administratorstomonitorand
troubleshoot.25010 StateStoreHTTPServerPort ImpalaStateStore
Daemon
Catalogservicewebinterfacefor
administratorstomonitorand25020 CatalogHTTPServerPort ImpalaCatalogDaemon
troubleshoot. NewinImpala1.2and
higher.
Internaluseonly.Thestatestore
daemonlistensonthisportfor
registration/unregistrationrequests.24000 StateStoreServicePort ImpalaStateStore
Daemon
Internaluseonly.Thecatalogservice
usesthisporttocommunic atewith26000 CatalogServicePort ImpalaCatalogDaemon
theImpaladaemons. NewinImpala
1.2andhigher.
ApacheImpalaGuide|743PortsUsedbyImpala
Comment Default
PortSettinginClouderaManager Scope/Role
Internaluseonly.Impaladaemons use
thisportforKRPCbased
communic ationwitheachother.27000 KRPCPort ImpalaDaemon
744|ApacheImpalaGuidePortsUsedbyImpala
ImpalaReservedWords
ThistopicliststhereservedwordsinImpala.
Areservedwordisonethatcannotbeuseddirectlyasanidentifier.Ifyouneedtouseitasanidentifier,youmust
quoteitwithbackticks.Forexample:
â¢CREATE TABLE select (x INT) :fails
â¢CREATE TABLE `select` (x INT) :succeeds
Becausedifferentdatabasesystemshavedifferentsetsofreservedwords,andthereservedwordschangefromrelease
torelease,carefullyconsiderdatabase,table,andcolumnnamestoensuremaximumcompatibilitybetweenproducts
andversions.
AlsoconsiderwhetheryourobjectnamesarethesameasanyHivekeywords,andrenameorquoteanythatconflict
asyoumightswitchbetweenImpalaandHivewhendoinganalyticsandETL.ConsultthelistofHivekeywords.
Tofuture-proofyourcode,youshouldavoidadditional wordsincasetheybecomereservedwordsifImpalaadds
featuresinlaterreleases.ThiskindofplanningcanalsohelptoavoidnameconflictsincaseyouportSQLfromother
systemsthathavedifferentsetsofreservedwords.TheFutureKeywordcolumninthetablebelowindicatesthose
additional wordsthatyoushouldavoidfortable,column,orotherobjectnames,eventhoughtheyarenotcurrently
reservedbyImpala.
Thefollowingisasummaryoftheprocessfordecidingwhetheraparticular SQL2016wordistobereservedinImpala.
â¢Bydefault,ImpalatargetstohavethesamelistofreservedwordsasSQL2016.
â¢Atthesametime,tobecompatiblewithearlierversionsofImpalaandtoavoidbreakingexistingtables/workloads,
Impalabuilt-infunctionnamesareremovedfromthereservedwordslist,e.g.COUNT,AVG,asImpalagenerally
doesnotneedtoreservethenamesofbuilt-infunctions forparsingtowork.
â¢Forthoseremaining SQL2016reservedwords,ifawordislikelytobein-usebyusersofolderImpalaversions
andifthereisalowchanceofImpalaneedingtoreservethatwordinthefuture,thenthewordisnotreserved.
â¢Otherwise,thewordisreservedinImpala.
ListofCurrentReservedWords
FutureKeyword Reserved
inReserved
inReserved
inKeyword
CDH6.0/Impala3.0
andhigherImpala2.12andlower SQL:2016
X abs
X acos
X X add
X X aggregate
X X X all
X X allocate
X X X alter
X X analytic
X X X and
X X anti
ApacheImpalaGuide|745ImpalaReservedWords
X X any
X api_version
X X are
X X X array
X X array_agg
X X array_max_cardinality
X X X as
X X asc
X X asensitive
X asin
X X asymmetric
X X at
X atan
X X atomic
X X authorization
X avg
X X avro
X backup
X X begin
X X begin_frame
X X begin_partition
X X X between
X X X bigint
X X X binary
X X blob
X block_size
X X X boolean
X X both
X break
X browse
X bulk
X X X by
cache
X X cached
X call
X X called
746|ApacheImpalaGuideImpalaReservedWords
X X cardinality
X X cascade
X X cascaded
X X X case
X X X cast
X ceil
X ceiling
X X change
X X X char
X char_length
X X character
X character_length
X X check
X checkpoint
X X class
X classifier
X X clob
X X close
X close_fn
X clustered
X X coalesce
X X collate
X X collect
X X X column
X X columns
X X comment
X X commit
X X compression
X X compute
X X condition
conf
X X connect
X X constraint
X X contains
X continue
X X convert
ApacheImpalaGuide|747ImpalaReservedWords
X X copy
X X corr
X X corresponding
X cos
X cosh
X count
X X covar_pop
X X covar_samp
X X X create
X X X cross
X X cube
X cume_dist
X X X current
X current_catalog
X X current_date
X X current_default_transform_group
X X current_path
X X current_role
X X current_row
X X current_schema
X X current_time
X X current_timestamp
X X current_transform_group_for_type
X X current_user
X X cursor
X X cycle
X X data
X X database
X X databases
X X X date
X X datetime
X day
dayofweek
X dbcc
X X deallocate
X X dec
748|ApacheImpalaGuideImpalaReservedWords
X X decfloat
X X X decimal
X X declare
X X X default
X X define
X X X delete
X X delimited
X dense_rank
X deny
X X deref
X X desc
X X X describe
X X deterministic
X X disconnect
X disk
X X X distinct
X distributed
X X div
X X X double
X X X drop
X dump
X X dynamic
X X each
X X element
X X X else
X X empty
X X encoding
X X X end
X X end-exec
X X end_frame
X X end_partition
X X equals
X errlvl
X X escape
X X escaped
X X every
ApacheImpalaGuide|749ImpalaReservedWords
X X except
exchange
X X exec
X X execute
X X X exists
X exit
X exp
X X explain
X X extended
X X X external
X extract
X X X false
X X fetch
X X fields
X file
X filefactor
X X fileformat
X X files
X X filter
X finalize_fn
X X first
X first_value
X X X float
X floor
X X following
X X X for
X X foreign
X X format
X X formatted
X X frame_row
X X free
X freetext
X X X from
X X X full
X X X function
X X functions
750|ApacheImpalaGuideImpalaReservedWords
X X fusion
X X get
X X global
X goto
X X X grant
X X X group
X X grouping
X X groups
X X hash
X X X having
X X hold
X holdlock
X hour
X X identity
X X if
X X ignore
X X ilike
import
X X X in
X X incremental
X index
X X indicator
X init_fn
X X initial
X X X inner
X X inout
X X inpath
X X insensitive
X X X insert
X X X int
X X X integer
X X intermediate
X X intersect
X X intersection
X X X interval
X X X into
ApacheImpalaGuide|751ImpalaReservedWords
X X invalidate
X X iregexp
X X X is
X X X join
X X json_array
X X json_arrayagg
X X json_exists
X X json_object
X X json_objectagg
X X json_query
X X json_table
X X json_table_primitive
X X json_value
X key
X kill
X X kudu
X lag
X language
X X large
X X last
X last_value
X X lateral
X lead
X X leading
X X X left
less
X X X like
X X like_regex
X X limit
X lineno
X X lines
X X listagg
X ln
X X load
X X local
X localtime
752|ApacheImpalaGuideImpalaReservedWords
X X localtimestamp
X X location
X log
X X log10
X lower
macro
X X map
X X match
X X match_number
X X match_recognize
X X matches
X max
X member
X X merge
X merge_fn
X X metadata
X X method
X min
X minute
X mod
X X modifies
X module
X month
more
X X multiset
X X national
X X natural
X X nchar
X X nclob
X new
X X no
X nocheck
X nonclustered
X X none
X X normalize
X X X not
ApacheImpalaGuide|753ImpalaReservedWords
X X nth_value
X ntile
X X X null
X X nullif
X X nulls
X X numeric
X X occurrences_regex
X X octet_length
X X of
X off
X X X offset
X offsets
X old
X X omit
X X X on
X X one
X X only
X X open
X option
X X X or
X X X order
X X out
X X X outer
X X X over
X X overlaps
X X overlay
X X overwrite
X parameter
X X parquet
X X parquetfile
partialscan
X X X partition
X X partitioned
X X partitions
X X pattern
X X per
754|ApacheImpalaGuideImpalaReservedWords
X X percent
X percent_rank
X X percentile_cont
X X percentile_disc
X period
X pivot
X plan
X X portion
X X position
X X position_regex
X power
X X precedes
X X preceding
X X precision
X X prepare
X prepare_fn
preserve
X X X primary
X print
X proc
X X procedure
X X produced
X X ptf
X public
X X purge
X raiseerror
X X X range
X rank
X X rcfile
X read
X X reads
X readtext
X X X real
X reconfigure
X X recover
X X recursive
ApacheImpalaGuide|755ImpalaReservedWords
reduce
X X ref
X X references
X X referencing
X X refresh
X X regexp
X X regr_avgx
X X regr_avgy
X X regr_count
X X regr_intercept
X X regr_r2
X X regr_slope
X X regr_sxx
X X regr_sxy
X X regr_syy
X X release
X X rename
X X repeatable
X X replace
X X replication
X restore
X X restrict
X result
X X return
X X X returns
X revert
X X X revoke
X X X right
X X rlike
X X role
X X roles
X X rollback
X X rollup
X X X row
X row_number
X rowcount
756|ApacheImpalaGuideImpalaReservedWords
X X X rows
X rule
X X running
X save
X X savepoint
X X schema
X X schemas
X X scope
X X scroll
X X search
X second
X securityaudit
X X seek
X X X select
X X semi
X X sensitive
X X sequencefile
X X serdeproperties
X serialize_fn
X X session_user
X X X set
X setuser
X X X show
X shutdown
X X similar
X sin
X sinh
X X skip
X X X smallint
X X some
X X sort
X X specific
X X specifictype
X sql
X X sqlexception
X X sqlstate
ApacheImpalaGuide|757ImpalaReservedWords
X X sqlwarning
X sqrt
X start
X X static
X statistics
X X stats
X stddev_pop
X stddev_samp
X X stored
X straight_join
X X string
X X struct
X X submultiset
X X subset
X substring
X X substring_regex
X X succeeds
X sum
X X symbol
X X symmetric
X system
X X system_time
X X system_user
X X X table
X X tables
X X X tablesample
X tan
X tanh
X X tblproperties
X X terminated
X X textfile
X textsize
X X X then
X time
X X X timestamp
X X timezone_hour
758|ApacheImpalaGuideImpalaReservedWords
X X timezone_minute
X X tinyint
X X X to
X top
X X trailing
X tran
transform
X translate
X X translate_regex
X X translation
X X treat
X X trigger
X trim
X X trim_array
X X X true
X X X truncate
X try_convert
X X uescape
X X unbounded
X X uncached
X X X union
X X unique
uniquejoin
X X X unknown
X X unnest
X unpivot
X X X update
X update_fn
X updatetext
X upper
X X upsert
X X use
X X user
X X X using
utc_tmestamp
X value
ApacheImpalaGuide|759ImpalaReservedWords
X X value_of
X X X values
X var_pop
X var_samp
X X varbinary
X X X varchar
X X varying
X X versioning
X X view
views
X waitfor
X X X when
X X whenever
X X X where
X while
X X width_bucket
X X window
X X X with
X X within
X X without
X writetext
X year
760|ApacheImpalaGuideImpalaReservedWords
ImpalaFrequentlyAskedQuestions
HerearethecategoriesoffrequentlyaskedquestionsforApacheImpala,theinteractiveSQLengineforCDH.
TransitiontoApacheGovernance
Does"ApacheImpala(incubating)"meanImpalaisnotproduction-r eady?
No.Theâ(incubating)âlabelwasonlyappliedtotheApacheImpalaprojectwhileitwastransitioning togovernance
bytheApacheSoftwareFoundation.Impalagraduatedtoatop-levelApacheprojectonNovember15,2017.
ImpalahasalwaysbeenApache-licensed. Thesoftwareitselfisthesameproduction-r eadyandbattle-testedanalytic
databasethathasbeensupportedbyClouderasinceImpala1.0in2013.
WhydoestheImpalaversionstringinCDH5.10sayImpala2.7,whilethedocsrefertoImpala2.8?
TheversionofImpalathatisincludedinCDH5.10isImpala2.7plusalmostallthepatchesthatwentintoImpala2.8.
CDH5.10wasreleasedveryshortlyafterApacheImpala2.8,andtheversionstringwasnotupdatedintheCDH
packaging.ToaccuratelyrelatetheCDH5.10featuresettothecorresponding levelofApacheImpala,thedocumen tation
referstoImpala2.8astheminimum ImpalaversionnumberforfeaturessuchastheMT_DOPqueryoptionandfull
integrationofImpalaSQLsyntaxwithApacheKudu.
ThefulllistofrelevantcommitsfortheImpalaincludedwithCDH5.10.0,andtheupstreamApacheImpalaproject,
are:
â¢CDH5.10:https://github.com/cloudera/Impala/ commits/cdh5-2.7.0_5.10.0
â¢ApacheImpala2.8:https://github.com/apache/incuba tor-impala/ commits/br anch-2.8.0
â¢
BecausetheClouderapolicyistokeepversionnumbering consistentacrossCDHmaintenancereleases,theImpala
versionstringintheCDHpackagingremainsat2.7forCDH5.10.1andanyfuture5.10maintenancereleases.
TryingImpala
HowdoItryImpalaout?
Tolookatthecorefeaturesandfunctionality onImpala,theeasiestwaytotryoutImpalaistodownloadtheCloudera
QuickStartVMandstarttheImpalaservicethroughClouderaManager,thenuseimpala-shell inaterminalwindow
ortheImpalaQueryUIintheHuewebinterface.
Todoperformance testingandtryoutthemanagementfeaturesforImpalaonacluster,youneedtomovebeyond
theQuickStartVMwithitsvirtualizedsingle-node environment.Ideally,downloadtheClouderaManagersoftwareto
setupthecluster,theninstalltheImpalasoftwarethroughClouderaManager.
DoesClouderaofferaVMfordemonstratingImpala?
ClouderaoffersademonstrationVMcalledtheQuickStartVM,availableinVMWare,VirtualBo x,andKVMformats.
Formoreinformation,seetheClouderaQuickStartVM.AfterbootingtheQuickStartVM,manyservicesareturned
offbydefault;intheClouderaManagerUIthatappearsautomatically,turnonImpalaandanyothercomponen tsthat
youwanttotryout.
ApacheImpalaGuide|761ImpalaFrequentlyAskedQuestions
WherecanIfindImpaladocumen tation?
ThecoreImpaladeveloperandadministratorinformationremainsintheassociatedImpaladocumen tationportion.
InformationaboutImpalareleasenotes,installation,configuration,startup,andsecurityisembedded inthe
corresponding CDHguides.
â¢ImpalaUpgradeConsiderationsonpage38
â¢ConfiguringImpala
â¢SecurityforImpala
â¢CDHVersionandPackagingInformation
WherecanIgetmoreinformationaboutImpala?
Moreproductinformationisavailablehere:
â¢O'Reillyintroductorye-book:ClouderaImpala:BringingtheSQLandHadoopWorldsTogether
â¢O'Reillygettingstartedguidefordevelopers:GettingStartedwithImpala:InteractiveSQLforApacheHadoop
â¢Blog:ClouderaImpala:Real-TimeQueriesinApacheHadoop,ForReal
â¢Webinar:Introduction toImpala
â¢Productwebsitepage:ClouderaEnterpriseRTQ
Toseethelatestreleaseannouncemen tsforImpala,seetheClouderaAnnouncemen tsforum.
HowcanIaskquestionsandprovidefeedbackaboutImpala?
â¢JointheImpaladiscussion forumandtheImpalamailinglisttoaskquestionsandprovidefeedback.
â¢UsetheImpalaJiraprojecttologbugreportsandrequestsforfeatures.
WherecanIgetsampledatatotry?
YoucangetscriptsthatproducedatafilesandsetupanenvironmentforTPC-DSstylebenchmark testsfromthisGithub
repository.Inadditiontobeingusefulforexperimen tingwithperformance, thetablesaresuitedtoexperimen ting
withmanyaspectsofSQLonImpala:theycontainagoodmixtureofdatatypes,datadistributions, partitioning ,and
relationaldatasuitableforjoinqueries.
ImpalaSystemRequirements
WhatarethesoftwareandhardwarerequirementsforrunningImpala?
ForinformationonImpalarequirements,seeImpalaRequirementsonpage23.Notethatthereisoftenaminimum
requiredlevelofClouderaManagerforanygivenImpalaversion.
Howmuchmemoryisrequired?
Although Impalaisnotanin-memor ydatabase,whendealingwithlargetablesandlargeresultsets,youshouldexpect
todedicateasubstantialportionofphysicalmemoryfortheimpalad daemon. Recommended physicalmemoryfor
anImpalanodeis128GBorhigher.Ifpractical,devoteapproximately80%ofphysicalmemorytoImpala.
TheamountofmemoryrequiredforanImpalaoperationdependsonseveralfactors:
â¢Thefileformatofthetable.Differentfileformatsrepresentthesamedatainmoreorfewerdatafiles.The
compressionandencodingforeachfileformatmightrequireadifferentamountoftemporarymemoryto
decompressthedataforanalysis.
â¢WhethertheoperationisaSELECToranINSERT.Forexample,Parquettablesrequirerelativelylittlememory
toquery,becauseImpalareadsanddecompressesdatain8MBchunks.Inserting intoaParquettableisamore
memory-intensiveoperationbecausethedataforeachdatafile(potentiallyhundredsofmegabytes,depending
onthevalueofthePARQUET_FILE_SIZE queryoption)isstoredinmemoryuntilencoded,compressed,and
writtentodisk.
762|ApacheImpalaGuideImpalaFrequentlyAskedQuestions
â¢Whetherthetableispartitioned ornot,andwhetheraqueryagainstapartitioned tablecantakeadvantageof
partition pruning.
â¢WhetherthefinalresultsetissortedbytheORDER BY clause.EachImpalanodescansandfiltersaportionofthe
totaldata,andappliestheLIMITtoitsownportionoftheresultset.InCDH5.1/Impala1.4andhigher,ifthe
sortoperationrequiresmorememorythanisavailableonanyparticular host,Impalausesatemporarydiskwork
areatoperformthesort.Theintermediateresultsetsareallsentbacktothecoordinatornode,whichdoesthe
finalsortingandthenappliestheLIMITclausetothefinalresultset.
Forexample,ifyouexecutethequery:
select * from giant_table order by some_column limit 1000;
andyourclusterhas50nodes,theneachofthose50nodeswilltransmitamaximumof1000rowsbacktothe
coordinatornode.Thecoordinatornodeneedsenoughmemorytosort(LIMIT*cluster_size)rows,although in
theendthefinalresultsetisatmostLIMITrows,1000inthiscase.
Likewise,ifyouexecutethequery:
select * from giant_table where test_val > 100 order by some_column;
theneachnodefiltersoutasetofrowsmatchingtheWHEREconditions, sortstheresults(withnosizelimit),and
sendsthesortedintermediaterowsbacktothecoordinatornode.Thecoordinatornodemightneedsubstantial
memorytosortthefinalresultset,andsomightuseatemporarydiskworkareaforthatfinalphaseofthequery.
â¢Whetherthequerycontainsanyjoinclauses,GROUP BY clauses,analyticfunctions, orDISTINCT operators.These
operationsallrequiresomein-memor yworkareasthatvarydepending onthevolumeanddistribution ofdata.
InImpala2.0andlater,thesekindsofoperationsutilizetemporarydiskworkareasifmemoryusagegrowstoo
largetohandle.SeeSQLOperationsthatSpilltoDiskonpage607fordetails.
â¢Thesizeoftheresultset.Whenintermediateresultsarebeingpassedaroundbetweennodes,theamountofdata
dependsonthenumberofcolumnsreturnedbythequery.Forexample,itismorememory-efficienttoquery
onlythecolumnsthatareactuallyneededintheresultsetratherthanalwaysissuingSELECT * .
â¢Themechanism bywhichworkisdividedforajoinquery.YouusetheCOMPUTE STATS statement,andquery
hintsinthemostdifficultcases,tohelpImpalapickthemostefficientexecutionplan.SeePerformance
ConsiderationsforJoinQueriesonpage568fordetails.
SeeHardwareRequirementsonpage24formoredetailsandrecommenda tionsaboutImpalahardwareprerequisites.
WhatprocessortypeandspeeddoesClouderarecommend?
ImpalamakesuseofSSE4.1instructions.
WhatEC2instancesarerecommended forImpala?
ForlargestoragecapacityandlargeI/Obandwidth, considerthehs1.8xlarge andcc2.8xlarge instancetypes.
ImpalaI/OpatternstypicallydonotbenefitenoughfromSSDstoragetomakeupfortheloweroverallsize.For
performance andsecurityconsiderationsfordeployingCDHanditscomponen tsonAWS,seeClouderaEnterprise
ReferenceArchitectureforAWSDeployments.
SupportedandUnsupport edFunctionality InImpala
WhatarethemainfeaturesofImpala?
â¢AlargesetofSQLstatements,including SELECTandINSERT,withjoins,Subqueries inImpalaSELECTStatements
onpage312,andImpalaAnalyticFunctions onpage506.HighlycompatiblewithHiveQL,andalsoincluding some
vendorextensions.Formoreinformation,seeImpalaSQLLanguageReferenceonpage101.
ApacheImpalaGuide|763ImpalaFrequentlyAskedQuestions
â¢Distributed,high-performance queries.SeeTuningImpalaforPerformance onpage565forinformationabout
Impalaperformance optimizationsandtuningtechniques forqueries.
â¢UsingClouderaManager,youcandeployandmanageyourImpalaservices.ClouderaManageristhebestwayto
getstartedwithImpalaonyourcluster.
â¢UsingHueforqueries.
â¢Appending andinserting dataintotablesthroughtheINSERTstatement.SeeHowImpalaWorkswithHadoopFile
Formatsonpage634forthedetailsaboutwhichoperationsaresupportedforwhichfileformats.
â¢ODBC:ImpalaiscertifiedtorunagainstMicroStrategyandTableau,withrestrictions. Formoreinformation,see
ConfiguringImpalatoWorkwithODBConpage723.
â¢QueryingdatastoredinHDFSandHBaseinasinglequery.SeeUsingImpalatoQueryHBaseTablesonpage684
fordetails.
â¢InImpala2.2.0andhigher,queryingdatastoredintheAmazonSimpleStorageService(S3).SeeUsingImpalawith
theAmazonS3Filesystemonpage692fordetails.
â¢Concurrentclientrequests.EachImpaladaemoncanhandlemultipleconcurrentclientrequests.Theeffectson
performance dependonyourparticular hardwareandworkload.
â¢Kerberosauthentication.Formoreinformation,seeImpalaSecurityonpage82.
â¢Partitions. WithImpalaSQL,youcancreatepartitioned tableswiththeCREATE TABLE statement,andaddand
droppartitions withtheALTER TABLE statement.Impalaalsotakesadvantageofthepartitioning presentinHive
tables.SeePartitioning forImpalaTablesonpage625fordetails.
WhatfeaturesfromrelationaldatabasesorHivearenotavailableinImpala?
â¢Queryingstreamingdata.
â¢Deletingindividual rows.Youdeletedatainbulkbyoverwritinganentiretableorpartition, orbydroppingatable.
â¢Indexing(notcurrently).LZO-compressedtextfilescanbeindexedoutsideofImpala,asdescribed inUsing
LZO-CompressedTextFilesonpage640.
â¢Fulltextsearchontextfields.TheClouderaSearchproductisappropriateforthisusecase.
â¢CustomHiveSerializer/Deserializ erclasses(SerDes). Impalasupports asetofcommonnativefileformatsthat
havebuilt-inSerDesinCDH.SeeHowImpalaWorkswithHadoopFileFormatsonpage634fordetails.
â¢Checkpoin tingwithinaquery.Thatis,Impaladoesnotsaveintermediateresultstodiskduringlong-running
queries.Currently,Impalacancelsarunningqueryifanyhostonwhichthatqueryisexecutingfails.Whenoneor
morehostsaredown,Impalareroutesfuturequeriestoonlyusetheavailablehosts,andImpaladetectswhen
thehostscomebackupandbeginsusingthemagain.BecauseaquerycanbesubmittedthroughanyImpalanode,
thereisnosinglepointoffailure.Inthefuture,wewillconsideraddingadditional workallocationfeaturesto
Impala,sothatarunningquerywouldcompleteeveninthepresenceofhostfailures.
â¢Hiveindexes.
â¢Non-Hadoop datastores,suchasrelationaldatabases.
ForthedetailedlistoffeaturesthataredifferentbetweenImpalaandHiveQL,seeSQLDifferencesBetweenImpala
andHiveonpage541.
DoesImpalasupportgenericJDBC?
Impalasupports theHiveServer2JDBCdriver.
IsAvrosupported?
Yes,Avroissupported.ImpalahasalwaysbeenabletoqueryAvrotables.YoucanusetheImpalaLOAD DATA statement
toloadexistingAvrodatafilesintoatable.StartingwithCDH5.1/Impala1.4,youcancreateAvrotableswithImpala.
Currently,youstillusetheINSERTstatementinHivetocopydatafromanothertableintoanAvrotable.SeeUsing
theAvroFileFormatwithImpalaTablesonpage659fordetails.
764|ApacheImpalaGuideImpalaFrequentlyAskedQuestions
HowdoI?
HowdoIpreventusersfromseeingthetextofSQLqueries?
Forinstructions onmakingtheImpalalogfilesunreadablebyunprivileg edusers,seeSecuringImpalaDataandLog
Filesonpage83.
Forinstructions onpassword-protectingthewebinterfacetotheImpalalogfilesandotherinternalserverinformation,
seeSecuringtheImpalaWebUserInterfaceonpage84.
InCDH5.4/Impala2.2andhigher,youcanusethelogredaction featuretoobfuscatesensitiveinformationinImpala
logfiles.Seehttp://www.cloudera.com/documen tation/enterprise/la test/topics/sg_redaction.h tmlfordetails.
HowdoIknowhowmanyImpalanodesareinmycluster?
TheImpalastatestorekeepstrackofhowmanyimpalad nodesarecurrentlyavailable.Youcanseethisinformation
throughthestatestorewebinterface.Forexample,attheURLhttp://statestore_host :25010/metrics you
mightseelineslikethefollowing:
statestore.live-backends:3
statestore.live-backends.list:[ host1:22000, host1:26000, host2:22000]
Thenumberofimpalad nodesisthenumberoflistitemsreferringtoport22000,inthiscasetwo.(Typically,this
numberisonelessthanthenumberreportedbythestatestore.live-backends line.)Ifanimpalad nodebecame
unavailableorcamebackafteranoutage,theinformationreportedonthispagewouldchangeappropriately.
ImpalaPerformance
Areresultsreturnedastheybecomeavailable,orallatoncewhenaquerycompletes?
Impalastreamsresultswhenevertheyareavailable,whenpossible. CertainSQLoperations(aggregationorORDER
BY)requirealloftheinputtobereadybeforeImpalacanreturnresults.
Whydoesmyqueryrunslowly?
Therearemanypossiblereasonswhyagivenquerycouldbeslow.Usethefollowingchecklisttodiagnose performance
issueswithexistingqueries,andtoavoidsuchissueswhenwritingnewqueries,settingupnewnodes,creatingnew
tables,orloadingdata.
â¢Immediatelyafterthequeryfinishes,issueaSUMMARY command inimpala-shell .Youcancheckwhichphases
ofexecutiontookthelongest,andcompareestimatedvaluesformemoryusageandnumberofrowswiththe
actualvalues.
â¢Immediatelyafterthequeryfinishes,issueaPROFILE commandinimpala-shell .ThenumbersintheBytesRead ,
BytesReadLocal ,andBytesReadShortCircuit shouldbeidenticalforaspecificnode.Forexample:
- BytesRead: 180.33 MB
- BytesReadLocal: 180.33 MB
- BytesReadShortCircuit: 180.33 MB
IfBytesReadLocal islowerthanBytesRead ,somethinginyourclusterismisconfigured,suchastheimpalad
daemonnotrunningonallthedatanodes.IfBytesReadShortCircuit islowerthanBytesRead ,short-circuit
readsarenotenabledproperlyonthatnode;seePost-InstallationConfigurationforImpalaonpage36for
instructions.
â¢Ifthetablewasjustcreated,orthisisthefirstquerythataccessed thetableafteranINVALIDATE METADATA
statementoraftertheimpalad daemonwasrestarted,theremightbeaone-time delaywhilethemetadatafor
thetableisloadedandcached.Checkwhethertheslowdowndisappear swhenthequeryisrunagain.Whendoing
ApacheImpalaGuide|765ImpalaFrequentlyAskedQuestions
performance comparisons, considerissuingaDESCRIBE table_name statementforeachtablefirst,tomake
sureanytimingsonlymeasuretheactualquerytimeandnottheone-time waittoloadthetablemetadata.
â¢Isthetabledatainuncompressedtextformat?CheckbyissuingaDESCRIBE FORMATTED table_name statement.
Atexttableisindicatedbytheline:
InputFormat: org.apache.hadoop.mapred.TextInputFormat
Although uncompressedtextisthedefaultformatforaCREATE TABLE statementwithnoSTORED AS clauses,
itisalsothebulkiestformatfordiskstorageandconsequen tlyusuallytheslowestformatforqueries.Fordata
wherequeryperformance iscrucial,particularly fortablesthatarefrequentlyqueried,considerstartingwithor
convertingtoacompactbinaryfileformatsuchasParquet,Avro,RCFile,orSequenceFile. Fordetails,seeHow
ImpalaWorkswithHadoopFileFormatsonpage634.
â¢Ifyourtablehasmanycolumns,butthequeryreferstoonlyafewcolumns,considerusingtheParquetfileformat.
Itsdatafilesareorganizedwithacolumn-orien tedlayoutthatletsqueriesminimizetheamountofI/Oneeded
toretrieve,filter,andaggregatethevaluesforspecificcolumns.SeeUsingtheParquetFileFormatwithImpala
Tablesonpage643fordetails.
â¢Ifyourqueryinvolvesanyjoins,arethetablesinthequeryorderedsothatthetablesorsubqueries areordered
withtheonereturningthelargestnumberofrowsontheleft,followedbythesmallest(mostselective),thesecond
smallest,andsoon?ThatorderingallowsImpalatooptimizethewayworkisdistributedamongthenodesand
howintermediateresultsareroutedfromonenodetoanother.Forexample,allotherthingsbeingequal,the
followingjoinorderresultsinanefficientquery:
select some_col from
    huge_table join big_table join small_table join medium_table
  where
    huge_table.id = big_table.id
    and big_table.id = medium_table.id
    and medium_table.id = small_table.id;
SeePerformance ConsiderationsforJoinQueriesonpage568forperformance tipsforjoinqueries.
â¢Alsoforjoinqueries,doyouhavetablestatisticsforthetable,andcolumnstatisticsforthecolumnsusedinthe
joinclauses?ColumnstatisticsletImpalabetterchoosehowtodistributetheworkforthevariouspiecesofajoin
query.SeeTableandColumnStatisticsonpage575fordetailsaboutgatheringstatistics.
â¢Doesyourtableconsistofmanysmalldatafiles?Impalaworksmostefficientlywithdatafilesinthemulti-meg abyte
range;Parquet,aformatoptimizedfordatawarehouse-stylequeries,useslargefiles(originally 1GB,now256
MBinImpala2.0andhigher)withablocksizematchingthefilesize.UsetheDESCRIBE FORMATTED table_name
statementinimpala-shell toseewherethedataforatableislocated,andusethehadoop fs -ls orhdfs
dfs -ls Unixcommands toseethefilesandtheirsizes.Ifyouhavethousands ofsmalldatafiles,thatisasignal
thatyoushouldconsolidateintoasmallernumberoflargefiles.UseanINSERT ... SELECT statementtocopy
thedatatoanewtable,reorganizingintonewdatafilesaspartoftheprocess.Prefertoconstructlargedatafiles
andimporttheminbulkthroughtheLOAD DATA orCREATE EXTERNAL TABLE statements,ratherthanissuing
manyINSERT ... VALUES statements;eachINSERT ... VALUES statementcreatesaseparatetinydatafile.
Ifyouhavethousands offilesallinthesamedirectory,buteachoneismegabytesinsize,considerusingapartitioned
tablesothateachpartition containsasmallernumberoffiles.Seethefollowingpointformoreonpartitioning.
â¢Ifyourdataiseasytogroupaccordingtotimeorgeographicregion,haveyoupartitioned yourtablebasedonthe
corresponding columnssuchasYEAR,MONTH,and/orDAY?Partitioning atablebasedoncertaincolumnsallows
queriesthatfilterbasedonthosesamecolumnstoavoidreadingthedatafilesforirrelevantyears,postalcodes,
andsoon.(Donotpartition downtotoofinealevel;trytostructurethepartitions sothatthereisstillsufficient
dataineachonetotakeadvantageofthemulti-meg abyteHDFSblocksize.)SeePartitioning forImpalaTableson
page625fordetails.
WhydoesmySELECTstatementfail?
WhenaSELECTstatementfails,thecauseusuallyfallsintooneofthefollowingcategories:
â¢Atimeoutbecauseofaperformance, capacity,ornetworkissueaffectingoneparticular node.
â¢Excessivememoryuseforajoinquery,resultinginautomaticcancellationofthequery.
766|ApacheImpalaGuideImpalaFrequentlyAskedQuestions
â¢Alow-levelissueaffectinghownativecodeisgeneratedoneachnodetohandleparticular WHEREclausesinthe
query.Forexample,amachineinstructioncouldbegeneratedthatisnotsupportedbytheprocessorofacertain
node.Iftheerrormessageinthelogsuggeststhecausewasanillegalinstruction,considerturningoffnativecode
generationtemporarily,andtryingthequeryagain.
â¢Malformedinputdata,suchasatextdatafilewithanenormously longline,orwithadelimiterthatdoesnot
matchthecharacterspecified intheFIELDS TERMINATED BY clauseoftheCREATE TABLE statement.
WhydoesmyINSERTstatementfail?
WhenanINSERTstatementfails,itisusuallytheresultofexceedingsomelimitwithinaHadoopcomponen t,typically
HDFS.
â¢AnINSERTintoapartitioned tablecanbeastrenuousoperationduetothepossibility ofopeningmanyfilesand
associatedthreadssimultaneously inHDFS.Impala1.1.1includessomeimprovementstodistributetheworkmore
efficiently,sothatthevaluesforeachpartition arewrittenbyasinglenode,ratherthanasaseparatedatafile
fromeachnode.
â¢CertainexpressionsintheSELECTpartoftheINSERTstatementcancomplicatetheexecutionplanningandresult
inaninefficientINSERToperation.Trytomakethecolumndatatypesofthesourceanddestinationtablesmatch
up,forexamplebydoingALTER TABLE ... REPLACE COLUMNS onthesourcetableifnecessary.Trytoavoid
CASEexpressionsintheSELECTportion,becausetheymaketheresultvalueshardertopredictthantransferring
acolumnunchangedorpassingthecolumnthroughabuilt-infunction.
â¢BepreparedtoraisesomelimitsintheHDFSconfigurationsettings,eithertemporarilyduringtheINSERTor
permanen tlyifyoufrequentlyrunsuchINSERTstatementsaspartofyourETLpipeline.
â¢TheresourceusageofanINSERTstatementcanvarydepending onthefileformatofthedestinationtable.
Inserting intoaParquettableismemory-intensive,becausethedataforeachpartition isbufferedinmemory
untilitreaches1gigabyte,atwhichpointthedatafileiswrittentodisk.Impalacandistributetheworkforan
INSERTmoreefficientlywhenstatisticsareavailableforthesourcetablethatisqueriedduringtheINSERT
statement.SeeTableandColumnStatisticsonpage575fordetailsaboutgatheringstatistics.
DoesImpalaperformance improveasitisdeployedtomorehostsinaclusterinmuchthesamewaythatHadoop
performance does?
Yes.Impalascaleswiththenumberofhosts.ItisimportanttoinstallImpalaonalltheDataNodesinthecluster,because
otherwisesomeofthenodesmustdoremotereadstoretrievedatanotavailableforlocalreads.Datalocalityisan
importantarchitecturalaspectforImpalaperformance. SeethisImpalaperformance blogpostforbackground.Note
thatthisblogpostreferstobenchmark swithImpala1.1.1;Impalahasaddedevenmoreperformance featuresinthe
1.2.xseries.
IstheHDFSblocksizereducedtoachievefasterqueryresults?
No.ImpaladoesnotmakeanychangestotheHDFSorHBasedatasets.
ThedefaultParquetblocksizeisrelativelylarge(256MBinImpala2.0andlater;1GBinearlierreleases).Youcan
controltheblocksizewhencreatingParquetfilesusingthePARQUET_FILE_SIZE queryoption.
DoesImpalausecaching?
Impaladoesnotcachetabledata.Itdoescachesometableandfilemetadata.Although queriesmightrunfasteron
subsequentiterationsbecausethedatasetwascachedintheOSbuffercache,Impaladoesnotexplicitlycontrolthis.
ImpalatakesadvantageoftheHDFScachingfeatureinCDH.Youcandesignatewhichtablesorpartitions arecached
throughtheCACHEDandUNCACHED clausesoftheCREATE TABLE andALTER TABLE statements.Impalacanalso
takeadvantageofdatathatispinnedintheHDFScachethroughthehdfscacheadmin command. SeeUsingHDFS
CachingwithImpala(CDH5.3orhigheronly)onpage593fordetails.
ApacheImpalaGuide|767ImpalaFrequentlyAskedQuestions
ImpalaUseCases
WhataregoodusecasesforImpalaasopposedtoHiveorMapReduce?
Impalaiswell-suitedtoexecutingSQLqueriesforinteractiveexploratoryanalyticsonlargedatasets.Hiveand
MapReduceareappropriateforverylongrunning,batch-orientedtaskssuchasETL.
IsMapReducerequiredforImpala?WillImpalacontinuetoworkasexpectedifMapReduceisstopped?
ImpaladoesnotuseMapReduceatall.
CanImpalabeusedforcomplexeventprocessing?
Forexample,inanindustrialenvironment,manyagentsmaygeneratelargeamountsofdata.CanImpalabeusedto
analyzethisdata,checking fornotablechangesintheenvironment?
ComplexEventProcessing(CEP)isusuallyperformedbydedicatedstream-processingsystems.Impalaisnota
stream-processingsystem,asitmostcloselyresembles arelationaldatabase.
IsImpalaintendedtohandlerealtimequeriesinlow-latencyapplicationsorisitforadhocqueriesforthepurposeof
dataexploration?
Ad-hocqueriesaretheprimaryusecaseforImpala.Weanticipateitbeingusedinmanyothersituationswhere
low-latencyisrequired.WhetherImpalaisappropriateforanyparticular use-casedependsontheworkload,datasize
andqueryvolume.SeeImpalaBenefitsonpage16fortheprimarybenefitsyoucanexpectwhenusingImpala.
QuestionsaboutImpalaAndHive
HowdoesImpalacomparetoHiveandPig?
ImpalaisdifferentfromHiveandPigbecauseitusesitsowndaemons thatarespreadacrosstheclusterforqueries.
BecauseImpaladoesnotrelyonMapReduce,itavoidsthestartupoverheadofMapReducejobs,allowingImpalato
returnresultsinrealtime.
CanIdotransformsoraddnewfunctionality?
ImpalaaddssupportforUDFsinImpala1.2.Youcanwriteyourownfunctions inC++,orreuseexistingJava-basedHive
UDFs.TheUDFsupportincludesscalarfunctions anduser-definedaggregatefunctions (UDAs).User-definedtable
functions (UDTFs)arenotcurrentlysupported.
Impaladoesnotcurrentlysupportanextensibleserialization-deserializ ationframework(SerDes), andsoaddingextra
functionality toImpalaisnotasstraightforwardasforHiveorPig.
CananyImpalaqueryalsobeexecutedinHive?
Yes.Therearesomeminordifferencesinhowsomequeriesarehandled, butImpalaqueriescanalsobecompleted
inHive.ImpalaSQLisasubsetofHiveQL,withsomefunctional limitationssuchastransforms.FordetailsoftheImpala
SQLdialect,seeImpalaSQLStatementsonpage202.FortheImpalabuilt-infunctions, seeImpalaBuilt-InFunctions on
page391.ForthedetailedlistofdifferencesbetweenImpalaandHiveQL,seeSQLDifferencesBetweenImpalaand
Hiveonpage541.
CanIuseImpalatoquerydataalreadyloadedintoHiveandHBase?
Therearenoadditional stepstoallowImpalatoquerytablesmanagedbyHive,whethertheyarestoredinHDFSor
HBase.MakesurethatImpalaisconfiguredtoaccesstheHivemetastorecorrectlyandyoushouldbereadytogo.
Keepinmindthatimpalad ,bydefault,runsastheimpalauser,soyoumightneedtoadjustsomefilepermissions
depending onhowstrictyourpermissions arecurrently.
768|ApacheImpalaGuideImpalaFrequentlyAskedQuestions
SeeUsingImpalatoQueryHBaseTablesonpage684fordetailsaboutqueryingdatainHBase.
IsHiveanImpalarequirement?
TheHivemetastoreserviceisarequirement.ImpalasharesthesamemetastoredatabaseasHive,allowingImpalaand
Hivetoaccessthesametablestransparently.
Hiveitselfisoptional,anddoesnotneedtobeinstalledonthesamenodesasImpala.Currently,Impalasupports a
widervarietyofread(query)operationsthanwrite(insert)operations;youuseHivetoinsertdataintotablesthatuse
certainfileformats.SeeHowImpalaWorkswithHadoopFileFormatsonpage634fordetails.
ImpalaAvailability
IsImpalaproduction ready?
Impalahasfinisheditsbetareleasecycle,andthe1.0,1.1,and1.2GAreleasesareproduction ready.The1.1.xseries
includesadditional securityfeaturesforauthorization,animportantrequirementforproduction useinmany
organizations.The1.2.xseriesincludesimportantperformance features,particularly forlargejoinqueries.Some
ClouderacustomersarealreadyusingImpalaforlargeworkloads.
TheImpala1.3.0andhigherreleasesarebundledwithcorresponding levelsofCDH.Thenumberofnewfeaturesgrows
witheachrelease.SeeNewFeaturesinCDH6.0.0forafulllist.
HowdoIconfigureHadoophighavailability(HA)forImpala?
YoucansetupaproxyservertorelayrequestsbackandforthtotheImpalaservers,forloadbalancing andhigh
availability.SeeUsingImpalathroughaProxyforHighAvailabilityonpage72fordetails.
YoucanenableHDFSHAfortheHivemetastore.SeetheCDH5HighAvailabilityGuidefordetails.
WhathappensifthereisanerrorinImpala?
ThereisnotasinglepointoffailureinImpala.AllImpaladaemons arefullyabletohandleincomingqueries.Ifamachine
failshowever,allquerieswithfragmentsrunningonthatmachinewillfail.Becausequeriesareexpectedtoreturn
quickly,youcanjustrerunthequeryifthereisafailure.SeeImpalaConceptsandArchitectureonpage18fordetails
abouttheImpalaarchitecture.
Thelongeranswer:ImpalamustbeabletoconnecttotheHivemetastore.Impalaaggressivelycachesmetadataso
themetastorehostshouldhaveminimalload.ImpalareliesontheHDFSNameNode, andyoucanconfigureHAfor
HDFS.Impalaalsohascentralizedservices,knownasthestatestoreandcatalogservices,thatrunononehostonly.
Impalacontinuestoexecutequeriesifthestatestorehostisdown,butitwillnotgetstateupdates.Forexample,ifa
hostisaddedtotheclusterwhilethestatestorehostisdown,theexistinginstancesofimpalad runningontheother
hostswillnotfindoutaboutthisnewhost.Oncethestatestoreprocessisrestarted,alltheinformationitservesis
automaticallyreconstructedfromallrunningImpaladaemons.
Whatisthemaximumnumberofrowsinatable?
Thereisnodefinedmaximum.SomecustomershaveusedImpalatoqueryatablewithoveratrillionrows.
CanImpalaandMapReducejobsrunonthesameclusterwithoutresourcecontention?
Yes.SeeControllingImpalaResourceUsageonpage588forhowtocontrolImpalaresourceusageusingtheLinux
cgroupmechanism, andResourceManagementonpage549forhowtouseImpalawiththeYARNresourcemanagement
framework.Impalaisdesigned torunontheDataNodehosts.Anycontentiondependsmostlyontheclustersetup
andworkload.
ForadetailedinformationaboutconfiguringaclustertoshareresourcesbetweenImpalaqueriesandMapReduce
jobs,seehttps://www.cloudera.com/documen tation/enterprise/la test/topics/admin_ho wto_multitenancy.htmland
ConfiguringResourcePoolsandAdmission Controlonpage554.
ApacheImpalaGuide|769ImpalaFrequentlyAskedQuestions
ImpalaInternals
OnwhichhostsdoesImpalarun?
Clouderastronglyrecommends runningtheimpalad daemononeachDataNodeforgoodperformance. Although this
topologyisnotahardrequirement,iftherearedatablockswithnoImpaladaemons runningonanyofthehosts
containingreplicasofthoseblocks,queriesinvolvingthatdatacouldbeveryinefficient.Inthatcase,thedatamustbe
transmittedfromonehosttoanotherforprocessingbyâremotereadsâ,aconditionImpalanormally triestoavoid.
SeeImpalaConceptsandArchitectureonpage18fordetailsabouttheImpalaarchitecture.Impalaschedules query
fragmentsonallhostsholdingdatarelevanttothequery,ifpossible.
IncaseswheresomehostsintheclusterhavemuchgreaterCPUandmemorycapacitythanothers,orwheresome
hostshaveextraCPUcapacitybecausesomeCPU-intensivephasesaresingle-thr eaded,someusershaverunmultiple
impalad daemons onasinglehosttotakeadvantageoftheextraCPUcapacity.Thisconfigurationisonlypractical
forspecificworkloadsthatrelyheavilyonaggregation,andthephysicalhostsmusthavesufficientmemoryto
accommodatetherequirementsformultipleimpalad instances.
HowarejoinsperformedinImpala?
Bydefault,Impalaautomaticallydeterminesthemostefficientorderinwhichtojointablesusingacost-basedmethod,
basedontheiroverallsizeandnumberofrows.(ThisisanewfeatureinImpala1.2.2andhigher.)TheCOMPUTE STATS
statementgathersinformationabouteachtablethatiscrucialforefficientjoinperformance. Impalachoosesbetween
twotechniques forjoinqueries,knownasâbroadcastjoinsâandâpartitioned joinsâ.SeeJoinsinImpalaSELECT
Statementsonpage296forsyntaxdetailsandPerformanceConsiderationsforJoinQueriesonpage568forperformance
considerations.
HowdoesImpalaprocessjoinqueriesforlargetables?
Impalautilizesmultiplestrategiestoallowjoinsbetweentablesandresultsetsofvarioussizes.Whenjoiningalarge
tablewithasmallone,thedatafromthesmalltableistransmittedtoeachnodeforintermediateprocessing. When
joiningtwolargetables,thedatafromoneofthetablesisdividedintopieces,andeachnodeprocessesonlyselected
pieces.SeeJoinsinImpalaSELECTStatementsonpage296fordetailsaboutjoinprocessing,PerformanceConsiderations
forJoinQueriesonpage568forperformance considerations,andOptimizerHintsinImpalaonpage387forhowto
fine-tune thejoinstrategy.
WhatisImpala'saggregationstrategy?
Impalacurrentlyonlysupports in-memor yhashaggregation.InImpala2.0andhigher,ifthememoryrequirements
forajoinoraggregationoperationexceedthememorylimitforaparticular host,Impalausesatemporaryworkarea
ondisktohelpthequerycompletesuccessfully.
HowisImpalametadatamanaged?
Impalausestwopiecesofmetadata:thecataloginformationfromtheHivemetastoreandthefilemetadatafromthe
NameNode. Currently,thismetadataislazilypopulatedandcachedwhenanimpalad needsittoplanaquery.
TheREFRESHstatementupdatesthemetadataforaparticular tableafterloadingnewdatathroughHive.TheINVALIDATE
METADATAStatementonpage286statementrefreshesallmetadata,sothatImpalarecognizesnewtablesorother
DDLandDMLchangesperformedthroughHive.
InImpala1.2andhigher,adedicatedcatalogd daemonbroadcastsmetadatachangesduetoImpalaDDLorDML
statementstoallnodes,reducingoreliminatingtheneedtousetheREFRESH andINVALIDATE METADATA statements.
WhatloaddoconcurrentqueriesproduceontheNameNode?
TheloadImpalageneratesisverysimilartoMapReduce.ImpalacontactstheNameNode duringtheplanningphase
togetthefilemetadata(thisisonlyrunonthehostthequerywassentto).Everyimpalad willreadfilesaspartof
normalprocessingofthequery.
770|ApacheImpalaGuideImpalaFrequentlyAskedQuestions
HowdoesImpalaachieveitsperformance improvements?
Thesearethemainfactorsintheperformance ofImpalaversusthatofotherHadoopcomponen tsandrelated
technologies.
ImpalaavoidsMapReduce.WhileMapReduceisagreatgeneralparallelprocessingmodelwithmanybenefits,itisnot
designed toexecuteSQL.Impalaavoidstheinefficiencies ofMapReduceintheseways:
â¢Impaladoesnotmaterializeintermediateresultstodisk.SQLqueriesoftenmaptomultipleMapReducejobswith
allintermediatedatasetswrittentodisk.
â¢ImpalaavoidsMapReducestart-uptime.Forinteractivequeries,theMapReducestart-uptimebecomesvery
noticeable. Impalarunsasaserviceandessentiallyhasnostart-uptime.
â¢Impalacanmorenaturallydispersequeryplansinsteadofhavingtofitthemintoapipelineofmapandreduce
jobs.ThisenablesImpalatoparallelizemultiplestagesofaqueryandavoidoverheadssuchassortandshuffle
whenunnecessar y.
Impalausesamoreefficientexecutionenginebytakingadvantageofmodernhardwareandtechnologies:
â¢Impalageneratesruntimecode.ImpalausesLLVMtogenerateassembly codeforthequerythatisbeingrun.
Individual queriesdonothavetopaytheoverheadofrunningonasystemthatneedstobeabletoexecute
arbitraryqueries.
â¢Impalausesavailablehardwareinstructions whenpossible.Impalausesthesupplemen talSSE3(SSSE3)instructions
whichcanoffertremendous speedupsinsomecases.(Impala2.0and2.1requiredtheSSE4.1instructionset;
Impala2.2andhigherrelaxtherestrictionagainsoonlySSSE3isrequired.)
â¢ImpalausesbetterI/Oscheduling. Impalaisawareofthedisklocationofblocksandisabletoschedule theorder
toprocessblockstokeepalldisksbusy.
â¢Impalaisdesigned forperformance. Alotoftimehasbeenspentindesigning Impalawithsound
performance-orien tedfundamen tals,suchastightinnerloops,inlinedfunctioncalls,minimalbranching,better
useofcache,andminimalmemoryusage.
Whathappenswhenthedatasetexceedsavailablememory?
Currently,ifthememoryrequiredtoprocessintermediateresultsonanodeexceedstheamountavailabletoImpala
onthatnode,thequeryiscancelled. YoucanadjustthememoryavailabletoImpalaoneachnode,andyoucanfine-tune
thejoinstrategytoreducethememoryrequiredforthebiggestqueries.Wedoplanonsupporting externaljoinsand
sortinginthefuture.
Keepinmindthoughthatthememoryusageisnotdirectlybasedontheinputdatasetsize.Foraggregations,the
memoryusageisthenumberofrowsaftergrouping.Forjoins,thememoryusageisthecombined sizeofthetables
excludingthebiggesttable,andImpalacanusejoinstrategiesthatdivideuplargejoinedtablesamongthevarious
nodesratherthantransmittingtheentiretabletoeachnode.
Whatarethemostmemory-intensiveoperations?
Ifaqueryfailswithanerrorindicatingâmemorylimitexceededâ,youmightsuspectamemoryleak.Theproblemcould
actuallybeaquerythatisstructuredinawaythatcausesImpalatoallocatemorememorythanyouexpect,exceeded
thememoryallocatedforImpalaonaparticular node.Someexamplesofqueryortablestructuresthatareespecially
memory-intensiveare:
â¢INSERTstatementsusingdynamicpartitioning ,intoatablewithmanydifferentpartitions. (Particularly fortables
usingParquetformat,wherethedataforeachpartition isheldinmemoryuntilitreachesthefullblocksizein
sizebeforeitiswrittentodisk.)Consider breakingupsuchoperationsintoseveraldifferentINSERTstatements,
forexampletoloaddataoneyearatatimeratherthanforallyearsatonce.
â¢GROUP BY onauniqueorhigh-cardinalitycolumn.Impalaallocatessomehandlerstructuresforeachdifferent
valueinaGROUP BY query.HavingmillionsofdifferentGROUP BY valuescouldexceedthememorylimit.
â¢Queriesinvolvingverywidetables,withthousands ofcolumns,particularly withmanySTRINGcolumns.Because
ImpalaallowsaSTRINGvaluetobeupto32KB,theintermediateresultsduringsuchqueriescouldrequire
substantialmemoryallocation.
ApacheImpalaGuide|771ImpalaFrequentlyAskedQuestions
WhendoesImpalaholdontoorreturnmemory?
Impalaallocatesmemoryusingtcmalloc ,amemoryallocatorthatisoptimizedforhighconcurrency.OnceImpala
allocatesmemory,itkeepsthatmemoryreservedtouseforfuturequeries.Thus,itisnormalforImpalatoshowhigh
memoryusagewhenidle.IfImpaladetectsthatitisabouttoexceeditsmemorylimit(definedbythe-mem_limit
startupoptionortheMEM_LIMIT queryoption),itdeallocatesmemorynotneededbythecurrentqueries.
WhenissuingqueriesthroughtheJDBCorODBCinterfaces,makesuretocalltheappropriateclosemethodafterwards.
Otherwise,somememoryassociatedwiththequeryisnotfreed.
SQL
IsthereanUPDATEstatement?
InCDH5.10/Impala2.8andhigher,ImpalahasthestatementsUPDATE,DELETE,andUPSERT.Thesestatementsapply
toKudutablesonly.
Fornon-Kudutables,youcanusethefollowingtechniques toachievethesamegoalsasthefamiliarUPDATEstatement,
inawaythatpreservesefficientfilelayoutsforsubsequentqueries:
â¢Replacetheentirecontentsofatableorpartition withupdateddatathatyouhavealreadystagedinadifferent
location,eitherusingINSERT OVERWRITE ,LOAD DATA ,ormanualHDFSfileoperationsfollowedbyaREFRESH
statementforthetable.Optionally,youcanusebuilt-infunctions andexpressionsintheINSERTstatementto
transformthecopieddatainthesamewayyouwouldnormally doinanUPDATEstatement,forexampletoturn
amixed-casestringintoalluppercaseoralllowercase.
â¢Toupdateasinglerow,useanHBasetable,andissueanINSERT ... VALUES statementusingthesamekeyas
theoriginalrow.BecauseHBasehandlesduplicatekeysbyonlyreturningthelatestrowwithaparticular key
value,thenewlyinsertedroweffectivelyhidesthepreviousone.
CanImpaladouser-definedfunctions (UDFs)?
Impala1.2andhigherdoessupportUDFsandUDAs.YoucaneitherwritenativeImpalaUDFsandUDAsinC++,orreuse
UDFs(butnotUDAs)originally writteninJavaforusewithHive.SeeUser-DefinedFunctions (UDFs)onpage525for
details.
WhydoIhavetouseREFRESHandINVALIDATEMETADATA,whatdotheydo?
InImpala1.2andhigher,thereismuchlessneedtousetheREFRESH andINVALIDATE METADATA statements:
â¢Thenewimpala-catalog service,representedbythecatalogd daemon, broadcaststheresultsofImpalaDDL
statementstoallImpalanodes.Thus,ifyoudoaCREATE TABLE statementinImpalawhileconnectedtoone
node,youdonotneedtodoINVALIDATE METADATA beforeissuingqueriesthroughadifferentnode.
â¢ThecatalogserviceonlyrecognizeschangesmadethroughImpala,soyoumuststillissueaREFRESH statement
ifyouloaddatathroughHiveorbymanipula tingfilesinHDFS,andyoumustissueanINVALIDATE METADATA
statementifyoucreateatable,alteratable,addordroppartitions, ordootherDDLstatementsinHive.
â¢BecausethecatalogservicebroadcaststheresultsofREFRESH andINVALIDATE METADATA statementstoall
nodes,inthecaseswhereyoudostillneedtoissuethosestatements,youcandothatonasinglenoderather
thanoneverynode,andthechangeswillbeautomaticallyrecognizedacrossthecluster,makingitmoreconvenient
toloadbalancebyissuingqueriesthrougharbitraryImpalanodesratherthanalwaysusingthesamecoordinator
node.
WhyisspacenotfreedupwhenIissueDROPTABLE?
ImpaladeletesdatafileswhenyouissueaDROP TABLE onaninternaltable,butnotanexternalone.Bydefault,the
CREATE TABLE statementcreatesinternaltables,wherethefilesaremanagedbyImpala.Anexternaltableiscreated
withaCREATE EXTERNAL TABLE statement,wherethefilesresideinalocationoutsidethecontrolofImpala.Issue
aDESCRIBE FORMATTED statementtocheckwhetheratableisinternalorexternal.ThekeywordMANAGED_TABLE
772|ApacheImpalaGuideImpalaFrequentlyAskedQuestions
indicatesaninternaltable,fromwhichImpalacandeletethedatafiles.ThekeywordEXTERNAL_TABLE indicatesan
externaltable,whereImpalawillleavethedatafilesuntouchedwhenyoudropthetable.
Evenwhenyoudropaninternaltableandthefilesareremovedfromtheiroriginallocation,youmightnotgetthe
harddrivespacebackimmediately.Bydefault,filesthataredeletedinHDFSgointoaspecialtrashcandirectory,from
whichtheyarepurgedafteraperiodoftime(bydefault,6hours).Forbackgroundinformationonthetrashcan
mechanism, seeHDFSArchitecture.Forinformationonpurgingfilesfromthetrashcan,seeFileSystemShell.
WhenImpaladeletesfilesandtheyaremovedtotheHDFStrashcan,theygointoanHDFSdirectoryownedbythe
impalauser.IftheimpalauserdoesnothaveanHDFShomedirectorywhereatrashcancanbecreated,thefiles
arenotdeletedormoved,asasafetymeasure.IfyouissueaDROP TABLE statementandfindthatthetabledatafiles
areleftintheiroriginallocation,createanHDFSdirectory/user/impala ,ownedandwriteablebytheimpalauser.
Forexample,youmightfindthat/user/impala isownedbythehdfsuser,inwhichcaseyouwouldswitchtothe
hdfsuserandissueacommand suchas:
hdfs dfs -chown -R impala /user/impala
IsthereaDUALtable?
Youmightbeusedtorunningqueriesagainstasingle-rowtablenamedDUALtotryoutexpressions,built-infunctions,
andUDFs.ImpaladoesnothaveaDUALtable.Toachievethesameresult,youcanissueaSELECTstatementwithout
anytablename:
select 2+2;
select substr('hello',2,1);
select pow(10,6);
Partitioned Tables
HowdoIloadabigCSVfileintoapartitioned table?
Toloadadatafileintoapartitioned table,whenthedatafileincludesfieldslikeyear,month,andsoonthatcorrespond
tothepartition keycolumns,useatwo-stageprocess.First,usetheLOAD DATA orCREATE EXTERNAL TABLE
statementtobringthedataintoanunpartitioned texttable.ThenuseanINSERT ... SELECT statementtocopy
thedatafromtheunpartitioned tabletoapartitioned one.IncludeaPARTITION clauseintheINSERTstatementto
specifythepartition keycolumns.TheINSERToperationsplitsupthedataintoseparatedatafilesforeachpartition.
Forexamples,seePartitioning forImpalaTablesonpage625.Fordetailsaboutloadingdataintopartitioned Parquet
tables,apopularchoiceforhigh-volumedata,seeLoadingDataintoParquetTablesonpage644.
CanIdoINSERT...SELECT*intoapartitioned table?
WhenyouusetheINSERT ... SELECT * syntaxtocopydataintoapartitioned table,thecolumnscorresponding
tothepartitionkeycolumnsmustappearlastinthecolumnsreturnedbytheSELECT * .Youcancreatethetablewith
thepartition keycolumnsdefinedlast.Or,youcanusetheCREATE VIEW statementtocreateaviewthatreorders
thecolumns:putthepartition keycolumnslast,thendotheINSERT ... SELECT * fromtheview.
HBase
WhatkindsofImpalaqueriesordataarebestsuitedforHBase?
HBasetablesareidealforquerieswherenormally youwoulduseakey-valuestore.Thatis,whereyouretrieveasingle
roworafewrows,bytestingaspecialuniquekeycolumnusingthe=orINoperators.
ApacheImpalaGuide|773ImpalaFrequentlyAskedQuestions
HBasetablesarenotsuitableforqueriesthatproducelargeresultsetswiththousands ofrows.HBasetablesarealso
notsuitableforqueriesthatperformfulltablescansbecausetheWHEREclausedoesnotrequestspecificvaluesfrom
theuniquekeycolumn.
UseHBasetablesfordatathatisinsertedoneroworafewrowsatatime,suchasbytheINSERT ... VALUES syntax.
Loadingdatapiecemeal likethisintoanHDFS-backedtableproducesmanytinyfiles,whichisaveryinefficientlayout
forHDFSdatafiles.
IfthelackofanUPDATEstatementinImpalaisaproblemforyou,youcansimulatesingle-rowupdatesbydoingan
INSERT ... VALUES statementusinganexistingvalueforthekeycolumn.Theoldrowvalueishidden;onlythenew
rowvalueisseenbyqueries.
HBasetablesareoftenwide(containingmanycolumns)andsparse(withmostcolumnvaluesNULL).Forexample,you
mightrecordhundredsofdifferentdatapointsforeachuserofanonlineservice,suchaswhethertheuserhadregistered
foranonlinegameorenabledparticular accountfeatures.WithImpalaandHBase,youcouldlookupalltheinformation
foraspecificcustomerefficientlyinasinglequery.Foranygivencustomer,mostofthesecolumnsmightbeNULL,
becauseatypicalcustomermightnotmakeuseofmostfeaturesofanonlineservice.
774|ApacheImpalaGuideImpalaFrequentlyAskedQuestions
Appendix: ApacheLicense,Version2.0
SPDXshortidentifier:Apache-2.0
ApacheLicense
Version2.0,January2004
http://www.apache.or g/licenses/
TERMSANDCONDITIONS FORUSE,REPRODUCTION,ANDDISTRIBUTION
1.Definitions.
"License" shallmeanthetermsandconditions foruse,reproduction, anddistribution asdefinedbySections1through
9ofthisdocumen t.
"Licensor" shallmeanthecopyrightownerorentityauthorizedbythecopyrightownerthatisgrantingtheLicense.
"LegalEntity"shallmeantheunionoftheactingentityandallotherentitiesthatcontrol,arecontrolledby,orare
undercommoncontrolwiththatentity.Forthepurposes ofthisdefinition,"control"means(i)thepower,director
indirect,tocausethedirectionormanagementofsuchentity,whetherbycontractorotherwise,or(ii)ownershipof
fiftypercent(50%)ormoreoftheoutstandingshares,or(iii)beneficialownershipofsuchentity.
"You"(or"Your")shallmeananindividual orLegalEntityexercisingpermissions grantedbythisLicense.
"Source"formshallmeanthepreferredformformakingmodifications,including butnotlimitedtosoftwaresource
code,documen tationsource,andconfigurationfiles.
"Object"formshallmeananyformresultingfrommechanic altransformationortranslationofaSourceform,including
butnotlimitedtocompiledobjectcode,generateddocumen tation,andconversionstoothermediatypes.
"Work"shallmeantheworkofauthorship,whetherinSourceorObjectform,madeavailableundertheLicense,as
indicatedbyacopyrightnoticethatisincludedinorattachedtothework(anexampleisprovidedintheAppendix
below).
"DerivativeWorks"shallmeananywork,whetherinSourceorObjectform,thatisbasedon(orderivedfrom)the
Workandforwhichtheeditorialrevisions,annotations,elaborations,orothermodificationsrepresent,asawhole,
anoriginalworkofauthorship.Forthepurposes ofthisLicense,DerivativeWorksshallnotincludeworksthatremain
separablefrom,ormerelylink(orbindbyname)totheinterfacesof,theWorkandDerivativeWorksthereof.
"Contribution" shallmeananyworkofauthorship,including theoriginalversionoftheWorkandanymodificationsor
additions tothatWorkorDerivativeWorksthereof,thatisintentionallysubmittedtoLicensorforinclusion intheWork
bythecopyrightownerorbyanindividual orLegalEntityauthorizedtosubmitonbehalfofthecopyrightowner.For
thepurposes ofthisdefinition,"submitted"meansanyformofelectronic,verbal,orwrittencommunic ationsentto
theLicensororitsrepresentatives,including butnotlimitedtocommunic ationonelectronicmailinglists,sourcecode
controlsystems,andissuetrackingsystemsthataremanagedby,oronbehalfof,theLicensorforthepurposeof
discussing andimprovingtheWork,butexcludingcommunic ationthatisconspicuously markedorotherwisedesignated
inwritingbythecopyrightowneras"NotaContribution."
"Contributor"shallmeanLicensorandanyindividual orLegalEntityonbehalfofwhomaContributionhasbeenreceived
byLicensorandsubsequentlyincorporatedwithintheWork.
2.GrantofCopyrightLicense.
Subjecttothetermsandconditions ofthisLicense,eachContributorherebygrantstoYouaperpetual,worldwide,
non-exclusive,no-charge,royalty-free,irrevocablecopyrightlicensetoreproduce,prepareDerivativeWorksof,publicly
display,publiclyperform,sublicense, anddistributetheWorkandsuchDerivativeWorksinSourceorObjectform.
3.GrantofPatentLicense.
Subjecttothetermsandconditions ofthisLicense,eachContributorherebygrantstoYouaperpetual,worldwide,
non-exclusive,no-charge,royalty-free,irrevocable(exceptasstatedinthissection)patentlicensetomake,havemade,
use,offertosell,sell,import,andotherwisetransfertheWork,wheresuchlicenseappliesonlytothosepatentclaims
Cloudera|775Appendix: ApacheLicense,Version2.0
licensable bysuchContributorthatarenecessarily infringedbytheirContribution(s) aloneorbycombinationoftheir
Contribution(s) withtheWorktowhichsuchContribution(s) wassubmitted.IfYouinstitutepatentlitigationagainst
anyentity(including across-claim orcounterclaiminalawsuit)allegingthattheWorkoraContribution incorporated
withintheWorkconstitutesdirectorcontributorypatentinfringement,thenanypatentlicensesgrantedtoYouunder
thisLicenseforthatWorkshallterminateasofthedatesuchlitigationisfiled.
4.Redistribution.
YoumayreproduceanddistributecopiesoftheWorkorDerivativeWorksthereofinanymedium, withorwithout
modifications,andinSourceorObjectform,providedthatYoumeetthefollowingconditions:
1.YoumustgiveanyotherrecipientsoftheWorkorDerivativeWorksacopyofthisLicense;and
2.Youmustcauseanymodified filestocarryprominentnoticesstatingthatYouchangedthefiles;and
3.Youmustretain,intheSourceformofanyDerivativeWorksthatYoudistribute,allcopyright,patent,trademark,
andattribution noticesfromtheSourceformoftheWork,excludingthosenoticesthatdonotpertaintoanypart
oftheDerivativeWorks;and
4.IftheWorkincludesa"NOTICE"textfileaspartofitsdistribution, thenanyDerivativeWorksthatYoudistribute
mustincludeareadablecopyoftheattribution noticescontainedwithinsuchNOTICEfile,excludingthosenotices
thatdonotpertaintoanypartoftheDerivativeWorks,inatleastoneofthefollowingplaces:withinaNOTICE
textfiledistributedaspartoftheDerivativeWorks;withintheSourceformordocumen tation,ifprovidedalong
withtheDerivativeWorks;or,withinadisplaygeneratedbytheDerivativeWorks,ifandwhereversuchthird-party
noticesnormally appear.ThecontentsoftheNOTICEfileareforinformationalpurposes onlyanddonotmodify
theLicense.YoumayaddYourownattribution noticeswithinDerivativeWorksthatYoudistribute,alongside or
asanaddendum totheNOTICEtextfromtheWork,providedthatsuchadditional attribution noticescannotbe
construedasmodifyingtheLicense.
YoumayaddYourowncopyrightstatementtoYourmodificationsandmayprovideadditional ordifferentlicense
termsandconditions foruse,reproduction, ordistribution ofYourmodifications,orforanysuchDerivativeWorksas
awhole,providedYouruse,reproduction, anddistribution oftheWorkotherwisecomplieswiththeconditions stated
inthisLicense.
5.Submission ofContributions.
UnlessYouexplicitlystateotherwise,anyContribution intentionallysubmittedforinclusion intheWorkbyYoutothe
Licensorshallbeunderthetermsandconditions ofthisLicense,withoutanyadditional termsorconditions.
Notwithstandingtheabove,nothinghereinshallsupersedeormodifythetermsofanyseparatelicenseagreement
youmayhaveexecutedwithLicensorregardingsuchContributions.
6.Trademarks.
ThisLicensedoesnotgrantpermission tousethetradenames,trademarks,servicemarks,orproductnamesofthe
Licensor,exceptasrequiredforreasonable andcustomaryuseindescribing theoriginoftheWorkandreproducing
thecontentoftheNOTICEfile.
7.Disclaimer ofWarranty.
Unlessrequiredbyapplicablelaworagreedtoinwriting,LicensorprovidestheWork(andeachContributorprovides
itsContributions) onan"ASIS"BASIS,WITHOUT WARRANTIE SORCONDITIONS OFANYKIND,eitherexpressorimplied,
including,withoutlimitation,anywarrantiesorconditions ofTITLE,NON-INFRINGEMENT ,MERCHANTABILITY,or
FITNESSFORAPARTICULARPURPOSE. Youaresolelyresponsible fordetermining theappropriatenessofusingor
redistributingtheWorkandassumeanyrisksassociatedwithYourexerciseofpermissions underthisLicense.
8.LimitationofLiability.
Innoeventandundernolegaltheory,whetherintort(including negligence),contract,orotherwise,unlessrequired
byapplicablelaw(suchasdeliberateandgrosslynegligentacts)oragreedtoinwriting,shallanyContributorbeliable
toYoufordamages,including anydirect,indirect,special,incidental,orconsequen tialdamagesofanycharacterarising
asaresultofthisLicenseoroutoftheuseorinabilitytousetheWork(including butnotlimitedtodamagesforloss
ofgoodwill,workstoppage,computerfailureormalfunction, oranyandallothercommercialdamagesorlosses),even
ifsuchContributorhasbeenadvisedofthepossibility ofsuchdamages.
9.AcceptingWarrantyorAdditional Liability.
776|ClouderaAppendix: ApacheLicense,Version2.0
WhileredistributingtheWorkorDerivativeWorksthereof,Youmaychoosetooffer,andchargeafeefor,acceptance
ofsupport,warranty,indemnity ,orotherliabilityobligationsand/orrightsconsistentwiththisLicense.However,in
acceptingsuchobligations,YoumayactonlyonYourownbehalfandonYoursoleresponsibility ,notonbehalfofany
otherContributor,andonlyifYouagreetoindemnify,defend,andholdeachContributorharmless foranyliability
incurredby,orclaimsassertedagainst,suchContributorbyreasonofyouracceptinganysuchwarrantyoradditional
liability.
ENDOFTERMSANDCONDITIONS
APPENDIX: HowtoapplytheApacheLicensetoyourwork
ToapplytheApacheLicensetoyourwork,attachthefollowingboilerplatenotice,withthefieldsenclosed bybrackets
"[]"replacedwithyourownidentifyinginformation.(Don'tincludethebrackets!)Thetextshouldbeenclosed inthe
appropriatecommentsyntaxforthefileformat.Wealsorecommend thatafileorclassnameanddescriptionof
purposebeincludedonthesame"printedpage"asthecopyrightnoticeforeasieridentificationwithinthird-party
archives.
Copyright [yyyy] [name of copyright owner]
Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at
  http://www.apache.org/licenses/LICENSE-2.0
Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
Cloudera|777Appendix: ApacheLicense,Version2.0
