OpenMP
Application Programming
Interface
Version 5.0 November 2018
Copyright c1997-2018 OpenMP Architecture Review Board.
Permission to copy without fee all or part of this material is granted, provided the OpenMP
Architecture Review Board copyright notice and the title of this document appear. Notice is
given that copying is by permission of the OpenMP Architecture Review Board.
This page intentionally left blank.
Contents
1 Introduction 1
1.1 Scope . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1
1.2 Glossary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2
1.2.1 Threading Concepts . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2
1.2.2 OpenMP Language Terminology . . . . . . . . . . . . . . . . . . . . . . . 2
1.2.3 Loop Terminology . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 8
1.2.4 Synchronization Terminology . . . . . . . . . . . . . . . . . . . . . . . . . 9
1.2.5 Tasking Terminology . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 10
1.2.6 Data Terminology . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12
1.2.7 Implementation Terminology . . . . . . . . . . . . . . . . . . . . . . . . . 17
1.2.8 Tool Terminology . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17
1.3 Execution Model . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 20
1.4 Memory Model . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23
1.4.1 Structure of the OpenMP Memory Model . . . . . . . . . . . . . . . . . . . 23
1.4.2 Device Data Environments . . . . . . . . . . . . . . . . . . . . . . . . . . 24
1.4.3 Memory Management . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 25
1.4.4 The Flush Operation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 25
1.4.5 Flush Synchronization and Happens Before . . . . . . . . . . . . . . . . . . 27
1.4.6 OpenMP Memory Consistency . . . . . . . . . . . . . . . . . . . . . . . . 28
1.5 Tool Interfaces . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29
1.5.1 OMPT . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29
1.5.2 OMPD . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 30
i
1.6 OpenMP Compliance . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 31
1.7 Normative References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 31
1.8 Organization of this Document . . . . . . . . . . . . . . . . . . . . . . . . . . . 34
2 Directives 37
2.1 Directive Format . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 38
2.1.1 Fixed Source Form Directives . . . . . . . . . . . . . . . . . . . . . . . . . 41
2.1.2 Free Source Form Directives . . . . . . . . . . . . . . . . . . . . . . . . . 41
2.1.3 Stand-Alone Directives . . . . . . . . . . . . . . . . . . . . . . . . . . . . 42
2.1.4 Array Shaping . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 43
2.1.5 Array Sections . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 44
2.1.6 Iterators . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 47
2.2 Conditional Compilation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 49
2.2.1 Fixed Source Form Conditional Compilation Sentinels . . . . . . . . . . . . 50
2.2.2 Free Source Form Conditional Compilation Sentinel . . . . . . . . . . . . . 50
2.3 Variant Directives . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 51
2.3.1 OpenMP Context . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 51
2.3.2 Context Selectors . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 53
2.3.3 Matching and Scoring Context Selectors . . . . . . . . . . . . . . . . . . . 55
2.3.4 Metadirectives . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 56
2.3.5 declare variant Directive . . . . . . . . . . . . . . . . . . . . . . . . 58
2.4 requires Directive . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 60
2.5 Internal Control Variables . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 63
2.5.1 ICV Descriptions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 64
2.5.2 ICV Initialization . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 66
2.5.3 Modifying and Retrieving ICV Values . . . . . . . . . . . . . . . . . . . . 68
2.5.4 How ICVs are Scoped . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 70
2.5.4.1 How the Per-Data Environment ICVs Work . . . . . . . . . . . . . . . 72
2.5.5 ICV Override Relationships . . . . . . . . . . . . . . . . . . . . . . . . . . 72
2.6 parallel Construct . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 74
2.6.1 Determining the Number of Threads for a parallel Region . . . . . . . . 78
2.6.2 Controlling OpenMP Thread Aﬃnity . . . . . . . . . . . . . . . . . . . . . 80
2.7 teamsConstruct . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 82
iiOpenMP API – Version 5.0 November 2018
2.8 Worksharing Constructs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 86
2.8.1 sections Construct . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 86
2.8.2 single Construct . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 89
2.8.3 workshare Construct . . . . . . . . . . . . . . . . . . . . . . . . . . . . 92
2.9 Loop-Related Directives . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 95
2.9.1 Canonical Loop Form . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 95
2.9.2 Worksharing-Loop Construct . . . . . . . . . . . . . . . . . . . . . . . . . 101
2.9.2.1 Determining the Schedule of a Worksharing-Loop . . . . . . . . . . . . 109
2.9.3 SIMD Directives . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 110
2.9.3.1 simdConstruct . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 110
2.9.3.2 Worksharing-Loop SIMD Construct . . . . . . . . . . . . . . . . . . . 114
2.9.3.3 declare simd Directive . . . . . . . . . . . . . . . . . . . . . . . . 116
2.9.4 distribute Loop Constructs . . . . . . . . . . . . . . . . . . . . . . . . 120
2.9.4.1 distribute Construct . . . . . . . . . . . . . . . . . . . . . . . . . 120
2.9.4.2 distribute simd Construct . . . . . . . . . . . . . . . . . . . . . . 123
2.9.4.3 Distribute Parallel Worksharing-Loop Construct . . . . . . . . . . . . . 125
2.9.4.4 Distribute Parallel Worksharing-Loop SIMD Construct . . . . . . . . . 126
2.9.5 loopConstruct . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 128
2.9.6 scanDirective . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 132
2.10 Tasking Constructs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 135
2.10.1 taskConstruct . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 135
2.10.2 taskloop Construct . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 140
2.10.3 taskloop simd Construct . . . . . . . . . . . . . . . . . . . . . . . . . 146
2.10.4 taskyield Construct . . . . . . . . . . . . . . . . . . . . . . . . . . . . 147
2.10.5 Initial Task . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 148
2.10.6 Task Scheduling . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 149
2.11 Memory Management Directives . . . . . . . . . . . . . . . . . . . . . . . . . . 152
2.11.1 Memory Spaces . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 152
2.11.2 Memory Allocators . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 152
2.11.3 allocate Directive . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 156
2.11.4 allocate Clause . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 158
2.12 Device Directives . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 160
2.12.1 Device Initialization . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 160
Contents iii
2.12.2 target data Construct . . . . . . . . . . . . . . . . . . . . . . . . . . . 161
2.12.3 target enter data Construct . . . . . . . . . . . . . . . . . . . . . . . 164
2.12.4 target exit data Construct . . . . . . . . . . . . . . . . . . . . . . . 166
2.12.5 target Construct . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 170
2.12.6 target update Construct . . . . . . . . . . . . . . . . . . . . . . . . . 176
2.12.7 declare target Directive . . . . . . . . . . . . . . . . . . . . . . . . . 180
2.13 Combined Constructs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 185
2.13.1 Parallel Worksharing-Loop Construct . . . . . . . . . . . . . . . . . . . . . 185
2.13.2 parallel loop Construct . . . . . . . . . . . . . . . . . . . . . . . . . 186
2.13.3 parallel sections Construct . . . . . . . . . . . . . . . . . . . . . . 188
2.13.4 parallel workshare Construct . . . . . . . . . . . . . . . . . . . . . 189
2.13.5 Parallel Worksharing-Loop SIMD Construct . . . . . . . . . . . . . . . . . 190
2.13.6 parallel master Construct . . . . . . . . . . . . . . . . . . . . . . . . 191
2.13.7 master taskloop Construct . . . . . . . . . . . . . . . . . . . . . . . . 192
2.13.8 master taskloop simd Construct . . . . . . . . . . . . . . . . . . . . 194
2.13.9 parallel master taskloop Construct . . . . . . . . . . . . . . . . . 195
2.13.10 parallel master taskloop simd Construct . . . . . . . . . . . . . . 196
2.13.11 teams distribute Construct . . . . . . . . . . . . . . . . . . . . . . . 197
2.13.12 teams distribute simd Construct . . . . . . . . . . . . . . . . . . . 198
2.13.13 Teams Distribute Parallel Worksharing-Loop Construct . . . . . . . . . . . 200
2.13.14 Teams Distribute Parallel Worksharing-Loop SIMD Construct . . . . . . . . 201
2.13.15 teams loop Construct . . . . . . . . . . . . . . . . . . . . . . . . . . . . 202
2.13.16 target parallel Construct . . . . . . . . . . . . . . . . . . . . . . . . 203
2.13.17 Target Parallel Worksharing-Loop Construct . . . . . . . . . . . . . . . . . 205
2.13.18 Target Parallel Worksharing-Loop SIMD Construct . . . . . . . . . . . . . 206
2.13.19 target parallel loop Construct . . . . . . . . . . . . . . . . . . . . 208
2.13.20 target simd Construct . . . . . . . . . . . . . . . . . . . . . . . . . . . 209
2.13.21 target teams Construct . . . . . . . . . . . . . . . . . . . . . . . . . . 210
2.13.22 target teams distribute Construct . . . . . . . . . . . . . . . . . . 211
2.13.23 target teams distribute simd Construct . . . . . . . . . . . . . . 213
2.13.24 target teams loop Construct . . . . . . . . . . . . . . . . . . . . . . . 214
2.13.25 Target Teams Distribute Parallel Worksharing-Loop Construct . . . . . . . . 215
2.13.26 Target Teams Distribute Parallel Worksharing-Loop SIMD Construct . . . . 216
ivOpenMP API – Version 5.0 November 2018
2.14 Clauses on Combined and Composite Constructs . . . . . . . . . . . . . . . . . . 218
2.15 ifClause . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 220
2.16 master Construct . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 221
2.17 Synchronization Constructs and Clauses . . . . . . . . . . . . . . . . . . . . . . 223
2.17.1 critical Construct . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 223
2.17.2 barrier Construct . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 226
2.17.3 Implicit Barriers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 228
2.17.4 Implementation-Speciﬁc Barriers . . . . . . . . . . . . . . . . . . . . . . . 230
2.17.5 taskwait Construct . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 230
2.17.6 taskgroup Construct . . . . . . . . . . . . . . . . . . . . . . . . . . . . 232
2.17.7 atomic Construct . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 234
2.17.8 flushConstruct . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 242
2.17.8.1 Implicit Flushes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 246
2.17.9 ordered Construct . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 250
2.17.10 Depend Objects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 254
2.17.10.1 depobj Construct . . . . . . . . . . . . . . . . . . . . . . . . . . . . 254
2.17.11 depend Clause . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 255
2.17.12 Synchronization Hints . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 260
2.18 Cancellation Constructs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 263
2.18.1 cancel Construct . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 263
2.18.2 cancellation point Construct . . . . . . . . . . . . . . . . . . . . . 267
2.19 Data Environment . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 269
2.19.1 Data-Sharing Attribute Rules . . . . . . . . . . . . . . . . . . . . . . . . . 269
2.19.1.1 Variables Referenced in a Construct . . . . . . . . . . . . . . . . . . . 270
2.19.1.2 Variables Referenced in a Region but not in a Construct . . . . . . . . . 273
2.19.2 threadprivate Directive . . . . . . . . . . . . . . . . . . . . . . . . . 274
2.19.3 List Item Privatization . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 279
2.19.4 Data-Sharing Attribute Clauses . . . . . . . . . . . . . . . . . . . . . . . . 282
2.19.4.1 default Clause . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 282
2.19.4.2 shared Clause . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 283
2.19.4.3 private Clause . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 285
2.19.4.4 firstprivate Clause . . . . . . . . . . . . . . . . . . . . . . . . . 286
2.19.4.5 lastprivate Clause . . . . . . . . . . . . . . . . . . . . . . . . . . 288
Contents v
2.19.4.6 linear Clause . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 290
2.19.5 Reduction Clauses and Directives . . . . . . . . . . . . . . . . . . . . . . . 293
2.19.5.1 Properties Common To All Reduction Clauses . . . . . . . . . . . . . . 294
2.19.5.2 Reduction Scoping Clauses . . . . . . . . . . . . . . . . . . . . . . . . 299
2.19.5.3 Reduction Participating Clauses . . . . . . . . . . . . . . . . . . . . . 300
2.19.5.4 reduction Clause . . . . . . . . . . . . . . . . . . . . . . . . . . . 300
2.19.5.5 task_reduction Clause . . . . . . . . . . . . . . . . . . . . . . . 303
2.19.5.6 in_reduction Clause . . . . . . . . . . . . . . . . . . . . . . . . . 303
2.19.5.7 declare reduction Directive . . . . . . . . . . . . . . . . . . . . 304
2.19.6 Data Copying Clauses . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 309
2.19.6.1 copyin Clause . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 310
2.19.6.2 copyprivate Clause . . . . . . . . . . . . . . . . . . . . . . . . . . 312
2.19.7 Data-Mapping Attribute Rules, Clauses, and Directives . . . . . . . . . . . 314
2.19.7.1 mapClause . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 315
2.19.7.2 defaultmap Clause . . . . . . . . . . . . . . . . . . . . . . . . . . . 324
2.19.7.3 declare mapper Directive . . . . . . . . . . . . . . . . . . . . . . . 326
2.20 Nesting of Regions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 328
3 Runtime Library Routines 331
3.1 Runtime Library Deﬁnitions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 332
3.2 Execution Environment Routines . . . . . . . . . . . . . . . . . . . . . . . . . . 334
3.2.1 omp_set_num_threads . . . . . . . . . . . . . . . . . . . . . . . . . . 334
3.2.2 omp_get_num_threads . . . . . . . . . . . . . . . . . . . . . . . . . . 335
3.2.3 omp_get_max_threads . . . . . . . . . . . . . . . . . . . . . . . . . . 336
3.2.4 omp_get_thread_num . . . . . . . . . . . . . . . . . . . . . . . . . . 337
3.2.5 omp_get_num_procs . . . . . . . . . . . . . . . . . . . . . . . . . . . 338
3.2.6 omp_in_parallel . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 339
3.2.7 omp_set_dynamic . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 340
3.2.8 omp_get_dynamic . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 341
3.2.9 omp_get_cancellation . . . . . . . . . . . . . . . . . . . . . . . . . 342
3.2.10 omp_set_nested . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 343
3.2.11 omp_get_nested . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 344
3.2.12 omp_set_schedule . . . . . . . . . . . . . . . . . . . . . . . . . . . . 345
3.2.13 omp_get_schedule . . . . . . . . . . . . . . . . . . . . . . . . . . . . 347
viOpenMP API – Version 5.0 November 2018
3.2.14 omp_get_thread_limit . . . . . . . . . . . . . . . . . . . . . . . . . 348
3.2.15 omp_get_supported_active_levels . . . . . . . . . . . . . . . . 349
3.2.16 omp_set_max_active_levels . . . . . . . . . . . . . . . . . . . . . 350
3.2.17 omp_get_max_active_levels . . . . . . . . . . . . . . . . . . . . . 351
3.2.18 omp_get_level . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 352
3.2.19 omp_get_ancestor_thread_num . . . . . . . . . . . . . . . . . . . 353
3.2.20 omp_get_team_size . . . . . . . . . . . . . . . . . . . . . . . . . . . 354
3.2.21 omp_get_active_level . . . . . . . . . . . . . . . . . . . . . . . . . 355
3.2.22 omp_in_final . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 356
3.2.23 omp_get_proc_bind . . . . . . . . . . . . . . . . . . . . . . . . . . . 357
3.2.24 omp_get_num_places . . . . . . . . . . . . . . . . . . . . . . . . . . 358
3.2.25 omp_get_place_num_procs . . . . . . . . . . . . . . . . . . . . . . 359
3.2.26 omp_get_place_proc_ids . . . . . . . . . . . . . . . . . . . . . . . 360
3.2.27 omp_get_place_num . . . . . . . . . . . . . . . . . . . . . . . . . . . 362
3.2.28 omp_get_partition_num_places . . . . . . . . . . . . . . . . . . 362
3.2.29 omp_get_partition_place_nums . . . . . . . . . . . . . . . . . . 363
3.2.30 omp_set_affinity_format . . . . . . . . . . . . . . . . . . . . . . 364
3.2.31 omp_get_affinity_format . . . . . . . . . . . . . . . . . . . . . . 366
3.2.32 omp_display_affinity . . . . . . . . . . . . . . . . . . . . . . . . . 367
3.2.33 omp_capture_affinity . . . . . . . . . . . . . . . . . . . . . . . . . 368
3.2.34 omp_set_default_device . . . . . . . . . . . . . . . . . . . . . . . 369
3.2.35 omp_get_default_device . . . . . . . . . . . . . . . . . . . . . . . 370
3.2.36 omp_get_num_devices . . . . . . . . . . . . . . . . . . . . . . . . . . 371
3.2.37 omp_get_device_num . . . . . . . . . . . . . . . . . . . . . . . . . . 372
3.2.38 omp_get_num_teams . . . . . . . . . . . . . . . . . . . . . . . . . . . 373
3.2.39 omp_get_team_num . . . . . . . . . . . . . . . . . . . . . . . . . . . . 374
3.2.40 omp_is_initial_device . . . . . . . . . . . . . . . . . . . . . . . . 375
3.2.41 omp_get_initial_device . . . . . . . . . . . . . . . . . . . . . . . 376
3.2.42 omp_get_max_task_priority . . . . . . . . . . . . . . . . . . . . . 377
3.2.43 omp_pause_resource . . . . . . . . . . . . . . . . . . . . . . . . . . 378
3.2.44 omp_pause_resource_all . . . . . . . . . . . . . . . . . . . . . . . 380
3.3 Lock Routines . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 381
3.3.1 omp_init_lock andomp_init_nest_lock . . . . . . . . . . . . . 384
Contents vii
3.3.2 omp_init_lock_with_hint and
omp_init_nest_lock_with_hint . . . . . . . . . . . . . . . . . . 385
3.3.3 omp_destroy_lock andomp_destroy_nest_lock . . . . . . . . . 387
3.3.4 omp_set_lock andomp_set_nest_lock . . . . . . . . . . . . . . . 388
3.3.5 omp_unset_lock andomp_unset_nest_lock . . . . . . . . . . . . 390
3.3.6 omp_test_lock andomp_test_nest_lock . . . . . . . . . . . . . 392
3.4 Timing Routines . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 394
3.4.1 omp_get_wtime . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 394
3.4.2 omp_get_wtick . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 395
3.5 Event Routine . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 396
3.5.1 omp_fulfill_event . . . . . . . . . . . . . . . . . . . . . . . . . . . 396
3.6 Device Memory Routines . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 397
3.6.1 omp_target_alloc . . . . . . . . . . . . . . . . . . . . . . . . . . . . 397
3.6.2 omp_target_free . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 399
3.6.3 omp_target_is_present . . . . . . . . . . . . . . . . . . . . . . . . 400
3.6.4 omp_target_memcpy . . . . . . . . . . . . . . . . . . . . . . . . . . . 400
3.6.5 omp_target_memcpy_rect . . . . . . . . . . . . . . . . . . . . . . . 402
3.6.6 omp_target_associate_ptr . . . . . . . . . . . . . . . . . . . . . . 403
3.6.7 omp_target_disassociate_ptr . . . . . . . . . . . . . . . . . . . 405
3.7 Memory Management Routines . . . . . . . . . . . . . . . . . . . . . . . . . . . 406
3.7.1 Memory Management Types . . . . . . . . . . . . . . . . . . . . . . . . . 406
3.7.2 omp_init_allocator . . . . . . . . . . . . . . . . . . . . . . . . . . 409
3.7.3 omp_destroy_allocator . . . . . . . . . . . . . . . . . . . . . . . . 410
3.7.4 omp_set_default_allocator . . . . . . . . . . . . . . . . . . . . . 411
3.7.5 omp_get_default_allocator . . . . . . . . . . . . . . . . . . . . . 412
3.7.6 omp_alloc . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 413
3.7.7 omp_free . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 414
3.8 Tool Control Routine . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 415
4 OMPT Interface 419
4.1 OMPT Interfaces Deﬁnitions . . . . . . . . . . . . . . . . . . . . . . . . . . . . 419
4.2 Activating a First-Party Tool . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 420
4.2.1 ompt_start_tool . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 420
4.2.2 Determining Whether a First-Party Tool Should be Initialized . . . . . . . . 421
viiiOpenMP API – Version 5.0 November 2018
4.2.3 Initializing a First-Party Tool . . . . . . . . . . . . . . . . . . . . . . . . . 423
4.2.3.1 Binding Entry Points in the OMPT Callback Interface . . . . . . . . . . 424
4.2.4 Monitoring Activity on the Host with OMPT . . . . . . . . . . . . . . . . . 425
4.2.5 Tracing Activity on Target Devices with OMPT . . . . . . . . . . . . . . . 427
4.3 Finalizing a First-Party Tool . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 432
4.4 OMPT Data Types . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 433
4.4.1 Tool Initialization and Finalization . . . . . . . . . . . . . . . . . . . . . . 433
4.4.2 Callbacks . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 434
4.4.3 Tracing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 435
4.4.3.1 Record Type . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 435
4.4.3.2 Native Record Kind . . . . . . . . . . . . . . . . . . . . . . . . . . . . 435
4.4.3.3 Native Record Abstract Type . . . . . . . . . . . . . . . . . . . . . . . 436
4.4.3.4 Record Type . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 436
4.4.4 Miscellaneous Type Deﬁnitions . . . . . . . . . . . . . . . . . . . . . . . . 438
4.4.4.1 ompt_callback_t . . . . . . . . . . . . . . . . . . . . . . . . . . . 438
4.4.4.2 ompt_set_result_t . . . . . . . . . . . . . . . . . . . . . . . . . 438
4.4.4.3 ompt_id_t . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 439
4.4.4.4 ompt_data_t . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 440
4.4.4.5 ompt_device_t . . . . . . . . . . . . . . . . . . . . . . . . . . . . 441
4.4.4.6 ompt_device_time_t . . . . . . . . . . . . . . . . . . . . . . . . 441
4.4.4.7 ompt_buffer_t . . . . . . . . . . . . . . . . . . . . . . . . . . . . 441
4.4.4.8 ompt_buffer_cursor_t . . . . . . . . . . . . . . . . . . . . . . . 442
4.4.4.9 ompt_dependence_t . . . . . . . . . . . . . . . . . . . . . . . . . 442
4.4.4.10 ompt_thread_t . . . . . . . . . . . . . . . . . . . . . . . . . . . . 443
4.4.4.11 ompt_scope_endpoint_t . . . . . . . . . . . . . . . . . . . . . . 443
4.4.4.12 ompt_dispatch_t . . . . . . . . . . . . . . . . . . . . . . . . . . . 444
4.4.4.13 ompt_sync_region_t . . . . . . . . . . . . . . . . . . . . . . . . 444
4.4.4.14 ompt_target_data_op_t . . . . . . . . . . . . . . . . . . . . . . 444
4.4.4.15 ompt_work_t . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 445
4.4.4.16 ompt_mutex_t . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 445
4.4.4.17 ompt_native_mon_flag_t . . . . . . . . . . . . . . . . . . . . . 446
4.4.4.18 ompt_task_flag_t . . . . . . . . . . . . . . . . . . . . . . . . . . 446
4.4.4.19 ompt_task_status_t . . . . . . . . . . . . . . . . . . . . . . . . 447
Contents ix
4.4.4.20 ompt_target_t . . . . . . . . . . . . . . . . . . . . . . . . . . . . 448
4.4.4.21 ompt_parallel_flag_t . . . . . . . . . . . . . . . . . . . . . . . 448
4.4.4.22 ompt_target_map_flag_t . . . . . . . . . . . . . . . . . . . . . 449
4.4.4.23 ompt_dependence_type_t . . . . . . . . . . . . . . . . . . . . . 450
4.4.4.24 ompt_cancel_flag_t . . . . . . . . . . . . . . . . . . . . . . . . 450
4.4.4.25 ompt_hwid_t . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 451
4.4.4.26 ompt_state_t . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 452
4.4.4.27 ompt_frame_t . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 454
4.4.4.28 ompt_frame_flag_t . . . . . . . . . . . . . . . . . . . . . . . . . 455
4.4.4.29 ompt_wait_id_t . . . . . . . . . . . . . . . . . . . . . . . . . . . 456
4.5 OMPT Tool Callback Signatures and Trace Records . . . . . . . . . . . . . . . . 457
4.5.1 Initialization and Finalization Callback Signature . . . . . . . . . . . . . . . 457
4.5.1.1 ompt_initialize_t . . . . . . . . . . . . . . . . . . . . . . . . . 457
4.5.1.2 ompt_finalize_t . . . . . . . . . . . . . . . . . . . . . . . . . . . 458
4.5.2 Event Callback Signatures and Trace Records . . . . . . . . . . . . . . . . . 459
4.5.2.1 ompt_callback_thread_begin_t . . . . . . . . . . . . . . . . 459
4.5.2.2 ompt_callback_thread_end_t . . . . . . . . . . . . . . . . . . 460
4.5.2.3 ompt_callback_parallel_begin_t . . . . . . . . . . . . . . . 461
4.5.2.4 ompt_callback_parallel_end_t . . . . . . . . . . . . . . . . 463
4.5.2.5 ompt_callback_work_t . . . . . . . . . . . . . . . . . . . . . . . 464
4.5.2.6 ompt_callback_dispatch_t . . . . . . . . . . . . . . . . . . . 465
4.5.2.7 ompt_callback_task_create_t . . . . . . . . . . . . . . . . . 467
4.5.2.8 ompt_callback_dependences_t . . . . . . . . . . . . . . . . . 468
4.5.2.9 ompt_callback_task_dependence_t . . . . . . . . . . . . . . 470
4.5.2.10 ompt_callback_task_schedule_t . . . . . . . . . . . . . . . 470
4.5.2.11 ompt_callback_implicit_task_t . . . . . . . . . . . . . . . 471
4.5.2.12 ompt_callback_master_t . . . . . . . . . . . . . . . . . . . . . 473
4.5.2.13 ompt_callback_sync_region_t . . . . . . . . . . . . . . . . . 474
4.5.2.14 ompt_callback_mutex_acquire_t . . . . . . . . . . . . . . . 476
4.5.2.15 ompt_callback_mutex_t . . . . . . . . . . . . . . . . . . . . . . 477
4.5.2.16 ompt_callback_nest_lock_t . . . . . . . . . . . . . . . . . . . 479
4.5.2.17 ompt_callback_flush_t . . . . . . . . . . . . . . . . . . . . . . 480
4.5.2.18 ompt_callback_cancel_t . . . . . . . . . . . . . . . . . . . . . 481
xOpenMP API – Version 5.0 November 2018
4.5.2.19 ompt_callback_device_initialize_t . . . . . . . . . . . . 482
4.5.2.20 ompt_callback_device_finalize_t . . . . . . . . . . . . . . 484
4.5.2.21 ompt_callback_device_load_t . . . . . . . . . . . . . . . . . 484
4.5.2.22 ompt_callback_device_unload_t . . . . . . . . . . . . . . . 486
4.5.2.23 ompt_callback_buffer_request_t . . . . . . . . . . . . . . . 486
4.5.2.24 ompt_callback_buffer_complete_t . . . . . . . . . . . . . . 487
4.5.2.25 ompt_callback_target_data_op_t . . . . . . . . . . . . . . . 488
4.5.2.26 ompt_callback_target_t . . . . . . . . . . . . . . . . . . . . . 490
4.5.2.27 ompt_callback_target_map_t . . . . . . . . . . . . . . . . . . 492
4.5.2.28 ompt_callback_target_submit_t . . . . . . . . . . . . . . . 494
4.5.2.29 ompt_callback_control_tool_t . . . . . . . . . . . . . . . . 495
4.6 OMPT Runtime Entry Points for Tools . . . . . . . . . . . . . . . . . . . . . . . 497
4.6.1 Entry Points in the OMPT Callback Interface . . . . . . . . . . . . . . . . . 497
4.6.1.1 ompt_enumerate_states_t . . . . . . . . . . . . . . . . . . . . 498
4.6.1.2 ompt_enumerate_mutex_impls_t . . . . . . . . . . . . . . . . 499
4.6.1.3 ompt_set_callback_t . . . . . . . . . . . . . . . . . . . . . . . 500
4.6.1.4 ompt_get_callback_t . . . . . . . . . . . . . . . . . . . . . . . 502
4.6.1.5 ompt_get_thread_data_t . . . . . . . . . . . . . . . . . . . . . 503
4.6.1.6 ompt_get_num_procs_t . . . . . . . . . . . . . . . . . . . . . . . 503
4.6.1.7 ompt_get_num_places_t . . . . . . . . . . . . . . . . . . . . . . 504
4.6.1.8 ompt_get_place_proc_ids_t . . . . . . . . . . . . . . . . . . . 505
4.6.1.9 ompt_get_place_num_t . . . . . . . . . . . . . . . . . . . . . . . 506
4.6.1.10 ompt_get_partition_place_nums_t . . . . . . . . . . . . . . 507
4.6.1.11 ompt_get_proc_id_t . . . . . . . . . . . . . . . . . . . . . . . . 508
4.6.1.12 ompt_get_state_t . . . . . . . . . . . . . . . . . . . . . . . . . . 508
4.6.1.13 ompt_get_parallel_info_t . . . . . . . . . . . . . . . . . . . 510
4.6.1.14 ompt_get_task_info_t . . . . . . . . . . . . . . . . . . . . . . . 512
4.6.1.15 ompt_get_task_memory_t . . . . . . . . . . . . . . . . . . . . . 514
4.6.1.16 ompt_get_target_info_t . . . . . . . . . . . . . . . . . . . . . 515
4.6.1.17 ompt_get_num_devices_t . . . . . . . . . . . . . . . . . . . . . 516
4.6.1.18 ompt_get_unique_id_t . . . . . . . . . . . . . . . . . . . . . . . 517
4.6.1.19 ompt_finalize_tool_t . . . . . . . . . . . . . . . . . . . . . . . 517
Contents xi
4.6.2 Entry Points in the OMPT Device Tracing Interface . . . . . . . . . . . . . 518
4.6.2.1 ompt_get_device_num_procs_t . . . . . . . . . . . . . . . . . 518
4.6.2.2 ompt_get_device_time_t . . . . . . . . . . . . . . . . . . . . . 519
4.6.2.3 ompt_translate_time_t . . . . . . . . . . . . . . . . . . . . . . 520
4.6.2.4 ompt_set_trace_ompt_t . . . . . . . . . . . . . . . . . . . . . . 521
4.6.2.5 ompt_set_trace_native_t . . . . . . . . . . . . . . . . . . . . 522
4.6.2.6 ompt_start_trace_t . . . . . . . . . . . . . . . . . . . . . . . . 523
4.6.2.7 ompt_pause_trace_t . . . . . . . . . . . . . . . . . . . . . . . . 524
4.6.2.8 ompt_flush_trace_t . . . . . . . . . . . . . . . . . . . . . . . . 525
4.6.2.9 ompt_stop_trace_t . . . . . . . . . . . . . . . . . . . . . . . . . 526
4.6.2.10 ompt_advance_buffer_cursor_t . . . . . . . . . . . . . . . . 527
4.6.2.11 ompt_get_record_type_t . . . . . . . . . . . . . . . . . . . . . 528
4.6.2.12 ompt_get_record_ompt_t . . . . . . . . . . . . . . . . . . . . . 529
4.6.2.13 ompt_get_record_native_t . . . . . . . . . . . . . . . . . . . 530
4.6.2.14 ompt_get_record_abstract_t . . . . . . . . . . . . . . . . . . 531
4.6.3 Lookup Entry Points: ompt_function_lookup_t . . . . . . . . . . . 531
5 OMPD Interface 533
5.1 OMPD Interfaces Deﬁnitions . . . . . . . . . . . . . . . . . . . . . . . . . . . . 534
5.2 Activating an OMPD Tool . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 534
5.2.1 Enabling the Runtime for OMPD . . . . . . . . . . . . . . . . . . . . . . . 534
5.2.2 ompd_dll_locations . . . . . . . . . . . . . . . . . . . . . . . . . . 535
5.2.3 ompd_dll_locations_valid . . . . . . . . . . . . . . . . . . . . . . 536
5.3 OMPD Data Types . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 536
5.3.1 Size Type . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 536
5.3.2 Wait ID Type . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 537
5.3.3 Basic Value Types . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 537
5.3.4 Address Type . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 538
5.3.5 Frame Information Type . . . . . . . . . . . . . . . . . . . . . . . . . . . . 538
5.3.6 System Device Identiﬁers . . . . . . . . . . . . . . . . . . . . . . . . . . . 539
5.3.7 Native Thread Identiﬁers . . . . . . . . . . . . . . . . . . . . . . . . . . . . 539
5.3.8 OMPD Handle Types . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 540
5.3.9 OMPD Scope Types . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 541
5.3.10 ICV ID Type . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 542
xiiOpenMP API – Version 5.0 November 2018
5.3.11 Tool Context Types . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 542
5.3.12 Return Code Types . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 543
5.3.13 Primitive Type Sizes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 544
5.4 OMPD Tool Callback Interface . . . . . . . . . . . . . . . . . . . . . . . . . . . 545
5.4.1 Memory Management of OMPD Library . . . . . . . . . . . . . . . . . . . 545
5.4.1.1 ompd_callback_memory_alloc_fn_t . . . . . . . . . . . . . . 546
5.4.1.2 ompd_callback_memory_free_fn_t . . . . . . . . . . . . . . . 546
5.4.2 Context Management and Navigation . . . . . . . . . . . . . . . . . . . . . 547
5.4.2.1 ompd_callback_get_thread_context_for_thread_id
_fn_t. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 547
5.4.2.2 ompd_callback_sizeof_fn_t . . . . . . . . . . . . . . . . . . . 549
5.4.3 Accessing Memory in the OpenMP Program or Runtime . . . . . . . . . . . 549
5.4.3.1 ompd_callback_symbol_addr_fn_t . . . . . . . . . . . . . . . 550
5.4.3.2 ompd_callback_memory_read_fn_t . . . . . . . . . . . . . . . 551
5.4.3.3 ompd_callback_memory_write_fn_t . . . . . . . . . . . . . . 553
5.4.4 Data Format Conversion: ompd_callback_device_host_fn_t . . . 554
5.4.5 Output: ompd_callback_print_string_fn_t . . . . . . . . . . . . 556
5.4.6 The Callback Interface . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 556
5.5 OMPD Tool Interface Routines . . . . . . . . . . . . . . . . . . . . . . . . . . . 558
5.5.1 Per OMPD Library Initialization and Finalization . . . . . . . . . . . . . . 558
5.5.1.1 ompd_initialize . . . . . . . . . . . . . . . . . . . . . . . . . . . 558
5.5.1.2 ompd_get_api_version . . . . . . . . . . . . . . . . . . . . . . . 559
5.5.1.3 ompd_get_version_string . . . . . . . . . . . . . . . . . . . . 560
5.5.1.4 ompd_finalize . . . . . . . . . . . . . . . . . . . . . . . . . . . . 561
5.5.2 Per OpenMP Process Initialization and Finalization . . . . . . . . . . . . . 562
5.5.2.1 ompd_process_initialize . . . . . . . . . . . . . . . . . . . . 562
5.5.2.2 ompd_device_initialize . . . . . . . . . . . . . . . . . . . . . 563
5.5.2.3 ompd_rel_address_space_handle . . . . . . . . . . . . . . . 564
5.5.3 Thread and Signal Safety . . . . . . . . . . . . . . . . . . . . . . . . . . . 565
5.5.4 Address Space Information . . . . . . . . . . . . . . . . . . . . . . . . . . 565
5.5.4.1 ompd_get_omp_version . . . . . . . . . . . . . . . . . . . . . . . 565
5.5.4.2 ompd_get_omp_version_string . . . . . . . . . . . . . . . . . 566
Contents xiii
5.5.5 Thread Handles . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 567
5.5.5.1 ompd_get_thread_in_parallel . . . . . . . . . . . . . . . . . 567
5.5.5.2 ompd_get_thread_handle . . . . . . . . . . . . . . . . . . . . . 568
5.5.5.3 ompd_rel_thread_handle . . . . . . . . . . . . . . . . . . . . . 569
5.5.5.4 ompd_thread_handle_compare . . . . . . . . . . . . . . . . . . 570
5.5.5.5 ompd_get_thread_id . . . . . . . . . . . . . . . . . . . . . . . . 570
5.5.6 Parallel Region Handles . . . . . . . . . . . . . . . . . . . . . . . . . . . . 571
5.5.6.1 ompd_get_curr_parallel_handle . . . . . . . . . . . . . . . 571
5.5.6.2 ompd_get_enclosing_parallel_handle . . . . . . . . . . . 572
5.5.6.3 ompd_get_task_parallel_handle . . . . . . . . . . . . . . . 573
5.5.6.4 ompd_rel_parallel_handle . . . . . . . . . . . . . . . . . . . 574
5.5.6.5 ompd_parallel_handle_compare . . . . . . . . . . . . . . . . 575
5.5.7 Task Handles . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 576
5.5.7.1 ompd_get_curr_task_handle . . . . . . . . . . . . . . . . . . . 576
5.5.7.2 ompd_get_generating_task_handle . . . . . . . . . . . . . . 577
5.5.7.3 ompd_get_scheduling_task_handle . . . . . . . . . . . . . . 578
5.5.7.4 ompd_get_task_in_parallel . . . . . . . . . . . . . . . . . . . 579
5.5.7.5 ompd_rel_task_handle . . . . . . . . . . . . . . . . . . . . . . . 580
5.5.7.6 ompd_task_handle_compare . . . . . . . . . . . . . . . . . . . 580
5.5.7.7 ompd_get_task_function . . . . . . . . . . . . . . . . . . . . . 581
5.5.7.8 ompd_get_task_frame . . . . . . . . . . . . . . . . . . . . . . . 582
5.5.7.9 ompd_enumerate_states . . . . . . . . . . . . . . . . . . . . . . 583
5.5.7.10 ompd_get_state . . . . . . . . . . . . . . . . . . . . . . . . . . . 585
5.5.8 Display Control Variables . . . . . . . . . . . . . . . . . . . . . . . . . . . 586
5.5.8.1 ompd_get_display_control_vars . . . . . . . . . . . . . . . 586
5.5.8.2 ompd_rel_display_control_vars . . . . . . . . . . . . . . . 587
5.5.9 Accessing Scope-Speciﬁc Information . . . . . . . . . . . . . . . . . . . . 588
5.5.9.1 ompd_enumerate_icvs . . . . . . . . . . . . . . . . . . . . . . . 588
5.5.9.2 ompd_get_icv_from_scope . . . . . . . . . . . . . . . . . . . . 590
5.5.9.3 ompd_get_icv_string_from_scope . . . . . . . . . . . . . . . 591
5.5.9.4 ompd_get_tool_data . . . . . . . . . . . . . . . . . . . . . . . . 592
5.6 Runtime Entry Points for OMPD . . . . . . . . . . . . . . . . . . . . . . . . . . 594
5.6.1 Beginning Parallel Regions . . . . . . . . . . . . . . . . . . . . . . . . . . 594
xivOpenMP API – Version 5.0 November 2018
5.6.2 Ending Parallel Regions . . . . . . . . . . . . . . . . . . . . . . . . . . . . 595
5.6.3 Beginning Task Regions . . . . . . . . . . . . . . . . . . . . . . . . . . . . 595
5.6.4 Ending Task Regions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 596
5.6.5 Beginning OpenMP Threads . . . . . . . . . . . . . . . . . . . . . . . . . . 597
5.6.6 Ending OpenMP Threads . . . . . . . . . . . . . . . . . . . . . . . . . . . 597
5.6.7 Initializing OpenMP Devices . . . . . . . . . . . . . . . . . . . . . . . . . 598
5.6.8 Finalizing OpenMP Devices . . . . . . . . . . . . . . . . . . . . . . . . . . 599
6 Environment Variables 601
6.1 OMP_SCHEDULE . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 601
6.2 OMP_NUM_THREADS . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 602
6.3 OMP_DYNAMIC . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 603
6.4 OMP_PROC_BIND . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 604
6.5 OMP_PLACES . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 605
6.6 OMP_STACKSIZE . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 607
6.7 OMP_WAIT_POLICY . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 608
6.8 OMP_MAX_ACTIVE_LEVELS . . . . . . . . . . . . . . . . . . . . . . . . . . . 608
6.9 OMP_NESTED . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 609
6.10 OMP_THREAD_LIMIT . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 610
6.11 OMP_CANCELLATION . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 610
6.12 OMP_DISPLAY_ENV . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 611
6.13 OMP_DISPLAY_AFFINITY . . . . . . . . . . . . . . . . . . . . . . . . . . . . 612
6.14 OMP_AFFINITY_FORMAT . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 613
6.15 OMP_DEFAULT_DEVICE . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 615
6.16 OMP_MAX_TASK_PRIORITY . . . . . . . . . . . . . . . . . . . . . . . . . . . 615
6.17 OMP_TARGET_OFFLOAD . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 615
6.18 OMP_TOOL . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 616
6.19 OMP_TOOL_LIBRARIES . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 617
6.20 OMP_DEBUG . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 617
6.21 OMP_ALLOCATOR . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 618
A OpenMP Implementation-Deﬁned Behaviors 619
B Features History 627
B.1 Deprecated Features . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 627
Contents xv
B.2 Version 4.5 to 5.0 Diﬀerences . . . . . . . . . . . . . . . . . . . . . . . . . . . . 627
B.3 Version 4.0 to 4.5 Diﬀerences . . . . . . . . . . . . . . . . . . . . . . . . . . . . 631
B.4 Version 3.1 to 4.0 Diﬀerences . . . . . . . . . . . . . . . . . . . . . . . . . . . . 633
B.5 Version 3.0 to 3.1 Diﬀerences . . . . . . . . . . . . . . . . . . . . . . . . . . . . 634
B.6 Version 2.5 to 3.0 Diﬀerences . . . . . . . . . . . . . . . . . . . . . . . . . . . . 635
Index 639
xviOpenMP API – Version 5.0 November 2018
List of Figures
2.1 Determining the schedule for a Worksharing-Loop . . . . . . . . . . . . . . . . 109
4.1 First-Party Tool Activation Flow Chart . . . . . . . . . . . . . . . . . . . . . . . . 422
xvii
List of Tables
1.1 Map-Type Decay of Map Type Combinations . . . . . . . . . . . . . . . . . . . . 16
2.1 ICV Initial Values . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 66
2.2 Ways to Modify and to Retrieve ICV Values . . . . . . . . . . . . . . . . . . . . . 68
2.3 Scopes of ICVs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 70
2.4 ICV Override Relationships . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 72
2.5 schedule ClausekindValues . . . . . . . . . . . . . . . . . . . . . . . . . . . 104
2.6 schedule ClausemodiﬁerValues . . . . . . . . . . . . . . . . . . . . . . . . . 106
2.7 ompt_callback_task_create callback ﬂags evaluation . . . . . . . . . . . 139
2.8 Predeﬁned Memory Spaces . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 152
2.9 Allocator Traits . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 153
2.10 Predeﬁned Allocators . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 155
2.11 Implicitly Declared C/C++ reduction-identiﬁers . . . . . . . . . . . . . . . . . . . 294
2.12 Implicitly Declared Fortran reduction-identiﬁers . . . . . . . . . . . . . . . . . . . 295
3.1 Standard Tool Control Commands . . . . . . . . . . . . . . . . . . . . . . . . . . 417
4.1 OMPT Callback Interface Runtime Entry Point Names and Their Type Signatures . 426
4.2 Valid Return Codes of ompt_set_callback for Each Callback . . . . . . . . . 428
4.3 OMPT Tracing Interface Runtime Entry Point Names and Their Type Signatures . . 430
5.1 Mapping of Scope Type and OMPD Handles . . . . . . . . . . . . . . . . . . . . 542
5.2 OMPD-speciﬁc ICVs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 589
6.1 Deﬁned Abstract Names for OMP_PLACES . . . . . . . . . . . . . . . . . . . . . 605
6.2 Available Field Types for Formatting OpenMP Thread Aﬃnity Information . . . . 613
xviii
CHAPTER 1
Introduction 1
2
The collection of compiler directives, library routines, and environment variables described in this 3
document collectively deﬁne the speciﬁcation of the OpenMP Application Program Interface 4
(OpenMP API) for parallelism in C, C++ and Fortran programs. 5
This speciﬁcation provides a model for parallel programming that is portable across architectures 6
from diﬀerent vendors. Compilers from numerous vendors support the OpenMP API. More 7
information about the OpenMP API can be found at the following web site 8
http://www.openmp.org 9
The directives, library routines, environment variables, and tool support deﬁned in this document 10
allow users to create, to manage, to debug and to analyze parallel programs while permitting 11
portability. The directives extend the C, C++ and Fortran base languages with single program 12
multipledata(SPMD)constructs,taskingconstructs,deviceconstructs,worksharingconstructs,and 13
synchronization constructs, and they provide support for sharing, mapping and privatizing data. 14
The functionality to control the runtime environment is provided by library routines and 15
environment variables. Compilers that support the OpenMP API often include a command line 16
option to the compiler that activates and allows interpretation of all OpenMP directives. 17
1.1 Scope 18
The OpenMP API covers only user-directed parallelization, wherein the programmer explicitly 19
speciﬁestheactionstobetakenbythecompilerandruntimesysteminordertoexecutetheprogram 20
in parallel. OpenMP-compliant implementations are not required to check for data dependencies, 21
data conﬂicts, race conditions, or deadlocks, any of which may occur in conforming programs. In 22
addition, compliant implementations are not required to check for code sequences that cause a 23
program to be classiﬁed as non-conforming. Application developers are responsible for correctly 24
1
using the OpenMP API to produce a conforming program. The OpenMP API does not cover 1
compiler-generated automatic parallelization. 2
1.2 Glossary3
1.2.1 Threading Concepts4
thread An execution entity with a stack and associated static memory, called threadprivate 5
memory. 6
OpenMP thread Athreadthat is managed by the OpenMP implementation. 7
thread number A number that the OpenMP implementation assigns to an OpenMP thread. For 8
threads within the same team, zero identiﬁes the master thread and consecutive 9
numbers identify the other threads of this team. 10
idle thread AnOpenMP thread that is not currently part of any parallel region. 11
thread-safe routine A routine that performs the intended function even when executed concurrently (by 12
more than one thread). 13
processor Implementation-deﬁned hardware unit on which one or more OpenMP threads can 14
execute. 15
deviceAn implementation-deﬁned logical execution engine. 16
COMMENT: A devicecould have one or more processors . 17
host device Thedeviceon which the OpenMP program begins execution. 18
target device A device onto which code and data may be oﬄoaded from the host device . 19
parent device For a given target region, the device on which the corresponding target 20
construct was encountered. 21
1.2.2 OpenMP Language Terminology 22
base language A programming language that serves as the foundation of the OpenMP speciﬁcation. 23
COMMENT: See Section 1.7 on page 31 for a listing of current base 24
languages for the OpenMP API. 25
2OpenMP API – Version 5.0 November 2018
base program A program written in a base language . 1
program order An ordering of operations performed by the same thread as determined by the 2
execution sequence of operations speciﬁed by the base language . 3
COMMENT: For C11 and C++11, program order corresponds to the 4
sequenced before relation between operations performed by the same 5
thread. 6
structured block For C/C++, an executable statement, possibly compound, with a single entry at the 7
top and a single exit at the bottom, or an OpenMP construct. 8
For Fortran, a block of executable statements with a single entry at the top and a 9
single exit at the bottom, or an OpenMP construct. 10
COMMENT: See Section 2.1 on page 38 for restrictions on structured 11
blocks. 12
compilation unit For C/C++, a translation unit. 13
For Fortran, a program unit. 14
enclosing context For C/C++, the innermost scope enclosing an OpenMP directive. 15
For Fortran, the innermost scoping unit enclosing an OpenMP directive. 16
directive For C/C++, a #pragma , and for Fortran, a comment, that speciﬁes OpenMP 17
programbehavior. 18
COMMENT: See Section 2.1 on page 38 for a description of OpenMP 19
directivesyntax. 20
metadirective Adirectivethat conditionally resolves to another directiveat compile time. 21
white space A non-empty sequence of space and/or horizontal tab characters. 22
OpenMP program A program that consists of a base program that is annotated with OpenMP directives 23
or that calls OpenMP API runtime library routines 24
conforming program AnOpenMP program that follows all rules and restrictions of the OpenMP 25
speciﬁcation. 26
declarative directive An OpenMP directivethat may only be placed in a declarative context. A declarative 27
directiveresults in one or more declarations only; it is not associated with the 28
immediate execution of any user code. 29
executable directive An OpenMP directivethat is not declarative. That is, it may be placed in an 30
executable context. 31
stand-alone directive An OpenMP executable directive that has no associated user code except for that 32
which appears in clauses in the directive. 33
CHAPTER 1. INTRODUCTION 3
construct An OpenMP executable directive (and for Fortran, the paired enddirective, if any) 1
and the associated statement, loop or structured block , if any, not including the code 2
in any called routines. That is, the lexical extent of an executable directive . 3
combined construct A construct that is a shortcut for specifying one construct immediately nested inside 4
anotherconstruct. Acombinedconstructissemanticallyidenticaltothatofexplicitly 5
specifying the ﬁrst construct containing one instance of the second construct and no 6
other statements. 7
composite construct A construct that is composed of two constructs but does not have identical semantics 8
to specifying one of the constructs immediately nested inside the other. A composite 9
construct either adds semantics not included in the constructs from which it is 10
composed or the nesting of the one construct inside the other is not conforming. 11
combined target
constructAcombined construct that is composed of a target construct along with another 12
construct. 13
regionAll code encountered during a speciﬁc instance of the execution of a given construct 14
or of an OpenMP library routine. A regionincludes any code in called routines as 15
wellasanyimplicitcodeintroducedbytheOpenMPimplementation. Thegeneration 16
of ataskat the point where a task generating construct is encountered is a part of the 17
regionof theencountering thread . However, an explicit task region corresponding to 18
ataskgeneratingconstruct isnotpartofthe regionoftheencounteringthread unless 19
it is anincluded task region . The point where a target orteamsdirective is 20
encountered is a part of the regionof theencountering thread , but theregion 21
corresponding to the target orteamsdirective is not. 22
COMMENTS: 23
Aregionmay also be thought of as the dynamic or runtime extent of a 24
construct or of an OpenMP library routine. 25
Duringtheexecutionofan OpenMPprogram ,aconstruct maygiveriseto 26
manyregions. 27
active parallel region Aparallel regionthat is executed by a teamconsisting of more than one thread. 28
inactive parallel region Aparallel regionthat is executed by a teamof only one thread. 29
active target region Atarget regionthat is executed on a deviceother than the devicethat encountered 30
thetarget construct. 31
inactive target region Atarget regionthat is executed on the same devicethat encountered the target 32
construct. 33
4OpenMP API – Version 5.0 November 2018
sequential part All code encountered during the execution of an initial task region that is not part of 1
aparallel regioncorresponding to a parallel construct or ataskregion 2
corresponding to a taskconstruct. 3
COMMENTS: 4
Asequential part is enclosed by an implicit parallel region . 5
Executable statements in called routines may be in both a sequential part 6
and any number of explicit parallel regionsat diﬀerent points in the 7
program execution. 8
master thread AnOpenMP thread that hasthreadnumber 0. A master thread may be an initial 9
threador thethreadthat encounters a parallel construct, creates a team, 10
generates a set of implicit tasks , and then executes one of those tasksasthread 11
number 0. 12
parent thread Thethreadthat encountered the parallel construct and generated a parallel 13
regionis theparent thread of each of the threadsin theteamof that parallel 14
region. Themaster thread of aparallel regionis the same threadas itsparent 15
threadwith respect to any resources associated with an OpenMP thread . 16
child thread When a thread encounters a parallel construct, each of the threads in the 17
generated parallel region’s team are child threads of the encountering thread. 18
Thetarget orteamsregion’sinitial thread is not achild thread of the thread that 19
encountered the target orteamsconstruct. 20
ancestor thread For a given thread, itsparent thread or one of its parent thread’s ancestor threads . 21
descendent thread For a given thread, one of its child threads or one of its child threads’ descendent 22
threads. 23
teamA set of one or more threadsparticipating in the execution of a parallel region. 24
COMMENTS: 25
For anactive parallel region , the team comprises the master thread and at 26
least one additional thread. 27
Foraninactiveparallelregion ,theteamcomprisesonlythe masterthread . 28
leagueThe set of teamscreated by a teamsconstruct. 29
contention group An initial threadand itsdescendent threads . 30
implicit parallel region Aninactive parallel region that is not generated from a parallel construct. 31
Implicitparallelregions surroundthewhole OpenMPprogram ,alltarget regions, 32
and all teamsregions. 33
initial thread Thethreadthat executes an implicit parallel region . 34
CHAPTER 1. INTRODUCTION 5
initial team Theteamthat comprises an initial thread executing an implicit parallel region . 1
nested construct Aconstruct (lexically) enclosed by another construct. 2
closely nested construct Aconstruct nested inside another construct with no other construct nested between 3
them. 4
nested region Aregion(dynamically) enclosed by another region. That is, a regiongenerated from 5
the execution of another regionor one of its nested regions . 6
COMMENT: Some nestings are conforming and some are not. See 7
Section 2.20 on page 328 for the restrictions on nesting. 8
closely nested region Aregion nested inside another regionwith no parallel region nested between 9
them. 10
strictly nested region Aregion nested inside another regionwith no other region nested between them. 11
all threads All OpenMP threadsparticipating in the OpenMP program . 12
current team Allthreadsin theteamexecuting the innermost enclosing parallel region. 13
encountering thread For a given region, thethreadthat encounters the corresponding construct. 14
all tasks Alltasksparticipating in the OpenMP program . 15
current team tasks Alltasksencountered by the corresponding team. Theimplicit tasks constituting the 16
parallel regionand anydescendent tasks encountered during the execution of 17
theseimplicit tasks are included in this set of tasks. 18
generating task For a given region, the task for which execution by a threadgenerated the region. 19
binding thread set The set of threadsthat are aﬀected by, or provide the context for, the execution of a 20
region. 21
Thebinding thread set for a given regioncan beall threads on adevice,all threads 22
in acontention group , allmaster threads executing an enclosing teamsregion, the 23
current team , or theencountering thread . 24
COMMENT:The bindingthreadset foraparticular regionisdescribedin 25
its corresponding subsection of this speciﬁcation. 26
binding task set The set of tasksthat are aﬀected by, or provide the context for, the execution of a 27
region. 28
Thebinding task set for a given regioncan beall tasks, thecurrent team tasks ,all 29
tasksofthecurrentteamthataregeneratedintheregion ,thebindingimplicittask ,or 30
thegenerating task . 31
COMMENT: The binding task set for a particular region(if applicable) is 32
described in its corresponding subsection of this speciﬁcation. 33
6OpenMP API – Version 5.0 November 2018
binding region The enclosing regionthat determines the execution context and limits the scope of 1
the eﬀects of the bound regionis called the binding region . 2
Binding region is not deﬁned for regionsfor which the binding thread set isall 3
threadsor theencountering thread , nor is it deﬁned for regionsfor which the binding 4
task setisall tasks. 5
COMMENTS: 6
Thebinding region for an ordered regionis the innermost enclosing 7
loop region . 8
Thebinding region for ataskwait regionis the innermost enclosing 9
task region . 10
Thebinding region for acancel regionis the innermost enclosing 11
regioncorresponding to the construct-type-clause of the cancel 12
construct. 13
Thebinding region for acancellation point regionis the 14
innermost enclosing regioncorresponding to the construct-type-clause of 15
thecancellation point construct. 16
For all other regionsfor which the binding thread set is thecurrent team 17
or thebinding task set is thecurrent team tasks , thebinding region is the 18
innermost enclosing parallel region. 19
Forregionsfor which the binding task set is thegenerating task , the 20
binding region is theregionof thegenerating task . 21
Aparallel regionneed not be activenor explicit to be a binding 22
region. 23
Atask region need not be explicit to be a binding region . 24
Aregionnever binds to any regionoutside of the innermost enclosing 25
parallel region. 26
orphaned construct Aconstruct that gives rise to a regionfor which the binding thread set is thecurrent 27
team, but is not nested within another construct giving rise to the binding region . 28
worksharing construct Aconstruct that deﬁnes units of work, each of which is executed exactly once by one 29
of thethreadsin theteamexecuting the construct. 30
For C/C++, worksharing constructs arefor,sections , andsingle. 31
For Fortran, worksharing constructs aredo,sections ,single and 32
workshare . 33
device construct An OpenMP construct that accepts the device clause. 34
CHAPTER 1. INTRODUCTION 7
device routine A function (for C/C+ and Fortran) or subroutine (for Fortran) that can be executed on 1
atarget device , as part of a target region. 2
placeAn unordered set of processors on a device. 3
place list The ordered list that describes all OpenMP placesavailable to the execution 4
environment. 5
place partition An ordered list that corresponds to a contiguous interval in the OpenMP place list. It 6
describes the placescurrently available to the execution environment for a given 7
parallelregion. 8
place number A number that uniquely identiﬁes a placein theplace list, with zero identifying the 9
ﬁrstplacein theplace list, and each consecutive whole number identifying the next 10
placein theplace list. 11
thread aﬃnity A binding of threadstoplaceswithin the current place partition . 12
SIMD instruction A single machine instruction that can operate on multiple data elements. 13
SIMD lane A software or hardware mechanism capable of processing one data element from a 14
SIMD instruction . 15
SIMD chunk A set of iterations executed concurrently, each by a SIMD lane , by a single threadby 16
means of SIMD instructions . 17
memory A storage resource to store and to retrieve variables accessible by OpenMP threads. 18
memory space A representation of storage resources from which memorycan be allocated or 19
deallocated. More than one memory space may exist. 20
memory allocator An OpenMP object that fulﬁlls requests to allocate and to deallocate memoryfor 21
program variables from the storage resources of its associated memory space . 22
handle An opaque reference that uniquely identiﬁes an abstraction. 23
1.2.3 Loop Terminology 24
loop-associated
directiveAn OpenMP executable directive for which the associated user code must be a loop 25
nest that is a structured block . 26
associated loop(s) The loop(s) controlled by a loop-associated directive . 27
COMMENT: If the loop-associated directive contains a collapse or an 28
ordered( n)clause then it may have more than one associated loop . 29
sequential loop A loop that is not associated with any OpenMP loop-associated directive . 30
8OpenMP API – Version 5.0 November 2018
SIMD loop A loop that includes at least one SIMD chunk . 1
non-rectangular loop
nestAloopnestforwhichtheiterationcountofaloopinsidetheloopnestisthenotsame 2
for all occurrences of the loop in the loop nest. 3
doacross loop nest A loop nest that has cross-iteration dependence. An iteration is dependent on one or 4
more lexicographically earlier iterations. 5
COMMENT: The ordered clause parameter on a worksharing-loop 6
directive identiﬁes the loop(s) associated with the doacross loop nest . 7
1.2.4 Synchronization Terminology8
barrier A point in the execution of a program encountered by a teamofthreads, beyond 9
which no threadin the team may execute until all threadsin theteamhave reached 10
the barrier and all explicit tasks generated by the teamhave executed to completion. 11
Ifcancellation has been requested, threads may proceed to the end of the canceled 12
regioneven if some threads in the team have not reached the barrier. 13
cancellation An action that cancels (that is, aborts) an OpenMP regionand causes executing 14
implicitorexplicittasks to proceed to the end of the canceled region. 15
cancellation point A point at which implicit and explicit tasks check if cancellation has been requested. 16
If cancellation has been observed, they perform the cancellation . 17
COMMENT: For a list of cancellation points, see Section 2.18.1 on 18
page 263. 19
ﬂushAn operation that a threadperforms to enforce consistency between its view and 20
otherthreads’ view of memory. 21
ﬂush property Properties that determine the manner in which a ﬂushoperation enforces memory 22
consistency. These properties are: 23
strong: ﬂushes a set of variables from the current thread’s temporary view of the 24
memory to the memory; 25
release: orders memory operations that precede the ﬂush before memory 26
operations performed by a diﬀerent thread with which it synchronizes; 27
acquire: orders memory operations that follow the ﬂush after memory operations 28
performed by a diﬀerent thread that synchronizes with it. 29
COMMENT: Any ﬂushoperation has one or more ﬂush properties . 30
strong ﬂush Aﬂushoperation that has the strong ﬂush property . 31
CHAPTER 1. INTRODUCTION 9
release ﬂush Aﬂushoperation that has the release ﬂush property . 1
acquire ﬂush Aﬂushoperation that has the acquire ﬂush property . 2
atomic operation An operation that is speciﬁed by an atomic construct and atomically accesses 3
and/or modiﬁes a speciﬁc storage location. 4
atomic read Anatomic operation that is speciﬁed by an atomic construct on which the read 5
clause is present. 6
atomic write Anatomic operation that is speciﬁed by an atomic construct on which the write 7
clause is present. 8
atomic update Anatomic operation that is speciﬁed by an atomic construct on which the 9
update clause is present. 10
atomic captured
updateAnatomic operation that is speciﬁed by an atomic construct on which the 11
capture clause is present. 12
read-modify-write Anatomic operation that reads and writes to a given storage location. 13
COMMENT: All atomic update andatomic captured update operations 14
areread-modify-write operations. 15
sequentially consistent
atomic constructAnatomic construct for which the seq_cst clause is speciﬁed. 16
non-sequentially
consistent atomic
constructAnatomic construct for which the seq_cst clause is not speciﬁed 17
sequentially consistent
atomic operationAnatomic operation that is speciﬁed by a sequentially consistent atomic construct . 18
1.2.5 Tasking Terminology 19
taskA speciﬁc instance of executable code and its data environment that the OpenMP 20
implementation can schedule for execution by threads. 21
task region Aregionconsisting of all code encountered during the execution of a task. 22
COMMENT: A parallel regionconsists of one or more implicit task 23
regions. 24
implicit task Ataskgenerated by an implicit parallel region or generated when a parallel 25
construct is encountered during execution. 26
10OpenMP API – Version 5.0 November 2018
binding implicit task Theimplicit task of the current thread team assigned to the encountering thread. 1
explicit task Ataskthat is not an implicit task . 2
initial task Animplicit task associated with an implicit parallel region . 3
current task For a given thread, thetaskcorresponding to the task region in which it is executing. 4
child task Ataskis achild task of its generating task region . Achild task region is not part of 5
its generating task region . 6
sibling tasks Tasksthat arechild tasks of the same task region . 7
descendent task Ataskthat is the child task of atask region or of one of its descendent task regions . 8
task completion Task completion occurs when the end of the structured block associated with the 9
construct that generated the taskis reached. 10
COMMENT: Completion of the initial task that is generated when the 11
program begins occurs at program exit. 12
task scheduling point A point during the execution of the current task region at which it can be suspended 13
to be resumed later; or the point of task completion , after which the executing thread 14
may switch to a diﬀerent task region . 15
COMMENT: For a list of task scheduling points , see Section 2.10.6 on 16
page 149. 17
task switching The act of a threadswitching from the execution of one taskto another task. 18
tied task Ataskthat, when its task region is suspended, can be resumed only by the same 19
threadthat suspended it. That is, the taskis tied to that thread. 20
untied task Ataskthat, when its task region is suspended, can be resumed by any threadin the 21
team. That is, the taskis not tied to any thread. 22
undeferred task Ataskfor which execution is not deferred with respect to its generating task region . 23
Thatis,itsgenerating task region issuspendeduntilexecutionofthestructuredblock 24
associated with the undeferred task is completed. 25
included task Ataskfor which execution is sequentially included in the generating task region . 26
That is, an included task isundeferred and executed by the encountering thread . 27
merged task Ataskfor which the data environment , inclusive of ICVs, is the same as that of its 28
generating task region . 29
mergeable task Ataskthat may be a merged task if it is an undeferred task or anincluded task . 30
ﬁnal task Ataskthat forces all of its child tasks to become ﬁnalandincluded tasks . 31
CHAPTER 1. INTRODUCTION 11
task dependence An ordering relation between two sibling tasks : thedependent task and a previously 1
generated predecessor task . Thetask dependence is fulﬁlled when the predecessor 2
taskhas completed. 3
dependent task Ataskthat because of a task dependence cannot be executed until its predecessor 4
taskshave completed. 5
mutually exclusive
tasksTasksthat may be executed in any order, but not at the same time. 6
predecessor task Ataskthat must complete before its dependent tasks can be executed. 7
task synchronization
constructAtaskwait ,taskgroup , or a barrier construct. 8
task generating
constructAconstruct that generates one or more explicit tasks . 9
target task Amergeable anduntied task that is generated by a target,target enter 10
data,target exit data , ortarget update construct. 11
taskgroup set A set of tasks that are logically grouped by a taskgroup region. 12
1.2.6 Data Terminology 13
variable A named data storage block, for which the value can be deﬁned and redeﬁned during 14
the execution of a program. 15
COMMENT: An array element or structure element is a variable that is 16
part of another variable. 17
scalar variable For C/C++, a scalar variable, as deﬁned by the base language. 18
For Fortran, a scalar variable with intrinsic type, as deﬁned by the base language, 19
excluding character type. 20
aggregate variable A variable, such as an array or structure, composed of other variables. 21
array section A designated subset of the elements of an array that is speciﬁed using a subscript 22
notation that can select more than one element. 23
array item An array, an array section, or an array element. 24
shape-operator For C/C++, an array shaping operator that reinterprets a pointer expression as an 25
array with one or more speciﬁed dimensions. 26
12OpenMP API – Version 5.0 November 2018
implicit array For C/C++, the set of array elements of non-array type Tthat may be accessed by 1
applyingasequenceof[]operatorstoagivenpointerthatiseitherapointertotype T 2
or a pointer to a multidimensional array of elements of type T. 3
For Fortran, the set of array elements for a given array pointer. 4
COMMENT: For C/C++, the implicit array for pointer p with type T 5
(*)[10] consists of all accessible elements p[ i][j], for alliandj=0..9. 6
base pointer For C/C++, an lvalue pointer expression that is used by a given lvalue expression or 7
array section to refer indirectly to its storage, where the lvalue expression or array 8
section is part of the implicit array for that lvalue pointer expression. 9
For Fortran, a data pointer that appears last in the designator for a given variable or 10
array section, where the variable or array section is part of the pointer target for that 11
data pointer. 12
COMMENT: For the array section 13
(*p0).x0[k1].p1->p2[k2].x1[k3].x2[4][0:n], where identiﬁers p ihave a 14
pointer type declaration and identiﬁers x ihave an array type declaration, 15
thebase pointer is: (*p0).x0[k1].p1->p2. 16
named pointer For C/C++, the base pointer of a given lvalue expression or array section, or the base 17
pointerof one of its named pointers . 18
For Fortran, the base pointer of a given variable or array section, or the base pointer 19
of one of its named pointers . 20
COMMENT: For the array section 21
(*p0).x0[k1].p1->p2[k2].x1[k3].x2[4][0:n], where identiﬁers p ihave a 22
pointer type declaration and identiﬁers x ihave an array type declaration, 23
thenamed pointers are: p0, (*p0).x0[k1].p1, and (*p0).x0[k1].p1->p2. 24
containing array For C/C++, a non-subscripted array (a containing array ) that appears in a given 25
lvalueexpressionorarraysection,wherethelvalueexpressionorarraysectionispart 26
of thatcontaining array . 27
For Fortran, an array (a containing array ) without the POINTER attribute and 28
without a subscript list that appears in the designator of a given variable or array 29
section, where the variable or array section is part of that containing array . 30
COMMENT: For the array section 31
(*p0).x0[k1].p1->p2[k2].x1[k3].x2[4][0:n], where identiﬁers p ihave a 32
pointer type declaration and identiﬁers x ihave an array type declaration, 33
thecontaining arrays are: (*p0).x0[k1].p1->p2[k2].x1 and 34
(*p0).x0[k1].p1->p2[k2].x1[k3].x2. 35
CHAPTER 1. INTRODUCTION 13
base array For C/C++, a containing array of a given lvalue expression or array section that does 1
not appear in the expression of any of its other containing arrays . 2
For Fortran, a containing array of a given variable or array section that does not 3
appear in the designator of any of its other containing arrays . 4
COMMENT: For the array section 5
(*p0).x0[k1].p1->p2[k2].x1[k3].x2[4][0:n], where identiﬁers p ihave a 6
pointer type declaration and identiﬁers x ihave an array type declaration, 7
thebase array is: (*p0).x0[k1].p1->p2[k2].x1[k3].x2. 8
named array For C/C++, a containing array of a given lvalue expression or array section, or a 9
containing array of one of its named pointers . 10
For Fortran, a containing array of a given variable or array section, or a containing 11
arrayof one of its named pointers . 12
COMMENT: For the array section 13
(*p0).x0[k1].p1->p2[k2].x1[k3].x2[4][0:n], where identiﬁers p ihave a 14
pointer type declaration and identiﬁers x ihave an array type declaration, 15
thenamed arrays are: (*p0).x0, (*p0).x0[k1].p1->p2[k2].x1, and 16
(*p0).x0[k1].p1->p2[k2].x1[k3].x2. 17
base expression Thebase array of a given array section or array element, if it exists; otherwise, the 18
base pointer of the array section or array element. 19
COMMENT: For the array section 20
(*p0).x0[k1].p1->p2[k2].x1[k3].x2[4][0:n], where identiﬁers p ihave a 21
pointer type declaration and identiﬁers x ihave an array type declaration, 22
thebase expression is: (*p0).x0[k1].p1->p2[k2].x1[k3].x2. 23
More examples for C/C++: 24
Thebaseexpression forx[i]andforx[i:n]isx,ifxisanarrayorpointer. 25
Thebase expression for x[5][i] and for x[5][i:n] is x, if x is a pointer to 26
an array or x is 2-dimensional array. 27
Thebase expression for y[5][i] and for y[5][i:n] is y[5], if y is an array 28
of pointers or y is a pointer to a pointer. 29
Examples for Fortran: 30
Thebase expression for x(i) and for x(i:j) is x. 31
attached pointer A pointer variable in a device data environment to which the eﬀect of a mapclause 32
assigns the address of an object, minus some oﬀset, that is created in the device data 33
environment. The pointer is an attached pointer for the remainder of its lifetime in 34
the device data environment. 35
14OpenMP API – Version 5.0 November 2018
simply contiguous
array sectionAn array section that statically can be determined to have contiguous storage or that, 1
in Fortran, has the CONTIGUOUS attribute. 2
structure A structure is a variable that contains one or more variables. 3
For C/C++: Implemented using struct types. 4
For C++: Implemented using class types. 5
For Fortran: Implemented using derived types. 6
private variable With respect to a given set of task regions orSIMD lanes that bind to the same 7
parallel region, avariablefor which the name provides access to a diﬀerent 8
block of storage for each task region orSIMD lane . 9
Avariablethatispartofanothervariable(asanarrayorstructureelement)cannotbe 10
made private independently of other components. 11
shared variable Withrespecttoagivensetof taskregions thatbindtothesame parallel region,a 12
variablefor which the name provides access to the same block of storage for each 13
task region . 14
Avariablethatispartofanothervariable(asanarrayorstructureelement)cannotbe 15
sharedindependently of the other components, except for static data members of 16
C++ classes. 17
threadprivate variable Avariablethat is replicated, one instance per thread, by the OpenMP 18
implementation. Itsnamethenprovidesaccesstoadiﬀerentblockofstorageforeach 19
thread. 20
Avariablethatispartofanothervariable(asanarrayorstructureelement)cannotbe 21
madethreadprivate independently of the other components, except for static data 22
members of C++ classes. 23
threadprivate memory The set of threadprivate variables associated with each thread. 24
data environment Thevariables associated with the execution of a given region. 25
device data
environmentThe initial data environment associated with a device. 26
device address Animplementation-deﬁned reference to an address in a device data environment . 27
device pointer Avariablethat contains a device address . 28
mapped variable An original variablein adata environment with a corresponding variablein a device 29
data environment . 30
COMMENT:Theoriginalandcorresponding variables maysharestorage. 31
CHAPTER 1. INTRODUCTION 15
TABLE 1.1:Map-Type Decay of Map Type Combinations
alloc tofromtofrom release delete
alloc allocallocallocallocrelease delete
to alloc toalloc torelease delete
from allocallocfromfromrelease delete
tofrom alloc tofromtofrom release delete
map-type decay The process used to determine the ﬁnal map type when mapping a variable with a 1
user deﬁned mapper. Table 1.1 shows the ﬁnal map type that the combination of the 2
two map types determines. 3
mappable type A type that is valid for a mapped variable . If a type is composed from other types 4
(such as the type of an array or structure element) and any of the other types are not 5
mappable then the type is not mappable. 6
COMMENT: Pointer types are mappable but the memory block to which 7
the pointer refers is not mapped. 8
For C, the type must be a complete type. 9
For C++, the type must be a complete type. 10
In addition, for class types: 11
All member functions accessed in any target region must appear in a 12
declare target directive. 13
For Fortran, no restrictions on the type except that for derived types: 14
All type-bound procedures accessed in any target region must appear in a 15
declare target directive. 16
deﬁned Forvariables, the property of having a valid value. 17
For C, for the contents of variables, the property of having a valid value. 18
For C++, for the contents of variables of POD (plain old data) type, the property of 19
having a valid value. 20
Forvariables ofnon-PODclasstype,thepropertyofhavingbeenconstructedbutnot 21
subsequently destructed. 22
For Fortran, for the contents of variables, the property of having a valid value. For 23
the allocation or association status of variables, the property of having a valid status. 24
COMMENT: Programs that rely upon variables that are not deﬁnedare 25
non-conforming programs . 26
class type For C++, variables declared with one of the class,struct, orunionkeywords. 27
16OpenMP API – Version 5.0 November 2018
1.2.7 Implementation Terminology1
supporting nactive
levels of parallelismImplies allowing an active parallel region to be enclosed by n-1 active parallel 2
regions. 3
supporting the
OpenMP APISupporting at least one active level of parallelism. 4
supporting nested
parallelismSupporting more than one active level of parallelism. 5
internal control
variableA conceptual variable that speciﬁes runtime behavior of a set of threadsortasksin 6
anOpenMP program . 7
COMMENT: The acronym ICV is used interchangeably with the term 8
internal control variable in the remainder of this speciﬁcation. 9
compliant
implementationAn implementation of the OpenMP speciﬁcation that compiles and executes any 10
conforming program as deﬁned by the speciﬁcation. 11
COMMENT: A compliant implementation may exhibit unspeciﬁed 12
behavior when compiling or executing a non-conforming program . 13
unspeciﬁed behavior A behavior or result that is not speciﬁed by the OpenMP speciﬁcation or not known 14
prior to the compilation or execution of an OpenMP program . 15
Suchunspeciﬁed behavior may result from: 16
Issues documented by the OpenMP speciﬁcation as having unspeciﬁed behavior . 17
Anon-conforming program . 18
Aconforming program exhibiting an implementation-deﬁned behavior. 19
implementation deﬁned Behavior that must be documented by the implementation, and is allowed to vary 20
among diﬀerent compliant implementations . An implementation is allowed to deﬁne 21
this behavior as unspeciﬁed . 22
COMMENT: All features that have implementation-deﬁned behavior are 23
documented in Appendix A. 24
deprecated For a construct, clause, or other feature, the property that it is normative in the 25
current speciﬁcation but is considered obsolescent and will be removed in the future. 26
1.2.8 Tool Terminology 27
toolExecutable code, distinct from application or runtime code, that can observe and/or 28
modify the execution of an application. 29
CHAPTER 1. INTRODUCTION 17
ﬁrst-party tool A tool that executes in the address space of the program that it is monitoring. 1
third-party tool A tool that executes as a separate process from the process that it is monitoring and 2
potentially controlling. 3
activated tool Aﬁrst-party tool that successfully completed its initialization. 4
eventA point of interest in the execution of a thread. 5
native thread A thread deﬁned by an underlying thread implementation. 6
tool callback A function that a tool provides to an OpenMP implementation to invoke when an 7
associated event occurs. 8
registering a callback Providing a tool callback to an OpenMP implementation. 9
dispatching a callback
at an eventProcessing a callback when an associated eventoccurs in a manner consistent with 10
the return code provided when a ﬁrst-party tool registered the callback. 11
thread state An enumeration type that describes the current OpenMP activity of a thread. A 12
threadcan be in only one state at any time. 13
wait identiﬁer A unique opaque handle associated with each data object (for example, a lock) used 14
by the OpenMP runtime to enforce mutual exclusion that may cause a thread to wait 15
actively or passively. 16
frameA storage area on a thread’s stack associated with a procedure invocation. A frame 17
includesspaceforoneormoresavedregistersandoftenalsoincludesspaceforsaved 18
arguments, local variables, and padding for alignment. 19
canonical frame
addressAnaddressassociatedwithaprocedure frameonacallstackthatwasthevalueofthe 20
stack pointer immediately prior to calling the procedure for which the invocation is 21
represented by the frame. 22
runtime entry point A function interface provided by an OpenMP runtime for use by a tool. A runtime 23
entry point is typically not associated with a global function symbol. 24
trace record A data structure in which to store information associated with an occurrence of an 25
event. 26
native trace record Atrace record for an OpenMP device that is in a device-speciﬁc format. 27
signalA software interrupt delivered to a thread. 28
signal handler A function called asynchronously when a signalis delivered to a thread. 29
async signal safe The guarantee that interruption by signaldelivery will not interfere with a set of 30
operations. An async signal safe runtime entry point is safe to call from a signal 31
handler. 32
18OpenMP API – Version 5.0 November 2018
code block A contiguous region of memory that contains code of an OpenMP program to be 1
executed on a device. 2
OMPT An interface that helps a ﬁrst-party tool monitor the execution of an OpenMP 3
program. 4
OMPT interface state A state that indicates the permitted interactions between a ﬁrst-party tool and the 5
OpenMP implementation. 6
OMPT active AnOMPTinterfacestate inwhichtheOpenMPimplementationispreparedtoaccept 7
runtime calls from a ﬁrst party tool and it dispatches any registered callbacks and in 8
which a ﬁrst-party tool can invoke runtime entry points if not otherwise restricted. 9
OMPT pending AnOMPT interface state in which the OpenMP implementation can only call 10
functions to initialize a ﬁrst party tool and in which a ﬁrst-party tool cannot invoke 11
runtime entry points . 12
OMPT inactive AnOMPT interface state in which the OpenMP implementation will not make any 13
callbacks and in which a ﬁrst-party tool cannot invoke runtime entry points . 14
OMPD An interface that helps a third-party tool inspect the OpenMP state of a program that 15
has begun execution. 16
OMPD library A dynamically loadable library that implements the OMPDinterface. 17
image ﬁle An executable or shared library. 18
address space A collection of logical, virtual, or physical memory address ranges that contain code, 19
stack, and/or data. Address ranges within an address space need not be contiguous. 20
An address space consists of one or more segments. 21
segment A portion of an address space associated with a set of address ranges. 22
OpenMP architecture The architecture on which an OpenMP regionexecutes. 23
tool architecture The architecture on which an OMPDtool executes. 24
OpenMP process A collection of one or more threadsandaddress spaces . A process may contain 25
threadsandaddress spaces for multiple OpenMP architectures . At least one thread 26
in an OpenMP process is an OpenMP thread. A process may be live or a core ﬁle. 27
address space handle Ahandlethat refers to an address space within an OpenMP process. 28
thread handle Ahandlethat refers to an OpenMP thread. 29
parallel handle Ahandlethat refers to an OpenMP parallel region. 30
task handle Ahandlethat refers to an OpenMP task region. 31
descendent handle An output handlethat is returned from the OMPDlibrary in a function that accepts 32
an inputhandle: the output handleis a descendent of the input handle. 33
CHAPTER 1. INTRODUCTION 19
ancestor handle An input handlethat is passed to the OMPDlibrary in a function that returns an 1
outputhandle: the input handleis an ancestor of the output handle. For a given 2
handle, the ancestors of the handleare also the ancestors of the handle’s descendent. 3
COMMENT: A handlecannot be used by the tool in an OMPDcall if any 4
ancestor of the handlehas been released, except for OMPDcalls that 5
release the handle. 6
tool context An opaque reference provided by a tool to an OMPDlibrary. A tool context uniquely 7
identiﬁes an abstraction. 8
address space context Atool context that refers to an address space within a process. 9
thread context Atool context that refers to a native thread . 10
native thread identiﬁer An identiﬁer for a native thread deﬁned by a thread implementation. 11
1.3 Execution Model 12
The OpenMP API uses the fork-join model of parallel execution. Multiple threads of execution 13
perform tasks deﬁned implicitly or explicitly by OpenMP directives. The OpenMP API is intended 14
to support programs that will execute correctly both as parallel programs (multiple threads of 15
execution and a full OpenMP support library) and as sequential programs (directives ignored and a 16
simple OpenMP stubs library). However, it is possible and permitted to develop a program that 17
executes correctly as a parallel program but not as a sequential program, or that produces diﬀerent 18
results when executed as a parallel program compared to when it is executed as a sequential 19
program. Furthermore, using diﬀerent numbers of threads may result in diﬀerent numeric results 20
because of changes in the association of numeric operations. For example, a serial addition 21
reduction may have a diﬀerent pattern of addition associations than a parallel reduction. These 22
diﬀerent associations may change the results of ﬂoating-point addition. 23
An OpenMP program begins as a single thread of execution, called an initial thread. An initial 24
thread executes sequentially, as if the code encountered is part of an implicit task region, called an 25
initial task region, that is generated by the implicit parallel region surrounding the whole program. 26
The thread that executes the implicit parallel region that surrounds the whole program executes on 27
thehost device . An implementation may support other target devices . If supported, one or more 28
devices are available to the host device for oﬄoading code and data. Each device has its own 29
threads that are distinct from threads that execute on another device. Threads cannot migrate from 30
one device to another device. The execution model is host-centric such that the host device oﬄoads 31
target regions to target devices. 32
20OpenMP API – Version 5.0 November 2018
When a target construct is encountered, a new target task is generated. The target task region 1
enclosesthe target region. The targettask iscompleteaftertheexecutionofthe target region 2
is complete. 3
When atarget task executes, the enclosed target region is executed by an initial thread. The 4
initialthreadmayexecuteona targetdevice . Theinitialthreadexecutessequentially,asifthetarget 5
region is part of an initial task region that is generated by an implicit parallel region. If the target 6
device does not exist or the implementation does not support the target device, all target regions 7
associated with that device execute on the host device. 8
The implementation must ensure that the target region executes as if it were executed in the data 9
environment of the target device unless an ifclause is present and the ifclause expression 10
evaluates to false. 11
Theteamsconstruct creates a league of teams , where each team is an initial team that comprises 12
an initial thread that executes the teamsregion. Each initial thread executes sequentially, as if the 13
code encountered is part of an initial task region that is generated by an implicit parallel region 14
associated with each team. 15
Ifaconstructcreatesadataenvironment,thedataenvironmentiscreatedatthetimetheconstructis 16
encountered. The description of a construct deﬁnes whether it creates a data environment. 17
When any thread encounters a parallel construct, the thread creates a team of itself and zero or 18
more additional threads and becomes the master of the new team. A set of implicit tasks, one per 19
thread, is generated. The code for each task is deﬁned by the code inside the parallel construct. 20
Each task is assigned to a diﬀerent thread in the team and becomes tied; that is, it is always 21
executed by the thread to which it is initially assigned. The task region of the task being executed 22
by the encountering thread is suspended, and each member of the new team executes its implicit 23
task. There is an implicit barrier at the end of the parallel construct. Only the master thread 24
resumes execution beyond the end of the parallel construct, resuming the task region that was 25
suspended upon encountering the parallel construct. Any number of parallel constructs 26
can be speciﬁed in a single program. 27
parallel regions may be arbitrarily nested inside each other. If nested parallelism is disabled, or 28
is not supported by the OpenMP implementation, then the new team that is created by a thread 29
encountering a parallel construct inside a parallel region will consist only of the 30
encountering thread. However, if nested parallelism is supported and enabled, then the new team 31
canconsistofmorethanonethread. A parallel constructmayincludea proc_bind clauseto 32
specify the places to use for the threads in the team within the parallel region. 33
Whenanyteamencountersaworksharingconstruct,theworkinsidetheconstructisdividedamong 34
the members of the team, and executed cooperatively instead of being executed by every thread. 35
There is a default barrier at the end of each worksharing construct unless the nowait clause is 36
present. Redundant execution of code by every thread in the team resumes after the end of the 37
worksharing construct. 38
CHAPTER 1. INTRODUCTION 21
When any thread encounters a task generating construct , one or more explicit tasks are generated. 1
Execution of explicitly generated tasks is assigned to one of the threads in the current team, subject 2
to the thread’s availability to execute work. Thus, execution of the new task could be immediate, or 3
deferred until later according to task scheduling constraints and thread availability. Threads are 4
allowed to suspend the current task region at a task scheduling point in order to execute a diﬀerent 5
task. If the suspended task region is for a tied task, the initially assigned thread later resumes 6
execution of the suspended task region. If the suspended task region is for an untied task, then any 7
threadmayresumeitsexecution. Completionofallexplicittasksboundtoagivenparallelregionis 8
guaranteed before the master thread leaves the implicit barrier at the end of the region. Completion 9
of a subset of all explicit tasks bound to a given parallel region may be speciﬁed through the use of 10
task synchronization constructs. Completion of all explicit tasks bound to the implicit parallel 11
region is guaranteed by the time the program exits. 12
When any thread encounters a simdconstruct, the iterations of the loop associated with the 13
construct may be executed concurrently using the SIMD lanes that are available to the thread. 14
When a loopconstruct is encountered, the iterations of the loop associated with the construct are 15
executed in the context of its encountering thread(s), as determined according to its binding region. 16
If the loopregion binds to a teamsregion, the region is encountered by the set of master threads 17
that execute the teamsregion. If the loopregion binds to a parallel region, the region is 18
encountered by the team of threads executing the parallel region. Otherwise, the region is 19
encountered by a single thread. 20
If the loopregion binds to a teamsregion, the encountering threads may continue execution 21
after the loopregion without waiting for all iterations to complete; the iterations are guaranteed to 22
complete before the end of the teamsregion. Otherwise, all iterations must complete before the 23
encountering thread(s) continue execution after the loopregion. All threads that encounter the 24
loopconstruct may participate in the execution of the iterations. Only one of these threads may 25
execute any given iteration. 26
Thecancel construct can alter the previously described ﬂow of execution in an OpenMP region. 27
The eﬀect of the cancel construct depends on its construct-type-clause . If a task encounters a 28
cancel construct with a taskgroup construct-type-clause , then the task activates cancellation 29
and continues execution at the end of its taskregion, which implies completion of that task. Any 30
other task in that taskgroup that has begun executing completes execution unless it encounters a 31
cancellation point construct, in which case it continues execution at the end of its task 32
region, which implies its completion. Other tasks in that taskgroup region that have not begun 33
execution are aborted, which implies their completion. 34
For all other construct-type-clause values, if a thread encounters a cancel construct, it activates 35
cancellation of the innermost enclosing region of the type speciﬁed and the thread continues 36
execution at the end of that region. Threads check if cancellation has been activated for their region 37
at cancellation points and, if so, also resume execution at the end of the canceled region. 38
If cancellation has been activated regardless of construct-type-clause , threads that are waiting 39
inside a barrier other than an implicit barrier at the end of the canceled region exit the barrier and 40
22OpenMP API – Version 5.0 November 2018
resume execution at the end of the canceled region. This action can occur before the other threads 1
reach that barrier. 2
Synchronization constructs and library routines are available in the OpenMP API to coordinate 3
tasks and data access in parallel regions. In addition, library routines and environment 4
variables are available to control or to query the runtime environment of OpenMP programs. 5
The OpenMP speciﬁcation makes no guarantee that input or output to the same ﬁle is synchronous 6
when executed in parallel. In this case, the programmer is responsible for synchronizing input and 7
output processing with the assistance of OpenMP synchronization constructs or library routines. 8
For the case where each thread accesses a diﬀerent ﬁle, no synchronization by the programmer is 9
necessary. 10
1.4 Memory Model 11
1.4.1 Structure of the OpenMP Memory Model 12
The OpenMP API provides a relaxed-consistency, shared-memory model. All OpenMP threads 13
have access to a place to store and to retrieve variables, called the memory. In addition, each thread 14
is allowed to have its own temporary view of the memory. The temporary view of memory for each 15
thread is not a required part of the OpenMP memory model, but can represent any kind of 16
intervening structure, such as machine registers, cache, or other local storage, between the thread 17
and the memory. The temporary view of memory allows the thread to cache variables and thereby 18
to avoid going to memory for every reference to a variable. Each thread also has access to another 19
type of memory that must not be accessed by other threads, called threadprivate memory . 20
A directive that accepts data-sharing attribute clauses determines two kinds of access to variables 21
used in the directive’s associated structured block: shared and private. Each variable referenced in 22
the structured block has an original variable, which is the variable by the same name that exists in 23
theprogramimmediatelyoutsidetheconstruct. Eachreferencetoasharedvariableinthestructured 24
block becomes a reference to the original variable. For each private variable referenced in the 25
structured block, a new version of the original variable (of the same type and size) is created in 26
memory for each task or SIMD lane that contains code associated with the directive. Creation of 27
the new version does not alter the value of the original variable. However, the impact of attempts to 28
access the original variable during the region corresponding to the directive is unspeciﬁed; see 29
Section 2.19.4.3 on page 285 for additional details. References to a private variable in the 30
structured block refer to the private version of the original variable for the current task or SIMD 31
lane. The relationship between the value of the original variable and the initial or ﬁnal value of the 32
private version depends on the exact clause that speciﬁes it. Details of this issue, as well as other 33
issues with privatization, are provided in Section 2.19 on page 269. 34
CHAPTER 1. INTRODUCTION 23
The minimum size at which a memory update may also read and write back adjacent variables that 1
are part of another variable (as array or structure elements) is implementation deﬁned but is no 2
larger than required by the base language. 3
Asingleaccesstoavariablemaybeimplementedwithmultipleloadorstoreinstructionsand,thus, 4
is not guaranteed to be atomic with respect to other accesses to the same variable. Accesses to 5
variables smaller than the implementation deﬁned minimum size or to C or C++ bit-ﬁelds may be 6
implemented by reading, modifying, and rewriting a larger unit of memory, and may thus interfere 7
with updates of variables or ﬁelds in the same unit of memory. 8
If multiple threads write without synchronization to the same memory unit, including cases due to 9
atomicity considerations as described above, then a data race occurs. Similarly, if at least one 10
thread reads from a memory unit and at least one thread writes without synchronization to that 11
same memory unit, including cases due to atomicity considerations as described above, then a data 12
race occurs. If a data race occurs then the result of the program is unspeciﬁed. 13
Aprivatevariableinataskregionthatsubsequentlygeneratesaninnernested parallel regionis 14
permitted to be made shared by implicit tasks in the inner parallel region. A private variable in 15
a task region can also be shared by an explicit task region generated during its execution. However, 16
it is the programmer’s responsibility to ensure through synchronization that the lifetime of the 17
variable does not end before completion of the explicit task region sharing it. Any other access by 18
one task to the private variables of another task results in unspeciﬁed behavior. 19
1.4.2 Device Data Environments 20
When an OpenMP program begins, an implicit target data region for each device surrounds 21
the whole program. Each device has a device data environment that is deﬁned by its implicit 22
target data region. Any declare target directives and the directives that accept 23
data-mapping attribute clauses determine how an original variable in a data environment is mapped 24
to a corresponding variable in a device data environment. 25
When an original variable is mapped to a device data environment and a corresponding variable is 26
notpresentinthedevicedataenvironment,anewcorrespondingvariable(ofthesametypeandsize 27
as the original variable) is created in the device data environment. Conversely, the original variable 28
becomes the new variable’s corresponding variable in the device data environment of the device 29
that performs the mapping operation. 30
The corresponding variable in the device data environment may share storage with the original 31
variable. Writes to the corresponding variable may alter the value of the original variable. The 32
impact of this possibility on memory consistency is discussed in Section 1.4.6 on page 28. When a 33
task executes in thecontext of a device data environment, referencesto the original variable refer to 34
the corresponding variable in the device data environment. If an original variable is not currently 35
mappedandacorrespondingvariabledoesnotexistinthedevicedataenvironmentthenaccessesto 36
24OpenMP API – Version 5.0 November 2018
the original variable result in unspeciﬁed behavior unless the unified_shared_memory 1
clause is speciﬁed on a requires directive for the compilation unit. 2
The relationship between the value of the original variable and the initial or ﬁnal value of the 3
corresponding variable depends on the map-type. Details of this issue, as well as other issues with 4
mapping a variable, are provided in Section 2.19.7.1 on page 315. 5
Theoriginalvariableinadataenvironmentandthecorrespondingvariable(s)inoneormoredevice 6
data environments may share storage. Without intervening synchronization data races can occur. 7
1.4.3 Memory Management8
The host device, and target devices that an implementation may support, have attached storage 9
resources where program variables are stored. These resources can have diﬀerent traits. A memory 10
space in an OpenMP program represents a set of these storage resources. Memory spaces are 11
deﬁned according to a set of traits, and a single resource may be exposed as multiple memory 12
spaces with diﬀerent traits or may be part of multiple memory spaces. In any device, at least one 13
memory space is guaranteed to exist. 14
An OpenMP program can use a memory allocator to allocate memoryin which to store variables. 15
Thismemorywill be allocated from the storage resources of the memory space associated with the 16
memory allocator. Memory allocators are also used to deallocate previously allocated memory. 17
When an OpenMP memory allocator is not used to allocate memory, OpenMP does not prescribe 18
thestorageresourcefortheallocation;thememoryforthevariablesmaybeallocatedinanystorage 19
resource. 20
1.4.4 The Flush Operation 21
The memory model has relaxed-consistency because a thread’s temporary view of memory is not 22
required to be consistent with memory at all times. A value written to a variable can remain in the 23
thread’s temporary view until it is forced to memory at a later time. Likewise, a read from a 24
variable may retrieve the value from the thread’s temporary view, unless it is forced to read from 25
memory. OpenMP ﬂush operations are used to enforce consistency between a thread’s temporary 26
view of memory and memory, or between multiple threads’ view of memory. 27
If a ﬂush operation is a strong ﬂush, it enforces consistency between a thread’s temporary view and 28
memory. A strong ﬂush operation is applied to a set of variables called the ﬂush-set. A strong ﬂush 29
restricts reordering of memory operations that an implementation might otherwise do. 30
Implementationsmustnotreorderthecodeforamemoryoperationforagivenvariable,orthecode 31
CHAPTER 1. INTRODUCTION 25
for a ﬂush operation for the variable, with respect to a strong ﬂush operation that refers to the same 1
variable. 2
Ifathreadhasperformedawritetoitstemporaryviewofasharedvariablesinceitslaststrongﬂush 3
of that variable, then when it executes another strong ﬂush of the variable, the strong ﬂush does not 4
complete until the value of the variable has been written to the variable in memory. If a thread 5
performsmultiplewritestothesamevariablebetweentwostrongﬂushesofthatvariable,thestrong 6
ﬂushensuresthatthevalueofthelastwriteiswrittentothevariableinmemory. Astrongﬂushofa 7
variable executed by a thread also causes its temporary view of the variable to be discarded, so that 8
if its next memory operation for that variable is a read, then the thread will read from memory and 9
capture the value in its temporary view. When a thread executes a strong ﬂush, no later memory 10
operationbythatthreadforavariableinvolvedinthatstrongﬂushisallowedtostartuntilthestrong 11
ﬂush completes. The completion of a strong ﬂush executed by a thread is deﬁned as the point at 12
which all writes to the ﬂush-set performed by the thread before the strong ﬂush are visible in 13
memorytoallotherthreads,andatwhichthatthread’stemporaryviewoftheﬂush-setisdiscarded. 14
A strong ﬂush operation provides a guarantee of consistency between a thread’s temporary view 15
and memory. Therefore, astrong ﬂushcan be usedto guaranteethat avalue writtento avariable by 16
one thread may be read by a second thread. To accomplish this, the programmer must ensure that 17
the second thread has not written to the variable since its last strong ﬂush of the variable, and that 18
the following sequence of events are completed in this speciﬁc order: 19
1. The value is written to the variable by the ﬁrst thread; 20
2. The variable is ﬂushed, with a strong ﬂush, by the ﬁrst thread; 21
3. The variable is ﬂushed, with a strong ﬂush, by the second thread; and 22
4. The value is read from the variable by the second thread. 23
If a ﬂush operation is a release ﬂush or acquire ﬂush, it can enforce consistency between the views 24
of memory of two synchronizing threads. A release ﬂush guarantees that any prior operation that 25
writes or reads a shared variable will appear to be completed before any operation that writes or 26
reads the same shared variable and follows an acquire ﬂush with which the release ﬂush 27
synchronizes (see Section 1.4.5 on page 27 for more details on ﬂush synchronization). A release 28
ﬂush will propagate the values of all shared variables in its temporary view to memory prior to the 29
thread performing any subsequent atomic operation that may establish a synchronization. An 30
acquire ﬂush will discard any value of a shared variable in its temporary view to which the thread 31
has not written since last performing a release ﬂush, so that it may subsequently read a value 32
propagated by a release ﬂush that synchronizes with it. Therefore, release and acquire ﬂushes may 33
also be used to guarantee that a value written to a variable by one thread may be read by a second 34
thread. To accomplish this, the programmer must ensure that the second thread has not written to 35
the variable since its last acquire ﬂush, and that the following sequence of events happen in this 36
speciﬁc order: 37
1. The value is written to the variable by the ﬁrst thread; 38
2. The ﬁrst thread performs a release ﬂush; 39
26OpenMP API – Version 5.0 November 2018
3. The second thread performs an acquire ﬂush; and 1
4. The value is read from the variable by the second thread. 2
3
Note– OpenMP synchronization operations, described in Section 2.17 on page 223 and in 4
Section 3.3 on page 381, are recommended for enforcing this order. Synchronization through 5
variables is possible but is not recommended because the proper timing of ﬂushes is diﬃcult. 6
7
The ﬂush properties that deﬁne whether a ﬂush operation is a strong ﬂush, a release ﬂush, or an 8
acquire ﬂush are not mutually disjoint. A ﬂush operation may be a strong ﬂush and a release ﬂush; 9
it may be a strong ﬂush and an acquire ﬂush; it may be a release ﬂush and an acquire ﬂush; or it 10
may be all three. 11
1.4.5 Flush Synchronization and Happens Before 12
OpenMP supports thread synchronization with the use of release ﬂushes and acquire ﬂushes. For 13
anysuchsynchronization,areleaseﬂushisthesourceofthesynchronizationandanacquireﬂushis 14
the sink of the synchronization, such that the release ﬂush synchronizes with the acquire ﬂush. 15
A release ﬂush has one or more associated release sequences that deﬁne the set of modiﬁcations 16
that may be used to establish a synchronization. A release sequence starts with an atomic operation 17
that follows the release ﬂush and modiﬁes a shared variable and additionally includes any 18
read-modify-write atomic operations that read a value taken from some modiﬁcation in the release 19
sequence. The following rules determine the atomic operation that starts an associated release 20
sequence. 21
If a release ﬂush is performed on entry to an atomic operation, that atomic operation starts its 22
release sequence. 23
If a release ﬂush is performed in an implicit flushregion, an atomic operation that is provided 24
by the implementation and that modiﬁes an internal synchronization variable, starts its release 25
sequence. 26
If a release ﬂush is performed by an explicit flushregion, any atomic operation that modiﬁes a 27
shared variable and follows the flushregion in its thread’s program order starts an associated 28
release sequence. 29
An acquire ﬂush is associated with one or more prior atomic operations that read a shared variable 30
and that may be used to establish a synchronization. The following rules determine the associated 31
atomic operation that may establish a synchronization. 32
If an acquire ﬂush is performed on exit from an atomic operation, that atomic operation is its 33
associated atomic operation. 34
CHAPTER 1. INTRODUCTION 27
If an acquire ﬂush is performed in an implicit flushregion, an atomic operation that is 1
provided by the implementation and that reads an internal synchronization variable is its 2
associated atomic operation. 3
If an acquire ﬂush is performed by an explicit flushregion, any atomic operation that reads a 4
shared variable and precedes the flushregion in its thread’s program order is an associated 5
atomic operation. 6
A release ﬂush synchronizes with an acquire ﬂush if an atomic operation associated with the 7
acquire ﬂush reads a value written by a modiﬁcation from a release sequence associated with the 8
release ﬂush. 9
An operation X simply happens before an operation Yif any of the following conditions are 10
satisﬁed: 11
1.XandYare performed by the same thread, and XprecedesYin the thread’s program order; 12
2.Xsynchronizes with Yaccording to the ﬂush synchronization conditions explained above or 13
according to the base language’s deﬁnition of synchronizes with , if such a deﬁnition exists; or 14
3. There exists another operation Z, such that Xsimply happens before ZandZsimply happens 15
beforeY. 16
An operation X happens before an operation Yif any of the following conditions are satisﬁed: 17
1.Xhappens before Yaccording to the base language’s deﬁnition of happens before , if such a 18
deﬁnition exists; or 19
2.Xsimply happens before Y. 20
Avariablewithaninitialvalueistreatedasifthevalueisstoredtothevariablebyanoperationthat 21
happens before all operations that access or modify the variable in the program. 22
1.4.6 OpenMP Memory Consistency 23
The following rules guarantee the observable completion order of memory operations, as seen by 24
all threads. 25
If two operations performed by diﬀerent threads are sequentially consistent atomic operations or 26
they are strong ﬂushes that ﬂush the same variable, then they must be completed as if in some 27
sequential order, seen by all threads. 28
If two operations performed by the same thread are sequentially consistent atomic operations or 29
they access, modify, or, with a strong ﬂush, ﬂush the same variable, then they must be completed 30
as if in that thread’s program order, as seen by all threads. 31
If two operations are performed by diﬀerent threads and one happens before the other, then they 32
must be completed as if in that happens before order, as seen by all threads, if: 33
28OpenMP API – Version 5.0 November 2018
–both operations access or modify the same variable; 1
–both operations are strong ﬂushes that ﬂush the same variable; or 2
–both operations are sequentially consistent atomic operations. 3
Any two atomic memory operations from diﬀerent atomic regions must be completed as if in 4
the same order as the strong ﬂushes implied in their respective regions, as seen by all threads. 5
The ﬂush operation can be speciﬁed using the flushdirective, and is also implied at various 6
locations in an OpenMP program: see Section 2.17.8 on page 242 for details. 7
8
Note– Sinceﬂushoperationsbythemselvescannotpreventdataraces,explicitﬂushoperationsare 9
only useful in combination with non-sequentially consistent atomic directives. 10
11
OpenMP programs that: 12
Do not use non-sequentially consistent atomic directives; 13
Do not rely on the accuracy of a falseresult from omp_test_lock and 14
omp_test_nest_lock ; and 15
Correctly avoid data races as required in Section 1.4.1 on page 23, 16
behaveasthoughoperationsonsharedvariablesweresimplyinterleavedinanorderconsistentwith 17
the order in which they are performed by each thread. The relaxed consistency model is invisible 18
for such programs, and any explicit ﬂush operations in such programs are redundant. 19
1.5 Tool Interfaces 20
The OpenMP API includes two tool interfaces, OMPT and OMPD, to enable development of 21
high-quality, portable, tools that support monitoring, performance, or correctness analysis and 22
debugging of OpenMP programs developed using any implementation of the OpenMP API, 23
1.5.1 OMPT 24
The OMPT interface, which is intended for ﬁrst-party tools, provides the following: 25
A mechanism to initialize a ﬁrst-party tool; 26
CHAPTER 1. INTRODUCTION 29
Routines that enable a tool to determine the capabilities of an OpenMP implementation; 1
Routines that enable a tool to examine OpenMP state information associated with a thread; 2
Mechanisms that enable a tool to map implementation-level calling contexts back to their 3
source-level representations; 4
A callback interface that enables a tool to receive notiﬁcation of OpenMP events; 5
A tracing interface that enables a tool to trace activity on OpenMP target devices; and 6
A runtime library routine that an application can use to control a tool. 7
OpenMP implementations may diﬀer with respect to the thread states that they support, the mutual 8
exclusion implementations that they employ, and the OpenMP events for which tool callbacks are 9
invoked. For some OpenMP events, OpenMP implementations must guarantee that a registered 10
callback will be invoked for each occurrence of the event. For other OpenMP events, OpenMP 11
implementations are permitted to invoke a registered callback for some or no occurrences of the 12
event; for such OpenMP events, however, OpenMP implementations are encouraged to invoke tool 13
callbacks on as many occurrences of the event as is practical. Section 4.2.4 speciﬁes the subset of 14
OMPT callbacks that an OpenMP implementation must support for a minimal implementation of 15
the OMPT interface. 16
An implementation of the OpenMP API may diﬀer from the abstract execution model described by 17
its speciﬁcation. The ability of tools that use the OMPT interface to observe such diﬀerences does 18
not constrain implementations of the OpenMP API in any way. 19
With the exception of the omp_control_tool runtime library routine for tool control, all other 20
routines in the OMPT interface are intended for use only by tools and are not visible to 21
applications. For that reason, a Fortran binding is provided only for omp_control_tool ; all 22
other OMPT functionality is described with C syntax only. 23
1.5.2 OMPD 24
The OMPD interface is intended for third-party tools, which run as separate processes. An 25
OpenMP implementation must provide an OMPD library that can be dynamically loaded and used 26
by a third-party tool. A third-party tool, such as a debugger, uses the OMPD library to access 27
OpenMP state of a program that has begun execution. OMPD deﬁnes the following: 28
An interface that an OMPD library exports, which a tool can use to access OpenMP state of a 29
program that has begun execution; 30
A callback interface that a tool provides to the OMPD library so that the library can use it to 31
access the OpenMP state of a program that has begun execution; and 32
30OpenMP API – Version 5.0 November 2018
A small number of symbols that must be deﬁned by an OpenMP implementation to help the tool 1
ﬁnd the correct OMPD library to use for that OpenMP implementation and to facilitate 2
notiﬁcation of events. 3
Section 5 describes OMPD in detail. 4
1.6 OpenMP Compliance5
The OpenMP API deﬁnes constructs that operate in the context of the base language that is 6
supported by an implementation. If the implementation of the base language does not support a 7
language construct that appears in this document, a compliant OpenMP implementation is not 8
required to support it, with the exception that for Fortran, the implementation must allow case 9
insensitivity for directive and API routines names, and must allow identiﬁers of more than six 10
characters. An implementation of the OpenMP API is compliant if and only if it compiles and 11
executes all other conforming programs, and supports the tool interface, according to the syntax 12
and semantics laid out in Chapters 1, 2, 3, 4 and 5. Appendices A, B, C, and D, as well as sections 13
designated as Notes (see Section 1.8 on page 34) are for information purposes only and are not part 14
of the speciﬁcation. 15
All library, intrinsic and built-in routines provided by the base language must be thread-safe in a 16
compliant implementation. In addition, the implementation of the base language must also be 17
thread-safe. For example, ALLOCATE andDEALLOCATE statements must be thread-safe in 18
Fortran. Unsynchronized concurrent use of such routines by diﬀerent threads must produce correct 19
results (although not necessarily the same as serial execution results, as in the case of random 20
number generation routines). 21
Starting with Fortran 90, variables with explicit initialization have the SAVEattribute implicitly. 22
This is not the case in Fortran 77. However, a compliant OpenMP Fortran implementation must 23
give such a variable the SAVEattribute, regardless of the underlying base language version. 24
Appendix A lists certain aspects of the OpenMP API that are implementation deﬁned. A compliant 25
implementation must deﬁne and document its behavior for each of the items in Appendix A. 26
1.7 Normative References 27
ISO/IEC 9899:1990, Information Technology - Programming Languages - C . 28
This OpenMP API speciﬁcation refers to ISO/IEC 9899:1990 as C90. 29
CHAPTER 1. INTRODUCTION 31
ISO/IEC 9899:1999, Information Technology - Programming Languages - C . 1
This OpenMP API speciﬁcation refers to ISO/IEC 9899:1999 as C99. 2
ISO/IEC 9899:2011, Information Technology - Programming Languages - C . 3
This OpenMP API speciﬁcation refers to ISO/IEC 9899:2011 as C11. While future versions of 4
the OpenMP speciﬁcation are expected to address the following features, currently their use may 5
result in unspeciﬁed behavior. 6
–Supporting the noreturn property 7
–Adding alignment support 8
–Creation of complex value 9
–Threads for the C standard library 10
–Thread-local storage 11
–Parallel memory sequencing model 12
–Atomic 13
ISO/IEC 14882:1998, Information Technology - Programming Languages - C++ . 14
This OpenMP API speciﬁcation refers to ISO/IEC 14882:1998 as C++98. 15
ISO/IEC 14882:2011, Information Technology - Programming Languages - C++ . 16
This OpenMP API speciﬁcation refers to ISO/IEC 14882:2011 as C++11. While future versions 17
of the OpenMP speciﬁcation are expected to address the following features, currently their use 18
may result in unspeciﬁed behavior. 19
–Alignment support 20
–Standard layout types 21
–Allowing move constructs to throw 22
–Deﬁning move special member functions 23
–Concurrency 24
–Data-dependency ordering: atomics and memory model 25
–Additions to the standard library 26
–Thread-local storage 27
–Dynamic initialization and destruction with concurrency 28
–C++11 library 29
32OpenMP API – Version 5.0 November 2018
ISO/IEC 14882:2014, Information Technology - Programming Languages - C++ . 1
This OpenMP API speciﬁcation refers to ISO/IEC 14882:2014 as C++14. While future versions 2
of the OpenMP speciﬁcation are expected to address the following features, currently their use 3
may result in unspeciﬁed behavior. 4
–Sized deallocation 5
–What signal handlers can do 6
ISO/IEC 14882:2017, Information Technology - Programming Languages - C++ . 7
This OpenMP API speciﬁcation refers to ISO/IEC 14882:2017 as C++17. 8
ISO/IEC 1539:1980, Information Technology - Programming Languages - Fortran . 9
This OpenMP API speciﬁcation refers to ISO/IEC 1539:1980 as Fortran 77. 10
ISO/IEC 1539:1991, Information Technology - Programming Languages - Fortran . 11
This OpenMP API speciﬁcation refers to ISO/IEC 1539:1991 as Fortran 90. 12
ISO/IEC 1539-1:1997, Information Technology - Programming Languages - Fortran . 13
This OpenMP API speciﬁcation refers to ISO/IEC 1539-1:1997 as Fortran 95. 14
ISO/IEC 1539-1:2004, Information Technology - Programming Languages - Fortran . 15
This OpenMP API speciﬁcation refers to ISO/IEC 1539-1:2004 as Fortran 2003. 16
ISO/IEC 1539-1:2010, Information Technology - Programming Languages - Fortran . 17
This OpenMP API speciﬁcation refers to ISO/IEC 1539-1:2010 as Fortran 2008. While future 18
versions of the OpenMP speciﬁcation are expected to address the following features, currently 19
their use may result in unspeciﬁed behavior. 20
–Submodules 21
–Coarrays 22
–DO CONCURRENT 23
–Allocatable components of recursive type 24
–Pointer initialization 25
–Value attribute is permitted for any nonallocatable nonpointer nonarray 26
–Simply contiguous arrays rank remapping to rank>1 target 27
–Polymorphic assignment 28
–Accessing real and imaginary parts 29
–Pointer function reference is a variable 30
CHAPTER 1. INTRODUCTION 33
–Recursive I/O 1
–The BLOCK construct 2
–EXIT statement (to terminate a non-DO construct) 3
–ERROR STOP 4
–Internal procedure as an actual argument 5
–Generic resolution by procedureness 6
–Generic resolution by pointer vs. allocatable 7
–Impure elemental procedures 8
Where this OpenMP API speciﬁcation refers to C, C++ or Fortran, reference is made to the base 9
language supported by the implementation. 10
1.8 Organization of this Document 11
The remainder of this document is structured as follows: 12
Chapter 2 “Directives” 13
Chapter 3 “Runtime Library Routines” 14
Chapter 4 “OMPT Interface” 15
Chapter 5 “OMPD Interface” 16
Chapter 6 “Environment Variables” 17
Appendix A “OpenMP Implementation-Deﬁned Behaviors” 18
Appendix B “Features History” 19
Somesectionsofthisdocumentonlyapplytoprogramswritteninacertainbaselanguage. Textthat 20
applies only to programs for which the base language is C or C++ is shown as follows: 21
C / C++
C/C++ speciﬁc text... 22
C / C++
Text that applies only to programs for which the base language is C only is shown as follows: 23
C
C speciﬁc text... 24
C
34OpenMP API – Version 5.0 November 2018
Text that applies only to programs for which the base language is C90 only is shown as follows: 1
C90
C90 speciﬁc text... 2
C90
Text that applies only to programs for which the base language is C99 only is shown as follows: 3
C99
C99 speciﬁc text... 4
C99
Text that applies only to programs for which the base language is C++ only is shown as follows: 5
C++
C++ speciﬁc text... 6
C++
Text that applies only to programs for which the base language is Fortran is shown as follows: 7
Fortran
Fortran speciﬁc text...... 8
Fortran
Where an entire page consists of base language speciﬁc text, a marker is shown at the top of the 9
page. For Fortran-speciﬁc text, the marker is: 10
Fortran (cont.)
For C/C++-speciﬁc text, the marker is: 11
C/C++ (cont.)
Some text is for information only, and is not part of the normative speciﬁcation. Such text is 12
designated as a note, like this: 13
14
Note– Non-normative text... 15
16
CHAPTER 1. INTRODUCTION 35
This page intentionally left blank
CHAPTER 2
Directives 1
2
This chapter describes the syntax and behavior of OpenMP directives. 3
C / C++
In C/C++, OpenMP directives are speciﬁed by using the #pragma mechanism provided by the C 4
and C++ standards. 5
C / C++
Fortran
In Fortran, OpenMP directives are speciﬁed by using special comments that are identiﬁed by 6
unique sentinels. Also, a special comment form is available for conditional compilation. 7
Fortran
Compilers can therefore ignore OpenMP directives and conditionally compiled code if support of 8
the OpenMP API is not provided or enabled. A compliant implementation must provide an option 9
or interface that ensures that underlying support of all OpenMP directives and OpenMP conditional 10
compilation mechanisms is enabled. In the remainder of this document, the phrase OpenMP 11
compilation is used to mean a compilation with these OpenMP features enabled. 12
Fortran
Restrictions 13
The following restriction applies to all OpenMP directives: 14
OpenMP directives, except simdand any declarative directive, may not appear in pure 15
procedures. 16
OpenMP directives may not appear in the WHERE and FORALL constructs. 17
Fortran
CHAPTER 2. DIRECTIVES 37
2.1 Directive Format1
C / C++
OpenMP directives for C/C++ are speciﬁed with #pragma directives. The syntax of an OpenMP 2
directive is as follows: 3
#pragma omp directive-name [clause[ [ ,] clause] ... ] new-line 4
Each directive starts with #pragma omp . The remainder of the directive follows the conventions 5
of the C and C++ standards for compiler directives. In particular, white space can be used before 6
and after the #, and sometimes white space must be used to separate the words in a directive. 7
Preprocessing tokens following #pragma omp are subject to macro replacement. 8
Some OpenMP directives may be composed of consecutive #pragma directives if speciﬁed in 9
their syntax. 10
Directives are case-sensitive. 11
Each of the expressions used in the OpenMP syntax inside of the clauses must be a valid 12
assignment-expression of the base language unless otherwise speciﬁed. 13
C / C++
C++
Directivesmaynotappearin constexpr functionsorinconstantexpressions. Variadicparameter 14
packs cannot be expanded into a directive or its clauses except as part of an expression argument to 15
be evaluated by the base language, such as into a function call inside an ifclause. 16
C++
Fortran
OpenMP directives for Fortran are speciﬁed as follows: 17
sentinel directive-name [clause[ [ ,] clause]...] 18
All OpenMP compiler directives must begin with a directive sentinel. The format of a sentinel 19
diﬀers between ﬁxed form and free form source ﬁles, as described in Section 2.1.1 on page 41 and 20
Section 2.1.2 on page 41. 21
Directives are case insensitive. Directives cannot be embedded within continued statements, and 22
statements cannot be embedded within directives. 23
EachoftheexpressionsusedintheOpenMPsyntaxinsideoftheclausesmustbeavalid expression 24
of the base language unless otherwise speciﬁed. 25
In order to simplify the presentation, free form is used for the syntax of OpenMP directives for 26
Fortran in the remainder of this document, except as noted. 27
Fortran
38OpenMP API – Version 5.0 November 2018
Only one directive-name can be speciﬁed per directive (note that this includes combined directives, 1
see Section 2.13 on page 185). The order in which clauses appear on directives is not signiﬁcant. 2
Clauses on directives may be repeated as needed, subject to the restrictions listed in the description 3
of each clause. 4
Some clauses accept a list, anextended-list , or alocator-list . Alistconsists of a comma-separated 5
collection of one or more list items. Anextended-list consists of a comma-separated collection of 6
one or more extended list items . Alocator-list consists of a comma-separated collection of one or 7
morelocator list items . 8
C / C++
Alistitemisavariableoranarraysection. An extendedlistitem isalistitemorafunctionname. A 9
locator list item is any lvalue expression, including variables, or an array section. 10
C / C++
Fortran
Alist itemis a variable, array section or common block name (enclosed in slashes). An extended 11
list itemis alist itemor a procedure name. A locator list item is alist item. 12
Whenanamedcommonblockappearsina list,ithasthesamemeaningasifeveryexplicitmember 13
of the common block appeared in the list. An explicit member of a common block is a variable that 14
isnamedina COMMON statementthatspeciﬁesthecommonblocknameandisdeclaredinthesame 15
scoping unit in which the clause appears. 16
Although variables in common blocks can be accessed by use association or host association, 17
common block names cannot. As a result, a common block name speciﬁed in a data-sharing 18
attribute, a data copying or a data-mapping attribute clause must be declared to be a common block 19
in the same scoping unit in which the clause appears. 20
If a list item that appears in a directive or clause is an optional dummy argument that is not present, 21
the directive or clause for that list item is ignored. 22
If the variable referenced inside a construct is an optional dummy argument that is not present, any 23
explicitly determined, implicitly determined, or predetermined data-sharing and data-mapping 24
attribute rules for that variable are ignored. Otherwise, if the variable is an optional dummy 25
argument that is present, it is present inside the construct. 26
Fortran
For all base languages, a list item, anextended list item , or alocator list item is subject to the 27
restrictions speciﬁed in Section 2.1.5 on page 44 and in each of the sections describing clauses and 28
directives for which the list, theextended-list , or thelocator-list appears. 29
Some executable directives include a structured block. A structured block: 30
may contain inﬁnite loops where the point of exit is never reached; 31
may halt due to an IEEE exception; 32
CHAPTER 2. DIRECTIVES 39
C / C++
may contain calls to exit(),_Exit() ,quick_exit() ,abort() or functions with a 1
_Noreturn speciﬁer (in C) or a noreturn attribute (in C/C++); 2
may be an expression statement, iteration statement, selection statement, or try block, provided 3
that the corresponding compound statement obtained by enclosing it in {and}would be a 4
structured block; and 5
C / C++
Fortran
may contain STOPstatements. 6
Fortran
Restrictions 7
Restrictions to structured blocks are as follows: 8
Entry to a structured block must not be the result of a branch. 9
The point of exit cannot be a branch out of the structured block. 10
C / C++
The point of entry to a structured block must not be a call to setjmp() . 11
longjmp() andthrow() must not violate the entry/exit criteria. 12
C / C++
40OpenMP API – Version 5.0 November 2018
Fortran
2.1.1 Fixed Source Form Directives1
The following sentinels are recognized in ﬁxed form source ﬁles: 2
!$omp | c$omp | *$omp 3
Sentinels must start in column 1 and appear as a single word with no intervening characters. 4
Fortran ﬁxed form line length, white space, continuation, and column rules apply to the directive 5
line. Initial directive lines must have a space or a zero in column 6, and continuation directive lines 6
must have a character other than a space or a zero in column 6. 7
Comments may appear on the same line as a directive. The exclamation point initiates a comment 8
when it appears after column 6. The comment extends to the end of the source line and is ignored. 9
If the ﬁrst non-blank character after the directive sentinel of an initial or continuation directive line 10
is an exclamation point, the line is ignored. 11
12
Note– In the following example, the three formats for specifying the directive are equivalent (the 13
ﬁrst line represents the position of the ﬁrst 9 columns): 14
c23456789 15
!$omp parallel do shared(a,b,c) 16
17
c$omp parallel do 18
c$omp+shared(a,b,c) 19
20
c$omp paralleldoshared(a,b,c) 21
22
2.1.2 Free Source Form Directives 23
The following sentinel is recognized in free form source ﬁles: 24
!$omp 25
The sentinel can appear in any column as long as it is preceded only by white space. It must appear 26
as a single word with no intervening white space. Fortran free form line length, white space, and 27
continuation rules apply to the directive line. Initial directive lines must have a space after the 28
sentinel. Continued directive lines must have an ampersand ( &) as the last non-blank character on 29
the line, prior to any comment placed inside the directive. Continuation directive lines can have an 30
ampersand after the directive sentinel with optional white space before and after the ampersand. 31
CHAPTER 2. DIRECTIVES 41
Comments may appear on the same line as a directive. The exclamation point ( !) initiates a 1
comment. The comment extends to the end of the source line and is ignored. If the ﬁrst non-blank 2
character after the directive sentinel is an exclamation point, the line is ignored. 3
One or more blanks or horizontal tabs are optional to separate adjacent keywords in 4
directive-names unless otherwise speciﬁed. 5
6
Note– In the following example the three formats for specifying the directive are equivalent (the 7
ﬁrst line represents the position of the ﬁrst 9 columns): 8
!23456789 9
!$omp parallel do & 10
!$omp shared(a,b,c) 11
12
!$omp parallel & 13
!$omp&do shared(a,b,c) 14
15
!$omp paralleldo shared(a,b,c) 16
17
18
Fortran
2.1.3 Stand-Alone Directives 19
Summary 20
Stand-alone directives are executable directives that have no associated user code. 21
Description 22
Stand-alone directives do not have any associated executable user code. Instead, they represent 23
executable statements that typically do not have succinct equivalent statements in the base 24
language. Therearesomerestrictionsontheplacementofastand-alonedirectivewithinaprogram. 25
Astand-alonedirectivemaybeplacedonlyatapointwhereabaselanguageexecutablestatementis 26
allowed. 27
42OpenMP API – Version 5.0 November 2018
Restrictions 1
C / C++
A stand-alone directive may not be used in place of the statement following an if,while,do, 2
switch, orlabel. 3
C / C++
Fortran
A stand-alone directive may not be used as the action statement in an ifstatement or as the 4
executable statement following a label if the label is referenced in the program. 5
Fortran
C / C++
2.1.4 Array Shaping6
Ifanexpressionhasatypeofpointerto T,thenashape-operatorcanbeusedtospecifytheextentof 7
that pointer. In other words, theshape-operator is used to reinterpret, as an n-dimensional array, the 8
region of memory to which that expression points. 9
Formally, the syntax of the shape-operator is as follows: 10
shaped-expression := ([s1][s2]...[sn])cast-expression 11
The result of applying the shape-operator to an expression is an lvalue expression with an 12
n-dimensional array type with dimensions s1s2...snand element type T. 13
The precedence of the shape-operator is the same as a type cast. 14
Eachsiis an integral type expression that must evaluate to a positive integer. 15
Restrictions 16
Restrictions to the shape-operator are as follows: 17
The type Tmust be a complete type. 18
The shape-operator can appear only in clauses where it is explicitly allowed. 19
The result of a shape-operator must be a named array of a list item. 20
The type of the expression upon which a shape-operator is applied must be a pointer type. 21
C++
If the type Tis a reference to a type T’, then the type will be considered to be T’for all purposes 22
of the designated array. 23
C++
C / C++
CHAPTER 2. DIRECTIVES 43
2.1.5 Array Sections1
An array section designates a subset of the elements in an array. 2
C / C++
To specify an array section in an OpenMP construct, array subscript expressions are extended with 3
the following syntax: 4
[lower-bound :length :stride ] or 5
[lower-bound :length : ] or 6
[lower-bound :length ] or 7
[lower-bound : :stride ] or 8
[lower-bound : : ] or 9
[lower-bound : ] or 10
[ :length :stride ] or 11
[ :length : ] or 12
[ :length ] or 13
[ : :stride ] 14
[ : : ] 15
[ : ] 16
The array section must be a subset of the original array. 17
Array sections are allowed on multidimensional arrays. Base language array subscript expressions 18
can be used to specify length-one dimensions of multidimensional array sections. 19
Each of the lower-bound ,length, andstrideexpressions if speciﬁed must be an integral type 20
expression of the base language. When evaluated they represent a set of integer values as follows: 21
{lower-bound ,lower-bound +stride,lower-bound + 2 *stride,... ,lower-bound + ((length- 1) * 22
stride) } 23
Thelengthmust evaluate to a non-negative integer. 24
Thestridemust evaluate to a positive integer. 25
When the size of the array dimension is not known, the lengthmust be speciﬁed explicitly. 26
When the strideis absent it defaults to 1. 27
When the lengthis absent it defaults to d d(size lower-bound )=stride e e, wheresizeis the size of the 28
array dimension. 29
When the lower-bound is absent it defaults to 0. 30
44OpenMP API – Version 5.0 November 2018
C/C++ (cont.)
The precedence of a subscript operator that uses the array section syntax is the same as the 1
precedence of a subscript operator that does not use the array section syntax. 2
3
Note– The following are examples of array sections: 4
a[0:6] 5
a[0:6:1] 6
a[1:10] 7
a[1:] 8
a[:10:2] 9
b[10][:][:] 10
b[10][:][:0] 11
c[42][0:6][:] 12
c[42][0:6:2][:] 13
c[1:10][42][0:6] 14
S.c[:100] 15
p->y[:10] 16
this->a[:N] 17
(p+10)[:N] 18
Assume ais declared to be a 1-dimensional array with dimension size 11. The ﬁrst two examples 19
areequivalent,andthethirdandfourthexamplesareequivalent. Theﬁfthexamplespeciﬁesastride 20
of 2 and therefore is not contiguous. 21
Assume bis declared to be a pointer to a 2-dimensional array with dimension sizes 10 and 10. The 22
sixth example refers to all elements of the 2-dimensional array given by b[10]. The seventh 23
example is a zero-length array section. 24
Assume cis declared to be a 3-dimensional array with dimension sizes 50, 50, and 50. The eighth 25
example is contiguous, while the ninth and tenth examples are not contiguous. 26
The ﬁnal four examples show array sections that are formed from more general base expressions. 27
The following are examples that are non-conforming array sections: 28
s[:10].x 29
p[:10]->y 30
*(xp[:10]) 31
CHAPTER 2. DIRECTIVES 45
For all three examples, a base language operator is applied in an undeﬁned manner to an array 1
section. The only operator that may be applied to an array section is a subscript operator for which 2
the array section appears as the postﬁx expression. 3
4
5
C / C++
Fortran
Fortran has built-in support for array sections although some restrictions apply to their use, as 6
enumerated in the following section. 7
Fortran
Restrictions 8
Restrictions to array sections are as follows: 9
An array section can appear only in clauses where it is explicitly allowed. 10
Astrideexpression may not be speciﬁed unless otherwise stated. 11
C / C++
An element of an array section with a non-zero size must have a complete type. 12
The base expression of an array section must have an array or pointer type. 13
If a consecutive sequence of array subscript expressions appears in an array section, and the ﬁrst 14
subscript expression in the sequence uses the extended array section syntax deﬁned in this 15
section, then only the last subscript expression in the sequence may select array elements that 16
have a pointer type. 17
C / C++
C++
If the type of the base expression of an array section is a reference to a type T, then the type will 18
be considered to be Tfor all purposes of the array section. 19
An array section cannot be used in an overloaded []operator. 20
C++
Fortran
If a stride expression is speciﬁed, it must be positive. 21
The upper bound for the last dimension of an assumed-size dummy array must be speciﬁed. 22
If a list item is an array section with vector subscripts, the ﬁrst array element must be the lowest 23
in the array element order of the array section. 24
Ifalistitemisanarraysection,thelast part-refofthelistitemmusthaveasectionsubscriptlist. 25
Fortran
46OpenMP API – Version 5.0 November 2018
2.1.6 Iterators1
Iterators are identiﬁers that expand to multiple values in the clause on which they appear. 2
The syntax of the iterator modiﬁer is as follows: 3
iterator( iterators-deﬁnition ) 4
whereiterators-deﬁnition is one of the following: 5
iterator-speciﬁer [ ,iterators-deﬁnition ] 6
whereiterator-speciﬁer is one of the following: 7
[ iterator-type ] identiﬁer =range-speciﬁcation 8
where: 9
identiﬁer is a base language identiﬁer. 10
C / C++
iterator-type is a type name. 11
C / C++
Fortran
iterator-type is a type speciﬁer. 12
Fortran
range-speciﬁcation is of the form begin:end[:step], wherebeginandendare expressions for 13
which their types can be converted to iterator-type andstepis an integral expression. 14
C / C++
In aniterator-speciﬁer , if theiterator-type is not speciﬁed then the type of that iterator is of int 15
type. 16
C / C++
Fortran
In aniterator-speciﬁer , if theiterator-type is not speciﬁed then the type of that iterator is default 17
integer. 18
Fortran
In arange-speciﬁcation , if thestepis not speciﬁed its value is implicitly deﬁned to be 1. 19
An iterator only exists in the context of the clause in which it appears. An iterator also hides all 20
accessible symbols with the same name in the context of the clause. 21
The use of a variable in an expression that appears in the range-speciﬁcation causes an implicit 22
reference to the variable in all enclosing constructs. 23
CHAPTER 2. DIRECTIVES 47
C / C++
The values of the iterator are the set of values i0, ...,iN 1where: 1
i0= (iterator-type )begin, 2
ij= (iterator-type ) (ij 1+step), and 3
ifstep > 0, 4
–i0<(iterator-type )end, 5
–iN 1<(iterator-type )end, and 6
–(iterator-type ) (iN 1+step)(iterator-type )end; 7
ifstep < 0, 8
–i0>(iterator-type )end, 9
–iN 1>(iterator-type )end, and 10
–(iterator-type ) (iN 1+step)(iterator-type )end. 11
C / C++
Fortran
The values of the iterator are the set of values i1, ...,iNwhere: 12
i1=begin, 13
ij=ij 1+step, and 14
ifstep > 0, 15
–i1end, 16
–iNend, and 17
–iN+step > end ; 18
ifstep < 0, 19
–i1end, 20
–iNend, and 21
–iN+step < end . 22
Fortran
48OpenMP API – Version 5.0 November 2018
The set of values will be empty if no possible value complies with the conditions above. 1
For those clauses that contain expressions that contain iterator identiﬁers, the eﬀect is as if the list 2
item is instantiated within the clause for each value of the iterator in the set deﬁned above, 3
substituting each occurrence of the iterator identiﬁer in the expression with the iterator value. If the 4
set of values of the iterator is empty then the eﬀect is as if the clause was not speciﬁed. 5
The behavior is unspeciﬁed if ij+stepcannot be represented in iterator-type in any of the 6
ij+stepcomputations for any 0j < Nin C/C++ or 0< jNin Fortran. 7
Restrictions 8
An expression that contains an iterator identiﬁer can only appear in clauses that explicitly allow 9
expressions that contain iterators. 10
Theiterator-type must not declare a new type. 11
C / C++
Theiterator-type must be an integral or pointer type. 12
Theiterator-type must not be constqualiﬁed. 13
C / C++
Fortran
Theiterator-type must be an integer type. 14
Fortran
If thestepexpression of a range-speciﬁcation equals zero, the behavior is unspeciﬁed. 15
Each iterator identiﬁer can only be deﬁned once in an iterators-deﬁnition . 16
Iterators cannot appear in the range-speciﬁcation . 17
2.2 Conditional Compilation 18
In implementations that support a preprocessor, the _OPENMP macro name is deﬁned to have the 19
decimal value yyyymmwhereyyyyandmmare the year and month designations of the version of 20
the OpenMP API that the implementation supports. 21
If a#define or a#undef preprocessing directive in user code deﬁnes or undeﬁnes the 22
_OPENMP macro name, the behavior is unspeciﬁed. 23
Fortran
The OpenMP API requires Fortran lines to be compiled conditionally, as described in the following 24
sections. 25
CHAPTER 2. DIRECTIVES 49
Fortran (cont.)
2.2.1 Fixed Source Form Conditional Compilation Sentinels1
The following conditional compilation sentinels are recognized in ﬁxed form source ﬁles: 2
!$ | *$ | c$ 3
To enable conditional compilation, a line with a conditional compilation sentinel must satisfy the 4
following criteria: 5
The sentinel must start in column 1 and appear as a single word with no intervening white space; 6
After the sentinel is replaced with two spaces, initial lines must have a space or zero in column 6 7
and only white space and numbers in columns 1 through 5; 8
Afterthesentinelisreplacedwithtwospaces,continuationlinesmusthaveacharacterotherthan 9
a space or zero in column 6 and only white space in columns 1 through 5. 10
If these criteria are met, the sentinel is replaced by two spaces. If these criteria are not met, the line 11
is left unchanged. 12
13
Note– In the following example, the two forms for specifying conditional compilation in ﬁxed 14
source form are equivalent (the ﬁrst line represents the position of the ﬁrst 9 columns): 15
c23456789 16
!$ 10 iam = omp_get_thread_num() + 17
!$ & index 18
19
#ifdef _OPENMP 20
10 iam = omp_get_thread_num() + 21
& index 22
#endif 23
24
2.2.2 Free Source Form Conditional Compilation Sentinel 25
The following conditional compilation sentinel is recognized in free form source ﬁles: 26
!$ 27
To enable conditional compilation, a line with a conditional compilation sentinel must satisfy the 28
following criteria: 29
The sentinel can appear in any column but must be preceded only by white space; 30
The sentinel must appear as a single word with no intervening white space; 31
50OpenMP API – Version 5.0 November 2018
Initial lines must have a space after the sentinel; 1
Continued lines must have an ampersand as the last non-blank character on the line, prior to any 2
comment appearing on the conditionally compiled line. 3
Continuation lines can have an ampersand after the sentinel, with optional white space before and 4
aftertheampersand. Ifthesecriteriaaremet,thesentinelisreplacedbytwospaces. Ifthesecriteria 5
are not met, the line is left unchanged. 6
7
Note– In the following example, the two forms for specifying conditional compilation in free 8
source form are equivalent (the ﬁrst line represents the position of the ﬁrst 9 columns): 9
c23456789 10
!$ iam = omp_get_thread_num() + & 11
!$& index 12
13
#ifdef _OPENMP 14
iam = omp_get_thread_num() + & 15
index 16
#endif 17
18
19
Fortran
2.3 Variant Directives 20
2.3.1 OpenMP Context 21
At any point in a program, an OpenMP context exists that deﬁnes traits that describe the active 22
OpenMPconstructs,theexecutiondevices,andfunctionalitysupportedbytheimplementation. The 23
traits are grouped into trait sets. The following trait sets exist: construct,deviceand 24
implementation . 25
Theconstruct set is composed of the directive names, each being a trait, of all enclosing constructs 26
at that point in the program up to a target construct. Combined and composite constructs are 27
added to the set as distinct constructs in the same nesting order speciﬁed by the original construct. 28
The set is ordered by nesting level in ascending order. Speciﬁcally, the ordering of the set of 29
constructs is c1, ...,cN, where c1is the construct at the outermost nesting level and cNis the 30
construct at the innermost nesting level. In addition, if the point in the program is not enclosed by a 31
target construct, the following rules are applied in order: 32
CHAPTER 2. DIRECTIVES 51
1. For functions with a declare simd directive, the simdtrait is added to the beginning of the 1
set as c1for any generated SIMD versions so the total size of the set is increased by 1. 2
2. For functions that are determined to be function variants by a declare variant directive, 3
the selectors c1, ...,cMof the construct selector set are added in the same order to the 4
beginning of the set as c1, ...,cMso the total size of the set is increased by M. 5
3. Forfunctionswithina declare target block,the targettraitisaddedtothebeginningofthe 6
set as c1for any versions of the function that are generated for target regions so the total size 7
of the set is increased by 1. 8
Thesimdtrait can be further deﬁned with properties that match the clauses accepted by the 9
declare simd directive with the same name and semantics. The simdtrait must deﬁne at least 10
thesimdlenproperty and one of the inbranch ornotinbranch properties. 11
Thedeviceset includes traits that deﬁne the characteristics of the device being targeted by the 12
compiler at that point in the program. At least the following traits must be deﬁned: 13
Thekind(kind-name-list) trait speciﬁes the general kind of the device. The following kind-name 14
values are deﬁned: 15
–host, which speciﬁes that the device is the host device; 16
–nohost, which speciﬁes that the devices is not the host device; and 17
–the values deﬁned in the “OpenMP Context Deﬁnitions” document, which is available at 18
http://www.openmp.org/ . 19
Theisa(isa-name-list) trait speciﬁes the Instruction Set Architectures supported by the device. 20
The accepted isa-name values are implementation deﬁned. 21
Thearch(arch-name-list) trait speciﬁes the architectures supported by the device. The accepted 22
arch-name values are implementation deﬁned. 23
Theimplementation set includes traits that describe the functionality supported by the OpenMP 24
implementation at that point in the program. At least the following traits can be deﬁned: 25
Thevendor(vendor-name-list) trait, which speciﬁes the vendor identiﬁers of the implementation. 26
OpenMP deﬁned values for vendor-name are deﬁned in the “OpenMP Context Deﬁnitions” 27
document, which is available at http://www.openmp.org/ . 28
Theextension(extension-name-list) trait, which speciﬁes vendor speciﬁc extensions to the 29
OpenMP speciﬁcation. The accepted extension-name values are implementation deﬁned. 30
A trait with a name that is identical to the name of any clause that can be supplied to the 31
requires directive. 32
52OpenMP API – Version 5.0 November 2018
Implementationscandeﬁnefurthertraitsinthe deviceandimplementation sets. Allimplementation 1
deﬁned traits must follow the following syntax: 2
identiﬁer[ (context-element[ ,context-element[ ,...]])] 3
4
context-element : 5
identiﬁer[ (context-element[ ,context-element[ ,...]])] 6
or 7
context-value 8
9
context-value : 10
constant string 11
or 12
constant integer expression 13
whereidentiﬁer is a base language identiﬁer. 14
2.3.2 Context Selectors 15
Context selectors are used to deﬁne the properties of an OpenMP context that a directive or clause 16
can match. OpenMP deﬁnes diﬀerent sets of selectors, each containing diﬀerent selectors. 17
The syntax to deﬁne a context-selector-speciﬁcation is the following: 18
trait-set-selector[ ,trait-set-selector[ ,...]] 19
20
trait-set-selector : 21
trait-set-selector-name ={trait-selector[ ,trait-selector[ ,...]]} 22
23
trait-selector : 24
trait-selector-name[ ([trait-score :] trait-property[ ,trait-property[ ,...]])] 25
26
trait-score : 27
score(score-expression ) 28
Theconstruct selector set deﬁnes the construct traits that should be active in the OpenMP 29
context. The following selectors can be deﬁned in the construct set:target;teams; 30
parallel ;for(in C/C++); do(in Fortran); and simd. The properties of each selector are the 31
same properties that are deﬁned for the corresponding trait. The construct selector is an 32
ordered list c1, ...,cN. 33
Thedevice andimplementation selector sets deﬁne the traits that should be active in the 34
corresponding trait set of the OpenMP context. The same traits deﬁned in the corresponding traits 35
CHAPTER 2. DIRECTIVES 53
sets can be used as selectors with the same properties. The kindselector of the device selector 1
set can also be set to the value any, which is as if no kindselector was speciﬁed. 2
Theuserselector set deﬁnes the condition selector that provides additional user-deﬁned 3
conditions. 4
C
Thecondition( boolean-expr )selector deﬁnes a constant expression that must evaluate to true 5
for the selector to be true. 6
C
C++
Thecondition( boolean-expr )selector deﬁnes a constexpr expression that must evaluate to 7
true for the selector to be true. 8
C++
Fortran
Thecondition( logical-expr )selector deﬁnes a constant expression that must evaluate to true 9
for the selector to be true. 10
Fortran
Ascore-expression must be an constant integer expression. 11
Implementations can allow further selectors to be speciﬁed. Implementations can ignore speciﬁed 12
selectors that are not those described in this section. 13
Restrictions 14
Eachtrait-set-selector-name can only be speciﬁed once. 15
Eachtrait-selector-name can only be speciﬁed once. 16
Atrait-score cannot be speciﬁed in traits from the construct ordevice trait-selector-sets . 17
54OpenMP API – Version 5.0 November 2018
2.3.3 Matching and Scoring Context Selectors1
A givencontext selector is compatiblewith a givenOpenMP context ifthe following conditions are 2
satisﬁed: 3
All selectors in the userset of the context selector are true; 4
All selectors in the construct ,device, andimplementation sets of the context selector 5
appear in the corresponding trait set of the OpenMP context; 6
For each selector in the context selector, its properties are a subset of the properties of the 7
corresponding trait of the OpenMP context; and 8
Selectors in the construct set of the context selector appear in the same relative order as their 9
corresponding traits in the construct trait set of the OpenMP context. 10
Some properties of the simdselector have special rules to match the properties of the simdtrait: 11
Thesimdlen( N)propertyoftheselectormatchesthe simdlen(M) traitoftheOpenMPcontext 12
ifM%Nequals zero; and 13
Thealigned( list:N )property of the selector matches the aligned(list:M) trait of the OpenMP 14
context if N%Mequals zero. 15
Among compatible context selectors, a score is computed using the following algorithm: 16
1. Each trait that appears in the construct trait set in the OpenMP context is given the value 2p 117
where pis the position of the construct trait, cp, in the set; 18
2. The kind,arch, andisaselectors are given the values 2l,2l+1and2l+2, respectively, where 19
lis the number of traits in the construct set; 20
3. Traits for which a trait-score is speciﬁed are given the value speciﬁed by the trait-score 21
score-expression ; 22
4. The values given to any additional selectors allowed by the implementation are implemented 23
deﬁned; 24
5. Other selectors are given a value of zero; and 25
6. A context selector that is a strict subset of another context selector has a score of zero. For other 26
context selectors, the ﬁnal score is the sum of the values of all speciﬁed selectors plus 1. If the 27
traits that correspond to the construct selectors appear multiple times in the OpenMP 28
context, the highest valued subset of traits that contains all selectors in the same order are used. 29
CHAPTER 2. DIRECTIVES 55
2.3.4 Metadirectives1
Summary 2
A metadirective is a directive that can specify multiple directive variants of which one may be 3
conditionally selected to replace the metadirective based on the enclosing OpenMP context. 4
Syntax 5
C / C++
The syntax of a metadirective takes one of the following forms: 6
#pragma omp metadirective [clause[ [ ,] clause] ... ] new-line 7
or 8
#pragma omp begin metadirective [clause[ [ ,] clause] ... ] new-line 9
stmt(s) 10
#pragma omp end metadirective 11
whereclauseis one of the following: 12
when(context-selector-speciﬁcation :[directive-variant] ) 13
default( directive-variant ) 14
C / C++
Fortran
The syntax of a metadirective takes one of the following forms: 15
!$omp metadirective [clause[ [ ,] clause] ... ] 16
or 17
!$omp begin metadirective [clause[ [ ,] clause] ... ] 18
stmt(s) 19
!$omp end metadirective 20
whereclauseis one of the following: 21
when(context-selector-speciﬁcation :[directive-variant] ) 22
default( directive-variant ) 23
Fortran
In the whenclause,context-selector-speciﬁcation speciﬁes a context selector (see Section 2.3.2). 24
In the whenanddefault clauses,directive-variant has the following form and speciﬁes a 25
directive variant that speciﬁes an OpenMP directive with clauses that apply to it. 26
directive-name [clause[ [ ,] clause] ... ] 27
56OpenMP API – Version 5.0 November 2018
Description 1
A metadirective is a directive that behaves as if it is either ignored or replaced by the directive 2
variant speciﬁed in one of the whenordefault clauses that appears on the metadirective. 3
The OpenMP context for a given metadirective is deﬁned according to Section 2.3.1. For each 4
whenclause that appears on a metadirective, the speciﬁed directive variant, if present, is a 5
candidate to replace the metadirective if the corresponding context selector is compatible with the 6
OpenMP context according to the matching rules deﬁned in Section 2.3.3. If only one compatible 7
contextselectorspeciﬁedbya whenclausehasthehighestscoreanditspeciﬁesadirectivevariant, 8
the directive variant will replace the metadirective. If more than one whenclause speciﬁes a 9
compatible context selector that has the highest computed score and at least one speciﬁes a 10
directive variant, the ﬁrst directive variant speciﬁed in the lexical order of those whenclauses will 11
replace the metadirective. 12
If no context selector from any whenclause is compatible with the OpenMP context and a 13
default clause is present, the directive variant speciﬁed in the default clause will replace the 14
metadirective. 15
If a directive variant is not selected to replace a metadirective according to the above rules, the 16
metadirective has no eﬀect on the execution of the program. 17
Thebegin metadirective directive behaves identically to the metadirective directive, 18
except that the directive syntax for the speciﬁed directive variants must accept a paired 19
enddirective. For any directive variant that is selected to replace the begin metadirective 20
directive, the end metadirective directive will be implicitly replaced by its paired 21
enddirectiveto demarcate the statements that are aﬀected by or are associated with the directive 22
variant. If no directive variant is selected to replace the begin metadirective directive, its 23
paired end metadirective directive is ignored. 24
Restrictions 25
Restrictions to metadirectives are as follows: 26
The directive variant appearing in a whenordefault clause must not specify a 27
metadirective ,begin metadirective , orend metadirective directive. 28
The context selector that appears in a whenclause must not specify any properties for the simd 29
selector. 30
Any replacement that occurs for a metadirective must not result in a non-conforming OpenMP 31
program. 32
Any directive variant that is speciﬁed by a whenordefault clause on a 33
begin metadirective directive must be an OpenMP directive that has a paired 34
enddirective, and the begin metadirective directive must have a paired 35
end metadirective directive. 36
Thedefault clause may appear at most once on a metadirective. 37
CHAPTER 2. DIRECTIVES 57
2.3.5 declare variant Directive 1
Summary 2
Thedeclare variant directive declares a specialized variant of a base function and speciﬁes 3
the context in which that specialized variant is used. The declare variant directive is a 4
declarative directive. 5
Syntax 6
C / C++
The syntax of the declare variant directive is as follows: 7
#pragma omp declare variant( variant-func-id )clause new-line 8
[#pragma omp declare variant( variant-func-id )clause new-line] 9
[ ... ] 10
function deﬁnition or declaration 11
whereclauseis one of the following: 12
match(context-selector-speciﬁcation ) 13
and where variant-func-id is the name of a function variant that is either a base language identiﬁer 14
or, for C++, a template-id . 15
C / C++
Fortran
The syntax of the declare variant directive is as follows: 16
!$omp declare variant( [base-proc-name :]variant-proc-name )clause 17
whereclauseis one of the following: 18
match(context-selector-speciﬁcation ) 19
and where variant-proc-name is the name of a function variant that is a base language identiﬁer. 20
Fortran
Description 21
Thedeclare variant directive declares the base function to have the speciﬁed function 22
variant. The context selector in the matchclause is associated with the variant. 23
58OpenMP API – Version 5.0 November 2018
The OpenMP context for a call to a given base function is deﬁned according to Section 2.3.1. If the 1
context selector that is associated with a declared function variant is compatible with the OpenMP 2
context of a call to a base function according to the matching rules deﬁned in Section 2.3.3 then a 3
call to the variant is a candidate to replace the base function call. For any call to the base function 4
for which candidate variants exist, the variant with the highest score is selected from all compatible 5
variants. If multiple variants have the highest score, the selected variant is implementation deﬁned. 6
If a compatible variant exists, the call to the base function is replaced with a call to the selected 7
variant. If no compatible variants exist then the call to the base function is not changed. 8
Diﬀerent declare variant directives may be speciﬁed for diﬀerent declarations of the same 9
base function. 10
Any diﬀerences that the speciﬁc OpenMP context requires in the prototype of the variant from the 11
base function prototype are implementation deﬁned. 12
C++
The function variant is determined by base language standard name lookup rules ([basic.lookup]) 13
ofvariant-func-id with arguments that correspond to the argument types in the base function 14
declaration. 15
Thevariant-func-id and any expressions inside of the matchclause are interpreted as if they 16
appeared at the scope of the trailing return type of the base function. 17
C++
Restrictions 18
Restrictions to the declare variant directive are as follows: 19
Calling functions that a declare variant directive determined to be a function variant 20
directly in an OpenMP context that is diﬀerent from the one that the construct selector set of 21
the context selector speciﬁes is non-conforming. 22
If a function is determined to be a function variant through more than one declare variant 23
directive then the construct selector set of their context selectors must be the same. 24
C / C++
Ifthefunctionhasanydeclarations,thenthe declare variant directivesforanydeclarations 25
that have one must be equivalent. If the function deﬁnition has a declare variant , it must 26
also be equivalent. Otherwise, the result is unspeciﬁed. 27
C / C++
C++
Thedeclare variant directive cannot be speciﬁed for a virtual function. 28
The type of the function variant must be compatible with the type of the base function after the 29
implementation-deﬁned transformation for its OpenMP context. 30
C++
CHAPTER 2. DIRECTIVES 59
Fortran
base-proc-name must not be a generic name, procedure pointer, or entry name. 1
Ifbase-proc-name is omitted then the declare variant directive must appear in the 2
speciﬁcation part of a subroutine subprogram or a function subprogram. 3
Anydeclare variant directive must appear in the speciﬁcation part of a subroutine, 4
subprogram, function subprogram, or interface body to which it applies. 5
If adeclare variant directive is speciﬁed in an interface block for a procedure then it must 6
match a declare variant directive in the deﬁnition of the procedure. 7
If a procedure is declared via a procedure declaration statement then the procedure 8
base-proc-name should appear in the same speciﬁcation. 9
If adeclare variant directive is speciﬁed for a procedure name with an explicit interface 10
and a declare variant directive is also speciﬁed for the deﬁnition of the procedure, the two 11
declare variant directives must match. Otherwise the result is unspeciﬁed. 12
Fortran
Cross References 13
OpenMP Context Speciﬁcation, see Section 2.3.1 on page 51. 14
Context Selectors, see Section 2.3.2 on page 53. 15
2.4 requires Directive 16
Summary 17
Therequires directive speciﬁes the features that an implementation must provide in order for 18
the code to compile and to execute correctly. The requires directive is a declarative directive. 19
Syntax 20
C / C++
The syntax of the requires directive is as follows: 21
#pragma omp requires clause[ [ [ ,] clause] ... ] new-line 22
C / C++
60OpenMP API – Version 5.0 November 2018
Fortran
The syntax of the requires directive is as follows: 1
!$omp requires clause[ [ [ ,] clause] ... ] 2
Fortran
Whereclauseis either one of the requirement clauses listed below or a clause of the form 3
ext_implementation-deﬁned-requirement for an implementation deﬁned requirement clause. 4
reverse_offload 5
unified_address 6
unified_shared_memory 7
atomic_default_mem_order(seq_cst | acq_rel | relaxed) 8
dynamic_allocators 9
Description 10
Therequires directive speciﬁes features that an implementation must support for correct 11
execution. The behavior that a requirement clause speciﬁes may override the normal behavior 12
speciﬁed elsewhere in this document. Whether an implementation supports the feature that a given 13
requirement clause speciﬁes is implementation deﬁned. 14
Therequires directive speciﬁes requirements for the execution of all code in the current 15
compilation unit. 16
17
Note– Use of this directive makes your code less portable. Users should be aware that not all 18
devices or implementations support all requirements. 19
20
When the reverse_offload clause appears on a requires directive, the implementation 21
guarantees that a target region, for which the target construct speciﬁes a device clause in 22
which the ancestor modiﬁer appears, can execute on the parent device of an enclosing target 23
region. 24
When the unified_address clause appears on a requires directive, the implementation 25
guarantees that all devices accessible through OpenMP API routines and directives use a uniﬁed 26
address space. In this address space, a pointer will always refer to the same location in memory 27
from all devices accessible through OpenMP. The pointers returned by omp_target_alloc and 28
accessed through use_device_ptr are guaranteed to be pointer values that can support pointer 29
arithmetic while still being native device pointers. The is_device_ptr clause is not necessary 30
fordevicepointerstobetranslatedin target regions,andpointersfoundnotpresentarenotsetto 31
null but keep their original value. Memory local to a speciﬁc execution context may be exempt 32
from this requirement, following the restrictions of locality to a given execution context, thread, or 33
CHAPTER 2. DIRECTIVES 61
contention group. Target devices may still have discrete memories and dereferencing a device 1
pointer on the host device or host pointer on a target device remains unspeciﬁed behavior. 2
Theunified_shared_memory clause implies the unified_address requirement, 3
inheriting all of its behaviors. Additionally, memory in the device data environment of any device 4
visible to OpenMP, including but not limited to the host, is considered part of the device data 5
environmentofalldevicesaccessiblethroughOpenMPexceptasnotedbelow. Everydeviceaddress 6
allocated through OpenMP device memory routines is a valid host pointer. Memory local to an 7
executioncontextasdeﬁnedin unified_address abovemayremainpartofdistinctdevicedata 8
environments as long as the execution context is local to the device containing that environment. 9
Theunified_shared_memory clause makes the mapclause optional on target constructs 10
and the declare target directive optional for static lifetime variables accessed inside 11
declare target functions. Scalar variables are still ﬁrstprivate by default when referenced 12
inside target constructs. Values stored into memory by one device may not be visible to another 13
device until those two devices synchronize with each other or both devices synchronize with the 14
host. 15
Theatomic_default_mem_order clause speciﬁes the default memory ordering behavior for 16
atomic constructs that must be provided by an implementation. If the default memory ordering is 17
speciﬁed as seq_cst , allatomic constructs on which memory-order-clause is not speciﬁed 18
behave as if the seq_cst clause appears. If the default memory ordering is speciﬁed as 19
relaxed , allatomic constructs on which memory-order-clause is not speciﬁed behave as if the 20
relaxed clause appears. 21
If the default memory ordering is speciﬁed as acq_rel ,atomic constructs on which 22
memory-order-clause is not speciﬁed behave as if the release clause appears if the atomic write 23
or atomic update operation is speciﬁed, as if the acquire clause appears if the atomic read 24
operation is speciﬁed, and as if the acq_rel clause appears if the atomic captured update 25
operation is speciﬁed. 26
Thedynamic_allocators clause removescertain restrictionson theuse ofmemory allocators 27
intarget regions. It makes the uses_allocators clause optional on target constructs for 28
the purpose of using allocators in the corresponding target regions. It allows calls to the 29
omp_init_allocator andomp_destroy_allocator API routines in target regions. 30
Finally, it allows default allocators to be used by allocate directives, allocate clauses, and 31
omp_alloc API routines in target regions. 32
Implementers are allowed to include additional implementation deﬁned requirement clauses. All 33
implementation deﬁned requirements should begin with ext_. Requirement names that do not 34
start with ext_are reserved. 35
Restrictions 36
The restrictions for the requires directive are as follows: 37
Each of the clauses can appear at most once on the directive. 38
62OpenMP API – Version 5.0 November 2018
At most one requires directive with atomic_default_mem_order clause can appear in 1
a single compilation unit. 2
Arequires directive with a unified_address ,unified_shared_memory , or 3
reverse_offload clause must appear lexically before any device constructs or device 4
routines. 5
Arequires directive with any of the following clauses must appear in all compilation units of 6
a program that contain device constructs or device routines or in none of them: 7
–reverse_offload 8
–unified_address 9
–unified_shared_memory 10
Therequires directive with atomic_default_mem_order clause may not appear 11
lexically after any atomic construct on which memory-order-clause is not speciﬁed. 12
C
Therequires directive may only appear at ﬁle scope. 13
C
C++
Therequires directive may only appear at ﬁle or namespace scope. 14
C++
2.5 Internal Control Variables 15
An OpenMP implementation must act as if there are internal control variables (ICVs) that control 16
the behavior of an OpenMP program. These ICVs store information such as the number of threads 17
to use for future parallel regions, the schedule to use for worksharing loops and whether nested 18
parallelism is enabled or not. The ICVs are given values at various times (described below) during 19
the execution of the program. They are initialized by the implementation itself and may be given 20
values through OpenMP environment variables and through calls to OpenMP API routines. The 21
program can retrieve the values of these ICVs only through OpenMP API routines. 22
For purposes of exposition, this document refers to the ICVs by certain names, but an 23
implementation is not required to use these names or to oﬀer any way to access the variables other 24
than through the ways shown in Section 2.5.2 on page 66. 25
CHAPTER 2. DIRECTIVES 63
2.5.1 ICV Descriptions1
The following ICVs store values that aﬀect the operation of parallel regions. 2
dyn-var- controls whether dynamic adjustment of the number of threads is enabled for 3
encountered parallel regions. There is one copy of this ICV per data environment. 4
nthreads-var - controls the number of threads requested for encountered parallel regions. 5
There is one copy of this ICV per data environment. 6
thread-limit-var - controls the maximum number of threads participating in the contention 7
group. There is one copy of this ICV per data environment. 8
max-active-levels-var - controls the maximum number of nested active parallel regions. 9
There is one copy of this ICV per device. 10
place-partition-var - controls the place partition available to the execution environment for 11
encountered parallel regions. There is one copy of this ICV per implicit task. 12
active-levels-var - the number of nested active parallel regions that enclose the current task 13
such that all of the parallel regions are enclosed by the outermost initial task region on the 14
current device. There is one copy of this ICV per data environment. 15
levels-var - the number of nested parallel regions that enclose the current task such that all of the 16
parallel regions are enclosed by the outermost initial task region on the current device. 17
There is one copy of this ICV per data environment. 18
bind-var- controls the binding of OpenMP threads to places. When binding is requested, the 19
variable indicates that the execution environment is advised not to move threads between places. 20
The variable can also provide default thread aﬃnity policies. There is one copy of this ICV per 21
data environment. 22
The following ICVs store values that aﬀect the operation of worksharing-loop regions. 23
run-sched-var - controls the schedule that is used for worksharing-loop regions when the 24
runtime schedule kind is speciﬁed. There is one copy of this ICV per data environment. 25
def-sched-var - controls the implementation deﬁned default scheduling of worksharing-loop 26
regions. There is one copy of this ICV per device. 27
The following ICVs store values that aﬀect program execution. 28
stacksize-var -controlsthestacksizeforthreadsthattheOpenMPimplementationcreates. There 29
is one copy of this ICV per device. 30
wait-policy-var - controls the desired behavior of waiting threads. There is one copy of this ICV 31
per device. 32
display-aﬃnity-var -controlswhethertodisplaythreadaﬃnity. ThereisonecopyofthisICVfor 33
the whole program. 34
64OpenMP API – Version 5.0 November 2018
aﬃnity-format-var - controls the thread aﬃnity format when displaying thread aﬃnity. There is 1
one copy of this ICV per device. 2
cancel-var - controls the desired behavior of the cancel construct and cancellation points. 3
There is one copy of this ICV for the whole program. 4
default-device-var - controls the default target device. There is one copy of this ICV per data 5
environment. 6
target-oﬄoad-var - controls the oﬄoading behavior. There is one copy of this ICV for the whole 7
program. 8
max-task-priority-var - controls the maximum priority value that can be speciﬁed in the 9
priority clause of the taskconstruct. There is one copy of this ICV for the whole program. 10
The following ICVs store values that aﬀect the operation of the OMPT tool interface. 11
tool-var- controls whether an OpenMP implementation will try to register a tool. There is one 12
copy of this ICV for the whole program. 13
tool-libraries-var - speciﬁes a list of absolute paths to tool libraries for OpenMP devices. There 14
is one copy of this ICV for the whole program. 15
The following ICVs store values that aﬀect the operation of the OMPD tool interface. 16
debug-var - controls whether an OpenMP implementation will collect information that an 17
OMPD library can access to satisfy requests from a tool. There is one copy of this ICV for the 18
whole program. 19
The following ICVs store values that aﬀect default memory allocation. 20
def-allocator-var - controls the memory allocator to be used by memory allocation routines, 21
directives and clauses when a memory allocator is not speciﬁed by the user. There is one copy of 22
this ICV per implicit task. 23
CHAPTER 2. DIRECTIVES 65
2.5.2 ICV Initialization1
TABLE 2.1:ICV Initial Values
ICV Environment Variable Initial value
dyn-var OMP_DYNAMIC See description below
nthreads-var OMP_NUM_THREADS Implementation deﬁned
run-sched-var OMP_SCHEDULE Implementation deﬁned
def-sched-var (none) Implementation deﬁned
bind-var OMP_PROC_BIND Implementation deﬁned
stacksize-var OMP_STACKSIZE Implementation deﬁned
wait-policy-var OMP_WAIT_POLICY Implementation deﬁned
thread-limit-var OMP_THREAD_LIMIT Implementation deﬁned
max-active-levels-var OMP_MAX_ACTIVE_LEVELS ,
OMP_NESTEDSee description below
active-levels-var (none) zero
levels-var (none) zero
place-partition-var OMP_PLACES Implementation deﬁned
cancel-var OMP_CANCELLATION false
display-aﬃnity-var OMP_DISPLAY_AFFINITY false
aﬃnity-format-var OMP_AFFINITY_FORMAT Implementation deﬁned
default-device-var OMP_DEFAULT_DEVICE Implementation deﬁned
target-oﬄoad-var OMP_TARGET_OFFLOAD DEFAULT
max-task-priority-var OMP_MAX_TASK_PRIORITY zero
tool-var OMP_TOOL enabled
tool-libraries-var OMP_TOOL_LIBRARIES empty string
debug-var OMP_DEBUG disabled
def-allocator-var OMP_ALLOCATOR Implementation deﬁned
Table 2.1 shows the ICVs, associated environment variables, and initial values. 2
66OpenMP API – Version 5.0 November 2018
Description 1
Each device has its own ICVs. 2
The initial value of dyn-varis implementation deﬁned if the implementation supports dynamic 3
adjustment of the number of threads; otherwise, the initial value is false. 4
The value of the nthreads-var ICV is a list. 5
The value of the bind-varICV is a list. 6
The initial value of max-active-levels-var is the number of active levels of parallelism that the 7
implementation supports if OMP_NUM_THREADS orOMP_PROC_BIND is set to a 8
comma-separated list of more than one value. Otherwise, the initial value of 9
max-active-levels-var is implementation deﬁned. 10
The host and target device ICVs are initialized before any OpenMP API construct or OpenMP API 11
routine executes. After the initial values are assigned, the values of any OpenMP environment 12
variables that were set by the user are read and the associated ICVs for the host device are modiﬁed 13
accordingly. The method for initializing a target device’s ICVs is implementation deﬁned. 14
Cross References 15
OMP_SCHEDULE environment variable, see Section 6.1 on page 601. 16
OMP_NUM_THREADS environment variable, see Section 6.2 on page 602. 17
OMP_DYNAMIC environment variable, see Section 6.3 on page 603. 18
OMP_PROC_BIND environment variable, see Section 6.4 on page 604. 19
OMP_PLACES environment variable, see Section 6.5 on page 605. 20
OMP_STACKSIZE environment variable, see Section 6.6 on page 607. 21
OMP_WAIT_POLICY environment variable, see Section 6.7 on page 608. 22
OMP_MAX_ACTIVE_LEVELS environment variable, see Section 6.8 on page 608. 23
OMP_NESTED environment variable, see Section 6.9 on page 609. 24
OMP_THREAD_LIMIT environment variable, see Section 6.10 on page 610. 25
OMP_CANCELLATION environment variable, see Section 6.11 on page 610. 26
OMP_DISPLAY_AFFINITY environment variable, see Section 6.13 on page 612. 27
OMP_AFFINITY_FORMAT environment variable, see Section 6.14 on page 613. 28
OMP_DEFAULT_DEVICE environment variable, see Section 6.15 on page 615. 29
OMP_MAX_TASK_PRIORITY environment variable, see Section 6.16 on page 615. 30
OMP_TARGET_OFFLOAD environment variable, see Section 6.17 on page 615. 31
CHAPTER 2. DIRECTIVES 67
OMP_TOOL environment variable, see Section 6.18 on page 616. 1
OMP_TOOL_LIBRARIES environment variable, see Section 6.19 on page 617. 2
OMP_DEBUG environment variable, see Section 6.20 on page 617. 3
OMP_ALLOCATOR environment variable, see Section 6.21 on page 618. 4
2.5.3 Modifying and Retrieving ICV Values5
Table 2.2 shows the method for modifying and retrieving the values of ICVs through OpenMP API 6
routines. 7
TABLE 2.2:Ways to Modify and to Retrieve ICV Values
ICV Ways to Modify Value Ways to Retrieve Value
dyn-var omp_set_dynamic() omp_get_dynamic()
nthreads-var omp_set_num_threads() omp_get_max_threads()
run-sched-var omp_set_schedule() omp_get_schedule()
def-sched-var (none) (none)
bind-var (none) omp_get_proc_bind()
stacksize-var (none) (none)
wait-policy-var (none) (none)
thread-limit-var thread_limit clause omp_get_thread_limit()
max-active-levels-var omp_set_max_active_levels() ,
omp_set_nested()omp_get_max_active_levels()
active-levels-var (none) omp_get_active_level()
levels-var (none) omp_get_level()
place-partition-var (none) See description below
cancel-var (none) omp_get_cancellation()
display-aﬃnity-var (none) (none)
aﬃnity-format-var omp_set_affinity_format() omp_get_affinity_format()
table continued on next page
68OpenMP API – Version 5.0 November 2018
table continued from previous page
ICV Ways to Modify Value Ways to Retrieve Value
default-device-var omp_set_default_device() omp_get_default_device()
target-oﬄoad-var (none) (none)
max-task-priority-var (none) omp_get_max_task_priority()
tool-var (none) (none)
tool-libraries-var (none) (none)
debug-var (none) (none)
def-allocator-var omp_set_default_allocator() omp_get_default_allocator()
Description 1
The value of the nthreads-var ICV is a list. The runtime call omp_set_num_threads sets 2
the value of the ﬁrst element of this list, and omp_get_max_threads retrieves the value of 3
the ﬁrst element of this list. 4
The value of the bind-varICV is a list. The runtime call omp_get_proc_bind retrieves the 5
value of the ﬁrst element of this list. 6
Detailed values in the place-partition-var ICV are retrieved using the runtime calls 7
omp_get_partition_num_places ,omp_get_partition_place_nums , 8
omp_get_place_num_procs , andomp_get_place_proc_ids . 9
Cross References 10
thread_limit clause of the teamsconstruct, see Section 2.7 on page 82. 11
omp_set_num_threads routine, see Section 3.2.1 on page 334. 12
omp_get_max_threads routine, see Section 3.2.3 on page 336. 13
omp_set_dynamic routine, see Section 3.2.7 on page 340. 14
omp_get_dynamic routine, see Section 3.2.8 on page 341. 15
omp_get_cancellation routine, see Section 3.2.9 on page 342. 16
omp_set_nested routine, see Section 3.2.10 on page 343. 17
omp_get_nested routine, see Section 3.2.11 on page 344. 18
omp_set_schedule routine, see Section 3.2.12 on page 345. 19
omp_get_schedule routine, see Section 3.2.13 on page 347. 20
CHAPTER 2. DIRECTIVES 69
omp_get_thread_limit routine, see Section 3.2.14 on page 348. 1
omp_get_supported_active_levels , see Section 3.2.15 on page 349. 2
omp_set_max_active_levels routine, see Section 3.2.16 on page 350. 3
omp_get_max_active_levels routine, see Section 3.2.17 on page 351. 4
omp_get_level routine, see Section 3.2.18 on page 352. 5
omp_get_active_level routine, see Section 3.2.21 on page 355. 6
omp_get_proc_bind routine, see Section 3.2.23 on page 357. 7
omp_get_place_num_procs routine, see Section 3.2.25 on page 359. 8
omp_get_place_proc_ids routine, see Section 3.2.26 on page 360. 9
omp_get_partition_num_places routine, see Section 3.2.28 on page 362. 10
omp_get_partition_place_nums routine, see Section 3.2.29 on page 363. 11
omp_set_affinity_format routine, see Section 3.2.30 on page 364. 12
omp_get_affinity_format routine, see Section 3.2.31 on page 366. 13
omp_set_default_device routine, see Section 3.2.34 on page 369. 14
omp_get_default_device routine, see Section 3.2.35 on page 370. 15
omp_get_max_task_priority routine, see Section 3.2.42 on page 377. 16
omp_set_default_allocator routine, see Section 3.7.4 on page 411. 17
omp_get_default_allocator routine, see Section 3.7.5 on page 412. 18
2.5.4 How ICVs are Scoped 19
Table 2.3 shows the ICVs and their scope. 20
TABLE 2.3:Scopes of ICVs
ICV Scope
dyn-var data environment
nthreads-var data environment
table continued on next page
70OpenMP API – Version 5.0 November 2018
table continued from previous page
ICV Scope
run-sched-var data environment
def-sched-var device
bind-var data environment
stacksize-var device
wait-policy-var device
thread-limit-var data environment
max-active-levels-var device
active-levels-var data environment
levels-var data environment
place-partition-var implicit task
cancel-var global
display-aﬃnity-var global
aﬃnity-format-var device
default-device-var data environment
target-oﬄoad-var global
max-task-priority-var global
tool-var global
tool-libraries-var global
debug-var global
def-allocator-var implicit task
Description 1
There is one copy per device of each ICV with device scope. 2
Each data environment has its own copies of ICVs with data environment scope. 3
Each implicit task has its own copy of ICVs with implicit task scope. 4
Calls to OpenMP API routines retrieve or modify data environment scoped ICVs in the data 5
environment of their binding tasks. 6
CHAPTER 2. DIRECTIVES 71
2.5.4.1 How the Per-Data Environment ICVs Work1
When a taskconstruct or parallel construct is encountered, the generated task(s) inherit the 2
values of the data environment scoped ICVs from the generating task’s ICV values. 3
When a parallel construct is encountered, the value of each ICV with implicit task scope is 4
inherited, unless otherwise speciﬁed, from the implicit binding task of the generating task unless 5
otherwise speciﬁed. 6
When a taskconstruct is encountered, the generated task inherits the value of nthreads-var from 7
the generating task’s nthreads-var value. When a parallel construct is encountered, and the 8
generatingtask’s nthreads-var listcontainsasingleelement,thegeneratedtask(s)inheritthatlistas 9
the value of nthreads-var . When a parallel construct is encountered, and the generating task’s 10
nthreads-var list contains multiple elements, the generated task(s) inherit the value of nthreads-var 11
as the list obtained by deletion of the ﬁrst element from the generating task’s nthreads-var value. 12
Thebind-varICV is handled in the same way as the nthreads-var ICV. 13
When atarget task executes a target region, the generated initial task uses the values of the data 14
environment scoped ICVs from the device data environment ICV values of the device that will 15
execute the region. 16
If ateamsconstruct with a thread_limit clause is encountered, the thread-limit-var ICV 17
from the data environment of the initial task for each team is instead set to a value that is less than 18
or equal to the value speciﬁed in the clause. 19
When encountering a worksharing-loop region for which the runtime schedule kind is speciﬁed, 20
all implicit task regions that constitute the binding parallel region must have the same value for 21
run-sched-var in their data environments. Otherwise, the behavior is unspeciﬁed. 22
2.5.5 ICV Override Relationships 23
Table 2.4 shows the override relationships among construct clauses and ICVs. 24
TABLE 2.4:ICV Override Relationships
ICV construct clause, if used
dyn-var (none)
nthreads-var num_threads
run-sched-var schedule
table continued on next page
72OpenMP API – Version 5.0 November 2018
table continued from previous page
ICV construct clause, if used
def-sched-var schedule
bind-var proc_bind
stacksize-var (none)
wait-policy-var (none)
thread-limit-var (none)
max-active-levels-var (none)
active-levels-var (none)
levels-var (none)
place-partition-var (none)
cancel-var (none)
display-aﬃnity-var (none)
aﬃnity-format-var (none)
default-device-var (none)
target-oﬄoad-var (none)
max-task-priority-var (none)
tool-var (none)
tool-libraries-var (none)
debug-var (none)
def-allocator-var allocator
Description 1
Thenum_threads clause overrides the value of the ﬁrst element of the nthreads-var ICV. 2
If aschedule clause speciﬁes a modiﬁer then that modiﬁer overrides any modiﬁer that is 3
speciﬁed in the run-sched-var ICV. 4
Ifbind-varis notset to falsethen the proc_bind clause overridesthe valueof theﬁrst element 5
of thebind-varICV; otherwise, the proc_bind clause has no eﬀect. 6
Cross References 7
parallel construct, see Section 2.6 on page 74. 8
proc_bind clause, Section 2.6 on page 74. 9
num_threads clause, see Section 2.6.1 on page 78. 10
CHAPTER 2. DIRECTIVES 73
Worksharing-Loop construct, see Section 2.9.2 on page 101. 1
schedule clause, see Section 2.9.2.1 on page 109. 2
2.6 parallel Construct 3
Summary 4
The parallel construct creates a team of OpenMP threads that execute the region. 5
Syntax 6
C / C++
The syntax of the parallel construct is as follows: 7
#pragma omp parallel [clause[ [ ,] clause] ... ] new-line 8
structured-block 9
whereclauseis one of the following: 10
if([parallel : ] scalar-expression ) 11
num_threads( integer-expression ) 12
default(shared | none) 13
private( list) 14
firstprivate( list) 15
shared( list) 16
copyin( list) 17
reduction( [reduction-modiﬁer ,] reduction-identiﬁer :list) 18
proc_bind(master | close | spread) 19
allocate( [allocator :] list) 20
C / C++
74OpenMP API – Version 5.0 November 2018
Fortran
The syntax of the parallel construct is as follows: 1
!$omp parallel [clause[ [ ,] clause] ... ] 2
structured-block 3
!$omp end parallel 4
whereclauseis one of the following: 5
if([parallel : ] scalar-logical-expression ) 6
num_threads( scalar-integer-expression ) 7
default(private | firstprivate | shared | none) 8
private( list) 9
firstprivate( list) 10
shared( list) 11
copyin( list) 12
reduction( [reduction-modiﬁer ,] reduction-identiﬁer :list) 13
proc_bind(master | close | spread) 14
allocate( [allocator :] list) 15
Fortran
Binding 16
Thebindingthreadsetfora parallel regionistheencounteringthread. Theencounteringthread 17
becomes the master thread of the new team. 18
Description 19
When a thread encounters a parallel construct, a team of threads is created to execute the 20
parallel region (see Section 2.6.1 on page 78 for more information about how the number of 21
threads in the team is determined, including the evaluation of the ifandnum_threads clauses). 22
The thread that encountered the parallel construct becomes the master thread of the new team, 23
with a thread number of zero for the duration of the new parallel region. All threads in the new 24
team, including the master thread, execute the region. Once the team is created, the number of 25
threads in the team remains constant for the duration of that parallel region. 26
The optional proc_bind clause, described in Section 2.6.2 on page 80, speciﬁes the mapping of 27
OpenMP threads to places within the current place partition, that is, within the places listed in the 28
place-partition-var ICV for the implicit task of the encountering thread. 29
Within a parallel region, thread numbers uniquely identify each thread. Thread numbers are 30
consecutive whole numbers ranging from zero for the master thread up to one less than the number 31
CHAPTER 2. DIRECTIVES 75
of threads in the team. A thread may obtain its own thread number by a call to the 1
omp_get_thread_num library routine. 2
A set of implicit tasks, equal in number to the number of threads in the team, is generated by the 3
encountering thread. The structured block of the parallel construct determines the code that 4
will be executed in each implicit task. Each task is assigned to a diﬀerent thread in the team and 5
becomes tied. The task region of the task being executed by the encountering thread is suspended 6
and each thread in the team executes its implicit task. Each thread can execute a path of statements 7
that is diﬀerent from that of the other threads. 8
The implementation may cause any thread to suspend execution of its implicit task at a task 9
scheduling point, and to switch to execution of any explicit task generated by any of the threads in 10
the team, before eventually resuming execution of the implicit task (for more details see 11
Section 2.10 on page 135). 12
There is an implied barrier at the end of a parallel region. After the end of a parallel 13
region, only the master thread of the team resumes execution of the enclosing task region. 14
If a thread in a team executing a parallel region encounters another parallel directive, it 15
createsanewteam,accordingtotherulesinSection2.6.1onpage78,anditbecomesthemasterof 16
that new team. 17
If execution of a thread terminates while inside a parallel region, execution of all threads in all 18
teamsterminates. Theorderofterminationofthreadsisunspeciﬁed. Allworkdonebyateamprior 19
to any barrier that the team has passed in the program is guaranteed to be complete. The amount of 20
work done by each thread after the last barrier that it passed and before it terminates is unspeciﬁed. 21
Execution Model Events 22
Theparallel-begin event occurs in a thread that encounters a parallel construct before any 23
implicit task is created for the corresponding parallel region. 24
Upon creation of each implicit task, an implicit-task-begin event occurs in the thread that executes 25
the implicit task after the implicit task is fully initialized but before the thread begins to execute the 26
structured block of the parallel construct. 27
If the parallel region creates a native thread, a native-thread-begin event occurs as the ﬁrst 28
event in the context of the new thread prior to the implicit-task-begin event. 29
Events associated with implicit barriers occur at the end of a parallel region. Section 2.17.3 30
describes events associated with implicit barriers. 31
When a thread ﬁnishes an implicit task, an implicit-task-end event occurs in the thread after events 32
associated with implicit barrier synchronization in the implicit task. 33
Theparallel-end event occurs in the thread that encounters the parallel construct after the 34
thread executes its implicit-task-end event but before the thread resumes execution of the 35
encountering task. 36
76OpenMP API – Version 5.0 November 2018
If a native thread is destroyed at the end of a parallel region, anative thread-end event occurs 1
in the thread as the last event prior to destruction of the thread. 2
Tool Callbacks 3
A thread dispatches a registered ompt_callback_parallel_begin callback for each 4
occurrence of a parallel-begin event in that thread. The callback occurs in the task that encounters 5
theparallel construct. This callback has the type signature 6
ompt_callback_parallel_begin_t . In the dispatched callback, 7
(ﬂags& ompt_parallel_team) evaluates to true. 8
A thread dispatches a registered ompt_callback_implicit_task callback with 9
ompt_scope_begin as itsendpoint argument for each occurrence of an implicit-task-begin 10
event in that thread. Similarly, a thread dispatches a registered 11
ompt_callback_implicit_task callback with ompt_scope_end as itsendpoint 12
argument for each occurrence of an implicit-task-end event in that thread. The callbacks occur in 13
the context of the implicit task and have type signature ompt_callback_implicit_task_t . 14
In the dispatched callback, (ﬂags& ompt_task_implicit) evaluates to true. 15
A thread dispatches a registered ompt_callback_parallel_end callback for each 16
occurrence of a parallel-end event in that thread. The callback occurs in the task that encounters 17
theparallel construct. This callback has the type signature 18
ompt_callback_parallel_end_t . 19
A thread dispatches a registered ompt_callback_thread_begin callback for the 20
native-thread-begin event in that thread. The callback occurs in the context of the thread. The 21
callback has type signature ompt_callback_thread_begin_t . 22
A thread dispatches a registered ompt_callback_thread_end callback for the 23
native-thread-end event in that thread. The callback occurs in the context of the thread. The 24
callback has type signature ompt_callback_thread_end_t . 25
Restrictions 26
Restrictions to the parallel construct are as follows: 27
A program that branches into or out of a parallel region is non-conforming. 28
A program must not depend on any ordering of the evaluations of the clauses of the parallel 29
directive, or on any side eﬀects of the evaluations of the clauses. 30
At most one ifclause can appear on the directive. 31
At most one proc_bind clause can appear on the directive. 32
At most one num_threads clause can appear on the directive. The num_threads 33
expression must evaluate to a positive integer value. 34
CHAPTER 2. DIRECTIVES 77
C++
Athrowexecuted inside a parallel region must cause execution to resume within the same 1
parallel region, and the same thread that threw the exception must catch it. 2
C++
Cross References 3
OpenMP execution model, see Section 1.3 on page 20. 4
num_threads clause, see Section 2.6 on page 74. 5
proc_bind clause, see Section 2.6.2 on page 80. 6
allocate clause, see Section 2.11.4 on page 158. 7
ifclause, see Section 2.15 on page 220. 8
default ,shared,private ,firstprivate , andreduction clauses, see 9
Section 2.19.4 on page 282. 10
copyin clause, see Section 2.19.6 on page 309. 11
omp_get_thread_num routine, see Section 3.2.4 on page 337. 12
ompt_scope_begin andompt_scope_end , see Section 4.4.4.11 on page 443. 13
ompt_callback_thread_begin_t , see Section 4.5.2.1 on page 459. 14
ompt_callback_thread_end_t , see Section 4.5.2.2 on page 460. 15
ompt_callback_parallel_begin_t , see Section 4.5.2.3 on page 461. 16
ompt_callback_parallel_end_t , see Section 4.5.2.4 on page 463. 17
ompt_callback_implicit_task_t , see Section 4.5.2.11 on page 471. 18
2.6.1 Determining the Number of Threads for a parallel Region 19
When execution encounters a parallel directive, the value of the ifclause or num_threads 20
clause (if any) on the directive, the current parallel context, and the values of the nthreads-var , 21
dyn-var,thread-limit-var , andmax-active-levels-var ICVs are used to determine the number of 22
threads to use in the region. 23
Using a variable in an ifornum_threads clause expression of a parallel construct causes 24
an implicit reference to the variable in all enclosing constructs. The ifclause expression and the 25
num_threads clauseexpressionareevaluatedinthecontextoutsideofthe parallel construct, 26
78OpenMP API – Version 5.0 November 2018
and no ordering of those evaluations is speciﬁed. In what order or how many times any side eﬀects 1
of the evaluation of the num_threads orifclause expressions occur is also unspeciﬁed. 2
When a thread encounters a parallel construct, the number of threads is determined according 3
to Algorithm 2.1. 4
5
Algorithm 2.16
7
letThreadsBusy be the number of OpenMP threads currently executing in this contention group; 8
letActiveParRegions be the number of enclosing active parallel regions; 9
ifanifclause exists 10
then letIfClauseValue be the value of the ifclause expression; 11
else letIfClauseValue =true; 12
ifanum_threads clause exists 13
then letThreadsRequested be the value of the num_threads clause expression; 14
else letThreadsRequested = value of the ﬁrst element of nthreads-var ; 15
letThreadsAvailable = (thread-limit-var -ThreadsBusy + 1); 16
if(IfClauseValue =false) 17
thennumber of threads = 1; 18
else if(ActiveParRegions =max-active-levels-var ) 19
thennumber of threads = 1; 20
else if(dyn-var=true)and(ThreadsRequested ThreadsAvailable ) 21
then1number of threads ThreadsRequested ; 22
else if(dyn-var=true)and(ThreadsRequested >ThreadsAvailable ) 23
then1number of threads ThreadsAvailable ; 24
else if(dyn-var=false)and(ThreadsRequested ThreadsAvailable ) 25
thennumber of threads = ThreadsRequested ; 26
else if(dyn-var=false)and(ThreadsRequested >ThreadsAvailable ) 27
thenbehavior is implementation deﬁned; 28
29
30
CHAPTER 2. DIRECTIVES 79
1
Note– Sincetheinitialvalueofthe dyn-varICVisimplementationdeﬁned,programsthatdepend 2
on a speciﬁc number of threads for correct execution should explicitly disable dynamic adjustment 3
of the number of threads. 4
5
Cross References 6
nthreads-var ,dyn-var,thread-limit-var , andmax-active-levels-var ICVs, see Section 2.5 on 7
page 63. 8
parallel construct, see Section 2.6 on page 74. 9
num_threads clause, see Section 2.6 on page 74. 10
ifclause, see Section 2.15 on page 220. 11
2.6.2 Controlling OpenMP Thread Afﬁnity 12
When a thread encounters a parallel directive without a proc_bind clause, the bind-varICV 13
is used to determine the policy for assigning OpenMP threads to places within the current place 14
partition, that is, within the places listed in the place-partition-var ICV for the implicit task of the 15
encountering thread. If the parallel directive has a proc_bind clause then the binding policy 16
speciﬁed by the proc_bind clause overrides the policy speciﬁed by the ﬁrst element of the 17
bind-varICV.Onceathreadintheteamisassignedtoaplace,theOpenMPimplementationshould 18
not move it to another place. 19
Themaster threadaﬃnitypolicyinstructstheexecutionenvironmenttoassigneverythreadinthe 20
team to the same place as the master thread. The place partition is not changed by this policy, and 21
each implicit task inherits the place-partition-var ICV of the parent implicit task. 22
Theclosethread aﬃnity policy instructs the execution environment to assign the threads in the 23
team to places close to the place of the parent thread. The place partition is not changed by this 24
policy, and each implicit task inherits the place-partition-var ICV of the parent implicit task. If T 25
is the number of threads in the team, and Pis the number of places in the parent’s place partition, 26
then the assignment of threads in the team to places is as follows: 27
TP: The master thread executes on the place of the parent thread. The thread with the next 28
smallest thread number executes on the next place in the place partition, and so on, with wrap 29
around with respect to the place partition of the master thread. 30
80OpenMP API – Version 5.0 November 2018
T > P: Each place pwill contain Spthreads with consecutive thread numbers where 1
b bT=P c cSpd dT=P e e. The ﬁrst S0threads (including the master thread) are assigned to the 2
place of the parent thread. The next S1threads are assigned to the next place in the place 3
partition, and so on, with wrap around with respect to the place partition of the master thread. 4
When Pdoes not divide Tevenly, the exact number of threads in a particular place is 5
implementation deﬁned. 6
The purpose of the spread thread aﬃnity policy is to create a sparse distribution for a team of T 7
threads among the Pplaces of the parent’s place partition. A sparse distribution is achieved by ﬁrst 8
subdividing the parent partition into Tsubpartitions if TP, orPsubpartitions if T > P. Then 9
one thread ( TP) or a set of threads ( T > P) is assigned to each subpartition. The 10
place-partition-var ICV of each implicit task is set to its subpartition. The subpartitioning is not 11
only a mechanism for achieving a sparse distribution, it also deﬁnes a subset of places for a thread 12
tousewhencreatinganested parallel region. Theassignmentofthreadstoplacesisasfollows: 13
TP: The parent thread’s place partition is split into Tsubpartitions, where each subpartition 14
contains b bP=T c cord dP=T e econsecutive places. A single thread is assigned to each subpartition. 15
The master thread executes on the place of the parent thread and is assigned to the subpartition 16
that includes that place. The thread with the next smallest thread number is assigned to the ﬁrst 17
place in the next subpartition, and so on, with wrap around with respect to the original place 18
partition of the master thread. 19
T > P: The parent thread’s place partition is split into Psubpartitions, each consisting of a 20
single place. Each subpartition is assigned Spthreads with consecutive thread numbers, where 21
b bT=P c cSpd dT=P e e. The ﬁrst S0threads (including the master thread) are assigned to the 22
subpartition containing the place of the parent thread. The next S1threads are assigned to the 23
next subpartition, and so on, with wrap around with respect to the original place partition of the 24
master thread. When P does not divide Tevenly, the exact number of threads in a particular 25
subpartition is implementation deﬁned. 26
The determination of whether the aﬃnity request can be fulﬁlled is implementation deﬁned. If the 27
aﬃnityrequestcannotbefulﬁlled,thentheaﬃnityofthreadsintheteamisimplementationdeﬁned. 28
29
Note– Wrap around is needed if the end of a place partition is reached before all thread 30
assignmentsare done. Forexample, wraparound maybe neededin thecase of closeandTP, 31
if the master thread is assigned to a place other than the ﬁrst place in the place partition. In this 32
case, thread 1 is assigned to the place after the place of the master place, thread 2 is assigned to the 33
place after that, and so on. The end of the place partition may be reached before all threads are 34
assigned. In this case, assignment of threads is resumed with the ﬁrst place in the place partition. 35
36
CHAPTER 2. DIRECTIVES 81
2.7 teams Construct 1
Summary 2
Theteamsconstruct creates a league of initial teams and the initial thread in each team executes 3
the region. 4
Syntax 5
C / C++
The syntax of the teamsconstruct is as follows: 6
#pragma omp teams [clause[ [ ,] clause] ... ] new-line 7
structured-block 8
whereclauseis one of the following: 9
num_teams( integer-expression ) 10
thread_limit( integer-expression ) 11
default(shared | none) 12
private( list) 13
firstprivate( list) 14
shared( list) 15
reduction( [default , ] reduction-identiﬁer :list) 16
allocate( [allocator :] list) 17
C / C++
Fortran
The syntax of the teamsconstruct is as follows: 18
!$omp teams [clause[ [ ,] clause] ... ] 19
structured-block 20
!$omp end teams 21
82OpenMP API – Version 5.0 November 2018
whereclauseis one of the following: 1
num_teams( scalar-integer-expression ) 2
thread_limit( scalar-integer-expression ) 3
default(shared | firstprivate | private | none) 4
private( list) 5
firstprivate( list) 6
shared( list) 7
reduction( [default , ] reduction-identiﬁer :list) 8
allocate( [allocator :] list) 9
Fortran
Binding 10
The binding thread set for a teamsregion is the encountering thread. 11
Description 12
When a thread encounters a teamsconstruct, a league of teams is created. Each team is an initial 13
team, and the initial thread in each team executes the teamsregion. 14
The number of teams created is implementation deﬁned, but is less than or equal to the value 15
speciﬁed in the num_teams clause. A thread may obtain the number of initial teams created by 16
the construct by a call to the omp_get_num_teams routine. 17
The maximum number of threads participating in the contention group that each team initiates is 18
implementation deﬁned, but is less than or equal to the value speciﬁed in the thread_limit 19
clause. 20
On a combined or composite construct that includes target andteamsconstructs, the 21
expressions in num_teams andthread_limit clauses are evaluated on the host device on 22
entry to the target construct. 23
Once the teams are created, the number of initial teams remains constant for the duration of the 24
teamsregion. 25
Within a teamsregion, initial team numbers uniquely identify each initial team. Initial team 26
numbers are consecutive whole numbers ranging from zero to one less than the number of initial 27
teams. A thread may obtain its own initial team number by a call to the omp_get_team_num 28
libraryroutine. Thepolicyforassigningtheinitialthreadstoplacesisimplementationdeﬁned. The 29
teamsconstruct sets the place-partition-var anddefault-device-var ICVs for each initial thread to 30
an implementation-deﬁned value. 31
After the teams have completed execution of the teamsregion, the encountering task resumes 32
execution of the enclosing task region. 33
CHAPTER 2. DIRECTIVES 83
Execution Model Events 1
Theteams-begin event occurs in a thread that encounters a teamsconstruct before any initial task 2
is created for the corresponding teamsregion. 3
Upon creation of each initial task, an initial-task-begin event occurs in the thread that executes the 4
initial task after the initial task is fully initialized but before the thread begins to execute the 5
structured block of the teamsconstruct. 6
If the teamsregion creates a native thread, a native-thread-begin event occurs as the ﬁrst event in 7
the context of the new thread prior to the initial-task-begin event. 8
When a thread ﬁnishes an initial task, an initial-task-end event occurs in the thread. 9
Theteams-end event occurs in the thread that encounters the teamsconstruct after the thread 10
executes its initial-task-end event but before it resumes execution of the encountering task. 11
Ifanativethreadisdestroyedattheendofa teamsregion,anative-thread-end eventoccursinthe 12
thread as the last event prior to destruction of the thread. 13
Tool Callbacks 14
A thread dispatches a registered ompt_callback_parallel_begin callback for each 15
occurrenceofa teams-begin eventinthatthread. Thecallbackoccursinthetaskthatencountersthe 16
teamsconstruct. This callback has the type signature 17
ompt_callback_parallel_begin_t . In the dispatched callback, 18
(ﬂags& ompt_parallel_league) evaluates to true. 19
A thread dispatches a registered ompt_callback_implicit_task callback with 20
ompt_scope_begin as itsendpoint argument for each occurrence of an initial-task-begin in 21
that thread. Similarly, a thread dispatches a registered ompt_callback_implicit_task 22
callback with ompt_scope_end as itsendpoint argument for each occurrence of an 23
initial-task-end event in that thread. The callbacks occur in the context of the initial task and have 24
type signature ompt_callback_implicit_task_t . In the dispatched callback, 25
(ﬂags& ompt_task_initial) evaluates to true. 26
A thread dispatches a registered ompt_callback_parallel_end callback for each 27
occurrence of a teams-end event in that thread. The callback occurs in the task that encounters the 28
teamsconstruct. This callback has the type signature ompt_callback_parallel_end_t . 29
A thread dispatches a registered ompt_callback_thread_begin callback for the 30
native-thread-begin event in that thread. The callback occurs in the context of the thread. The 31
callback has type signature ompt_callback_thread_begin_t . 32
A thread dispatches a registered ompt_callback_thread_end callback for the 33
native-thread-end event in that thread. The callback occurs in the context of the thread. The 34
callback has type signature ompt_callback_thread_end_t . 35
84OpenMP API – Version 5.0 November 2018
Restrictions 1
Restrictions to the teamsconstruct are as follows: 2
A program that branches into or out of a teamsregion is non-conforming. 3
A program must not depend on any ordering of the evaluations of the clauses of the teams 4
directive, or on any side eﬀects of the evaluation of the clauses. 5
At most one thread_limit clause can appear on the directive. The thread_limit 6
expression must evaluate to a positive integer value. 7
At most one num_teams clause can appear on the directive. The num_teams expression must 8
evaluate to a positive integer value. 9
Ateamsregion can only be strictly nested within the implicit parallel region or a target 10
region. If a teamsconstruct is nested within a target construct, that target construct must 11
contain no statements, declarations or directives outside of the teamsconstruct. 12
distribute ,distribute simd , distribute parallel worksharing-loop, distribute parallel 13
worksharing-loop SIMD, parallel regions, including any parallel regions arising from 14
combined constructs, omp_get_num_teams() regions, and omp_get_team_num() 15
regions are the only OpenMP regions that may be strictly nested inside the teamsregion. 16
Cross References 17
parallel construct, see Section 2.6 on page 74. 18
distribute construct, see Section 2.9.4.1 on page 120. 19
distribute simd construct, see Section 2.9.4.2 on page 123. 20
allocate clause, see Section 2.11.4 on page 158. 21
target construct, see Section 2.12.5 on page 170. 22
default ,shared,private ,firstprivate , andreduction clauses, see 23
Section 2.19.4 on page 282. 24
omp_get_num_teams routine, see Section 3.2.38 on page 373. 25
omp_get_team_num routine, see Section 3.2.39 on page 374. 26
ompt_callback_thread_begin_t , see Section 4.5.2.1 on page 459. 27
ompt_callback_thread_end_t , see Section 4.5.2.2 on page 460. 28
ompt_callback_parallel_begin_t , see Section 4.5.2.3 on page 461. 29
ompt_callback_parallel_end_t , see Section 4.5.2.4 on page 463. 30
ompt_callback_implicit_task_t , see Section 4.5.2.11 on page 471. 31
CHAPTER 2. DIRECTIVES 85
2.8 Worksharing Constructs1
A worksharing construct distributes the execution of the corresponding region among the members 2
of the team that encounters it. Threads execute portions of the region in the context of the implicit 3
tasksthateachoneisexecuting. Iftheteamconsistsofonlyonethreadthentheworksharingregion 4
is not executed in parallel. 5
A worksharing region has no barrier on entry; however, an implied barrier exists at the end of the 6
worksharing region, unless a nowait clause is speciﬁed. If a nowait clause is present, an 7
implementation may omit the barrier at the end of the worksharing region. In this case, threads that 8
ﬁnish early may proceed straight to the instructions that follow the worksharing region without 9
waitingfortheothermembersoftheteamtoﬁnishtheworksharingregion,andwithoutperforming 10
a ﬂush operation. 11
The OpenMP API deﬁnes the worksharing constructs that are described in this section as well as 12
the worksharing-loop construct, which is described in Section 2.9.2 on page 101. 13
Restrictions 14
The following restrictions apply to worksharing constructs: 15
Each worksharing region must be encountered by all threads in a team or by none at all, unless 16
cancellation has been requested for the innermost enclosing parallel region. 17
The sequence of worksharing regions and barrier regions encountered must be the same for 18
every thread in a team. 19
2.8.1 sections Construct 20
Summary 21
Thesections construct is a non-iterative worksharing construct that contains a set of structured 22
blocks that are to be distributed among and executed by the threads in a team. Each structured 23
block is executed once by one of the threads in the team in the context of its implicit task. 24
86OpenMP API – Version 5.0 November 2018
Syntax 1
C / C++
The syntax of the sections construct is as follows: 2
#pragma omp sections [clause[ [ ,] clause] ... ] new-line 3
{ 4
[#pragma omp section new-line] 5
structured-block 6
[#pragma omp section new-line 7
structured-block] 8
... 9
} 10
whereclauseis one of the following: 11
private( list) 12
firstprivate( list) 13
lastprivate( [ lastprivate-modiﬁer :] list) 14
reduction( [reduction-modiﬁer ,] reduction-identiﬁer :list) 15
allocate( [allocator :] list) 16
nowait 17
C / C++
Fortran
The syntax of the sections construct is as follows: 18
!$omp sections [clause[ [ ,] clause] ... ] 19
[!$omp section ] 20
structured-block 21
[!$omp section 22
structured-block] 23
... 24
!$omp end sections [nowait] 25
whereclauseis one of the following: 26
private( list) 27
firstprivate( list) 28
lastprivate( [ lastprivate-modiﬁer :] list) 29
reduction( [reduction-modiﬁer ,] reduction-identiﬁer :list) 30
allocate( [allocator :] list) 31
Fortran
CHAPTER 2. DIRECTIVES 87
Binding 1
The binding thread set for a sections region is the current team. A sections region binds to 2
the innermost enclosing parallel region. Only the threads of the team that executes the binding 3
parallel region participate in the execution of the structured blocks and the implied barrier of 4
thesections region if the barrier is not eliminated by a nowait clause. 5
Description 6
Each structured block in the sections construct is preceded by a section directive except 7
possibly the ﬁrst block, for which a preceding section directive is optional. 8
The method of scheduling the structured blocks among the threads in the team is implementation 9
deﬁned. 10
There is an implicit barrier at the end of a sections construct unless a nowait clause is 11
speciﬁed. 12
Execution Model Events 13
Thesection-begin event occurs after an implicit task encounters a sections construct but before 14
the task executes any structured block of the sections region. 15
Thesections-end event occurs after an implicit task ﬁnishes execution of a sections region but 16
before it resumes execution of the enclosing context. 17
Thesection-begin event occurs before an implicit task starts to execute a structured block in the 18
sections construct for each of those structured blocks that the task executes. 19
Tool Callbacks 20
A thread dispatches a registered ompt_callback_work callback with ompt_scope_begin 21
as itsendpoint argument and ompt_work_sections as itswstypeargument for each 22
occurrence of a section-begin event in that thread. Similarly, a thread dispatches a registered 23
ompt_callback_work callback with ompt_scope_end as itsendpoint argument and 24
ompt_work_sections as itswstypeargument for each occurrence of a sections-end event in 25
that thread. The callbacks occur in the context of the implicit task. The callbacks have type 26
signature ompt_callback_work_t . 27
A thread dispatches a registered ompt_callback_dispatch callback for each occurrence of a 28
section-begin event in that thread. The callback occurs in the context of the implicit task. The 29
callback has type signature ompt_callback_dispatch_t . 30
88OpenMP API – Version 5.0 November 2018
Restrictions 1
Restrictions to the sections construct are as follows: 2
Orphaned section directives are prohibited. That is, the section directives must appear 3
within the sections construct and must not be encountered elsewhere in the sections 4
region. 5
The code enclosed in a sections construct must be a structured block. 6
Only a single nowait clause can appear on a sections directive. 7
C++
A throw executed inside a sections region must cause execution to resume within the same 8
section of the sections region, and the same thread that threw the exception must catch it. 9
C++
Cross References 10
allocate clause, see Section 2.11.4 on page 158. 11
private ,firstprivate ,lastprivate ,andreduction clauses,seeSection2.19.4on 12
page 282. 13
ompt_scope_begin andompt_scope_end , see Section 4.4.4.11 on page 443. 14
ompt_work_sections , see Section 4.4.4.15 on page 445. 15
ompt_callback_work_t , see Section 4.5.2.5 on page 464. 16
ompt_callback_dispatch_t , see Section 4.5.2.6 on page 465. 17
2.8.2 single Construct 18
Summary 19
Thesingle construct speciﬁes that the associated structured block is executed by only one of the 20
threads in the team (not necessarily the master thread), in the context of its implicit task. The other 21
threads in the team, which do not execute the block, wait at an implicit barrier at the end of the 22
single construct unless a nowait clause is speciﬁed. 23
CHAPTER 2. DIRECTIVES 89
Syntax 1
C / C++
The syntax of the single construct is as follows: 2
#pragma omp single [clause[ [ ,] clause] ... ] new-line 3
structured-block 4
whereclauseis one of the following: 5
private( list) 6
firstprivate( list) 7
copyprivate( list) 8
allocate( [allocator :] list) 9
nowait 10
C / C++
Fortran
The syntax of the single construct is as follows: 11
!$omp single [clause[ [ ,] clause] ... ] 12
structured-block 13
!$omp end single [end_clause[ [ ,] end_clause] ... ] 14
whereclauseis one of the following: 15
private( list) 16
firstprivate( list) 17
allocate( [allocator :] list) 18
andend_clause is one of the following: 19
copyprivate( list) 20
nowait 21
Fortran
Binding 22
The binding thread set for a single region is the current team. A single region binds to the 23
innermost enclosing parallel region. Only the threads of the team that executes the binding 24
parallel regionparticipateintheexecutionofthestructuredblockandtheimpliedbarrierofthe 25
single region if the barrier is not eliminated by a nowait clause. 26
90OpenMP API – Version 5.0 November 2018
Description 1
Onlyoneoftheencounteringthreadswillexecutethestructuredblockassociatedwiththe single 2
construct. The method of choosing a thread to execute the structured block each time the team 3
encounters the construct is implementation deﬁned. There is an implicit barrier at the end of the 4
single construct unless a nowait clause is speciﬁed. 5
Execution Model Events 6
Thesingle-begin event occurs after an implicit task encounters a single construct but 7
before the task starts to execute the structured block of the single region. 8
Thesingle-end eventoccursafteranimplicittaskﬁnishesexecutionofa single regionbutbefore 9
it resumes execution of the enclosing region. 10
Tool Callbacks 11
A thread dispatches a registered ompt_callback_work callback with ompt_scope_begin 12
as itsendpoint argument for each occurrence of a single-begin event in that thread. Similarly, a 13
thread dispatches a registered ompt_callback_work callback with ompt_scope_begin as 14
itsendpoint argument for each occurrence of a single-end event in that thread. For each of these 15
callbacks, the wstypeargument is ompt_work_single_executor if the thread executes the 16
structured block associated with the single region; otherwise, the wstypeargument is 17
ompt_work_single_other . The callback has type signature ompt_callback_work_t . 18
Restrictions 19
Restrictions to the single construct are as follows: 20
Thecopyprivate clause must not be used with the nowait clause. 21
At most one nowait clause can appear on a single construct. 22
C++
A throw executed inside a single region must cause execution to resume within the same 23
single region, and the same thread that threw the exception must catch it. 24
C++
CHAPTER 2. DIRECTIVES 91
Cross References 1
allocate clause, see Section 2.11.4 on page 158. 2
private andfirstprivate clauses, see Section 2.19.4 on page 282. 3
copyprivate clause, see Section 2.19.6.2 on page 312. 4
ompt_scope_begin andompt_scope_end , see Section 4.4.4.11 on page 443. 5
ompt_work_single_executor andompt_work_single_other , see Section 4.4.4.15 6
on page 445. 7
ompt_callback_work_t , Section 4.5.2.5 on page 464. 8
Fortran
2.8.3 workshare Construct 9
Summary 10
Theworkshare construct divides the execution of the enclosed structured block into separate 11
units of work, and causes the threads of the team to share the work such that each unit is executed 12
only once by one thread, in the context of its implicit task. 13
Syntax 14
The syntax of the workshare construct is as follows: 15
!$omp workshare 16
structured-block 17
!$omp end workshare [nowait] 18
Binding 19
The binding thread set for a workshare region is the current team. A workshare region binds 20
to the innermost enclosing parallel region. Only the threads of the team that executes the 21
binding parallel region participate in the execution of the units of work and the implied barrier 22
of the workshare region if the barrier is not eliminated by a nowait clause. 23
92OpenMP API – Version 5.0 November 2018
Fortran (cont.)
Description 1
There is an implicit barrier at the end of a workshare construct unless a nowait clause is 2
speciﬁed. 3
An implementation of the workshare construct must insert any synchronization that is required 4
to maintain standard Fortran semantics. For example, the eﬀects of one statement within the 5
structured block must appear to occur before the execution of succeeding statements, and the 6
evaluation of the right hand side of an assignment must appear to complete prior to the eﬀects of 7
assigning to the left hand side. 8
The statements in the workshare construct are divided into units of work as follows: 9
For array expressions within each statement, including transformational array intrinsic functions 10
that compute scalar values from arrays: 11
–Evaluation of each element of the array expression, including any references to ELEMENTAL 12
functions, is a unit of work. 13
–Evaluation of transformational array intrinsic functions may be freely subdivided into any 14
number of units of work. 15
For an array assignment statement, the assignment of each element is a unit of work. 16
For a scalar assignment statement, the assignment operation is a unit of work. 17
For a WHEREstatement or construct, the evaluation of the mask expression and the masked 18
assignments are each a unit of work. 19
For a FORALL statement or construct, the evaluation of the mask expression, expressions 20
occurring in the speciﬁcation of the iteration space, and the masked assignments are each a unit 21
of work. 22
For an atomic construct, the atomic operation on the storage location designated as xis a unit 23
of work. 24
For a critical construct, the construct is a single unit of work. 25
For a parallel construct, the construct is a unit of work with respect to the workshare 26
construct. The statements contained in the parallel construct are executed by a new thread 27
team. 28
If none of the rules above apply to a portion of a statement in the structured block, then that 29
portion is a unit of work. 30
The transformational array intrinsic functions are MATMUL,DOT_PRODUCT ,SUM,PRODUCT , 31
MAXVAL,MINVAL,COUNT,ANY,ALL,SPREAD,PACK,UNPACK,RESHAPE ,TRANSPOSE , 32
EOSHIFT ,CSHIFT,MINLOC, andMAXLOC. 33
It is unspeciﬁed how the units of work are assigned to the threads executing a workshare region. 34
CHAPTER 2. DIRECTIVES 93
Fortran (cont.)
If an array expression in the block references the value, association status, or allocation status of 1
private variables, the value of the expression is undeﬁned, unless the same value would be 2
computed by every thread. 3
If an array assignment, a scalar assignment, a masked array assignment, or a FORALL assignment 4
assigns to a private variable in the block, the result is unspeciﬁed. 5
Theworkshare directive causes the sharing of work to occur only in the workshare construct, 6
and not in the remainder of the workshare region. 7
Execution Model Events 8
Theworkshare-begin event occurs after an implicit task encounters a workshare construct but 9
before the task starts to execute the structured block of the workshare region. 10
Theworkshare-end event occurs after an implicit task ﬁnishes execution of a workshare region 11
but before it resumes execution of the enclosing context. 12
Tool Callbacks 13
A thread dispatches a registered ompt_callback_work callback with ompt_scope_begin 14
as itsendpoint argument and ompt_work_workshare as itswstypeargument for each 15
occurrence of a workshare-begin event in that thread. Similarly, a thread dispatches a registered 16
ompt_callback_work callback with ompt_scope_end as itsendpoint argument and 17
ompt_work_workshare as itswstypeargument for each occurrence of a workshare-end event 18
in that thread. The callbacks occur in the context of the implicit task. The callbacks have type 19
signature ompt_callback_work_t . 20
Restrictions 21
The following restrictions apply to the workshare construct: 22
The only OpenMP constructs that may be closely nested inside a workshare construct are the 23
atomic,critical , andparallel constructs. 24
Base language statements that are encountered inside a workshare construct but that are not 25
enclosed within a parallel construct that is nested inside the workshare construct must 26
consist of only the following: 27
–array assignments 28
–scalar assignments 29
–FORALL statements 30
–FORALL constructs 31
–WHEREstatements 32
94OpenMP API – Version 5.0 November 2018
–WHEREconstructs 1
All array assignments, scalar assignments, and masked array assignments that are encountered 2
inside a workshare construct but are not nested inside a parallel construct that is nested 3
inside the workshare construct must be intrinsic assignments. 4
The construct must not contain any user deﬁned function calls unless the function is 5
ELEMENTAL or the function call is contained inside a parallel construct that is nested inside 6
theworkshare construct. 7
Cross References 8
parallel construct, see Section 2.6 on page 74. 9
critical construct, see Section 2.17.1 on page 223. 10
atomic construct, see Section 2.17.7 on page 234. 11
ompt_scope_begin andompt_scope_end , see Section 4.4.4.11 on page 443. 12
ompt_work_workshare , see Section 4.4.4.15 on page 445. 13
ompt_callback_work_t , see Section 4.5.2.5 on page 464. 14
Fortran
2.9 Loop-Related Directives 15
2.9.1 Canonical Loop Form 16
C / C++
The loops associated with a loop-associated directive have canonical loop form if they conform to 17
the following: 18
for (init-expr ;test-expr ;incr-expr )structured-block
init-expr One of the following:
var=lb
integer-type var =lb
random-access-iterator-type var =lb
pointer-type var =lb
continued on next page
CHAPTER 2. DIRECTIVES 95
C/C++ (cont.)
continued from previous page
test-expr One of the following:
var relational-op b
b relational-op var
incr-expr One of the following:
++var
var++
- -var
var- -
var+=incr
var- =incr
var=var+incr
var=incr+var
var=var-incr
var One of the following:
A variable of a signed or unsigned integer type.
For C++, a variable of a random access iterator type.
For C, a variable of a pointer type.
This variable must not be modiﬁed during the execution of the for-loopother
than inincr-expr.
relational-op One of the following:
<
<=
>
>=
!=
lbandb Expressions of a type compatible with the type of varthat are loop invariant
with respect to the outermost associated loop or are one of the following (where
var-outer,a1, anda2have a type compatible with the type of var,var-outer
isvarfrom an outer associated loop, and a1anda2are loop invariant integer
expressions with respect to the outermost loop):
continued on next page
96OpenMP API – Version 5.0 November 2018
continued from previous page
var-outer
var-outer +a2
a2+var-outer
var-outer -a2
a2-var-outer
a1*var-outer
a1*var-outer +a2
a2+a1*var-outer
a1*var-outer -a2
a2-a1*var-outer
var-outer *a1
var-outer *a1+a2
a2+var-outer *a1
var-outer *a1-a2
a2-var-outer *a1
incr An integer expression that is loop invariant with respect to the outermost
associated loop.
C / C++
Fortran
The loops associated with a loop-associated directive have canonical loop form if each of them is a 1
do-loopthatisado-construct oraninner-shared-do-construct asdeﬁnedbytheFortranstandard. If 2
anend dodirectivefollowsa do-construct inwhichseveralloopstatementssharea DOtermination 3
statement, then the directive can only be speciﬁed for the outermost of these DOstatements. 4
CHAPTER 2. DIRECTIVES 97
Thedo-stmtfor anydo-loopmust conform to the following: 1
DO[ label ] var =lb,b [,incr ]
var A variable of integer type.
lbandb Expressions of a type compatible with the type of varthat are loop invariant
with respect to the outermost associated loop or are one of the following (where
var-outer,a1, anda2have a type compatible with the type of var,var-outer
isvarfrom an outer associated loop, and a1anda2are loop invariant integer
expressions with respect to the outermost loop):
var-outer
var-outer +a2
a2+var-outer
var-outer -a2
a2-var-outer
a1*var-outer
a1*var-outer +a2
a2+a1*var-outer
a1*var-outer -a2
a2-a1*var-outer
var-outer *a1
var-outer *a1+a2
a2+var-outer *a1
var-outer *a1-a2
a2-var-outer *a1
incr An integer expression that is loop invariant with respect to the outermost
associated loop. If it is not explicitly speciﬁed, its value is assumed to be 1.
Fortran
The canonical form allows the iteration count of all associated loops to be computed before 2
executing the outermost loop. The incrandrange-expr are evaluated before executing the 3
loop-associated construct. If borlbis loop invariant with respect to the outermost associated loop, 4
it is evaluated before executing the loop-associated construct. If borlbis not loop invariant with 5
respect to the outermost associated loop, a1and/ora2are evaluated before executing the 6
loop-associatedconstruct. Thecomputationisperformedforeachloopinanintegertype. Thistype 7
is derived from the type of varas follows: 8
Ifvaris of an integer type, then the type is the type of var. 9
98OpenMP API – Version 5.0 November 2018
C++
Ifvaris of a random access iterator type, then the type is the type that would be used by 1
std::distance applied to variables of the type of var. 2
C++
C
Ifvaris of a pointer type, then the type is ptrdiff_t . 3
C
The behavior is unspeciﬁed if any intermediate result required to compute the iteration count 4
cannot be represented in the type determined above. 5
There is no implied synchronization during the evaluation of the lb,b, orincrexpressions. It is 6
unspeciﬁed whether, in what order, or how many times any side eﬀects within the lb,b, orincr 7
expressions occur. 8
9
Note– Random access iterators are required to support random access to elements in constant 10
time. Otheriteratorsareprecludedbytherestrictionssincetheycantakelineartimeoroﬀerlimited 11
functionality. The use of tasks to parallelize those cases is therefore advisable. 12
13
C++
A range-based for loop that is valid in the base language and has a begin value that satisﬁes the 14
random access iterator requirement has canonical loop form . Range-based for loops are of the 15
following form: 16
for (range-decl :range-expr )structured-block 17
Thebegin-expr andend-expr expressions are derived from range-expr by the base language and 18
assigned to variables to which this speciﬁcation refers as __begin and__endrespectively. Both 19
__begin and__endare privatized. For the purpose of the rest of the standard __begin is the 20
iteration variable of the range-for loop. 21
C++
CHAPTER 2. DIRECTIVES 99
Restrictions 1
The following restrictions also apply: 2
C / C++
Iftest-expr is of the form var relational-op b andrelational-op is < or <= then incr-expr must 3
causevarto increase on each iteration of the loop. If test-expr is of the form var relational-op b 4
andrelational-op is > or >= then incr-expr must cause varto decrease on each iteration of the 5
loop. 6
Iftest-expr is of the form b relational-op var andrelational-op is < or <= then incr-expr must 7
causevarto decrease on each iteration of the loop. If test-expr is of the form b relational-op var 8
andrelational-op is > or >= then incr-expr must cause varto increase on each iteration of the 9
loop. 10
Iftest-expr is of the form b!=varorvar!=bthenincr-expr must cause vareither to increase on 11
each iteration of the loop or to decrease on each iteration of the loop. 12
Ifrelational-op is != and incr-expr is of the form that has incrthenincrmust be a constant 13
expression and evaluate to -1 or 1. 14
C / C++
C++
In the simdconstruct the only random access iterator types that are allowed for varare pointer 15
types. 16
Therange-expr of a range-for loop must be loop invariant with respect to the outermost 17
associated loop, and must not reference iteration variables of any associated loops. 18
The loops associated with an ordered clause with a parameter may not include range-for loops. 19
C++
Theb,lb,incr, andrange-expr expressions may not reference any varor member of the 20
range-decl of any enclosed associated loop. 21
For any associated loop where the borlbexpression is not loop invariant with respect to the 22
outermost loop, the var-outer that appears in the expression may not have a random access 23
iterator type. 24
Foranyassociatedloopwhere borlbisnotloopinvariantwithrespecttotheoutermostloop,the 25
expression b lbwill have the form cvar-outer +d, wherecanddare loop invariant integer 26
expressions. Let incr-outer be theincrexpression of the outer loop referred to by var-outer. The 27
value ofcincr-outer modincrmust be 0. 28
100 OpenMP API – Version 5.0 November 2018
Cross References 1
simdconstruct, see Section 2.9.3.1 on page 110. 2
lastprivate clause, see Section 2.19.4.5 on page 288. 3
linear clause, see Section 2.19.4.6 on page 290. 4
2.9.2 Worksharing-Loop Construct5
Summary 6
The worksharing-loop construct speciﬁes that the iterations of one or more associated loops will be 7
executed in parallel by threads in the team in the context of their implicit tasks. The iterations are 8
distributed across threads that already exist in the team that is executing the parallel region to 9
which the worksharing-loop region binds. 10
Syntax 11
C / C++
The syntax of the worksharing-loop construct is as follows: 12
#pragma omp for [clause[ [ ,] clause] ... ] new-line 13
for-loops 14
where clause is one of the following: 15
private( list) 16
firstprivate( list) 17
lastprivate( [ lastprivate-modiﬁer :] list) 18
linear( list[:linear-step] ) 19
reduction( [ reduction-modiﬁer ,]reduction-identiﬁer :list) 20
schedule( [modiﬁer [ ,modiﬁer] :]kind[ ,chunk_size] ) 21
collapse( n) 22
ordered [(n)] 23
nowait 24
allocate( [allocator :]list ) 25
order(concurrent) 26
Thefordirective places restrictions on the structure of all associated for-loops. Speciﬁcally, all 27
associated for-loops must have canonical loop form (see Section 2.9.1 on page 95). 28
C / C++
CHAPTER 2. DIRECTIVES 101
Fortran
The syntax of the worksharing-loop construct is as follows: 1
!$omp do [clause[ [ ,] clause] ... ] 2
do-loops 3
[!$omp end do [nowait]] 4
whereclauseis one of the following: 5
private( list) 6
firstprivate( list) 7
lastprivate( [ lastprivate-modiﬁer :] list) 8
linear( list[:linear-step] ) 9
reduction( [ reduction-modiﬁer ,]reduction-identiﬁer :list) 10
schedule( [modiﬁer [ ,modiﬁer] :]kind[ ,chunk_size] ) 11
collapse( n) 12
ordered [(n)] 13
allocate( [allocator :]list ) 14
order(concurrent) 15
If anend dodirective is not speciﬁed, an end dodirective is assumed at the end of the do-loops. 16
Thedodirective places restrictions on the structure of all associated do-loops. Speciﬁcally, all 17
associated do-loops must have canonical loop form (see Section 2.9.1 on page 95). 18
Fortran
Binding 19
The binding thread set for a worksharing-loop region is the current team. A worksharing-loop 20
region binds to the innermost enclosing parallel region. Only the threads of the team executing 21
the binding parallel region participate in the execution of the loop iterations and the implied 22
barrier of the worksharing-loop region if the barrier is not eliminated by a nowait clause. 23
Description 24
The worksharing-loop construct is associated with a loop nest that consists of one or more loops 25
that follow the directive. 26
There is an implicit barrier at the end of a worksharing-loop construct unless a nowait clause is 27
speciﬁed. 28
Thecollapse clause may be used to specify how many loops are associated with the 29
worksharing-loop construct. The parameter of the collapse clause must be a constant positive 30
102 OpenMP API – Version 5.0 November 2018
integer expression. If a collapse clause is speciﬁed with a parameter value greater than 1, then 1
the iterations of the associated loops to which the clause applies are collapsed into one larger 2
iterationspacethatisthendividedaccordingtothe schedule clause. Thesequentialexecutionof 3
the iterations in these associated loops determines the order of the iterations in the collapsed 4
iteration space. If no collapse clause is present or its parameter is 1, the only loop that is 5
associated with the worksharing-loop construct for the purposes of determining how the iteration 6
space is divided according to the schedule clause is the one that immediately follows the 7
worksharing-loop directive. 8
If more than one loop is associated with the worksharing-loop construct then the number of times 9
that any intervening code between any two associated loops will be executed is unspeciﬁed but will 10
be at least once per iteration of the loop enclosing the intervening code and at most once per 11
iteration of the innermost loop associated with the construct. If the iteration count of any loop that 12
is associated with the worksharing-loop construct is zero and that loop does not enclose the 13
intervening code, the behavior is unspeciﬁed. 14
The integer type (or kind, for Fortran) used to compute the iteration count for the collapsed loop is 15
implementation deﬁned. 16
A worksharing-loop has logical iterations numbered 0,1,...,N-1 where N is the number of loop 17
iterations, and the logical numbering denotes the sequence in which the iterations would be 18
executed if a set of associated loop(s) were executed sequentially. At the beginning of each logical 19
iteration, the loop iteration variable of each associated loop has the value that it would have if the 20
set of the associated loop(s) were executed sequentially. The schedule clause speciﬁes how 21
iterations of these associated loops are divided into contiguous non-empty subsets, called chunks, 22
and how these chunks are distributed among threads of the team. Each thread executes its assigned 23
chunk(s) in the context of its implicit task. The iterations of a given chunk are executed in 24
sequential order by the assigned thread. The chunk_size expression is evaluated using the original 25
list items of any variables that are made private in the worksharing-loop construct. It is unspeciﬁed 26
whether, in what order, or how many times, any side eﬀects of the evaluation of this expression 27
occur. The use of a variable in a schedule clause expression of a worksharing-loop construct 28
causes an implicit reference to the variable in all enclosing constructs. 29
Diﬀerent worksharing-loop regions with the same schedule and iteration count, even if they occur 30
in the same parallel region, can distribute iterations among threads diﬀerently. The only exception 31
is for the static schedule as speciﬁed in Table 2.5. Programs that depend on which thread 32
executes a particular iteration under any other circumstances are non-conforming. 33
See Section 2.9.2.1 on page 109 for details of how the schedule for a worksharing-loop region is 34
determined. 35
The schedule kindcan be one of those speciﬁed in Table 2.5. 36
The schedule modiﬁercan be one of those speciﬁed in Table 2.6. If the static schedule kind is 37
speciﬁed or if the ordered clause is speciﬁed, and if the nonmonotonic modiﬁer is not 38
speciﬁed, the eﬀect is as if the monotonic modiﬁer is speciﬁed. Otherwise, unless the 39
monotonic modiﬁer is speciﬁed, the eﬀect is as if the nonmonotonic modiﬁer is speciﬁed. If 40
CHAPTER 2. DIRECTIVES 103
aschedule clause speciﬁes a modiﬁer then that modiﬁer overrides any modiﬁer that is speciﬁed 1
in therun-sched-var ICV. 2
Theordered clause with the parameter may also be used to specify how many loops are 3
associated with the worksharing-loop construct. The parameter of the ordered clause must be a 4
constant positive integer expression if speciﬁed. The parameter of the ordered clause does not 5
aﬀect how the logical iteration space is then divided. If an ordered clause with the parameter is 6
speciﬁedfortheworksharing-loopconstruct,thenthoseassociatedloopsforma doacrossloopnest . 7
If the value of the parameter in the collapse orordered clause is larger than the number of 8
nested loops following the construct, the behavior is unspeciﬁed. 9
Ifanorder(concurrent) clauseispresent,thenafterassigningtheiterationsoftheassociated 10
loops to their respective threads, as speciﬁed in Table 2.5, the iterations may be executed in any 11
order, including concurrently. 12
TABLE 2.5:schedule ClausekindValues
static Whenkindisstatic, iterations are divided into chunks of size chunk_size ,
and the chunks are assigned to the threads in the team in a round-robin
fashion in the order of the thread number. Each chunk contains chunk_size
iterations, except for the chunk that contains the sequentially last iteration,
which may have fewer iterations.
When no chunk_size is speciﬁed, the iteration space is divided into chunks
that are approximately equal in size, and at most one chunk is distributed to
each thread. The size of the chunks is unspeciﬁed in this case.
A compliant implementation of the static schedule must ensure that the
same assignment of logical iteration numbers to threads will be used in
two worksharing-loop regions if the following conditions are satisﬁed: 1)
both worksharing-loop regions have the same number of loop iterations, 2)
both worksharing-loop regions have the same value of chunk_size speciﬁed,
or both worksharing-loop regions have no chunk_size speciﬁed, 3) both
worksharing-loop regions bind to the same parallel region, and 4) neither
loop is associated with a SIMD construct. A data dependence between
the same logical iterations in two such loops is guaranteed to be satisﬁed
allowing safe use of the nowait clause.
table continued on next page
104 OpenMP API – Version 5.0 November 2018
table continued from previous page
dynamic Whenkindisdynamic , the iterations are distributed to threads in the team
in chunks. Each thread executes a chunk of iterations, then requests another
chunk, until no chunks remain to be distributed.
Each chunk contains chunk_size iterations, except for the chunk that contains
the sequentially last iteration, which may have fewer iterations.
When no chunk_size is speciﬁed, it defaults to 1.
guided Whenkindisguided, the iterations are assigned to threads in the team in
chunks. Each thread executes a chunk of iterations, then requests another
chunk, until no chunks remain to be assigned.
For achunk_size of 1, the size of each chunk is proportional to the number
of unassigned iterations divided by the number of threads in the team,
decreasing to 1. For a chunk_size with value k(greater than 1), the size
of each chunk is determined in the same way, with the restriction that
the chunks do not contain fewer than kiterations (except for the chunk
that contains the sequentially last iteration, which may have fewer than k
iterations).
When no chunk_size is speciﬁed, it defaults to 1.
auto Whenkindisauto, the decision regarding scheduling is delegated to the
compiler and/or runtime system. The programmer gives the implementation
the freedom to choose any possible mapping of iterations to threads in the
team.
runtime Whenkindisruntime , the decision regarding scheduling is deferred until
run time, and the schedule and chunk size are taken from the run-sched-var
ICV. If the ICV is set to auto, the schedule is implementation deﬁned.
1
Note– For a team of pthreads and a loop of niterations, let d dn=pe ebe the integer qthat satisﬁes 2
n=pq r,with 0<=r < p. Onecompliantimplementationofthe static schedule(withno 3
speciﬁed chunk_size ) would behave as though chunk_size had been speciﬁed with value q. Another 4
compliantimplementationwouldassign qiterationstotheﬁrst p rthreads,and q 1iterationsto 5
theremaining rthreads. Thisillustrateswhyaconformingprogrammustnotrelyonthedetailsofa 6
particular implementation. 7
A compliant implementation of the guided schedule with a chunk_size value of kwould assign 8
q=d dn=pe eiterations to the ﬁrst available thread and set nto the larger of n qandpk. It would 9
then repeat this process until qis greater than or equal to the number of remaining iterations, at 10
which time the remaining iterations form the ﬁnal chunk. Another compliant implementation could 11
use the same method, except with q=d dn=(2p)e e, and set nto the larger of n qand2pk. 12
13
CHAPTER 2. DIRECTIVES 105
TABLE 2.6:schedule ClausemodiﬁerValues
monotonic When the monotonic modiﬁer is speciﬁed then each thread executes
the chunks that it is assigned in increasing logical iteration order.
nonmonotonic When the nonmonotonic modiﬁer is speciﬁed then chunks are
assigned to threads in any order and the behavior of an application that
depends on any execution order of the chunks is unspeciﬁed.
simd When the simdmodiﬁer is speciﬁed and the loop is associated with
a SIMD construct, the chunk_size for all chunks except the ﬁrst and
last chunks is new_chunk_size =d dchunk_size=simd _width e e
simd_widthwheresimd_width is an implementation-deﬁned value.
The ﬁrst chunk will have at least new_chunk_size iterations except if
it is also the last chunk. The last chunk may have fewer iterations than
new_chunk_size . If the simdmodiﬁer is speciﬁed and the loop is not
associated with a SIMD construct, the modiﬁer is ignored.1
Execution Model Events 2
Thews-loop-begin event occurs after an implicit task encounters a worksharing-loop construct but 3
before the task starts execution of the structured block of the worksharing-loop region. 4
Thews-loop-end event occurs after a worksharing-loop region ﬁnishes execution but before 5
resuming execution of the encountering task. 6
Thews-loop-iteration-begin event occurs once for each iteration of a worksharing-loop before the 7
iteration is executed by an implicit task. 8
Tool Callbacks 9
A thread dispatches a registered ompt_callback_work callback with ompt_scope_begin 10
as itsendpoint argument and work_loop as itswstypeargument for each occurrence of a 11
ws-loop-begin event in that thread. Similarly, a thread dispatches a registered 12
ompt_callback_work callback with ompt_scope_end as itsendpoint argument and 13
work_loop as itswstypeargument for each occurrence of a ws-loop-end event in that thread. The 14
callbacks occur in the context of the implicit task. The callbacks have type signature 15
ompt_callback_work_t . 16
A thread dispatches a registered ompt_callback_dispatch callback for each occurrence of a 17
ws-loop-iteration-begin event in that thread. The callback occurs in the context of the implicit task. 18
The callback has type signature ompt_callback_dispatch_t . 19
106 OpenMP API – Version 5.0 November 2018
Restrictions 1
Restrictions to the worksharing-loop construct are as follows: 2
No OpenMP directive may appear in the region between any associated loops. 3
If acollapse clause is speciﬁed, exactly one loop must occur in the region at each nesting 4
level up to the number of loops speciﬁed by the parameter of the collapse clause. 5
If the ordered clause is present, all loops associated with the construct must be perfectly 6
nested; that is there must be no intervening code between any two loops. 7
If areduction clause with the inscan modiﬁer is speciﬁed, neither the ordered nor 8
schedule clause may appear on the worksharing-loop directive. 9
The values of the loop control expressions of the loops associated with the worksharing-loop 10
construct must be the same for all threads in the team. 11
Only one schedule clause can appear on a worksharing-loop directive. 12
Theschedule clause must not appear on the worksharing-loop directive if the associated 13
loop(s) form a non-rectangular loop nest. 14
Theordered clause must not appear on the worksharing-loop directive if the associated 15
loop(s) form a non-rectangular loop nest. 16
Only one collapse clause can appear on a worksharing-loop directive. 17
chunk_size must be a loop invariant integer expression with a positive value. 18
The value of the chunk_size expression must be the same for all threads in the team. 19
The value of the run-sched-var ICV must be the same for all threads in the team. 20
When schedule(runtime) orschedule(auto) is speciﬁed, chunk_size must not be 21
speciﬁed. 22
Amodiﬁermay not be speciﬁed on a linear clause. 23
Only one ordered clause can appear on a worksharing-loop directive. 24
Theordered clause must be present on the worksharing-loop construct if any ordered 25
region ever binds to a worksharing-loop region arising from the worksharing-loop construct. 26
Thenonmonotonic modiﬁer cannot be speciﬁed if an ordered clause is speciﬁed. 27
Eitherthe monotonic modiﬁerorthe nonmonotonic modiﬁercanbespeciﬁedbutnotboth. 28
The loop iteration variable may not appear in a threadprivate directive. 29
Ifboththe collapse andordered clausewithaparameterarespeciﬁed,theparameterofthe 30
ordered clause must be greater than or equal to the parameter of the collapse clause. 31
CHAPTER 2. DIRECTIVES 107
Alinear clause or an ordered clause with a parameter can be speciﬁed on a 1
worksharing-loop directive but not both. 2
Ifanorder(concurrent) clauseispresent,allrestrictionsfromthe loopconstructwithan 3
order(concurrent) clause also apply. 4
If anorder(concurrent) clause is present, an ordered clause may not appear on the 5
same directive. 6
C / C++
The associated for-loops must be structured blocks. 7
Only an iteration of the innermost associated loop may be curtailed by a continue statement. 8
No statement can branch to any associated forstatement. 9
Only one nowait clause can appear on a fordirective. 10
A throw executed inside a worksharing-loop region must cause execution to resume within the 11
sameiterationoftheworksharing-loopregion,andthesamethreadthatthrewtheexceptionmust 12
catch it. 13
C / C++
Fortran
The associated do-loops must be structured blocks. 14
Only an iteration of the innermost associated loop may be curtailed by a CYCLEstatement. 15
No statement in the associated loops other than the DOstatements can cause a branch out of the 16
loops. 17
Thedo-loopiteration variable must be of type integer. 18
Thedo-loopcannot be a DO WHILE or aDOloop without loop control. 19
Fortran
Cross References 20
order(concurrent) clause, see Section 2.9.5 on page 128. 21
ordered construct, see Section 2.17.9 on page 250. 22
depend clause, see Section 2.17.11 on page 255. 23
private ,firstprivate ,lastprivate ,linear, andreduction clauses, see 24
Section 2.19.4 on page 282. 25
ompt_scope_begin andompt_scope_end , see Section 4.4.4.11 on page 443. 26
ompt_work_loop , see Section 4.4.4.15 on page 445. 27
ompt_callback_work_t , see Section 4.5.2.5 on page 464. 28
OMP_SCHEDULE environment variable, see Section 6.1 on page 601. 29
108 OpenMP API – Version 5.0 November 2018
START
schedule
clause present?
schedule
kind value is
runtime ?Usedef-sched-var schedule kind
Use schedule kind speciﬁed in
schedule clause
Userun-sched-var schedule kindNo
Yes
No
Yes
FIGURE 2.1:Determining the schedule for a Worksharing-Loop
2.9.2.1 Determining the Schedule of a Worksharing-Loop1
When execution encounters a worksharing-loop directive, the schedule clause (if any) on the 2
directive, and the run-sched-var anddef-sched-var ICVs are used to determine how loop iterations 3
are assigned to threads. See Section 2.5 on page 63 for details of how the values of the ICVs are 4
determined. If the worksharing-loop directive does not have a schedule clause then the current 5
value of the def-sched-var ICV determines the schedule. If the worksharing-loop directive has a 6
schedule clause that speciﬁes the runtime schedule kind then the current value of the 7
run-sched-var ICV determines the schedule. Otherwise, the value of the schedule clause 8
determines the schedule. Figure 2.1 describes how the schedule for a worksharing-loop is 9
determined. 10
Cross References 11
ICVs, see Section 2.5 on page 63. 12
CHAPTER 2. DIRECTIVES 109
2.9.3 SIMD Directives1
2.9.3.1 simd Construct 2
Summary 3
Thesimdconstruct can be applied to a loop to indicate that the loop can be transformed into a 4
SIMD loop (that is, multiple iterations of the loop can be executed concurrently using SIMD 5
instructions). 6
Syntax 7
The syntax of the simdconstruct is as follows: 8
C / C++
#pragma omp simd [clause[ [ ,] clause] ... ] new-line 9
for-loops 10
whereclauseis one of the following: 11
if([simd :] scalar-expression ) 12
safelen( length ) 13
simdlen( length ) 14
linear( list[:linear-step] ) 15
aligned( list[:alignment] ) 16
nontemporal( list) 17
private( list) 18
lastprivate( [ lastprivate-modiﬁer :] list) 19
reduction( [ reduction-modiﬁer ,]reduction-identiﬁer :list) 20
collapse( n) 21
order(concurrent) 22
Thesimddirective places restrictions on the structure of the associated for-loops. Speciﬁcally, all 23
associated for-loops must have canonical loop form (Section 2.9.1 on page 95). 24
C / C++
110 OpenMP API – Version 5.0 November 2018
Fortran
!$omp simd [clause[ [ ,] clause ... ] 1
do-loops 2
[!$omp end simd ] 3
whereclauseis one of the following: 4
if([simd :] scalar-logical-expression ) 5
safelen( length ) 6
simdlen( length ) 7
linear( list[:linear-step] ) 8
aligned( list[:alignment] ) 9
nontemporal( list) 10
private( list) 11
lastprivate( [ lastprivate-modiﬁer :] list) 12
reduction( [ reduction-modiﬁer ,]reduction-identiﬁer :list) 13
collapse( n) 14
order(concurrent) 15
If anend simd directive is not speciﬁed, an end simd directive is assumed at the end of the 16
do-loops. 17
Thesimddirective places restrictions on the structure of all associated do-loops. Speciﬁcally, all 18
associated do-loops must have canonical loop form (see Section 2.9.1 on page 95). 19
Fortran
Binding 20
Asimdregion binds to the current task region. The binding thread set of the simdregion is the 21
current team. 22
Description 23
Thesimdconstruct enables the execution of multiple iterations of the associated loops 24
concurrently by means of SIMD instructions. 25
Thecollapse clause may be used to specify how many loops are associated with the construct. 26
The parameter of the collapse clause must be a constant positive integer expression. If no 27
collapse clause is present, the only loop that is associated with the simdconstruct is the one 28
that immediately follows the directive. 29
CHAPTER 2. DIRECTIVES 111
If more than one loop is associated with the simdconstruct, then the iterations of all associated 1
loops are collapsed into one larger iteration space that is then executed with SIMD instructions. 2
The sequential execution of the iterations in all associated loops determines the order of the 3
iterations in the collapsed iteration space. 4
If more than one loop is associated with the simdconstruct then the number of times that any 5
intervening code between any two associated loops will be executed is unspeciﬁed but will be at 6
least once per iteration of the loop enclosing the intervening code and at most once per iteration of 7
theinnermostloopassociatedwiththeconstruct. Iftheiterationcountofanyloopthatisassociated 8
withthe simdconstructiszeroandthatloopdoesnotenclosetheinterveningcode,thebehavioris 9
unspeciﬁed. 10
The integer type (or kind, for Fortran) used to compute the iteration count for the collapsed loop is 11
implementation deﬁned. 12
A SIMD loop has logical iterations numbered 0,1,...,N-1 where N is the number of loop iterations, 13
and the logical numbering denotes the sequence in which the iterations would be executed if the 14
associated loop(s) were executed with no SIMD instructions. At the beginning of each logical 15
iteration, the loop iteration variable of each associated loop has the value that it would have if the 16
set of the associated loop(s) were executed sequentially. The number of iterations that are executed 17
concurrently at any given time is implementation deﬁned. Each concurrent iteration will be 18
executed by a diﬀerent SIMD lane. Each set of concurrent iterations is a SIMD chunk. Lexical 19
forward dependencies in the iterations of the original loop must be preserved within each SIMD 20
chunk. 21
Thesafelen clause speciﬁes that no two concurrent iterations within a SIMD chunk can have a 22
distance in the logical iteration space that is greater than or equal to the value given in the clause. 23
The parameter of the safelen clause must be a constant positive integer expression. The 24
simdlen clause speciﬁes the preferred number of iterations to be executed concurrently unless an 25
ifclause is present and evaluates to false, in which case the preferred number of iterations to be 26
executed concurrently is one. The parameter of the simdlen clause must be a constant positive 27
integer expression. 28
C / C++
Thealigned clause declares that the object to which each list item points is aligned to the 29
number of bytes expressed in the optional parameter of the aligned clause. 30
C / C++
Fortran
Thealigned clause declares that the location of each list item is aligned to the number of bytes 31
expressed in the optional parameter of the aligned clause. 32
Fortran
112 OpenMP API – Version 5.0 November 2018
The optional parameter of the aligned clause,alignment , must be a constant positive integer 1
expression. If no optional parameter is speciﬁed, implementation-deﬁned default alignments for 2
SIMD instructions on the target platforms are assumed. 3
Thenontemporal clause speciﬁes that accesses to the storage locations to which the list items 4
refer have low temporal locality across the iterations in which those storage locations are accessed. 5
Restrictions 6
No OpenMP directive may appear in the region between any associated loops. 7
If acollapse clause is speciﬁed, exactly one loop must occur in the region at each nesting 8
level up to the number of loops speciﬁed by the parameter of the collapse clause. 9
The associated loops must be structured blocks. 10
A program that branches into or out of a simdregion is non-conforming. 11
Only one collapse clause can appear on a simddirective. 12
Alist-itemcannot appear in more than one aligned clause. 13
Alist-itemcannot appear in more than one nontemporal clause. 14
Only one safelen clause can appear on a simddirective. 15
Only one simdlen clause can appear on a simddirective. 16
If both simdlen andsafelen clauses are speciﬁed, the value of the simdlen parameter 17
must be less than or equal to the value of the safelen parameter. 18
Amodiﬁermay not be speciﬁed on a linear clause. 19
The only OpenMP constructs that can be encountered during execution of a simdregion are the 20
atomic construct, the loopconstruct, the simdconstruct and the ordered construct with 21
thesimdclause. 22
Ifanorder(concurrent) clauseispresent,allrestrictionsfromthe loopconstructwithan 23
order(concurrent) clause also apply. 24
C / C++
Thesimdregion cannot contain calls to the longjmp orsetjmp functions. 25
C / C++
C
The type of list items appearing in the aligned clause must be array or pointer. 26
C
CHAPTER 2. DIRECTIVES 113
C++
The type of list items appearing in the aligned clause must be array, pointer, reference to 1
array, or reference to pointer. 2
No exception can be raised in the simdregion. 3
C++
Fortran
Thedo-loopiteration variable must be of type integer . 4
Thedo-loopcannot be a DO WHILE or aDOloop without loop control. 5
Ifalistitemonthe aligned clausehasthe ALLOCATABLE attribute,theallocationstatusmust 6
be allocated. 7
If a list item on the aligned clause has the POINTER attribute, the association status must be 8
associated. 9
If the type of a list item on the aligned clause is either C_PTRor Cray pointer, the list item 10
must be deﬁned. 11
Fortran
Cross References 12
order(concurrent) clause, see Section 2.9.5 on page 128. 13
ifClause, see Section 2.15 on page 220. 14
private ,lastprivate ,linear andreduction clauses,seeSection2.19.4onpage282. 15
2.9.3.2 Worksharing-Loop SIMD Construct 16
Summary 17
The worksharing-loop SIMD construct speciﬁes that the iterations of one or more associated loops 18
will be distributed across threads that already exist in the team and that the iterations executed by 19
each thread can also be executed concurrently using SIMD instructions. The worksharing-loop 20
SIMD construct is a composite construct. 21
114 OpenMP API – Version 5.0 November 2018
Syntax 1
C / C++
#pragma omp for simd [clause[ [ ,] clause] ... ] new-line 2
for-loops 3
whereclausecan be any of the clauses accepted by the fororsimddirectives with identical 4
meanings and restrictions. 5
C / C++
Fortran
!$omp do simd [clause[ [ ,] clause] ... ] 6
do-loops 7
[!$omp end do simd [nowait] ] 8
whereclausecan be any of the clauses accepted by the simdordodirectives, with identical 9
meanings and restrictions. 10
If anend do simd directive is not speciﬁed, an end do simd directive is assumed at the end of 11
thedo-loops. 12
Fortran
Description 13
The worksharing-loop SIMD construct will ﬁrst distribute the iterations of the associated loop(s) 14
across the implicit tasks of the parallel region in a manner consistent with any clauses that apply to 15
the worksharing-loop construct. The resulting chunks of iterations will then be converted to a 16
SIMD loop in a manner consistent with any clauses that apply to the simdconstruct. 17
Execution Model Events 18
This composite construct generates the same events as the worksharing-loop construct. 19
Tool Callbacks 20
This composite construct dispatches the same callbacks as the worksharing-loop construct. 21
CHAPTER 2. DIRECTIVES 115
Restrictions 1
All restrictions to the worksharing-loop construct and the simdconstruct apply to the 2
worksharing-loop SIMD construct. In addition, the following restrictions apply: 3
Noordered clause with a parameter can be speciﬁed. 4
A list item may appear in a linear orfirstprivate clause but not both. 5
Cross References 6
worksharing-loop construct, see Section 2.9.2 on page 101. 7
simdconstruct, see Section 2.9.3.1 on page 110. 8
Data attribute clauses, see Section 2.19.4 on page 282. 9
2.9.3.3 declare simd Directive 10
Summary 11
Thedeclare simd directive can be applied to a function (C, C++ and Fortran) or a subroutine 12
(Fortran) to enable the creation of one or more versions that can process multiple arguments using 13
SIMD instructions from a single invocation in a SIMD loop. The declare simd directive is a 14
declarative directive. There may be multiple declare simd directives for a function (C, C++, 15
Fortran) or subroutine (Fortran). 16
Syntax 17
The syntax of the declare simd directive is as follows: 18
C / C++
#pragma omp declare simd [clause[ [ ,] clause] ... ] new-line 19
[#pragma omp declare simd [clause[ [ ,] clause] ... ] new-line] 20
[ ... ] 21
function deﬁnition or declaration 22
whereclauseis one of the following: 23
simdlen( length ) 24
linear( linear-list[ :linear-step] ) 25
aligned( argument-list[ :alignment] ) 26
uniform( argument-list ) 27
inbranch 28
notinbranch 29
C / C++
116 OpenMP API – Version 5.0 November 2018
Fortran
!$omp declare simd [(proc-name )] [clause[ [ ,] clause] ... ] 1
whereclauseis one of the following: 2
simdlen( length ) 3
linear( linear-list[ :linear-step] ) 4
aligned( argument-list[ :alignment] ) 5
uniform( argument-list ) 6
inbranch 7
notinbranch 8
Fortran
Description 9
C / C++
The use of one or more declare simd directives immediately prior to a function declaration or 10
deﬁnition enables the creation of corresponding SIMD versions of the associated function that can 11
be used to process multiple arguments from a single invocation in a SIMD loop concurrently. 12
The expressions appearing in the clauses of each directive are evaluated in the scope of the 13
arguments of the function declaration or deﬁnition. 14
C / C++
Fortran
The use of one or more declare simd directives for a speciﬁed subroutine or function enables 15
the creation of corresponding SIMD versions of the subroutine or function that can be used to 16
process multiple arguments from a single invocation in a SIMD loop concurrently. 17
Fortran
If a SIMD version is created, the number of concurrent arguments for the function is determined by 18
thesimdlen clause. If the simdlen clause is used its value corresponds to the number of 19
concurrent arguments of the function. The parameter of the simdlen clause must be a constant 20
positive integer expression. Otherwise, the number of concurrent arguments for the function is 21
implementation deﬁned. 22
C++
The special thispointer can be used as if it was one of the arguments to the function in any of the 23
linear,aligned , oruniform clauses. 24
C++
Theuniform clause declares one or more arguments to have an invariant value for all concurrent 25
invocations of the function in the execution of a single SIMD loop. 26
CHAPTER 2. DIRECTIVES 117
C / C++
Thealigned clause declares that the object to which each list item points is aligned to the 1
number of bytes expressed in the optional parameter of the aligned clause. 2
C / C++
Fortran
Thealigned clause declares that the target of each list item is aligned to the number of bytes 3
expressed in the optional parameter of the aligned clause. 4
Fortran
The optional parameter of the aligned clause,alignment , must be a constant positive integer 5
expression. If no optional parameter is speciﬁed, implementation-deﬁned default alignments for 6
SIMD instructions on the target platforms are assumed. 7
Theinbranch clause speciﬁes that the SIMD version of the function will always be called from 8
insideaconditionalstatementofaSIMDloop. The notinbranch clausespeciﬁesthattheSIMD 9
version of the function will never be called from inside a conditional statement of a SIMD loop. If 10
neither clause is speciﬁed, then the SIMD version of the function may or may not be called from 11
inside a conditional statement of a SIMD loop. 12
Restrictions 13
Each argument can appear in at most one uniform orlinear clause. 14
At most one simdlen clause can appear in a declare simd directive. 15
Either inbranch ornotinbranch may be speciﬁed, but not both. 16
Whenalinear-step expressionisspeciﬁedina linear clauseitmustbeeitheraconstantinteger 17
expression or an integer-typed parameter that is speciﬁed in a uniform clause on the directive. 18
The function or subroutine body must be a structured block. 19
The execution of the function or subroutine, when called from a SIMD loop, cannot result in the 20
executionofanOpenMPconstructexceptforan ordered constructwiththe simdclauseoran 21
atomic construct. 22
The execution of the function or subroutine cannot have any side eﬀects that would alter its 23
execution for concurrent iterations of a SIMD chunk. 24
A program that branches into or out of the function is non-conforming. 25
C / C++
If the function has any declarations, then the declare simd construct for any declaration that 26
has one must be equivalent to the one speciﬁed for the deﬁnition. Otherwise, the result is 27
unspeciﬁed. 28
The function cannot contain calls to the longjmp orsetjmp functions. 29
C / C++
118 OpenMP API – Version 5.0 November 2018
C
The type of list items appearing in the aligned clause must be array or pointer. 1
C
C++
The function cannot contain any calls to throw. 2
The type of list items appearing in the aligned clause must be array, pointer, reference to 3
array, or reference to pointer. 4
C++
Fortran
proc-name must not be a generic name, procedure pointer or entry name. 5
Ifproc-name is omitted, the declare simd directive must appear in the speciﬁcation part of a 6
subroutine subprogram or a function subprogram for which creation of the SIMD versions is 7
enabled. 8
Anydeclare simd directivemustappearinthespeciﬁcationpartofasubroutinesubprogram, 9
function subprogram or interface body to which it applies. 10
If adeclare simd directive is speciﬁed in an interface block for a procedure, it must match a 11
declare simd directive in the deﬁnition of the procedure. 12
Ifaprocedureisdeclaredviaaproceduredeclarationstatement,theprocedure proc-name should 13
appear in the same speciﬁcation. 14
If adeclare simd directive is speciﬁed for a procedure name with explicit interface and a 15
declare simd directive is also speciﬁed for the deﬁnition of the procedure then the two 16
declare simd directives must match. Otherwise the result is unspeciﬁed. 17
Procedure pointers may not be used to access versions created by the declare simd directive. 18
The type of list items appearing in the aligned clause must be C_PTRor Cray pointer, or the 19
list item must have the POINTER orALLOCATABLE attribute. 20
Fortran
Cross References 21
linear clause, see Section 2.19.4.6 on page 290. 22
reduction clause, see Section 2.19.5.4 on page 300. 23
CHAPTER 2. DIRECTIVES 119
2.9.4 distribute Loop Constructs 1
2.9.4.1 distribute Construct 2
Summary 3
Thedistribute construct speciﬁes that the iterations of one or more loops will be executed by 4
the initial teams in the context of their implicit tasks. The iterations are distributed across the initial 5
threadsofallinitialteamsthatexecutethe teamsregiontowhichthe distribute regionbinds. 6
Syntax 7
C / C++
The syntax of the distribute construct is as follows: 8
#pragma omp distribute [clause[ [ ,] clause] ... ] new-line 9
for-loops 10
Whereclauseis one of the following: 11
private( list) 12
firstprivate( list) 13
lastprivate( list) 14
collapse( n) 15
dist_schedule( kind[,chunk_size] ) 16
allocate( [allocator :]list ) 17
Thedistribute directive places restrictions on the structure of all associated for-loops. 18
Speciﬁcally,allassociated for-loops musthave canonicalloopform (seeSection2.9.1onpage95). 19
C / C++
Fortran
The syntax of the distribute construct is as follows: 20
!$omp distribute [clause[ [ ,] clause] ... ] 21
do-loops 22
[!$omp end distribute ] 23
120 OpenMP API – Version 5.0 November 2018
Whereclauseis one of the following: 1
private( list) 2
firstprivate( list) 3
lastprivate( list) 4
collapse( n) 5
dist_schedule( kind[,chunk_size] ) 6
allocate( [allocator :]list ) 7
If anend distribute directive is not speciﬁed, an end distribute directive is assumed at 8
the end of the do-loops. 9
Thedistribute directive places restrictions on the structure of all associated do-loops. 10
Speciﬁcally, all associated do-loops must have canonical loop form (see Section 2.9.1 on page 95). 11
Fortran
Binding 12
The binding thread set for a distribute region is the set of initial threads executing an 13
enclosing teamsregion. A distribute region binds to this teamsregion. 14
Description 15
Thedistribute construct is associated with a loop nest consisting of one or more loops that 16
follow the directive. 17
There is no implicit barrier at the end of a distribute construct. To avoid data races the 18
original list items modiﬁed due to lastprivate orlinear clauses should not be accessed 19
between the end of the distribute construct and the end of the teamsregion to which the 20
distribute binds. 21
Thecollapse clause may be used to specify how many loops are associated with the 22
distribute construct. The parameter of the collapse clause must be a constant positive 23
integer expression. If no collapse clause is present or its parameter is 1, the only loop that is 24
associated with the distribute construct is the one that immediately follows the distribute 25
construct. If a collapse clause is speciﬁed with a parameter value greater than 1 and more than 26
one loop is associated with the distribute construct, then the iteration of all associated loops 27
are collapsed into one larger iteration space. The sequential execution of the iterations in all 28
associated loops determines the order of the iterations in the collapsed iteration space. 29
A distribute loop has logical iterations numbered 0,1,...,N-1 where N is the number of loop 30
iterations, and the logical numbering denotes the sequence in which the iterations would be 31
executed if the set of associated loop(s) were executed sequentially. At the beginning of each 32
CHAPTER 2. DIRECTIVES 121
logical iteration, the loop iteration variable of each associated loop has the value that it would have 1
if the set of the associated loop(s) were executed sequentially. 2
If more than one loop is associated with the distribute construct then the number of times that 3
any intervening code between any two associated loops will be executed is unspeciﬁed but will be 4
at least once per iteration of the loop enclosing the intervening code and at most once per iteration 5
of the innermost loop associated with the construct. If the iteration count of any loop that is 6
associated with the distribute construct is zero and that loop does not enclose the intervening 7
code, the behavior is unspeciﬁed. 8
The integer type (or kind, for Fortran) used to compute the iteration count for the collapsed loop is 9
implementation deﬁned. 10
Ifdist_schedule is speciﬁed, kindmust be static. If speciﬁed, iterations are divided into 11
chunks of size chunk_size , chunks are assigned to the initial teams of the league in a round-robin 12
fashion in the order of the initial team number. When no chunk_size is speciﬁed, the iteration space 13
is divided into chunks that are approximately equal in size, and at most one chunk is distributed to 14
each initial team of the league. The size of the chunks is unspeciﬁed in this case. 15
When no dist_schedule clause is speciﬁed, the schedule is implementation deﬁned. 16
Execution Model Events 17
Thedistribute-begin event occurs after an implicit task encounters a distribute construct but 18
before the task starts to execute the structured block of the distribute region. 19
Thedistribute-end event occurs after an implicit task ﬁnishes execution of a distribute region 20
but before it resumes execution of the enclosing context. 21
Tool Callbacks 22
A thread dispatches a registered ompt_callback_work callback with ompt_scope_begin 23
as itsendpoint argument and ompt_work_distribute as itswstypeargument for each 24
occurrence of a distribute-begin event in that thread. Similarly, a thread dispatches a registered 25
ompt_callback_work callback with ompt_scope_end as itsendpoint argument and 26
ompt_work_distribute as itswstypeargument for each occurrence of a distribute-end event 27
in that thread. The callbacks occur in the context of the implicit task. The callbacks have type 28
signature ompt_callback_work_t . 29
Restrictions 30
Restrictions to the distribute construct are as follows: 31
Thedistribute construct inherits the restrictions of the worksharing-loop construct. 32
Eachdistribute region must be encountered by the initial threads of all initial teams in a 33
league or by none at all. 34
122 OpenMP API – Version 5.0 November 2018
Thesequenceofthe distribute regionsencounteredmustbethesameforeveryinitialthread 1
of every initial team in a league. 2
Theregioncorrespondingtothe distribute constructmustbestrictlynestedinsidea teams 3
region. 4
A list item may appear in a firstprivate orlastprivate clause but not both. 5
Thedist_schedule clause must not appear on the distribute directive if the associated 6
loop(s) form a non-rectangular loop nest. 7
Cross References 8
teamsconstruct, see Section 2.7 on page 82 9
worksharing-loop construct, see Section 2.9.2 on page 101. 10
ompt_work_distribute , see Section 4.4.4.15 on page 445. 11
ompt_callback_work_t , see Section 4.5.2.5 on page 464. 12
2.9.4.2 distribute simd Construct 13
Summary 14
Thedistribute simd construct speciﬁes a loop that will be distributed across the master 15
threads of the teamsregion and executed concurrently using SIMD instructions. The 16
distribute simd construct is a composite construct. 17
Syntax 18
The syntax of the distribute simd construct is as follows: 19
C / C++
#pragma omp distribute simd [clause[ [ ,] clause] ... ] newline 20
for-loops 21
whereclausecan be any of the clauses accepted by the distribute orsimddirectives with 22
identical meanings and restrictions. 23
C / C++
CHAPTER 2. DIRECTIVES 123
Fortran
!$omp distribute simd [clause[ [ ,] clause] ... ] 1
do-loops 2
[!$omp end distribute simd ] 3
whereclausecan be any of the clauses accepted by the distribute orsimddirectives with 4
identical meanings and restrictions. 5
Ifanend distribute simd directiveisnotspeciﬁed,an end distribute simd directiveis 6
assumed at the end of the do-loops. 7
Fortran
Description 8
Thedistribute simd construct will ﬁrst distribute the iterations of the associated loop(s) 9
according to the semantics of the distribute construct and any clauses that apply to the 10
distribute construct. The resulting chunks of iterations will then be converted to a SIMD loop in a 11
manner consistent with any clauses that apply to the simdconstruct. 12
Execution Model Events 13
This composite construct generates the same events as the distribute construct. 14
Tool Callbacks 15
This composite construct dispatches the same callbacks as the distribute construct. 16
Restrictions 17
The restrictions for the distribute andsimdconstructs apply. 18
A list item may not appear in a linear clause unless it is the loop iteration variable of a loop 19
that is associated with the construct. 20
Theconditional modiﬁer may not appear in a lastprivate clause. 21
Cross References 22
simdconstruct, see Section 2.9.3.1 on page 110. 23
distribute construct, see Section 2.9.4.1 on page 120. 24
Data attribute clauses, see Section 2.19.4 on page 282. 25
124 OpenMP API – Version 5.0 November 2018
2.9.4.3 Distribute Parallel Worksharing-Loop Construct1
Summary 2
The distribute parallel worksharing-loop construct speciﬁes a loop that can be executed in parallel 3
by multiple threads that are members of multiple teams. The distribute parallel worksharing-loop 4
construct is a composite construct. 5
Syntax 6
The syntax of the distribute parallel worksharing-loop construct is as follows: 7
C / C++
#pragma omp distribute parallel for [clause[ [ ,] clause] ... ] newline 8
for-loops 9
whereclausecanbeanyoftheclausesacceptedbythe distribute orparallelworksharing-loop 10
directives with identical meanings and restrictions. 11
C / C++
Fortran
!$omp distribute parallel do [clause[ [ ,] clause] ... ] 12
do-loops 13
[!$omp end distribute parallel do ] 14
whereclausecanbeanyoftheclausesacceptedbythe distribute orparallelworksharing-loop 15
directives with identical meanings and restrictions. 16
If anend distribute parallel do directive is not speciﬁed, an end distribute 17
parallel do directive is assumed at the end of the do-loops. 18
Fortran
Description 19
The distribute parallel worksharing-loop construct will ﬁrst distribute the iterations of the 20
associated loop(s) into chunks according to the semantics of the distribute construct and any 21
clauses that apply to the distribute construct. Each of these chunks will form a loop. Each 22
resulting loop will then be distributed across the threads within the teamsregion to which the 23
distribute construct binds in a manner consistent with any clauses that apply to the parallel 24
worksharing-loop construct. 25
Execution Model Events 26
This composite construct generates the same events as the distribute and parallel 27
worksharing-loop constructs. 28
CHAPTER 2. DIRECTIVES 125
Tool Callbacks 1
This composite construct dispatches the same callbacks as the distribute and parallel 2
worksharing-loop constructs. 3
Restrictions 4
The restrictions for the distribute and parallel worksharing-loop constructs apply. 5
Noordered clause can be speciﬁed. 6
Nolinear clause can be speciﬁed. 7
Theconditional modiﬁer may not appear in a lastprivate clause. 8
Cross References 9
distribute construct, see Section 2.9.4.1 on page 120. 10
Parallel worksharing-loop construct, see Section 2.13.1 on page 185. 11
Data attribute clauses, see Section 2.19.4 on page 282. 12
2.9.4.4 Distribute Parallel Worksharing-Loop SIMD Construct 13
Summary 14
The distribute parallel worksharing-loop SIMD construct speciﬁes a loop that can be executed 15
concurrently using SIMD instructions in parallel by multiple threads that are members of multiple 16
teams. The distribute parallel worksharing-loop SIMD construct is a composite construct. 17
Syntax 18
C / C++
The syntax of the distribute parallel worksharing-loop SIMD construct is as follows: 19
#pragma omp distribute parallel for simd \ 20
[clause[ [ ,] clause] ... ] newline 21
for-loops 22
whereclausecanbeanyoftheclausesacceptedbythe distribute orparallelworksharing-loop 23
SIMD directives with identical meanings and restrictions. 24
C / C++
126 OpenMP API – Version 5.0 November 2018
Fortran
The syntax of the distribute parallel worksharing-loop SIMD construct is as follows: 1
!$omp distribute parallel do simd [clause[ [ ,] clause] ... ] 2
do-loops 3
[!$omp end distribute parallel do simd ] 4
whereclausecanbeanyoftheclausesacceptedbythe distribute orparallelworksharing-loop 5
SIMD directives with identical meanings and restrictions. 6
If anend distribute parallel do simd directive is not speciﬁed, an end distribute 7
parallel do simd directive is assumed at the end of the do-loops. 8
Fortran
Description 9
The distribute parallel worksharing-loop SIMD construct will ﬁrst distribute the iterations of the 10
associated loop(s) according to the semantics of the distribute construct and any clauses that 11
apply to the distribute construct. The resulting loops will then be distributed across the 12
threads contained within the teamsregion to which the distribute construct binds in a 13
manner consistent with any clauses that apply to the parallel worksharing-loop construct. The 14
resulting chunks of iterations will then be converted to a SIMD loop in a manner consistent with 15
any clauses that apply to the simdconstruct. 16
Execution Model Events 17
This composite construct generates the same events as the distribute and parallel 18
worksharing-loop SIMD constructs. 19
Tool Callbacks 20
This composite construct dispatches the same callbacks as the distribute and parallel 21
worksharing-loop SIMD constructs. 22
Restrictions 23
The restrictions for the distribute and parallel worksharing-loop SIMD constructs apply. 24
Noordered clause can be speciﬁed. 25
A list item may not appear in a linear clause unless it is the loop iteration variable of a loop 26
that is associated with the construct. 27
Theconditional modiﬁer may not appear in a lastprivate clause. 28
CHAPTER 2. DIRECTIVES 127
Cross References 1
distribute construct, see Section 2.9.4.1 on page 120. 2
Parallel worksharing-loop SIMD construct, see Section 2.13.5 on page 190. 3
Data attribute clauses, see Section 2.19.4 on page 282. 4
2.9.5 loop Construct 5
Summary 6
Aloopconstruct speciﬁes that the iterations of the associated loops may execute concurrently and 7
permits the encountering thread(s) to execute the loop accordingly. 8
Syntax 9
C / C++
The syntax of the loopconstruct is as follows: 10
#pragma omp loop [clause[ [ ,] clause] ... ] new-line 11
for-loops 12
whereclauseis one of the following: 13
bind(binding ) 14
collapse( n) 15
order(concurrent) 16
private( list) 17
lastprivate( list) 18
reduction( [default , ]reduction-identiﬁer :list) 19
wherebindingis one of the following: 20
teams 21
parallel 22
thread 23
Theloopdirective places restrictions on the structure of all associated for-loops. Speciﬁcally, all 24
associated for-loops must have canonical loop form (see Section 2.9.1 on page 95). 25
C / C++
128 OpenMP API – Version 5.0 November 2018
Fortran
The syntax of the loopconstruct is as follows: 1
!$omp loop [clause[ [ ,] clause] ... ] 2
do-loops 3
[!$omp end loop] 4
whereclauseis one of the following: 5
bind(binding ) 6
collapse( n) 7
order(concurrent) 8
private( list) 9
lastprivate( list) 10
reduction( [default , ]reduction-identiﬁer :list) 11
wherebindingis one of the following: 12
teams 13
parallel 14
thread 15
If anend loop directive is not speciﬁed, an end loop directive is assumed at the end of the 16
do-loops. 17
Theloopdirective places restrictions on the structure of all associated do-loops. Speciﬁcally, all 18
associated do-loops must have canonical loop form (see Section 2.9.1 on page 95). 19
Fortran
Binding 20
If the bindclause is present on the construct, the binding region is determined by binding. 21
Speciﬁcally, if bindingisteamsand there exists an innermost enclosing teamsregion then the 22
binding region is that teamsregion; if bindingisparallel then the binding region is the 23
innermost enclosing parallel region, which may be an implicit parallel region; and if bindingis 24
thread then the binding region is not deﬁned. If the bindclause is not present on the construct 25
and the loopconstruct is closely nested inside a teamsorparallel construct, the binding 26
region is the corresponding teamsorparallel region. If none of those conditions hold, the 27
binding region is not deﬁned. 28
If the binding region is a teamsregion, then the binding thread set is the set of master threads that 29
areexecutingthatregion. Ifthebindingregionisaparallelregion,thenthebindingthreadsetisthe 30
team of threads that are executing that region. If the binding region is not deﬁned, then the binding 31
thread set is the encountering thread. 32
CHAPTER 2. DIRECTIVES 129
Description 1
Theloopconstruct is associated with a loop nest that consists of one or more loops that follow the 2
directive. The directive asserts that the iterations may execute in any order, including concurrently. 3
Thecollapse clause may be used to specify how many loops are associated with the loop 4
construct. The parameter of the collapse clause must be a constant positive integer expression. 5
If acollapse clause is speciﬁed with a parameter value greater than 1, then the iterations of the 6
associated loops to which the clause applies are collapsed into one larger iteration space with 7
unspeciﬁed ordering. If no collapse clause is present or its parameter is 1, the only loop that is 8
associated with the loopconstruct is the one that immediately follows the loopdirective. 9
If more than one loop is associated with the loopconstruct then the number of times that any 10
intervening code between any two associated loops will be executed is unspeciﬁed but will be at 11
least once per iteration of the loop enclosing the intervening code and at most once per iteration of 12
theinnermostloopassociatedwiththeconstruct. Iftheiterationcountofanyloopthatisassociated 13
withthe loopconstructiszeroandthatloopdoesnotenclosetheinterveningcode,thebehavioris 14
unspeciﬁed. 15
The iteration space of the associated loops correspond to logical iterations numbered 0,1,...,N-1 16
where N is the number of loop iterations, and the logical numbering denotes the sequence in which 17
the iterations would be executed if a set of associated loop(s) were executed sequentially. At the 18
beginning of each logical iteration, the loop iteration variable of each associated loop has the value 19
that it would have if the set of the associated loop(s) were executed sequentially. 20
Each logical iteration is executed once per instance of the loopregion that is encountered by the 21
binding thread set. 22
If the order(concurrent) clause appears on the loopconstruct, the iterations of the 23
associated loops may execute in any order, including concurrently. If the orderclause is not 24
present, the behavior is as if the order(concurrent) clause appeared on the construct. 25
Thesetofthreadsthatmayexecutetheiterationsofthe loopregionisthebindingthreadset. Each 26
iteration is executed by one thread from this set. 27
If the loopregion binds to a teamsregion, the threads in the binding thread set may continue 28
execution after the loopregion without waiting for all iterations of the associated loop(s) to 29
complete. The iterations are guaranteed to complete before the end of the teamsregion. 30
If the loopregion does not bind to a teamsregion, all iterations of the associated loop(s) must 31
complete before the encountering thread(s) continue execution after the loopregion. 32
Restrictions 33
Restrictions to the loopconstruct are as follows: 34
If the collapse clause is speciﬁed then there may be no intervening OpenMP directives 35
between the associated loops. 36
130OpenMP API – Version 5.0 November 2018
At most one collapse clause can appear on a loopdirective. 1
A list item may not appear in a lastprivate clause unless it is the loop iteration variable of a 2
loop that is associated with the construct. 3
IfaloopconstructisnotnestedinsideanotherOpenMPconstructanditappearsinaprocedure, 4
thebindclause must be present. 5
If aloopregion binds to a teamsor parallel region, it must be encountered by all threads in 6
the binding thread set or by none of them. 7
If the bindclause is present and bindingisteams, theloopregion corresponding to the 8
loopconstruct must be strictly nested inside a teamsregion. 9
If the bindclause is present and bindingisparallel , the behavior is unspeciﬁed if the loop 10
region corresponding to a loopconstruct is closely nested inside a simdregion. 11
The only constructs that may be nested inside a loopregion are the loopconstruct, the 12
parallel construct, the simdconstruct, and combined constructs for which the ﬁrst construct 13
is aparallel construct. 14
Aloopregion corresponding to a loopconstruct may not contain calls to procedures that 15
contain OpenMP directives. 16
Aloopregion corresponding to a loopconstruct may not contain calls to the OpenMP 17
Runtime API. 18
If a threadprivate variable is referenced inside a loopregion, the behavior is unspeciﬁed. 19
C / C++
The associated for-loops must be structured blocks. 20
No statement can branch to any associated forstatement. 21
C / C++
Fortran
The associated do-loops must be structured blocks. 22
No statement in the associated loops other than the DO statements can cause a branch out of the 23
loops. 24
Fortran
Cross References 25
Thesingle construct, see Section 2.8.2 on page 89. 26
The Worksharing-Loop construct, see Section 2.9.2 on page 101. 27
SIMD directives, see Section 2.9.3 on page 110. 28
distribute construct, see Section 2.9.4.1 on page 120. 29
CHAPTER 2. DIRECTIVES 131
2.9.6 scan Directive 1
Summary 2
Thescandirective speciﬁes that scan computations update the list items on each iteration. 3
Syntax 4
C / C++
The syntax of the scandirective is as follows: 5
loop-associated-directive 6
for-loop-headers 7
{ 8
structured-block 9
#pragma omp scan clause new-line 10
structured-block 11
} 12
whereclauseis one of the following: 13
inclusive( list) 14
exclusive( list) 15
and where loop-associated-directive is afor,for simd , orsimddirective. 16
C / C++
Fortran
The syntax of the scandirective is as follows: 17
loop-associated-directive 18
do-loop-headers 19
structured-block 20
!$omp scan clause 21
structured-block 22
do-termination-stmts(s) 23
[end-loop-associated-directive] 24
whereclauseis one of the following: 25
inclusive( list) 26
exclusive( list) 27
and where loop-associated-directive (end-loop-associated-directive ) is ado(end do),do simd 28
(end do simd ), orsimd(end simd ) directive. 29
Fortran
132 OpenMP API – Version 5.0 November 2018
Description 1
Thescandirective may appear in the body of a loop or loop nest associated with an enclosing 2
worksharing-loop, worksharing-loop SIMD, or simdconstruct, to specify that a scan computation 3
updates each list item on each loop iteration. The directive speciﬁes that either an inclusive scan 4
computation is to be performed for each list item that appears in an inclusive clause on the 5
directive, or an exclusive scan computation is to be performed for each list item that appears in an 6
exclusive clause on the directive. For each list item for which a scan computation is speciﬁed, 7
statements that lexically precede or follow the directive constitute one of two phases for a given 8
logical iteration of the loop – an input phase or ascan phase . 9
If the list item appears in an inclusive clause, all statements in the structured block that 10
lexically precede the directive constitute the input phase and all statements in the structured block 11
that lexically follow the directive constitute the scan phase . If the list item appears in an 12
exclusive clause and the iteration is not the last iteration, all statements in the structured block 13
that lexically precede the directive constitute the scan phase and all statements in the structured 14
block that lexically follow the directive constitute the input phase . If the list item appears in an 15
exclusive clause and the iteration is the last iteration, the iteration does not have an input phase 16
and all statements that lexically precede or follow the directive constitute the scan phase for the 17
iteration. The inputphase containsallcomputationsthatupdatethelistitemintheiteration,andthe 18
scanphase ensuresthatanystatementthatreadsthelistitemusestheresultofthescancomputation 19
for that iteration. 20
The result of a scan computation for a given iteration is calculated according to the last generalized 21
preﬁx sum (PRESUM last) applied over the sequence of values given by the original value of the list 22
item prior to the loop and all preceding updates to the list item in the logical iteration space of the 23
loop. The operation PRESUM last(op,a1, ...,aN) is deﬁned for a given binary operator opand a 24
sequence of Nvaluesa1, ...,aNas follows: 25
ifN= 1,a1 26
ifN>1,op(PRESUM last(op,a1, ...,aK),PRESUM last(op,aL, ...,aN) ), where 27
1K+ 1 =LN. 28
At the beginning of the input phase of each iteration, the list item is initialized with the initializer 29
value of the reduction-identiﬁer speciﬁed by the reduction clause on the innermost enclosing 30
construct. The update value of a list item is, for a given iteration, the value of the list item on 31
completion of its input phase . 32
Letorig-valbe the value of the original list item on entry to the enclosing worksharing-loop, 33
worksharing-loop SIMD, or simdconstruct. Let combiner be the combiner for the 34
reduction-identiﬁer speciﬁed by the reduction clause on the construct. And let uIbe the update 35
value of a list item for iteration I. For list items appearing in an inclusive clause on the scan 36
directive, at the beginning of the scan phase for iteration Ithe list item is assigned the result of the 37
operation PRESUM last(combiner ,orig-val,u0, ...,uI). For list items appearing in an 38
exclusive clause on the scandirective, at the beginning of the scan phase for iteration I= 0 39
CHAPTER 2. DIRECTIVES 133
thelistitemisassignedthevalue orig-val,andatthebeginningofthe scanphase foriteration I>0 1
the list item is assigned the result of the operation PRESUM last(combiner ,orig-val,u0, ...,uI-1). 2
Restrictions 3
Restrictions to the scandirective are as follows: 4
Exactly one scandirective must appear in the loop body of an enclosing worksharing-loop, 5
worksharing-loop SIMD, or simdconstruct on which a reduction clause with the inscan 6
modiﬁer is present. 7
A list item that appears in the inclusive orexclusive clause must appear in a 8
reduction clause with the inscan modiﬁer on the enclosing worksharing-loop, 9
worksharing-loop SIMD, or simdconstruct. 10
Cross-iteration dependences across diﬀerent logical iterations must not exist, except for 11
dependences for the list items speciﬁed in an inclusive orexclusive clause. 12
Intra-iteration dependences from a statement in the structured block preceding a scandirective 13
to a statement in the structured block following a scandirective must not exist, except for 14
dependences for the list items speciﬁed in an inclusive orexclusive clause. 15
Cross References 16
worksharing-loop construct, see Section 2.9.2 on page 101. 17
simdconstruct, see Section 2.9.3.1 on page 110. 18
worksharing-loop SIMD construct, see Section 2.9.3.2 on page 114. 19
reduction clause, see Section 2.19.5.4 on page 300. 20
134OpenMP API – Version 5.0 November 2018
2.10 Tasking Constructs1
2.10.1 task Construct 2
Summary 3
Thetaskconstruct deﬁnes an explicit task. 4
Syntax 5
C / C++
The syntax of the taskconstruct is as follows: 6
#pragma omp task [clause[ [ ,] clause] ... ] new-line 7
structured-block 8
whereclauseis one of the following: 9
if([task :] scalar-expression ) 10
final(scalar-expression ) 11
untied 12
default(shared | none) 13
mergeable 14
private( list) 15
firstprivate( list) 16
shared( list) 17
in_reduction( reduction-identiﬁer :list) 18
depend( [depend-modiﬁer ,] dependence-type :locator-list ) 19
priority( priority-value ) 20
allocate( [allocator :] list) 21
affinity( [aﬀ-modiﬁer :] locator-list ) 22
detach( event-handle ) 23
whereaﬀ-modiﬁer is one of the following: 24
iterator( iterators-deﬁnition ) 25
whereevent-handle is a variable of the omp_event_handle_t type. 26
C / C++
CHAPTER 2. DIRECTIVES 135
Fortran
The syntax of the taskconstruct is as follows: 1
!$omp task [clause[ [ ,] clause] ... ] 2
structured-block 3
!$omp end task 4
whereclauseis one of the following: 5
if([task :] scalar-logical-expression ) 6
final(scalar-logical-expression ) 7
untied 8
default(private | firstprivate | shared | none) 9
mergeable 10
private( list) 11
firstprivate( list) 12
shared( list) 13
in_reduction( reduction-identiﬁer :list) 14
depend( [depend-modiﬁer ,] dependence-type :locator-list ) 15
priority( priority-value ) 16
allocate( [allocator :] list) 17
affinity( [aﬀ-modiﬁer :] locator-list ) 18
detach( event-handle ) 19
whereaﬀ-modiﬁer is one of the following: 20
iterator( iterators-deﬁnition ) 21
whereevent-handle is an integer variable of omp_event_handle_kind kind. 22
Fortran
Binding 23
The binding thread set of the taskregion is the current team. A taskregion binds to the 24
innermost enclosing parallel region. 25
136 OpenMP API – Version 5.0 November 2018
Description 1
Thetaskconstructisa taskgeneratingconstruct . Whenathreadencountersa taskconstruct,an 2
explicit task is generated from the code for the associated structured-block . The data environment 3
ofthetaskiscreatedaccordingtothedata-sharingattributeclausesonthe taskconstruct,per-data 4
environment ICVs, and any defaults that apply. The data environment of the task is destroyed when 5
the execution code of the associated structured-block is completed. 6
Theencounteringthreadmayimmediatelyexecutethetask,ordeferitsexecution. Inthelattercase, 7
any thread in the team may be assigned the task. Completion of the task can be guaranteed using 8
task synchronization constructs. If a taskconstruct is encountered during execution of an outer 9
task, the generated taskregion corresponding to this construct is not a part of the outer task 10
region unless the generated task is an included task. 11
If adetach clause is present on a taskconstruct a new event allow-completion-event is created. 12
Theallow-completion-event is connected to the completion of the associated taskregion. The 13
originalevent-handle will be updated to represent the allow-completion-event event before the task 14
data environment is created. The event-handle will be considered as if it was speciﬁed on a 15
firstprivate clause. The use of a variable in a detach clause expression of a task 16
construct causes an implicit reference to the variable in all enclosing constructs. 17
If nodetach clause is present on a taskconstruct the generated taskis completed when the 18
executionofitsassociated structured-block iscompleted. Ifa detach clauseispresentona task 19
construct the task is completed when the execution of its associated structured-block is completed 20
and theallow-completion-event is fulﬁlled. 21
Whenan ifclauseispresentona taskconstruct,andthe ifclauseexpressionevaluatesto false, 22
an undeferred task is generated, and the encountering thread must suspend the current task region, 23
for which execution cannot be resumed until execution of the structured block that is associated 24
with the generated task is completed. The use of a variable in an ifclause expression of a task 25
construct causes an implicit reference to the variable in all enclosing constructs. 26
When a finalclause is present on a taskconstruct and the finalclause expression evaluates 27
totrue,thegeneratedtaskwillbeaﬁnaltask. All taskconstructsencounteredduringexecutionof 28
a ﬁnal task will generate ﬁnal and included tasks. The use of a variable in a finalclause 29
expression of a taskconstruct causes an implicit reference to the variable in all enclosing 30
constructs. Encountering a taskconstruct with the detach clause during the execution of a ﬁnal 31
task results in unspeciﬁed behavior. 32
Theifclause expression and the finalclause expression are evaluated in the context outside of 33
thetaskconstruct, and no ordering of those evaluations is speciﬁed.. 34
A thread that encounters a task scheduling point within the taskregion may temporarily suspend 35
thetaskregion. By default, a task is tied and its suspended taskregion can only be resumed by 36
the thread that started its execution. If the untied clause is present on a taskconstruct, any 37
thread in the team can resume the taskregion after a suspension. The untied clause is ignored 38
CHAPTER 2. DIRECTIVES 137
if afinalclause is present on the same taskconstruct and the finalclause expression 1
evaluates to true, or if a task is an included task. 2
Thetaskconstruct includes a task scheduling point in the task region of its generating task, 3
immediately following the generation of the explicit task. Each explicit taskregion includes a 4
task scheduling point at the end of its associated structured-block . 5
When the mergeable clause is present on a taskconstruct, the generated task is a mergeable 6
task. 7
Thepriority clause is a hint for the priority of the generated task. The priority-value is a 8
non-negative integer expression that provides a hint for task execution order. Among all tasks ready 9
to be executed, higher priority tasks (those with a higher numerical value in the priority clause 10
expression) are recommended to execute before lower priority ones. The default priority-value 11
when no priority clause is speciﬁed is zero (the lowest priority). If a value is speciﬁed in the 12
priority clause that is higher than the max-task-priority-var ICV then the implementation will 13
use the value of that ICV. A program that relies on task execution order being determined by this 14
priority-value may have unspeciﬁed behavior. 15
Theaffinity clause is a hint to indicate data aﬃnity of the generated task. The task is 16
recommended to execute closely to the location of the list items. A program that relies on the task 17
execution location being determined by this list may have unspeciﬁed behavior. 18
The list items that appear in the affinity clause may reference iterators deﬁned by an 19
iterators-deﬁnition appearing in the same clause. The list items that appear in the affinity 20
clause may include array sections. 21
C / C++
The list items that appear in the affinity clause may use shape-operators. 22
C / C++
If a list item appears in an affinity clause then data aﬃnity refers to the original list item. 23
24
Note– When storage is shared by an explicit taskregion, the programmer must ensure, by 25
adding proper synchronization, that the storage does not reach the end of its lifetime before the 26
explicit taskregion completes its execution. 27
28
Execution Model Events 29
Thetask-create event occurs when a thread encounters a construct that causes a new task to be 30
created. The event occurs after the task is initialized but before it begins execution or is deferred. 31
138 OpenMP API – Version 5.0 November 2018
Tool Callbacks 1
A thread dispatches a registered ompt_callback_task_create callback for each occurrence 2
of atask-create event in the context of the encountering task. This callback has the type signature 3
ompt_callback_task_create_t and theﬂagsargument indicates the task types shown in 4
Table 2.7. 5
TABLE 2.7:ompt_callback_task_create callback ﬂags evaluation
Operation Evaluates to true
(ﬂags& ompt_task_explicit) Always in the dispatched callback
(ﬂags& ompt_task_undeferred) If the task is an undeferred task
(ﬂags& ompt_task_final) If the task is a ﬁnal task
(ﬂags& ompt_task_untied) If the task is an untied task
(ﬂags& ompt_task_mergeable) If the task is a mergeable task
(ﬂags& ompt_task_merged) If the task is a merged task
Restrictions 6
Restrictions to the taskconstruct are as follows: 7
A program that branches into or out of a taskregion is non-conforming. 8
A program must not depend on any ordering of the evaluations of the clauses of the task 9
directive, or on any side eﬀects of the evaluations of the clauses. 10
At most one ifclause can appear on the directive. 11
At most one finalclause can appear on the directive. 12
At most one priority clause can appear on the directive. 13
At most one detach clause can appear on the directive. 14
If adetach clause appears on the directive, then a mergeable clause cannot appear on the 15
same directive. 16
C / C++
A throw executed inside a taskregion must cause execution to resume within the same task 17
region, and the same thread that threw the exception must catch it. 18
C / C++
CHAPTER 2. DIRECTIVES 139
Cross References 1
Task scheduling constraints, see Section 2.10.6 on page 149. 2
allocate clause, see Section 2.11.4 on page 158. 3
ifclause, see Section 2.15 on page 220. 4
depend clause, see Section 2.17.11 on page 255. 5
Data-sharing attribute clauses, Section 2.19.4 on page 282. 6
default clause, see Section 2.19.4.1 on page 282. 7
in_reduction clause, see Section 2.19.5.6 on page 303. 8
omp_fulfill_event , see Section 3.5.1 on page 396. 9
ompt_callback_task_create_t , see Section 4.5.2.7 on page 467. 10
2.10.2 taskloop Construct 11
Summary 12
Thetaskloop construct speciﬁes that the iterations of one or more associated loops will be 13
executed in parallel using explicit tasks. The iterations are distributed across tasks generated by the 14
construct and scheduled to be executed. 15
Syntax 16
C / C++
The syntax of the taskloop construct is as follows: 17
#pragma omp taskloop [clause[[ ,] clause] ...] new-line 18
for-loops 19
whereclauseis one of the following: 20
if([taskloop : ] scalar-expression ) 21
shared( list) 22
private( list) 23
firstprivate( list) 24
lastprivate( list) 25
reduction( [default , ]reduction-identiﬁer :list) 26
in_reduction( reduction-identiﬁer :list) 27
140 OpenMP API – Version 5.0 November 2018
default(shared | none) 1
grainsize( grain-size ) 2
num_tasks( num-tasks ) 3
collapse( n) 4
final(scalar-expr ) 5
priority( priority-value ) 6
untied 7
mergeable 8
nogroup 9
allocate( [allocator :] list) 10
Thetaskloop directive places restrictions on the structure of all associated for-loops. 11
Speciﬁcally,allassociated for-loops musthave canonicalloopform (seeSection2.9.1onpage95). 12
C / C++
Fortran
The syntax of the taskloop construct is as follows: 13
!$omp taskloop [clause[[ ,] clause] ...] 14
do-loops 15
[!$omp end taskloop ] 16
whereclauseis one of the following: 17
if([taskloop : ] scalar-logical-expression ) 18
shared( list) 19
private( list) 20
firstprivate( list) 21
lastprivate( list) 22
reduction( [default , ]reduction-identiﬁer :list) 23
in_reduction( reduction-identiﬁer :list) 24
default(private | firstprivate | shared | none) 25
grainsize( grain-size ) 26
num_tasks( num-tasks ) 27
collapse( n) 28
final(scalar-logical-expr ) 29
priority( priority-value ) 30
CHAPTER 2. DIRECTIVES 141
untied 1
mergeable 2
nogroup 3
allocate( [allocator :] list) 4
Ifanend taskloop directiveisnotspeciﬁed,an end taskloop directiveisassumedattheend 5
of thedo-loops. 6
Thetaskloop directive places restrictions on the structure of all associated do-loops. 7
Speciﬁcally, all associated do-loops must have canonical loop form (see Section 2.9.1 on page 95). 8
Fortran
Binding 9
The binding thread set of the taskloop region is the current team. A taskloop region binds to 10
the innermost enclosing parallel region. 11
Description 12
Thetaskloop construct is a task generating construct . When a thread encounters a taskloop 13
construct, the construct partitions the iterations of the associated loops into explicit tasks for 14
parallel execution. The data environment of each generated task is created according to the 15
data-sharing attribute clauses on the taskloop construct, per-data environment ICVs, and any 16
defaults that apply. The order of the creation of the loop tasks is unspeciﬁed. Programs that rely on 17
any execution order of the logical loop iterations are non-conforming. 18
By default, the taskloop construct executes as if it was enclosed in a taskgroup construct 19
with no statements or directives outside of the taskloop construct. Thus, the taskloop 20
construct creates an implicit taskgroup region. If the nogroup clause is present, no implicit 21
taskgroup region is created. 22
If areduction clause is present on the taskloop construct, the behavior is as if a 23
task_reduction clause with the same reduction operator and list items was applied to the 24
implicit taskgroup construct enclosing the taskloop construct. The taskloop construct 25
executes as if each generated task was deﬁned by a taskconstruct on which an in_reduction 26
clause with the same reduction operator and list items is present. Thus, the generated tasks are 27
participants of the reduction deﬁned by the task_reduction clause that was applied to the 28
implicit taskgroup construct. 29
If anin_reduction clause is present on the taskloop construct, the behavior is as if each 30
generated task was deﬁned by a taskconstruct on which an in_reduction clause with the 31
same reduction operator and list items is present. Thus, the generated tasks are participants of a 32
reduction previously deﬁned by a reduction scoping clause. 33
142OpenMP API – Version 5.0 November 2018
If agrainsize clause is present on the taskloop construct, the number of logical loop 1
iterations assigned to each generated task is greater than or equal to the minimum of the value of 2
thegrain-size expressionandthenumberoflogicalloopiterations,butlessthantwotimesthevalue 3
of thegrain-size expression. 4
The parameter of the grainsize clause must be a positive integer expression. If num_tasks is 5
speciﬁed, the taskloop construct creates as many tasks as the minimum of the num-tasks 6
expression and the number of logical loop iterations. Each task must have at least one logical loop 7
iteration. Theparameterofthe num_tasks clausemustbeapositiveintegerexpression. Ifneither 8
agrainsize nornum_tasks clause is present, the number of loop tasks generated and the 9
number of logical loop iterations assigned to these tasks is implementation deﬁned. 10
Thecollapse clausemaybeusedtospecifyhowmanyloopsareassociatedwiththe taskloop 11
construct. The parameter of the collapse clause must be a constant positive integer expression. 12
If nocollapse clause is present or its parameter is 1, the only loop that is associated with the 13
taskloop construct is the one that immediately follows the taskloop directive. If a 14
collapse clause is speciﬁed with a parameter value greater than 1 and more than one loop is 15
associated with the taskloop construct, then the iterations of all associated loops are collapsed 16
into one larger iteration space that is then divided according to the grainsize andnum_tasks 17
clauses. The sequential execution of the iterations in all associated loops determines the order of 18
the iterations in the collapsed iteration space. 19
If more than one loop is associated with the taskloop construct then the number of times that 20
any intervening code between any two associated loops will be executed is unspeciﬁed but will be 21
at least once per iteration of the loop enclosing the intervening code and at most once per iteration 22
of the innermost loop associated with the construct. If the iteration count of any loop that is 23
associated with the taskloop construct is zero and that loop does not enclose intervening code, 24
the behavior is unspeciﬁed. 25
A taskloop loop has logical iterations numbered 0,1,...,N-1 where N is the number of loop 26
iterations, and the logical numbering denotes the sequence in which the iterations would be 27
executed if the set of associated loop(s) were executed sequentially. At the beginning of each 28
logical iteration, the loop iteration variable of each associated loop has the value that it would have 29
if the set of the associated loop(s) were executed sequentially. 30
The iteration count for each associated loop is computed before entry to the outermost loop. If 31
execution of any associated loop changes any of the values used to compute any of the iteration 32
counts, then the behavior is unspeciﬁed. 33
The integer type (or kind, for Fortran) used to compute the iteration count for the collapsed loop is 34
implementation deﬁned. 35
When an ifclause is present on a taskloop construct, and if the ifclause expression evaluates 36
tofalse, undeferred tasks are generated. The use of a variable in an ifclause expression of a 37
taskloop construct causes an implicit reference to the variable in all enclosing constructs. 38
CHAPTER 2. DIRECTIVES 143
When a finalclause is present on a taskloop construct and the finalclause expression 1
evaluates to true, the generated tasks will be ﬁnal tasks. The use of a variable in a finalclause 2
expression of a taskloop construct causes an implicit reference to the variable in all enclosing 3
constructs. 4
When a priority clause is present on a taskloop construct, the generated tasks use the 5
priority-value as if it was speciﬁed for each individual task. If the priority clause is not 6
speciﬁed, tasks generated by the taskloop construct have the default task priority (zero). 7
If the untied clause is speciﬁed, all tasks generated by the taskloop construct are untied tasks. 8
When the mergeable clause is present on a taskloop construct, each generated task is a 9
mergeable task . 10
C++
Forfirstprivate variables of class type, the number of invocations of copy constructors to 11
perform the initialization is implementation-deﬁned. 12
C++
13
Note– When storage is shared by a taskloop region, the programmer must ensure, by adding 14
propersynchronization,thatthestoragedoesnotreachtheendofitslifetimebeforethe taskloop 15
region and its descendant tasks complete their execution. 16
17
Execution Model Events 18
Thetaskloop-begin event occurs after a task encounters a taskloop construct but before any 19
other events that may trigger as a consequence of executing the taskloop . Speciﬁcally, a 20
taskloop-begin event for a taskloop will precede the taskgroup-begin that occurs unless a 21
nogroup clause is present. Regardless of whether an implicit taskgroup is present, a 22
taskloop-begin will always precede any task-create events for generated tasks. 23
Thetaskloop-end event occurs after a taskloop region ﬁnishes execution but before resuming 24
execution of the encountering task. 25
Thetaskloop-iteration-begin event occurs before an explicit task executes each iteration of a 26
taskloop . 27
144 OpenMP API – Version 5.0 November 2018
Tool Callbacks 1
A thread dispatches a registered ompt_callback_work callback for each occurrence of a 2
taskloop-begin andtaskloop-end event in that thread. The callback occurs in the context of the 3
encountering task. The callback has type signature ompt_callback_work_t . The callback 4
receives ompt_scope_begin orompt_scope_end as itsendpoint argument, as appropriate, 5
andompt_work_taskloop as itswstypeargument. 6
A thread dispatches a registered ompt_callback_dispatch callback for each occurrence of a 7
taskloop-iteration-begin eventinthatthread. Thecallbackoccursinthecontextoftheencountering 8
task. The callback has type signature ompt_callback_dispatch_t . 9
Restrictions 10
The restrictions of the taskloop construct are as follows: 11
A program that branches into or out of a taskloop region is non-conforming. 12
No OpenMP directive may appear in the region between any associated loops. 13
If acollapse clause is speciﬁed, exactly one loop must occur in the region at each nesting 14
level up to the number of loops speciﬁed by the parameter of the collapse clause. 15
If areduction clause is present on the taskloop directive, the nogroup clause must not 16
be speciﬁed. 17
The same list item cannot appear in both a reduction and an in_reduction clause. 18
At most one grainsize clause can appear on a taskloop directive. 19
At most one num_tasks clause can appear on a taskloop directive. 20
Thegrainsize clause and num_tasks clause are mutually exclusive and may not appear on 21
the same taskloop directive. 22
At most one collapse clause can appear on a taskloop directive. 23
At most one ifclause can appear on the directive. 24
At most one finalclause can appear on the directive. 25
At most one priority clause can appear on the directive. 26
Cross References 27
taskconstruct, Section 2.10.1 on page 135. 28
ifclause, see Section 2.15 on page 220. 29
taskgroup construct, Section 2.17.6 on page 232. 30
Data-sharing attribute clauses, Section 2.19.4 on page 282. 31
CHAPTER 2. DIRECTIVES 145
default clause, see Section 2.19.4.1 on page 282. 1
ompt_scope_begin andompt_scope_end , see Section 4.4.4.11 on page 443. 2
ompt_work_taskloop , see Section 4.4.4.15 on page 445. 3
ompt_callback_work_t , see Section 4.5.2.5 on page 464. 4
ompt_callback_dispatch_t , see Section 4.5.2.6 on page 465. 5
2.10.3 taskloop simd Construct 6
Summary 7
Thetaskloop simd construct speciﬁes a loop that can be executed concurrently using SIMD 8
instructions and that those iterations will also be executed in parallel using explicit tasks. The 9
taskloop simd construct is a composite construct. 10
Syntax 11
C / C++
The syntax of the taskloop simd construct is as follows: 12
#pragma omp taskloop simd [clause[[ ,] clause] ...] new-line 13
for-loops 14
whereclausecan be any of the clauses accepted by the taskloop orsimddirectives with 15
identical meanings and restrictions. 16
C / C++
Fortran
The syntax of the taskloop simd construct is as follows: 17
!$omp taskloop simd [clause[[ ,] clause] ...] 18
do-loops 19
[!$omp end taskloop simd ] 20
whereclausecan be any of the clauses accepted by the taskloop orsimddirectives with 21
identical meanings and restrictions. 22
If anend taskloop simd directive is not speciﬁed, an end taskloop simd directive is 23
assumed at the end of the do-loops. 24
Fortran
146 OpenMP API – Version 5.0 November 2018
Binding 1
The binding thread set of the taskloop simd region is the current team. A taskloop simd 2
region binds to the innermost enclosing parallel region. 3
Description 4
Thetaskloop simd construct will ﬁrst distribute the iterations of the associated loop(s) across 5
tasks in a manner consistent with any clauses that apply to the taskloop construct. The resulting 6
tasks will then be converted to a SIMD loop in a manner consistent with any clauses that apply to 7
thesimdconstruct,exceptforthe collapse clause. Forthepurposesofeachtask’sconversionto 8
a SIMD loop, the collapse clause is ignored and the eﬀect of any in_reduction clause is as 9
if areduction clause with the same reduction operator and list items is present on the construct. 10
Execution Model Events 11
This composite construct generates the same events as the taskloop construct. 12
Tool Callbacks 13
This composite construct dispatches the same callbacks as the taskloop construct. 14
Restrictions 15
The restrictions for the taskloop andsimdconstructs apply. 16
Theconditional modiﬁer may not appear in a lastprivate clause. 17
Cross References 18
simdconstruct, see Section 2.9.3.1 on page 110. 19
taskloop construct, see Section 2.10.2 on page 140. 20
Data-sharing attribute clauses, see Section 2.19.4 on page 282. 21
2.10.4 taskyield Construct 22
Summary 23
Thetaskyield constructspeciﬁesthatthecurrenttaskcanbesuspendedinfavorofexecutionof 24
a diﬀerent task. The taskyield construct is a stand-alone directive. 25
CHAPTER 2. DIRECTIVES 147
Syntax 1
C / C++
The syntax of the taskyield construct is as follows: 2
#pragma omp taskyield new-line 3
C / C++
Fortran
The syntax of the taskyield construct is as follows: 4
!$omp taskyield 5
Fortran
Binding 6
Ataskyield region binds to the current task region. The binding thread set of the taskyield 7
region is the current team. 8
Description 9
Thetaskyield region includes an explicit task scheduling point in the current task region. 10
Cross References 11
Task scheduling, see Section 2.10.6 on page 149. 12
2.10.5 Initial Task 13
Execution Model Events 14
No events are associated with the implicit parallel region in each initial thread. 15
Theinitial-thread-begin eventoccursinaninitialthreadaftertheOpenMPruntimeinvokesthetool 16
initializer but before the initial thread begins to execute the ﬁrst OpenMP region in the initial task. 17
Theinitial-task-begin event occurs after an initial-thread-begin event but before the ﬁrst OpenMP 18
region in the initial task begins to execute. 19
Theinitial-task-end event occurs before an initial-thread-end event but after the last OpenMP 20
region in the initial task ﬁnishes to execute. 21
Theinitial-thread-end event occurs as the ﬁnal event in an initial thread at the end of an initial task 22
immediately prior to invocation of the tool ﬁnalizer. 23
148 OpenMP API – Version 5.0 November 2018
Tool Callbacks 1
A thread dispatches a registered ompt_callback_thread_begin callback for the 2
initial-thread-begin event in an initial thread. The callback occurs in the context of the initial 3
thread. The callback has type signature ompt_callback_thread_begin_t . The callback 4
receives ompt_thread_initial as itsthread_type argument. 5
A thread dispatches a registered ompt_callback_implicit_task callback with 6
ompt_scope_begin as itsendpoint argument for each occurrence of an initial-task-begin in 7
that thread. Similarly, a thread dispatches a registered ompt_callback_implicit_task 8
callback with ompt_scope_end as itsendpoint argument for each occurrence of an 9
initial-task-end event in that thread. The callbacks occur in the context of the initial task and have 10
type signature ompt_callback_implicit_task_t . In the dispatched callback, 11
(ﬂag& ompt_task_initial) always evaluates to true. 12
A thread dispatches a registered ompt_callback_thread_end callback for the 13
initial-thread-end event in that thread. The callback occurs in the context of the thread. The 14
callback has type signature ompt_callback_thread_end_t . The implicit parallel region 15
does not dispatch a ompt_callback_parallel_end callback; however, the implicit parallel 16
region can be ﬁnalized within this ompt_callback_thread_end callback. 17
Cross References 18
ompt_thread_initial , see Section 4.4.4.10 on page 443. 19
ompt_task_initial , see Section 4.4.4.18 on page 446. 20
ompt_callback_thread_begin_t , see Section 4.5.2.1 on page 459. 21
ompt_callback_thread_end_t , see Section 4.5.2.2 on page 460. 22
ompt_callback_parallel_begin_t , see Section 4.5.2.3 on page 461. 23
ompt_callback_parallel_end_t , see Section 4.5.2.4 on page 463. 24
ompt_callback_implicit_task_t , see Section 4.5.2.11 on page 471. 25
2.10.6 Task Scheduling 26
Whenever a thread reaches a task scheduling point, the implementation may cause it to perform a 27
task switch, beginning or resuming execution of a diﬀerent task bound to the current team. Task 28
scheduling points are implied at the following locations: 29
during the generation of an explicit task; 30
the point immediately following the generation of an explicit task; 31
CHAPTER 2. DIRECTIVES 149
after the point of completion of the structured block associated with a task; 1
in ataskyield region; 2
in ataskwait region; 3
at the end of a taskgroup region; 4
in an implicit barrier region; 5
in an explicit barrier region; 6
during the generation of a target region; 7
the point immediately following the generation of a target region; 8
at the beginning and end of a target data region; 9
in atarget update region; 10
in atarget enter data region; 11
in atarget exit data region; 12
in the omp_target_memcpy routine; 13
in the omp_target_memcpy_rect routine; 14
When a thread encounters a task scheduling point it may do one of the following, subject to the 15
Task Scheduling Constraints (below): 16
begin execution of a tied task bound to the current team; 17
resume any suspended task region, bound to the current team, to which it is tied; 18
begin execution of an untied task bound to the current team; or 19
resume any suspended untied task region bound to the current team. 20
If more than one of the above choices is available, it is unspeciﬁed as to which will be chosen. 21
Task Scheduling Constraints are as follows: 22
1. Schedulingofnewtiedtasksisconstrainedbythesetoftaskregionsthatarecurrentlytiedtothe 23
thread and that are not suspended in a barrier region. If this set is empty, any new tied task may 24
be scheduled. Otherwise, a new tied task may be scheduled only if it is a descendent task of 25
every task in the set. 26
2. A dependent task shall not start its execution until its task dependences are fulﬁlled. 27
3. A task shall not be scheduled while any task with which it is mutually exclusive has been 28
scheduled, but has not yet completed. 29
150OpenMP API – Version 5.0 November 2018
4. When an explicit task is generated by a construct containing an ifclause for which the 1
expression evaluated to false, and the previous constraints are already met, the task is executed 2
immediately after generation of the task. 3
A program relying on any other assumption about task scheduling is non-conforming. 4
5
Note– Task scheduling points dynamically divide task regions into parts. Each part is executed 6
uninterrupted from start to end. Diﬀerent parts of the same task region are executed in the order in 7
which they are encountered. In the absence of task synchronization constructs, the order in which a 8
thread executes parts of diﬀerent schedulable tasks is unspeciﬁed. 9
A program must behave correctly and consistently with all conceivable scheduling sequences that 10
are compatible with the rules above. 11
For example, if threadprivate storage is accessed (explicitly in the source code or implicitly 12
in calls to library routines) in one part of a task region, its value cannot be assumed to be preserved 13
into the next part of the same task region if another schedulable task exists that modiﬁes it. 14
As another example, if a lock acquire and release happen in diﬀerent parts of a task region, no 15
attempt should be made to acquire the same lock in any part of another task that the executing 16
thread may schedule. Otherwise, a deadlock is possible. A similar situation can occur when a 17
critical region spans multiple parts of a task and another schedulable task contains a 18
critical region with the same name. 19
Theuseofthreadprivatevariablesandtheuseoflocksorcriticalsectionsinanexplicittaskwithan 20
ifclause must take into account that when the ifclause evaluates to false, the task is executed 21
immediately, without regard to Task Scheduling Constraint 2. 22
23
Execution Model Events 24
Thetask-schedule event occurs in a thread when the thread switches tasks at a task scheduling 25
point; no event occurs when switching to or from a merged task. 26
Tool Callbacks 27
A thread dispatches a registered ompt_callback_task_schedule callback for each 28
occurrence of a task-schedule event in the context of the task that begins or resumes. This callback 29
has the type signature ompt_callback_task_schedule_t . The argument prior_task_status 30
is used to indicate the cause for suspending the prior task. This cause may be the completion of the 31
prior task region, the encountering of a taskyield construct, or the encountering of an active 32
cancellation point. 33
Cross References 34
ompt_callback_task_schedule_t , see Section 4.5.2.10 on page 470. 35
CHAPTER 2. DIRECTIVES 151
2.11 Memory Management Directives1
2.11.1 Memory Spaces2
OpenMP memory spaces represent storage resources where variables can be stored and retrieved. 3
Table 2.8 shows the list of predeﬁned memory spaces. The selection of a given memory space 4
expressesanintenttousestoragewithcertaintraitsfortheallocations. Theactualstorageresources 5
that each memory space represents are implementation deﬁned. 6
TABLE 2.8:Predeﬁned Memory Spaces
Memory space name Storage selection intent
omp_default_mem_space Represents the system default storage.
omp_large_cap_mem_space Represents storage with large capacity.
omp_const_mem_space Represents storage optimized for variables with
constant values. The result of writing to this storage
is unspeciﬁed.
omp_high_bw_mem_space Represents storage with high bandwidth.
omp_low_lat_mem_space Represents storage with low latency.
7
Note– For variables allocated in the omp_const_mem_space memory space OpenMP 8
supports initializing constant memory either by means of the firstprivate clause or through 9
initialization with compile time constants for static and constant variables. Implementation-deﬁned 10
mechanisms to provide the constant value of these variables may also be supported. 11
12
Cross References 13
omp_init_allocator routine, see Section 3.7.2 on page 409. 14
2.11.2 Memory Allocators 15
OpenMP memory allocators can be used by a program to make allocation requests. When a 16
memory allocator receives a request to allocate storage of a certain size, an allocation of logically 17
consecutive memoryin the resources of its associated memory space of at least the size that was 18
requested will be returned if possible. This allocation will not overlap with any other existing 19
allocation from an OpenMP memory allocator. 20
152 OpenMP API – Version 5.0 November 2018
The behavior of the allocation process can be aﬀected by the allocator traits that the user speciﬁes. 1
Table2.9showstheallowedallocatorstraits,theirpossiblevaluesandthedefaultvalueofeachtrait. 2
TABLE 2.9:Allocator Traits
Allocator trait Allowed values Default value
sync_hint contended ,uncontended ,
serialized ,privatecontended
alignment A positive integer value that is a power of
21 byte
access all ,cgroup,pteam,thread all
pool_size Positive integer value Implementation
deﬁned
fallback default_mem_fb ,null_fb ,
abort_fb ,allocator_fbdefault_mem_fb
fb_data an allocator handle (none)
pinned true ,false false
partition environment ,nearest ,blocked ,
interleavedenvironment3
Thesync_hint trait describes the expected manner in which multiple threads may use the 4
allocator. The values and their description are: 5
contended : high contention is expected on the allocator; that is, many threads are expected to 6
request allocations simultaneously. 7
uncontended : low contention is expected on the allocator; that is, few threads are expected to 8
request allocations simultaneously. 9
serialized : only one thread at a time will request allocations with the allocator. Requesting 10
two allocations simultaneously when specifying serialized results in unspeciﬁed behavior. 11
private : the same thread will request allocations with the allocator every time. Requesting an 12
allocation from diﬀerent threads, simultaneously or not, when specifying private results in 13
unspeciﬁed behavior. 14
Allocated memory will be byte aligned to at least the value speciﬁed for the alignment trait of 15
the allocator. Some directives and API routines can specify additional requirements on alignment 16
beyond those described in this section. 17
Memory allocated by allocators with the access trait deﬁned to be allmust be accessible by all 18
threads in the device where the allocation was requested. Memory allocated by allocators with the 19
access trait deﬁned to be cgroup will be memory accessible by all threads in the same 20
CHAPTER 2. DIRECTIVES 153
contention group as the thread that requested the allocation. Attempts to access the memory 1
returned by an allocator with the access trait deﬁned to be cgroup from a thread that is not part 2
ofthesamecontentiongroupasthethreadthatallocatedthememoryresultinunspeciﬁedbehavior. 3
Memory allocated by allocators with the access trait deﬁned to be pteamwill be memory 4
accessible by all threads that bind to the same parallel region of the thread that requested the 5
allocation. Attempts to access the memory returned by an allocator with the access trait deﬁned 6
to bepteamfrom a thread that does not bind to the same parallel region as the thread that 7
allocated the memory result in unspeciﬁed behavior. Memory allocated by allocator with the 8
access trait deﬁned to be thread will be memory accessible by the threadthat requested the 9
allocation. Attempts to access the memory returned by an allocator with the access trait deﬁned 10
to bethread from a thread other than the one that allocated the memory result in unspeciﬁed 11
behavior. 12
The total amount of storage in bytes that an allocator can use is limited by the pool_size trait. 13
For allocators with the access trait deﬁned to be all, this limit refers to allocations from all 14
threads that access the allocator. For allocators with the access trait deﬁned to be cgroup, this 15
limitreferstoallocationsfromthreadsthataccesstheallocatorfromthesamecontentiongroup. For 16
allocators with the access trait deﬁned to be pteam, this limit refers to allocations from threads 17
that access the allocator from the same parallel team. For allocators with the access trait deﬁned 18
to bethread, this limit refers to allocations from each thread that access the allocator. Requests 19
that would result in using more storage than pool_size will not be fulﬁlled by the allocator. 20
Thefallback trait speciﬁes how the allocator behaves when it cannot fulﬁll an allocation 21
request. If the fallback trait is set to null_fb , the allocator returns the value zero if it fails to 22
allocate the memory. If the fallback trait is set to abort_fb , program execution will be 23
terminated if the allocation fails. If the fallback trait is set to allocator_fb then when an 24
allocation fails the request will be delegated to the allocator speciﬁed in the fb_data trait. If the 25
fallback trait is set to default_mem_fb then when an allocation fails another allocation will 26
be tried in the omp_default_mem_space memory space, which assumes all allocator traits to 27
be set to their default values except for fallback trait which will be set to null_fb . 28
Allocators with the pinned trait deﬁned to be trueensure that their allocations remain in the 29
same storage resource at the same location for their entire lifetime. 30
Thepartition trait describes the partitioning of allocated memory over the storage resources 31
represented by the memory space associated with the allocator. The partitioning will be done in 32
parts with a minimum size that is implementation deﬁned. The values are: 33
environment : the placement of allocated memory is determined by the execution 34
environment. 35
nearest : allocated memory is placed in the storage resource that is nearest to the thread that 36
requests the allocation. 37
blocked : allocated memory is partitioned into parts of approximately the same size with at 38
most one part per storage resource. 39
154OpenMP API – Version 5.0 November 2018
interleaved : allocated memory parts are distributed in a round-robin fashion across the 1
storage resources. 2
Table2.10showsthelistofpredeﬁnedmemoryallocatorsandtheirassociatedmemoryspaces. The 3
predeﬁned memory allocators have default values for their allocator traits unless otherwise 4
speciﬁed. 5
TABLE 2.10:Predeﬁned Allocators
Allocator name Associated memory space Non-default trait
values
omp_default_mem_alloc omp_default_mem_space (none)
omp_large_cap_mem_alloc omp_large_cap_mem_space (none)
omp_const_mem_alloc omp_const_mem_space (none)
omp_high_bw_mem_alloc omp_high_bw_mem_space (none)
omp_low_lat_mem_alloc omp_low_lat_mem_space (none)
omp_cgroup_mem_alloc Implementation deﬁned access:cgroup
omp_pteam_mem_alloc Implementation deﬁned access:pteam
omp_thread_mem_alloc Implementation deﬁned access:thread6
Fortran
If any operation of the base language causes a reallocation of an array that is allocated with a 7
memory allocator then that memory allocator will be used to release the current memory and to 8
allocate the new memory. 9
Fortran
Cross References 10
omp_init_allocator routine, see Section 3.7.2 on page 409. 11
omp_destroy_allocator routine, see Section 3.7.3 on page 410. 12
omp_set_default_allocator routine, see Section 3.7.4 on page 411. 13
omp_get_default_allocator routine, see Section 3.7.5 on page 412. 14
OMP_ALLOCATOR environment variable, see Section 6.21 on page 618. 15
CHAPTER 2. DIRECTIVES 155
2.11.3 allocate Directive 1
Summary 2
Theallocate directive speciﬁes how a set of variables are allocated. The allocate directive 3
is a declarative directive if it is not associated with an allocation statement. 4
Syntax 5
C / C++
The syntax of the allocate directive is as follows: 6
#pragma omp allocate( list)[clause] new-line 7
whereclauseis one of the following: 8
allocator( allocator ) 9
whereallocator is an expression of omp_allocator_handle_t type. 10
C / C++
Fortran
The syntax of the allocate directive is as follows: 11
!$omp allocate( list)[clause] 12
or 13
!$omp allocate [(list)] clause 14
[!$omp allocate( list)clause 15
[...]] 16
allocate statement 17
whereclauseis one of the following: 18
allocator( allocator ) 19
whereallocator is an integer expression of omp_allocator_handle_kind kind. 20
Fortran
156 OpenMP API – Version 5.0 November 2018
Description 1
If the directive is not associated with a statement, the storage for each list itemthat appears in the 2
directive will be provided by an allocation through a memory allocator. If no clause is speciﬁed 3
then the memory allocator speciﬁed by the def-allocator-var ICV will be used. If the allocator 4
clauseisspeciﬁed,thememoryallocatorspeciﬁedintheclausewillbeused. Theallocationofeach 5
list itemwill be byte aligned to at least the alignment required by the base language for the type of 6
thatlist item. 7
Thescopeofthisallocationisthatofthelistiteminthebaselanguage. Attheendofthescopefora 8
given list item the memory allocator used to allocate that list item deallocates the storage. 9
Fortran
If the directive is associated with an allocate statement , the same list items appearing in the 10
directivelistandthe allocatestatement listareallocatedwiththememoryallocatorofthedirective. 11
If no list items are speciﬁed then all variables listed in the allocate statement are allocated with the 12
memory allocator of the directive. 13
Fortran
For allocations that arise from this directive the null_fb value of the fallback allocator trait will 14
behave as if the abort_fb had been speciﬁed. 15
Restrictions 16
A variable that is part of another variable (as an array or structure element) cannot appear in an 17
allocate directive. 18
Theallocate directive must appear in the same scope as the declarations of each of its list 19
items and must follow all such declarations. 20
At most one allocator clause can appear on the allocate directive. 21
allocate directives that appear in a target region must specify an allocator clause 22
unless a requires directive with the dynamic_allocators clause is present in the same 23
compilation unit. 24
C / C++
If a list item has a static storage type, the allocator expression in the allocator clause must 25
be a constant expression that evaluates to one of the predeﬁned memory allocator values. 26
Afteralistitemhasbeenallocated,thescopethatcontainsthe allocate directivemustnotend 27
abnormallyotherthanthroughC++exceptions,suchasthroughacalltothe longjmp function. 28
C / C++
CHAPTER 2. DIRECTIVES 157
Fortran
List items speciﬁed in the allocate directive must not have the ALLOCATABLE attribute 1
unless the directive is associated with an allocate statement . 2
List itemsspeciﬁed in an allocate directive that isassociated with an allocate statement must 3
be variables that are allocated by the allocate statement . 4
Multipledirectivescanonlybeassociatedwithan allocatestatement iflistitemsarespeciﬁedon 5
eachallocate directive. 6
If a list item has the SAVEattribute, is a common block name, or is declared in the scope of a 7
module, then only predeﬁned memory allocator parameters can be used in the allocator 8
clause. 9
A type parameter inquiry cannot appear in an allocate directive. 10
Fortran
Cross References 11
def-allocator-var ICV, see Section 2.5.1 on page 64. 12
Memory allocators, see Section 2.11.2 on page 152. 13
omp_allocator_handle_t andomp_allocator_handle_kind , see Section 3.7.1 on 14
page 406. 15
2.11.4 allocate Clause 16
Summary 17
Theallocate clause speciﬁes the memory allocator to be used to obtain storage for private 18
variables of a directive. 19
Syntax 20
The syntax of the allocate clause is as follows: 21
allocate( [allocator :] list) 22
158 OpenMP API – Version 5.0 November 2018
C / C++
whereallocator is an expression of the omp_allocator_handle_t type. 1
C / C++
Fortran
whereallocator is an integer expression of the omp_allocator_handle_kind kind. 2
Fortran
Description 3
The storage for new list items that arise from list items that appear in the directive will be provided 4
through a memory allocator. If an allocator is speciﬁed in the clause, that allocator will be used for 5
allocations. Foralldirectivesexceptthe target directive,ifno allocator isspeciﬁedintheclause 6
then the memory allocator that is speciﬁed by the def-allocator-var ICV will be used for the list 7
items that are speciﬁed in the allocate clause. The allocation of each list itemwill be byte 8
aligned to at least the alignment required by the base language for the type of that list item. 9
For allocations that arise from this clause the null_fb value of the fallback allocator trait will 10
behave as if the abort_fb had been speciﬁed. 11
Restrictions 12
For any list item that is speciﬁed in the allocate clause on a directive, a data-sharing attribute 13
clause that may create a private copy of that list item must be speciﬁed on the same directive. 14
Fortask,taskloop ortarget directives, allocation requests to memory allocators with the 15
traitaccess set to thread result in unspeciﬁed behavior. 16
allocate clauses that appear on a target construct or on constructs in a target region 17
must specify an allocator expression unless a requires directive with the 18
dynamic_allocators clause is present in the same compilation unit. 19
Cross References 20
def-allocator-var ICV, see Section 2.5.1 on page 64. 21
Memory allocators, see Section 2.11.2 on page 152. 22
omp_allocator_handle_t andomp_allocator_handle_kind , see Section 3.7.1 on 23
page 406. 24
CHAPTER 2. DIRECTIVES 159
2.12 Device Directives1
2.12.1 Device Initialization2
Execution Model Events 3
Thedevice-initialize eventoccursinathreadthatencounterstheﬁrst target,target data ,or 4
target enter data construct or a device memory routine that is associated with a particular 5
target device after the thread initiates initialization of OpenMP on the device and the device’s 6
OpenMP initialization, which may include device-side tool initialization, completes. 7
Thedevice-load event for a code block for a target device occurs in some thread before any thread 8
executes code from that code block on that target device. 9
Thedevice-unload event for a target device occurs in some thread whenever a code block is 10
unloaded from the device. 11
Thedevice-ﬁnalize event for a target device that has been initialized occurs in some thread before 12
an OpenMP implementation shuts down. 13
Tool Callbacks 14
A thread dispatches a registered ompt_callback_device_initialize callback for each 15
occurrence of a device-initialize event in that thread. This callback has type signature 16
ompt_callback_device_initialize_t . 17
A thread dispatches a registered ompt_callback_device_load callback for each occurrence 18
of adevice-load event in that thread. This callback has type signature 19
ompt_callback_device_load_t . 20
A thread dispatches a registered ompt_callback_device_unload callback for each 21
occurrence of a device-unload event in that thread. This callback has type signature 22
ompt_callback_device_unload_t . 23
A thread dispatches a registered ompt_callback_device_finalize callback for each 24
occurrence of a device-ﬁnalize event in that thread. This callback has type signature 25
ompt_callback_device_finalize_t . 26
Restrictions 27
No thread may oﬄoad execution of an OpenMP construct to a device until a dispatched 28
ompt_callback_device_initialize callback completes. 29
No thread may oﬄoad execution of an OpenMP construct to a device after a dispatched 30
ompt_callback_device_finalize callback occurs. 31
160 OpenMP API – Version 5.0 November 2018
Cross References 1
ompt_callback_device_load_t , see Section 4.5.2.21 on page 484. 2
ompt_callback_device_unload_t , see Section 4.5.2.22 on page 486. 3
ompt_callback_device_initialize_t , see Section 4.5.2.19 on page 482. 4
ompt_callback_device_finalize_t , see Section 4.5.2.20 on page 484. 5
2.12.2 target data Construct 6
Summary 7
Map variables to a device data environment for the extent of the region. 8
Syntax 9
C / C++
The syntax of the target data construct is as follows: 10
#pragma omp target data clause[ [ [ ,] clause] ... ] new-line 11
structured-block 12
whereclauseis one of the following: 13
if([target data : ] scalar-expression ) 14
device( integer-expression ) 15
map([[map-type-modiﬁer[ ,] [map-type-modiﬁer[ ,] ...] map-type :] locator-list ) 16
use_device_ptr( ptr-list ) 17
use_device_addr( list) 18
C / C++
Fortran
The syntax of the target data construct is as follows: 19
!$omp target data clause[ [ [ ,] clause] ... ] 20
structured-block 21
!$omp end target data 22
CHAPTER 2. DIRECTIVES 161
whereclauseis one of the following: 1
if([target data : ] scalar-logical-expression ) 2
device( scalar-integer-expression ) 3
map([[map-type-modiﬁer[ ,] [map-type-modiﬁer[ ,] ...] map-type :] locator-list ) 4
use_device_ptr( ptr-list ) 5
use_device_addr( list) 6
Fortran
Binding 7
The binding task set for a target data region is the generating task. The target data region 8
binds to the region of the generating task. 9
Description 10
When a target data construct is encountered, the encountering task executes the region. If 11
there is no device clause, the default device is determined by the default-device-var ICV. When 12
anifclause is present and the ifclause expression evaluates to false, the device is the host. 13
Variables are mapped for the extent of the region, according to any data-mapping attribute clauses, 14
from the data environment of the encountering task to the device data environment. 15
Pointers that appear in a use_device_ptr clause are privatized and the device pointers to the 16
corresponding list items in the device data environment are assigned into the private versions. 17
List items that appear in a use_device_addr clause have the address of the corresponding 18
objectinthedevicedataenvironmentinsidetheconstruct. Forobjects,anyreferencetothevalueof 19
the object will be to the corresponding object on the device, while references to the address will 20
result in a valid device address that points to that object. Array sections privatize the base of the 21
array section and assign the private copy to the address of the corresponding array section in the 22
device data environment. 23
If one or more of the use_device_ptr oruse_device_addr clauses and one or more map 24
clauses are present on the same construct, the address conversions of use_device_addr and 25
use_device_ptr clauses will occur as if performed after all variables are mapped according to 26
those mapclauses. 27
Execution Model Events 28
The events associated with entering a target data region are the same events as associated with a 29
target enter data construct, described in Section 2.12.3 on page 164. 30
The events associated with exiting a target data region are the same events as associated with a 31
target exit data construct, described in Section 2.12.4 on page 166. 32
162 OpenMP API – Version 5.0 November 2018
Tool Callbacks 1
The tool callbacks dispatched when entering a target data region are the same as the tool callbacks 2
dispatched when encountering a target enter data construct, described in Section 2.12.3 on 3
page 164. 4
The tool callbacks dispatched when exiting a target data region are the same as the tool callbacks 5
dispatched when encountering a target exit data construct, described in Section 2.12.4 on page 166. 6
Restrictions 7
A program must not depend on any ordering of the evaluations of the clauses of the 8
target data directive, except as explicitly stated for mapclauses relative to 9
use_device_ptr anduse_device_addr clauses,oronanysideeﬀectsoftheevaluations 10
of the clauses. 11
At most one device clause can appear on the directive. The device clause expression must 12
evaluate to a non-negative integer value less than the value of omp_get_num_devices() or 13
to the value of omp_get_initial_device() . 14
At most one ifclause can appear on the directive. 15
Amap-type in amapclause must be to,from,tofrom oralloc. 16
At least one map,use_device_addr oruse_device_ptr clause must appear on the 17
directive. 18
A list item in a use_device_ptr clause must hold the address of an object that has a 19
corresponding list item in the device data environment. 20
A list item in a use_device_addr clause must have a corresponding list item in the device 21
data environment. 22
A list item that speciﬁes a given variable may not appear in more than one use_device_ptr 23
clause. 24
Areferencetoalistitemina use_device_addr clausemustbetotheaddressofthelistitem. 25
Cross References 26
default-device-var , see Section 2.5 on page 63. 27
ifClause, see Section 2.15 on page 220. 28
mapclause, see Section 2.19.7.1 on page 315. 29
omp_get_num_devices routine, see Section 3.2.36 on page 371. 30
ompt_callback_target_t , see Section 4.5.2.26 on page 490. 31
CHAPTER 2. DIRECTIVES 163
2.12.3 target enter data Construct 1
Summary 2
Thetarget enter data directive speciﬁes that variables are mapped to a device data 3
environment. The target enter data directive is a stand-alone directive. 4
Syntax 5
C / C++
The syntax of the target enter data construct is as follows: 6
#pragma omp target enter data [ clause[ [ ,] clause]...] new-line 7
whereclauseis one of the following: 8
if([target enter data : ] scalar-expression ) 9
device( integer-expression ) 10
map([map-type-modiﬁer[ ,] [map-type-modiﬁer[ ,] ...] map-type :locator-list ) 11
depend( [depend-modiﬁer ,] dependence-type :locator-list ) 12
nowait 13
C / C++
Fortran
The syntax of the target enter data is as follows: 14
!$omp target enter data [ clause[ [ ,] clause]...] 15
where clause is one of the following: 16
if([target enter data : ] scalar-logical-expression ) 17
device( scalar-integer-expression ) 18
map([map-type-modiﬁer[ ,] [map-type-modiﬁer[ ,] ...] map-type :locator-list ) 19
depend( [depend-modiﬁer ,] dependence-type :locator-list ) 20
nowait 21
Fortran
Binding 22
The binding task set for a target enter data region is the generating task, which is the target 23
taskgenerated by the target enter data construct. The target enter data region binds 24
to the corresponding target task region. 25
164 OpenMP API – Version 5.0 November 2018
Description 1
When a target enter data construct is encountered, the list items are mapped to the device 2
data environment according to the mapclause semantics. 3
Thetarget enter data construct is a task generating construct. The generated task is a target 4
task. The generated task region encloses the target enter data region. 5
All clauses are evaluated when the target enter data construct is encountered. The data 6
environment of the target task is created according to the data-sharing attribute clauses on the 7
target enter data construct, per-data environment ICVs, and any default data-sharing 8
attribute rules that apply to the target enter data construct. A variable that is mapped in the 9
target enter data construct has a default data-sharing attribute of shared in the data 10
environment of the target task . 11
Assignment operations associated with mapping a variable (see Section 2.19.7.1 on page 315) 12
occur when the target task executes. 13
If the nowait clause is present, execution of the target task may be deferred. If the nowait 14
clause is not present, the target task is an included task. 15
If adepend clause is present, it is associated with the target task . 16
If nodevice clause is present, the default device is determined by the default-device-var ICV. 17
Whenan ifclauseispresentandthe ifclauseexpressionevaluatesto false,thedeviceisthehost. 18
Execution Model Events 19
Events associated with a target task are the same as for the taskconstruct deﬁned in 20
Section 2.10.1 on page 135. 21
Thetarget-enter-data-begin event occurs when a thread enters a target enter data region. 22
Thetarget-enter-data-end event occurs when a thread exits a target enter data region. 23
Tool Callbacks 24
Callbacks associated with events for target tasks are the same as for the taskconstruct deﬁned in 25
Section 2.10.1 on page 135; (ﬂags& ompt_task_target) always evaluates to truein the 26
dispatched callback. 27
A thread dispatches a registered ompt_callback_target callback with 28
ompt_scope_begin as itsendpoint argument and ompt_target_enter_data as itskind 29
argument for each occurrence of a target-enter-data-begin event in that thread in the context of the 30
target task on the host. Similarly, a thread dispatches a registered ompt_callback_target 31
callback with ompt_scope_end as itsendpoint argument and ompt_target_enter_data 32
as itskindargument for each occurrence of a target-enter-data-end event in that thread in the 33
CHAPTER 2. DIRECTIVES 165
context of the target task on the host. These callbacks have type signature 1
ompt_callback_target_t . 2
Restrictions 3
A program must not depend on any ordering of the evaluations of the clauses of the 4
target enter data directive, or on any side eﬀects of the evaluations of the clauses. 5
At least one mapclause must appear on the directive. 6
At most one device clause can appear on the directive. The device clause expression must 7
evaluate to a non-negative integer value less than the value of omp_get_num_devices() or 8
to the value of omp_get_initial_device() . 9
At most one ifclause can appear on the directive. 10
Amap-type must be speciﬁed in all mapclauses and must be either tooralloc. 11
At most one nowait clause can appear on the directive. 12
Cross References 13
default-device-var , see Section 2.5.1 on page 64. 14
task, see Section 2.10.1 on page 135. 15
task scheduling constraints , see Section 2.10.6 on page 149. 16
target data , see Section 2.12.2 on page 161. 17
target exit data , see Section 2.12.4 on page 166. 18
ifClause, see Section 2.15 on page 220. 19
mapclause, see Section 2.19.7.1 on page 315. 20
omp_get_num_devices routine, see Section 3.2.36 on page 371. 21
ompt_callback_target_t , see Section 4.5.2.26 on page 490. 22
2.12.4 target exit data Construct 23
Summary 24
Thetarget exit data directive speciﬁes that list items are unmapped from a device data 25
environment. The target exit data directive is a stand-alone directive. 26
166 OpenMP API – Version 5.0 November 2018
Syntax 1
C / C++
The syntax of the target exit data construct is as follows: 2
#pragma omp target exit data [ clause[ [ ,] clause]...] new-line 3
whereclauseis one of the following: 4
if([target exit data : ] scalar-expression ) 5
device( integer-expression ) 6
map([map-type-modiﬁer[ ,] [map-type-modiﬁer[ ,] ...] map-type :locator-list ) 7
depend( [depend-modiﬁer ,] dependence-type :locator-list ) 8
nowait 9
C / C++
Fortran
The syntax of the target exit data is as follows: 10
!$omp target exit data [ clause[ [ ,] clause]...] 11
where clause is one of the following: 12
if([target exit data : ] scalar-logical-expression ) 13
device( scalar-integer-expression ) 14
map([map-type-modiﬁer[ ,] [map-type-modiﬁer[ ,] ...] map-type :locator-list ) 15
depend( [depend-modiﬁer ,] dependence-type :locator-list ) 16
nowait 17
Fortran
Binding 18
The binding task set for a target exit data region is the generating task, which is the target 19
taskgenerated by the target exit data construct. The target exit data region binds to 20
the corresponding target task region. 21
CHAPTER 2. DIRECTIVES 167
Description 1
When a target exit data construct is encountered, the list items in the mapclauses are 2
unmapped from the device data environment according to the mapclause semantics. 3
Thetarget exit data construct is a task generating construct. The generated task is a target 4
task. The generated task region encloses the target exit data region. 5
All clauses are evaluated when the target exit data construct is encountered. The data 6
environment of the target task is created according to the data-sharing attribute clauses on the 7
target exit data construct, per-data environment ICVs, and any default data-sharing attribute 8
rules that apply to the target exit data construct. A variable that is mapped in the 9
target exit data construct has a default data-sharing attribute of shared in the data 10
environment of the target task . 11
Assignment operations associated with mapping a variable (see Section 2.19.7.1 on page 315) 12
occur when the target task executes. 13
If the nowait clause is present, execution of the target task may be deferred. If the nowait 14
clause is not present, the target task is an included task. 15
If adepend clause is present, it is associated with the target task . 16
If nodevice clause is present, the default device is determined by the default-device-var ICV. 17
Whenan ifclauseispresentandthe ifclauseexpressionevaluatesto false,thedeviceisthehost. 18
Execution Model Events 19
Events associated with a target task are the same as for the taskconstruct deﬁned in 20
Section 2.10.1 on page 135. 21
Thetarget-exit-data-begin event occurs when a thread enters a target exit data region. 22
Thetarget-exit-data-end event occurs when a thread exits a target exit data region. 23
Tool Callbacks 24
Callbacks associated with events for target tasks are the same as for the taskconstruct deﬁned in 25
Section 2.10.1 on page 135; (ﬂags& ompt_task_target) always evaluates to truein the 26
dispatched callback. 27
A thread dispatches a registered ompt_callback_target callback with 28
ompt_scope_begin as itsendpoint argument and ompt_target_exit_data as itskind 29
argument for each occurrence of a target-exit-data-begin event in that thread in the context of the 30
target task on the host. Similarly, a thread dispatches a registered ompt_callback_target 31
callback with ompt_scope_end as itsendpoint argument and ompt_target_exit_data as 32
itskindargumentforeachoccurrenceofa target-exit-data-end eventinthatthreadinthecontextof 33
the target task on the host. These callbacks have type signature ompt_callback_target_t . 34
168OpenMP API – Version 5.0 November 2018
Restrictions 1
A program must not depend on any ordering of the evaluations of the clauses of the 2
target exit data directive, or on any side eﬀects of the evaluations of the clauses. 3
At least one mapclause must appear on the directive. 4
At most one device clause can appear on the directive. The device clause expression must 5
evaluate to a non-negative integer value less than the value of omp_get_num_devices() or 6
to the value of omp_get_initial_device() . 7
At most one ifclause can appear on the directive. 8
Amap-type must be speciﬁed in all mapclauses and must be either from,release , or 9
delete. 10
At most one nowait clause can appear on the directive. 11
Cross References 12
default-device-var , see Section 2.5.1 on page 64. 13
task, see Section 2.10.1 on page 135. 14
task scheduling constraints , see Section 2.10.6 on page 149. 15
target data , see Section 2.12.2 on page 161. 16
target enter data , see Section 2.12.3 on page 164. 17
ifClause, see Section 2.15 on page 220. 18
mapclause, see Section 2.19.7.1 on page 315. 19
omp_get_num_devices routine, see Section 3.2.36 on page 371. 20
ompt_callback_target_t , see Section 4.5.2.26 on page 490. 21
CHAPTER 2. DIRECTIVES 169
2.12.5 target Construct 1
Summary 2
Map variables to a device data environment and execute the construct on that device. 3
Syntax 4
C / C++
The syntax of the target construct is as follows: 5
#pragma omp target [clause[ [ ,] clause] ... ] new-line 6
structured-block 7
whereclauseis one of the following: 8
if([target : ] scalar-expression ) 9
device( [ device-modiﬁer :] integer-expression ) 10
private( list) 11
firstprivate( list) 12
in_reduction( reduction-identiﬁer :list) 13
map([[map-type-modiﬁer[ ,] [map-type-modiﬁer[ ,] ...] map-type :] locator-list ) 14
is_device_ptr( list) 15
defaultmap( implicit-behavior[:variable-category] ) 16
nowait 17
depend( [depend-modiﬁer ,] dependence-type :locator-list ) 18
allocate([ [allocator :] list) 19
uses_allocators( allocator[ (allocator-traits-array )] 20
[,allocator[ (allocator-traits-array )] ...]) 21
and where device-modiﬁer is one of the following: 22
ancestor 23
device_num 24
and where allocator is an identiﬁer of omp_allocator_handle_t type and 25
allocator-traits-array is an identiﬁer of const omp_alloctrait_t *type. 26
C / C++
170 OpenMP API – Version 5.0 November 2018
Fortran
The syntax of the target construct is as follows: 1
!$omp target [clause[ [ ,] clause] ... ] 2
structured-block 3
!$omp end target 4
whereclauseis one of the following: 5
if([target : ] scalar-logical-expression ) 6
device( [ device-modiﬁer :] scalar-integer-expression ) 7
private( list) 8
firstprivate( list) 9
in_reduction( reduction-identiﬁer :list) 10
map([[map-type-modiﬁer[ ,] [map-type-modiﬁer[ ,] ...] map-type :] locator-list ) 11
is_device_ptr( list) 12
defaultmap( implicit-behavior[:variable-category] ) 13
nowait 14
depend( [depend-modiﬁer ,] dependence-type :locator-list ) 15
allocate( [allocator :]list) 16
uses_allocators( allocator[ (allocator-traits-array )] 17
[,allocator[ (allocator-traits-array )] ...]) 18
and where device-modiﬁer is one of the following: 19
ancestor 20
device_num 21
and where allocator is an integer expression of omp_allocator_handle_kind kindand 22
allocator-traits-array is an array of type(omp_alloctrait) type. 23
Fortran
Binding 24
The binding task set for a target region is the generating task, which is the target task generated 25
by the target construct. The target region binds to the corresponding target task region. 26
CHAPTER 2. DIRECTIVES 171
Description 1
Thetarget construct provides a superset of the functionality provided by the target data 2
directive, except for the use_device_ptr anduse_device_addr clauses. 3
The functionality added to the target directive is the inclusion of an executable region to be 4
executed by a device. That is, the target directive is an executable directive. 5
Thetarget construct is a task generating construct. The generated task is a target task . The 6
generated task region encloses the target region. 7
All clauses are evaluated when the target construct is encountered. The data environment of the 8
target task is created according to the data-sharing attribute clauses on the target construct, 9
per-data environment ICVs, and any default data-sharing attribute rules that apply to the target 10
construct. If a variable or part of a variable is mapped by the target construct and does not 11
appear as a list item in an in_reduction clause on the construct, the variable has a default 12
data-sharing attribute of shared in the data environment of the target task . 13
Assignment operations associated with mapping a variable (see Section 2.19.7.1 on page 315) 14
occur when the target task executes. 15
If adevice clause in which the device_num device-modiﬁer appears is present on the 16
construct, the device clause expression speciﬁes the device number of the target device. If 17
device-modiﬁer does not appear in the clause, the behavior of the clause is as if device-modiﬁer is 18
device_num . 19
If adevice clause in which the ancestor device-modiﬁer appears is present on the target 20
constructandthe device clauseexpressionevaluatesto1,executionofthe target regionoccurs 21
on the parent device of the enclosing target region. If the target construct is not encountered 22
in atarget region, the current device is treated as the parent device. The encountering thread 23
waits for completion of the target region on the parent device before resuming. For any list item 24
thatappearsina mapclauseonthesameconstruct,ifthecorrespondinglistitemexistsinthedevice 25
data environment of the parent device, it is treated as if it has a reference count of positive inﬁnity. 26
If the nowait clause is present, execution of the target task may be deferred. If the nowait 27
clause is not present, the target task is an included task. 28
If adepend clause is present, it is associated with the target task . 29
When an ifclause is present and the ifclause expression evaluates to false, thetarget region 30
is executed by the host device in the host data environment. 31
Theis_device_ptr clause is used to indicate that a list item is a device pointer already in the 32
device data environment and that it should be used directly. Support for device pointers created 33
outside of OpenMP, speciﬁcally outside of the omp_target_alloc routine and the 34
use_device_ptr clause, is implementation deﬁned. 35
172 OpenMP API – Version 5.0 November 2018
If a function (C, C++, Fortran) or subroutine (Fortran) is referenced in a target construct then 1
that function or subroutine is treated as if its name had appeared in a toclause on a 2
declare target directive. 3
Each memory allocator speciﬁed in the uses_allocators clause will be made available in the 4
target region. For each non-predeﬁned allocator that is speciﬁed, a new allocator handle will be 5
associated with an allocator that is created with the speciﬁed traitsas if by a call to 6
omp_init_allocator at the beginning of the target region. Each non-predeﬁned allocator 7
willbedestroyedasifbyacallto omp_destroy_allocator attheendofthe target region. 8
C / C++
If a list item in a mapclause has a base pointer and it is a scalar variable with a predetermined 9
data-sharing attribute of ﬁrstprivate (see Section 2.19.1.1 on page 270), then on entry to the 10
target region: 11
If the list item is not a zero-length array section, the corresponding private variable is initialized 12
such that the corresponding list item in the device data environment can be accessed through the 13
pointer in the target region. 14
Ifthelistitemisazero-lengtharraysection,thecorrespondingprivatevariableisinitializedsuch 15
that the corresponding storage location of the array section can be referenced through the pointer 16
in the target region. If the corresponding storage location is not present in the device data 17
environment, the corresponding private variable is initialized to NULL. 18
C / C++
Execution Model Events 19
Events associated with a target task are the same as for the taskconstruct deﬁned in 20
Section 2.10.1 on page 135. 21
Events associated with the initial task that executes the target region are deﬁned in 22
Section 2.10.5 on page 148. 23
Thetarget-begin event occurs when a thread enters a target region. 24
Thetarget-end event occurs when a thread exits a target region. 25
Thetarget-submit event occurs prior to creating an initial task on a target device for a target 26
region. 27
CHAPTER 2. DIRECTIVES 173
Tool Callbacks 1
Callbacks associated with events for target tasks are the same as for the taskconstruct deﬁned in 2
Section 2.10.1 on page 135; (ﬂags& ompt_task_target) always evaluates to truein the 3
dispatched callback. 4
A thread dispatches a registered ompt_callback_target callback with 5
ompt_scope_begin as itsendpoint argument and ompt_target as itskindargument for 6
each occurrence of a target-begin event in that thread in the context of the target task on the host. 7
Similarly, a thread dispatches a registered ompt_callback_target callback with 8
ompt_scope_end as itsendpoint argument and ompt_target as itskindargument for each 9
occurrence of a target-end event in that thread in the context of the target task on the host. These 10
callbacks have type signature ompt_callback_target_t . 11
A thread dispatches a registered ompt_callback_target_submit callback for each 12
occurrence of a target-submit event in that thread. The callback has type signature 13
ompt_callback_target_submit_t . 14
Restrictions 15
If atarget update ,target data ,target enter data , ortarget exit data 16
construct is encountered during execution of a target region, the behavior is unspeciﬁed. 17
The result of an omp_set_default_device ,omp_get_default_device , or 18
omp_get_num_devices routine called within a target region is unspeciﬁed. 19
The eﬀect of an access to a threadprivate variable in a target region is unspeciﬁed. 20
If a list item in a mapclause is a structure element, any other element of that structure that is 21
referenced in the target construct must also appear as a list item in a mapclause. 22
A variable referenced in a target region but not the target construct that is not declared in 23
thetarget region must appear in a declare target directive. 24
At most one defaultmap clause for each category can appear on the directive. 25
At most one nowait clause can appear on the directive. 26
Amap-type in amapclause must be to,from,tofrom oralloc. 27
A list item that appears in an is_device_ptr clause must be a valid device pointer in the 28
device data environment. 29
At most one device clause can appear on the directive. The device clause expression must 30
evaluate to a non-negative integer value less than the value of omp_get_num_devices() or 31
to the value of omp_get_initial_device() . 32
If adevice clause in which the ancestor device-modiﬁer appears is present on the 33
construct, then the following restrictions apply: 34
174 OpenMP API – Version 5.0 November 2018
–Arequires directive with the reverse_offload clause must be speciﬁed; 1
–Thedevice clause expression must evaluate to 1; 2
–Only the device,firstprivate ,private ,defaultmap , andmapclauses may 3
appear on the construct; 4
–No OpenMP constructs or calls to OpenMP API runtime routines are allowed inside the 5
corresponding target region. 6
Memory allocators that do not appear in a uses_allocators clause cannot appear as an 7
allocator in an allocate clause or be used in the target region unless a requires 8
directive with the dynamic_allocators clause is present in the same compilation unit. 9
Memory allocators that appear in a uses_allocators clause cannot appear in other 10
data-sharing attribute clauses or data-mapping attribute clauses in the same construct. 11
Predeﬁned allocators appearing in a uses_allocators clause cannot have traitsspeciﬁed. 12
Non-predeﬁnedallocatorsappearingina uses_allocators clausemusthave traitsspeciﬁed. 13
Arrays that contain allocator traits that appear in a uses_allocators clause must be 14
constant arrays, have constant values and be deﬁned in the same scope as the construct in which 15
the clause appears. 16
Any IEEE ﬂoating-point exception status ﬂag, halting mode, or rounding mode set prior to a 17
target region is unspeciﬁed in the region. 18
Any IEEE ﬂoating-point exception status ﬂag, halting mode, or rounding mode set in a target 19
region is unspeciﬁed upon exiting the region. 20
C / C++
An attached pointer must not be modiﬁed in a target region. 21
C / C++
C
A list item that appears in an is_device_ptr clause must have a type of pointer or array. 22
C
C++
A list item that appears in an is_device_ptr clause must have a type of pointer, array, 23
reference to pointer or reference to array. 24
The eﬀect of invoking a virtual member function of an object on a device other than the device 25
on which the object was constructed is implementation deﬁned. 26
Athrowexecuted inside a target region must cause execution to resume within the same 27
target region, and the same thread that threw the exception must catch it. 28
C++
CHAPTER 2. DIRECTIVES 175
Fortran
An attached pointer that is associated with a given pointer target must not become associated 1
with a diﬀerent pointer target in a target region. 2
A list item that appears in an is_device_ptr clause must be a dummy argument that does 3
not have the ALLOCATABLE ,POINTER orVALUEattribute. 4
If a list item in a mapclause is an array section, and the array section is derived from a variable 5
with a POINTER orALLOCATABLE attribute then the behavior is unspeciﬁed if the 6
corresponding list item’s variable is modiﬁed in the region. 7
Fortran
Cross References 8
default-device-var , see Section 2.5 on page 63. 9
taskconstruct, see Section 2.10.1 on page 135. 10
taskscheduling constraints, see Section 2.10.6 on page 149 11
Memory allocators, see Section 2.11.2 on page 152. 12
target data construct, see Section 2.12.2 on page 161. 13
ifClause, see Section 2.15 on page 220. 14
private andfirstprivate clauses, see Section 2.19.4 on page 282. 15
Data-Mapping Attribute Rules and Clauses, see Section 2.19.7 on page 314. 16
omp_get_num_devices routine, see Section 3.2.36 on page 371. 17
omp_alloctrait_t andomp_alloctrait types, see Section 3.7.1 on page 406. 18
omp_set_default_allocator routine, see Section 3.7.4 on page 411. 19
omp_get_default_allocator routine, see Section 3.7.5 on page 412. 20
ompt_callback_target_t , see Section 4.5.2.26 on page 490. 21
ompt_callback_target_submit_t , Section 4.5.2.28 on page 494. 22
2.12.6 target update Construct 23
Summary 24
Thetarget update directive makes the corresponding list items in the device data environment 25
consistent with their original list items, according to the speciﬁed motion clauses. The 26
target update construct is a stand-alone directive. 27
176 OpenMP API – Version 5.0 November 2018
Syntax 1
C / C++
The syntax of the target update construct is as follows: 2
#pragma omp target update clause[ [ [ ,] clause] ... ] new-line 3
whereclauseis eithermotion-clause or one of the following: 4
if([target update : ] scalar-expression ) 5
device( integer-expression ) 6
nowait 7
depend( [depend-modiﬁer ,] dependence-type :locator-list ) 8
andmotion-clause is one of the following: 9
to([mapper( mapper-identiﬁer ):]locator-list ) 10
from([mapper( mapper-identiﬁer ):]locator-list ) 11
C / C++
Fortran
The syntax of the target update construct is as follows: 12
!$omp target update clause[ [ [ ,] clause] ... ] 13
whereclauseis eithermotion-clause or one of the following: 14
if([target update : ] scalar-logical-expression ) 15
device( scalar-integer-expression ) 16
nowait 17
depend( [depend-modiﬁer ,] dependence-type :locator-list ) 18
andmotion-clause is one of the following: 19
to([mapper( mapper-identiﬁer ):]locator-list ) 20
from([mapper( mapper-identiﬁer ):]locator-list ) 21
Fortran
Binding 22
The binding task set for a target update region is the generating task, which is the target task 23
generated by the target update construct. The target update region binds to the 24
corresponding target task region. 25
CHAPTER 2. DIRECTIVES 177
Description 1
Foreachlistitemina toorfromclausethereisacorrespondinglistitemandanoriginallistitem. 2
If the corresponding list item is not present in the device data environment then no assignment 3
occurs to or from the original list item. Otherwise, each corresponding list item in the device data 4
environment has an original list item in the current task’s data environment. If a mapper() 5
modiﬁer appears in a toclause, each list item is replaced with the list items that the given mapper 6
speciﬁes are to be mapped with a toortofrom map-type. If a mapper() modiﬁer appears in a 7
fromclause, each list item is replaced with the list items that the given mapper speciﬁes are to be 8
mapped with a fromortofrom map-type. 9
For each list item in a fromor atoclause: 10
For each part of the list item that is an attached pointer: 11
C / C++
–On exit from the region that part of the original list item will have the value it had on entry to 12
the region; 13
–On exit from the region that part of the corresponding list item will have the value it had on 14
entry to the region; 15
C / C++
Fortran
–On exit from the region that part of the original list item, if associated, will be associated with 16
the same pointer target with which it was associated on entry to the region; 17
–On exit from the region that part of the corresponding list item, if associated, will be 18
associated with the same pointer target with which it was associated on entry to the region. 19
Fortran
For each part of the list item that is not an attached pointer: 20
–If the clause is from, the value of that part of the corresponding list item is assigned to that 21
part of the original list item; 22
–If the clause is to, the value of that part of the original list item is assigned to that part of the 23
corresponding list item. 24
To avoid data races: 25
–Concurrent reads or updates of any part of the original list item must be synchronized with the 26
update of the original list item that occurs as a result of the fromclause; 27
–Concurrent reads or updates of any part of the corresponding list item must be synchronized 28
with the update of the corresponding list item that occurs as a result of the toclause. 29
C / C++
The list items that appear in the toorfromclauses may use shape-operators. 30
C / C++
178 OpenMP API – Version 5.0 November 2018
The list items that appear in the toorfromclauses may include array sections with stride 1
expressions. 2
Thetarget update construct is a task generating construct. The generated task is a target task . 3
The generated task region encloses the target update region. 4
All clauses are evaluated when the target update construct is encountered. The data 5
environment of the target task is created according to the data-sharing attribute clauses on the 6
target update construct, per-data environment ICVs, and any default data-sharing attribute 7
rules that apply to the target update construct. A variable that is mapped in the 8
target update construct has a default data-sharing attribute of shared in the data 9
environment of the target task . 10
Assignment operations associated with mapping a variable (see Section 2.19.7.1 on page 315) 11
occur when the target task executes. 12
If the nowait clause is present, execution of the target task may be deferred. If the nowait 13
clause is not present, the target task is an included task. 14
If adepend clause is present, it is associated with the target task . 15
The device is speciﬁed in the device clause. If there is no device clause, the device is 16
determined by the default-device-var ICV. When an ifclause is present and the ifclause 17
expression evaluates to falsethen no assignments occur. 18
Execution Model Events 19
Events associated with a target task are the same as for the taskconstruct deﬁned in 20
Section 2.10.1 on page 135. 21
Thetarget-update-begin event occurs when a thread enters a target update region. 22
Thetarget-update-end event occurs when a thread exits a target update region. 23
Tool Callbacks 24
Callbacks associated with events for target tasks are the same as for the taskconstruct deﬁned in 25
Section 2.10.1 on page 135; (ﬂags& ompt_task_target) always evaluates to truein the 26
dispatched callback. 27
A thread dispatches a registered ompt_callback_target callback with 28
ompt_scope_begin as itsendpoint argument and ompt_target_update as itskind 29
argument for each occurrence of a target-update-begin event in that thread in the context of the 30
target task on the host. Similarly, a thread dispatches a registered ompt_callback_target 31
callback with ompt_scope_end as itsendpoint argument and ompt_target_update as its 32
kindargument for each occurrence of a target-update-end event in that thread in the context of the 33
target task on the host. These callbacks have type signature ompt_callback_target_t . 34
CHAPTER 2. DIRECTIVES 179
Restrictions 1
A program must not depend on any ordering of the evaluations of the clauses of the 2
target update directive, or on any side eﬀects of the evaluations of the clauses. 3
At least one motion-clause must be speciﬁed. 4
A list item can only appear in a toorfromclause, but not both. 5
A list item in a toorfromclause must have a mappable type. 6
At most one device clause can appear on the directive. The device clause expression must 7
evaluate to a non-negative integer value less than the value of omp_get_num_devices() or 8
to the value of omp_get_initial_device() . 9
At most one ifclause can appear on the directive. 10
At most one nowait clause can appear on the directive. 11
Cross References 12
Array shaping, Section 2.1.4 on page 43 13
Array sections, Section 2.1.5 on page 44 14
default-device-var , see Section 2.5 on page 63. 15
taskconstruct, see Section 2.10.1 on page 135. 16
taskscheduling constraints, see Section 2.10.6 on page 149 17
target data , see Section 2.12.2 on page 161. 18
ifClause, see Section 2.15 on page 220. 19
omp_get_num_devices routine, see Section 3.2.36 on page 371. 20
ompt_callback_task_create_t , see Section 4.5.2.7 on page 467. 21
ompt_callback_target_t , see Section 4.5.2.26 on page 490. 22
2.12.7 declare target Directive 23
Summary 24
Thedeclare target directive speciﬁes that variables, functions (C, C++ and Fortran), and 25
subroutines (Fortran) are mapped to a device. The declare target directive is a declarative 26
directive. 27
180 OpenMP API – Version 5.0 November 2018
Syntax 1
C / C++
The syntax of the declare target directive takes either of the following forms: 2
#pragma omp declare target new-line 3
declaration-deﬁnition-seq 4
#pragma omp end declare target new-line 5
or 6
#pragma omp declare target ( extended-list )new-line 7
or 8
#pragma omp declare target clause[ [ ,] clause ... ] new-line 9
whereclauseis one of the following: 10
to(extended-list ) 11
link(list) 12
device_type(host | nohost | any) 13
C / C++
Fortran
The syntax of the declare target directive is as follows: 14
!$omp declare target ( extended-list ) 15
or 16
!$omp declare target [clause[ [ ,] clause] ... ] 17
whereclauseis one of the following: 18
to(extended-list ) 19
link(list) 20
device_type(host | nohost | any) 21
Fortran
CHAPTER 2. DIRECTIVES 181
Description 1
Thedeclare target directive ensures that procedures and global variables can be executed or 2
accessed on a device. Variables are mapped for all device executions, or for speciﬁc device 3
executions through a linkclause. 4
If anextended-list is present with no clause then the toclause is assumed. 5
Thedevice_type clause speciﬁes if a version of the procedure should be made available on 6
host, device or both. If hostis speciﬁed only a host version of the procedure is made available. If 7
nohost is speciﬁed then only a device version of the procedure is made available. If anyis 8
speciﬁed then both device and host versions of the procedure are made available. 9
C / C++
If a function appears in a toclause in the same translation unit in which the deﬁnition of the 10
function occurs then a device-speciﬁc version of the function is created. 11
If a variable appears in a toclause in the same translation unit in which the deﬁnition of the 12
variable occurs then the original list item is allocated a corresponding list item in the device data 13
environment of all devices. 14
C / C++
Fortran
If an internal procedure appears in a toclause then a device-speciﬁc version of the procedure is 15
created. 16
If a variable that is host associated appears in a toclause then the original list item is allocated a 17
corresponding list item in the device data environment of all devices. 18
Fortran
If a variable appears in a toclause then the corresponding list item in the device data environment 19
of each device is initialized once, in the manner speciﬁed by the program, but at an unspeciﬁed 20
point in the program prior to the ﬁrst reference to that list item. The list item is never removed from 21
those device data environments as if its reference count is initialized to positive inﬁnity. 22
Including list items in a linkclause supports compilation of functions called in a target region 23
that refer to the list items. The list items are not mapped by the declare target directive. 24
Instead, they are mapped according to the data mapping rules described in Section 2.19.7 on 25
page 314. 26
182 OpenMP API – Version 5.0 November 2018
C / C++
If a function is referenced in a function that appears as a list item in a toclause on a 1
declare target directive then the name of the referenced function is treated as if it had 2
appeared in a toclause on a declare target directive. 3
If a variable with static storage duration or a function (except lambdafor C++) is referenced in the 4
initializer expression list of a variable with static storage duration that appears as a list item in a to 5
clause on a declare target directive then the name of the referenced variable or function is 6
treated as if it had appeared in a toclause on a declare target directive. 7
The form of the declare target directive that has no clauses and requires a matching 8
end declare target directive deﬁnes an implicit extended-list to an implicit toclause. The 9
implicitextended-list consists of the variable names of any variable declarations at ﬁle or 10
namespace scope that appear between the two directives and of the function names of any function 11
declarations at ﬁle, namespace or class scope that appear between the two directives. 12
Thedeclaration-deﬁnition-seq deﬁned by a declare target directive and an 13
end declare target directive may contain declare target directives. If a 14
device_type clause is present on the contained declare target directive, then its argument 15
determines which versions are made available. If a list item appears both in an implicit and explicit 16
list, the explicit list determines which versions are made available. 17
C / C++
Fortran
If a procedure is referenced in a procedure that appears as a list item in a toclause on a 18
declare target directivethenthenameoftheprocedureistreatedasifithadappearedina to 19
clause on a declare target directive. 20
If adeclare target does not have any clauses then an implicit extended-list to an implicit to 21
clause of one item is formed from the name of the enclosing subroutine subprogram, function 22
subprogram or interface body to which it applies. 23
If adeclare target directive has a device_type clause then any enclosed internal 24
procedures cannot contain any declare target directives. The enclosing device_type 25
clause implicitly applies to internal procedures. 26
Fortran
Restrictions 27
A threadprivate variable cannot appear in a declare target directive. 28
A variable declared in a declare target directive must have a mappable type. 29
The same list item must not appear multiple times in clauses on the same directive. 30
The same list item must not explicitly appear in both a toclause on one declare target 31
directive and a linkclause on another declare target directive. 32
CHAPTER 2. DIRECTIVES 183
C++
The function names of overloaded functions or template functions may only be speciﬁed within 1
an implicit extended-list . 2
If alambda declaration and deﬁnition appears between a declare target directive and the 3
matching end declare target directive, all variables that are captured by the lambda 4
expression must also appear in a toclause. 5
C++
Fortran
Ifalistitemisaprocedurename,itmustnotbeagenericname,procedurepointerorentryname. 6
Anydeclare target directive with clauses must appear in a speciﬁcation part of a 7
subroutine subprogram, function subprogram, program or module. 8
Anydeclare target directive without clauses must appear in a speciﬁcation part of a 9
subroutine subprogram, function subprogram or interface body to which it applies. 10
Ifadeclare target directiveisspeciﬁedinaninterfaceblockforaprocedure,itmustmatch 11
adeclare target directive in the deﬁnition of the procedure. 12
If an external procedure is a type-bound procedure of a derived type and a declare target 13
directive is speciﬁed in the deﬁnition of the external procedure, such a directive must appear in 14
the interface block that is accessible to the derived type deﬁnition. 15
If any procedure is declared via a procedure declaration statement that is not in the type-bound 16
procedure part of a derived-type deﬁnition, any declare target with the procedure name 17
must appear in the same speciﬁcation part. 18
A variable that is part of another variable (as an array, structure element or type parameter 19
inquiry) cannot appear in a declare target directive. 20
Thedeclare target directive must appear in the declaration section of a scoping unit in 21
which the common block or variable is declared. 22
If adeclare target directive that speciﬁes a common block name appears in one program 23
unit, then such a directive must also appear in every other program unit that contains a COMMON 24
statementthatspeciﬁesthesamename,afterthelastsuch COMMON statementintheprogramunit. 25
If a list item is declared with the BINDattribute, the corresponding C entities must also be 26
speciﬁed in a declare target directive in the C program. 27
A blank common block cannot appear in a declare target directive. 28
Avariablecanonlyappearina declare target directiveinthescopeinwhichitisdeclared. 29
It must not be an element of a common block or appear in an EQUIVALENCE statement. 30
A variable that appears in a declare target directive must be declared in the Fortran scope 31
of a module or have the SAVEattribute, either explicitly or implicitly. 32
Fortran
184 OpenMP API – Version 5.0 November 2018
Cross References 1
target data construct, see Section 2.12.2 on page 161. 2
target construct, see Section 2.12.5 on page 170. 3
2.13 Combined Constructs4
Combined constructs are shortcuts for specifying one construct immediately nested inside another 5
construct. The semantics of the combined constructs are identical to that of explicitly specifying 6
the ﬁrst construct containing one instance of the second construct and no other statements. 7
For combined constructs, tool callbacks are invoked as if the constructs were explicitly nested. 8
2.13.1 Parallel Worksharing-Loop Construct9
Summary 10
The parallel worksharing-loop construct is a shortcut for specifying a parallel construct 11
containingaworksharing-loopconstructwithoneormoreassociatedloopsandnootherstatements. 12
Syntax 13
C / C++
The syntax of the parallel worksharing-loop construct is as follows: 14
#pragma omp parallel for [clause[ [ ,] clause] ... ] new-line 15
for-loops 16
whereclausecan be any of the clauses accepted by the parallel orfordirectives, except the 17
nowait clause, with identical meanings and restrictions. 18
C / C++
CHAPTER 2. DIRECTIVES 185
Fortran
The syntax of the parallel worksharing-loop construct is as follows: 1
!$omp parallel do [clause[ [ ,] clause] ... ] 2
do-loops 3
[!$omp end parallel do ] 4
whereclausecan be any of the clauses accepted by the parallel ordodirectives, with identical 5
meanings and restrictions. 6
If anend parallel do directive is not speciﬁed, an end parallel do directive is assumed at 7
the end of the do-loops.nowait may not be speciﬁed on an end parallel do directive. 8
Fortran
Description 9
The semantics are identical to explicitly specifying a parallel directive immediately followed 10
by a worksharing-loop directive. 11
Restrictions 12
The restrictions for the parallel construct and the worksharing-loop construct apply. 13
Cross References 14
parallel construct, see Section 2.6 on page 74. 15
Worksharing-loop construct, see Section 2.9.2 on page 101. 16
Data attribute clauses, see Section 2.19.4 on page 282. 17
2.13.2 parallel loop Construct 18
Summary 19
Theparallel loop construct is a shortcut for specifying a parallel construct containing a 20
loopconstruct with one or more associated loops and no other statements. 21
186 OpenMP API – Version 5.0 November 2018
Syntax 1
C / C++
The syntax of the parallel loop construct is as follows: 2
#pragma omp parallel loop [clause[ [ ,] clause] ... ] new-line 3
for-loops 4
whereclausecan be any of the clauses accepted by the parallel orloopdirectives, with 5
identical meanings and restrictions. 6
C / C++
Fortran
The syntax of the parallel loop construct is as follows: 7
!$omp parallel loop [clause[ [ ,] clause] ... ] 8
do-loops 9
[!$omp end parallel loop ] 10
whereclausecan be any of the clauses accepted by the parallel orloopdirectives, with 11
identical meanings and restrictions. 12
If anend parallel loop directive is not speciﬁed, an end parallel loop directive is 13
assumed at the end of the do-loops.nowait may not be speciﬁed on an end parallel loop 14
directive. 15
Fortran
Description 16
The semantics are identical to explicitly specifying a parallel directive immediately followed 17
by aloopdirective. 18
Restrictions 19
The restrictions for the parallel construct and the loopconstruct apply. 20
Cross References 21
parallel construct, see Section 2.6 on page 74. 22
loopconstruct, see Section 2.9.5 on page 128. 23
Data attribute clauses, see Section 2.19.4 on page 282. 24
CHAPTER 2. DIRECTIVES 187
2.13.3 parallel sections Construct 1
Summary 2
Theparallel sections construct is a shortcut for specifying a parallel construct 3
containing a sections construct and no other statements. 4
Syntax 5
C / C++
The syntax of the parallel sections construct is as follows: 6
#pragma omp parallel sections [clause[ [ ,] clause] ... ] new-line 7
{ 8
[#pragma omp section new-line] 9
structured-block 10
[#pragma omp section new-line 11
structured-block] 12
... 13
} 14
whereclausecan be any of the clauses accepted by the parallel orsections directives, 15
except the nowait clause, with identical meanings and restrictions. 16
C / C++
Fortran
The syntax of the parallel sections construct is as follows: 17
!$omp parallel sections [clause[ [ ,] clause] ... ] 18
[!$omp section ] 19
structured-block 20
[!$omp section 21
structured-block] 22
... 23
!$omp end parallel sections 24
whereclausecan be any of the clauses accepted by the parallel orsections directives, with 25
identical meanings and restrictions. 26
The last section ends at the end parallel sections directive. nowait cannot be speciﬁed 27
on an end parallel sections directive. 28
Fortran
188 OpenMP API – Version 5.0 November 2018
Description 1
C / C++
The semantics are identical to explicitly specifying a parallel directive immediately followed 2
by asections directive. 3
C / C++
Fortran
The semantics are identical to explicitly specifying a parallel directive immediately followed 4
by asections directive, and an end sections directive immediately followed by an 5
end parallel directive. 6
Fortran
Restrictions 7
The restrictions for the parallel construct and the sections construct apply. 8
Cross References 9
parallel construct, see Section 2.6 on page 74. 10
sections construct, see Section 2.8.1 on page 86. 11
Data attribute clauses, see Section 2.19.4 on page 282. 12
Fortran
2.13.4 parallel workshare Construct 13
Summary 14
Theparallel workshare construct is a shortcut for specifying a parallel construct 15
containing a workshare construct and no other statements. 16
Syntax 17
The syntax of the parallel workshare construct is as follows: 18
!$omp parallel workshare [clause[ [ ,] clause] ... ] 19
structured-block 20
!$omp end parallel workshare 21
whereclausecan be any of the clauses accepted by the parallel directive, with identical 22
meanings and restrictions. nowait may not be speciﬁed on an end parallel workshare 23
directive. 24
CHAPTER 2. DIRECTIVES 189
Description 1
The semantics are identical to explicitly specifying a parallel directive immediately followed 2
by aworkshare directive, and an end workshare directive immediately followed by an 3
end parallel directive. 4
Restrictions 5
The restrictions for the parallel construct and the workshare construct apply. 6
Cross References 7
parallel construct, see Section 2.6 on page 74. 8
workshare construct, see Section 2.8.3 on page 92. 9
Data attribute clauses, see Section 2.19.4 on page 282. 10
Fortran
2.13.5 Parallel Worksharing-Loop SIMD Construct 11
Summary 12
The parallel worksharing-loop SIMD construct is a shortcut for specifying a parallel construct 13
containing a worksharing-loop SIMD construct and no other statements. 14
Syntax 15
C / C++
The syntax of the parallel worksharing-loop SIMD construct is as follows: 16
#pragma omp parallel for simd [clause[ [ ,] clause] ... ] new-line 17
for-loops 18
whereclausecanbeanyoftheclausesacceptedbythe parallel orfor simd directives,except 19
thenowait clause, with identical meanings and restrictions. 20
C / C++
190 OpenMP API – Version 5.0 November 2018
Fortran
The syntax of the parallel worksharing-loop SIMD construct is as follows: 1
!$omp parallel do simd [clause[ [ ,] clause] ... ] 2
do-loops 3
[!$omp end parallel do simd ] 4
whereclausecan be any of the clauses accepted by the parallel ordo simd directives, with 5
identical meanings and restrictions. 6
If anend parallel do simd directive is not speciﬁed, an end parallel do simd directive 7
is assumed at the end of the do-loops.nowait may not be speciﬁed on an end parallel 8
do simd directive. 9
Fortran
Description 10
The semantics of the parallel worksharing-loop SIMD construct are identical to explicitly 11
specifying a parallel directive immediately followed by a worksharing-loop SIMD directive. 12
Restrictions 13
The restrictions for the parallel construct and the worksharing-loop SIMD construct apply. 14
Cross References 15
parallel construct, see Section 2.6 on page 74. 16
Worksharing-loop SIMD construct, see Section 2.9.3.2 on page 114. 17
Data attribute clauses, see Section 2.19.4 on page 282. 18
2.13.6 parallel master Construct 19
Summary 20
Theparallel master construct is a shortcut for specifying a parallel construct containing 21
amaster construct and no other statements. 22
CHAPTER 2. DIRECTIVES 191
Syntax 1
C / C++
The syntax of the parallel master construct is as follows: 2
#pragma omp parallel master [clause[ [ ,] clause] ... ] new-line 3
structured-block 4
whereclausecan be any of the clauses accepted by the parallel ormaster directives, with 5
identical meanings and restrictions. 6
C / C++
Fortran
The syntax of the parallel master construct is as follows: 7
!$omp parallel master [clause[ [ ,] clause] ... ] 8
structured-block 9
!$omp end parallel master 10
whereclausecan be any of the clauses accepted by the parallel ormaster directives, with 11
identical meanings and restrictions. 12
Fortran
Description 13
The semantics are identical to explicitly specifying a parallel directive immediately followed 14
by amaster directive. 15
Restrictions 16
The restrictions for the parallel construct and the master construct apply. 17
Cross References 18
parallel construct, see Section 2.6 on page 74. 19
master construct, see Section 2.16 on page 221. 20
Data attribute clauses, see Section 2.19.4 on page 282. 21
2.13.7 master taskloop Construct 22
Summary 23
Themaster taskloop construct is a shortcut for specifying a master construct containing a 24
taskloop construct and no other statements. 25
192 OpenMP API – Version 5.0 November 2018
Syntax 1
C / C++
The syntax of the master taskloop construct is as follows: 2
#pragma omp master taskloop [clause[ [ ,] clause] ... ] new-line 3
for-loops 4
whereclausecan be any of the clauses accepted by the master ortaskloop directives with 5
identical meanings and restrictions. 6
C / C++
Fortran
The syntax of the master taskloop construct is as follows: 7
!$omp master taskloop [clause[ [ ,] clause] ... ] 8
do-loops 9
[!$omp end master taskloop ] 10
whereclausecan be any of the clauses accepted by the master ortaskloop directives with 11
identical meanings and restrictions. 12
Ifanend master taskloop directiveisnotspeciﬁed,an end master taskloop directiveis 13
assumed at the end of the do-loops. 14
Fortran
Description 15
The semantics are identical to explicitly specifying a master directive immediately followed by a 16
taskloop directive. 17
Restrictions 18
The restrictions for the master andtaskloop constructs apply. 19
Cross References 20
taskloop construct, see Section 2.10.2 on page 140. 21
master construct, see Section 2.16 on page 221. 22
Data attribute clauses, see Section 2.19.4 on page 282. 23
CHAPTER 2. DIRECTIVES 193
2.13.8 master taskloop simd Construct 1
Summary 2
Themaster taskloop simd construct is a shortcut for specifying a master construct 3
containing a taskloop simd construct and no other statements. 4
Syntax 5
C / C++
The syntax of the master taskloop simd construct is as follows: 6
#pragma omp master taskloop simd [clause[ [ ,] clause] ... ] new-line 7
for-loops 8
whereclausecan be any of the clauses accepted by the master ortaskloop simd directives 9
with identical meanings and restrictions. 10
C / C++
Fortran
The syntax of the master taskloop simd construct is as follows: 11
!$omp master taskloop simd [clause[ [ ,] clause] ... ] 12
do-loops 13
[!$omp end master taskloop simd ] 14
whereclausecan be any of the clauses accepted by the master ortaskloop simd directives 15
with identical meanings and restrictions. 16
If anend master taskloop simd directive is not speciﬁed, an end master 17
taskloop simd directive is assumed at the end of the do-loops. 18
Fortran
Description 19
The semantics are identical to explicitly specifying a master directive immediately followed by a 20
taskloop simd directive. 21
Restrictions 22
The restrictions for the master andtaskloop simd constructs apply. 23
194 OpenMP API – Version 5.0 November 2018
Cross References 1
taskloop simd construct, see Section 2.10.3 on page 146. 2
master construct, see Section 2.16 on page 221. 3
Data attribute clauses, see Section 2.19.4 on page 282. 4
2.13.9 parallel master taskloop Construct 5
Summary 6
Theparallel master taskloop construct is a shortcut for specifying a parallel 7
construct containing a master taskloop construct and no other statements. 8
Syntax 9
C / C++
The syntax of the parallel master taskloop construct is as follows: 10
#pragma omp parallel master taskloop [clause[ [ ,] clause] ... ] new-line 11
for-loops 12
whereclausecan be any of the clauses accepted by the parallel ormaster taskloop 13
directives, except the in_reduction clause, with identical meanings and restrictions. 14
C / C++
Fortran
The syntax of the parallel master taskloop construct is as follows: 15
!$omp parallel master taskloop [clause[ [ ,] clause] ... ] 16
do-loops 17
[!$omp end parallel master taskloop ] 18
whereclausecan be any of the clauses accepted by the parallel ormaster taskloop 19
directives, except the in_reduction clause, with identical meanings and restrictions. 20
If anend parallel master taskloop directive is not speciﬁed, an 21
end parallel master taskloop directive is assumed at the end of the do-loops. 22
Fortran
Description 23
The semantics are identical to explicitly specifying a parallel directive immediately followed 24
by amaster taskloop directive. 25
CHAPTER 2. DIRECTIVES 195
Restrictions 1
The restrictions for the parallel construct and the master taskloop construct apply. 2
Cross References 3
parallel construct, see Section 2.6 on page 74. 4
master taskloop construct, see Section 2.13.7 on page 192. 5
Data attribute clauses, see Section 2.19.4 on page 282. 6
2.13.10 parallel master taskloop simd Construct 7
Summary 8
Theparallel master taskloop simd construct is a shortcut for specifying a parallel 9
construct containing a master taskloop simd construct and no other statements. 10
Syntax 11
C / C++
The syntax of the parallel master taskloop simd construct is as follows: 12
#pragma omp parallel master taskloop simd [clause[ [ ,] clause] ... ] new-line 13
for-loops 14
whereclausecan be any of the clauses accepted by the parallel ormaster taskloop simd 15
directives, except the in_reduction clause, with identical meanings and restrictions. 16
C / C++
Fortran
The syntax of the parallel master taskloop simd construct is as follows: 17
!$omp parallel master taskloop simd [clause[ [ ,] clause] ... ] 18
do-loops 19
[!$omp end parallel master taskloop simd ] 20
whereclausecan be any of the clauses accepted by the parallel ormaster taskloop simd 21
directives, except the in_reduction clause, with identical meanings and restrictions. 22
If anend parallel master taskloop simd directive is not speciﬁed, an end parallel 23
master taskloop simd directive is assumed at the end of the do-loops. 24
Fortran
196 OpenMP API – Version 5.0 November 2018
Description 1
The semantics are identical to explicitly specifying a parallel directive immediately followed 2
by amaster taskloop simd directive. 3
Restrictions 4
The restrictions for the parallel construct and the master taskloop simd construct apply. 5
Cross References 6
parallel construct, see Section 2.6 on page 74. 7
master taskloop simd construct, see Section 2.13.8 on page 194. 8
Data attribute clauses, see Section 2.19.4 on page 282. 9
2.13.11 teams distribute Construct 10
Summary 11
Theteams distribute construct is a shortcut for specifying a teamsconstruct containing a 12
distribute construct and no other statements. 13
Syntax 14
C / C++
The syntax of the teams distribute construct is as follows: 15
#pragma omp teams distribute [clause[ [ ,] clause] ... ] new-line 16
for-loops 17
whereclausecan be any of the clauses accepted by the teamsordistribute directives with 18
identical meanings and restrictions. 19
C / C++
CHAPTER 2. DIRECTIVES 197
Fortran
The syntax of the teams distribute construct is as follows: 1
!$omp teams distribute [clause[ [ ,] clause] ... ] 2
do-loops 3
[!$omp end teams distribute ] 4
whereclausecan be any of the clauses accepted by the teamsordistribute directives with 5
identical meanings and restrictions. 6
If anend teams distribute directive is not speciﬁed, an end teams distribute 7
directive is assumed at the end of the do-loops. 8
Fortran
Description 9
The semantics are identical to explicitly specifying a teamsdirective immediately followed by a 10
distribute directive. 11
Restrictions 12
The restrictions for the teamsanddistribute constructs apply. 13
Cross References 14
teamsconstruct, see Section 2.7 on page 82. 15
distribute construct, see Section 2.9.4.1 on page 120. 16
Data attribute clauses, see Section 2.19.4 on page 282. 17
2.13.12 teams distribute simd Construct 18
Summary 19
Theteams distribute simd construct is a shortcut for specifying a teamsconstruct 20
containing a distribute simd construct and no other statements. 21
198 OpenMP API – Version 5.0 November 2018
Syntax 1
C / C++
The syntax of the teams distribute simd construct is as follows: 2
#pragma omp teams distribute simd [clause[ [ ,] clause] ... ] new-line 3
for-loops 4
whereclausecan be any of the clauses accepted by the teamsordistribute simd directives 5
with identical meanings and restrictions. 6
C / C++
Fortran
The syntax of the teams distribute simd construct is as follows: 7
!$omp teams distribute simd [clause[ [ ,] clause] ... ] 8
do-loops 9
[!$omp end teams distribute simd ] 10
whereclausecan be any of the clauses accepted by the teamsordistribute simd directives 11
with identical meanings and restrictions. 12
If anend teams distribute simd directive is not speciﬁed, an end teams 13
distribute simd directive is assumed at the end of the do-loops. 14
Fortran
Description 15
The semantics are identical to explicitly specifying a teamsdirective immediately followed by a 16
distribute simd directive. 17
Restrictions 18
The restrictions for the teamsanddistribute simd constructs apply. 19
Cross References 20
teamsconstruct, see Section 2.7 on page 82. 21
distribute simd construct, see Section 2.9.4.2 on page 123. 22
Data attribute clauses, see Section 2.19.4 on page 282. 23
CHAPTER 2. DIRECTIVES 199
2.13.13 Teams Distribute Parallel Worksharing-Loop Construct1
Summary 2
The teams distribute parallel worksharing-loop construct is a shortcut for specifying a teams 3
construct containing a distribute parallel worksharing-loop construct and no other statements. 4
Syntax 5
C / C++
The syntax of the teams distribute parallel worksharing-loop construct is as follows: 6
#pragma omp teams distribute parallel for \ 7
[clause[ [ ,] clause] ... ] new-line 8
for-loops 9
whereclausecan be any of the clauses accepted by the teamsordistribute parallel for 10
directives with identical meanings and restrictions. 11
C / C++
Fortran
The syntax of the teams distribute parallel worksharing-loop construct is as follows: 12
!$omp teams distribute parallel do [clause[ [ ,] clause] ... ] 13
do-loops 14
[!$omp end teams distribute parallel do ] 15
whereclausecan be any of the clauses accepted by the teamsordistribute parallel do 16
directives with identical meanings and restrictions. 17
If anend teams distribute parallel do directive is not speciﬁed, an end teams 18
distribute parallel do directive is assumed at the end of the do-loops. 19
Fortran
Description 20
The semantics are identical to explicitly specifying a teamsdirective immediately followed by a 21
distribute parallel worksharing-loop directive. 22
Restrictions 23
The restrictions for the teamsand distribute parallel worksharing-loop constructs apply. 24
200 OpenMP API – Version 5.0 November 2018
Cross References 1
teamsconstruct, see Section 2.7 on page 82. 2
Distribute parallel worksharing-loop construct, see Section 2.9.4.3 on page 125. 3
Data attribute clauses, see Section 2.19.4 on page 282. 4
2.13.14 Teams Distribute Parallel Worksharing-Loop SIMD5
Construct 6
Summary 7
The teams distribute parallel worksharing-loop SIMD construct is a shortcut for specifying a 8
teamsconstruct containing a distribute parallel worksharing-loop SIMD construct and no other 9
statements. 10
Syntax 11
C / C++
The syntax of the teams distribute parallel worksharing-loop SIMD construct is as follows: 12
#pragma omp teams distribute parallel for simd \ 13
[clause[ [ ,] clause] ... ] new-line 14
for-loops 15
whereclausecan be any of the clauses accepted by the teamsordistribute parallel 16
for simd directives with identical meanings and restrictions. 17
C / C++
Fortran
The syntax of the teams distribute parallel worksharing-loop SIMD construct is as follows: 18
!$omp teams distribute parallel do simd [clause[ [ ,] clause] ... ] 19
do-loops 20
[!$omp end teams distribute parallel do simd ] 21
whereclausecan be any of the clauses accepted by the teamsordistribute parallel 22
do simd directives with identical meanings and restrictions. 23
If anend teams distribute parallel do simd directive is not speciﬁed, an end teams 24
distribute parallel do simd directive is assumed at the end of the do-loops. 25
Fortran
CHAPTER 2. DIRECTIVES 201
Description 1
The semantics are identical to explicitly specifying a teamsdirective immediately followed by a 2
distribute parallel worksharing-loop SIMD directive. 3
Restrictions 4
The restrictions for the teamsand distribute parallel worksharing-loop SIMD constructs apply. 5
Cross References 6
teamsconstruct, see Section 2.7 on page 82. 7
Distribute parallel worksharing-loop SIMD construct, see Section 2.9.4.4 on page 126. 8
Data attribute clauses, see Section 2.19.4 on page 282. 9
2.13.15 teams loop Construct 10
Summary 11
Theteams loop construct is a shortcut for specifying a teamsconstruct containing a loop 12
construct and no other statements. 13
Syntax 14
C / C++
The syntax of the teams loop construct is as follows: 15
#pragma omp teams loop [clause[ [ ,] clause] ... ] new-line 16
for-loops 17
whereclausecan be any of the clauses accepted by the teamsorloopdirectives with identical 18
meanings and restrictions. 19
C / C++
202 OpenMP API – Version 5.0 November 2018
Fortran
The syntax of the teams loop construct is as follows: 1
!$omp teams loop [clause[ [ ,] clause] ... ] 2
do-loops 3
[!$omp end teams loop ] 4
whereclausecan be any of the clauses accepted by the teamsorloopdirectives with identical 5
meanings and restrictions. 6
Ifanend teams loop directiveisnotspeciﬁed,an end teams loop directiveisassumedatthe 7
end of the do-loops. 8
Fortran
Description 9
The semantics are identical to explicitly specifying a teamsdirective immediately followed by a 10
loopdirective. 11
Restrictions 12
The restrictions for the teamsandloopconstructs apply. 13
Cross References 14
teamsconstruct, see Section 2.7 on page 82. 15
loopconstruct, see Section 2.9.5 on page 128. 16
Data attribute clauses, see Section 2.19.4 on page 282. 17
2.13.16 target parallel Construct 18
Summary 19
Thetarget parallel construct is a shortcut for specifying a target construct containing a 20
parallel construct and no other statements. 21
CHAPTER 2. DIRECTIVES 203
Syntax 1
C / C++
The syntax of the target parallel construct is as follows: 2
#pragma omp target parallel [clause[ [ ,] clause] ... ] new-line 3
structured-block 4
whereclausecan be any of the clauses accepted by the target orparallel directives, except 5
forcopyin, with identical meanings and restrictions. 6
C / C++
Fortran
The syntax of the target parallel construct is as follows: 7
!$omp target parallel [clause[ [ ,] clause] ... ] 8
structured-block 9
!$omp end target parallel 10
whereclausecan be any of the clauses accepted by the target orparallel directives, except 11
forcopyin, with identical meanings and restrictions. 12
Fortran
Description 13
The semantics are identical to explicitly specifying a target directive immediately followed by a 14
parallel directive. 15
Restrictions 16
The restrictions for the target andparallel constructs apply except for the following explicit 17
modiﬁcations: 18
If any ifclause on the directive includes a directive-name-modiﬁer then all ifclauses on the 19
directive must include a directive-name-modiﬁer . 20
At most one ifclause without a directive-name-modiﬁer can appear on the directive. 21
Atmostone ifclausewiththe parallel directive-name-modiﬁer canappearonthedirective. 22
At most one ifclause with the target directive-name-modiﬁer can appear on the directive. 23
204 OpenMP API – Version 5.0 November 2018
Cross References 1
parallel construct, see Section 2.6 on page 74. 2
target construct, see Section 2.12.5 on page 170. 3
ifClause, see Section 2.15 on page 220. 4
Data attribute clauses, see Section 2.19.4 on page 282. 5
2.13.17 Target Parallel Worksharing-Loop Construct6
Summary 7
The target parallel worksharing-loop construct is a shortcut for specifying a target construct 8
containing a parallel worksharing-loop construct and no other statements. 9
Syntax 10
C / C++
The syntax of the target parallel worksharing-loop construct is as follows: 11
#pragma omp target parallel for [clause[ [ ,] clause] ... ] new-line 12
for-loops 13
whereclausecan be any of the clauses accepted by the target orparallel for directives, 14
except for copyin, with identical meanings and restrictions. 15
C / C++
Fortran
The syntax of the target parallel worksharing-loop construct is as follows: 16
!$omp target parallel do [clause[ [ ,] clause] ... ] 17
do-loops 18
[!$omp end target parallel do ] 19
whereclausecan be any of the clauses accepted by the target orparallel do directives, 20
except for copyin, with identical meanings and restrictions. 21
If anend target parallel do directive is not speciﬁed, an end target parallel do 22
directive is assumed at the end of the do-loops. 23
Fortran
CHAPTER 2. DIRECTIVES 205
Description 1
The semantics are identical to explicitly specifying a target directive immediately followed by a 2
parallel worksharing-loop directive. 3
Restrictions 4
The restrictions for the target and parallel worksharing-loop constructs apply except for the 5
following explicit modiﬁcations: 6
If any ifclause on the directive includes a directive-name-modiﬁer then all ifclauses on the 7
directive must include a directive-name-modiﬁer . 8
At most one ifclause without a directive-name-modiﬁer can appear on the directive. 9
Atmostone ifclausewiththe parallel directive-name-modiﬁer canappearonthedirective. 10
At most one ifclause with the target directive-name-modiﬁer can appear on the directive. 11
Cross References 12
target construct, see Section 2.12.5 on page 170. 13
Parallel Worksharing-Loop construct, see Section 2.13.1 on page 185. 14
ifClause, see Section 2.15 on page 220. 15
Data attribute clauses, see Section 2.19.4 on page 282. 16
2.13.18 Target Parallel Worksharing-Loop SIMD Construct 17
Summary 18
The target parallel worksharing-loop SIMD construct is a shortcut for specifying a target 19
construct containing a parallel worksharing-loop SIMD construct and no other statements. 20
206OpenMP API – Version 5.0 November 2018
Syntax 1
C / C++
The syntax of the target parallel worksharing-loop SIMD construct is as follows: 2
#pragma omp target parallel for simd \ 3
[clause[[ ,] clause] ... ] new-line 4
for-loops 5
whereclausecan be any of the clauses accepted by the target orparallel for simd 6
directives, except for copyin, with identical meanings and restrictions. 7
C / C++
Fortran
The syntax of the target parallel worksharing-loop SIMD construct is as follows: 8
!$omp target parallel do simd [clause[ [ ,] clause] ... ] 9
do-loops 10
[!$omp end target parallel do simd ] 11
whereclausecan be any of the clauses accepted by the target orparallel do simd 12
directives, except for copyin, with identical meanings and restrictions. 13
If anend target parallel do simd directive is not speciﬁed, an end target parallel 14
do simd directive is assumed at the end of the do-loops. 15
Fortran
Description 16
The semantics are identical to explicitly specifying a target directive immediately followed by a 17
parallel worksharing-loop SIMD directive. 18
Restrictions 19
The restrictions for the target and parallel worksharing-loop SIMD constructs apply except for 20
the following explicit modiﬁcations: 21
If any ifclause on the directive includes a directive-name-modiﬁer then all ifclauses on the 22
directive must include a directive-name-modiﬁer . 23
At most one ifclause without a directive-name-modiﬁer can appear on the directive. 24
Atmostone ifclausewiththe parallel directive-name-modiﬁer canappearonthedirective. 25
At most one ifclause with the target directive-name-modiﬁer can appear on the directive. 26
CHAPTER 2. DIRECTIVES 207
Cross References 1
target construct, see Section 2.12.5 on page 170. 2
Parallel worksharing-loop SIMD construct, see Section 2.13.5 on page 190. 3
ifClause, see Section 2.15 on page 220. 4
Data attribute clauses, see Section 2.19.4 on page 282. 5
2.13.19 target parallel loop Construct 6
Summary 7
Thetarget parallel loop construct is a shortcut for specifying a target construct 8
containing a parallel loop construct and no other statements. 9
Syntax 10
C / C++
The syntax of the target parallel loop construct is as follows: 11
#pragma omp target parallel loop [clause[ [ ,] clause] ... ] new-line 12
for-loops 13
whereclausecan be any of the clauses accepted by the target orparallel loop directives 14
with identical meanings and restrictions. 15
C / C++
Fortran
The syntax of the target parallel loop construct is as follows: 16
!$omp target parallel loop [clause[ [ ,] clause] ... ] 17
do-loops 18
[!$omp end target parallel loop ] 19
whereclausecan be any of the clauses accepted by the teamsorparallel loop directives 20
with identical meanings and restrictions. 21
If anend target parallel loop directive is not speciﬁed, an end target parallel 22
loopdirective is assumed at the end of the do-loops.nowait may not be speciﬁed on an 23
end target parallel loop directive. 24
Fortran
208 OpenMP API – Version 5.0 November 2018
Description 1
The semantics are identical to explicitly specifying a target directive immediately followed by a 2
parallel loop directive. 3
Restrictions 4
The restrictions for the target andparallel loop constructs apply. 5
Cross References 6
target construct, see Section 2.12.5 on page 170. 7
parallel loop construct, see Section 2.13.2 on page 186. 8
Data attribute clauses, see Section 2.19.4 on page 282. 9
2.13.20 target simd Construct 10
Summary 11
Thetarget simd construct is a shortcut for specifying a target construct containing a simd 12
construct and no other statements. 13
Syntax 14
C / C++
The syntax of the target simd construct is as follows: 15
#pragma omp target simd [clause[ [ ,] clause] ... ] new-line 16
for-loops 17
whereclausecan be any of the clauses accepted by the target orsimddirectives with identical 18
meanings and restrictions. 19
C / C++
CHAPTER 2. DIRECTIVES 209
Fortran
The syntax of the target simd construct is as follows: 1
!$omp target simd [clause[ [ ,] clause] ... ] 2
do-loops 3
[!$omp end target simd ] 4
whereclausecan be any of the clauses accepted by the target orsimddirectives with identical 5
meanings and restrictions. 6
If anend target simd directive is not speciﬁed, an end target simd directive is assumed at 7
the end of the do-loops. 8
Fortran
Description 9
The semantics are identical to explicitly specifying a target directive immediately followed by a 10
simddirective. 11
Restrictions 12
The restrictions for the target andsimdconstructs apply. 13
Cross References 14
simdconstruct, see Section 2.9.3.1 on page 110. 15
target construct, see Section 2.12.5 on page 170. 16
Data attribute clauses, see Section 2.19.4 on page 282. 17
2.13.21 target teams Construct 18
Summary 19
Thetarget teams construct is a shortcut for specifying a target construct containing a 20
teamsconstruct and no other statements. 21
210 OpenMP API – Version 5.0 November 2018
Syntax 1
C / C++
The syntax of the target teams construct is as follows: 2
#pragma omp target teams [clause[ [ ,] clause] ... ] new-line 3
structured-block 4
whereclausecanbeanyoftheclausesacceptedbythe target orteamsdirectiveswithidentical 5
meanings and restrictions. 6
C / C++
Fortran
The syntax of the target teams construct is as follows: 7
!$omp target teams [clause[ [ ,] clause] ... ] 8
structured-block 9
!$omp end target teams 10
whereclausecanbeanyoftheclausesacceptedbythe target orteamsdirectiveswithidentical 11
meanings and restrictions. 12
Fortran
Description 13
The semantics are identical to explicitly specifying a target directive immediately followed by a 14
teamsdirective. 15
Restrictions 16
The restrictions for the target andteamsconstructs apply. 17
Cross References 18
teamsconstruct, see Section 2.7 on page 82. 19
target construct, see Section 2.12.5 on page 170. 20
Data attribute clauses, see Section 2.19.4 on page 282. 21
2.13.22 target teams distribute Construct 22
Summary 23
Thetarget teams distribute construct is a shortcut for specifying a target construct 24
containing a teams distribute construct and no other statements. 25
CHAPTER 2. DIRECTIVES 211
Syntax 1
C / C++
The syntax of the target teams distribute construct is as follows: 2
#pragma omp target teams distribute [clause[ [ ,] clause] ... ] new-line 3
for-loops 4
whereclausecan be any of the clauses accepted by the target orteams distribute 5
directives with identical meanings and restrictions. 6
C / C++
Fortran
The syntax of the target teams distribute construct is as follows: 7
!$omp target teams distribute [clause[ [ ,] clause] ... ] 8
do-loops 9
[!$omp end target teams distribute ] 10
whereclausecan be any of the clauses accepted by the target orteams distribute 11
directives with identical meanings and restrictions. 12
If anend target teams distribute directive is not speciﬁed, an end target teams 13
distribute directive is assumed at the end of the do-loops. 14
Fortran
Description 15
The semantics are identical to explicitly specifying a target directive immediately followed by a 16
teams distribute directive. 17
Restrictions 18
The restrictions for the target andteams distribute constructs. 19
Cross References 20
target construct, see Section 2.12.2 on page 161. 21
teams distribute construct, see Section 2.13.11 on page 197. 22
Data attribute clauses, see Section 2.19.4 on page 282. 23
212 OpenMP API – Version 5.0 November 2018
2.13.23 target teams distribute simd Construct 1
Summary 2
Thetarget teams distribute simd construct is a shortcut for specifying a target 3
construct containing a teams distribute simd construct and no other statements. 4
Syntax 5
C / C++
The syntax of the target teams distribute simd construct is as follows: 6
#pragma omp target teams distribute simd \ 7
[clause[ [ ,] clause] ... ] new-line 8
for-loops 9
whereclausecan be any of the clauses accepted by the target orteams distribute simd 10
directives with identical meanings and restrictions. 11
C / C++
Fortran
The syntax of the target teams distribute simd construct is as follows: 12
!$omp target teams distribute simd [clause[ [ ,] clause] ... ] 13
do-loops 14
[!$omp end target teams distribute simd ] 15
whereclausecan be any of the clauses accepted by the target orteams distribute simd 16
directives with identical meanings and restrictions. 17
If anend target teams distribute simd directive is not speciﬁed, an end target 18
teams distribute simd directive is assumed at the end of the do-loops. 19
Fortran
Description 20
The semantics are identical to explicitly specifying a target directive immediately followed by a 21
teams distribute simd directive. 22
Restrictions 23
The restrictions for the target andteams distribute simd constructs apply. 24
CHAPTER 2. DIRECTIVES 213
Cross References 1
target construct, see Section 2.12.2 on page 161. 2
teams distribute simd construct, see Section 2.13.12 on page 198. 3
Data attribute clauses, see Section 2.19.4 on page 282. 4
2.13.24 target teams loop Construct 5
Summary 6
Thetarget teams loop constructisashortcutforspecifyinga target constructcontaininga 7
teams loop construct and no other statements. 8
Syntax 9
C / C++
The syntax of the target teams loop construct is as follows: 10
#pragma omp target teams loop [clause[ [ ,] clause] ... ] new-line 11
for-loops 12
whereclausecan be any of the clauses accepted by the target orteams loop directives with 13
identical meanings and restrictions. 14
C / C++
Fortran
The syntax of the target teams loop construct is as follows: 15
!$omp target teams loop [clause[ [ ,] clause] ... ] 16
do-loops 17
[!$omp end target teams loop ] 18
whereclausecan be any of the clauses accepted by the target orteams loop directives with 19
identical meanings and restrictions. 20
If anend target teams loop directive is not speciﬁed, an end target teams loop 21
directive is assumed at the end of the do-loops. 22
Fortran
Description 23
The semantics are identical to explicitly specifying a target directive immediately followed by a 24
teams loop directive. 25
214 OpenMP API – Version 5.0 November 2018
Restrictions 1
The restrictions for the target andteams loop constructs. 2
Cross References 3
target construct, see Section 2.12.5 on page 170. 4
Teams loop construct, see Section 2.13.15 on page 202. 5
Data attribute clauses, see Section 2.19.4 on page 282. 6
2.13.25 Target Teams Distribute Parallel Worksharing-Loop7
Construct 8
Summary 9
The target teams distribute parallel worksharing-loop construct is a shortcut for specifying a 10
target construct containing a teams distribute parallel worksharing-loop construct and no other 11
statements. 12
Syntax 13
C / C++
The syntax of the target teams distribute parallel worksharing-loop construct is as follows: 14
#pragma omp target teams distribute parallel for \ 15
[clause[ [ ,] clause] ... ] new-line 16
for-loops 17
whereclausecan be any of the clauses accepted by the target orteams distribute 18
parallel for directives with identical meanings and restrictions. 19
C / C++
Fortran
The syntax of the target teams distribute parallel worksharing-loop construct is as follows: 20
!$omp target teams distribute parallel do [clause[ [ ,] clause] ... ] 21
do-loops 22
[!$omp end target teams distribute parallel do ] 23
whereclausecan be any of the clauses accepted by the target orteams distribute 24
parallel do directives with identical meanings and restrictions. 25
If anend target teams distribute parallel do directive is not speciﬁed, an 26
end target teams distribute parallel do directive is assumed at the end of the 27
do-loops. 28
Fortran
CHAPTER 2. DIRECTIVES 215
Description 1
The semantics are identical to explicitly specifying a target directive immediately followed by a 2
teams distribute parallel worksharing-loop directive. 3
Restrictions 4
The restrictions for the target and teams distribute parallel worksharing-loop constructs apply 5
except for the following explicit modiﬁcations: 6
If any ifclause on the directive includes a directive-name-modiﬁer then all ifclauses on the 7
directive must include a directive-name-modiﬁer . 8
At most one ifclause without a directive-name-modiﬁer can appear on the directive. 9
Atmostone ifclausewiththe parallel directive-name-modiﬁer canappearonthedirective. 10
At most one ifclause with the target directive-name-modiﬁer can appear on the directive. 11
Cross References 12
target construct, see Section 2.12.5 on page 170. 13
Teams distribute parallel worksharing-loop construct, see Section 2.13.13 on page 200. 14
ifClause, see Section 2.15 on page 220. 15
Data attribute clauses, see Section 2.19.4 on page 282. 16
2.13.26 Target Teams Distribute Parallel Worksharing-Loop SIMD 17
Construct 18
Summary 19
The target teams distribute parallel worksharing-loop SIMD construct is a shortcut for specifying a 20
target construct containing a teams distribute parallel worksharing-loop SIMD construct and no 21
other statements. 22
216 OpenMP API – Version 5.0 November 2018
Syntax 1
C / C++
The syntax of the target teams distribute parallel worksharing-loop SIMD construct is as follows: 2
#pragma omp target teams distribute parallel for simd \ 3
[clause[ [ ,] clause] ... ] new-line 4
for-loops 5
whereclausecan be any of the clauses accepted by the target orteams distribute 6
parallel for simd directives with identical meanings and restrictions. 7
C / C++
Fortran
The syntax of the target teams distribute parallel worksharing-loop SIMD construct is as follows: 8
!$omp target teams distribute parallel do simd [clause[ [ ,] clause] ... ] 9
do-loops 10
[!$omp end target teams distribute parallel do simd ] 11
whereclausecan be any of the clauses accepted by the target orteams distribute 12
parallel do simd directives with identical meanings and restrictions. 13
If anend target teams distribute parallel do simd directive is not speciﬁed, an 14
end target teams distribute parallel do simd directive is assumed at the end of the 15
do-loops. 16
Fortran
Description 17
The semantics are identical to explicitly specifying a target directive immediately followed by a 18
teams distribute parallel worksharing-loop SIMD directive. 19
Restrictions 20
The restrictions for the target and teams distribute parallel worksharing-loop SIMD constructs 21
apply except for the following explicit modiﬁcations: 22
If any ifclause on the directive includes a directive-name-modiﬁer then all ifclauses on the 23
directive must include a directive-name-modiﬁer . 24
At most one ifclause without a directive-name-modiﬁer can appear on the directive. 25
Atmostone ifclausewiththe parallel directive-name-modiﬁer canappearonthedirective. 26
At most one ifclause with the target directive-name-modiﬁer can appear on the directive. 27
CHAPTER 2. DIRECTIVES 217
Cross References 1
target construct, see Section 2.12.5 on page 170. 2
Teams distribute parallel worksharing-loop SIMD construct, see Section 2.13.14 on page 201. 3
ifClause, see Section 2.15 on page 220. 4
Data attribute clauses, see Section 2.19.4 on page 282. 5
2.14 Clauses on Combined and Composite Constructs6
This section speciﬁes the handling of clauses on combined or composite constructs and the 7
handling of implicit clauses from variables with predetermined data sharing if they are not 8
predeterminedonlyonaparticularconstruct. Someclausesarepermittedonlyonasingleconstruct 9
of the constructs that constitute the combined or composite construct, in which case the eﬀect is as 10
if the clause is applied to that speciﬁc construct. As detailed in this section, other clauses have the 11
eﬀect as if they are applied to one or more constituent constructs. 12
Thecollapse clause is applied once to the combined or composite construct. 13
The eﬀect of the private clause is as if it is applied only to the innermost constituent construct 14
that permits it. 15
The eﬀect of the firstprivate clause is as if it is applied to one or more constructs as follows: 16
To the distribute construct if it is among the constituent constructs; 17
To the teamsconstruct if it is among the constituent constructs and the distribute 18
construct is not; 19
To the worksharing-loop construct if it is among the constituent constructs; 20
To the taskloop construct if it is among the constituent constructs; 21
To the parallel construct if it is among the constituent constructs and the worksharing-loop 22
construct or the taskloop construct is not; 23
To the outermost constituent construct if not already applied to it by the above rules and the 24
outermost constituent construct is not a teamsconstruct, a parallel construct, a master 25
construct, or a target construct; and 26
Tothe target constructifitisamongtheconstituentconstructsandthesamelistitemdoesnot 27
appear in a lastprivate ormapclause. 28
218 OpenMP API – Version 5.0 November 2018
If the parallel construct is among the constituent constructs and the eﬀect is not as if the 1
firstprivate clause is applied to it by the above rules, then the eﬀect is as if the shared 2
clause with the same list item is applied to the parallel construct. If the teamsconstruct is 3
amongtheconstituentconstructsandtheeﬀectisnotasifthe firstprivate clauseisappliedto 4
it by the above rules, then the eﬀect is as if the shared clause with the same list item is applied to 5
theteamsconstruct. 6
The eﬀect of the lastprivate clause is as if it is applied to one or more constructs as follows: 7
To the worksharing-loop construct if it is among the constituent constructs; 8
To the taskloop construct if it is among the constituent constructs; 9
To the distribute construct if it is among the constituent constructs; and 10
To the innermost constituent construct that permits it unless it is a worksharing-loop or 11
distribute construct. 12
Ifthe parallel constructisamongtheconstituentconstructsandthelistitemisnotalsospeciﬁed 13
in the firstprivate clause, then the eﬀect of the lastprivate clause is as if the shared 14
clause with the same list item is applied to the parallel construct. If the teamsconstruct is 15
among the constituent constructs and the list item is not also speciﬁed in the firstprivate 16
clause, then the eﬀect of the lastprivate clause is as if the shared clause with the same list 17
item is applied to the teamsconstruct. If the target construct is among the constituent 18
constructsandthelistitemisnotspeciﬁedina mapclause,theeﬀectofthe lastprivate clause 19
is as if the same list item appears in a mapclause with a map-type oftofrom. 20
The eﬀect of the shared,default ,order, orallocate clause is as if it is applied to all 21
constituent constructs that permit the clause. 22
The eﬀect of the reduction clause is as if it is applied to all constructs that permit the clause, 23
except for the following constructs: 24
Theparallel construct, when combined with the sections , worksharing-loop, loop, or 25
taskloop construct; and 26
Theteamsconstruct, when combined with the loopconstruct. 27
Forthe parallel andteamsconstructsabove,theeﬀectofthe reduction clauseinsteadisas 28
if each list item or, for any list item that is an array item, its corresponding base array or base 29
pointer appears in a shared clause for the construct. If the taskreduction-modiﬁer is speciﬁed, 30
the eﬀect is as if it only modiﬁes the behavior of the reduction clause on the innermost 31
constructthatconstitutesthecombinedconstructandthatacceptsthemodiﬁer(seeSection2.19.5.4 32
on page 300). If the inscan reduction-modiﬁer is speciﬁed, the eﬀect is as if it modiﬁes the 33
behaviorofthe reduction clauseonallconstructsofthecombinedconstructtowhichtheclause 34
is applied and that accept the modiﬁer. If a construct to which the inscan reduction-modiﬁer is 35
appliediscombinedwiththe target construct,theeﬀectisasifthesamelistitemalsoappearsin 36
amapclause with a map-type oftofrom. 37
CHAPTER 2. DIRECTIVES 219
Thein_reduction clause is permitted on a single construct among those that constitute the 1
combined or composite construct and the eﬀect is as if the clause is applied to that construct, but if 2
that construct is a target construct, the eﬀect is also as if the same list item appears in a map 3
clause with a map-type oftofrom and amap-type-modiﬁer ofalways. 4
The eﬀect of the ifclause is described in Section 2.15 on page 220. 5
The eﬀect of the linear clause is as if it is applied to the innermost constituent construct. 6
Additionally, if the list item is not the iteration variable of a simdor worksharing-loop SIMD 7
construct, the eﬀect on the outer constituent constructs is as if the list item was speciﬁed in 8
firstprivate andlastprivate clauses on the combined or composite construct, with the 9
rules speciﬁed above applied. If a list item of the linear clause is the iteration variable of a 10
simdor worksharing-loop SIMD construct and it is not declared in the construct, the eﬀect on the 11
outer constituent constructs is as if the list item was speciﬁed in a lastprivate clause on the 12
combined or composite construct with the rules speciﬁed above applied. 13
The eﬀect of the nowait clause is as if it is applied to the outermost constituent construct that 14
permits it. 15
If the clauses have expressions on them, such as for various clauses where the argument of the 16
clause is an expression, or lower-bound ,length, orstrideexpressions inside array sections (or 17
subscript andstrideexpressions in subscript-triplet for Fortran), or linear-step oralignment 18
expressions, the expressions are evaluated immediately before the construct to which the clause has 19
been split or duplicated per the above rules (therefore inside of the outer constituent constructs). 20
However, the expressions inside the num_teams andthread_limit clauses are always 21
evaluated before the outermost constituent construct. 22
The restriction that a list item may not appear in more than one data sharing clause with the 23
exception of specifying a variable in both firstprivate andlastprivate clauses applies 24
after the clauses are split or duplicated per the above rules. 25
2.15 ifClause 26
Summary 27
Thesemanticsofan ifclausearedescribedinthesectionontheconstructtowhichitapplies. The 28
ifclausedirective-name-modiﬁer names the associated construct to which an expression applies, 29
and is particularly useful for composite and combined constructs. 30
220 OpenMP API – Version 5.0 November 2018
Syntax 1
C / C++
The syntax of the ifclause is as follows: 2
if([ directive-name-modiﬁer :] scalar-expression ) 3
C / C++
Fortran
The syntax of the ifclause is as follows: 4
if([ directive-name-modiﬁer :] scalar-logical-expression ) 5
Fortran
Description 6
The eﬀect of the ifclause depends on the construct to which it is applied. For combined or 7
composite constructs, the ifclause only applies to the semantics of the construct named in the 8
directive-name-modiﬁer if one is speciﬁed. If no directive-name-modiﬁer is speciﬁed for a 9
combined or composite construct then the ifclause applies to all constructs to which an ifclause 10
can apply. 11
2.16 master Construct 12
Summary 13
Themaster constructspeciﬁesastructuredblockthatisexecutedbythemasterthreadoftheteam. 14
Syntax 15
C / C++
The syntax of the master construct is as follows: 16
#pragma omp master new-line 17
structured-block 18
C / C++
Fortran
The syntax of the master construct is as follows: 19
!$omp master 20
structured-block 21
!$omp end master 22
Fortran
CHAPTER 2. DIRECTIVES 221
Binding 1
The binding thread set for a master region is the current team. A master region binds to the 2
innermost enclosing parallel region. 3
Description 4
Only the master thread of the team that executes the binding parallel region participates in the 5
execution of the structured block of the master region. Other threads in the team do not execute 6
the associated structured block. There is no implied barrier either on entry to, or exit from, the 7
master construct. 8
Execution Model Events 9
Themaster-begin eventoccursinthemasterthreadofateamthatencountersthe master construct 10
on entry to the master region. 11
Themaster-end event occurs in the master thread of a team that encounters the master construct 12
on exit from the master region. 13
Tool Callbacks 14
A thread dispatches a registered ompt_callback_master callback with 15
ompt_scope_begin as itsendpoint argument for each occurrence of a master-begin event in 16
that thread. Similarly, a thread dispatches a registered ompt_callback_master callback with 17
ompt_scope_end as itsendpoint argument for each occurrence of a master-end event in that 18
thread. These callbacks occur in the context of the task executed by the master thread and have the 19
type signature ompt_callback_master_t . 20
Restrictions 21
C++
A throw executed inside a master region must cause execution to resume within the same 22
master region, and the same thread that threw the exception must catch it 23
C++
Cross References 24
parallel construct, see Section 2.6 on page 74. 25
ompt_scope_begin andompt_scope_end , see Section 4.4.4.11 on page 443. 26
ompt_callback_master_t , see Section 4.5.2.12 on page 473. 27
222 OpenMP API – Version 5.0 November 2018
2.17 Synchronization Constructs and Clauses1
A synchronization construct orders the completion of code executed by diﬀerent threads. This 2
ordering is imposed by synchronizing ﬂush operations that are executed as part of the region that 3
corresponds to the construct. 4
Synchronization through the use of synchronizing ﬂush operations and atomic operations is 5
described in Section 1.4.4 on page 25 and Section 1.4.6 on page 28. Section 2.17.8.1 on page 246 6
deﬁnes the behavior of synchronizing ﬂush operations that are implied at various other locations in 7
an OpenMP program. 8
2.17.1 critical Construct 9
Summary 10
Thecritical construct restricts execution of the associated structured block to a single thread at 11
a time. 12
Syntax 13
C / C++
The syntax of the critical construct is as follows: 14
#pragma omp critical [(name)[[,]hint(hint-expression )] ] new-line 15
structured-block 16
wherehint-expression is an integer constant expression that evaluates to a valid synchronization 17
hint (as described in Section 2.17.12 on page 260). 18
C / C++
Fortran
The syntax of the critical construct is as follows: 19
!$omp critical [(name)[[,]hint(hint-expression )] ] 20
structured-block 21
!$omp end critical [(name)] 22
wherehint-expression is a constant expression that evaluates to a scalar value with kind 23
omp_sync_hint_kind and a value that is a valid synchronization hint (as described 24
in Section 2.17.12 on page 260). 25
Fortran
CHAPTER 2. DIRECTIVES 223
Binding 1
The binding thread set for a critical region is all threads in the contention group. 2
Description 3
The region that corresponds to a critical construct is executed as if only a single thread at a 4
timeamongallthreadsinthecontentiongroupenterstheregionforexecution,withoutregardtothe 5
team(s) to which the threads belong. An optional namemay be used to identify the critical 6
construct. All critical constructs without a name are considered to have the same unspeciﬁed 7
name. 8
C / C++
Identiﬁers used to identify a critical construct have external linkage and are in a name space 9
that is separate from the name spaces used by labels, tags, members, and ordinary identiﬁers. 10
C / C++
Fortran
The names of critical constructs are global entities of the program. If a name conﬂicts with 11
any other entity, the behavior of the program is unspeciﬁed. 12
Fortran
The threads of a contention group execute the critical region as if only one thread of the 13
contention group executes the critical region at a time. The critical construct enforces 14
these execution semantics with respect to all critical constructs with the same name in all 15
threads in the contention group. 16
If present, the hintclause gives the implementation additional information about the expected 17
runtime properties of the critical region that can optionally be used to optimize the 18
implementation. The presence of a hintclause does not aﬀect the isolation guarantees provided 19
by the critical construct. If no hintclause is speciﬁed, the eﬀect is as if 20
hint(omp_sync_hint_none) had been speciﬁed. 21
Execution Model Events 22
Thecritical-acquiring event occurs in a thread that encounters the critical construct on entry 23
to the critical region before initiating synchronization for the region. 24
Thecritical-acquired event occurs in a thread that encounters the critical construct after it 25
enters the region, but before it executes the structured block of the critical region. 26
Thecritical-released event occurs in a thread that encounters the critical construct after it 27
completes any synchronization on exit from the critical region. 28
224 OpenMP API – Version 5.0 November 2018
Tool Callbacks 1
A thread dispatches a registered ompt_callback_mutex_acquire callback for each 2
occurrence of a critical-acquiring event in that thread. This callback has the type signature 3
ompt_callback_mutex_acquire_t . 4
A thread dispatches a registered ompt_callback_mutex_acquired callback for each 5
occurrence of a critical-acquired event in that thread. This callback has the type signature 6
ompt_callback_mutex_t . 7
A thread dispatches a registered ompt_callback_mutex_released callback for each 8
occurrence of a critical-released event in that thread. This callback has the type signature 9
ompt_callback_mutex_t . 10
The callbacks occur in the task that encounters the critical construct. The callbacks should receive 11
ompt_mutex_critical as theirkindargument if practical, but a less speciﬁc kind is 12
acceptable. 13
Restrictions 14
The following restrictions apply to the critical construct: 15
Unless the eﬀect is as if hint(omp_sync_hint_none ) was speciﬁed, the critical 16
construct must specify a name. 17
If the hintclause is speciﬁed, each of the critical constructs with the same namemust 18
have a hintclause for which the hint-expression evaluates to the same value. 19
C++
A throw executed inside a critical region must cause execution to resume within the same 20
critical region, and the same thread that threw the exception must catch it. 21
C++
Fortran
If anameis speciﬁed on a critical directive, the same namemust also be speciﬁed on the 22
end critical directive. 23
If nonameappears on the critical directive, no namecan appear on the end critical 24
directive. 25
Fortran
CHAPTER 2. DIRECTIVES 225
Cross References 1
Synchronization Hints, see Section 2.17.12 on page 260. 2
ompt_mutex_critical , see Section 4.4.4.16 on page 445. 3
ompt_callback_mutex_acquire_t , see Section 4.5.2.14 on page 476. 4
ompt_callback_mutex_t , see Section 4.5.2.15 on page 477. 5
2.17.2 barrier Construct 6
Summary 7
Thebarrier construct speciﬁes an explicit barrier at the point at which the construct appears. 8
Thebarrier construct is a stand-alone directive. 9
Syntax 10
C / C++
The syntax of the barrier construct is as follows: 11
#pragma omp barrier new-line 12
C / C++
Fortran
The syntax of the barrier construct is as follows: 13
!$omp barrier 14
Fortran
Binding 15
The binding thread set for a barrier region is the current team. A barrier region binds to the 16
innermost enclosing parallel region. 17
Description 18
Allthreadsoftheteamthatisexecutingthebinding parallel regionmustexecutethe barrier 19
region and complete execution of all explicit tasks bound to this parallel region before any are 20
allowed to continue execution beyond the barrier. 21
Thebarrier region includes an implicit task scheduling point in the current task region. 22
226 OpenMP API – Version 5.0 November 2018
Execution Model Events 1
Theexplicit-barrier-begin event occurs in each thread that encounters the barrier construct on 2
entry to the barrier region. 3
Theexplicit-barrier-wait-begin event occurs when a task begins an interval of active or passive 4
waiting in a barrier region. 5
Theexplicit-barrier-wait-end event occurs when a task ends an interval of active or passive waiting 6
and resumes execution in a barrier region. 7
Theexplicit-barrier-end event occurs in each thread that encounters the barrier construct after 8
the barrier synchronization on exit from the barrier region. 9
Acancellation event occurs if cancellation is activated at an implicit cancellation point in a 10
barrier region. 11
Tool Callbacks 12
A thread dispatches a registered ompt_callback_sync_region callback with 13
ompt_sync_region_barrier_explicit — or ompt_sync_region_barrier , if the 14
implementation cannot make a distinction — as its kindargument and ompt_scope_begin as 15
itsendpoint argument for each occurrence of an explicit-barrier-begin event in the task that 16
encounters the barrier construct. Similarly, a thread dispatches a registered 17
ompt_callback_sync_region callback with 18
ompt_sync_region_barrier_explicit — or ompt_sync_region_barrier , if the 19
implementation cannot make a distinction — as its kindargument and ompt_scope_end as its 20
endpoint argument for each occurrence of an explicit-barrier-end event in the task that encounters 21
thebarrier construct. These callbacks occur in the task that encounters the barrier construct 22
and have the type signature ompt_callback_sync_region_t . 23
A thread dispatches a registered ompt_callback_sync_region_wait callback with 24
ompt_sync_region_barrier_explicit — or ompt_sync_region_barrier , if the 25
implementation cannot make a distinction — as its kindargument and ompt_scope_begin as 26
itsendpoint argument for each occurrence of an explicit-barrier-wait-begin event. Similarly, a 27
thread dispatches a registered ompt_callback_sync_region_wait callback with 28
ompt_sync_region_barrier_explicit — or ompt_sync_region_barrier , if the 29
implementation cannot make a distinction — as its kindargument and ompt_scope_end as its 30
endpoint argument for each occurrence of an explicit-barrier-wait-end event. These callbacks 31
occur in the context of the task that encountered the barrier construct and have type signature 32
ompt_callback_sync_region_t . 33
A thread dispatches a registered ompt_callback_cancel callback with 34
ompt_cancel_detected as itsﬂagsargument for each occurrence of a cancellation event in 35
that thread. The callback occurs in the context of the encountering task. The callback has type 36
signature ompt_callback_cancel_t . 37
CHAPTER 2. DIRECTIVES 227
Restrictions 1
The following restrictions apply to the barrier construct: 2
Eachbarrier region must be encountered by all threads in a team or by none at all, unless 3
cancellation has been requested for the innermost enclosing parallel region. 4
The sequence of worksharing regions and barrier regions encountered must be the same for 5
every thread in a team. 6
Cross References 7
ompt_scope_begin andompt_scope_end , see Section 4.4.4.11 on page 443. 8
ompt_sync_region_barrier , see Section 4.4.4.13 on page 444. 9
ompt_callback_sync_region_t , see Section 4.5.2.13 on page 474. 10
ompt_callback_cancel_t , see Section 4.5.2.18 on page 481. 11
2.17.3 Implicit Barriers 12
This section describes the OMPT events and tool callbacks associated with implicit barriers, which 13
occur at the end of various regions as deﬁned in the description of the constructs to which they 14
correspond. Implicit barriers are task scheduling points. For a description of task scheduling 15
points, associated events, and tool callbacks, see Section 2.10.6 on page 149. 16
Execution Model Events 17
Theimplicit-barrier-begin event occurs in each implicit task at the beginning of an implicit barrier 18
region. 19
Theimplicit-barrier-wait-begin event occurs when a task begins an interval of active or passive 20
waiting in an implicit barrier region. 21
Theimplicit-barrier-wait-end event occurs when a task ends an interval of active or waiting and 22
resumes execution of an implicit barrier region. 23
Theimplicit-barrier-end event occurs in each implicit task after the barrier synchronization on exit 24
from an implicit barrier region. 25
Acancellation event occurs if cancellation is activated at an implicit cancellation point in an 26
implicit barrier region. 27
228OpenMP API – Version 5.0 November 2018
Tool Callbacks 1
A thread dispatches a registered ompt_callback_sync_region callback with 2
ompt_sync_region_barrier_implicit — or ompt_sync_region_barrier , if the 3
implementation cannot make a distinction — as its kindargument and ompt_scope_begin as 4
itsendpoint argument for each occurrence of an implicit-barrier-begin event in that thread. 5
Similarly, a thread dispatches a registered ompt_callback_sync_region callback with 6
ompt_sync_region_barrier_implicit — or ompt_sync_region_barrier , if the 7
implementation cannot make a distinction — as its kindargument and ompt_scope_end as its 8
endpoint argument for each occurrence of an implicit-barrier-end event in that thread. These 9
callbacks occur in the implicit task that executes the parallel region and have the type signature 10
ompt_callback_sync_region_t . 11
A thread dispatches a registered ompt_callback_sync_region_wait callback with 12
ompt_sync_region_barrier_implicit — or ompt_sync_region_barrier , if the 13
implementation cannot make a distinction — as its kindargument and ompt_scope_begin as 14
itsendpoint argument for each occurrence of a implicit-barrier-wait-begin event in that thread. 15
Similarly, a thread dispatches a registered ompt_callback_sync_region_wait callback 16
withompt_sync_region_barrier_explicit — or ompt_sync_region_barrier , 17
if the implementation cannot make a distinction — as its kindargument and ompt_scope_end 18
as itsendpoint argument for each occurrence of an implicit-barrier-wait-end event in that thread. 19
These callbacks occur in the implicit task that executes the parallel region and have type signature 20
ompt_callback_sync_region_t . 21
A thread dispatches a registered ompt_callback_cancel callback with 22
ompt_cancel_detected as itsﬂagsargument for each occurrence of a cancellation event in 23
that thread. The callback occurs in the context of the encountering task. The callback has type 24
signature ompt_callback_cancel_t . 25
Restrictions 26
If a thread is in the state ompt_state_wait_barrier_implicit_parallel , a call to 27
ompt_get_parallel_info may return a pointer to a copy of the data object associated with 28
the parallel region rather than a pointer to the associated data object itself. Writing to the data 29
object returned by omp_get_parallel_info when a thread is in the 30
ompt_state_wait_barrier_implicit_parallel results in unspeciﬁed behavior. 31
Cross References 32
ompt_scope_begin andompt_scope_end , see Section 4.4.4.11 on page 443. 33
ompt_sync_region_barrier , see Section 4.4.4.13 on page 444 34
ompt_cancel_detected , see Section 4.4.4.24 on page 450. 35
ompt_callback_sync_region_t , see Section 4.5.2.13 on page 474. 36
ompt_callback_cancel_t , see Section 4.5.2.18 on page 481. 37
CHAPTER 2. DIRECTIVES 229
2.17.4 Implementation-Speciﬁc Barriers1
An OpenMP implementation can execute implementation-speciﬁc barriers that are not implied by 2
the OpenMP speciﬁcation; therefore, no execution model events are bound to these barriers. The 3
implementation can handle these barriers like implicit barriers and dispatch all events as for 4
implicit barriers. These callbacks are dispatched with 5
ompt_sync_region_barrier_implementation — or 6
ompt_sync_region_barrier , ifthe implementation cannotmake a distinction —as the kind 7
argument. 8
2.17.5 taskwait Construct 9
Summary 10
Thetaskwait construct speciﬁes a wait on the completion of child tasks of the current task. The 11
taskwait construct is a stand-alone directive. 12
Syntax 13
C / C++
The syntax of the taskwait construct is as follows: 14
#pragma omp taskwait [clause[ [ ,] clause] ... ] new-line 15
whereclauseis one of the following: 16
depend( [depend-modiﬁer ,]dependence-type :locator-list ) 17
C / C++
Fortran
The syntax of the taskwait construct is as follows: 18
!$omp taskwait [clause[ [ ,] clause] ... ] 19
whereclauseis one of the following: 20
depend( [depend-modiﬁer ,]dependence-type :locator-list ) 21
Fortran
Binding 22
Thetaskwait region binds to the current task region. The binding thread set of the taskwait 23
region is the current team. 24
230 OpenMP API – Version 5.0 November 2018
Description 1
If nodepend clause is present on the taskwait construct, the current task region is suspended 2
at an implicit task scheduling point associated with the construct. The current task region remains 3
suspended until all child tasks that it generated before the taskwait region complete execution. 4
Otherwise, if one or more depend clauses are present on the taskwait construct, the behavior 5
is as if these clauses were applied to a taskconstruct with an empty associated structured block 6
that generates a mergeable andincluded task . Thus, the current task region is suspended until the 7
predecessor tasks of this task complete execution. 8
Execution Model Events 9
Thetaskwait-begin event occurs in each thread that encounters the taskwait construct on entry 10
to the taskwait region. 11
Thetaskwait-wait-begin event occurs when a task begins an interval of active or passive waiting in 12
ataskwait region. 13
Thetaskwait-wait-end event occurs when a task ends an interval of active or passive waiting and 14
resumes execution in a taskwait region. 15
Thetaskwait-end event occurs in each thread that encounters the taskwait construct after the 16
taskwait synchronization on exit from the taskwait region. 17
Tool Callbacks 18
A thread dispatches a registered ompt_callback_sync_region callback with 19
ompt_sync_region_taskwait as itskindargument and ompt_scope_begin as its 20
endpoint argument for each occurrence of a taskwait-begin event in the task that encounters the 21
taskwait construct. Similarly, a thread dispatches a registered 22
ompt_callback_sync_region callback with ompt_sync_region_taskwait as its 23
kindargument and ompt_scope_end as itsendpoint argument for each occurrence of a 24
taskwait-end event in the task that encounters the taskwait construct. These callbacks occur in 25
the task that encounters the taskwait construct and have the type signature 26
ompt_callback_sync_region_t . 27
A thread dispatches a registered ompt_callback_sync_region_wait callback with 28
ompt_sync_region_taskwait as itskindargument and ompt_scope_begin as its 29
endpoint argument for each occurrence of a taskwait-wait-begin event. Similarly, a thread 30
dispatches a registered ompt_callback_sync_region_wait callback with 31
ompt_sync_region_taskwait as itskindargument and ompt_scope_end as itsendpoint 32
argument for each occurrence of a taskwait-wait-end event. These callbacks occur in the context of 33
the task that encounters the taskwait construct and have type signature 34
ompt_callback_sync_region_t . 35
CHAPTER 2. DIRECTIVES 231
Restrictions 1
The following restrictions apply to the taskwait construct: 2
Themutexinoutset dependence-type may not appear in a depend clause on a taskwait 3
construct. 4
If thedependence-type of adepend clause is depobj then the dependence objects cannot 5
represent dependences of the mutexinoutset dependence type. 6
Cross References 7
taskconstruct, see Section 2.10.1 on page 135. 8
Task scheduling, see Section 2.10.6 on page 149. 9
depend clause, see Section 2.17.11 on page 255. 10
ompt_scope_begin andompt_scope_end , see Section 4.4.4.11 on page 443. 11
ompt_sync_region_taskwait , see Section 4.4.4.13 on page 444. 12
ompt_callback_sync_region_t , see Section 4.5.2.13 on page 474. 13
2.17.6 taskgroup Construct 14
Summary 15
Thetaskgroup construct speciﬁes a wait on completion of child tasks of the current task and 16
their descendent tasks. 17
Syntax 18
C / C++
The syntax of the taskgroup construct is as follows: 19
#pragma omp taskgroup [clause[[ ,] clause] ...] new-line 20
structured-block 21
whereclauseis one of the following: 22
task_reduction( reduction-identiﬁer :list) 23
allocate( [allocator: ]list ) 24
C / C++
232 OpenMP API – Version 5.0 November 2018
Fortran
The syntax of the taskgroup construct is as follows: 1
!$omp taskgroup [clause [ [ ,] clause] ...] 2
structured-block 3
!$omp end taskgroup 4
whereclauseis one of the following: 5
task_reduction( reduction-identiﬁer :list) 6
allocate( [allocator: ]list ) 7
Fortran
Binding 8
The binding task set of a taskgroup region is all tasks of the current team that are generated in 9
the region. A taskgroup region binds to the innermost enclosing parallel region. 10
Description 11
When a thread encounters a taskgroup construct, it starts executing the region. All child tasks 12
generated in the taskgroup region and all of their descendants that bind to the same parallel 13
region as the taskgroup region are part of the taskgroup set associated with the taskgroup 14
region. 15
There is an implicit task scheduling point at the end of the taskgroup region. The current task is 16
suspended at the task scheduling point until all tasks in the taskgroup set complete execution. 17
Execution Model Events 18
Thetaskgroup-begin event occurs in each thread that encounters the taskgroup construct on 19
entry to the taskgroup region. 20
Thetaskgroup-wait-begin event occurs when a task begins an interval of active or passive waiting 21
in ataskgroup region. 22
Thetaskgroup-wait-end event occurs when a task ends an interval of active or passive waiting and 23
resumes execution in a taskgroup region. 24
Thetaskgroup-end event occurs in each thread that encounters the taskgroup construct after the 25
taskgroup synchronization on exit from the taskgroup region. 26
CHAPTER 2. DIRECTIVES 233
Tool Callbacks 1
A thread dispatches a registered ompt_callback_sync_region callback with 2
ompt_sync_region_taskgroup as itskindargument and ompt_scope_begin as its 3
endpoint argument for each occurrence of a taskgroup-begin event in the task that encounters the 4
taskgroup construct. Similarly, a thread dispatches a registered 5
ompt_callback_sync_region callback with ompt_sync_region_taskgroup as its 6
kindargument and ompt_scope_end as itsendpoint argument for each occurrence of a 7
taskgroup-end event in the task that encounters the taskgroup construct. These callbacks occur 8
in the task that encounters the taskgroup construct and have the type signature 9
ompt_callback_sync_region_t . 10
A thread dispatches a registered ompt_callback_sync_region_wait callback with 11
ompt_sync_region_taskgroup as itskindargument and ompt_scope_begin as its 12
endpoint argument for each occurrence of a taskgroup-wait-begin event. Similarly, a thread 13
dispatches a registered ompt_callback_sync_region_wait callback with 14
ompt_sync_region_taskgroup as itskindargument and ompt_scope_end as its 15
endpoint argument for each occurrence of a taskgroup-wait-end event. These callbacks occur in the 16
context of the task that encounters the taskgroup construct and have type signature 17
ompt_callback_sync_region_t . 18
Cross References 19
Task scheduling, see Section 2.10.6 on page 149. 20
task_reduction Clause, see Section 2.19.5.5 on page 303. 21
ompt_scope_begin andompt_scope_end , see Section 4.4.4.11 on page 443. 22
ompt_sync_region_taskgroup , see Section 4.4.4.13 on page 444. 23
ompt_callback_sync_region_t , see Section 4.5.2.13 on page 474. 24
2.17.7 atomic Construct 25
Summary 26
Theatomic construct ensures that a speciﬁc storage location is accessed atomically, rather than 27
exposing it to the possibility of multiple, simultaneous reading and writing threads that may result 28
in indeterminate values. 29
234OpenMP API – Version 5.0 November 2018
Syntax 1
Inthefollowingsyntax, atomic-clause isaclausethatindicatesthesemanticsforwhichatomicityis 2
enforced, memory-order-clause is a clause that indicates the memory ordering behavior of the 3
construct and clauseis a clause other than atomic-clause . Speciﬁcally, atomic-clause is one of the 4
following: 5
read 6
write 7
update 8
capture 9
memory-order-clause is one of the following: 10
seq_cst 11
acq_rel 12
release 13
acquire 14
relaxed 15
andclauseis eithermemory-order-clause or one of the following: 16
hint(hint-expression ) 17
C / C++
The syntax of the atomic construct takes one of the following forms: 18
#pragma omp atomic [clause[[[ ,] clause] ... ] [ ,]] atomic-clause 19
[[,] clause [[[ ,] clause] ... ]] new-line 20
expression-stmt 21
or 22
#pragma omp atomic [clause[[ ,] clause] ... ] new-line 23
expression-stmt 24
or 25
#pragma omp atomic [clause[[[ ,] clause] ... ] [ ,]]capture 26
[[,] clause [[[ ,] clause] ... ]] new-line 27
structured-block 28
whereexpression-stmt is an expression statement with one of the following forms: 29
Ifatomic-clause isread: 30
v=x; 31
CHAPTER 2. DIRECTIVES 235
C/C++ (cont.)
Ifatomic-clause iswrite: 1
x=expr; 2
Ifatomic-clause isupdate or not present: 3
x++; 4
x--; 5
++x; 6
--x; 7
x binop =expr; 8
x=x binop expr ; 9
x=expr binop x ; 10
Ifatomic-clause iscapture : 11
v=x++; 12
v=x--; 13
v= ++x; 14
v= --x; 15
v=x binop =expr; 16
v=x=x binop expr ; 17
v=x=expr binop x ; 18
and where structured-block is a structured block with one of the following forms: 19
{v=x;x binop =expr; } 20
{x binop =expr;v=x; } 21
{v=x;x=x binop expr ; } 22
{v=x;x=expr binop x ; } 23
{x=x binop expr ;v=x; } 24
{x=expr binop x ;v=x; } 25
{v=x;x=expr; } 26
{v=x;x++; } 27
{v=x; ++x; } 28
{ ++x;v=x; } 29
{x++;v=x; } 30
{v=x;x--; } 31
{v=x; --x; } 32
{ --x;v=x; } 33
{x--;v=x; } 34
In the preceding expressions: 35
xandv(as applicable) are both l-valueexpressions with scalar type. 36
During the execution of an atomic region, multiple syntactic occurrences of xmust designate the 37
same storage location. 38
236 OpenMP API – Version 5.0 November 2018
Neither of vandexpr(as applicable) may access the storage location designated by x. 1
Neither of xandexpr(as applicable) may access the storage location designated by v. 2
expris an expression with scalar type. 3
binopis one of +,*,-,/,&,^,|,<<, or>>. 4
binop,binop =,++, and--are not overloaded operators. 5
The expression x binop expr must be numerically equivalent to x binop (expr) . This requirement 6
is satisﬁed if the operators in exprhave precedence greater than binop, or by using parentheses 7
aroundexpror subexpressions of expr. 8
The expression expr binop x must be numerically equivalent to (expr) binop x . This requirement 9
is satisﬁed if the operators in exprhave precedence equal to or greater than binop, or by using 10
parentheses around expror subexpressions of expr. 11
For forms that allow multiple occurrences of x, the number of times that xis evaluated is 12
unspeciﬁed. 13
hint-expression is a constant integer expression that evaluates to a valid synchronization hint. 14
C / C++
Fortran
The syntax of the atomic construct takes any of the following forms: 15
!$omp atomic [clause[[[ ,] clause] ... ] [ ,]]read[[,] clause [[[ ,] clause] ... ]] 16
capture-statement 17
[!$omp end atomic ] 18
or 19
!$omp atomic [clause[[[ ,] clause] ... ] [ ,]]write[[,] clause [[[ ,] clause] ... ]] 20
write-statement 21
[!$omp end atomic ] 22
or 23
!$omp atomic [clause[[[ ,] clause] ... ] [ ,]]update [[,] clause [[[ ,] clause] ... ]] 24
update-statement 25
[!$omp end atomic ] 26
or 27
!$omp atomic [clause[[ ,] clause] ... ] 28
update-statement 29
[!$omp end atomic ] 30
or 31
CHAPTER 2. DIRECTIVES 237
Fortran (cont.)
!$omp atomic [clause[[[ ,] clause] ... ] [ ,]]capture [[,] clause [[[ ,] clause] ... ]] 1
update-statement 2
capture-statement 3
!$omp end atomic 4
or 5
!$omp atomic [clause[[[ ,] clause] ... ] [ ,]]capture [[,] clause [[[ ,] clause] ... ]] 6
capture-statement 7
update-statement 8
!$omp end atomic 9
or 10
!$omp atomic [clause[[[ ,] clause] ... ] [ ,]]capture [[,] clause [[[ ,] clause] ... ]] 11
capture-statement 12
write-statement 13
!$omp end atomic 14
wherewrite-statement has the following form (if atomic-clause iscapture orwrite): 15
x=expr 16
wherecapture-statement has the following form (if atomic-clause iscapture orread): 17
v=x 18
and where update-statement has one of the following forms (if atomic-clause isupdate, 19
capture , or not present): 20
x=x operator expr 21
22
x=expr operator x 23
24
x=intrinsic_procedure_name (x,expr_list ) 25
26
x=intrinsic_procedure_name (expr_list ,x) 27
In the preceding statements: 28
xandv(as applicable) are both scalar variables of intrinsic type. 29
xmust not have the ALLOCATABLE attribute. 30
During the execution of an atomic region, multiple syntactic occurrences of xmust designate the 31
same storage location. 32
None ofv,expr, andexpr_list (as applicable) may access the same storage location as x. 33
238 OpenMP API – Version 5.0 November 2018
None ofx,expr, andexpr_list (as applicable) may access the same storage location as v. 1
expris a scalar expression. 2
expr_list is a comma-separated, non-empty list of scalar expressions. If 3
intrinsic_procedure_name refers to IAND,IOR, orIEOR, exactly one expression must appear in 4
expr_list. 5
intrinsic_procedure_name is one of MAX,MIN,IAND,IOR, orIEOR. 6
operator is one of +,*,-,/,.AND.,.OR.,.EQV., or.NEQV.. 7
The expression x operator expr must be numerically equivalent to x operator (expr) . This 8
requirement is satisﬁed if the operators in exprhave precedence greater than operator, or by 9
using parentheses around expror subexpressions of expr. 10
The expression expr operator x must be numerically equivalent to (expr) operator x . This 11
requirement is satisﬁed if the operators in exprhave precedence equal to or greater than 12
operator, or by using parentheses around expror subexpressions of expr. 13
intrinsic_procedure_name must refer to the intrinsic procedure name and not to other program 14
entities. 15
operator must refer to the intrinsic operator and not to a user-deﬁned operator. 16
All assignments must be intrinsic assignments. 17
For forms that allow multiple occurrences of x, the number of times that xis evaluated is 18
unspeciﬁed. 19
hint-expression is a constant expression that evaluates to a scalar value with kind 20
omp_sync_hint_kind and a value that is a valid synchronization hint. 21
Fortran
Binding 22
If the size of xis 8, 16, 32, or64 bits and xis aligned to amultiple of its size, the binding threadset 23
for the atomic region is all threads on the device. Otherwise, the binding thread set for the 24
atomic region is all threads in the contention group. atomic regions enforce exclusive access 25
with respect to other atomic regions that access the same storage location xamong all threads in 26
the binding thread set without regard to the teams to which the threads belong. 27
Description 28
Ifatomic-clause isnotpresentontheconstruct,thebehaviorisasifthe update clauseisspeciﬁed. 29
Theatomic construct with the readclause results in an atomic read of the location designated 30
byxregardless of the native machine word size. 31
CHAPTER 2. DIRECTIVES 239
Theatomic constructwiththe writeclauseresultsinanatomicwriteofthelocationdesignated 1
byxregardless of the native machine word size. 2
Theatomic construct with the update clause results in an atomic update of the location 3
designated by xusing the designated operator or intrinsic. Only the read and write of the location 4
designated by xare performed mutually atomically. The evaluation of exprorexpr_list need not be 5
atomic with respect to the read or write of the location designated by x. No task scheduling points 6
are allowed between the read and the write of the location designated by x. 7
Theatomic construct with the capture clause results in an atomic captured update — an 8
atomic update of the location designated by xusing the designated operator or intrinsic while also 9
capturing the original or ﬁnal value of the location designated by xwith respect to the atomic 10
update. The original or ﬁnal value of the location designated by xis written in the location 11
designated by vbased on the base language semantics of structured block or statements of the 12
atomic construct. Only the read and write of the location designated by xare performed mutually 13
atomically. Neithertheevaluationof exprorexpr_list,northewritetothelocationdesignatedby v, 14
need be atomic with respect to the read or write of the location designated by x. No task scheduling 15
points are allowed between the read and the write of the location designated by x. 16
Theatomic construct may be used to enforce memory consistency between threads, based on the 17
guarantees provided by Section 1.4.6 on page 28. A strong ﬂush on the location designated by xis 18
performed on entry to and exit from the atomic operation, ensuring that the set of all atomic 19
operations in the program applied to the same location has a total completion order. If the write, 20
update, orcapture clause is speciﬁed and the release ,acq_rel , orseq_cst clause is 21
speciﬁed then the strong ﬂush on entry to the atomic operation is also a release ﬂush. If the read 22
orcapture clause is speciﬁed and the acquire ,acq_rel , orseq_cst clause is speciﬁed 23
then the strong ﬂush on exit from the atomic operation is also an acquire ﬂush. Therefore, if 24
memory-order-clause is speciﬁed and is not relaxed , release and/or acquire ﬂush operations are 25
implied and permit synchronization between the threads without the use of explicit flush 26
directives. 27
For all forms of the atomic construct, any combination of two or more of these atomic 28
constructs enforces mutually exclusive access to the locations designated by xamong threads in the 29
binding thread set. To avoid data races, all accesses of the locations designated by xthat could 30
potentially occur in parallel must be protected with an atomic construct. 31
atomic regions do not guarantee exclusive access with respect to any accesses outside of 32
atomic regions to the same storage location xeven if those accesses occur during a critical 33
orordered region, while an OpenMP lock is owned by the executing task, or during the 34
execution of a reduction clause. 35
However, other OpenMP synchronization can ensure the desired exclusive access. For example, a 36
barrier that follows a series of atomic updates to xguarantees that subsequent accesses do not form 37
a race with the atomic accesses. 38
A compliant implementation may enforce exclusive access between atomic regions that update 39
diﬀerent storage locations. The circumstances under which this occurs are implementation deﬁned. 40
240 OpenMP API – Version 5.0 November 2018
If the storage location designated by xis not size-aligned (that is, if the byte alignment of xis not a 1
multiple of the size of x), then the behavior of the atomic region is implementation deﬁned. 2
If present, the hintclause gives the implementation additional information about the expected 3
properties of the atomic operation that can optionally be used to optimize the implementation. The 4
presence of a hintclause does not aﬀect the semantics of the atomic construct, and all hints 5
may be ignored. If no hintclause is speciﬁed, the eﬀect is as if 6
hint(omp_sync_hint_none) had been speciﬁed. 7
Execution Model Events 8
Theatomic-acquiring event occurs in the thread that encounters the atomic construct on entry to 9
the atomic region before initiating synchronization for the region. 10
Theatomic-acquired event occurs in the thread that encounters the atomic construct after it 11
enters the region, but before it executes the structured block of the atomic region. 12
Theatomic-released event occurs in the thread that encounters the atomic construct after it 13
completes any synchronization on exit from the atomic region. 14
Tool Callbacks 15
A thread dispatches a registered ompt_callback_mutex_acquire callback for each 16
occurrence of an atomic-acquiring event in that thread. This callback has the type signature 17
ompt_callback_mutex_acquire_t . 18
A thread dispatches a registered ompt_callback_mutex_acquired callback for each 19
occurrence of an atomic-acquired event in that thread. This callback has the type signature 20
ompt_callback_mutex_t . 21
A thread dispatches a registered ompt_callback_mutex_released callback with 22
ompt_mutex_atomic as thekindargument if practical, although a less speciﬁc kindmay be 23
used, for each occurrence of an atomic-released event in that thread. This callback has the type 24
signature ompt_callback_mutex_t and occurs in the task that encounters the atomic 25
construct. 26
Restrictions 27
The following restrictions apply to the atomic construct: 28
OpenMP constructs may not be encountered during execution of an atomic region. 29
At most one memory-order-clause may appear on the construct. 30
At most one hintclause may appear on the construct. 31
Ifatomic-clause isreadthenmemory-order-clause must not be acq_rel orrelease . 32
CHAPTER 2. DIRECTIVES 241
Ifatomic-clause iswritethenmemory-order-clause must not be acq_rel oracquire . 1
Ifatomic-clause isupdate or not present then memory-order-clause must not be acq_rel or 2
acquire . 3
C / C++
All atomic accesses to the storage locations designated by xthroughout the program are required 4
to have a compatible type. 5
C / C++
Fortran
All atomic accesses to the storage locations designated by xthroughout the program are required 6
to have the same type and type parameters. 7
Fortran
Cross References 8
critical construct, see Section 2.17.1 on page 223. 9
barrier construct, see Section 2.17.2 on page 226. 10
flushconstruct, see Section 2.17.8 on page 242. 11
ordered construct, see Section 2.17.9 on page 250. 12
Synchronization Hints, see Section 2.17.12 on page 260. 13
reduction clause, see Section 2.19.5.4 on page 300. 14
lock routines, see Section 3.3 on page 381. 15
ompt_mutex_atomic , see Section 4.4.4.16 on page 445. 16
ompt_callback_mutex_acquire_t , see Section 4.5.2.14 on page 476. 17
ompt_callback_mutex_t , see Section 4.5.2.15 on page 477. 18
2.17.8 flush Construct 19
Summary 20
Theflushconstruct executes the OpenMP ﬂush operation. This operation makes a thread’s 21
temporary view of memory consistent with memory and enforces an order on the memory 22
operations of the variables explicitly speciﬁed or implied. See the memory model description in 23
Section 1.4 on page 23 for more details. The flushconstruct is a stand-alone directive. 24
242OpenMP API – Version 5.0 November 2018
Syntax 1
C / C++
The syntax of the flushconstruct is as follows: 2
#pragma omp flush [memory-order-clause] [ (list)] new-line 3
wherememory-order-clause is one of the following: 4
acq_rel 5
release 6
acquire 7
C / C++
Fortran
The syntax of the flushconstruct is as follows: 8
!$omp flush [memory-order-clause] [ (list)] 9
wherememory-order-clause is one of the following: 10
acq_rel 11
release 12
acquire 13
Fortran
Binding 14
The binding thread set for a flushregion is the encountering thread. Execution of a flush 15
region aﬀects the memory and the temporary view of memory of only the thread that executes the 16
region. It does not aﬀect the temporary view of other threads. Other threads must themselves 17
execute a ﬂush operation in order to be guaranteed to observe the eﬀects of the ﬂush operation of 18
the encountering thread. 19
Description 20
Ifmemory-order-clause isnotspeciﬁedthenthe flushconstructresultsinastrongﬂushoperation 21
withthefollowingbehavior. A flushconstructwithoutalist,executedonagiventhread,operates 22
as if the whole thread-visible data state of the program, as deﬁned by the base language, is ﬂushed. 23
Aflushconstruct with a list applies the ﬂush operation to the items in the list, and the ﬂush 24
operation does not complete until the operation is complete for all speciﬁed list items. An 25
implementation may implement a flushwith a list by ignoring the list, and treating it the same as 26
aflushwithout a list. 27
CHAPTER 2. DIRECTIVES 243
If no list items are speciﬁed, the ﬂush operation has the release and/or acquire ﬂush properties: 1
Ifmemory-order-clause is not speciﬁed or is acq_rel , the ﬂush operation is both a release 2
ﬂush and an acquire ﬂush. 3
Ifmemory-order-clause isrelease , the ﬂush operation is a release ﬂush. 4
Ifmemory-order-clause isacquire , the ﬂush operation is an acquire ﬂush. 5
C / C++
If a pointer is present in the list, the pointer itself is ﬂushed, not the memory block to which the 6
pointer refers. 7
C / C++
Fortran
If the list item or a subobject of the list item has the POINTER attribute, the allocation or 8
association status of the POINTER item is ﬂushed, but the pointer target is not. If the list item is a 9
Cray pointer, the pointer is ﬂushed, but the object to which it points is not. If the list item is of type 10
C_PTR,thevariableisﬂushed,butthestoragethatcorrespondstothataddressisnotﬂushed. Ifthe 11
list item or the subobject of the list item has the ALLOCATABLE attribute and has an allocation 12
status of allocated, the allocated variable is ﬂushed; otherwise the allocation status is ﬂushed. 13
Fortran
14
Note– Use of a flushconstruct with a list is extremely error prone and users are strongly 15
discouraged from attempting it. The following examples illustrate the ordering properties of the 16
ﬂush operation. In the following incorrect pseudocode example, the programmer intends to prevent 17
simultaneous execution of the protected section by the two threads, but the program does not work 18
properly because it does not enforce the proper ordering of the operations on variables aandb. 19
Any shared data accessed in the protected section is not guaranteed to be current or consistent 20
during or after the protected section. The atomic notation in the pseudocode in the following two 21
examples indicates that the accesses to aandbare atomic write and atomic read operations. 22
Otherwisebothexampleswouldcontaindataracesandautomaticallyresultinunspeciﬁedbehavior. 23
Theﬂushoperations are strong ﬂushes that are applied to the speciﬁed ﬂush lists 24
244 OpenMP API – Version 5.0 November 2018
Incorrect example:
a = b = 0
thread 1 thread 2
atomic(b = 1) atomic(a = 1)
ﬂush(b) ﬂush(a)
ﬂush(a) ﬂush(b)
atomic(tmp = a) atomic(tmp = b)
if (tmp == 0) then if (tmp == 0) then
protected section protected section
end if end if1
The problem with this example is that operations on variables aandbare not ordered with respect 2
toeachother. Forinstance,nothingpreventsthecompilerfrommovingtheﬂushof bonthread1or 3
the ﬂush of aon thread 2 to a position completely after the protected section (assuming that the 4
protected section on thread 1 does not reference band the protected section on thread 2 does not 5
reference a). If either re-ordering happens, both threads can simultaneously execute the protected 6
section. 7
The following pseudocode example correctly ensures that the protected section is executed by not 8
more than one of the two threads at any one time. Execution of the protected section by neither 9
thread is considered correct in this example. This occurs if both ﬂushes complete prior to either 10
thread executing its ifstatement. 11
Correct example:
a = b = 0
thread 1 thread 2
atomic(b = 1) atomic(a = 1)
ﬂush(a,b) ﬂush(a,b)
atomic(tmp = a) atomic(tmp = b)
if (tmp == 0) then if (tmp == 0) then
protected section protected section
end if end if12
CHAPTER 2. DIRECTIVES 245
The compiler is prohibited from moving the ﬂush at all for either thread, ensuring that the 1
respective assignment is complete and the data is ﬂushed before the ifstatement is executed. 2
3
4
Execution Model Events 5
Theﬂushevent occurs in a thread that encounters the flushconstruct. 6
Tool Callbacks 7
A thread dispatches a registered ompt_callback_flush callback for each occurrence of a 8
ﬂushevent in that thread. This callback has the type signature ompt_callback_flush_t . 9
Restrictions 10
The following restrictions apply to the flushconstruct: 11
Ifmemory-order-clause isrelease ,acquire , oracq_rel , list items must not be speciﬁed 12
on the flushdirective. 13
Cross References 14
ompt_callback_flush_t , see Section 4.5.2.17 on page 480. 15
2.17.8.1 Implicit Flushes 16
Flush operations implied when executing an atomic region are described in Section 2.17.7. 17
Aflushregion that corresponds to a flushdirective with the release clause present is 18
implied at the following locations: 19
During a barrier region; 20
At entry to a parallel region; 21
At entry to a teamsregion; 22
At exit from a critical region; 23
During an omp_unset_lock region; 24
During an omp_unset_nest_lock region; 25
Immediately before every task scheduling point; 26
246 OpenMP API – Version 5.0 November 2018
At exit from the task region of each implicit task; 1
At exit from an ordered region, if a threads clause or a depend clause with a source 2
dependence type is present, or if no clauses are present; and 3
During a cancel region, if the cancel-var ICV istrue. 4
Aflushregion that corresponds to a flushdirective with the acquire clause present is 5
implied at the following locations: 6
During a barrier region; 7
At exit from a teamsregion; 8
At entry to a critical region; 9
If the region causes the lock to be set, during: 10
–anomp_set_lock region; 11
–anomp_test_lock region; 12
–anomp_set_nest_lock region; and 13
–anomp_test_nest_lock region; 14
Immediately after every task scheduling point; 15
At entry to the task region of each implicit task; 16
At entry to an ordered region, if a threads clause or a depend clause with a sink 17
dependence type is present, or if no clauses are present; and 18
Immediately before a cancellation point, if the cancel-var ICV istrueand cancellation has been 19
activated. 20
21
Note– Aflushregion is not implied at the following locations: 22
At entry to worksharing regions; and 23
At entry to or exit from master regions. 24
25
The synchronization behavior of implicit ﬂushes is as follows: 26
When a thread executes an atomic region for which the corresponding construct has the 27
release ,acq_rel , orseq_cst clause and speciﬁes an atomic operation that starts a given 28
release sequence, the release ﬂush that is performed on entry to the atomic operation 29
synchronizes with an acquire ﬂush that is performed by a diﬀerent thread and has an associated 30
atomic operation that reads a value written by a modiﬁcation in the release sequence. 31
CHAPTER 2. DIRECTIVES 247
When a thread executes an atomic region for which the corresponding construct has the 1
acquire ,acq_rel , orseq_cst clause and speciﬁes an atomic operation that reads a value 2
written by a given modiﬁcation, a release ﬂush that is performed by a diﬀerent thread and has an 3
associated release sequence that contains that modiﬁcation synchronizes with the acquire ﬂush 4
that is performed on exit from the atomic operation. 5
When a thread executes a critical region that has a given name, the behavior is as if the 6
releaseﬂushperformedonexitfromtheregionsynchronizeswiththeacquireﬂushperformedon 7
entry to the next critical region with the same name that is performed by a diﬀerent thread, 8
if it exists. 9
When a thread team executes a barrier region, the behavior is as if the release ﬂush 10
performed by each thread within the region synchronizes with the acquire ﬂush performed by all 11
other threads within the region. 12
When a thread executes a taskwait region that does not result in the creation of a dependent 13
task,thebehaviorisasifeachthreadthatexecutesaremainingchildtaskperformsareleaseﬂush 14
upon completion of the child task that synchronizes with an acquire ﬂush performed in the 15
taskwait region. 16
When a thread executes a taskgroup region, the behavior is as if each thread that executes a 17
remaining descendant task performs a release ﬂush upon completion of the descendant task that 18
synchronizes with an acquire ﬂush performed on exit from the taskgroup region. 19
When a thread executes an ordered region that does not arise from a stand-alone ordered 20
directive, the behavior is as if the release ﬂush performed on exit from the region synchronizes 21
with the acquire ﬂush performed on entry to an ordered region encountered in the next logical 22
iteration to be executed by a diﬀerent thread, if it exists. 23
When a thread executes an ordered region that arises from a stand-alone ordered directive, 24
the behavior is as if the release ﬂush performed in the ordered region from a given source 25
iteration synchronizes with the acquire ﬂush performed in all ordered regions executed by a 26
diﬀerent thread that are waiting for dependences on that iteration to be satisﬁed. 27
When a thread team begins execution of a parallel region, the behavior is as if the release 28
ﬂush performed by the master thread on entry to the parallel region synchronizes with the 29
acquire ﬂush performed on entry to each implicit task that is assigned to a diﬀerent thread. 30
When an initial thread begins execution of a target region that is generated by a diﬀerent 31
thread from a target task, the behavior is as if the release ﬂush performed by the generating 32
thread in the target task synchronizes with the acquire ﬂush performed by the initial thread on 33
entry to its initial task region. 34
When an initial thread completes execution of a target region that is generated by a diﬀerent 35
thread from a target task, the behavior is as if the release ﬂush performed by the initial thread on 36
exit from its initial task region synchronizes with the acquire ﬂush performed by the generating 37
thread in the target task. 38
248 OpenMP API – Version 5.0 November 2018
Whenathreadencountersa teamsconstruct,thebehaviorisasifthereleaseﬂushperformedby 1
the thread on entry to the teamsregion synchronizes with the acquire ﬂush performed on entry 2
toeachinitialtaskthatisexecutedbyadiﬀerentinitialthreadthatparticipatesintheexecutionof 3
theteamsregion. 4
When a thread that encounters a teamsconstruct reaches the end of the teamsregion, the 5
behavior is as if the release ﬂush performed by each diﬀerent participating initial thread at exit 6
from its initial task synchronizes with the acquire ﬂush performed by the thread at exit from the 7
teamsregion. 8
When a task generates an explicit task that begins execution on a diﬀerent thread, the behavior is 9
as if the thread that is executing the generating task performs a release ﬂush that synchronizes 10
with the acquire ﬂush performed by the thread that begins to execute the explicit task. 11
When an undeferred task completes execution on a given thread that is diﬀerent from the thread 12
on which its generating task is suspended, the behavior is as if a release ﬂush performed by the 13
thread that completes execution of the undeferred task synchronizes with an acquire ﬂush 14
performed by the thread that resumes execution of the generating task. 15
When a dependent task with one or more predecessor tasks begins execution on a given thread, 16
the behavior is as if each release ﬂush performed by a diﬀerent thread on completion of a 17
predecessor task synchronizes with the acquire ﬂush performed by the thread that begins to 18
execute the dependent task. 19
When a task begins execution on a given thread and it is mutually exclusive with respect to 20
another sibling task that is executed by a diﬀerent thread, the behavior is as if each release ﬂush 21
performed on completion of the sibling task synchronizes with the acquire ﬂush performed by 22
the thread that begins to execute the task. 23
When a thread executes a cancel region, the cancel-var ICV istrue, and cancellation is not 24
already activated for the speciﬁed region, the behavior is as if the release ﬂush performed during 25
thecancel region synchronizes with the acquire ﬂush performed by a diﬀerent thread 26
immediately before a cancellation point in which that thread observes cancellation was activated 27
for the region. 28
Whenathreadexecutesan omp_unset_lock regionthatcausesthespeciﬁedlocktobeunset, 29
the behavior is as if a release ﬂush is performed during the omp_unset_lock region that 30
synchronizes with an acquire ﬂush that is performed during the next omp_set_lock or 31
omp_test_lock regiontobeexecutedbyadiﬀerentthreadthatcausesthespeciﬁedlocktobe 32
set. 33
When a thread executes an omp_unset_nest_lock region that causes the speciﬁed nested 34
lock to be unset, the behavior is as if a release ﬂush is performed during the 35
omp_unset_nest_lock region that synchronizes with an acquire ﬂush that is performed 36
during the next omp_set_nest_lock oromp_test_nest_lock region to be executed by 37
a diﬀerent thread that causes the speciﬁed nested lock to be set. 38
CHAPTER 2. DIRECTIVES 249
2.17.9 ordered Construct 1
Summary 2
Theordered construct either speciﬁes a structured block in a worksharing-loop, simd, or 3
worksharing-loop SIMD region that will be executed in the order of the loop iterations, or it is a 4
stand-alone directive that speciﬁes cross-iteration dependences in a doacross loop nest. The 5
ordered construct sequentializes and orders the execution of ordered regions while allowing 6
code outside the region to run in parallel. 7
Syntax 8
C / C++
The syntax of the ordered construct is as follows: 9
#pragma omp ordered [clause[ [ ,] clause] ] new-line 10
structured-block 11
whereclauseis one of the following: 12
threads 13
simd 14
or 15
#pragma omp ordered clause [[[ ,] clause] ... ] new-line 16
whereclauseis one of the following: 17
depend(source) 18
depend(sink : vec) 19
C / C++
Fortran
The syntax of the ordered construct is as follows: 20
!$omp ordered [clause[ [ ,] clause] ] 21
structured-block 22
!$omp end ordered 23
whereclauseis one of the following: 24
threads 25
simd 26
or 27
!$omp ordered clause [[[ ,] clause] ... ] 28
250 OpenMP API – Version 5.0 November 2018
whereclauseis one of the following: 1
depend(source) 2
depend(sink : vec) 3
Fortran
If the depend clause is speciﬁed, the ordered construct is a stand-alone directive. 4
Binding 5
The binding thread set for an ordered region is the current team. An ordered region binds to 6
theinnermostenclosing simdorworksharing-loopSIMDregionifthe simdclauseispresent,and 7
otherwiseitbindstotheinnermostenclosingworksharing-loopregion. ordered regionsthatbind 8
to diﬀerent regions execute independently of each other. 9
Description 10
If no clause is speciﬁed, the ordered construct behaves as if the threads clause had been 11
speciﬁed. If the threads clause is speciﬁed, the threads in the team that is executing the 12
worksharing-loop region execute ordered regions sequentially in the order of the loop iterations. 13
Ifany depend clausesarespeciﬁedthenthoseclausesspecifytheorderinwhichthethreadsinthe 14
team execute ordered regions. If the simdclause is speciﬁed, the ordered regions 15
encountered by any thread will execute one at a time in the order of the loop iterations. 16
When the thread that is executing the ﬁrst iteration of the loop encounters an ordered construct, 17
it can enter the ordered region without waiting. When a thread that is executing any subsequent 18
iteration encounters an ordered construct without a depend clause, it waits at the beginning of 19
theordered region until execution of all ordered regions belonging to all previous iterations 20
has completed. When a thread that is executing any subsequent iteration encounters an ordered 21
construct with one or more depend(sink: vec)clauses, it waits until its dependences on all 22
valid iterations speciﬁed by the depend clauses are satisﬁed before it completes execution of the 23
ordered region. A speciﬁc dependence is satisﬁed when a thread that is executing the 24
corresponding iteration encounters an ordered construct with a depend(source) clause. 25
Execution Model Events 26
Theordered-acquiring event occurs in the task that encounters the ordered construct on entry to 27
the ordered region before it initiates synchronization for the region. 28
Theordered-acquired event occurs in the task that encounters the ordered construct after it 29
enters the region, but before it executes the structured block of the ordered region. 30
Theordered-released event occurs in the task that encounters the ordered construct after it 31
completes any synchronization on exit from the ordered region. 32
CHAPTER 2. DIRECTIVES 251
Thedoacross-sink event occurs in the task that encounters a ordered construct for each 1
depend(sink: vec)clause after the dependence is fulﬁlled. 2
Thedoacross-source event occurs in the task that encounters a ordered construct with a 3
depend(source: vec)clause before signaling the dependence to be fulﬁlled. 4
Tool Callbacks 5
A thread dispatches a registered ompt_callback_mutex_acquire callback for each 6
occurrence of an ordered-acquiring event in that thread. This callback has the type signature 7
ompt_callback_mutex_acquire_t . 8
A thread dispatches a registered ompt_callback_mutex_acquired callback for each 9
occurrence of an ordered-acquired event in that thread. This callback has the type signature 10
ompt_callback_mutex_t . 11
A thread dispatches a registered ompt_callback_mutex_released callback with 12
ompt_mutex_ordered as thekindargument if practical, although a less speciﬁc kind may be 13
used, for each occurrence of an ordered-released event in that thread. This callback has the type 14
signature ompt_callback_mutex_t and occurs in the task that encounters the atomic 15
construct. 16
A thread dispatches a registered ompt_callback_dependences callback with all vector 17
entrieslistedas ompt_dependence_type_sink inthedepsargumentforeachoccurrenceofa 18
doacross-sink event in that thread. A thread dispatches a registered 19
ompt_callback_dependences callback with all vector entries listed as 20
ompt_dependence_type_source in thedepsargument for each occurrence of a 21
doacross-source event in that thread. These callbacks have the type signature 22
ompt_callback_dependences_t . 23
Restrictions 24
Restrictions to the ordered construct are as follows: 25
At most one threads clause can appear on an ordered construct. 26
At most one simdclause can appear on an ordered construct. 27
At most one depend(source) clause can appear on an ordered construct. 28
The construct corresponding to the binding region of an ordered region must not specify a 29
reduction clause with the inscan modiﬁer. 30
Either depend(sink: vec)clauses or depend(source) clauses may appear on an 31
ordered construct, but not both. 32
252 OpenMP API – Version 5.0 November 2018
The worksharing-loop or worksharing-loop SIMD region to which an ordered region 1
corresponding to an ordered construct without a depend clause binds must have an 2
ordered clause without the parameter speciﬁed on the corresponding worksharing-loop or 3
worksharing-loop SIMD directive. 4
The worksharing-loop region to which an ordered region corresponding to an ordered 5
construct with any depend clauses binds must have an ordered clause with the parameter 6
speciﬁed on the corresponding worksharing-loop directive. 7
Anordered construct with the depend clause speciﬁed must be closely nested inside a 8
worksharing-loop (or parallel worksharing-loop) construct. 9
Anordered region corresponding to an ordered construct without the simdclause 10
speciﬁed must be closely nested inside a loop region. 11
Anordered region corresponding to an ordered construct with the simdclause speciﬁed 12
must be closely nested inside a simdor worksharing-loop SIMD region. 13
Anordered region corresponding to an ordered construct with both the simdand 14
threads clauses must be closely nested inside a worksharing-loop SIMD region or must be 15
closely nested inside a worksharing-loop and simdregion. 16
During execution of an iteration of a worksharing-loop or a loop nest within a worksharing-loop, 17
simd, or worksharing-loop SIMD region, a thread must not execute more than one ordered 18
region corresponding to an ordered construct without a depend clause. 19
C++
A throw executed inside a ordered region must cause execution to resume within the same 20
ordered region, and the same thread that threw the exception must catch it. 21
C++
Cross References 22
worksharing-loop construct, see Section 2.9.2 on page 101. 23
simdconstruct, see Section 2.9.3.1 on page 110. 24
parallel Worksharing-loop construct, see Section 2.13.1 on page 185. 25
depend Clause, see Section 2.17.11 on page 255 26
ompt_mutex_ordered , see Section 4.4.4.16 on page 445. 27
ompt_callback_mutex_acquire_t , see Section 4.5.2.14 on page 476. 28
ompt_callback_mutex_t , see Section 4.5.2.15 on page 477. 29
CHAPTER 2. DIRECTIVES 253
2.17.10 Depend Objects1
This section describes constructs that support OpenMP depend objects that can be used to supply 2
user-computed dependences to depend clauses. OpenMP depend objects must be accessed only 3
through the depobj construct or through the depend clause; programs that otherwise access 4
OpenMP depend objects are non-conforming. 5
An OpenMP depend object can be in one of the following states: uninitialized orinitialized . 6
Initially OpenMP depend objects are in the uninitialized state. 7
2.17.10.1 depobj Construct 8
Summary 9
Thedepobj construct initializes, updates or destroys an OpenMP depend object. The depobj 10
construct is a stand-alone directive. 11
Syntax 12
C / C++
The syntax of the depobj construct is as follows: 13
#pragma omp depobj( depobj )clause new-line 14
wheredepobjis an lvalue expression of type omp_depend_t . 15
whereclauseis one of the following: 16
depend( dependence-type :locator ) 17
destroy 18
update( dependence-type ) 19
C / C++
Fortran
The syntax of the depobj construct is as follows: 20
!$omp depobj( depobj )clause 21
wheredepobjis a scalar integer variable of the omp_depend_kind kind. 22
whereclauseis one of the following: 23
depend( dependence-type :locator ) 24
destroy 25
update( dependence-type ) 26
Fortran
254 OpenMP API – Version 5.0 November 2018
Binding 1
The binding thread set for depobj regions is the encountering thread. 2
Description 3
Adepobj construct with a depend clause present sets the state of depobjto initialized. The 4
depobjis initialized to represent the dependence that the depend clause speciﬁes. 5
Adepobj construct with a destroy clause present changes the state of the depobjto 6
uninitialized. 7
Adepobj construct with an update clause present changes the dependence type of the 8
dependence represented by depobjto the one speciﬁed by the updateclause. 9
Restrictions 10
Adepend clause on a depobj construct must not have source,sinkordepobj as 11
dependence-type . 12
Adepend clause on a depobj construct can only specify one locator. 13
Thedepobjof adepobj construct with the depend clause present must be in the uninitialized 14
state. 15
Thedepobjof adepobj construct with the destroy clause present must be in the initialized 16
state. 17
Thedepobjof adepobj construct with the update clause present must be in the initialized 18
state. 19
Cross References 20
depend clause, see Section 2.17.11 on page 255. 21
2.17.11 depend Clause 22
Summary 23
Thedepend clause enforces additional constraints on the scheduling of tasks or loop iterations. 24
These constraints establish dependences only between sibling tasks or between loop iterations. 25
CHAPTER 2. DIRECTIVES 255
Syntax 1
The syntax of the depend clause is as follows: 2
depend( [depend-modiﬁer ,]dependence-type :locator-list ) 3
wheredependence-type is one of the following: 4
in 5
out 6
inout 7
mutexinoutset 8
depobj 9
wheredepend-modiﬁer is one of the following: 10
iterator( iterators-deﬁnition ) 11
or 12
depend( dependence-type ) 13
wheredependence-type is: 14
source 15
or 16
depend( dependence-type :vec) 17
wheredependence-type is: 18
sink 19
and where vecis the iteration vector, which has the form: 20
x1[d1], x2[d2], ..., x n[dn] 21
wherenisthevaluespeciﬁedbythe ordered clauseintheworksharing-loopdirective,x idenotes 22
the loop iteration variable of the i-th nested loop associated with the worksharing-loop directive, 23
and diis a constant non-negative integer. 24
Description 25
Task dependences are derived from the dependence-type of adepend clause and its list items 26
whendependence-type isin,out,inout, ormutexinoutset . When the dependence-type is 27
depobj, the task dependences are derived from the dependences represented by the depend 28
objects speciﬁed in the depend clause as if the depend clauses of the depobj constructs were 29
speciﬁed in the current construct. 30
256 OpenMP API – Version 5.0 November 2018
Forthe independence-type ,ifthestoragelocationofatleastoneofthelistitemsisthesameasthe 1
storage location of a list item appearing in a depend clause with an out,inout, or 2
mutexinoutset dependence-type on a construct from which a sibling task was previously 3
generated, then the generated task will be a dependent task of that sibling task. 4
For the outandinoutdependence-types , if the storage location of at least one of the list items is 5
the same as the storage location of a list item appearing in a depend clause with an in,out, 6
inout, ormutexinoutset dependence-type on a construct from which a sibling task was 7
previously generated, then the generated task will be a dependent task of that sibling task. 8
For the mutexinoutset dependence-type , if the storage location of at least one of the list items 9
is the same as the storage location of a list item appearing in a depend clause with an in,out, or 10
inoutdependence-type on a construct from which a sibling task was previously generated, then 11
the generated task will be a dependent task of that sibling task. 12
If a list item appearing in a depend clause with a mutexinoutset dependence-type on a 13
task-generating construct has the same storage location as a list item appearing in a depend clause 14
with a mutexinoutset dependence-type on a diﬀerent task generating construct, and both 15
constructs generate sibling tasks, the sibling tasks will be mutually exclusive tasks. 16
The list items that appear in the depend clause may reference iterators deﬁned by an 17
iterators-deﬁnition appearing on an iterator modiﬁer. 18
The list items that appear in the depend clause may include array sections. 19
Fortran
If a list item has the ALLOCATABLE attribute and its allocation status is unallocated, the behavior 20
is unspeciﬁed. If a list item has the POINTER attribute and its association status is disassociated or 21
undeﬁned, the behavior is unspeciﬁed. 22
Fortran
C / C++
The list items that appear in a depend clause may use shape-operators. 23
C / C++
24
Note– The enforced task dependence establishes a synchronization of memory accesses 25
performed by a dependent task with respect to accesses performed by the predecessor tasks. 26
However, it is the responsibility of the programmer to synchronize properly with respect to other 27
concurrent accesses that occur outside of those tasks. 28
29
Thesource dependence-type speciﬁes the satisfaction of cross-iteration dependences that arise 30
from the current iteration. 31
Thesinkdependence-type speciﬁes a cross-iteration dependence, where the iteration vector vec 32
indicates the iteration that satisﬁes the dependence. 33
CHAPTER 2. DIRECTIVES 257
If the iteration vector vecdoes not occur in the iteration space, the depend clause is ignored. If all 1
depend clauses on an ordered construct are ignored then the construct is ignored. 2
3
Note– Aniterationvector vecthatdoesnotindicatealexicographicallyearlieriterationmaycause 4
a deadlock. 5
6
Execution Model Events 7
Thetask-dependences event occurs in a thread that encounters a task generating construct or a 8
taskwait construct with a depend clause immediately after the task-create event for the new 9
task or the taskwait-begin event. 10
Thetask-dependence event indicates an unfulﬁlled dependence for the generated task. This event 11
occurs in a thread that observes the unfulﬁlled dependence before it is satisﬁed. 12
Tool Callbacks 13
A thread dispatches the ompt_callback_dependences callback for each occurrence of the 14
task-dependences event to announce its dependences with respect to the list items in the depend 15
clause. This callback has type signature ompt_callback_dependences_t . 16
A thread dispatches the ompt_callback_task_dependence callback for a task-dependence 17
event to report a dependence between a predecessor task ( src_task_data ) and a dependent task 18
(sink_task_data ). This callback has type signature ompt_callback_task_dependence_t . 19
Restrictions 20
Restrictions to the depend clause are as follows: 21
List items used in depend clauses of the same task or sibling tasks must indicate identical 22
storage locations or disjoint storage locations. 23
List items used in depend clauses cannot be zero-length array sections. 24
Array sections cannot be speciﬁed in depend clauses with the depobj dependence type. 25
List items used in depend clauses with the depobj dependence type must be depend objects 26
in the initialized state. 27
C / C++
List items used in depend clauses with the depobj dependence type must be expressions of 28
theomp_depend_t type. 29
List items used in depend clauses with the in,out,inoutormutexinoutset 30
dependence types cannot be expressions of the omp_depend_t type. 31
C / C++
258 OpenMP API – Version 5.0 November 2018
Fortran
A common block name cannot appear in a depend clause. 1
List items used in depend clauses with the depobj dependence type must be integer 2
expressions of the omp_depend_kind kind. 3
Fortran
For avecelement of sinkdependence-type of the form x i+dior xi diif the loop iteration 4
variable x ihas an integral or pointer type, the expression x i+dior xi difor any value of the 5
loopiterationvariablex ithatcanencounterthe ordered constructmustbecomputablewithout 6
overﬂow in the type of the loop iteration variable. 7
C++
For avecelement of sinkdependence-type of the form x i+dior xi diif the loop iteration 8
variable x iis of a random access iterator type other than pointer type, the expression 9
(xi lbi) +dior(xi lbi) difor any value of the loop iteration variable x ithat can 10
encounter the ordered construct must be computable without overﬂow in the type that would 11
be used by std::distance applied to variables of the type of x i. 12
C++
C / C++
A bit-ﬁeld cannot appear in a depend clause. 13
C / C++
Cross References 14
Array sections, see Section 2.1.5 on page 44. 15
Iterators, see Section 2.1.6 on page 47. 16
taskconstruct, see Section 2.10.1 on page 135. 17
Task scheduling constraints, see Section 2.10.6 on page 149. 18
target enter data construct, see Section 2.12.3 on page 164. 19
target exit data construct, see Section 2.12.4 on page 166. 20
target construct, see Section 2.12.5 on page 170. 21
target update construct, see Section 2.12.6 on page 176. 22
ordered construct, see Section 2.17.9 on page 250. 23
depobj construct, see Section 2.17.10.1 on page 254. 24
ompt_callback_dependences_t , see Section 4.5.2.8 on page 468. 25
ompt_callback_task_dependence_t , see Section 4.5.2.9 on page 470. 26
CHAPTER 2. DIRECTIVES 259
2.17.12 Synchronization Hints1
Hints about the expected dynamic behavior or suggested implementation can be provided by the 2
programmer to locks (by using the omp_init_lock_with_hint or 3
omp_init_nest_lock_with_hint functions to initialize the lock), and to atomic and 4
critical directivesbyusingthe hintclause. Theeﬀectofahintdoesnotchangethesemantics 5
of the associated construct; if ignoring the hint changes the program semantics, the result is 6
unspeciﬁed. 7
The C/C++ header ﬁle ( omp.h) and the Fortran include ﬁle ( omp_lib.h ) and/or Fortran 90 8
module ﬁle ( omp_lib ) deﬁne the valid hint constants. The valid constants must include the 9
following, which can be extended with implementation-deﬁned values: 10
C / C++
typedef enum omp_sync_hint_t { 11
omp_sync_hint_none = 0x0, 12
omp_lock_hint_none = omp_sync_hint_none, 13
omp_sync_hint_uncontended = 0x1, 14
omp_lock_hint_uncontended = omp_sync_hint_uncontended, 15
omp_sync_hint_contended = 0x2, 16
omp_lock_hint_contended = omp_sync_hint_contended, 17
omp_sync_hint_nonspeculative = 0x4, 18
omp_lock_hint_nonspeculative = omp_sync_hint_nonspeculative, 19
omp_sync_hint_speculative = 0x8 20
omp_lock_hint_speculative = omp_sync_hint_speculative 21
} omp_sync_hint_t; 22
23
typedef omp_sync_hint_t omp_lock_hint_t; 24
C / C++
Fortran
integer, parameter :: omp_lock_hint_kind = omp_sync_hint_kind 25
26
integer (kind=omp_sync_hint_kind), & 27
parameter :: omp_sync_hint_none = & 28
int(Z’0’, kind=omp_sync_hint_kind) 29
integer (kind=omp_lock_hint_kind), & 30
parameter :: omp_lock_hint_none = omp_sync_hint_none 31
integer (kind=omp_sync_hint_kind), & 32
parameter :: omp_sync_hint_uncontended = & 33
int(Z’1’, kind=omp_sync_hint_kind) 34
integer (kind=omp_lock_hint_kind), & 35
parameter :: omp_lock_hint_uncontended = & 36
omp_sync_hint_uncontended 37
integer (kind=omp_sync_hint_kind), & 38
260 OpenMP API – Version 5.0 November 2018
parameter :: omp_sync_hint_contended = & 1
int(Z’2’, kind=omp_sync_hint_kind) 2
integer (kind=omp_lock_hint_kind), & 3
parameter :: omp_lock_hint_contended = & 4
omp_sync_hint_contended 5
integer (kind=omp_sync_hint_kind), & 6
parameter :: omp_sync_hint_nonspeculative = & 7
int(Z’4’, kind=omp_sync_hint_kind) 8
integer (kind=omp_lock_hint_kind), & 9
parameter :: omp_lock_hint_nonspeculative = & 10
omp_sync_hint_nonspeculative 11
integer (kind=omp_sync_hint_kind), & 12
parameter :: omp_sync_hint_speculative = & 13
int(Z’8’, kind=omp_sync_hint_kind) 14
integer (kind=omp_lock_hint_kind), & 15
parameter :: omp_lock_hint_speculative = & 16
omp_sync_hint_speculative 17
Fortran
The hints can be combined by using the +or|operators in C/C++ or the +operator in Fortran. 18
Combining omp_sync_hint_none withanyotherhintisequivalenttospecifyingtheotherhint. 19
The intended meaning of each hint is: 20
omp_sync_hint_uncontended : low contention is expected in this operation, that is, few 21
threads are expected to perform the operation simultaneously in a manner that requires 22
synchronization; 23
omp_sync_hint_contended : high contention is expected in this operation, that is, many 24
threads are expected to perform the operation simultaneously in a manner that requires 25
synchronization; 26
omp_sync_hint_speculative : the programmer suggests that the operation should be 27
implemented using speculative techniques such as transactional memory; and 28
omp_sync_hint_nonspeculative : the programmer suggests that the operation should 29
not be implemented using speculative techniques such as transactional memory. 30
31
Note– Future OpenMP speciﬁcations may add additional hints to the omp_sync_hint_t type 32
and the omp_sync_hint_kind kind. Implementers are advised to add implementation-deﬁned 33
hints starting from the most signiﬁcant bit of the omp_sync_hint_t type and 34
omp_sync_hint_kind kind and to include the name of the implementation in the name of the 35
added hint to avoid name conﬂicts with other OpenMP implementations. 36
37
CHAPTER 2. DIRECTIVES 261
Theomp_sync_hint_t andomp_lock_hint_t enumeration types and the equivalent types 1
in Fortran are synonyms for each other. The type omp_lock_hint_t has been deprecated. 2
Restrictions 3
Restrictions to the synchronization hints are as follows: 4
The hints omp_sync_hint_uncontended andomp_sync_hint_contended cannot 5
be combined. 6
The hints omp_sync_hint_nonspeculative andomp_sync_hint_speculative 7
cannot be combined. 8
The restrictions for combining multiple values of omp_sync_hint apply equally to the 9
corresponding values of omp_lock_hint , and expressions that mix the two types. 10
Cross References 11
critical construct, see Section 2.17.1 on page 223. 12
atomic construct, see Section 2.17.7 on page 234 13
omp_init_lock_with_hint andomp_init_nest_lock_with_hint , see 14
Section 3.3.2 on page 385. 15
262 OpenMP API – Version 5.0 November 2018
2.18 Cancellation Constructs1
2.18.1 cancel Construct 2
Summary 3
Thecancel construct activates cancellation of the innermost enclosing region of the type 4
speciﬁed. The cancel construct is a stand-alone directive. 5
Syntax 6
C / C++
The syntax of the cancel construct is as follows: 7
#pragma omp cancel construct-type-clause [ [ ,] if-clause] new-line 8
whereconstruct-type-clause is one of the following: 9
parallel 10
sections 11
for 12
taskgroup 13
andif-clauseis 14
if ([cancel : ] scalar-expression ) 15
C / C++
Fortran
The syntax of the cancel construct is as follows: 16
!$omp cancel construct-type-clause [ [ ,] if-clause] 17
whereconstruct-type-clause is one of the following: 18
parallel 19
sections 20
do 21
taskgroup 22
andif-clauseis 23
if ([cancel : ] scalar-logical-expression ) 24
Fortran
CHAPTER 2. DIRECTIVES 263
Binding 1
The binding thread set of the cancel region is the current team. The binding region of the 2
cancel region is the innermost enclosing region of the type corresponding to the 3
construct-type-clause speciﬁed in the directive (that is, the innermost parallel ,sections , 4
worksharing-loop, or taskgroup region). 5
Description 6
Thecancel construct activates cancellation of the binding region only if the cancel-var ICV is 7
true, in which case the cancel construct causes the encountering task to continue execution at the 8
end of the binding region if construct-type-clause isparallel ,for,do, orsections . If the 9
cancel-var ICV istrueandconstruct-type-clause istaskgroup , the encountering task continues 10
execution at the end of the current task region. If the cancel-var ICV isfalse, thecancel 11
construct is ignored. 12
Threads check for active cancellation only at cancellation points that are implied at the following 13
locations: 14
cancel regions; 15
cancellation point regions; 16
barrier regions; 17
implicit barriers regions. 18
When a thread reaches one of the above cancellation points and if the cancel-var ICV istrue, then: 19
If the thread is at a cancel orcancellation point region and construct-type-clause is 20
parallel ,for,do, orsections , the thread continues execution at the end of the canceled 21
region if cancellation has been activated for the innermost enclosing region of the type speciﬁed. 22
If the thread is at a cancel orcancellation point region and construct-type-clause is 23
taskgroup , the encountering task checks for active cancellation of all of the taskgroup sets to 24
which the encountering task belongs, and continues execution at the end of the current task 25
region if cancellation has been activated for any of the taskgroup sets . 26
Iftheencounteringtaskisatabarrierregion,theencounteringtaskchecksforactivecancellation 27
of the innermost enclosing parallel region. If cancellation has been activated, then the 28
encountering task continues execution at the end of the canceled region. 29
30
Note– If one thread activates cancellation and another thread encounters a cancellation point, the 31
order of execution between the two threads is non-deterministic. Whether the thread that 32
encounters a cancellation point detects the activated cancellation depends on the underlying 33
hardware and operating system. 34
35
264 OpenMP API – Version 5.0 November 2018
When cancellation of tasks is activated through a cancel construct with the taskgroup 1
construct-type-clause , the tasks that belong to the taskgroup set of the innermost enclosing 2
taskgroup region will be canceled. The task that encountered that construct continues execution 3
at the end of its task region, which implies completion of that task. Any task that belongs to the 4
innermost enclosing taskgroup and has already begun execution must run to completion or until 5
a cancellation point is reached. Upon reaching a cancellation point and if cancellation is active, the 6
taskcontinuesexecutionattheendofitstaskregion,whichimpliesthetask’scompletion. Anytask 7
that belongs to the innermost enclosing taskgroup and that has not begun execution may be 8
discarded, which implies its completion. 9
When cancellation is active for a parallel ,sections , or worksharing-loop region, each 10
threadofthebindingthreadsetresumesexecutionattheendofthecanceledregionifacancellation 11
point is encountered. If the canceled region is a parallel region, any tasks that have been 12
created by a taskor ataskloop construct and their descendent tasks are canceled according to 13
the above taskgroup cancellation semantics. If the canceled region is a sections , or 14
worksharing-loop region, no task cancellation occurs. 15
C++
The usual C++ rules for object destruction are followed when cancellation is performed. 16
C++
Fortran
All private objects or subobjects with ALLOCATABLE attribute that are allocated inside the 17
canceled construct are deallocated. 18
Fortran
If the canceled construct contains a reduction ,task_reduction orlastprivate clause, 19
the ﬁnal value of the list items that appeared in those clauses are undeﬁned. 20
When an ifclause is present on a cancel construct and the ifexpression evaluates to false, the 21
cancel construct does not activate cancellation. The cancellation point associated with the 22
cancel construct is always encountered regardless of the value of the ifexpression. 23
24
Note– The programmer is responsible for releasing locks and other synchronization data 25
structures that might cause a deadlock when a cancel construct is encountered and blocked 26
threads cannot be canceled. The programmer is also responsible for ensuring proper 27
synchronizations to avoid deadlocks that might arise from cancellation of OpenMP regions that 28
contain OpenMP synchronization constructs. 29
30
Execution Model Events 31
If a task encounters a cancel construct that will activate cancellation then a cancelevent occurs. 32
Adiscarded-task event occurs for any discarded tasks. 33
CHAPTER 2. DIRECTIVES 265
Tool Callbacks 1
A thread dispatches a registered ompt_callback_cancel callback for each occurrence of a 2
cancelevent in the context of the encountering task. This callback has type signature 3
ompt_callback_cancel_t ;(ﬂags& ompt_cancel_activated) always evaluates to 4
truein the dispatched callback; (ﬂags& ompt_cancel_parallel) evaluates to truein the 5
dispatched callback if construct-type-clause isparallel ; 6
(ﬂags& ompt_cancel_sections) evaluates to truein the dispatched callback if 7
construct-type-clause issections ;(ﬂags& ompt_cancel_loop) evaluates to truein the 8
dispatched callback if construct-type-clause isforordo; and 9
(ﬂags& ompt_cancel_taskgroup) evaluates to truein the dispatched callback if 10
construct-type-clause istaskgroup . 11
A thread dispatches a registered ompt_callback_cancel callback with the ompt_data_t 12
associated with the discarded task as its task_data argument and 13
ompt_cancel_discarded_task as itsﬂagsargument for each occurrence of a 14
discarded-task event. The callback occurs in the context of the task that discards the task and has 15
type signature ompt_callback_cancel_t . 16
Restrictions 17
The restrictions to the cancel construct are as follows: 18
The behavior for concurrent cancellation of a region and a region nested within it is unspeciﬁed. 19
Ifconstruct-type-clause istaskgroup , thecancel construct must be closely nested inside a 20
taskor ataskloop construct and the cancel region must be closely nested inside a 21
taskgroup region. If construct-type-clause issections , thecancel construct must be 22
closely nested inside a sections orsection construct. Otherwise, the cancel construct 23
must be closely nested inside an OpenMP construct that matches the type speciﬁed in 24
construct-type-clause of the cancel construct. 25
A worksharing construct that is canceled must not have a nowait clause. 26
A worksharing-loop construct that is canceled must not have an ordered clause. 27
During execution of a construct that may be subject to cancellation, a thread must not encounter 28
an orphaned cancellation point. That is, a cancellation point must only be encountered within 29
that construct and must not be encountered elsewhere in its region. 30
Cross References 31
cancel-var ICV, see Section 2.5.1 on page 64. 32
ifclause, see Section 2.15 on page 220. 33
cancellation point construct, see Section 2.18.2 on page 267. 34
266 OpenMP API – Version 5.0 November 2018
omp_get_cancellation routine, see Section 3.2.9 on page 342. 1
omp_cancel_flag_t enumeration type, see Section 4.4.4.24 on page 450. 2
ompt_callback_cancel_t , see Section 4.5.2.18 on page 481. 3
2.18.2 cancellation point Construct 4
Summary 5
Thecancellation point construct introduces a user-deﬁned cancellation point at which 6
implicit or explicit tasks check if cancellation of the innermost enclosing region of the type 7
speciﬁed has been activated. The cancellation point construct is a stand-alone directive. 8
Syntax 9
C / C++
The syntax of the cancellation point construct is as follows: 10
#pragma omp cancellation point construct-type-clause new-line 11
whereconstruct-type-clause is one of the following: 12
parallel 13
sections 14
for 15
taskgroup 16
C / C++
Fortran
The syntax of the cancellation point construct is as follows: 17
!$omp cancellation point construct-type-clause 18
whereconstruct-type-clause is one of the following: 19
parallel 20
sections 21
do 22
taskgroup 23
Fortran
CHAPTER 2. DIRECTIVES 267
Binding 1
The binding thread set of the cancellation point construct is the current team. The binding 2
region of the cancellation point region is the innermost enclosing region of the type 3
corresponding to the construct-type-clause speciﬁed in the directive (that is, the innermost 4
parallel ,sections , worksharing-loop, or taskgroup region). 5
Description 6
This directive introduces a user-deﬁned cancellation point at which an implicit or explicit task must 7
check if cancellation of the innermost enclosing region of the type speciﬁed in the clause has been 8
requested. This construct does not implement any synchronization between threads or tasks. 9
When an implicit or explicit task reaches a user-deﬁned cancellation point and if the cancel-var 10
ICV istrue, then: 11
If theconstruct-type-clause of the encountered cancellation point construct is 12
parallel ,for,do, orsections , the thread continues execution at the end of the canceled 13
region if cancellation has been activated for the innermost enclosing region of the type speciﬁed. 14
If theconstruct-type-clause of the encountered cancellation point construct is 15
taskgroup , the encountering task checks for active cancellation of all taskgroup sets to which 16
the encountering task belongs and continues execution at the end of the current task region if 17
cancellation has been activated for any of them. 18
Execution Model Events 19
Thecancellation event occurs if a task encounters a cancellation point and detected the activation 20
of cancellation. 21
Tool Callbacks 22
A thread dispatches a registered ompt_callback_cancel callback for each occurrence of a 23
cancelevent in the context of the encountering task. This callback has type signature 24
ompt_callback_cancel_t ;(ﬂags& ompt_cancel_detected) always evaluates to true 25
in the dispatched callback; (ﬂags& ompt_cancel_parallel) evaluates to truein the 26
dispatched callback if construct-type-clause of the encountered cancellation point 27
construct is parallel ;(ﬂags& ompt_cancel_sections) evaluates to truein the 28
dispatched callback if construct-type-clause of the encountered cancellation point 29
construct is sections ;(ﬂags& ompt_cancel_loop) evaluates to truein the dispatched 30
callbackif construct-type-clause oftheencountered cancellation point constructis foror 31
do; and(ﬂags& ompt_cancel_taskgroup) evaluates to truein the dispatched callback if 32
construct-type-clause of the encountered cancellation point construct is taskgroup . 33
268OpenMP API – Version 5.0 November 2018
Restrictions 1
Acancellation point construct for which construct-type-clause istaskgroup must be 2
closely nested inside a taskortaskloop construct, and the cancellation point region 3
must be closely nested inside a taskgroup region. 4
Acancellation point construct for which construct-type-clause issections must be 5
closely nested inside a sections orsection construct. 6
Acancellation point constructforwhich construct-type-clause isneither sections nor 7
taskgroup must be closely nested inside an OpenMP construct that matches the type speciﬁed 8
inconstruct-type-clause . 9
Cross References 10
cancel-var ICV, see Section 2.5.1 on page 64. 11
cancel construct, see Section 2.18.1 on page 263. 12
omp_get_cancellation routine, see Section 3.2.9 on page 342. 13
ompt_callback_cancel_t , see Section 4.5.2.18 on page 481. 14
2.19 Data Environment 15
This section presents directives and clauses for controlling data environments. 16
2.19.1 Data-Sharing Attribute Rules 17
This section describes how the data-sharing attributes of variables referenced in data environments 18
are determined. The following two cases are described separately: 19
Section2.19.1.1onpage270describesthedata-sharingattributerulesforvariablesreferencedin 20
a construct. 21
Section2.19.1.2onpage273describesthedata-sharingattributerulesforvariablesreferencedin 22
a region, but outside any construct. 23
CHAPTER 2. DIRECTIVES 269
2.19.1.1 Variables Referenced in a Construct1
The data-sharing attributes of variables that are referenced in a construct can be predetermined , 2
explicitly determined , orimplicitly determined , according to the rules outlined in this section. 3
Specifying a variable in a data-sharing attribute clause, except for the private clause, or 4
copyprivate clause of an enclosed construct causes an implicit reference to the variable in the 5
enclosing construct. Specifying a variable in a mapclause of an enclosed construct may cause an 6
implicit reference to the variable in the enclosing construct. Such implicit references are also 7
subject to the data-sharing attribute rules outlined in this section. 8
Certain variables and objects have predetermined data-sharing attributes as follows: 9
C / C++
Variables that appear in threadprivate directives are threadprivate. 10
Variables with automatic storage duration that are declared in a scope inside the construct are 11
private. 12
Objects with dynamic storage duration are shared. 13
Static data members are shared. 14
The loop iteration variable(s) in the associated for-loop(s) of afor,parallel for , 15
taskloop , ordistribute construct is (are) private. 16
The loop iteration variable in the associated for-loopof asimdconstruct with just one 17
associated for-loopis linear with a linear-step that is the increment of the associated for-loop. 18
The loop iteration variables in the associated for-loops of asimdconstruct with multiple 19
associated for-loops are lastprivate. 20
Theloopiterationvariable(s)intheassociated for-loop(s) ofaloopconstructis(are)lastprivate. 21
Variables with static storage duration that are declared in a scope inside the construct are shared. 22
If a list item in a mapclause on the target construct has a base pointer, and the base pointer is 23
a scalar variable that does not appear in a mapclause on the construct, the base pointer is 24
ﬁrstprivate. 25
Ifalistitemina reduction orin_reduction clauseonaconstructhasabasepointerthen 26
the base pointer is private. 27
C / C++
Fortran
Variables and common blocks that appear in threadprivate directives are threadprivate. 28
The loop iteration variable(s) in the associated do-loop(s) of ado,parallel do ,taskloop , 29
ordistribute construct is (are) private. 30
270 OpenMP API – Version 5.0 November 2018
The loop iteration variable in the associated do-loopof asimdconstruct with just one 1
associated do-loopis linear with a linear-step that is the increment of the associated do-loop. 2
The loop iteration variables in the associated do-loops of asimdconstruct with multiple 3
associated do-loops are lastprivate. 4
Theloopiterationvariable(s)intheassociated do-loop(s) ofaloopconstructis(are)lastprivate. 5
A loop iteration variable for a sequential loop in a parallel or task generating construct is 6
private in the innermost such construct that encloses the loop. 7
Implied-do indices and forall indices are private. 8
Cray pointees have the same data-sharing attribute as the storage with which their Cray pointers 9
are associated. 10
Assumed-size arrays are shared. 11
An associate name preserves the association with the selector established at the ASSOCIATE or 12
SELECT TYPE statement. 13
Fortran
Variables with predetermined data-sharing attributes may not be listed in data-sharing attribute 14
clauses, except for the cases listed below. For these exceptions only, listing a predetermined 15
variable in a data-sharing attribute clause is allowed and overrides the variable’s predetermined 16
data-sharing attributes. 17
C / C++
The loop iteration variable(s) in the associated for-loop(s) of afor,parallel for , 18
taskloop ,distribute , orloopconstruct may be listed in a private or 19
lastprivate clause. 20
The loop iteration variable in the associated for-loopof asimdconstruct with just one 21
associated for-loopmay be listed in a private ,lastprivate , orlinear clause with a 22
linear-step that is the increment of the associated for-loop. 23
The loop iteration variables in the associated for-loops of asimdconstruct with multiple 24
associated for-loops may be listed in a private orlastprivate clause. 25
Variables with const-qualiﬁed type with no mutable members may be listed in a 26
firstprivate clause, even if they are static data members. 27
C / C++
CHAPTER 2. DIRECTIVES 271
Fortran
The loop iteration variable(s) in the associated do-loop(s) of ado,parallel do ,taskloop , 1
distribute , orloopconstruct may be listed in a private orlastprivate clause. 2
The loop iteration variable in the associated do-loopof asimdconstruct with just one 3
associated do-loopmay be listed in a private ,lastprivate , orlinear clause with a 4
linear-step that is the increment of the associated loop. 5
The loop iteration variables in the associated do-loops of asimdconstruct with multiple 6
associated do-loops may be listed in a private orlastprivate clause. 7
Variables used as loop iteration variables in sequential loops in a parallel or task generating 8
construct may be listed in data-sharing attribute clauses on the construct itself, and on enclosed 9
constructs, subject to other restrictions. 10
Assumed-size arrays may be listed in a shared clause. 11
Fortran
Additional restrictions on the variables that may appear in individual clauses are described with 12
each clause in Section 2.19.4 on page 282. 13
Variables with explicitly determined data-sharing attributes are those that are referenced in a given 14
construct and are listed in a data-sharing attribute clause on the construct. 15
Variables with implicitly determined data-sharing attributes are those that are referenced in a given 16
construct, do not have predetermined data-sharing attributes, and are not listed in a data-sharing 17
attribute clause on the construct. 18
Rules for variables with implicitly determined data-sharing attributes are as follows: 19
In aparallel ,teams, or task generating construct, the data-sharing attributes of these 20
variables are determined by the default clause, if present (see Section 2.19.4.1 on page 282). 21
In aparallel construct, if no default clause is present, these variables are shared. 22
For constructs other than task generating constructs, if no default clause is present, these 23
variables reference the variables with the same names that exist in the enclosing context. 24
In atarget construct, variables that are not mapped after applying data-mapping attribute 25
rules (see Section 2.19.7 on page 314) are ﬁrstprivate. 26
C++
In an orphaned task generating construct, if no default clause is present, formal arguments 27
passed by reference are ﬁrstprivate. 28
C++
Fortran
In an orphaned task generating construct, if no default clause is present, dummy arguments 29
are ﬁrstprivate. 30
Fortran
272 OpenMP API – Version 5.0 November 2018
In a task generating construct, if no default clause is present, a variable for which the 1
data-sharing attribute is not determined by the rules above and that in the enclosing context is 2
determined to be shared by all implicit tasks bound to the current team is shared. 3
In a task generating construct, if no default clause is present, a variable for which the 4
data-sharing attribute is not determined by the rules above is ﬁrstprivate. 5
Additional restrictions on the variables for which data-sharing attributes cannot be implicitly 6
determined in a task generating construct are described in Section 2.19.4.4 on page 286. 7
2.19.1.2 Variables Referenced in a Region but not in a Construct8
The data-sharing attributes of variables that are referenced in a region, but not in a construct, are 9
determined as follows: 10
C / C++
Variables with static storage duration that are declared in called routines in the region are shared. 11
File-scope or namespace-scope variables referenced in called routines in the region are shared 12
unless they appear in a threadprivate directive. 13
Objects with dynamic storage duration are shared. 14
Static data members are shared unless they appear in a threadprivate directive. 15
In C++, formal arguments of called routines in the region that are passed by reference have the 16
same data-sharing attributes as the associated actual arguments. 17
Other variables declared in called routines in the region are private. 18
C / C++
Fortran
Local variables declared in called routines in the region and that have the saveattribute, or that 19
are data initialized, are shared unless they appear in a threadprivate directive. 20
Variables belonging to common blocks, or accessed by host or use association, and referenced in 21
called routines in the region are shared unless they appear in a threadprivate directive. 22
Dummy arguments of called routines in the region that have the VALUEattribute are private. 23
Dummy arguments of called routines in the region that do not have the VALUEattribute are 24
private if the associated actual argument is not shared. 25
Dummy arguments of called routines in the region that do not have the VALUEattribute are 26
shared if the actual argument is shared and it is a scalar variable, structure, an array that is not a 27
pointer or assumed-shape array, or a simply contiguous array section. Otherwise, the 28
data-sharing attribute of the dummy argument is implementation-deﬁned if the associated actual 29
argument is shared. 30
CHAPTER 2. DIRECTIVES 273
Cray pointees have the same data-sharing attribute as the storage with which their Cray pointers 1
are associated. 2
Implied-do indices, forall indices, and other local variables declared in called routines in the 3
region are private. 4
Fortran
2.19.2 threadprivate Directive 5
Summary 6
Thethreadprivate directive speciﬁes that variables are replicated, with each thread having its 7
own copy. The threadprivate directive is a declarative directive. 8
Syntax 9
C / C++
The syntax of the threadprivate directive is as follows: 10
#pragma omp threadprivate( list)new-line 11
wherelistis a comma-separated list of ﬁle-scope, namespace-scope, or static block-scope variables 12
that do not have incomplete types. 13
C / C++
Fortran
The syntax of the threadprivate directive is as follows: 14
!$omp threadprivate( list) 15
wherelistis a comma-separated list of named variables and named common blocks. Common 16
block names must appear between slashes. 17
Fortran
Description 18
Each copy of a threadprivate variable is initialized once, in the manner speciﬁed by the program, 19
but at an unspeciﬁed point in the program prior to the ﬁrst reference to that copy. The storage of all 20
copies of a threadprivate variable is freed according to how static variables are handled in the base 21
language, but at an unspeciﬁed point in the program. 22
274 OpenMP API – Version 5.0 November 2018
A program in which a thread references another thread’s copy of a threadprivate variable is 1
non-conforming. 2
The content of a threadprivate variable can change across a task scheduling point if the executing 3
thread switches to another task that modiﬁes the variable. For more details on task scheduling, see 4
Section 1.3 on page 20 and Section 2.10 on page 135. 5
Inparallel regions, references by the master thread will be to the copy of the variable in the 6
thread that encountered the parallel region. 7
During a sequential part references will be to the initial thread’s copy of the variable. The values of 8
data in the initial thread’s copy of a threadprivate variable are guaranteed to persist between any 9
two consecutive references to the variable in the program provided that no teamsconstruct that is 10
not nested inside of a target construct is encountered between the references and that the initial 11
thread is not nested inside of a teamsregion. For initial threads nested inside of a teamsregion, 12
the values of data in the copies of a threadprivate variable of those initial threads are guaranteed to 13
persist between any two consecutive references to the variable inside of that teamsregion. 14
The values of data in the threadprivate variables of threads that are not initial threads are 15
guaranteed to persist between two consecutive active parallel regions only if all of the 16
following conditions hold: 17
Neither parallel region is nested inside another explicit parallel region; 18
The number of threads used to execute both parallel regions is the same; 19
The thread aﬃnity policies used to execute both parallel regions are the same; 20
The value of the dyn-varinternal control variable in the enclosing task region is falseat entry to 21
bothparallel regions; and 22
Noteamsconstruct that is not nested inside of a target construct is encountered between 23
bothparallel regions. 24
Neither the omp_pause_resource noromp_pause_resource_all routine is called. 25
If these conditions all hold, and if a threadprivate variable is referenced in both regions, then 26
threadswiththesamethreadnumberintheirrespectiveregionswillreferencethesamecopyofthat 27
variable. 28
C / C++
If the above conditions hold, the storage duration, lifetime, and value of a thread’s copy of a 29
threadprivate variable that does not appear in any copyin clause on the second region will be 30
retained. Otherwise, the storage duration, lifetime, and value of a thread’s copy of the variable in 31
the second region is unspeciﬁed. 32
C / C++
CHAPTER 2. DIRECTIVES 275
Fortran
If the above conditions hold, the deﬁnition, association, or allocation status of a thread’s copy of a 1
threadprivate variable or a variable in a threadprivate common block that is not aﬀected by any 2
copyin clause that appears on the second region (a variable is aﬀected by a copyin clause if the 3
variable appears in the copyin clause or it is in a common block that appears in the copyin 4
clause) will be retained. Otherwise, the deﬁnition and association status of a thread’s copy of the 5
variable in the second region are undeﬁned, and the allocation status of an allocatable variable will 6
be implementation deﬁned. 7
If a threadprivate variable or a variable in a threadprivate common block is not aﬀected by any 8
copyin clause that appears on the ﬁrst parallel region in which it is referenced, the thread’s 9
copy of the variable inherits the declared type parameter and the default parameter values from the 10
original variable. The variable or any subobject of the variable is initially deﬁned or undeﬁned 11
according to the following rules: 12
If it has the ALLOCATABLE attribute, each copy created will have an initial allocation status of 13
unallocated; 14
If it has the POINTER attribute: 15
–If it has an initial association status of disassociated, either through explicit initialization or 16
default initialization, each copy created will have an association status of disassociated; 17
–Otherwise, each copy created will have an association status of undeﬁned. 18
If it does not have either the POINTER or the ALLOCATABLE attribute: 19
–If it is initially deﬁned, either through explicit initialization or default initialization, each copy 20
created is so deﬁned; 21
–Otherwise, each copy created is undeﬁned. 22
Fortran
C / C++
The address of a threadprivate variable is not an address constant. 23
C / C++
C++
The order in which any constructors for diﬀerent threadprivate variables of class type are called is 24
unspeciﬁed. The order in which any destructors for diﬀerent threadprivate variables of class type 25
are called is unspeciﬁed. 26
C++
276 OpenMP API – Version 5.0 November 2018
Restrictions 1
The restrictions to the threadprivate directive are as follows: 2
A threadprivate variable must not appear in any clause except the copyin,copyprivate , 3
schedule ,num_threads ,thread_limit , andifclauses. 4
A program in which an untied task accesses threadprivate storage is non-conforming. 5
C / C++
If the value of a variable referenced in an explicit initializer of a threadprivate variable is 6
modiﬁed prior to the ﬁrst reference to any instance of the threadprivate variable, then the 7
behavior is unspeciﬁed. 8
A variable that is part of another variable (as an array or structure element) cannot appear in a 9
threadprivate clause unless it is a static data member of a C++ class. 10
Athreadprivate directive for ﬁle-scope variables must appear outside any deﬁnition or 11
declaration, and must lexically precede all references to any of the variables in its list. 12
Athreadprivate directive for namespace-scope variables must appear outside any 13
deﬁnition or declaration other than the namespace deﬁnition itself, and must lexically precede all 14
references to any of the variables in its list. 15
Each variable in the list of a threadprivate directive at ﬁle, namespace, or class scope must 16
refer to a variable declaration at ﬁle, namespace, or class scope that lexically precedes the 17
directive. 18
Athreadprivate directive for static block-scope variables must appear in the scope of the 19
variable and not in a nested scope. The directive must lexically precede all references to any of 20
the variables in its list. 21
Each variable in the list of a threadprivate directive in block scope must refer to a variable 22
declaration in the same scope that lexically precedes the directive. The variable declaration must 23
use the static storage-class speciﬁer. 24
If a variable is speciﬁed in a threadprivate directive in one translation unit, it must be 25
speciﬁed in a threadprivate directive in every translation unit in which it is declared. 26
C / C++
C++
Athreadprivate directive for static class member variables must appear in the class 27
deﬁnition, in the same scope in which the member variables are declared, and must lexically 28
precede all references to any of the variables in its list. 29
A threadprivate variable must not have an incomplete type or a reference type. 30
A threadprivate variable with class type must have: 31
–An accessible, unambiguous default constructor in the case of default initialization without a 32
given initializer; 33
CHAPTER 2. DIRECTIVES 277
–An accessible, unambiguous constructor that accepts the given argument in the case of direct 1
initialization; and 2
–Anaccessible,unambiguouscopyconstructorinthecaseofcopyinitializationwithanexplicit 3
initializer. 4
C++
Fortran
A variable that is part of another variable (as an array, structure element or type parameter 5
inquiry) cannot appear in a threadprivate clause. 6
Thethreadprivate directive must appear in the declaration section of a scoping unit in 7
which the common block or variable is declared. 8
If athreadprivate directive that speciﬁes a common block name appears in one program 9
unit, then such a directive must also appear in every other program unit that contains a COMMON 10
statement that speciﬁes the same name. It must appear after the last such COMMON statement in 11
the program unit. 12
If a threadprivate variable or a threadprivate common block is declared with the BINDattribute, 13
the corresponding C entities must also be speciﬁed in a threadprivate directive in the C 14
program. 15
A blank common block cannot appear in a threadprivate directive. 16
A variable can only appear in a threadprivate directive in the scope in which it is declared. 17
It must not be an element of a common block or appear in an EQUIVALENCE statement. 18
A variable that appears in a threadprivate directive must be declared in the scope of a 19
module or have the SAVEattribute, either explicitly or implicitly. 20
Fortran
Cross References 21
dyn-varICV, see Section 2.5 on page 63. 22
Number of threads used to execute a parallel region, see Section 2.6.1 on page 78. 23
copyin clause, see Section 2.19.6.1 on page 310. 24
278 OpenMP API – Version 5.0 November 2018
2.19.3 List Item Privatization1
For any construct, a list item that appears in a data-sharing attribute clause, including a reduction 2
clause, may be privatized. Each task that references a privatized list item in any statement in the 3
construct receives at least one new list item if the construct has one or more associated loops, and 4
otherwiseeachsuchtaskreceivesonenewlistitem. EachSIMDlaneusedina simdconstructthat 5
references a privatized list item in any statement in the construct receives at least one new list item. 6
Language-speciﬁcattributesfornewlistitemsarederivedfromthecorrespondingoriginallistitem. 7
Inside the construct, all references to the original list item are replaced by references to a new list 8
item received by the task or SIMD lane. 9
If the construct has one or more associated loops, within the same logical iteration of the loop(s) 10
thesamenewlistitemreplacesallreferencestotheoriginallistitem. Foranytwologicaliterations, 11
if the referencesto the original list itemare replaced by the same listitem then the logical iterations 12
must execute in some sequential order. 13
Intherestoftheregion,itisunspeciﬁedwhetherreferencesaretoanewlistitemortheoriginallist 14
item. Therefore,ifanattemptismadetoreferencetheoriginalitem,itsvalueaftertheregionisalso 15
unspeciﬁed. If a task or a SIMD lane does not reference a privatized list item, it is unspeciﬁed 16
whether the task or SIMD lane receives a new list item. 17
The value and/or allocation status of the original list item will change only: 18
If accessed and modiﬁed via pointer; 19
If possibly accessed in the region but outside of the construct; 20
As a side eﬀect of directives or clauses; or 21
Fortran
If accessed and modiﬁed via construct association. 22
Fortran
C++
If the construct is contained in a member function, it is unspeciﬁed anywhere in the region if 23
accesses through the implicit thispointer refer to the new list item or the original list item. 24
C++
C / C++
A new list item of the same type, with automatic storage duration, is allocated for the construct. 25
The storage and thus lifetime of these list items last until the block in which they are created exits. 26
The size and alignment of the new list item are determined by the type of the variable. This 27
allocation occurs once for each task generated by the construct and once for each SIMD lane used 28
by the construct. 29
The new list item is initialized, or has an undeﬁned initial value, as if it had been locally declared 30
without an initializer. 31
C / C++
CHAPTER 2. DIRECTIVES 279
C++
If the type of a list item is a reference to a type Tthen the type will be considered to be Tfor all 1
purposes of this clause. 2
The order in which any default constructors for diﬀerent private variables of class type are called is 3
unspeciﬁed. The order in which any destructors for diﬀerent private variables of class type are 4
called is unspeciﬁed. 5
C++
Fortran
If any statement of the construct references a list item, a new list item of the same type and type 6
parameters is allocated. This allocation occurs once for each task generated by the construct and 7
once for each SIMD lane used by the construct. The initial value of the new list item is undeﬁned. 8
The initial status of a private pointer is undeﬁned. 9
For a list item or the subobject of a list item with the ALLOCATABLE attribute: 10
If the allocation status is unallocated, the new list item or the subobject of the new list item will 11
have an initial allocation status of unallocated; 12
If the allocation status is allocated, the new list item or the subobject of the new list item will 13
have an initial allocation status of allocated; and 14
Ifthenewlistitemorthesubobjectofthenewlistitemisanarray,itsboundswillbethesameas 15
those of the original list item or the subobject of the original list item. 16
A privatized list item may be storage-associated with other variables when the data-sharing 17
attribute clause is encountered. Storage association may exist because of constructs such as 18
EQUIVALENCE orCOMMON. IfAis a variable that is privatized by a construct and Bis a variable 19
that is storage-associated with A, then: 20
The contents, allocation, and association status of Bare undeﬁned on entry to the region; 21
Any deﬁnition of A, or of its allocation or association status, causes the contents, allocation, and 22
association status of Bto become undeﬁned; and 23
Any deﬁnition of B, or of its allocation or association status, causes the contents, allocation, and 24
association status of Ato become undeﬁned. 25
A privatized list item clause may be a selector of an ASSOCIATE orSELECT TYPE construct. If 26
the construct association is established prior to a parallel region, the association between the 27
associate name and the original list item will be retained in the region. 28
Finalization of a list item of a ﬁnalizable type or subobjects of a list item of a ﬁnalizable type 29
occurs at the end of the region. The order in which any ﬁnal subroutines for diﬀerent variables of a 30
ﬁnalizable type are called is unspeciﬁed. 31
Fortran
280 OpenMP API – Version 5.0 November 2018
If a list item appears in both firstprivate andlastprivate clauses, the update required 1
for the lastprivate clause occurs after all initializations for the firstprivate clause. 2
Restrictions 3
Thefollowingrestrictionsapplytoanylistitemthatisprivatizedunlessotherwisestatedforagiven 4
data-sharing attribute clause: 5
C
Avariablethatispartofanothervariable(asanarrayorstructureelement)cannotbeprivatized. 6
C
C++
A variable that is part of another variable (as an array or structure element) cannot be privatized 7
except if the data-sharing attribute clause is associated with a construct within a class non-static 8
member function and the variable is an accessible data member of the object for which the 9
non-static member function is invoked. 10
A variable of class type (or array thereof) that is privatized requires an accessible, unambiguous 11
default constructor for the class type. 12
C++
C / C++
A variable that is privatized must not have a const-qualiﬁed type unless it is of class type with 13
amutable member. This restriction does not apply to the firstprivate clause. 14
A variable that is privatized must not have an incomplete type or be a reference to an incomplete 15
type. 16
C / C++
Fortran
A variable that is part of another variable (as an array or structure element) cannot be privatized. 17
A variable that is privatized must either be deﬁnable, or an allocatable variable. This restriction 18
does not apply to the firstprivate clause. 19
Variables that appear in namelist statements, in variable format expressions, and in expressions 20
for statement function deﬁnitions, may not be privatized. 21
Pointers with the INTENT(IN) attribute may not be privatized. This restriction does not apply 22
to the firstprivate clause. 23
Assumed-size arrays may not be privatized in a target,teams, ordistribute construct. 24
Fortran
CHAPTER 2. DIRECTIVES 281
2.19.4 Data-Sharing Attribute Clauses1
Several constructs accept clauses that allow a user to control the data-sharing attributes of variables 2
referenced in the construct. Not all of the clauses listed in this section are valid on all directives. 3
The set of clauses that is valid on a particular directive is described with the directive. 4
Mostoftheclausesacceptacomma-separatedlistoflistitems(seeSection2.1onpage38). Alllist 5
items that appear in a clause must be visible, according to the scoping rules of the base language. 6
Withtheexceptionofthe default clause,clausesmayberepeatedasneeded. Alistitemmaynot 7
appear in more than one clause on the same directive, except that it may be speciﬁed in both 8
firstprivate andlastprivate clauses. 9
The reduction data-sharing attribute clauses are explained in Section 2.19.5 on page 293. 10
C++
If a variable referenced in a data-sharing attribute clause has a type derived from a template, and 11
the program does not otherwise reference that variable then any behavior related to that variable is 12
unspeciﬁed. 13
C++
Fortran
When a named common block appears in a private ,firstprivate ,lastprivate , or 14
shared clause of a directive, none of its members may be declared in another data-sharing 15
attribute clause in that directive. When individual members of a common block appear in a 16
private ,firstprivate ,lastprivate ,reduction , orlinear clause of a directive, 17
thestorageofthespeciﬁedvariablesisnolongerFortranassociatedwiththestorageofthecommon 18
block itself. 19
Fortran
2.19.4.1 default Clause 20
Summary 21
Thedefault clause explicitly determines the data-sharing attributes of variables that are 22
referencedina parallel ,teams,ortaskgeneratingconstructandwouldotherwisebeimplicitly 23
determined (see Section 2.19.1.1 on page 270). 24
282 OpenMP API – Version 5.0 November 2018
Syntax 1
C / C++
The syntax of the default clause is as follows: 2
default(shared | none) 3
C / C++
Fortran
The syntax of the default clause is as follows: 4
default(private | firstprivate | shared | none) 5
Fortran
Description 6
Thedefault(shared) clause causes all variables referenced in the construct that have 7
implicitly determined data-sharing attributes to be shared. 8
Fortran
Thedefault(firstprivate) clause causes all variables in the construct that have implicitly 9
determined data-sharing attributes to be ﬁrstprivate. 10
Thedefault(private) clause causes all variables referenced in the construct that have 11
implicitly determined data-sharing attributes to be private. 12
Fortran
Thedefault(none) clause requires that each variable that is referenced in the construct, and 13
that does not have a predetermined data-sharing attribute, must have its data-sharing attribute 14
explicitly determined by being listed in a data-sharing attribute clause. 15
Restrictions 16
The restrictions to the default clause are as follows: 17
Only a single default clause may be speciﬁed on a parallel ,task,taskloop or 18
teamsdirective. 19
2.19.4.2 shared Clause 20
Summary 21
Theshared clause declares one or more list items to be shared by tasks generated by a 22
parallel ,teams, or task generating construct. 23
CHAPTER 2. DIRECTIVES 283
Syntax 1
The syntax of the shared clause is as follows: 2
shared( list) 3
Description 4
Allreferencestoalistitemwithinataskrefertothestorageareaoftheoriginalvariableatthepoint 5
the directive was encountered. 6
The programmer must ensure, by adding proper synchronization, that storage shared by an explicit 7
task region does not reach the end of its lifetime before the explicit task region completes its 8
execution. 9
Fortran
The association status of a shared pointer becomes undeﬁned upon entry to and exit from the 10
parallel ,teams, or task generating construct if it is associated with a target or a subobject of a 11
target that appears as a privatized list item in a data-sharing attribute clause on the construct. 12
13
Note– Passingasharedvariabletoaproceduremayresultintheuseoftemporarystorageinplace 14
of the actual argument when the corresponding dummy argument does not have the VALUEor 15
CONTIGUOUS attribute and its data-sharing attribute is implementation-deﬁned as per the rules in 16
Section2.19.1.2onpage273. Theseconditionseﬀectivelyresultinreferencesto,anddeﬁnitionsof, 17
thetemporarystorageduringtheprocedurereference. Furthermore,thevalueofthesharedvariable 18
is copied into the intervening temporary storage before the procedure reference when the dummy 19
argument does not have the INTENT(OUT) attribute, and is copied out of the temporary storage 20
intothesharedvariablewhenthedummyargumentdoesnothavethe INTENT(IN) attribute. Any 21
references to (or deﬁnitions of) the shared storage that is associated with the dummy argument by 22
any other task must be synchronized with the procedure reference to avoid possible data races. 23
24
25
Fortran
Restrictions 26
The restrictions for the shared clause are as follows: 27
C
A variable that is part of another variable (as an array or structure element) cannot appear in a 28
shared clause. 29
C
284 OpenMP API – Version 5.0 November 2018
C++
A variable that is part of another variable (as an array or structure element) cannot appear in a 1
shared clause except if the shared clause is associated with a construct within a class 2
non-staticmemberfunctionandthevariableisanaccessibledatamemberoftheobjectforwhich 3
the non-static member function is invoked. 4
C++
Fortran
A variable that is part of another variable (as an array, structure element or type parameter 5
inquiry) cannot appear in a shared clause. 6
Fortran
2.19.4.3 private Clause 7
Summary 8
Theprivate clause declares one or more list items to be private to a task or to a SIMD lane. 9
Syntax 10
The syntax of the private clause is as follows: 11
private( list) 12
Description 13
Theprivate clause speciﬁes that its list items are to be privatized according to Section 2.19.3 on 14
page 279. Each task or SIMD lane that references a list item in the construct receives only one new 15
list item, unless the construct has one or more associated loops and the order(concurrent) 16
clause is also present. 17
List items that appear in a private ,firstprivate , orreduction clause in a parallel 18
construct may also appear in a private clause in an enclosed parallel , worksharing, loop, 19
task,taskloop ,simd, ortarget construct. 20
List items that appear in a private orfirstprivate clause in a taskortaskloop 21
construct may also appear in a private clause in an enclosed parallel ,loop,task, 22
taskloop ,simd, ortarget construct. 23
List items that appear in a private ,firstprivate ,lastprivate , orreduction clause 24
in a worksharing construct may also appear in a private clause in an enclosed parallel , 25
loop,task,simd, ortarget construct. 26
List items that appear in a private clause on a loopconstruct may also appear in a private 27
clause in an enclosed loop,parallel , orsimdconstruct. 28
CHAPTER 2. DIRECTIVES 285
Restrictions 1
The restrictions to the private clause are as speciﬁed in Section 2.19.3. 2
Cross References 3
List Item Privatization, see Section 2.19.3 on page 279. 4
2.19.4.4 firstprivate Clause 5
Summary 6
Thefirstprivate clause declares one or more list items to be private to a task, and initializes 7
each of them with the value that the corresponding original item has when the construct is 8
encountered. 9
Syntax 10
The syntax of the firstprivate clause is as follows: 11
firstprivate( list) 12
Description 13
Thefirstprivate clause provides a superset of the functionality provided by the private 14
clause. 15
A list item that appears in a firstprivate clause is subject to the private clause semantics 16
described in Section 2.19.4.3 on page 285, except as noted. In addition, the new list item is 17
initialized from the original list item existing before the construct. The initialization of the new list 18
item is done once for each task that references the list item in any statement in the construct. The 19
initialization is done prior to the execution of the construct. 20
For a firstprivate clause on a parallel ,task,taskloop ,target, orteams 21
construct, the initial value of the new list item is the value of the original list item that exists 22
immediately prior to the construct in the task region where the construct is encountered unless 23
otherwise speciﬁed. For a firstprivate clause on a worksharing construct, the initial value of 24
the new list item for each implicit task of the threads that execute the worksharing construct is the 25
value of the original list item that exists in the implicit task immediately prior to the point in time 26
that the worksharing construct is encountered unless otherwise speciﬁed. 27
To avoid data races, concurrent updates of the original list item must be synchronized with the read 28
of the original list item that occurs as a result of the firstprivate clause. 29
286 OpenMP API – Version 5.0 November 2018
C / C++
For variables of non-array type, the initialization occurs by copy assignment. For an array of 1
elements of non-array type, each element is initialized as if by assignment from an element of the 2
original array to the corresponding element of the new array. 3
C / C++
C++
For each variable of class type: 4
If the firstprivate clause is not on a target construct then a copy constructor is invoked 5
to perform the initialization; and 6
If the firstprivate clause is on a target construct then it is unspeciﬁed how many copy 7
constructors, if any, are invoked. 8
If copy constructors are called, the order in which copy constructors for diﬀerent variables of class 9
type are called is unspeciﬁed. 10
C++
Fortran
If the original list item does not have the POINTER attribute, initialization of the new list items 11
occurs as if by intrinsic assignment unless the list item has a type bound procedure as a deﬁned 12
assignment. If the original list item that does not have the POINTER attribute has the allocation 13
status of unallocated, the new list items will have the same status. 14
If the original list item has the POINTER attribute, the new list items receive the same association 15
status of the original list item as if by pointer assignment. 16
Fortran
Restrictions 17
The restrictions to the firstprivate clause are as follows: 18
A list item that is private within a parallel region must not appear in a firstprivate 19
clauseonaworksharingconstructifanyoftheworksharingregionsarisingfromtheworksharing 20
construct ever bind to any of the parallel regions arising from the parallel construct. 21
A list item that is private within a teamsregion must not appear in a firstprivate clause 22
on adistribute construct if any of the distribute regions arising from the 23
distribute construct ever bind to any of the teamsregions arising from the teams 24
construct. 25
A list item that appears in a reduction clause of a parallel construct must not appear in a 26
firstprivate clause on a worksharing, task, ortaskloop construct if any of the 27
worksharing or taskregions arising from the worksharing, task, ortaskloop construct 28
ever bind to any of the parallel regions arising from the parallel construct. 29
CHAPTER 2. DIRECTIVES 287
A list item that appears in a reduction clause of a teamsconstruct must not appear in a 1
firstprivate clause on a distribute construct if any of the distribute regions 2
arisingfromthe distribute constructeverbindtoanyofthe teamsregionsarisingfromthe 3
teamsconstruct. 4
A list item that appears in a reduction clause of a worksharing construct must not appear in a 5
firstprivate clause in a taskconstruct encountered during execution of any of the 6
worksharing regions arising from the worksharing construct. 7
C++
A variable of class type (or array thereof) that appears in a firstprivate clause requires an 8
accessible, unambiguous copy constructor for the class type. 9
C++
C / C++
Ifalistitemina firstprivate clauseonaworksharingconstructhasareferencetypethenit 10
must bind to the same object for all threads of the team. 11
C / C++
Fortran
If the list item is a polymorphic variable with the ALLOCATABLE attribute, the behavior is 12
unspeciﬁed. 13
Fortran
2.19.4.5 lastprivate Clause 14
Summary 15
Thelastprivate clause declares one or more list items to be private to an implicit task or to a 16
SIMDlane,andcausesthecorrespondingoriginallistitemtobeupdatedaftertheendoftheregion. 17
Syntax 18
The syntax of the lastprivate clause is as follows: 19
lastprivate( [ lastprivate-modiﬁer :] list) 20
wherelastprivate-modiﬁer is: 21
conditional 22
288 OpenMP API – Version 5.0 November 2018
Description 1
Thelastprivate clause provides a superset of the functionality provided by the private 2
clause. 3
A list item that appears in a lastprivate clause is subject to the private clause semantics 4
described in Section 2.19.4.3 on page 285. In addition, when a lastprivate clause without the 5
conditional modiﬁer appears on a directive, the value of each new list item from the 6
sequentially last iteration of the associated loops, or the lexically last section construct, is 7
assigned to the original list item. When the conditional modiﬁer appears on the clause, if an 8
assignment to a list item is encountered in the construct then the original list item is assigned the 9
value that is assigned to the new list item in the sequentially last iteration or lexically last section in 10
which such an assignment is encountered. 11
C / C++
For an array of elements of non-array type, each element is assigned to the corresponding element 12
of the original array. 13
C / C++
Fortran
If the original list item does not have the POINTER attribute, its update occurs as if by intrinsic 14
assignment unless it has a type bound procedure as a deﬁned assignment. 15
If the original list item has the POINTER attribute, its update occurs as if by pointer assignment. 16
Fortran
When the conditional modiﬁer does not appear on the lastprivate clause, list items that 17
are not assigned a value by the sequentially last iteration of the loops, or by the lexically last 18
section construct, have unspeciﬁed values after the construct. Unassigned subcomponents also 19
have unspeciﬁed values after the construct. 20
If the lastprivate clause is used on a construct to which neither the nowait nor the 21
nogroup clauses areapplied, the original listitem becomes deﬁnedat the end ofthe construct. To 22
avoiddataraces,concurrentreadsorupdatesoftheoriginallistitemmustbesynchronizedwiththe 23
update of the original list item that occurs as a result of the lastprivate clause. 24
Otherwise, If the lastprivate clause is used on a construct to which the nowait or the 25
nogroup clauses are applied, accesses to the original list item may create a data race. To avoid 26
thisdatarace,ifanassignmenttotheoriginallistitemoccursthensynchronizationmustbeinserted 27
to ensure that the assignment completes and the original list item is ﬂushed to memory. 28
If a list item that appears in a lastprivate clause with the conditional modiﬁer is 29
modiﬁed in the region by an assignment outside the construct or not to the list item then the value 30
assigned to the original list item is unspeciﬁed. 31
CHAPTER 2. DIRECTIVES 289
Restrictions 1
The restrictions to the lastprivate clause are as follows: 2
A list item that is private within a parallel region, or that appears in the reduction clause 3
of aparallel construct, must not appear in a lastprivate clause on a worksharing 4
construct if any of the corresponding worksharing regions ever binds to any of the corresponding 5
parallel regions. 6
A list item that appears in a lastprivate clause with the conditional modiﬁer must be a 7
scalar variable. 8
C++
A variable of class type (or array thereof) that appears in a lastprivate clause requires an 9
accessible, unambiguous default constructor for the class type, unless the list item is also 10
speciﬁed in a firstprivate clause. 11
A variable of class type (or array thereof) that appears in a lastprivate clause requires an 12
accessible, unambiguous copy assignment operator for the class type. The order in which copy 13
assignment operators for diﬀerent variables of class type are called is unspeciﬁed. 14
C++
C / C++
If a list item in a lastprivate clause on a worksharing construct has a reference type then it 15
must bind to the same object for all threads of the team. 16
C / C++
Fortran
A variable that appears in a lastprivate clause must be deﬁnable. 17
Iftheoriginallistitemhasthe ALLOCATABLE attribute,thecorrespondinglistitemwhosevalue 18
is assigned to the original list item must have an allocation status of allocated upon exit from the 19
sequentially last iteration or lexically last section construct. 20
If the list item is a polymorphic variable with the ALLOCATABLE attribute, the behavior is 21
unspeciﬁed. 22
Fortran
2.19.4.6 linear Clause 23
Summary 24
Thelinear clause declares one or more list items to be private and to have a linear relationship 25
with respect to the iteration space of a loop associated with the construct on which the clause 26
appears. 27
290 OpenMP API – Version 5.0 November 2018
Syntax 1
C
The syntax of the linear clause is as follows: 2
linear( linear-list[ :linear-step] ) 3
wherelinear-list is one of the following 4
list 5
modiﬁer (list) 6
wheremodiﬁeris one of the following: 7
val 8
C
C++
The syntax of the linear clause is as follows: 9
linear( linear-list[ :linear-step] ) 10
wherelinear-list is one of the following 11
list 12
modiﬁer (list) 13
wheremodiﬁeris one of the following: 14
ref 15
val 16
uval 17
C++
Fortran
The syntax of the linear clause is as follows: 18
linear( linear-list[ :linear-step] ) 19
wherelinear-list is one of the following 20
list 21
modiﬁer (list) 22
CHAPTER 2. DIRECTIVES 291
wheremodiﬁeris one of the following: 1
ref 2
val 3
uval 4
Fortran
Description 5
Thelinear clause provides a superset of the functionality provided by the private clause. A 6
list item that appears in a linear clause is subject to the private clause semantics described in 7
Section 2.19.4.3 on page 285 except as noted. If linear-step is not speciﬁed, it is assumed to be 1. 8
When a linear clause is speciﬁed on a construct, the value of the new list item on each iteration 9
of the associated loop(s) corresponds to the value of the original list item before entering the 10
construct plus the logical number of the iteration times linear-step . The value corresponding to the 11
sequentially last iteration of the associated loop(s) is assigned to the original list item. 12
When a linear clause is speciﬁed on a declarative directive, all list items must be formal 13
parameters (or, in Fortran, dummy arguments) of a function that will be invoked concurrently on 14
each SIMD lane. If no modiﬁeris speciﬁed or the valoruvalmodiﬁer is speciﬁed, the value of 15
each list item on each lane corresponds to the value of the list item upon entry to the function plus 16
the logical number of the lane times linear-step . If the uvalmodiﬁer is speciﬁed, each invocation 17
uses the same storage location for each SIMD lane; this storage location is updated with the ﬁnal 18
value of the logically last lane. If the refmodiﬁer is speciﬁed, the storage location of each list 19
item on each lane corresponds to an array at the storage location upon entry to the function indexed 20
by the logical number of the lane times linear-step . 21
Restrictions 22
Thelinear-step expression must be invariant during the execution of the region that corresponds 23
to the construct. Otherwise, the execution results in unspeciﬁed behavior. 24
Only a loop iteration variable of a loop that is associated with the construct may appear as a 25
list-itemin alinear clause if a reduction clause with the inscan modiﬁer also appears 26
on the construct. 27
C
Alist-itemthat appears in a linear clause must be of integral or pointer type. 28
C
292 OpenMP API – Version 5.0 November 2018
C++
Alist-itemthat appears in a linear clause without the refmodiﬁer must be of integral or 1
pointer type, or must be a reference to an integral or pointer type. 2
Thereforuvalmodiﬁer can only be used if the list-itemis of a reference type. 3
If a list item in a linear clause on a worksharing construct has a reference type then it must 4
bind to the same object for all threads of the team. 5
If the list item is of a reference type and the refmodiﬁer is not speciﬁed and if any write to the 6
list item occurs before any read of the list item then the result is unspeciﬁed. 7
C++
Fortran
Alist-itemthat appears in a linear clause without the refmodiﬁer must be of type 8
integer . 9
Thereforuvalmodiﬁer can only be used if the list-itemis a dummy argument without the 10
VALUEattribute. 11
Variables that have the POINTER attribute and Cray pointers may not appear in a linear 12
clause. 13
If the list item has the ALLOCATABLE attribute and the refmodiﬁer is not speciﬁed, the 14
allocation status of the list item in the sequentially last iteration must be allocated upon exit from 15
that iteration. 16
If the refmodiﬁer is speciﬁed, variables with the ALLOCATABLE attribute, assumed-shape 17
arrays and polymorphic variables may not appear in the linear clause. 18
If the list item is a dummy argument without the VALUEattribute and the refmodiﬁer is not 19
speciﬁed and if any write to the list item occurs before any read of the list item then the result is 20
unspeciﬁed. 21
A common block name cannot appear in a linear clause. 22
Fortran
2.19.5 Reduction Clauses and Directives 23
The reduction clauses are data-sharing attribute clauses that can be used to perform some forms of 24
recurrence calculations in parallel. Reduction clauses include reduction scoping clauses and 25
reduction participating clauses. Reduction scoping clauses deﬁne the region in which a reduction is 26
computed. Reduction participating clauses deﬁne the participants in the reduction. Reduction 27
clauses specify a reduction-identiﬁer and one or more list items. 28
CHAPTER 2. DIRECTIVES 293
2.19.5.1 Properties Common To All Reduction Clauses1
Syntax 2
The syntax of a reduction-identiﬁer is deﬁned as follows: 3
C
Areduction-identiﬁer is either an identiﬁer or one of the following operators: +,-,*,&,|,^,&& 4
and||. 5
C
C++
Areduction-identiﬁer is either an id-expression or one of the following operators: +,-,*,&,|,^, 6
&&and||. 7
C++
Fortran
Areduction-identiﬁer is either a base language identiﬁer, or a user-deﬁned operator, or one of the 8
following operators: +,-,*,.and.,.or.,.eqv.,.neqv., or one of the following intrinsic 9
procedure names: max,min,iand,ior,ieor. 10
Fortran
C / C++
Table 2.11 lists each reduction-identiﬁer that is implicitly declared at every scope for arithmetic 11
types and its semantic initializer value. The actual initializer value is that value as expressed in the 12
data type of the reduction list item. 13
TABLE 2.11:Implicitly Declared C/C++ reduction-identiﬁers
Identiﬁer Initializer Combiner
+ omp_priv = 0 omp_out += omp_in
- omp_priv = 0 omp_out += omp_in
* omp_priv = 1 omp_out *= omp_in
& omp_priv = ~ 0 omp_out &= omp_in
| omp_priv = 0 omp_out |= omp_in
^ omp_priv = 0 omp_out ^= omp_in
&& omp_priv = 1 omp_out = omp_in && omp_out
table continued on next page
294 OpenMP API – Version 5.0 November 2018
table continued from previous page
Identiﬁer Initializer Combiner
|| omp_priv = 0 omp_out = omp_in || omp_out
max omp_priv = Least
representable number in the
reduction list item typeomp_out = omp_in > omp_out ?
omp_in : omp_out
min omp_priv = Largest
representable number in the
reduction list item typeomp_out = omp_in < omp_out ?
omp_in : omp_out
C / C++
Fortran
Table 2.12 lists each reduction-identiﬁer that is implicitly declared for numeric and logical types 1
and its semantic initializer value. The actual initializer value is that value as expressed in the data 2
type of the reduction list item. 3
TABLE 2.12:Implicitly Declared Fortran reduction-identiﬁers
Identiﬁer Initializer Combiner
+ omp_priv = 0 omp_out = omp_in + omp_out
- omp_priv = 0 omp_out = omp_in + omp_out
* omp_priv = 1 omp_out = omp_in *omp_out
.and. omp_priv = .true. omp_out = omp_in .and. omp_out
.or. omp_priv = .false. omp_out = omp_in .or. omp_out
.eqv. omp_priv = .true. omp_out = omp_in .eqv. omp_out
.neqv. omp_priv = .false. omp_out = omp_in .neqv. omp_out
max omp_priv = Least
representable number in the
reduction list item typeomp_out = max(omp_in, omp_out)
min omp_priv = Largest
representable number in the
reduction list item typeomp_out = min(omp_in, omp_out)
table continued on next page
CHAPTER 2. DIRECTIVES 295
table continued from previous page
Identiﬁer Initializer Combiner
iand omp_priv = All bits on omp_out = iand(omp_in, omp_out)
ior omp_priv = 0 omp_out = ior(omp_in, omp_out)
ieor omp_priv = 0 omp_out = ieor(omp_in, omp_out)
Fortran
Intheabovetables, omp_in andomp_out correspondtotwoidentiﬁersthatrefertostorageofthe 1
type of the list item. omp_out holds the ﬁnal value of the combiner operation. 2
Anyreduction-identiﬁer that is deﬁned with the declare reduction directive is also valid. In 3
that case, the initializer and combiner of the reduction-identiﬁer are speciﬁed by the 4
initializer-clause and thecombiner in the declare reduction directive. 5
Description 6
A reduction clause speciﬁes a reduction-identiﬁer and one or more list items. 7
Thereduction-identiﬁer speciﬁed in a reduction clause must match a previously declared 8
reduction-identiﬁer of the same name and type for each of the list items. This match is done by 9
means of a name lookup in the base language. 10
The list items that appear in a reduction clause may include array sections. 11
C++
If the type is a derived class, then any reduction-identiﬁer that matches its base classes is also a 12
match, if there is no speciﬁc match for the type. 13
If thereduction-identiﬁer is not anid-expression , then it is implicitly converted to one by 14
prepending the keyword operator (for example, +becomesoperator +). 15
If thereduction-identiﬁer is qualiﬁed then a qualiﬁed name lookup is used to ﬁnd the declaration. 16
If thereduction-identiﬁer is unqualiﬁed then an argument-dependent name lookup must be 17
performed using the type of each list item. 18
C++
Ifthelistitemisanarrayorarraysection,itwillbetreatedasifareductionclausewouldbeapplied 19
to each separate element of the array section. 20
If the list item is an array section, the elements of any copy of the array section will be allocated 21
contiguously. 22
296 OpenMP API – Version 5.0 November 2018
Fortran
If the original list item has the POINTER attribute, any copies of the list item are associated with 1
private targets. 2
Fortran
Any copies associated with the reduction are initialized with the initializer value of the 3
reduction-identiﬁer . 4
Any copies are combined using the combiner associated with the reduction-identiﬁer . 5
Execution Model Events 6
Thereduction-begin eventoccursbeforeataskbeginstoperformloadsandstoresthatbelongtothe 7
implementation of a reduction and the reduction-end event occurs after the task has completed 8
loads and stores associated with the reduction. If a task participates in multiple reductions, each 9
reduction may be bracketed by its own pair of reduction-begin /reduction-end events or multiple 10
reductions may be bracketed by a single pair of events. The interval deﬁned by a pair of 11
reduction-begin /reduction-end events may not contain a task scheduling point. 12
Tool Callbacks 13
A thread dispatches a registered ompt_callback_reduction with 14
ompt_sync_region_reduction in itskindargument and ompt_scope_begin as its 15
endpoint argumentforeachoccurrenceofa reduction-begin eventinthatthread. Similarly,athread 16
dispatches a registered ompt_callback_reduction with 17
ompt_sync_region_reduction in itskindargument and ompt_scope_end as its 18
endpoint argument for each occurrence of a reduction-end event in that thread. These callbacks 19
occur in the context of the task that performs the reduction and has the type signature 20
ompt_callback_sync_region_t . 21
Restrictions 22
The restrictions common to reduction clauses are as follows: 23
Any number of reduction clauses can be speciﬁed on the directive, but a list item (or any array 24
element in an array section) can appear only once in reduction clauses for that directive. 25
Forareduction-identiﬁer declaredwiththe declare reduction construct,thedirectivemust 26
appear before its use in a reduction clause. 27
If a list item is an array section or an array element, its base expression must be a base language 28
identiﬁer. 29
If a list item is an array section, it must specify contiguous storage and it cannot be a zero-length 30
array section. 31
CHAPTER 2. DIRECTIVES 297
If a list item is an array section or an array element, accesses to the elements of the array outside 1
the speciﬁed array section or array element result in unspeciﬁed behavior. 2
C
A variable that is part of another variable, with the exception of array elements, cannot appear in 3
a reduction clause. 4
C
C++
A variable that is part of another variable, with the exception of array elements, cannot appear in 5
a reduction clause except if the reduction clause is associated with a construct within a class 6
non-staticmemberfunctionandthevariableisanaccessibledatamemberoftheobjectforwhich 7
the non-static member function is invoked. 8
C++
C / C++
The type of a list item that appears in a reduction clause must be valid for the 9
reduction-identiﬁer . For a maxorminreduction in C, the type of the list item must be an 10
allowed arithmetic data type: char,int,float,double, or_Bool, possibly modiﬁed with 11
long,short,signed, orunsigned . For a maxorminreduction in C++, the type of the 12
list item must be an allowed arithmetic data type: char,wchar_t ,int,float,double, or 13
bool, possibly modiﬁed with long,short,signed, orunsigned . 14
A list item that appears in a reduction clause must not be const-qualiﬁed. 15
Thereduction-identiﬁer for any list item must be unambiguous and accessible. 16
C / C++
Fortran
A variable that is part of another variable, with the exception of array elements, cannot appear in 17
a reduction clause. 18
A type parameter inquiry cannot appear in a reduction clause. 19
The type, type parameters and rank of a list item that appears in a reduction clause must be valid 20
for thecombiner andinitializer . 21
A list item that appears in a reduction clause must be deﬁnable. 22
A procedure pointer may not appear in a reduction clause. 23
A pointer with the INTENT(IN) attribute may not appear in the reduction clause. 24
An original list item with the POINTER attribute or any pointer component of an original list 25
item that is referenced in the combiner must be associated at entry to the construct that contains 26
thereductionclause. Additionally,thelistitemorthepointercomponentofthelistitemmustnot 27
be deallocated, allocated, or pointer assigned within the region. 28
298 OpenMP API – Version 5.0 November 2018
An original list item with the ALLOCATABLE attribute or any allocatable component of an 1
original list item that corresponds to the special variable identiﬁer in the combiner or the 2
initializer must be in the allocated state at entry to the construct that contains the reduction 3
clause. Additionally, the list item or the allocatable component of the list item must be neither 4
deallocated nor allocated, explicitly or implicitly, within the region. 5
If thereduction-identiﬁer is deﬁned in a declare reduction directive, the 6
declare reduction directive must be in the same subprogram, or accessible by host or use 7
association. 8
If thereduction-identiﬁer is a user-deﬁned operator, the same explicit interface for that operator 9
must be accessible as at the declare reduction directive. 10
If thereduction-identiﬁer is deﬁned in a declare reduction directive, any subroutine or 11
function referenced in the initializer clause or combiner expression must be an intrinsic function, 12
or must have an explicit interface where the same explicit interface is accessible as at the 13
declare reduction directive. 14
Fortran
Cross References 15
ompt_scope_begin andompt_scope_end , see Section 4.4.4.11 on page 443. 16
ompt_sync_region_reduction , see Section 4.4.4.13 on page 444. 17
ompt_callback_sync_region_t , see Section 4.5.2.13 on page 474. 18
2.19.5.2 Reduction Scoping Clauses 19
Reduction scoping clauses deﬁne the region in which a reduction is computed by tasks or SIMD 20
lanes. All properties common to all reduction clauses, which are deﬁned in Section 2.19.5.1 on 21
page 294, apply to reduction scoping clauses. 22
The number of copies created for each list item and the time at which those copies are initialized 23
are determined by the particular reduction scoping clause that appears on the construct. 24
The time at which the original list item contains the result of the reduction is determined by the 25
particular reduction scoping clause. 26
The location in the OpenMP program at which values are combined and the order in which values 27
are combined are unspeciﬁed. Therefore, when comparing sequential and parallel runs, or when 28
comparing one parallel run to another (even if the number of threads used is the same), there is no 29
guarantee that bitwise-identical results will be obtained or that side eﬀects (such as ﬂoating-point 30
exceptions) will be identical or take place at the same location in the OpenMP program. 31
To avoid data races, concurrent reads or updates of the original list item must be synchronized with 32
the update of the original list item that occurs as a result of the reduction computation. 33
CHAPTER 2. DIRECTIVES 299
2.19.5.3 Reduction Participating Clauses1
A reduction participating clause speciﬁes a task or a SIMD lane as a participant in a reduction 2
deﬁned by a reduction scoping clause. All properties common to all reduction clauses, which are 3
deﬁned in Section 2.19.5.1 on page 294, apply to reduction participating clauses. 4
Accesses to the original list item may be replaced by accesses to copies of the original list item 5
created by a region that corresponds to a construct with a reduction scoping clause. 6
In any case, the ﬁnal value of the reduction must be determined as if all tasks or SIMD lanes that 7
participate in the reduction are executed sequentially in some arbitrary order. 8
2.19.5.4 reduction Clause 9
Summary 10
Thereduction clause speciﬁes a reduction-identiﬁer and one or more list items. For each list 11
item, a private copy is created in each implicit task or SIMD lane and is initialized with the 12
initializer value of the reduction-identiﬁer . After the end of the region, the original list item is 13
updated with the values of the private copies using the combiner associated with the 14
reduction-identiﬁer . 15
Syntax 16
reduction( [ reduction-modiﬁer ,]reduction-identiﬁer :list) 17
Wherereduction-identiﬁer is deﬁned in Section 2.19.5.1 on page 294, and reduction-modiﬁer is 18
one of the following: 19
inscan 20
task 21
default 22
Description 23
Thereduction clause is a reduction scoping clause and a reduction participating clause, as 24
described in Section 2.19.5.2 on page 299 and Section 2.19.5.3 on page 300. 25
Ifreduction-modiﬁer is not present or the default reduction-modiﬁer is present, the behavior is 26
as follows. For parallel and worksharing constructs, one or more private copies of each list 27
item are created for each implicit task, as if the private clause had been used. For the simd 28
construct, one or more private copies of each list item are created for each SIMD lane, as if the 29
private clause had been used. For the taskloop construct, private copies are created 30
according to the rules of the reduction scoping clauses. For the teamsconstruct, one or more 31
300 OpenMP API – Version 5.0 November 2018
private copies of each list item are created for the initial task of each team in the league, as if the 1
private clausehadbeenused. Forthe loopconstruct,privatecopiesarecreatedandusedinthe 2
construct according to the description and restrictions in Section 2.19.3 on page 279. At the end of 3
a region that corresponds to a construct for which the reduction clause was speciﬁed, the 4
original list item is updated by combining its original value with the ﬁnal value of each of the 5
private copies, using the combiner of the speciﬁed reduction-identiﬁer . 6
If the inscan reduction-modiﬁer is present, a scan computation is performed over updates to the 7
list item performed in each logical iteration of the loop associated with the worksharing-loop, 8
worksharing-loop SIMD, or simdconstruct (see Section 2.9.6 on page 132). The list items are 9
privatized in the construct according to the description and restrictions in Section 2.19.3 on 10
page 279. At the end of the region, each original list item is assigned the value of the private copy 11
from the last logical iteration of the loops associated with the construct. 12
If the taskreduction-modiﬁer is present fora parallel or worksharingconstruct,then each list 13
item is privatized according to the description and restrictions in Section 2.19.3 on page 279, and 14
an unspeciﬁed number of additional private copies are created to support task reductions. Any 15
copies associated with the reduction are initialized before they are accessed by the tasks that 16
participate in the reduction, which include all implicit tasks in the corresponding region and all 17
participating explicit tasks that specify an in_reduction clause (see Section 2.19.5.6 on 18
page 303). After the end of the region, the original list item contains the result of the reduction. 19
Ifnowait is not speciﬁed for the construct, the reduction computation will be complete at the end 20
of the construct; however, if the reduction clause is used on a construct to which nowait is 21
also applied, accesses to the original list item will create a race and, thus, have unspeciﬁed eﬀect 22
unless synchronization ensures that they occur after all threads have executed all of their iterations 23
orsection constructs, and the reduction computation has completed and stored the computed 24
value of that list item. This can most simply be ensured through a barrier synchronization. 25
Restrictions 26
The restrictions to the reduction clause are as follows: 27
All restrictions common to all reduction clauses, which are listed in Section 2.19.5.1 on 28
page 294, apply to this clause. 29
A list item that appears in a reduction clause of a worksharing construct must be shared in 30
theparallel region to which a corresponding worksharing region binds. 31
If a list item that appears in a reduction clause of a worksharing construct or loopconstruct 32
for which the corresponding region binds to a parallel region is an array section or an array 33
element, all threads that participate in the reduction must specify the same storage location. 34
A list item that appears in a reduction clause with the inscan reduction-modiﬁer must 35
appear as a list item in an inclusive orexclusive clause on a scandirective enclosed by 36
the construct. 37
CHAPTER 2. DIRECTIVES 301
Areduction clause without the inscan reduction-modiﬁer may not appear on a construct 1
on which a reduction clause with the inscan reduction-modiﬁer appears. 2
Areduction clause with the taskreduction-modiﬁer may only appear on a parallel 3
construct, a worksharing construct or a combined or composite construct for which any of the 4
aforementioned constructs is a constituent construct and simdorloopare not constituent 5
constructs. 6
Areduction clause with the inscan reduction-modiﬁer may only appear on a 7
worksharing-loop construct, a worksharing-loop SIMD construct, a simdconstruct, a parallel 8
worksharing-loop construct or a parallel worksharing-loop SIMD construct. 9
A list item that appears in a reduction clause of the innermost enclosing worksharing or 10
parallel construct may not be accessed in an explicit task generated by a construct for which 11
anin_reduction clause over the same list item does not appear. 12
Thetaskreduction-modiﬁer may not appear in a reduction clause if the nowait clause is 13
speciﬁed on the same construct. 14
C / C++
If a list item in a reduction clause on a worksharing construct or loopconstruct for which 15
the corresponding region binds to a parallel region has a reference type then it must bind to the 16
same object for all threads of the team. 17
If a list item in a reduction clause on a worksharing construct or loopconstruct for which 18
the corresponding region binds to a parallel region is an array section or an array element then 19
the base pointer must point to the same variable for all threads of the team. 20
A variable of class type (or array thereof) that appears in a reduction clause with the 21
inscan reduction-modiﬁer requires an accessible, unambiguous default constructor for the 22
class type. The numberof calls to the defaultconstructor while performing the scan computation 23
is unspeciﬁed. 24
A variable of class type (or array thereof) that appears in a reduction clause with the 25
inscan reduction-modiﬁer requires an accessible, unambiguous copy assignment operator for 26
the class type. The number of calls to the copy assignment operator while performing the scan 27
computation is unspeciﬁed. 28
C / C++
Cross References 29
scandirective, see Section 2.9.6 on page 132. 30
List Item Privatization, see Section 2.19.3 on page 279. 31
private clause, see Section 2.19.4.3 on page 285. 32
302 OpenMP API – Version 5.0 November 2018
2.19.5.5 task_reduction Clause 1
Summary 2
Thetask_reduction clause speciﬁes a reduction among tasks. 3
Syntax 4
task_reduction( reduction-identiﬁer :list) 5
Wherereduction-identiﬁer is deﬁned in Section 2.19.5.1. 6
Description 7
Thetask_reduction clause is a reduction scoping clause, as described in 2.19.5.2. 8
For each list item, the number of copies is unspeciﬁed. Any copies associated with the reduction 9
are initialized before they are accessed by the tasks participating in the reduction. After the end of 10
the region, the original list item contains the result of the reduction. 11
Restrictions 12
The restrictions to the task_reduction clause are as follows: 13
All restrictions common to all reduction clauses, which are listed in Section 2.19.5.1 on 14
page 294, apply to this clause. 15
2.19.5.6 in_reduction Clause 16
Summary 17
Thein_reduction clause speciﬁes that a task participates in a reduction. 18
Syntax 19
in_reduction( reduction-identiﬁer :list) 20
wherereduction-identiﬁer is deﬁned in Section 2.19.5.1 on page 294. 21
Description 22
Thein_reduction clause is a reduction participating clause, as described in Section 2.19.5.3 23
on page 300. For a given a list item, the in_reduction clause deﬁnes a task to be a participant 24
in a task reduction that is deﬁned by an enclosing region for a matching list item that appears in a 25
task_reduction clause or a reduction clause with the taskmodiﬁer, where either: 26
CHAPTER 2. DIRECTIVES 303
1. The matching list item has the same storage location as the list item in the in_reduction 1
clause; or 2
2. A private copy, derived from the matching list item, that is used to perform the task reduction 3
has the same storage location as the list item in the in_reduction clause. 4
For the taskconstruct, the generated task becomes the participating task. For each list item, a 5
private copy may be created as if the private clause had been used. 6
For the target construct, the target task becomes the participating task. For each list item, a 7
privatecopywillbecreatedinthedataenvironmentofthetargettaskasifthe private clausehad 8
been used, and this private copy will be implicitly mapped into the device data environment of the 9
target device. 10
Attheendofthetaskregion,ifaprivatecopywascreateditsvalueiscombinedwithacopycreated 11
by a reduction scoping clause or with the original list item. 12
Restrictions 13
The restrictions to the in_reduction clause are as follows: 14
All restrictions common to all reduction clauses, which are listed in Section 2.19.5.1 on 15
page 294, apply to this clause. 16
Alistitemthatappearsina task_reduction clauseora reduction clausewiththe task 17
modiﬁer that is speciﬁed on a construct that corresponds to a region in which the region of the 18
participating task is closely nested must match each list item. The construct that corresponds to 19
the innermost enclosing region that meets this condition must specify the same 20
reduction-identiﬁer for the matching list item as the in_reduction clause. 21
2.19.5.7 declare reduction Directive 22
Summary 23
The following section describes the directive for declaring user-deﬁned reductions. The 24
declare reduction directivedeclaresa reduction-identiﬁer thatcanbeusedina reduction 25
clause. The declare reduction directive is a declarative directive. 26
304OpenMP API – Version 5.0 November 2018
Syntax 1
C
#pragma omp declare reduction( reduction-identiﬁer :typename-list : 2
combiner )[initializer-clause] new-line 3
where: 4
reduction-identiﬁer is either a base language identiﬁer or one of the following operators: +,-,*, 5
&,|,^,&&and|| 6
typename-list is a list of type names 7
combiner is an expression 8
initializer-clause isinitializer( initializer-expr )whereinitializer-expr is 9
omp_priv = initializer orfunction-name (argument-list ) 10
C
C++
#pragma omp declare reduction( reduction-identiﬁer :typename-list : 11
combiner )[initializer-clause] new-line 12
where: 13
reduction-identiﬁer is either an id-expression or one of the following operators: +,-,*,&,|,^, 14
&&or|| 15
typename-list is a list of type names 16
combiner is an expression 17
initializer-clause isinitializer( initializer-expr )whereinitializer-expr is 18
omp_priv initializer orfunction-name (argument-list ) 19
C++
Fortran
!$omp declare reduction( reduction-identiﬁer :type-list :combiner ) 20
[initializer-clause] 21
where: 22
reduction-identiﬁer is either a base language identiﬁer, or a user-deﬁned operator, or one of the 23
following operators: +,-,*,.and.,.or.,.eqv.,.neqv., or one of the following intrinsic 24
procedure names: max,min,iand,ior,ieor. 25
type-listis a list of type speciﬁers that must not be CLASS( *)and abstract type 26
combiner is either an assignment statement or a subroutine name followed by an argument list 27
initializer-clause isinitializer( initializer-expr ), whereinitializer-expr is 28
omp_priv = expression orsubroutine-name (argument-list ) 29
Fortran
CHAPTER 2. DIRECTIVES 305
Description 1
Custom reductions can be deﬁned using the declare reduction directive; the 2
reduction-identiﬁer and the type identify the declare reduction directive. The 3
reduction-identiﬁer can later be used in a reduction clause that uses variables of the type or 4
types speciﬁed in the declare reduction directive. If the directive applies to several types 5
thenitisconsideredasifthereweremultiple declare reduction directives,oneforeachtype. 6
Fortran
If a type with deferred or assumed length type parameter is speciﬁed in a declare reduction 7
directive, the reduction-identiﬁer of that directive can be used in a reduction clause with any 8
variable of the same type and the same kind parameter, regardless of the length type Fortran 9
parameters with which the variable is declared. 10
Fortran
The visibility and accessibility of this declaration are the same as those of a variable declared at the 11
same point in the program. The enclosing context of the combiner and of the initializer-expr is that 12
of the declare reduction directive. The combiner and theinitializer-expr must be correct in 13
the base language as if they were the body of a function deﬁned at the same point in the program. 14
Fortran
If thereduction-identiﬁer is the same as the name of a user-deﬁned operator or an extended 15
operator, or the same as a generic name that is one of the allowed intrinsic procedures, and if the 16
operator or procedure name appears in an accessibility statement in the same module, the 17
accessibility of the corresponding declare reduction directive is determined by the 18
accessibility attribute of the statement. 19
If thereduction-identiﬁer is the same as a generic name that is one of the allowed intrinsic 20
procedures and is accessible, and if it has the same name as a derived type in the same module, the 21
accessibility of the corresponding declare reduction directive is determined by the 22
accessibility of the generic name according to the base language. 23
Fortran
C++
Thedeclare reduction directive can also appear at points in the program at which a static 24
data member could be declared. In this case, the visibility and accessibility of the declaration are 25
the same as those of a static data member declared at the same point in the program. 26
C++
Thecombiner speciﬁes how partial results can be combined into a single value. The combiner can 27
use the special variable identiﬁers omp_in andomp_out that are of the type of the variables that 28
thisreduction-identiﬁer reduces. Each of them will denote one of the values to be combined before 29
executing the combiner . The special omp_out identiﬁer refers to the storage that holds the 30
resulting combined value after executing the combiner . 31
The number of times that the combiner is executed, and the order of these executions, for any 32
reduction clause is unspeciﬁed. 33
306 OpenMP API – Version 5.0 November 2018
Fortran
Ifthecombiner isasubroutinenamewithanargumentlist,the combiner isevaluatedbycallingthe 1
subroutine with the speciﬁed argument list. 2
If thecombiner is an assignment statement, the combiner is evaluated by executing the assignment 3
statement. 4
Fortran
As theinitializer-expr value of a user-deﬁned reduction is not known a prioritheinitializer-clause 5
can be used to specify one. Then the contents of the initializer-clause will be used as the initializer 6
for private copies of reduction list items where the omp_priv identiﬁer will refer to the storage to 7
be initialized. The special identiﬁer omp_orig can also appear in the initializer-clause and it will 8
refer to the storage of the original variable to be reduced. 9
The number of times that the initializer-expr is evaluated, and the order of these evaluations, is 10
unspeciﬁed. 11
C / C++
If theinitializer-expr is a function name with an argument list, the initializer-expr is evaluated by 12
calling the function with the speciﬁed argument list. Otherwise, the initializer-expr speciﬁes how 13
omp_priv is declared and initialized. 14
C / C++
C
If noinitializer-clause is speciﬁed, the private variables will be initialized following the rules for 15
initialization of objects with static storage duration. 16
C
C++
If noinitializer-expr is speciﬁed, the private variables will be initialized following the rules for 17
default-initialization . 18
C++
Fortran
If theinitializer-expr is a subroutine name with an argument list, the initializer-expr is evaluated by 19
calling the subroutine with the speciﬁed argument list. 20
If theinitializer-expr is an assignment statement, the initializer-expr is evaluated by executing the 21
assignment statement. 22
If noinitializer-clause is speciﬁed, the private variables will be initialized as follows: 23
Forcomplex ,real, orinteger types, the value 0 will be used. 24
Forlogical types, the value .false. will be used. 25
CHAPTER 2. DIRECTIVES 307
For derived types for which default initialization is speciﬁed, default initialization will be used. 1
Otherwise, not specifying an initializer-clause results in unspeciﬁed behavior. 2
Fortran
C / C++
Ifreduction-identiﬁer is used in a target region then a declare target construct must be 3
speciﬁed for any function that can be accessed through the combiner andinitializer-expr . 4
C / C++
Fortran
Ifreduction-identiﬁer is used in a target region then a declare target construct must be 5
speciﬁed for any function or subroutine that can be accessed through the combiner and 6
initializer-expr . 7
Fortran
Restrictions 8
The only variables allowed in the combiner areomp_in andomp_out . 9
The only variables allowed in the initializer-clause areomp_priv andomp_orig . 10
If the variable omp_orig is modiﬁed in the initializer-clause , the behavior is unspeciﬁed. 11
If execution of the combiner or theinitializer-expr results in the execution of an OpenMP 12
construct or an OpenMP API call, then the behavior is unspeciﬁed. 13
Areduction-identiﬁer may not be re-declared in the current scope for the same type or for a type 14
that is compatible according to the base language rules. 15
At most one initializer-clause can be speciﬁed. 16
Thetypename-list must not declare new types. 17
C / C++
A type name in a declare reduction directive cannot be a function type, an array type, a 18
reference type, or a type qualiﬁed with const,volatile orrestrict . 19
C / C++
C
Iftheinitializer-expr isafunctionnamewithanargumentlist,thenoneoftheargumentsmustbe 20
the address of omp_priv . 21
C
C++
Iftheinitializer-expr isafunctionnamewithanargumentlist,thenoneoftheargumentsmustbe 22
omp_priv or the address of omp_priv . 23
C++
308 OpenMP API – Version 5.0 November 2018
Fortran
If theinitializer-expr is a subroutine name with an argument list, then one of the arguments must 1
beomp_priv . 2
If the declare reduction directive appears in the speciﬁcation part of a module and the 3
correspondingreductionclausedoesnotappearinthesamemodule,the reduction-identiﬁer must 4
be the same as the name of a user-deﬁned operator, one of the allowed operators that is extended 5
or a generic name that is the same as the name of one of the allowed intrinsic procedures. 6
If the declare reduction directive appears in the speciﬁcation of a module, if the 7
corresponding reduction clause does not appear in the same module, and if the 8
reduction-identiﬁer isthesameasthenameofauser-deﬁnedoperatororanextendedoperator,or 9
the same as a generic name that is the same as one of the allowed intrinsic procedures then the 10
interface for that operator or the generic name must be deﬁned in the speciﬁcation of the same 11
module, or must be accessible by use association. 12
Any subroutine or function used in the initializer clause or combiner expression must be 13
an intrinsic function, or must have an accessible interface. 14
Any user-deﬁned operator, deﬁned assignment or extended operator used in the initializer 15
clause or combiner expression must have an accessible interface. 16
If any subroutine, function, user-deﬁned operator, deﬁned assignment or extended operator is 17
used in the initializer clause or combiner expression, it must be accessible to the 18
subprogram in which the corresponding reduction clause is speciﬁed. 19
If the length type parameter is speciﬁed for a type, it must be a constant, a colon or an *. 20
If a type with deferred or assumed length parameter is speciﬁed in a declare reduction 21
directive, no other declare reduction directive with the same type, the same kind 22
parameters and the same reduction-identiﬁer is allowed in the same scope. 23
Any subroutine used in the initializer clause or combiner expression must not have any 24
alternate returns appear in the argument list. 25
Fortran
Cross References 26
Properties Common To All Reduction Clauses, see Section 2.19.5.1 on page 294. 27
2.19.6 Data Copying Clauses 28
This section describes the copyin clause (allowed on the parallel construct and combined 29
parallel worksharing constructs) and the copyprivate clause (allowed on the single 30
construct). 31
CHAPTER 2. DIRECTIVES 309
These clauses support the copying of data values from private or threadprivate variables on one 1
implicit task or thread to the corresponding variables on other implicit tasks or threads in the team. 2
The clauses accept a comma-separated list of list items (see Section 2.1 on page 38). All list items 3
appearing in a clause must be visible, according to the scoping rules of the base language. Clauses 4
may be repeated as needed, but a list item that speciﬁes a given variable may not appear in more 5
than one clause on the same directive. 6
Fortran
An associate name preserves the association with the selector established at the ASSOCIATE 7
statement. A list item that appears in a data copying clause may be a selector of an ASSOCIATE 8
construct. If the construct association is established prior to a parallel region, the association 9
between the associate name and the original list item will be retained in the region. 10
Fortran
2.19.6.1 copyin Clause 11
Summary 12
Thecopyin clause provides a mechanism to copy the value of a threadprivate variable of the 13
master thread to the threadprivate variable of each other member of the team that is executing the 14
parallel region. 15
Syntax 16
The syntax of the copyin clause is as follows: 17
copyin( list) 18
Description 19
C / C++
The copy is done after the team is formed and prior to the start of execution of the associated 20
structuredblock. Forvariablesofnon-arraytype,thecopyoccursbycopyassignment. Foranarray 21
of elements of non-array type, each element is copied as if by assignment from an element of the 22
array of the master thread to the corresponding element of the array of the other thread. 23
C / C++
C++
For class types, the copy assignment operator is invoked. The order in which copy assignment 24
operators for diﬀerent variables of class type are called is unspeciﬁed. 25
C++
310 OpenMP API – Version 5.0 November 2018
Fortran
The copy is done, as if by assignment, after the team is formed and prior to the start of execution of 1
the associated structured block. 2
On entry to any parallel region, each thread’s copy of a variable that is aﬀected by a copyin 3
clause for the parallel region will acquire the type parameters, allocation, association, and 4
deﬁnition status of the copy of the master thread, according to the following rules: 5
If the original list item has the POINTER attribute, each copy receives the same association 6
status as that of the copy of the master thread as if by pointer assignment. 7
If the original list item does not have the POINTER attribute, each copy becomes deﬁned with 8
the value of the copy of the master thread as if by intrinsic assignment unless the list item has a 9
type bound procedure as a deﬁned assignment. If the original list item that does not have the 10
POINTER attribute has the allocation status of unallocated, each copy will have the same status. 11
If the original list item is unallocated or unassociated, the copy of the other thread inherits the 12
declared type parameters and the default type parameter values from the original list item. 13
Fortran
Restrictions 14
The restrictions to the copyin clause are as follows: 15
C / C++
A list item that appears in a copyin clause must be threadprivate. 16
A variable of class type (or array thereof) that appears in a copyin clause requires an 17
accessible, unambiguous copy assignment operator for the class type. 18
C / C++
Fortran
A list item that appears in a copyin clause must be threadprivate. Named variables that appear 19
in a threadprivate common block may be speciﬁed: it is not necessary to specify the whole 20
common block. 21
Acommonblocknamethatappearsina copyin clausemustbedeclaredtobeacommonblock 22
in the same scoping unit in which the copyin clause appears. 23
If the list item is a polymorphic variable with the ALLOCATABLE attribute, the behavior is 24
unspeciﬁed. 25
Fortran
CHAPTER 2. DIRECTIVES 311
Cross References 1
parallel construct, see Section 2.6 on page 74. 2
threadprivate directive, see Section 2.19.2 on page 274. 3
2.19.6.2 copyprivate Clause 4
Summary 5
Thecopyprivate clause provides a mechanism to use a private variable to broadcast a value 6
from the data environment of one implicit task to the data environments of the other implicit tasks 7
that belong to the parallel region. 8
To avoid data races, concurrent reads or updates of the list item must be synchronized with the 9
update of the list item that occurs as a result of the copyprivate clause. 10
Syntax 11
The syntax of the copyprivate clause is as follows: 12
copyprivate( list) 13
Description 14
The eﬀect of the copyprivate clause on the speciﬁed list items occurs after the execution of the 15
structured block associated with the single construct (see Section 2.8.2 on page 89), and before 16
any of the threads in the team have left the barrier at the end of the construct. 17
C / C++
In all other implicit tasks that belong to the parallel region, each speciﬁed list item becomes 18
deﬁned with the value of the corresponding list item in the implicit task associated with the thread 19
that executed the structured block. For variables of non-array type, the deﬁnition occurs by copy 20
assignment. For an array of elements of non-array type, each element is copied by copy assignment 21
from an element of the array in the data environment of the implicit task that is associated with the 22
thread that executed the structured block to the corresponding element of the array in the data 23
environment of the other implicit tasks 24
C / C++
C++
For class types, a copy assignment operator is invoked. The order in which copy assignment 25
operators for diﬀerent variables of class type are called is unspeciﬁed. 26
C++
312 OpenMP API – Version 5.0 November 2018
Fortran
If a list item does not have the POINTER attribute, then in all other implicit tasks that belong to the 1
parallel region, the list item becomes deﬁned as if by intrinsic assignment with the value of the 2
corresponding list item in the implicit task that is associated with the thread that executed the 3
structured block. If the list item has a type bound procedure as a deﬁned assignment, the 4
assignment is performed by the deﬁned assignment. 5
If the list item has the POINTER attribute, then, in all other implicit tasks that belong to the 6
parallel region,thelistitemreceives,asifbypointerassignment,thesameassociationstatusof 7
the corresponding list item in the implicit task that is associated with the thread that executed the 8
structured block. 9
The order in which any ﬁnal subroutines for diﬀerent variables of a ﬁnalizable type are called is 10
unspeciﬁed. 11
Fortran
12
Note– The copyprivate clause is an alternative to using a shared variable for the value when 13
providing such a shared variable would be diﬃcult (for example, in a recursion requiring a diﬀerent 14
variable at each level). 15
16
Restrictions 17
The restrictions to the copyprivate clause are as follows: 18
All list items that appear in the copyprivate clause must be either threadprivate or private in 19
the enclosing context. 20
A list item that appears in a copyprivate clause may not appear in a private or 21
firstprivate clause on the single construct. 22
C++
A variable of class type (or array thereof) that appears in a copyprivate clause requires an 23
accessible unambiguous copy assignment operator for the class type. 24
C++
Fortran
A common block that appears in a copyprivate clause must be threadprivate. 25
Pointers with the INTENT(IN) attribute may not appear in the copyprivate clause. 26
Thelistitemwiththe ALLOCATABLE attributemusthavetheallocationstatusofallocatedwhen 27
the intrinsic assignment is performed. 28
If the list item is a polymorphic variable with the ALLOCATABLE attribute, the behavior is 29
unspeciﬁed. 30
Fortran
CHAPTER 2. DIRECTIVES 313
Cross References 1
parallel construct, see Section 2.6 on page 74. 2
threadprivate directive, see Section 2.19.2 on page 274. 3
private clause, see Section 2.19.4.3 on page 285. 4
2.19.7 Data-Mapping Attribute Rules, Clauses, and Directives5
This section describes how the data-mapping and data-sharing attributes of any variable referenced 6
in atarget region are determined. When speciﬁed, explicit data-sharing attributes, mapor 7
is_device_ptr clauses on target directives determine these attributes. Otherwise, the ﬁrst 8
matching rule from the following implicit data-mapping rules applies for variables referenced in a 9
target constructthatarenotdeclaredintheconstructanddonotappearindata-sharingattribute, 10
maporis_device_ptr clauses. 11
If a variable appears in a toorlinkclause on a declare target directive then it is treated 12
as if it had appeared in a mapclause with a map-type oftofrom. 13
If a list item appears in a reduction ,lastprivate orlinear clause on a combined 14
target construct then it is treated as if it also appears in a mapclause with a map-type of 15
tofrom. 16
Ifalistitemappearsinan in_reduction clauseona target constructthenitistreatedasif 17
it also appears in a mapclause with a map-type oftofrom and amap-type-modiﬁer of 18
always. 19
If adefaultmap clause is present for the category of the variable and speciﬁes an implicit 20
behavior other than default , the data-mapping attribute is determined by that clause. 21
C++
If the target construct is within a class non-static member function, and a variable is an 22
accessible data member of the object for which the non-static data member function is invoked, 23
the variable is treated as if the this[:1] expression had appeared in a mapclause with a 24
map-type oftofrom. Additionally, if the variable is of a type pointer or reference to pointer, it 25
is also treated as if it has appeared in a mapclause as a zero-length array section. 26
If the thiskeyword is referenced inside a target construct within a class non-static member 27
function, it is treated as if the this[:1] expression had appeared in a mapclause with a 28
map-type oftofrom. 29
C++
314 OpenMP API – Version 5.0 November 2018
C / C++
A variable that is of type pointer is treated as if it is the base pointer of a zero-length array 1
section that appeared as a list item in a mapclause. 2
C / C++
C++
A variable that is of type reference to pointer is treated as if it had appeared in a mapclause as a 3
zero-length array section. 4
C++
If avariable is nota scalar thenit is treatedas if ithad appeared ina mapclause witha map-type 5
oftofrom. 6
Fortran
If a scalar variable has the TARGET,ALLOCATABLE orPOINTER attribute then it is treated as 7
if it has appeared in a mapclause with a map-type oftofrom. 8
Fortran
Ifnoneoftheaboverulesappliesthenascalarvariableisnotmapped,butinsteadhasanimplicit 9
data-sharing attribute of mapped, but instead has an implicit data-sharing attribute of ﬁrstprivate 10
(see Section 2.19.1.1 on page 270). 11
2.19.7.1 mapClause 12
Summary 13
Themapclause speciﬁes how an original list item is mapped from the current task’s data 14
environment to a corresponding list item in the device data environment of the device identiﬁed by 15
the construct. 16
Syntax 17
The syntax of the map clause is as follows: 18
map([ [map-type-modiﬁer[ ,] [map-type-modiﬁer[ ,] ...] map-type :] locator-list ) 19
wheremap-type is one of the following: 20
to 21
from 22
tofrom 23
alloc 24
release 25
delete 26
CHAPTER 2. DIRECTIVES 315
andmap-type-modiﬁer is one of the following: 1
always 2
close 3
mapper( mapper-identiﬁer ) 4
Description 5
The list items that appear in a mapclause may include array sections and structure elements. 6
Themap-type andmap-type-modiﬁer specify the eﬀect of the mapclause, as described below. 7
For a given construct, the eﬀect of a mapclause with the to,from, ortofrom map-type is 8
ordered before the eﬀect of a mapclause with the alloc,release , ordelete map-type. If a 9
mapper is speciﬁed for the type being mapped, or explicitly speciﬁed with the mapper 10
map-type-modiﬁer , then the eﬀective map-type of a list item will be determined according to the 11
rules of map-type decay. 12
If a mapper is speciﬁed for the type being mapped, or explicitly speciﬁed with the mapper 13
map-type-modiﬁer , then all map clauses that appear on the declare mapper directive are 14
treated as though they appeared on the construct with the mapclause. Array sections of a mapper 15
type are mapped as normal, then each element in the array section is mapped according to the rules 16
of the mapper. 17
C / C++
If a list item in a mapclause is a variable of structure type then it is treated as if each structure 18
element contained in the variable is a list item in the clause. 19
C / C++
Fortran
If a list item in a mapclause is a derived type variable then it is treated as if each component is a 20
list item in the clause. 21
Each pointer component that is a list item that results from a mapped derived type variable is 22
treated as if its association status is undeﬁned, unless the pointer component appears as another list 23
item or as the base pointer of another list item in a mapclause on the same construct. 24
Fortran
If a list item in a mapclause is a structure element then all other structure elements of the 25
containing structure variable form a structure sibling list . The mapclause and the structure sibling 26
list are associated with the same construct. If a corresponding list item of the structure sibling list 27
item is present in the device data environment when the construct is encountered then: 28
316 OpenMP API – Version 5.0 November 2018
If the structure sibling list item does not appear in a mapclause on the construct then: 1
–If the construct is a target,target data , ortarget enter data construct then the 2
structure sibling list item is treated as if it is a list item in a mapclause on the construct with a 3
map-type ofalloc. 4
–Iftheconstructis target exit data construct,thenthestructuresiblinglistitemistreated 5
as if it is a list item in a mapclause on the construct with a map-type ofrelease . 6
Fortran
–If the structure sibling list item is a pointer then it is treated as if its association status is 7
undeﬁned, unless it appears as the base pointer of another list item in a mapclause on the 8
same construct. 9
Fortran
If the mapclause in which the structure element appears as a list item has a map-type of 10
delete and the structure sibling list item does not appear as a list item in a mapclause on the 11
construct with a map-type ofdelete then the structure sibling list item is treated as if it is a list 12
item in a mapclause on the construct with a map-type ofdelete. 13
Ifitem1is a list item in a mapclause, and item2is another list item in a mapclause on the same 14
construct that has a base pointer that is, or is part of, item1, then: 15
Ifthe mapclause(s)appearona target,target data ,ortarget enter data construct, 16
then on entry to the corresponding region the eﬀect of the mapclause on item1is ordered to 17
occur before the eﬀect of the mapclause on item2. 18
If the mapclause(s) appear on a target,target data , ortarget exit data construct 19
then on exit from the corresponding region the eﬀect of the mapclause on item2is ordered to 20
occur before the eﬀect of the mapclause on item1. 21
Fortran
If a list item in a mapclause is an associated pointer and the pointer is not the base pointer of 22
another list item in a mapclause on the same construct, then it is treated as if its pointer target is 23
implicitly mapped in the same clause. For the purposes of the mapclause, the mapped pointer 24
target is treated as if its base pointer is the associated pointer. 25
Fortran
If a list item in a mapclause has a base pointer, and a pointer variable is present in the device data 26
environment that corresponds to the base pointer when the eﬀect of the mapclause occurs, then if 27
the corresponding pointer or the corresponding list item is created in the device data environment 28
on entry to the construct, then: 29
C / C++
1. The corresponding pointer variable is assigned an address such that the corresponding list item 30
can be accessed through the pointer in a target region. 31
C / C++
CHAPTER 2. DIRECTIVES 317
Fortran
1. The corresponding pointer variable is associatedwith a pointer target that has the same rank and 1
bounds as the pointer target of the original pointer, such that the corresponding list item can be 2
accessed through the pointer in a target region. 3
Fortran
2. The corresponding pointer variable becomes an attached pointer for the corresponding list item. 4
3. If the original base pointer and the corresponding attached pointer share storage, then the 5
original list item and the corresponding list item must share storage. 6
C++
If alambdais mapped explicitly or implicitly, variables that are captured by the lambdabehave as 7
follows: 8
the variables that are of pointer type are treated as if they had appeared in a mapclause as 9
zero-length array sections; and 10
the variables that are of reference type are treated as if they had appeared in a mapclause. 11
If a member variable is captured by a lambdain class scope, and the lambdais later mapped 12
explicitly or implicitly with its full static type, the thispointer is treated as if it had appeared on a 13
mapclause. 14
C++
The original and corresponding list items may share storage such that writes to either item by one 15
task followed by a read or write of the other item by another task without intervening 16
synchronization can result in data races. 17
Ifthe mapclauseappearsona target,target data ,ortarget enter data constructthen 18
on entry to the region the following sequence of steps occurs as if performed as a single atomic 19
operation: 20
1. Ifacorrespondinglistitemoftheoriginallistitemisnotpresentinthedevicedataenvironment, 21
then: 22
a) A new list item with language-speciﬁc attributes is derived from the original list item and 23
created in the device data environment; 24
b) The new list item becomes the corresponding list item of the original list item in the device 25
data environment; 26
c) The corresponding list item has a reference count that is initialized to zero; and 27
d) The value of the corresponding list item is undeﬁned; 28
2. If the corresponding list item’s reference count was not already incremented because of the 29
eﬀect of a mapclause on the construct then: 30
a) The corresponding list item’s reference count is incremented by one; 31
318 OpenMP API – Version 5.0 November 2018
3. If the corresponding list item’s reference count is one or the always map-type-modiﬁer is 1
present, and if the map-type istoortofrom, then: 2
C / C++
a) For each part of the list item that is an attached pointer, that part of the corresponding list 3
item will have the value that it had immediately prior to the eﬀect of the mapclause; and 4
C / C++
Fortran
a) For each part of the list item that is an attached pointer, that part of the corresponding list 5
item,ifassociated,willbeassociatedwiththesamepointertargetthatitwasassociatedwith 6
immediately prior to the eﬀect of the mapclause. 7
Fortran
b) For each part of the list item that is not an attached pointer, the value of that part of the 8
original list item is assigned to that part of the corresponding list item. 9
10
Note– If the eﬀect of the mapclauses on a construct would assign the value of an original list 11
item to a corresponding list item more than once, then an implementation is allowed to ignore 12
additional assignments of the same value to the corresponding list item. 13
14
In all cases on entry to the region, concurrent reads or updates of any part of the corresponding list 15
item must be synchronized with any update of the corresponding list item that occurs as a result of 16
themapclause to avoid data races. 17
If the mapclause appears on a target,target data , ortarget exit data construct and a 18
corresponding list item of the original list item is not present in the device data environment on exit 19
fromtheregionthenthelistitemisignored. Alternatively,ifthe mapclauseappearsona target, 20
target data ,ortarget exit data constructandacorrespondinglistitemoftheoriginallist 21
item is present in the device data environment on exit from the region, then the following sequence 22
of steps occurs as if performed as a single atomic operation: 23
1. If themap-type is not delete and the corresponding list item’s reference count is ﬁnite and 24
was not already decremented because of the eﬀect of a mapclause on the construct then: 25
a) The corresponding list item’s reference count is decremented by one; 26
2. If themap-type isdelete and the corresponding list item’s reference count is ﬁnite then: 27
a) The corresponding list item’s reference count is set to zero; 28
3. If themap-type isfromortofrom and if the corresponding list item’s reference count is zero 29
or the always map-type-modiﬁer is present then: 30
CHAPTER 2. DIRECTIVES 319
C / C++
a) For each part of the list item that is an attached pointer, that part of the original list item will 1
have the value that it had immediately prior to the eﬀect of the mapclause; 2
C / C++
Fortran
a) For each part of the list item that is an attached pointer, that part of the corresponding list 3
item, if associated, will be associated with the same pointer target with which it was 4
associated immediately prior to the eﬀect of the mapclause; and 5
Fortran
b) For each part of the list item that is not an attached pointer, the value of that part of the 6
corresponding list item is assigned to that part of the original list item; and 7
4. If the corresponding list item’s reference count is zero then the corresponding list item is 8
removed from the device data environment. 9
10
Note– If the eﬀect of the mapclauses on a construct would assign the value of a corresponding 11
list item to an original list item more than once, then an implementation is allowed to ignore 12
additional assignments of the same value to the original list item. 13
14
In all cases on exit from the region, concurrent reads or updates of any part of the original list item 15
must be synchronized with any update of the original list item that occurs as a result of the map 16
clause to avoid data races. 17
If a single contiguous part of the original storage of a list item with an implicit data-mapping 18
attribute has corresponding storage in the device data environment prior to a task encountering the 19
construct that is associated with the mapclause, only that part of the original storage will have 20
corresponding storage in the device data environment as a result of the mapclause. 21
If a list item with an implicit data-mapping attribute does not have any corresponding storage in the 22
device data environment prior to a task encountering the construct associated with the mapclause, 23
and one or more contiguous parts of the original storage are either list items or base pointers to list 24
items that are explicitly mapped on the construct, only those parts of the original storage will have 25
corresponding storage in the device data environment as a result of the mapclauses on the 26
construct. 27
C / C++
Ifanewlistitemiscreatedthenanewlistitemofthesametype,withautomaticstorageduration,is 28
allocated for the construct. The size and alignment of the new list item are determined by the static 29
type of the variable. This allocation occurs if the region references the list item in any statement. 30
Initialization and assignment of the new list item are through bitwise copy. 31
C / C++
320 OpenMP API – Version 5.0 November 2018
Fortran
If a new list item is created then a new list item of the same type, type parameter, and rank is 1
allocated. The new list item inherits all default values for the type parameters from the original list 2
item. The value of the new list item becomes that of the original list item in the map initialization 3
and assignment. 4
If the allocation status of the original list item with the ALLOCATABLE attribute is changed in the 5
host device data environment and the corresponding list item is already present in the device data 6
environment, the allocation status of the corresponding list item is unspeciﬁed until a mapping 7
operation is performed with a mapclause on entry to a target,target data , or 8
target enter data region. 9
Fortran
Themap-type determines how the new list item is initialized. 10
If amap-type is not speciﬁed, the map-type defaults to tofrom. 11
Theclosemap-type-modiﬁer isahinttotheruntimetoallocatememoryclosetothetargetdevice. 12
Execution Model Events 13
Thetarget-map event occurs when a thread maps data to or from a target device. 14
Thetarget-data-op event occurs when a thread initiates a data operation on a target device. 15
Tool Callbacks 16
A thread dispatches a registered ompt_callback_target_map callback for each occurrence 17
of atarget-map event in that thread. The callback occurs in the context of the target task and has 18
type signature ompt_callback_target_map_t . 19
A thread dispatches a registered ompt_callback_target_data_op callback for each 20
occurrence of a target-data-op event in that thread. The callback occurs in the context of the target 21
task and has type signature ompt_callback_target_data_op_t . 22
Restrictions 23
The restrictions to the mapclause are as follows: 24
A list item cannot appear in both a mapclause and a data-sharing attribute clause on the same 25
construct unless the construct is a combined construct. 26
Each of the map-type-modiﬁer modiﬁers can appear at most once on the mapclause. 27
CHAPTER 2. DIRECTIVES 321
C / C++
List items of the mapclauses on the same construct must not share original storage unless they 1
are the same lvalue expression or array section. 2
C / C++
If a list item is an array section, it must specify contiguous storage. 3
If multiple list items are explicitly mapped on the same construct and have the same containing 4
array or have base pointers that share original storage, and if any of the list items do not have 5
corresponding list items that are present in the device data environment prior to a task 6
encountering the construct, then the list items must refer to the same array elements of either the 7
containing array or the implicit array of the base pointers. 8
If any part of the original storage of a list item with an explicit data-mapping attribute has 9
corresponding storage in the device data environment prior to a task encountering the construct 10
associatedwiththe mapclause,alloftheoriginalstoragemusthavecorrespondingstorageinthe 11
device data environment prior to the task encountering the construct. 12
If a list item is an element of a structure, and a diﬀerent element of the structure has a 13
corresponding list item in the device data environment prior to a task encountering the construct 14
associated with the mapclause, then the list item must also have a corresponding list item in the 15
device data environment prior to the task encountering the construct. 16
A list item must have a mappable type. 17
threadprivate variables cannot appear in a mapclause. 18
Ifamapper map-type-modiﬁerisspeciﬁed,itstypemustmatchthetypeofthelist-itemspassed 19
to that map clause. 20
Memory spaces and memory allocators cannot appear as a list item in a mapclause. 21
C++
If the type of a list item is a reference to a type Tthen the reference in the device data 22
environmentisinitializedtorefertotheobjectinthedevicedataenvironmentthatcorrespondsto 23
the object referenced by the list item. If mapping occurs, it occurs as though the object were 24
mapped through a pointer with an array section of type Tand length one. 25
No type mapped through a reference can contain a reference to its own type, or any references to 26
types that could produce a cycle of references. 27
If the list item is a lambda, any pointers and references captured by the lambdamust have the 28
corresponding list item in the device data environment prior to the task encountering the 29
construct. 30
C++
322 OpenMP API – Version 5.0 November 2018
C / C++
A list item cannot be a variable that is a member of a structure with a union type. 1
A bit-ﬁeld cannot appear in a mapclause. 2
A pointer that has a corresponding attached pointer must not be modiﬁed for the duration of the 3
lifetime of the list item to which the corresponding pointer is attached in the device data 4
environment. 5
C / C++
Fortran
List items of the mapclauses on the same construct must not share original storage unless they 6
are the same variable or array section. 7
A pointer that has a corresponding attached pointer and is associated with a given pointer target 8
must not become associated with a diﬀerent pointer target for the duration of the lifetime of the 9
list item to which the corresponding pointer is attached in the device data environment. 10
If the allocation status of a list item or any subobject of the list item with the ALLOCATABLE 11
attribute is unallocated upon entry to a target region, the list item or any subobject of the 12
corresponding list item must be unallocated upon exit from the region. 13
If the allocation status of a list item or any subobject of the list item with the ALLOCATABLE 14
attribute is allocated upon entry to a target region, the allocation status of the corresponding 15
list item or any subobject of the corresponding list item must not be changed and must not be 16
reshaped in the region. 17
If an array section is mapped and the size of the section is smaller than that of the whole array, 18
the behavior of referencing the whole array in the target region is unspeciﬁed. 19
A list item must not be a whole array of an assumed-size array. 20
If the association status of a list item with the POINTER attribute is associated upon entry to a 21
target region, the list item must be associated with the same pointer target upon exit from the 22
region. 23
Iftheassociationstatusofalistitemwiththe POINTER attributeisdisassociateduponentrytoa 24
target region, the list item must be disassociated upon exit from the region. 25
If the association status of a list item with the POINTER attribute is undeﬁned upon entry to a 26
target region, the list item must be undeﬁned upon exit from the region. 27
If the association status of a list item with the POINTER attribute is disassociated or undeﬁned 28
on entry and if the list item is associated with a pointer target inside a target region, then the 29
pointer association status must become disassociated before the end of the region. 30
Fortran
CHAPTER 2. DIRECTIVES 323
Cross References 1
ompt_callback_target_data_op_t , see Section 4.5.2.25 on page 488. 2
ompt_callback_target_map_t , see Section 4.5.2.27 on page 492. 3
2.19.7.2 defaultmap Clause 4
Summary 5
Thedefaultmap clause explicitly determines the data-mapping attributes of variables that are 6
referenced in a target construct for which the data-mapping attributes would otherwise be 7
implicitly determined (see Section 2.19.7 on page 314). 8
Syntax 9
The syntax of the defaultmap clause is as follows: 10
defaultmap( implicit-behavior[:variable-category] ) 11
Whereimplicit-behavior is one of: 12
alloc 13
to 14
from 15
tofrom 16
firstprivate 17
none 18
default 19
C / C++
andvariable-category is one of: 20
scalar 21
aggregate 22
pointer 23
C / C++
324 OpenMP API – Version 5.0 November 2018
Fortran
andvariable-category is one of: 1
scalar 2
aggregate 3
allocatable 4
pointer 5
Fortran
Description 6
Thedefaultmap clausesetstheimplicitdata-mappingattributeforallvariablesreferencedinthe 7
construct. If variable-category is speciﬁed, the eﬀect of the defaultmap clause is as follows: 8
Ifvariable-category isscalar, all scalar variables of non-pointer type or all non-pointer 9
non-allocatable scalar variables that have an implicitly determined data-mapping or data-sharing 10
attribute will have a data-mapping or data-sharing attribute speciﬁed by implicit-behavior . 11
Ifvariable-category isaggregate orallocatable , all aggregate or allocatable variables 12
that have an implicitly determined data-mapping or data-sharing attribute will have a 13
data-mapping or data-sharing attribute speciﬁed by implicit-behavior . 14
Ifvariable-category ispointer , all variables of pointer type or with the POINTER attribute 15
thathaveimplicitlydetermineddata-mappingordata-sharingattributeswillhaveadata-mapping 16
or data-sharing attribute speciﬁed by implicit-behavior . The zero-length array section and 17
attachment that are otherwise applied to an implicitly mapped pointer are only provided for the 18
default behavior. 19
If novariable-category is speciﬁed in the clause then implicit-behavior speciﬁes the implicitly 20
determined data-mapping or data-sharing attribute for all variables referenced in the construct. If 21
implicit-behavior isnone, each variable referenced in the construct that does not have a 22
predetermined data-sharing attribute and does not appear in a toorlinkclause on a 23
declare target directive must be listed in a data-mapping attribute clause, a data-sharing 24
attribute clause (including a data-sharing attribute clause on a combined construct where target 25
is one of the constituent constructs), or an is_device_ptr clause. If implicit-behavior is 26
default , then the clause has no eﬀect for the variables in the category speciﬁed by 27
variable-category . 28
CHAPTER 2. DIRECTIVES 325
2.19.7.3 declare mapper Directive 1
Summary 2
Thedeclare mapper directive declares a user-deﬁned mapper for a given type, and may deﬁne 3
amapper-identiﬁer that can be used in a mapclause. The declare mapper directive is a 4
declarative directive. 5
Syntax 6
C / C++
The syntax of the declare mapper directive is as follows: 7
#pragma omp declare mapper( [mapper-identiﬁer :]type var ) \ 8
[clause[ [ ,] clause] ... ] new-line 9
C / C++
Fortran
The syntax of the declare mapper directive is as follows: 10
!$omp declare mapper( [mapper-identiﬁer :] type :: var ) & 11
[clause[ [ ,] clause] ... ] 12
Fortran
where: 13
mapper-identiﬁer is a base-language identiﬁer or default 14
typeis a valid type in scope 15
varis a valid base-language identiﬁer 16
clauseismap([[map-type-modiﬁer[ ,] [map-type-modiﬁer[ ,] ...]] map-type :] list), where 17
map-type is one of the following: 18
–alloc 19
–to 20
–from 21
–tofrom 22
and where map-type-modiﬁer is one of the following: 23
–always 24
–close 25
326OpenMP API – Version 5.0 November 2018
Description 1
User-deﬁned mappers can be deﬁned using the declare mapper directive. The type and the 2
mapper-identiﬁer uniquely identify the mapper for use in a mapclause later in the program. If the 3
mapper-identiﬁer is not speciﬁed, then default is used. The visibility and accessibility of this 4
declaration are the same as those of a variable declared at the same point in the program. 5
The variable declared by varis available for use in all mapclauses on the directive, and no part of 6
the variable to be mapped is mapped by default. 7
Thedefaultmapperforalltypes T,designatedbythepre-deﬁned mapper-identiﬁer default ,isas 8
follows unless a user-deﬁned mapper is speciﬁed for that type. 9
declare mapper( Tv) map(tofrom: v) 10
Using the default mapper-identiﬁer overrides the pre-deﬁned default mapper for the given type, 11
making it the default for all variables of type. Allmapclauses with this construct in scope that map 12
a list item of typewill use this mapper unless another is explicitly speciﬁed. 13
Allmapclauses on the directive are expanded into corresponding mapclauses wherever this 14
mapper is invoked, either by matching type or by being explicitly named in a mapclause. A map 15
clause with list item varmapsvaras though no mapper were speciﬁed. 16
C++
Thedeclare mapper directive can also appear at points in the program at which a static data 17
member could be declared. In this case, the visibility and accessibility of the declaration are the 18
same as those of a static data member declared at the same point in the program. 19
C++
Restrictions 20
The restrictions to the declare mapper directive are as follows: 21
No instance of typecan be mapped as part of the mapper, either directly or indirectly through 22
anothertype,excepttheinstancepassedasthelistitem. Ifasetof declare mapper directives 23
results in a cyclic deﬁnition then the behavior is unspeciﬁed. 24
Thetypemust be of struct, union or class type in C and C++ or a non-intrinsic type in Fortran. 25
Thetypemust not declare a new type. 26
At least one mapclause that maps varor at least one element of varis required. 27
List-items in mapclauses on this construct may only refer to the declared variable varand 28
entities that could be referenced by a procedure deﬁned at the same location. 29
Eachmap-type-modiﬁer can appear at most once on the mapclause. 30
CHAPTER 2. DIRECTIVES 327
Amapper-identiﬁer may not be redeclared in the current scope for the same type or for a type 1
that is compatible according to the base language rules. 2
Fortran
typemust not be an abstract type. 3
Fortran
2.20 Nesting of Regions4
This section describes a set of restrictions on the nesting of regions. The restrictions on nesting are 5
as follows: 6
A worksharing region may not be closely nested inside a worksharing, loop,task, 7
taskloop ,critical ,ordered ,atomic, ormaster region. 8
Abarrier region may not be closely nested inside a worksharing, loop,task,taskloop , 9
critical ,ordered ,atomic, ormaster region. 10
Amaster region may not be closely nested inside a worksharing, loop,atomic,task, or 11
taskloop region. 12
Anordered region corresponding to an ordered construct without any clause or with the 13
threads ordepend clause may not be closely nested inside a critical ,ordered ,loop, 14
atomic,task, ortaskloop region. 15
Anordered region corresponding to an ordered construct without the simdclause 16
speciﬁed must be closely nested inside a worksharing-loop region. 17
Anordered region corresponding to an ordered construct with the simdclause speciﬁed 18
must be closely nested inside a simdor worksharing-loop SIMD region. 19
Anordered region corresponding to an ordered construct with both the simdand 20
threads clauses must be closely nested inside a worksharing-loop SIMD region or closely 21
nested inside a worksharing-loop and simdregion. 22
Acritical region may not be nested (closely or otherwise) inside a critical region with 23
the same name. This restriction is not suﬃcient to prevent deadlock. 24
OpenMP constructs may not be encountered during execution of an atomic region. 25
The only OpenMP constructs that can be encountered during execution of a simd(or 26
worksharing-loop SIMD) region are the atomic construct, the loopconstruct, the simd 27
construct and the ordered construct with the simdclause. 28
328 OpenMP API – Version 5.0 November 2018
If atarget update ,target data ,target enter data , ortarget exit data 1
construct is encountered during execution of a target region, the behavior is unspeciﬁed. 2
If atarget construct is encountered during execution of a target region and a device 3
clause in which the ancestor device-modiﬁer appears is not present on the construct, the 4
behavior is unspeciﬁed. 5
Ateamsregion can only be strictly nested within the implicit parallel region or a target 6
region. If a teamsconstruct is nested within a target construct, that target construct must 7
contain no statements, declarations or directives outside of the teamsconstruct. 8
distribute ,distribute simd , distribute parallel worksharing-loop, distribute parallel 9
worksharing-loop SIMD, loop,parallel regions, including any parallel regions arising 10
from combined constructs, omp_get_num_teams() regions, and omp_get_team_num() 11
regions are the only OpenMP regions that may be strictly nested inside the teamsregion. 12
Theregioncorrespondingtothe distribute constructmustbestrictlynestedinsidea teams 13
region. 14
Ifconstruct-type-clause istaskgroup , thecancel construct must be closely nested inside a 15
taskconstruct and the cancel region must be closely nested inside a taskgroup region. If 16
construct-type-clause issections , thecancel construct must be closely nested inside a 17
sections orsection construct. Otherwise, the cancel construct must be closely nested 18
inside an OpenMP construct that matches the type speciﬁed in construct-type-clause of the 19
cancel construct. 20
Acancellation point construct for which construct-type-clause istaskgroup must be 21
closelynestedinsidea taskconstruct,andthe cancellation point regionmustbeclosely 22
nested inside a taskgroup region. A cancellation point construct for which 23
construct-type-clause issections must be closely nested inside a sections orsection 24
construct. Otherwise, a cancellation point construct must be closely nested inside an 25
OpenMP construct that matches the type speciﬁed in construct-type-clause . 26
The only constructs that may be nested inside a loopregion are the loopconstruct, the 27
parallel construct, the simdconstruct, and combined constructs for which the ﬁrst construct 28
is aparallel construct. 29
Aloopregion may not contain calls to procedures that contain OpenMP directives or calls to 30
the OpenMP Runtime API. 31
CHAPTER 2. DIRECTIVES 329
This page intentionally left blank
CHAPTER 3
Runtime Library Routines 1
2
This chapter describes the OpenMP API runtime library routines and queryable runtime states. In 3
this chapter, trueandfalseare used as generic terms to simplify the description of the routines. 4
C / C++
truemeans a nonzero integer value and falsemeans an integer value of zero. 5
C / C++
Fortran
truemeans a logical value of .TRUE. andfalsemeans a logical value of .FALSE. . 6
Fortran
Fortran
Restrictions 7
The following restriction applies to all OpenMP runtime library routines: 8
OpenMP runtime library routines may not be called from PUREorELEMENTAL procedures. 9
Fortran
CHAPTER 3. RUNTIME LIBRARY ROUTINES 331
3.1 Runtime Library Deﬁnitions1
For each base language, a compliant implementation must supply a set of deﬁnitions for the 2
OpenMP API runtime library routines and the special data types of their parameters. The set of 3
deﬁnitions must contain a declaration for each OpenMP API runtime library routine and variable 4
and a deﬁnition of each required data type listed below. In addition, each set of deﬁnitions may 5
specify other implementation speciﬁc values. 6
C / C++
The library routines are external functions with “C” linkage. 7
Prototypes for the C/C++ runtime library routines described in this chapter shall be provided in a 8
header ﬁle named omp.h. This ﬁle also deﬁnes the following: 9
The type omp_lock_t ; 10
The type omp_nest_lock_t ; 11
The type omp_sync_hint_t ; 12
The type omp_lock_hint_t (deprecated); 13
The type omp_sched_t ; 14
The type omp_proc_bind_t ; 15
The type omp_control_tool_t ; 16
The type omp_control_tool_result_t ; 17
The type omp_depend_t ; 18
The type omp_memspace_handle_t , which must be an implementation-deﬁned enum type 19
with an enumerator for at least each predeﬁned memory space in Table 2.8 on page 152; 20
The type omp_allocator_handle_t , which must be an implementation-deﬁned enum type 21
with at least the omp_null_allocator enumerator with the value zero and an enumerator 22
for each predeﬁned memory allocator in Table 2.10 on page 155; 23
The type omp_uintptr_t , which is an unsigned integer type capable of holding a pointer on 24
any device; 25
The type omp_pause_resource_t ; and 26
The type omp_event_handle_t , which must be an implementation-deﬁned enum type. 27
C / C++
332 OpenMP API – Version 5.0 November 2018
C++
Theomp.hheader ﬁle also deﬁnes a class template that models the Allocator concept in the 1
omp::allocator namespace for each predeﬁned memory allocator in Table 2.10 on page 155 2
for which the name includes neither the omp_preﬁx nor the _alloc suﬃx. 3
C++
Fortran
The OpenMP Fortran API runtime library routines are external procedures. The return values of 4
these routines are of default kind, unless otherwise speciﬁed. 5
Interface declarations for the OpenMP Fortran runtime library routines described in this chapter 6
shall be provided in the form of a Fortran include ﬁle named omp_lib.h or a Fortran 90 7
module named omp_lib . It is implementation deﬁned whether the include ﬁle or the 8
module ﬁle (or both) is provided. 9
These ﬁles also deﬁne the following: 10
Theinteger parameter omp_lock_kind ; 11
Theinteger parameter omp_nest_lock_kind ; 12
Theinteger parameter omp_sync_hint_kind ; 13
Theinteger parameter omp_lock_hint_kind (deprecated); 14
Theinteger parameter omp_sched_kind ; 15
Theinteger parameter omp_proc_bind_kind ; 16
Theinteger parameter omp_control_tool_kind ; 17
Theinteger parameter omp_control_tool_result_kind ; 18
Theinteger parameter omp_depend_kind ; 19
Theinteger parameter omp_memspace_handle_kind ; 20
Theinteger parameter omp_allocator_handle_kind ; 21
Theinteger parameter omp_alloctrait_key_kind ; 22
Theinteger parameter omp_alloctrait_val_kind ; 23
Aninteger parameter of kind omp_memspace_handle_kind for each predeﬁned 24
memory space in Table 2.8 on page 152; 25
Aninteger parameter of kind omp_allocator_handle_kind for each predeﬁned 26
memory allocator in Table 2.10 on page 155; 27
Theinteger parameter omp_pause_resource_kind ; 28
Theinteger parameter omp_event_handle_kind ; and 29
CHAPTER 3. RUNTIME LIBRARY ROUTINES 333
Theinteger parameter openmp_version with a value yyyymmwhereyyyyandmmare 1
the year and month designations of the version of the OpenMP Fortran API that the 2
implementation supports; this value matches that of the C preprocessor macro _OPENMP , when 3
a macro preprocessor is supported (see Section 2.2 on page 49). 4
It is implementation deﬁned whether any of the OpenMP runtime library routines that take an 5
argument are extended with a generic interface so arguments of diﬀerent KINDtype can be 6
accommodated. 7
Fortran
3.2 Execution Environment Routines8
This section describes routines that aﬀect and monitor threads, processors, and the parallel 9
environment. 10
3.2.1 omp_set_num_threads 11
Summary 12
Theomp_set_num_threads routine aﬀects the number of threads to be used for subsequent 13
parallel regions that do not specify a num_threads clause, by setting the value of the ﬁrst 14
element of the nthreads-var ICV of the current task. 15
Format 16
C / C++
void omp_set_num_threads(int num_threads ); 17
C / C++
Fortran
subroutine omp_set_num_threads( num_threads ) 18
integer num_threads 19
Fortran
Constraints on Arguments 20
The value of the argument passed to this routine must evaluate to a positive integer, or else the 21
behavior of this routine is implementation deﬁned. 22
334 OpenMP API – Version 5.0 November 2018
Binding 1
The binding task set for an omp_set_num_threads region is the generating task. 2
Effect 3
The eﬀect of this routine is to set the value of the ﬁrst element of the nthreads-var ICV of the 4
current task to the value speciﬁed in the argument. 5
Cross References 6
nthreads-var ICV, see Section 2.5 on page 63. 7
parallel construct and num_threads clause, see Section 2.6 on page 74. 8
Determining the number of threads for a parallel region, see Section 2.6.1 on page 78. 9
omp_get_num_threads routine, see Section 3.2.2 on page 335. 10
omp_get_max_threads routine, see Section 3.2.3 on page 336. 11
OMP_NUM_THREADS environment variable, see Section 6.2 on page 602. 12
3.2.2 omp_get_num_threads 13
Summary 14
Theomp_get_num_threads routine returns the number of threads in the current team. 15
Format 16
C / C++
int omp_get_num_threads(void); 17
C / C++
Fortran
integer function omp_get_num_threads() 18
Fortran
Binding 19
The binding region for an omp_get_num_threads region is the innermost enclosing 20
parallel region. 21
CHAPTER 3. RUNTIME LIBRARY ROUTINES 335
Effect 1
Theomp_get_num_threads routinereturnsthenumberofthreadsintheteamthatisexecuting 2
theparallel region to which the routine region binds. If called from the sequential part of a 3
program, this routine returns 1. 4
Cross References 5
nthreads-var ICV, see Section 2.5 on page 63. 6
parallel construct and num_threads clause, see Section 2.6 on page 74. 7
Determining the number of threads for a parallel region, see Section 2.6.1 on page 78. 8
omp_set_num_threads routine, see Section 3.2.1 on page 334. 9
OMP_NUM_THREADS environment variable, see Section 6.2 on page 602. 10
3.2.3 omp_get_max_threads 11
Summary 12
Theomp_get_max_threads routine returns an upper bound on the number of threads that 13
couldbeusedtoformanewteamifa parallel constructwithouta num_threads clausewere 14
encountered after execution returns from this routine. 15
Format 16
C / C++
int omp_get_max_threads(void); 17
C / C++
Fortran
integer function omp_get_max_threads() 18
Fortran
Binding 19
The binding task set for an omp_get_max_threads region is the generating task. 20
336 OpenMP API – Version 5.0 November 2018
Effect 1
The value returned by omp_get_max_threads is the value of the ﬁrst element of the 2
nthreads-var ICV of the current task. This value is also an upper bound on the number of threads 3
that could be used to form a new team if a parallel region without a num_threads clause were 4
encountered after execution returns from this routine. 5
6
Note– The return value of the omp_get_max_threads routine can be used to allocate 7
suﬃcient storage dynamically for all threads in the team formed at the subsequent active 8
parallel region. 9
10
Cross References 11
nthreads-var ICV, see Section 2.5 on page 63. 12
parallel construct and num_threads clause, see Section 2.6 on page 74. 13
Determining the number of threads for a parallel region, see Section 2.6.1 on page 78. 14
omp_set_num_threads routine, see Section 3.2.1 on page 334. 15
omp_get_num_threads routine, see Section 3.2.2 on page 335. 16
omp_get_thread_num routine, see Section 3.2.4 on page 337. 17
OMP_NUM_THREADS environment variable, see Section 6.2 on page 602. 18
3.2.4 omp_get_thread_num 19
Summary 20
Theomp_get_thread_num routine returns the thread number, within the current team, of the 21
calling thread. 22
Format 23
C / C++
int omp_get_thread_num(void); 24
C / C++
Fortran
integer function omp_get_thread_num() 25
Fortran
CHAPTER 3. RUNTIME LIBRARY ROUTINES 337
Binding 1
The binding thread set for an omp_get_thread_num region is the current team. The binding 2
region for an omp_get_thread_num region is the innermost enclosing parallel region. 3
Effect 4
Theomp_get_thread_num routine returns the thread number of the calling thread, within the 5
team that is executing the parallel region to which the routine region binds. The thread number 6
is an integer between 0 and one less than the value returned by omp_get_num_threads , 7
inclusive. The thread number of the master thread of the team is 0. The routine returns 0 if it is 8
called from the sequential part of a program. 9
10
Note– The thread number may change during the execution of an untied task. The value returned 11
byomp_get_thread_num is not generally useful during the execution of such a task region. 12
13
Cross References 14
nthreads-var ICV, see Section 2.5 on page 63. 15
parallel construct and num_threads clause, see Section 2.6 on page 74. 16
Determining the number of threads for a parallel region, see Section 2.6.1 on page 78. 17
omp_set_num_threads routine, see Section 3.2.1 on page 334. 18
omp_get_num_threads routine, see Section 3.2.2 on page 335. 19
OMP_NUM_THREADS environment variable, see Section 6.2 on page 602. 20
3.2.5 omp_get_num_procs 21
Summary 22
Theomp_get_num_procs routine returns the number of processors available to the device. 23
Format 24
C / C++
int omp_get_num_procs(void); 25
C / C++
Fortran
integer function omp_get_num_procs() 26
Fortran
338 OpenMP API – Version 5.0 November 2018
Binding 1
The binding thread set for an omp_get_num_procs region is all threads on a device. The eﬀect 2
of executing this routine is not related to any speciﬁc region corresponding to any construct or API 3
routine. 4
Effect 5
Theomp_get_num_procs routine returns the number of processors that are available to the 6
device at the time the routine is called. This value may change between the time that it is 7
determined by the omp_get_num_procs routine and the time that it is read in the calling 8
context due to system actions outside the control of the OpenMP implementation. 9
Cross References 10
omp_get_num_places routine, see Section 3.2.24 on page 358. 11
omp_get_place_num_procs routine, see Section 3.2.25 on page 359. 12
omp_get_place_proc_ids routine, see Section 3.2.26 on page 360. 13
omp_get_place_num routine, see Section 3.2.27 on page 362. 14
3.2.6 omp_in_parallel 15
Summary 16
Theomp_in_parallel routine returns trueif theactive-levels-var ICV is greater than zero; 17
otherwise, it returns false. 18
Format 19
C / C++
int omp_in_parallel(void); 20
C / C++
Fortran
logical function omp_in_parallel() 21
Fortran
Binding 22
The binding task set for an omp_in_parallel region is the generating task. 23
CHAPTER 3. RUNTIME LIBRARY ROUTINES 339
Effect 1
Theeﬀectofthe omp_in_parallel routineistoreturn trueifthecurrenttaskisenclosedbyan 2
active parallel region, and the parallel region is enclosed by the outermost initial task 3
region on the device; otherwise it returns false. 4
Cross References 5
active-levels-var , see Section 2.5 on page 63. 6
parallel construct, see Section 2.6 on page 74. 7
omp_get_num_threads routine, see Section 3.2.2 on page 335. 8
omp_get_active_level routine, see Section 3.2.21 on page 355. 9
3.2.7 omp_set_dynamic 10
Summary 11
Theomp_set_dynamic routine enables or disables dynamic adjustment of the number of 12
threads available for the execution of subsequent parallel regions by setting the value of the 13
dyn-varICV. 14
Format 15
C / C++
void omp_set_dynamic(int dynamic_threads ); 16
C / C++
Fortran
subroutine omp_set_dynamic( dynamic_threads ) 17
logical dynamic_threads 18
Fortran
Binding 19
The binding task set for an omp_set_dynamic region is the generating task. 20
340 OpenMP API – Version 5.0 November 2018
Effect 1
For implementations that support dynamic adjustment of the number of threads, if the argument to 2
omp_set_dynamic evaluates to true, dynamic adjustment is enabled for the current task; 3
otherwise, dynamic adjustment is disabled for the current task. For implementations that do not 4
support dynamic adjustment of the number of threads, this routine has no eﬀect: the value of 5
dyn-varremainsfalse. 6
Cross References 7
dyn-varICV, see Section 2.5 on page 63. 8
Determining the number of threads for a parallel region, see Section 2.6.1 on page 78. 9
omp_get_num_threads routine, see Section 3.2.2 on page 335. 10
omp_get_dynamic routine, see Section 3.2.8 on page 341. 11
OMP_DYNAMIC environment variable, see Section 6.3 on page 603. 12
3.2.8 omp_get_dynamic 13
Summary 14
Theomp_get_dynamic routine returns the value of the dyn-varICV, which determines whether 15
dynamic adjustment of the number of threads is enabled or disabled. 16
Format 17
C / C++
int omp_get_dynamic(void); 18
C / C++
Fortran
logical function omp_get_dynamic() 19
Fortran
Binding 20
The binding task set for an omp_get_dynamic region is the generating task. 21
CHAPTER 3. RUNTIME LIBRARY ROUTINES 341
Effect 1
This routine returns trueif dynamic adjustment of the number of threads is enabled for the current 2
task; it returns false, otherwise. If an implementation does not support dynamic adjustment of the 3
number of threads, then this routine always returns false. 4
Cross References 5
dyn-varICV, see Section 2.5 on page 63. 6
Determining the number of threads for a parallel region, see Section 2.6.1 on page 78. 7
omp_set_dynamic routine, see Section 3.2.7 on page 340. 8
OMP_DYNAMIC environment variable, see Section 6.3 on page 603. 9
3.2.9 omp_get_cancellation 10
Summary 11
Theomp_get_cancellation routine returns the value of the cancel-var ICV, which 12
determines if cancellation is enabled or disabled. 13
Format 14
C / C++
int omp_get_cancellation(void); 15
C / C++
Fortran
logical function omp_get_cancellation() 16
Fortran
Binding 17
The binding task set for an omp_get_cancellation region is the whole program. 18
Effect 19
This routine returns trueif cancellation is enabled. It returns falseotherwise. 20
342 OpenMP API – Version 5.0 November 2018
Cross References 1
cancel-var ICV, see Section 2.5.1 on page 64. 2
cancel construct, see Section 2.18.1 on page 263. 3
OMP_CANCELLATION environment variable, see Section 6.11 on page 610. 4
3.2.10 omp_set_nested 5
Summary 6
The deprecated omp_set_nested routine enables or disables nested parallelism by setting the 7
max-active-levels-var ICV. 8
Format 9
C / C++
void omp_set_nested(int nested ); 10
C / C++
Fortran
subroutine omp_set_nested( nested ) 11
logical nested 12
Fortran
Binding 13
The binding task set for an omp_set_nested region is the generating task. 14
Effect 15
If the argument to omp_set_nested evaluates to true, the value of the max-active-levels-var 16
ICVissettothenumberofactivelevelsofparallelismthattheimplementationsupports;otherwise, 17
if the value of max-active-levels-var is greater than 1 then it is set to 1. This routine has been 18
deprecated. 19
CHAPTER 3. RUNTIME LIBRARY ROUTINES 343
Cross References 1
max-active-levels-var ICV, see Section 2.5 on page 63. 2
Determining the number of threads for a parallel region, see Section 2.6.1 on page 78. 3
omp_get_nested routine, see Section 3.2.11 on page 344. 4
omp_set_max_active_levels routine, see Section 3.2.16 on page 350. 5
omp_get_max_active_levels routine, see Section 3.2.17 on page 351. 6
OMP_NESTED environment variable, see Section 6.9 on page 609. 7
3.2.11 omp_get_nested 8
Summary 9
The deprecated omp_get_nested routine returns whether nested parallelism is enabled or 10
disabled, according to the value of the max-active-levels-var ICV. 11
Format 12
C / C++
int omp_get_nested(void); 13
C / C++
Fortran
logical function omp_get_nested() 14
Fortran
Binding 15
The binding task set for an omp_get_nested region is the generating task. 16
Effect 17
This routine returns trueifmax-active-levels-var is greater than 1 for the current task; it returns 18
false, otherwise. If an implementation does not support nested parallelism, this routine always 19
returnsfalse. This routine has been deprecated. 20
344 OpenMP API – Version 5.0 November 2018
Cross References 1
max-active-levels-var ICV, see Section 2.5 on page 63. 2
Determining the number of threads for a parallel region, see Section 2.6.1 on page 78. 3
omp_set_nested routine, see Section 3.2.10 on page 343. 4
omp_set_max_active_levels routine, see Section 3.2.16 on page 350. 5
omp_get_max_active_levels routine, see Section 3.2.17 on page 351. 6
OMP_NESTED environment variable, see Section 6.9 on page 609. 7
3.2.12 omp_set_schedule 8
Summary 9
Theomp_set_schedule routine aﬀects the schedule that is applied when runtime is used as 10
schedule kind, by setting the value of the run-sched-var ICV. 11
Format 12
C / C++
void omp_set_schedule(omp_sched_t kind, intchunk_size ); 13
C / C++
Fortran
subroutine omp_set_schedule( kind,chunk_size ) 14
integer (kind=omp_sched_kind) kind 15
integer chunk_size 16
Fortran
CHAPTER 3. RUNTIME LIBRARY ROUTINES 345
Constraints on Arguments 1
TheﬁrstargumentpassedtothisroutinecanbeoneofthevalidOpenMPschedulekinds(exceptfor 2
runtime ) or any implementation speciﬁc schedule. The C/C++ header ﬁle ( omp.h) and the 3
Fortran include ﬁle ( omp_lib.h ) and/or Fortran 90 module ﬁle ( omp_lib ) deﬁne the valid 4
constants. The valid constants must include the following, which can be extended with 5
implementation speciﬁc values: 6
C / C++
typedef enum omp_sched_t { 7
// schedule kinds 8
omp_sched_static = 0x1, 9
omp_sched_dynamic = 0x2, 10
omp_sched_guided = 0x3, 11
omp_sched_auto = 0x4, 12
13
// schedule modifier 14
omp_sched_monotonic = 0x80000000u 15
} omp_sched_t; 16
C / C++
Fortran
! schedule kinds 17
integer(kind=omp_sched_kind), & 18
parameter :: omp_sched_static = & 19
int(Z’1’, kind=omp_sched_kind) 20
integer(kind=omp_sched_kind), & 21
parameter :: omp_sched_dynamic = & 22
int(Z’2’, kind=omp_sched_kind) 23
integer(kind=omp_sched_kind), & 24
parameter :: omp_sched_guided = & 25
int(Z’3’, kind=omp_sched_kind) 26
integer(kind=omp_sched_kind), & 27
parameter :: omp_sched__auto = & 28
int(Z’4’, kind=omp_sched_kind) 29
30
! schedule modifier 31
integer(kind=omp_sched_kind), & 32
parameter :: omp_sched_monotonic = & 33
int(Z’80000000’, kind=omp_sched_kind) 34
Fortran
Binding 35
The binding task set for an omp_set_schedule region is the generating task. 36
346 OpenMP API – Version 5.0 November 2018
Effect 1
The eﬀect of this routine is to set the value of the run-sched-var ICV of the current task to the 2
values speciﬁed in the two arguments. The schedule is set to the schedule kind that is speciﬁed by 3
the ﬁrst argument kind. It can be any of the standard schedule kinds or any other implementation 4
speciﬁc one. For the schedule kinds static,dynamic , andguided thechunk_size is set to the 5
value of the second argument, or to the default chunk_size if the value of the second argument is 6
less than 1; for the schedule kind autothe second argument has no meaning; for implementation 7
speciﬁc schedule kinds, the values and associated meanings of the second argument are 8
implementation deﬁned. 9
Each of the schedule kinds can be combined with the omp_sched_monotonic modiﬁer by 10
using the + or | operators in C/C++ or the + operator in Fortran. If the schedule kind is combined 11
with the omp_sched_monotonic modiﬁer, the schedule is modiﬁed as if the monotonic 12
schedule modiﬁer was speciﬁed. Otherwise, the schedule modiﬁer is nonmonotonic . 13
Cross References 14
run-sched-var ICV, see Section 2.5 on page 63. 15
Determining the schedule of a worksharing-loop, see Section 2.9.2.1 on page 109. 16
omp_set_schedule routine, see Section 3.2.12 on page 345. 17
omp_get_schedule routine, see Section 3.2.13 on page 347. 18
OMP_SCHEDULE environment variable, see Section 6.1 on page 601. 19
3.2.13 omp_get_schedule 20
Summary 21
Theomp_get_schedule routine returns the schedule that is applied when the runtime schedule 22
is used. 23
Format 24
C / C++
void omp_get_schedule(omp_sched_t *kind, int *chunk_size ); 25
C / C++
Fortran
subroutine omp_get_schedule( kind,chunk_size ) 26
integer (kind=omp_sched_kind) kind 27
integer chunk_size 28
Fortran
CHAPTER 3. RUNTIME LIBRARY ROUTINES 347
Binding 1
The binding task set for an omp_get_schedule region is the generating task. 2
Effect 3
This routine returns the run-sched-var ICV in the task to which the routine binds. The ﬁrst 4
argument kindreturns the schedule to be used. It can be any of the standard schedule kinds as 5
deﬁned in Section 3.2.12 on page 345, or any implementation speciﬁc schedule kind. The second 6
argument chunk_size returns the chunk size to be used, or a value less than 1 if the default chunk 7
size is to be used, if the returned schedule kind is static,dynamic , orguided. The value 8
returned by the second argument is implementation deﬁned for any other schedule kinds. 9
Cross References 10
run-sched-var ICV, see Section 2.5 on page 63. 11
Determining the schedule of a worksharing-loop, see Section 2.9.2.1 on page 109. 12
omp_set_schedule routine, see Section 3.2.12 on page 345. 13
OMP_SCHEDULE environment variable, see Section 6.1 on page 601. 14
3.2.14 omp_get_thread_limit 15
Summary 16
Theomp_get_thread_limit routine returns the maximum number of OpenMP threads 17
available to participate in the current contention group. 18
Format 19
C / C++
int omp_get_thread_limit(void); 20
C / C++
Fortran
integer function omp_get_thread_limit() 21
Fortran
348 OpenMP API – Version 5.0 November 2018
Binding 1
The binding thread set for an omp_get_thread_limit region is all threads on the device. The 2
eﬀect of executing this routine is not related to any speciﬁc region corresponding to any construct 3
or API routine. 4
Effect 5
Theomp_get_thread_limit routine returns the value of the thread-limit-var ICV. 6
Cross References 7
thread-limit-var ICV, see Section 2.5 on page 63. 8
omp_get_num_threads routine, see Section 3.2.2 on page 335. 9
OMP_THREAD_LIMIT environment variable, see Section 6.10 on page 610. 10
OMP_NUM_THREADS environment variable, see Section 6.2 on page 602. 11
3.2.15 omp_get_supported_active_levels 12
Summary 13
Theomp_get_supported_active_levels routine returns the number of active levels of 14
parallelism supported by the implementation. 15
Format 16
C / C++
int omp_get_supported_active_levels(void); 17
C / C++
Fortran
integer function omp_get_supported_active_levels() 18
Fortran
Binding 19
The binding task set for an omp_get_supported_active_levels region is the generating 20
task. 21
CHAPTER 3. RUNTIME LIBRARY ROUTINES 349
Effect 1
Theomp_get_supported_active_levels routine returns the number of active levels of 2
parallelism supported by the implementation. The max-active-levels-var ICV may not have a value 3
that is greater than this number. The value returned by the 4
omp_get_supported_active_levels routine is implementation deﬁned, but it must be 5
greater than 0. 6
Cross References 7
max-active-levels-var ICV, see Section 2.5 on page 63. 8
omp_get_max_active_levels routine, see Section 3.2.17 on page 351. 9
omp_set_max_active_levels routine, see Section 3.2.16 on page 350. 10
3.2.16 omp_set_max_active_levels 11
Summary 12
Theomp_set_max_active_levels routine limits the number of nested active parallel 13
regions on the device, by setting the max-active-levels-var ICV 14
Format 15
C / C++
void omp_set_max_active_levels(int max_levels ); 16
C / C++
Fortran
subroutine omp_set_max_active_levels( max_levels ) 17
integer max_levels 18
Fortran
Constraints on Arguments 19
The value of the argument passed to this routine must evaluate to a non-negative integer, otherwise 20
the behavior of this routine is implementation deﬁned. 21
350 OpenMP API – Version 5.0 November 2018
Binding 1
When called from a sequential part of the program, the binding thread set for an 2
omp_set_max_active_levels region is the encountering thread. When called from within 3
anyparallel orteamsregion, the binding thread set (and binding region, if required) for the 4
omp_set_max_active_levels region is implementation deﬁned. 5
Effect 6
The eﬀect of this routine is to set the value of the max-active-levels-var ICV to the value speciﬁed 7
in the argument. 8
If the number of active levels requested exceeds the number of active levels of parallelism 9
supported by the implementation, the value of the max-active-levels-var ICV will be set to the 10
number of active levels supported by the implementation. 11
This routine has the described eﬀect only when called from a sequential part of the program. When 12
called from within a parallel orteamsregion, the eﬀect of this routine is implementation 13
deﬁned. 14
Cross References 15
max-active-levels-var ICV, see Section 2.5 on page 63. 16
parallel construct, see Section 2.6 on page 74. 17
omp_get_supported_active_levels routine, see Section 3.2.15 on page 349. 18
omp_get_max_active_levels routine, see Section 3.2.17 on page 351. 19
OMP_MAX_ACTIVE_LEVELS environment variable, see Section 6.8 on page 608. 20
3.2.17 omp_get_max_active_levels 21
Summary 22
Theomp_get_max_active_levels routine returns the value of the max-active-levels-var 23
ICV, which determines the maximum number of nested active parallel regions on the device. 24
Format 25
C / C++
int omp_get_max_active_levels(void); 26
C / C++
Fortran
integer function omp_get_max_active_levels() 27
Fortran
CHAPTER 3. RUNTIME LIBRARY ROUTINES 351
Binding 1
When called from a sequential part of the program, the binding thread set for an 2
omp_get_max_active_levels region is the encountering thread. When called from within 3
anyparallel orteamsregion, the binding thread set (and binding region, if required) for the 4
omp_get_max_active_levels region is implementation deﬁned. 5
Effect 6
Theomp_get_max_active_levels routine returns the value of the max-active-levels-var 7
ICV, which determines the maximum number of nested active parallel regions on the device. 8
Cross References 9
max-active-levels-var ICV, see Section 2.5 on page 63. 10
parallel construct, see Section 2.6 on page 74. 11
omp_get_supported_active_levels routine, see Section 3.2.15 on page 349. 12
omp_set_max_active_levels routine, see Section 3.2.16 on page 350. 13
OMP_MAX_ACTIVE_LEVELS environment variable, see Section 6.8 on page 608. 14
3.2.18 omp_get_level 15
Summary 16
Theomp_get_level routine returns the value of the levels-var ICV. 17
Format 18
C / C++
int omp_get_level(void); 19
C / C++
Fortran
integer function omp_get_level() 20
Fortran
Binding 21
The binding task set for an omp_get_level region is the generating task. 22
352 OpenMP API – Version 5.0 November 2018
Effect 1
The eﬀect of the omp_get_level routine is to return the number of nested parallel regions 2
(whether active or inactive) that enclose the current task such that all of the parallel regions are 3
enclosed by the outermost initial task region on the current device. 4
Cross References 5
levels-var ICV, see Section 2.5 on page 63. 6
parallel construct, see Section 2.6 on page 74. 7
omp_get_active_level routine, see Section 3.2.21 on page 355. 8
OMP_MAX_ACTIVE_LEVELS environment variable, see Section 6.8 on page 608. 9
3.2.19 omp_get_ancestor_thread_num 10
Summary 11
Theomp_get_ancestor_thread_num routine returns, for a given nested level of the current 12
thread, the thread number of the ancestor of the current thread. 13
Format 14
C / C++
int omp_get_ancestor_thread_num(int level); 15
C / C++
Fortran
integer function omp_get_ancestor_thread_num( level) 16
integer level 17
Fortran
Binding 18
The binding thread set for an omp_get_ancestor_thread_num region is the encountering 19
thread. The binding region for an omp_get_ancestor_thread_num region is the innermost 20
enclosing parallel region. 21
CHAPTER 3. RUNTIME LIBRARY ROUTINES 353
Effect 1
Theomp_get_ancestor_thread_num routine returns the thread number of the ancestor at a 2
given nest level of the current thread or the thread number of the current thread. If the requested 3
nest level is outside the range of 0 and the nest level of the current thread, as returned by the 4
omp_get_level routine, the routine returns -1. 5
6
Note– When the omp_get_ancestor_thread_num routine is called with a value of 7
level=0, the routine always returns 0. If level=omp_get_level() , the routine has the 8
same eﬀect as the omp_get_thread_num routine. 9
10
Cross References 11
parallel construct, see Section 2.6 on page 74. 12
omp_get_num_threads routine, see Section 3.2.2 on page 335. 13
omp_get_thread_num routine, see Section 3.2.4 on page 337. 14
omp_get_level routine, see Section 3.2.18 on page 352. 15
omp_get_team_size routine, see Section 3.2.20 on page 354. 16
3.2.20 omp_get_team_size 17
Summary 18
Theomp_get_team_size routinereturns,foragivennestedlevelofthecurrentthread,the size 19
of the thread team to which the ancestor or the current thread belongs. 20
Format 21
C / C++
int omp_get_team_size(int level); 22
C / C++
Fortran
integer function omp_get_team_size( level) 23
integer level 24
Fortran
354 OpenMP API – Version 5.0 November 2018
Binding 1
The binding thread set for an omp_get_team_size region is the encountering thread. The 2
binding region for an omp_get_team_size region is the innermost enclosing parallel 3
region. 4
Effect 5
Theomp_get_team_size routine returns the size of the thread team to which the ancestor or 6
the current thread belongs. If the requested nested level is outside the range of 0 and the nested 7
level of the current thread, as returned by the omp_get_level routine, the routine returns -1. 8
Inactive parallel regions are regarded like active parallel regions executed with one thread. 9
10
Note– When the omp_get_team_size routine is called with a value of level=0, the routine 11
always returns 1. If level=omp_get_level() , the routine has the same eﬀect as the 12
omp_get_num_threads routine. 13
14
Cross References 15
omp_get_num_threads routine, see Section 3.2.2 on page 335. 16
omp_get_level routine, see Section 3.2.18 on page 352. 17
omp_get_ancestor_thread_num routine, see Section 3.2.19 on page 353. 18
3.2.21 omp_get_active_level 19
Summary 20
Theomp_get_active_level routine returns the value of the active-level-vars ICV.. 21
Format 22
C / C++
int omp_get_active_level(void); 23
C / C++
Fortran
integer function omp_get_active_level() 24
Fortran
CHAPTER 3. RUNTIME LIBRARY ROUTINES 355
Binding 1
The binding task set for the an omp_get_active_level region is the generating task. 2
Effect 3
The eﬀect of the omp_get_active_level routine is to return the number of nested active 4
parallel regions enclosing the current task such that all of the parallel regions are enclosed 5
by the outermost initial task region on the current device. 6
Cross References 7
active-levels-var ICV, see Section 2.5 on page 63. 8
omp_get_level routine, see Section 3.2.18 on page 352. 9
omp_set_max_active_levels routine, see Section 3.2.16 on page 350. 10
omp_get_max_active_levels routine, see Section 3.2.17 on page 351. 11
OMP_MAX_ACTIVE_LEVELS environment variable, see Section 6.8 on page 608. 12
3.2.22 omp_in_final 13
Summary 14
Theomp_in_final routine returns trueif the routine is executed in a ﬁnal task region; 15
otherwise, it returns false. 16
Format 17
C / C++
int omp_in_final(void); 18
C / C++
Fortran
logical function omp_in_final() 19
Fortran
Binding 20
The binding task set for an omp_in_final region is the generating task. 21
356 OpenMP API – Version 5.0 November 2018
Effect 1
omp_in_final returnstrueif the enclosing task region is ﬁnal. Otherwise, it returns false. 2
Cross References 3
taskconstruct, see Section 2.10.1 on page 135. 4
3.2.23 omp_get_proc_bind 5
Summary 6
Theomp_get_proc_bind routine returns the thread aﬃnity policy to be used for the 7
subsequent nested parallel regions that do not specify a proc_bind clause. 8
Format 9
C / C++
omp_proc_bind_t omp_get_proc_bind(void); 10
C / C++
Fortran
integer (kind=omp_proc_bind_kind) function omp_get_proc_bind() 11
Fortran
Constraints on Arguments 12
The value returned by this routine must be one of the valid aﬃnity policy kinds. The C/C++ header 13
ﬁle (omp.h) and the Fortran include ﬁle ( omp_lib.h ) and/or Fortran 90 module ﬁle ( omp_lib ) 14
deﬁne the valid constants. The valid constants must include the following: 15
C / C++
typedef enum omp_proc_bind_t { 16
omp_proc_bind_false = 0, 17
omp_proc_bind_true = 1, 18
omp_proc_bind_master = 2, 19
omp_proc_bind_close = 3, 20
omp_proc_bind_spread = 4 21
} omp_proc_bind_t; 22
C / C++
CHAPTER 3. RUNTIME LIBRARY ROUTINES 357
Fortran
integer (kind=omp_proc_bind_kind), & 1
parameter :: omp_proc_bind_false = 0 2
integer (kind=omp_proc_bind_kind), & 3
parameter :: omp_proc_bind_true = 1 4
integer (kind=omp_proc_bind_kind), & 5
parameter :: omp_proc_bind_master = 2 6
integer (kind=omp_proc_bind_kind), & 7
parameter :: omp_proc_bind_close = 3 8
integer (kind=omp_proc_bind_kind), & 9
parameter :: omp_proc_bind_spread = 4 10
Fortran
Binding 11
The binding task set for an omp_get_proc_bind region is the generating task. 12
Effect 13
Theeﬀectofthisroutineistoreturnthevalueoftheﬁrstelementofthe bind-varICVofthecurrent 14
task. See Section 2.6.2 on page 80 for the rules that govern the thread aﬃnity policy. 15
Cross References 16
bind-varICV, see Section 2.5 on page 63. 17
Controlling OpenMP thread aﬃnity, see Section 2.6.2 on page 80. 18
omp_get_num_places routine, see Section 3.2.24 on page 358. 19
OMP_PROC_BIND environment variable, see Section 6.4 on page 604. 20
OMP_PLACES environment variable, see Section 6.5 on page 605. 21
3.2.24 omp_get_num_places 22
Summary 23
Theomp_get_num_places routine returns the number of places available to the execution 24
environment in the place list. 25
358 OpenMP API – Version 5.0 November 2018
Format 1
C / C++
int omp_get_num_places(void); 2
C / C++
Fortran
integer function omp_get_num_places() 3
Fortran
Binding 4
The binding thread set for an omp_get_num_places region is all threads on a device. The 5
eﬀect of executing this routine is not related to any speciﬁc region corresponding to any construct 6
or API routine. 7
Effect 8
Theomp_get_num_places routine returns the number of places in the place list. This value is 9
equivalent to the number of places in the place-partition-var ICV in the execution environment of 10
the initial task. 11
Cross References 12
place-partition-var ICV, see Section 2.5 on page 63. 13
Controlling OpenMP thread aﬃnity, see Section 2.6.2 on page 80. 14
omp_get_place_num routine, see Section 3.2.27 on page 362. 15
OMP_PLACES environment variable, see Section 6.5 on page 605. 16
3.2.25 omp_get_place_num_procs 17
Summary 18
Theomp_get_place_num_procs routine returns the number of processors available to the 19
execution environment in the speciﬁed place. 20
CHAPTER 3. RUNTIME LIBRARY ROUTINES 359
Format 1
C / C++
int omp_get_place_num_procs(int place_num ); 2
C / C++
Fortran
integer function omp_get_place_num_procs( place_num ) 3
integer place_num 4
Fortran
Binding 5
The binding thread set for an omp_get_place_num_procs region is all threads on a device. 6
The eﬀect of executing this routine is not related to any speciﬁc region corresponding to any 7
construct or API routine. 8
Effect 9
Theomp_get_place_num_procs routine returns the number of processors associated with 10
the place numbered place_num . The routine returns zero when place_num is negative, or is greater 11
than or equal to the value returned by omp_get_num_places() . 12
Cross References 13
place-partition-var ICV, see Section 2.5 on page 63. 14
Controlling OpenMP thread aﬃnity, see Section 2.6.2 on page 80. 15
omp_get_num_places routine, see Section 3.2.24 on page 358. 16
omp_get_place_proc_ids routine, see Section 3.2.26 on page 360. 17
OMP_PLACES environment variable, see Section 6.5 on page 605. 18
3.2.26 omp_get_place_proc_ids 19
Summary 20
Theomp_get_place_proc_ids routine returns the numerical identiﬁers of the processors 21
available to the execution environment in the speciﬁed place. 22
360 OpenMP API – Version 5.0 November 2018
Format 1
C / C++
void omp_get_place_proc_ids(int place_num , int *ids); 2
C / C++
Fortran
subroutine omp_get_place_proc_ids( place_num ,ids) 3
integer place_num 4
integer ids(*) 5
Fortran
Binding 6
The binding thread set for an omp_get_place_proc_ids region is all threads on a device. 7
The eﬀect of executing this routine is not related to any speciﬁc region corresponding to any 8
construct or API routine. 9
Effect 10
Theomp_get_place_proc_ids routine returns the numerical identiﬁers of each processor 11
associated with the place numbered place_num . The numerical identiﬁers are non-negative, and 12
theirmeaningisimplementationdeﬁned. Thenumericalidentiﬁersarereturnedinthearray idsand 13
their order in the array is implementation deﬁned. The array must be suﬃciently large to contain 14
omp_get_place_num_procs( place_num )integers; otherwise, the behavior is unspeciﬁed. 15
The routine has no eﬀect when place_num has a negative value, or a value greater than or equal to 16
omp_get_num_places() . 17
Cross References 18
place-partition-var ICV, see Section 2.5 on page 63. 19
Controlling OpenMP thread aﬃnity, see Section 2.6.2 on page 80. 20
omp_get_num_places routine, see Section 3.2.24 on page 358. 21
omp_get_place_num_procs routine, see Section 3.2.25 on page 359. 22
OMP_PLACES environment variable, see Section 6.5 on page 605. 23
CHAPTER 3. RUNTIME LIBRARY ROUTINES 361
3.2.27 omp_get_place_num 1
Summary 2
Theomp_get_place_num routine returns the place number of the place to which the 3
encountering thread is bound. 4
Format 5
C / C++
int omp_get_place_num(void); 6
C / C++
Fortran
integer function omp_get_place_num() 7
Fortran
Binding 8
The binding thread set for an omp_get_place_num region is the encountering thread. 9
Effect 10
When the encountering thread is bound to a place, the omp_get_place_num routine returns the 11
place number associated with the thread. The returned value is between 0 and one less than the 12
value returned by omp_get_num_places() , inclusive. When the encountering thread is not 13
bound to a place, the routine returns -1. 14
Cross References 15
place-partition-var ICV, see Section 2.5 on page 63. 16
Controlling OpenMP thread aﬃnity, see Section 2.6.2 on page 80. 17
omp_get_num_places routine, see Section 3.2.24 on page 358. 18
OMP_PLACES environment variable, see Section 6.5 on page 605. 19
3.2.28 omp_get_partition_num_places 20
Summary 21
Theomp_get_partition_num_places routine returns the number of places in the place 22
partition of the innermost implicit task. 23
362 OpenMP API – Version 5.0 November 2018
Format 1
C / C++
int omp_get_partition_num_places(void); 2
C / C++
Fortran
integer function omp_get_partition_num_places() 3
Fortran
Binding 4
The binding task set for an omp_get_partition_num_places region is the encountering 5
implicit task. 6
Effect 7
Theomp_get_partition_num_places routine returns the number of places in the 8
place-partition-var ICV. 9
Cross References 10
place-partition-var ICV, see Section 2.5 on page 63. 11
Controlling OpenMP thread aﬃnity, see Section 2.6.2 on page 80. 12
omp_get_num_places routine, see Section 3.2.24 on page 358. 13
OMP_PLACES environment variable, see Section 6.5 on page 605. 14
3.2.29 omp_get_partition_place_nums 15
Summary 16
Theomp_get_partition_place_nums routine returns the list of place numbers 17
corresponding to the places in the place-partition-var ICV of the innermost implicit task. 18
CHAPTER 3. RUNTIME LIBRARY ROUTINES 363
Format 1
C / C++
void omp_get_partition_place_nums(int *place_nums ); 2
C / C++
Fortran
subroutine omp_get_partition_place_nums( place_nums ) 3
integer place_nums (*) 4
Fortran
Binding 5
The binding task set for an omp_get_partition_place_nums region is the encountering 6
implicit task. 7
Effect 8
Theomp_get_partition_place_nums routine returns the list of place numbers that 9
correspond to the places in the place-partition-var ICV of the innermost implicit task. The array 10
must be suﬃciently large to contain omp_get_partition_num_places() integers; 11
otherwise, the behavior is unspeciﬁed. 12
Cross References 13
place-partition-var ICV, see Section 2.5 on page 63. 14
Controlling OpenMP thread aﬃnity, see Section 2.6.2 on page 80. 15
omp_get_partition_num_places routine, see Section 3.2.28 on page 362. 16
OMP_PLACES environment variable, see Section 6.5 on page 605. 17
3.2.30 omp_set_affinity_format 18
Summary 19
Theomp_set_affinity_format routine sets the aﬃnity format to be used on the device by 20
setting the value of the aﬃnity-format-var ICV. 21
364 OpenMP API – Version 5.0 November 2018
Format 1
C / C++
void omp_set_affinity_format(const char *format ); 2
C / C++
Fortran
subroutine omp_set_affinity_format( format ) 3
character(len= *),intent(in) :: format 4
Fortran
Binding 5
When called from a sequential part of the program, the binding thread set for an 6
omp_set_affinity_format region is the encountering thread. When called from within any 7
parallel orteamsregion, the binding thread set (and binding region, if required) for the 8
omp_set_affinity_format region is implementation deﬁned. 9
Effect 10
The eﬀect of omp_set_affinity_format routine is to copy the character string speciﬁed by 11
theformatargument into the aﬃnity-format-var ICV on the current device. 12
This routine has the described eﬀect only when called from a sequential part of the program. When 13
called from within a parallel orteamsregion, the eﬀect of this routine is implementation 14
deﬁned. 15
Cross References 16
Controlling OpenMP thread aﬃnity, see Section 2.6.2 on page 80. 17
omp_get_affinity_format routine, see Section 3.2.31 on page 366. 18
omp_display_affinity routine, see Section 3.2.32 on page 367. 19
omp_capture_affinity routine, see Section 3.2.33 on page 368. 20
OMP_DISPLAY_AFFINITY environment variable, see Section 6.13 on page 612. 21
OMP_AFFINITY_FORMAT environment variable, see Section 6.14 on page 613. 22
CHAPTER 3. RUNTIME LIBRARY ROUTINES 365
3.2.31 omp_get_affinity_format 1
Summary 2
Theomp_get_affinity_format routine returns the value of the aﬃnity-format-var ICV on 3
the device. 4
Format 5
C / C++
size_t omp_get_affinity_format(char *buﬀer , size_t size); 6
C / C++
Fortran
integer function omp_get_affinity_format( buﬀer ) 7
character(len= *),intent(out) :: buﬀer 8
Fortran
Binding 9
When called from a sequential part of the program, the binding thread set for an 10
omp_get_affinity_format region is the encountering thread. When called from within any 11
parallel orteamsregion, the binding thread set (and binding region, if required) for the 12
omp_get_affinity_format region is implementation deﬁned. 13
Effect 14
C / C++
Theomp_get_affinity_format routine returns the number of characters in the 15
aﬃnity-format-var ICV on the current device, excluding the terminating null byte ( ’\0’) and if 16
sizeis non-zero, writes the value of the aﬃnity-format-var ICV on the current device to buﬀer 17
followed by a null byte. If the return value is larger or equal to size, the aﬃnity format speciﬁcation 18
is truncated, with the terminating null byte stored to buﬀer [size-1]. Ifsizeis zero, nothing is 19
stored and buﬀermay be NULL. 20
C / C++
Fortran
Theomp_get_affinity_format routine returns the number of characters that are required to 21
hold theaﬃnity-format-var ICV on the current device and writes the value of the 22
aﬃnity-format-var ICV on the current device to buﬀer. If the return value is larger than 23
len(buﬀer ), the aﬃnity format speciﬁcation is truncated. 24
Fortran
If thebuﬀerargument does not conform to the speciﬁed format then the result is implementation 25
deﬁned. 26
366 OpenMP API – Version 5.0 November 2018
Cross References 1
Controlling OpenMP thread aﬃnity, see Section 2.6.2 on page 80. 2
omp_set_affinity_format routine, see Section 3.2.30 on page 364. 3
omp_display_affinity routine, see Section 3.2.32 on page 367. 4
omp_capture_affinity routine, see Section 3.2.33 on page 368. 5
OMP_DISPLAY_AFFINITY environment variable, see Section 6.13 on page 612. 6
OMP_AFFINITY_FORMAT environment variable, see Section 6.14 on page 613. 7
3.2.32 omp_display_affinity 8
Summary 9
Theomp_display_affinity routine prints the OpenMP thread aﬃnity information using the 10
format speciﬁcation provided. 11
Format 12
C / C++
void omp_display_affinity(const char *format ); 13
C / C++
Fortran
subroutine omp_display_affinity( format ) 14
character(len= *),intent(in) :: format 15
Fortran
Binding 16
The binding thread set for an omp_display_affinity region is the encountering thread. 17
Effect 18
Theomp_display_affinity routine prints the thread aﬃnity information of the current 19
thread in the format speciﬁed by the formatargument, followed by a new-line. If theformatis 20
NULL(for C/C++) or a zero-length string (for Fortran and C/C++), the value of the 21
aﬃnity-format-var ICV is used. If the formatargument does not conform to the speciﬁed format 22
then the result is implementation deﬁned. 23
CHAPTER 3. RUNTIME LIBRARY ROUTINES 367
Cross References 1
Controlling OpenMP thread aﬃnity, see Section 2.6.2 on page 80. 2
omp_set_affinity_format routine, see Section 3.2.30 on page 364. 3
omp_get_affinity_format routine, see Section 3.2.31 on page 366. 4
omp_capture_affinity routine, see Section 3.2.33 on page 368. 5
OMP_DISPLAY_AFFINITY environment variable, see Section 6.13 on page 612. 6
OMP_AFFINITY_FORMAT environment variable, see Section 6.14 on page 613. 7
3.2.33 omp_capture_affinity 8
Summary 9
Theomp_capture_affinity routine prints the OpenMP thread aﬃnity information into a 10
buﬀer using the format speciﬁcation provided. 11
Format 12
C / C++
size_t omp_capture_affinity( 13
char *buﬀer , 14
size_t size, 15
const char *format 16
); 17
C / C++
Fortran
integer function omp_capture_affinity( buﬀer ,format ) 18
character(len= *),intent(out) :: buﬀer 19
character(len= *),intent(in) :: format 20
Fortran
Binding 21
The binding thread set for an omp_capture_affinity region is the encountering thread. 22
368 OpenMP API – Version 5.0 November 2018
Effect 1
C / C++
Theomp_capture_affinity routine returns the number of characters in the entire thread 2
aﬃnityinformationstringexcludingtheterminatingnullbyte( ’\0’)andifsizeisnon-zero,writes 3
the thread aﬃnity information of the current thread in the format speciﬁed by the formatargument 4
into the character string buffer followed by a null byte. If the return value is larger or equal to 5
size, the thread aﬃnity information string is truncated, with the terminating null byte stored to 6
buﬀer [size-1]. Ifsizeiszero,nothingisstoredand buﬀermaybe NULL.IftheformatisNULLor 7
a zero-length string, the value of the aﬃnity-format-var ICV is used. 8
C / C++
Fortran
Theomp_capture_affinity routine returns the number of characters required to hold the 9
entire thread aﬃnity information string and prints the thread aﬃnity information of the current 10
thread into the character string buffer with the size of len(buﬀer )in the format speciﬁed by 11
theformatargument. If the formatis a zero-length string, the value of the aﬃnity-format-var ICV 12
is used. If the return value is larger than len(buﬀer ), the thread aﬃnity information string is 13
truncated. If the formatis a zero-length string, the value of the aﬃnity-format-var ICV is used. 14
Fortran
If theformatargument does not conform to the speciﬁed format then the result is implementation 15
deﬁned. 16
Cross References 17
Controlling OpenMP thread aﬃnity, see Section 2.6.2 on page 80. 18
omp_set_affinity_format routine, see Section 3.2.30 on page 364. 19
omp_get_affinity_format routine, see Section 3.2.31 on page 366. 20
omp_display_affinity routine, see Section 3.2.32 on page 367. 21
OMP_DISPLAY_AFFINITY environment variable, see Section 6.13 on page 612. 22
OMP_AFFINITY_FORMAT environment variable, see Section 6.14 on page 613. 23
3.2.34 omp_set_default_device 24
Summary 25
Theomp_set_default_device routine controls the default target device by assigning the 26
value of the default-device-var ICV. 27
CHAPTER 3. RUNTIME LIBRARY ROUTINES 369
Format 1
C / C++
void omp_set_default_device(int device_num ); 2
C / C++
Fortran
subroutine omp_set_default_device( device_num ) 3
integer device_num 4
Fortran
Binding 5
The binding task set for an omp_set_default_device region is the generating task. 6
Effect 7
The eﬀect of this routine is to set the value of the default-device-var ICV of the current task to the 8
value speciﬁed in the argument. When called from within a target region the eﬀect of this 9
routine is unspeciﬁed. 10
Cross References 11
default-device-var , see Section 2.5 on page 63. 12
target construct, see Section 2.12.5 on page 170 13
omp_get_default_device , see Section 3.2.35 on page 370. 14
OMP_DEFAULT_DEVICE environment variable, see Section 6.15 on page 615 15
3.2.35 omp_get_default_device 16
Summary 17
Theomp_get_default_device routine returns the default target device. 18
370 OpenMP API – Version 5.0 November 2018
Format 1
C / C++
int omp_get_default_device(void); 2
C / C++
Fortran
integer function omp_get_default_device() 3
Fortran
Binding 4
The binding task set for an omp_get_default_device region is the generating task. 5
Effect 6
Theomp_get_default_device routine returns the value of the default-device-var ICV of the 7
current task. When called from within a target region the eﬀect of this routine is unspeciﬁed. 8
Cross References 9
default-device-var , see Section 2.5 on page 63. 10
target construct, see Section 2.12.5 on page 170 11
omp_set_default_device , see Section 3.2.34 on page 369. 12
OMP_DEFAULT_DEVICE environment variable, see Section 6.15 on page 615. 13
3.2.36 omp_get_num_devices 14
Summary 15
Theomp_get_num_devices routine returns the number of target devices. 16
Format 17
C / C++
int omp_get_num_devices(void); 18
C / C++
Fortran
integer function omp_get_num_devices() 19
Fortran
CHAPTER 3. RUNTIME LIBRARY ROUTINES 371
Binding 1
The binding task set for an omp_get_num_devices region is the generating task. 2
Effect 3
Theomp_get_num_devices routine returns the number of available target devices. When 4
called from within a target region the eﬀect of this routine is unspeciﬁed. 5
Cross References 6
target construct, see Section 2.12.5 on page 170 7
omp_get_default_device , see Section 3.2.35 on page 370. 8
omp_get_device_num , see Section 3.2.37 on page 372. 9
3.2.37 omp_get_device_num 10
Summary 11
Theomp_get_device_num routine returns the device number of the device on which the 12
calling thread is executing. 13
Format 14
C / C++
int omp_get_device_num(void); 15
C / C++
Fortran
integer function omp_get_device_num() 16
Fortran
Binding 17
The binding task set for an omp_get_devices_num region is the generating task. 18
Effect 19
Theomp_get_device_num routine returns the device number of the device on which the 20
calling thread is executing. When called on the host device, it will return the same value as the 21
omp_get_initial_device routine. 22
372 OpenMP API – Version 5.0 November 2018
Cross References 1
target construct, see Section 2.12.5 on page 170 2
omp_get_default_device , see Section 3.2.35 on page 370. 3
omp_get_num_devices , see Section 3.2.36 on page 371. 4
omp_get_initial_device routine, see Section 3.2.41 on page 376. 5
3.2.38 omp_get_num_teams 6
Summary 7
Theomp_get_num_teams routine returns the number of initial teams in the current teams 8
region. 9
Format 10
C / C++
int omp_get_num_teams(void); 11
C / C++
Fortran
integer function omp_get_num_teams() 12
Fortran
Binding 13
The binding task set for an omp_get_num_teams region is the generating task 14
Effect 15
The eﬀect of this routine is to return the number of initial teams in the current teamsregion. The 16
routine returns 1 if it is called from outside of a teamsregion. 17
Cross References 18
teamsconstruct, see Section 2.7 on page 82. 19
target construct, see Section 2.12.5 on page 170. 20
omp_get_team_num routine, see Section 3.2.39 on page 374. 21
CHAPTER 3. RUNTIME LIBRARY ROUTINES 373
3.2.39 omp_get_team_num 1
Summary 2
Theomp_get_team_num routine returns the initial team number of the calling thread. 3
Format 4
C / C++
int omp_get_team_num(void); 5
C / C++
Fortran
integer function omp_get_team_num() 6
Fortran
Binding 7
The binding task set for an omp_get_team_num region is the generating task. 8
Effect 9
Theomp_get_team_num routine returns the initial team number of the calling thread. The 10
initial team number is an integer between 0 and one less than the value returned by 11
omp_get_num_teams() , inclusive. The routine returns 0 if it is called outside of a teams 12
region. 13
Cross References 14
teamsconstruct, see Section 2.7 on page 82. 15
target construct, see Section 2.12.5 on page 170 16
omp_get_num_teams routine, see Section 3.2.38 on page 373. 17
374 OpenMP API – Version 5.0 November 2018
3.2.40 omp_is_initial_device 1
Summary 2
Theomp_is_initial_device routine returns trueif the current task is executing on the host 3
device; otherwise, it returns false. 4
Format 5
C / C++
int omp_is_initial_device(void); 6
C / C++
Fortran
logical function omp_is_initial_device() 7
Fortran
Binding 8
The binding task set for an omp_is_initial_device region is the generating task. 9
Effect 10
The eﬀect of this routine is to return trueif the current task is executing on the host device; 11
otherwise, it returns false. 12
Cross References 13
omp_get_get_initial_device routine, see Section 3.2.41 on page 376. 14
Device memory routines, see Section 3.6 on page 397. 15
CHAPTER 3. RUNTIME LIBRARY ROUTINES 375
3.2.41 omp_get_initial_device 1
Summary 2
Theomp_get_initial_device routine returns a device number that represents the host 3
device. 4
Format 5
C / C++
int omp_get_initial_device(void); 6
C / C++
Fortran
integer function omp_get_initial_device() 7
Fortran
Binding 8
The binding task set for an omp_get_initial_device region is the generating task. 9
Effect 10
The eﬀect of this routine is to return the device number of the host device. The value of the device 11
number is implementation deﬁned. When called from within a target region the eﬀect of this 12
routine is unspeciﬁed. 13
Cross References 14
target construct, see Section 2.12.5 on page 170. 15
omp_is_initial_device routine, see Section 3.2.40 on page 375. 16
Device memory routines, see Section 3.6 on page 397. 17
376 OpenMP API – Version 5.0 November 2018
3.2.42 omp_get_max_task_priority 1
Summary 2
Theomp_get_max_task_priority routine returns the maximum value that can be speciﬁed 3
in the priority clause. 4
Format 5
C / C++
int omp_get_max_task_priority(void); 6
C / C++
Fortran
integer function omp_get_max_task_priority() 7
Fortran
Binding 8
The binding thread set for an omp_get_max_task_priority region is all threads on the 9
device. The eﬀect of executing this routine is not related to any speciﬁc region that corresponds to 10
any construct or API routine. 11
Effect 12
Theomp_get_max_task_priority routine returns the value of the max-task-priority-var 13
ICV, which determines the maximum value that can be speciﬁed in the priority clause. 14
Cross References 15
max-task-priority-var , see Section 2.5 on page 63. 16
taskconstruct, see Section 2.10.1 on page 135. 17
CHAPTER 3. RUNTIME LIBRARY ROUTINES 377
3.2.43 omp_pause_resource 1
Summary 2
Theomp_pause_resource routineallowstheruntimetorelinquishresourcesusedbyOpenMP 3
on the speciﬁed device. 4
Format 5
C / C++
int omp_pause_resource( 6
omp_pause_resource_t kind, 7
int device_num 8
); 9
C / C++
Fortran
integer function omp_pause_resource(kind, device_num) 10
integer (kind=omp_pause_resource_kind) kind 11
integer device_num 12
Fortran
Constraints on Arguments 13
The ﬁrst argument passed to this routine can be one of the valid OpenMP pause kind, or any 14
implementation speciﬁc pause kind. The C/C++ header ﬁle ( omp.h) and the Fortran include ﬁle 15
(omp_lib.h ) and/or Fortran 90 module ﬁle ( omp_lib ) deﬁne the valid constants. The valid 16
constants must include the following, which can be extended with implementation speciﬁc values: 17
Format 18
C / C++
typedef enum omp_pause_resource_t { 19
omp_pause_soft = 1, 20
omp_pause_hard = 2 21
} omp_pause_resource_t; 22
C / C++
Fortran
integer (kind=omp_pause_resource_kind), parameter :: & 23
omp_pause_soft = 1 24
integer (kind=omp_pause_resource_kind), parameter :: & 25
omp_pause_hard = 2 26
Fortran
378 OpenMP API – Version 5.0 November 2018
The second argument passed to this routine indicates the device that will be paused. The 1
device_num parameter must be greater than or equal to zero and less than the result of 2
omp_get_num_devices() or equal to the result of a call to 3
omp_get_initial_device() . 4
Binding 5
The binding task set for an omp_pause_resource region is the whole program. 6
Effect 7
Theomp_pause_resource routineallowstheruntimetorelinquishresourcesusedbyOpenMP 8
on the speciﬁed device. 9
If successful, the omp_pause_hard value results in a hard pause for which the OpenMP state is 10
not guaranteed to persist across the omp_pause_resource call. A hard pause may relinquish 11
any data allocated by OpenMP on a given device, including data allocated by memory routines for 12
that device as well as data present on the device as a result of a declare target ortarget 13
dataconstruct. A hard pause may also relinquish any data associated with a threadprivate 14
directive. When relinquished and when applicable, base language appropriate 15
deallocation/ﬁnalization is performed. When relinquished and when applicable, mapped data on a 16
device will not be copied back from the device to the host. 17
If successful, the omp_pause_soft value results in a soft pause for which the OpenMP state is 18
guaranteed to persist across the call, with the exception of any data associated with a 19
threadprivate directive, which may be relinquished across the call. When relinquished and 20
when applicable, base language appropriate deallocation/ﬁnalization is performed. 21
22
Note– A hard pause may relinquish more resources, but may resume processing OpenMP regions 23
moreslowly. AsoftpauseallowsOpenMPregionstorestartmorequickly,butmayrelinquishfewer 24
resources. An OpenMP implementation will reclaim resources as needed for OpenMP regions 25
encounteredafterthe omp_pause_resource region. Sinceahardpausemayunmapdataonthe 26
speciﬁed device, appropriate data mapping is required before using data on the speciﬁed device 27
after the omp_pause_region region. 28
29
The routine returns zero in case of success, and nonzero otherwise. 30
Tool Callbacks 31
If the tool is not allowed to interact with the speciﬁed device after encountering this call, then the 32
runtime must call the tool ﬁnalizer for that device. 33
CHAPTER 3. RUNTIME LIBRARY ROUTINES 379
Restrictions 1
Theomp_pause_resource routine has the following restrictions: 2
Theomp_pause_resource region may not be nested in any explicit OpenMP region. 3
The routine may only be called when all explicit tasks have ﬁnalized execution. Calling the 4
routine in any other circumstances may result in unspeciﬁed behavior. 5
Cross References 6
target construct, see Section 2.12.5 on page 170 7
declare target directive, see Section 2.12.7 on page 180 8
threadprivate directives, see Section 2.19.2 on page 274. 9
omp_get_num_devices , see Section 3.2.36 on page 371. 10
omp_get_get_initial_device routine, see Section 3.2.41 on page 376. 11
To pause resources on all devices at once, see Section 3.2.44 on page 380. 12
3.2.44 omp_pause_resource_all 13
Summary 14
Theomp_pause_resource_all routine allows the runtime to relinquish resources used by 15
OpenMP on all devices. 16
Format 17
C / C++
int omp_pause_resource_all(omp_pause_resource_t kind); 18
C / C++
Fortran
integer function omp_pause_resource_all(kind) 19
integer (kind=omp_pause_resource_kind) kind 20
Fortran
Binding 21
The binding task set for an omp_pause_resource_all region is the whole program. 22
380 OpenMP API – Version 5.0 November 2018
Effect 1
Theomp_pause_resource_all routine allows the runtime to relinquish resources used by 2
OpenMP on all devices. It is equivalent to calling the omp_pause_resource routine once for 3
each available device, including the host device. 4
Theargument kindpassedtothisroutinecanbeoneofthevalidOpenMPpausekindasdeﬁnedin 5
Section 3.2.43 on page 378, or any implementation speciﬁc pause kind. 6
Tool Callbacks 7
If the tool is not allowed to interact with a given device after encountering this call, then the 8
runtime must call the tool ﬁnalizer for that device. 9
Restrictions 10
Theomp_pause_resource_all routine has the following restrictions: 11
Theomp_pause_resource_all region may not be nested in any explicit OpenMP region. 12
The routine may only be called when all explicit tasks have ﬁnalized execution. Calling the 13
routine in any other circumstances may result in unspeciﬁed behavior. 14
Cross References 15
target construct, see Section 2.12.5 on page 170 16
declare target directive, see Section 2.12.7 on page 180 17
omp_get_num_devices , see Section 3.2.36 on page 371. 18
omp_get_get_initial_device routine, see Section 3.2.41 on page 376. 19
To pause resources on a speciﬁc device only, see Section 3.2.43 on page 378. 20
3.3 Lock Routines 21
The OpenMP runtime library includes a set of general-purpose lock routines that can be used for 22
synchronization. These general-purpose lock routines operate on OpenMP locks that are 23
represented by OpenMP lock variables. OpenMP lock variables must be accessed only through the 24
routines described in this section; programs that otherwise access OpenMP lock variables are 25
non-conforming. 26
CHAPTER 3. RUNTIME LIBRARY ROUTINES 381
An OpenMP lock can be in one of the following states: uninitialized ;unlocked; orlocked. If a lock 1
is in theunlocked state, a task can setthe lock, which changes its state to locked. The task that sets 2
the lock is then said to ownthe lock. A task that owns a lock can unsetthat lock, returning it to the 3
unlocked state. A program in which a task unsets a lock that is owned by another task is 4
non-conforming. 5
Two types of locks are supported: simple locks andnestable locks . Anestable lock can be set 6
multiple times by the same task before being unset; a simple lock cannot be set if it is already 7
owned by the task trying to set it. Simple lock variables are associated with simple locks and can 8
only be passed to simple lock routines. Nestable lock variables are associated with nestable locks 9
and can only be passed to nestable lock routines. 10
Each type of lock can also have a synchronization hint that contains information about the intended 11
usage of the lock by the application code. The eﬀect of the hint is implementation deﬁned. An 12
OpenMP implementation can use this hint to select a usage-speciﬁc lock, but hints do not change 13
the mutual exclusion semantics of locks. A conforming implementation can safely ignore the hint. 14
Constraints on the state and ownership of the lock accessed by each of the lock routines are 15
described with the routine. If these constraints are not met, the behavior of the routine is 16
unspeciﬁed. 17
The OpenMP lock routines access a lock variable such that they always read and update the most 18
current value of the lock variable. It is not necessary for an OpenMP program to include explicit 19
flushdirectives to ensure that the lock variable’s value is consistent among diﬀerent tasks. 20
Binding 21
The binding thread set for all lock routine regions is all threads in the contention group. As a 22
consequence,foreachOpenMPlock,thelockroutineeﬀectsrelatetoalltasksthatcalltheroutines, 23
without regard to which teams the threads in the contention group that are executing the tasks 24
belong. 25
Simple Lock Routines 26
C / C++
Thetype omp_lock_t representsasimplelock. Forthefollowingroutines,asimplelockvariable 27
must be of omp_lock_t type. All simple lock routines require an argument that is a pointer to a 28
variable of type omp_lock_t . 29
C / C++
Fortran
For the following routines, a simple lock variable must be an integer variable of 30
kind=omp_lock_kind . 31
Fortran
382 OpenMP API – Version 5.0 November 2018
The simple lock routines are as follows: 1
Theomp_init_lock routine initializes a simple lock; 2
Theomp_init_lock_with_hint routine initializes a simple lock and attaches a hint to it; 3
Theomp_destroy_lock routine uninitializes a simple lock; 4
Theomp_set_lock routine waits until a simple lock is available and then sets it; 5
Theomp_unset_lock routine unsets a simple lock; and 6
Theomp_test_lock routine tests a simple lock and sets it if it is available. 7
Nestable Lock Routines 8
C / C++
The type omp_nest_lock_t represents a nestable lock. For the following routines, a nestable 9
lock variable must be of omp_nest_lock_t type. All nestable lock routines require an 10
argument that is a pointer to a variable of type omp_nest_lock_t . 11
C / C++
Fortran
For the following routines, a nestable lock variable must be an integer variable of 12
kind=omp_nest_lock_kind . 13
Fortran
The nestable lock routines are as follows: 14
Theomp_init_nest_lock routine initializes a nestable lock; 15
Theomp_init_nest_lock_with_hint routine initializes a nestable lock and attaches a 16
hint to it; 17
Theomp_destroy_nest_lock routine uninitializes a nestable lock; 18
Theomp_set_nest_lock routine waits until a nestable lock is available and then sets it; 19
Theomp_unset_nest_lock routine unsets a nestable lock; and 20
Theomp_test_nest_lock routine tests a nestable lock and sets it if it is available. 21
Restrictions 22
OpenMP lock routines have the following restriction: 23
The use of the same OpenMP lock in diﬀerent contention groups results in unspeciﬁed behavior. 24
CHAPTER 3. RUNTIME LIBRARY ROUTINES 383
3.3.1 omp_init_lock andomp_init_nest_lock 1
Summary 2
These routines initialize an OpenMP lock without a hint. 3
Format 4
C / C++
void omp_init_lock(omp_lock_t *lock); 5
void omp_init_nest_lock(omp_nest_lock_t *lock); 6
C / C++
Fortran
subroutine omp_init_lock( svar) 7
integer (kind=omp_lock_kind) svar 8
9
subroutine omp_init_nest_lock( nvar) 10
integer (kind=omp_nest_lock_kind) nvar 11
Fortran
Constraints on Arguments 12
A program that accesses a lock that is not in the uninitialized state through either routine is 13
non-conforming. 14
Effect 15
The eﬀect of these routines is to initialize the lock to the unlocked state; that is, no task owns the 16
lock. In addition, the nesting count for a nestable lock is set to zero. 17
Execution Model Events 18
Thelock-initevent occurs in a thread that executes an omp_init_lock region after initialization 19
ofthelock,butbeforeitﬁnishestheregion. The nest-lock-init eventoccursinathreadthatexecutes 20
anomp_init_nest_lock regionafterinitializationofthelock,butbeforeitﬁnishestheregion. 21
384 OpenMP API – Version 5.0 November 2018
Tool Callbacks 1
A thread dispatches a registered ompt_callback_lock_init callback with 2
omp_sync_hint_none as thehintargument and ompt_mutex_lock as thekindargument 3
for each occurrence of a lock-initevent in that thread. Similarly, a thread dispatches a registered 4
ompt_callback_lock_init callback with omp_sync_hint_none as thehintargument 5
andompt_mutex_nest_lock as thekindargument for each occurrence of a nest-lock-init 6
event in that thread. These callbacks have the type signature 7
ompt_callback_mutex_acquire_t and occur in the task that encounters the routine. 8
Cross References 9
ompt_callback_mutex_acquire_t , see Section 4.5.2.14 on page 476. 10
3.3.2 omp_init_lock_with_hint and 11
omp_init_nest_lock_with_hint 12
Summary 13
These routines initialize an OpenMP lock with a hint. The eﬀect of the hint is 14
implementation-deﬁned. The OpenMP implementation can ignore the hint without changing 15
program semantics. 16
Format 17
C / C++
void omp_init_lock_with_hint( 18
omp_lock_t *lock, 19
omp_sync_hint_t hint 20
); 21
void omp_init_nest_lock_with_hint( 22
omp_nest_lock_t *lock, 23
omp_sync_hint_t hint 24
); 25
C / C++
CHAPTER 3. RUNTIME LIBRARY ROUTINES 385
Fortran
subroutine omp_init_lock_with_hint( svar,hint) 1
integer (kind=omp_lock_kind) svar 2
integer (kind=omp_sync_hint_kind) hint 3
4
subroutine omp_init_nest_lock_with_hint( nvar,hint) 5
integer (kind=omp_nest_lock_kind) nvar 6
integer (kind=omp_sync_hint_kind) hint 7
Fortran
Constraints on Arguments 8
A program that accesses a lock that is not in the uninitialized state through either routine is 9
non-conforming. 10
The second argument passed to these routines ( hint) is a hint as described in Section 2.17.12 on 11
page 260. 12
Effect 13
The eﬀect of these routines is to initialize the lock to the unlocked state and, optionally, to choose a 14
speciﬁc lock implementation based on the hint. After initialization no task owns the lock. In 15
addition, the nesting count for a nestable lock is set to zero. 16
Execution Model Events 17
Thelock-initevent occurs in a thread that executes an omp_init_lock_with_hint region 18
after initialization of the lock, but before it ﬁnishes the region. The nest-lock-init_with_hint event 19
occurs in a thread that executes an omp_init_nest_lock region after initialization of the lock, 20
but before it ﬁnishes the region. 21
Tool Callbacks 22
A thread dispatches a registered ompt_callback_lock_init callback with the same value 23
for itshintargument as the hintargument of the call to omp_init_lock_with_hint and 24
ompt_mutex_lock as thekindargument for each occurrence of a lock-initevent in that thread. 25
Similarly, a thread dispatches a registered ompt_callback_lock_init callback with the 26
same value for its hintargument as the hintargument of the call to 27
omp_init_nest_lock_with_hint andompt_mutex_nest_lock as thekindargument 28
for each occurrence of a nest-lock-init event in that thread. These callbacks have the type signature 29
ompt_callback_mutex_acquire_t and occur in the task that encounters the routine. 30
386 OpenMP API – Version 5.0 November 2018
Cross References 1
Synchronization Hints, see Section 2.17.12 on page 260. 2
ompt_callback_mutex_acquire_t , see Section 4.5.2.14 on page 476. 3
3.3.3 omp_destroy_lock and 4
omp_destroy_nest_lock 5
Summary 6
These routines ensure that the OpenMP lock is uninitialized. 7
Format 8
C / C++
void omp_destroy_lock(omp_lock_t *lock); 9
void omp_destroy_nest_lock(omp_nest_lock_t *lock); 10
C / C++
Fortran
subroutine omp_destroy_lock( svar) 11
integer (kind=omp_lock_kind) svar 12
13
subroutine omp_destroy_nest_lock( nvar) 14
integer (kind=omp_nest_lock_kind) nvar 15
Fortran
Constraints on Arguments 16
A program that accesses a lock that is not in the unlocked state through either routine is 17
non-conforming. 18
Effect 19
The eﬀect of these routines is to change the state of the lock to uninitialized. 20
Execution Model Events 21
Thelock-destroy event occurs in a thread that executes an omp_destroy_lock region before it 22
ﬁnishes the region. The nest-lock-destroy_with_hint event occurs in a thread that executes an 23
omp_destroy_nest_lock region before it ﬁnishes the region. 24
CHAPTER 3. RUNTIME LIBRARY ROUTINES 387
Tool Callbacks 1
A thread dispatches a registered ompt_callback_lock_destroy callback with 2
ompt_mutex_lock as thekindargument for each occurrence of a lock-destroy event in that 3
thread. Similarly, a thread dispatches a registered ompt_callback_lock_destroy callback 4
withompt_mutex_nest_lock as thekindargument for each occurrence of a nest-lock-destroy 5
event in that thread. These callbacks have the type signature 6
ompt_callback_mutex_acquire_t and occur in the task that encounters the routine. 7
Cross References 8
ompt_callback_mutex_t , see Section 4.5.2.15 on page 477. 9
3.3.4 omp_set_lock andomp_set_nest_lock 10
Summary 11
These routines provide a means of setting an OpenMP lock. The calling task region behaves as if it 12
was suspended until the lock can be set by this task. 13
Format 14
C / C++
void omp_set_lock(omp_lock_t *lock); 15
void omp_set_nest_lock(omp_nest_lock_t *lock); 16
C / C++
Fortran
subroutine omp_set_lock( svar) 17
integer (kind=omp_lock_kind) svar 18
19
subroutine omp_set_nest_lock( nvar) 20
integer (kind=omp_nest_lock_kind) nvar 21
Fortran
Constraints on Arguments 22
A program that accesses a lock that is in the uninitialized state through either routine is 23
non-conforming. A simple lock accessed by omp_set_lock that is in the locked state must not 24
be owned by the task that contains the call or deadlock will result. 25
388 OpenMP API – Version 5.0 November 2018
Effect 1
Eachoftheseroutineshasaneﬀectequivalenttosuspensionofthetaskthatisexecutingtheroutine 2
until the speciﬁed lock is available. 3
4
Note– The semantics of these routines is speciﬁed as ifthey serialize execution of the region 5
guarded by the lock. However, implementations may implement them in other ways provided that 6
the isolation properties are respected so that the actual execution delivers a result that could arise 7
from some serialization. 8
9
A simple lock is available if it is unlocked. Ownership of the lock is granted to the task that 10
executes the routine. 11
A nestable lock is available if it is unlocked or if it is already owned by the task that executes the 12
routine. The task that executes the routine is granted, or retains, ownership of the lock, and the 13
nesting count for the lock is incremented. 14
Execution Model Events 15
Thelock-acquire event occurs in a thread that executes an omp_set_lock region before the 16
associated lock is requested. The nest-lock-acquire event occurs in a thread that executes an 17
omp_set_nest_lock region before the associated lock is requested. 18
Thelock-acquired event occurs in a thread that executes an omp_set_lock region after it 19
acquirestheassociatedlockbutbeforeitﬁnishestheregion. The nest-lock-acquired eventoccursin 20
a thread that executes an omp_set_nest_lock region if the thread did not already own the 21
lock, after it acquires the associated lock but before it ﬁnishes the region. 22
Thenest-lock-owned event occurs in a thread when it already owns the lock and executes an 23
omp_set_nest_lock region. The event occurs after the nesting count is incremented but 24
before the thread ﬁnishes the region. 25
Tool Callbacks 26
A thread dispatches a registered ompt_callback_mutex_acquire callback for each 27
occurrence of a lock-acquire ornest-lock-acquire event in that thread. This callback has the type 28
signature ompt_callback_mutex_acquire_t . 29
A thread dispatches a registered ompt_callback_mutex_acquired callback for each 30
occurrence of a lock-acquired ornest-lock-acquired event in that thread. This callback has the type 31
signature ompt_callback_mutex_t . 32
A thread dispatches a registered ompt_callback_nest_lock callback with 33
ompt_scope_begin as itsendpoint argument for each occurrence of a nest-lock-owned event in 34
that thread. This callback has the type signature ompt_callback_nest_lock_t . 35
CHAPTER 3. RUNTIME LIBRARY ROUTINES 389
Theabovecallbacksoccurinthetaskthatencountersthelockfunction. The kindargumentofthese 1
callbacks is ompt_mutex_lock when the events arise from an omp_set_lock region while it 2
isompt_mutex_nest_lock when the events arise from an omp_set_nest_lock region. 3
Cross References 4
ompt_callback_mutex_acquire_t , see Section 4.5.2.14 on page 476. 5
ompt_callback_mutex_t , see Section 4.5.2.15 on page 477. 6
ompt_callback_nest_lock_t , see Section 4.5.2.16 on page 479. 7
3.3.5 omp_unset_lock andomp_unset_nest_lock 8
Summary 9
These routines provide the means of unsetting an OpenMP lock. 10
Format 11
C / C++
void omp_unset_lock(omp_lock_t *lock); 12
void omp_unset_nest_lock(omp_nest_lock_t *lock); 13
C / C++
Fortran
subroutine omp_unset_lock( svar) 14
integer (kind=omp_lock_kind) svar 15
16
subroutine omp_unset_nest_lock( nvar) 17
integer (kind=omp_nest_lock_kind) nvar 18
Fortran
Constraints on Arguments 19
A program that accesses a lock that is not in the locked state or that is not owned by the task that 20
contains the call through either routine is non-conforming. 21
390 OpenMP API – Version 5.0 November 2018
Effect 1
For a simple lock, the omp_unset_lock routine causes the lock to become unlocked. 2
For a nestable lock, the omp_unset_nest_lock routine decrements the nesting count, and 3
causes the lock to become unlocked if the resulting nesting count is zero. 4
For either routine, if the lock becomes unlocked, and if one or more task regions were eﬀectively 5
suspended because the lock was unavailable, the eﬀect is that one task is chosen and given 6
ownership of the lock. 7
Execution Model Events 8
Thelock-release event occurs in a thread that executes an omp_unset_lock region after it 9
releases the associated lock but before it ﬁnishes the region. The nest-lock-release event occurs in a 10
thread that executes an omp_unset_nest_lock region after it releases the associated lock but 11
before it ﬁnishes the region. 12
Thenest-lock-held event occurs in a thread that executes an omp_unset_nest_lock region 13
before it ﬁnishes the region when the thread still owns the lock after the nesting count is 14
decremented. 15
Tool Callbacks 16
A thread dispatches a registered ompt_callback_mutex_released callback with 17
ompt_mutex_lock as thekindargument for each occurrence of a lock-release event in that 18
thread. Similarly, a thread dispatches a registered ompt_callback_mutex_released 19
callback with ompt_mutex_nest_lock as thekindargument for each occurrence of a 20
nest-lock-release event in that thread. These callbacks have the type signature 21
ompt_callback_mutex_t and occur in the task that encounters the routine. 22
A thread dispatches a registered ompt_callback_nest_lock callback with 23
ompt_scope_end as itsendpoint argument for each occurrence of a nest-lock-held event in that 24
thread. This callback has the type signature ompt_callback_nest_lock_t . 25
Cross References 26
ompt_callback_mutex_t , see Section 4.5.2.15 on page 477. 27
ompt_callback_nest_lock_t , see Section 4.5.2.16 on page 479. 28
CHAPTER 3. RUNTIME LIBRARY ROUTINES 391
3.3.6 omp_test_lock andomp_test_nest_lock 1
Summary 2
These routines attempt to set an OpenMP lock but do not suspend execution of the task that 3
executes the routine. 4
Format 5
C / C++
int omp_test_lock(omp_lock_t *lock); 6
int omp_test_nest_lock(omp_nest_lock_t *lock); 7
C / C++
Fortran
logical function omp_test_lock( svar) 8
integer (kind=omp_lock_kind) svar 9
integer function omp_test_nest_lock( nvar) 10
integer (kind=omp_nest_lock_kind) nvar 11
Fortran
Constraints on Arguments 12
A program that accesses a lock that is in the uninitialized state through either routine is 13
non-conforming. The behavior is unspeciﬁed if a simple lock accessed by omp_test_lock is in 14
the locked state and is owned by the task that contains the call. 15
Effect 16
These routines attempt to set a lock in the same manner as omp_set_lock and 17
omp_set_nest_lock , except that they do not suspend execution of the task that executes the 18
routine. 19
For a simple lock, the omp_test_lock routine returns trueif the lock is successfully set; 20
otherwise, it returns false. 21
For a nestable lock, the omp_test_nest_lock routine returns the new nesting count if the lock 22
is successfully set; otherwise, it returns zero. 23
392 OpenMP API – Version 5.0 November 2018
Execution Model Events 1
Thelock-testevent occurs in a thread that executes an omp_test_lock region before the 2
associated lock is tested. The nest-lock-test event occurs in a thread that executes an 3
omp_test_nest_lock region before the associated lock is tested. 4
Thelock-test-acquired event occurs in a thread that executes an omp_test_lock region before it 5
ﬁnishestheregioniftheassociatedlockwasacquired. The nest-lock-test-acquired eventoccursina 6
thread that executes an omp_test_nest_lock region before it ﬁnishes the region if the 7
associated lock was acquired and the thread did not already own the lock. 8
Thenest-lock-owned event occurs in a thread that executes an omp_test_nest_lock region 9
before it ﬁnishes the region after the nesting count is incremented if the thread already owned the 10
lock. 11
Tool Callbacks 12
A thread dispatches a registered ompt_callback_mutex_acquire callback for each 13
occurrence of a lock-testornest-lock-test event in that thread. This callback has the type signature 14
ompt_callback_mutex_acquire_t . 15
A thread dispatches a registered ompt_callback_mutex_acquired callback for each 16
occurrence of a lock-test-acquired ornest-lock-test-acquired event in that thread. This callback has 17
the type signature ompt_callback_mutex_t . 18
A thread dispatches a registered ompt_callback_nest_lock callback with 19
ompt_scope_begin as itsendpoint argument for each occurrence of a nest-lock-owned event in 20
that thread. This callback has the type signature ompt_callback_nest_lock_t . 21
Theabovecallbacksoccurinthetaskthatencountersthelockfunction. The kindargumentofthese 22
callbacks is ompt_mutex_test_lock when the events arise from an omp_test_lock 23
region while it is ompt_mutex_test_nest_lock when the events arise from an 24
omp_test_nest_lock region. 25
Cross References 26
ompt_callback_mutex_acquire_t , see Section 4.5.2.14 on page 476. 27
ompt_callback_mutex_t , see Section 4.5.2.15 on page 477. 28
ompt_callback_nest_lock_t , see Section 4.5.2.16 on page 479. 29
CHAPTER 3. RUNTIME LIBRARY ROUTINES 393
3.4 Timing Routines1
This section describes routines that support a portable wall clock timer. 2
3.4.1 omp_get_wtime 3
Summary 4
Theomp_get_wtime routine returns elapsed wall clock time in seconds. 5
Format 6
C / C++
double omp_get_wtime(void); 7
C / C++
Fortran
double precision function omp_get_wtime() 8
Fortran
Binding 9
The binding thread set for an omp_get_wtime region is the encountering thread. The routine’s 10
return value is not guaranteed to be consistent across any set of threads. 11
Effect 12
Theomp_get_wtime routine returns a value equal to the elapsed wall clock time in seconds 13
since some time-in-the-past . The actual time-in-the-past is arbitrary, but it is guaranteed not to 14
change during the execution of the application program. The time returned is a per-thread time , so 15
it is not required to be globally consistent across all threads that participate in an application. 16
17
Note– The routine is anticipated to be used to measure elapsed times as shown in the following 18
example: 19
394 OpenMP API – Version 5.0 November 2018
C / C++
double start; 1
double end; 2
start = omp_get_wtime(); 3
... work to be timed ... 4
end = omp_get_wtime(); 5
printf("Work took %f seconds\n", end - start); 6
C / C++
Fortran
DOUBLE PRECISION START, END 7
START = omp_get_wtime() 8
... work to be timed ... 9
END = omp_get_wtime() 10
PRINT *, "Work took", END - START, "seconds" 11
Fortran
12
3.4.2 omp_get_wtick 13
Summary 14
Theomp_get_wtick routine returns the precision of the timer used by omp_get_wtime . 15
Format 16
C / C++
double omp_get_wtick(void); 17
C / C++
Fortran
double precision function omp_get_wtick() 18
Fortran
Binding 19
The binding thread set for an omp_get_wtick region is the encountering thread. The routine’s 20
return value is not guaranteed to be consistent across any set of threads. 21
CHAPTER 3. RUNTIME LIBRARY ROUTINES 395
Effect 1
Theomp_get_wtick routine returns a value equal to the number of seconds between successive 2
clock ticks of the timer used by omp_get_wtime . 3
3.5 Event Routine4
This section describes a routine that supports OpenMP event objects. 5
Binding 6
The binding thread set for all event routine regions is the encountering thread. 7
3.5.1 omp_fulfill_event 8
Summary 9
This routine fulﬁlls and destroys an OpenMP event. 10
Format 11
C / C++
void omp_fulfill_event(omp_event_handle_t event); 12
C / C++
Fortran
subroutine omp_fulfill_event(event) 13
integer (kind=omp_event_handle_kind) event 14
Fortran
Constraints on Arguments 15
A program that calls this routine on an event that was already fulﬁlled is non-conforming. A 16
program that calls this routine with an event handle that was not created by the detach clause is 17
non-conforming. 18
396 OpenMP API – Version 5.0 November 2018
Effect 1
Theeﬀectofthisroutineistofulﬁlltheeventassociatedwiththeeventhandleargument. Theeﬀect 2
of fulﬁlling the event will depend on how the event was created. The event is destroyed and cannot 3
be accessed after calling this routine, and the event handle becomes unassociated with any event. 4
Execution Model Events 5
Thetask-fulﬁll event occurs in a thread that executes an omp_fulfill_event region before the 6
event is fulﬁlled if the OpenMP event object was created by a detach clause on a task. 7
Tool Callbacks 8
A thread dispatches a registered ompt_callback_task_schedule callback with NULLas its 9
next_task_data argument while the argument prior_task_data binds to the detached task for each 10
occurrenceofa task-fulﬁll event. Ifthe task-fulﬁll eventoccursbeforethedetachedtaskﬁnishedthe 11
execution of the associated structured-block , the callback has ompt_task_early_fulfill as 12
itsprior_task_status argument; otherwise the callback has ompt_task_late_fulfill as its 13
prior_task_status argument. This callback has type signature 14
ompt_callback_task_schedule_t . 15
Cross References 16
detach clause, see Section 2.10.1 on page 135. 17
ompt_callback_task_schedule_t , see Section 4.5.2.10 on page 470. 18
C / C++
3.6 Device Memory Routines 19
This section describes routines that support allocation of memory and management of pointers in 20
the data environments of target devices. 21
3.6.1 omp_target_alloc 22
Summary 23
Theomp_target_alloc routine allocates memory in a device data environment. 24
CHAPTER 3. RUNTIME LIBRARY ROUTINES 397
C/C++ (cont.)
Format 1
void *omp_target_alloc(size_t size, intdevice_num ); 2
Effect 3
Theomp_target_alloc routine returns the device address of a storage location of sizebytes. 4
Thestoragelocationisdynamicallyallocatedinthedevicedataenvironmentofthedevicespeciﬁed 5
bydevice_num , which must be greater than or equal to zero and less than the result of 6
omp_get_num_devices() or the result of a call to omp_get_initial_device() . When 7
called from within a target region the eﬀect of this routine is unspeciﬁed. 8
Theomp_target_alloc routine returns NULLif it cannot dynamically allocate the memory in 9
the device data environment. 10
The device address returned by omp_target_alloc can be used in an is_device_ptr 11
clause, Section 2.12.5 on page 170. 12
Unless unified_address clause appears on a requires directive in the compilation unit, 13
pointer arithmetic is not supported on the device address returned by omp_target_alloc . 14
Freeing the storage returned by omp_target_alloc with any routine other than 15
omp_target_free results in unspeciﬁed behavior. 16
Execution Model Events 17
Thetarget-data-allocation event occurs when a thread allocates data on a target device. 18
Tool Callbacks 19
A thread invokes a registered ompt_callback_target_data_op callback for each 20
occurrenceofa target-data-allocation eventinthatthread. Thecallbackoccursinthecontextofthe 21
target task and has type signature ompt_callback_target_data_op_t . 22
Cross References 23
target construct, see Section 2.12.5 on page 170 24
omp_get_num_devices routine, see Section 3.2.36 on page 371 25
omp_get_initial_device routine, see Section 3.2.41 on page 376 26
omp_target_free routine, see Section 3.6.2 on page 399 27
ompt_callback_target_data_op_t , see Section 4.5.2.25 on page 488. 28
398OpenMP API – Version 5.0 November 2018
C/C++ (cont.)
3.6.2 omp_target_free 1
Summary 2
Theomp_target_free routine frees the device memory allocated by the 3
omp_target_alloc routine. 4
Format 5
void omp_target_free(void *device_ptr , intdevice_num ); 6
Constraints on Arguments 7
A program that calls omp_target_free with a non-null pointer that does not have a value 8
returned from omp_target_alloc is non-conforming. The device_num must be greater than or 9
equal to zero and less than the result of omp_get_num_devices() or the result of a call to 10
omp_get_initial_device() . 11
Effect 12
Theomp_target_free routine frees the memory in the device data environment associated 13
withdevice_ptr . Ifdevice_ptr isNULL, the operation is ignored. 14
Synchronization must be inserted to ensure that all accesses to device_ptr are completed before the 15
call to omp_target_free . 16
When called from within a target region the eﬀect of this routine is unspeciﬁed. 17
Execution Model Events 18
Thetarget-data-free event occurs when a thread frees data on a target device. 19
Tool Callbacks 20
A thread invokes a registered ompt_callback_target_data_op callback for each 21
occurrenceofa target-data-free eventinthatthread. Thecallbackoccursinthecontextofthetarget 22
task and has type signature ompt_callback_target_data_op_t . 23
Cross References 24
target construct, see Section 2.12.5 on page 170 25
omp_get_num_devices routine, see Section 3.2.36 on page 371 26
omp_get_initial_device routine, see Section 3.2.41 on page 376 27
omp_target_alloc routine, see Section 3.6.1 on page 397 28
ompt_callback_target_data_op_t , see Section 4.5.2.25 on page 488. 29
CHAPTER 3. RUNTIME LIBRARY ROUTINES 399
C/C++ (cont.)
3.6.3 omp_target_is_present 1
Summary 2
Theomp_target_is_present routine tests whether a host pointer has corresponding storage 3
on a given device. 4
Format 5
int omp_target_is_present(const void *ptr, intdevice_num ); 6
Constraints on Arguments 7
The value of ptrmust be a valid host pointer or NULL. Thedevice_num must be greater than or 8
equal to zero and less than the result of omp_get_num_devices() or the result of a call to 9
omp_get_initial_device() . 10
Effect 11
This routine returns non-zero if the speciﬁed pointer would be found present on device device_num 12
by amapclause; otherwise, it returns zero. 13
When called from within a target region the eﬀect of this routine is unspeciﬁed. 14
Cross References 15
target construct, see Section 2.12.5 on page 170. 16
mapclause, see Section 2.19.7.1 on page 315. 17
omp_get_num_devices routine, see Section 3.2.36 on page 371 18
omp_get_initial_device routine, see Section 3.2.41 on page 376 19
3.6.4 omp_target_memcpy 20
Summary 21
Theomp_target_memcpy routine copies memory between any combination of host and device 22
pointers. 23
400 OpenMP API – Version 5.0 November 2018
C/C++ (cont.)
Format 1
int omp_target_memcpy( 2
void *dst, 3
const void *src, 4
size_t length , 5
size_t dst_oﬀset , 6
size_t src_oﬀset , 7
intdst_device_num , 8
intsrc_device_num 9
); 10
Constraints on Arguments 11
Eachdevicemustbecompatiblewiththedevicepointerspeciﬁedonthesamesideofthecopy. The 12
dst_device_num andsrc_device_num must be greater than or equal to zero and less than the result 13
ofomp_get_num_devices() or equal to the result of a call to 14
omp_get_initial_device() . 15
Effect 16
lengthbytes of memory at oﬀset src_oﬀset fromsrcin the device data environment of device 17
src_device_num are copied to dststarting at oﬀset dst_oﬀset in the device data environment of 18
devicedst_device_num . The return value is zero on success and non-zero on failure. The host 19
device and host device data environment can be referenced with the device number returned by 20
omp_get_initial_device . This routine contains a task scheduling point. 21
When called from within a target region the eﬀect of this routine is unspeciﬁed. 22
Execution Model Events 23
Thetarget-data-op event occurs when a thread transfers data on a target device. 24
Tool Callbacks 25
A thread invokes a registered ompt_callback_target_data_op callback for each 26
occurrence of a target-data-op event in that thread. The callback occurs in the context of the target 27
task and has type signature ompt_callback_target_data_op_t . 28
Cross References 29
target construct, see Section 2.12.5 on page 170. 30
omp_get_initial_device routine, see Section 3.2.41 on page 376 31
omp_target_alloc routine, see Section 3.6.1 on page 397. 32
ompt_callback_target_data_op_t , see Section 4.5.2.25 on page 488. 33
CHAPTER 3. RUNTIME LIBRARY ROUTINES 401
C/C++ (cont.)
3.6.5 omp_target_memcpy_rect 1
Summary 2
Theomp_target_memcpy_rect routine copies a rectangular subvolume from a 3
multi-dimensionalarraytoanothermulti-dimensionalarray. Thecopiescanuseanycombinationof 4
host and device pointers. 5
Format 6
int omp_target_memcpy_rect( 7
void *dst, 8
const void *src, 9
size_t element_size , 10
intnum_dims , 11
const size_t *volume , 12
const size_t *dst_oﬀsets , 13
const size_t *src_oﬀsets , 14
const size_t *dst_dimensions , 15
const size_t *src_dimensions , 16
intdst_device_num , 17
intsrc_device_num 18
); 19
Constraints on Arguments 20
The length of the oﬀset and dimension arrays must be at least the value of num_dims . The 21
dst_device_num andsrc_device_num must be greater than or equal to zero and less than 22
the result of omp_get_num_devices() or equal to the result of a call to 23
omp_get_initial_device() . 24
The value of num_dims must be between 1 and the implementation-deﬁned limit, which must be at 25
least three. 26
Effect 27
This routine copies a rectangular subvolume of src, in the device data environment of device 28
src_device_num , todst, in the device data environment of device dst_device_num . The volume is 29
speciﬁed in terms of the size of an element, number of dimensions, and constant arrays of length 30
num_dims . The maximum number of dimensions supported is at least three, support for higher 31
dimensionality is implementation deﬁned. The volume array speciﬁes the length, in number of 32
elements, to copy in each dimension from srctodst. Thedst_oﬀsets (src_oﬀsets ) parameter 33
speciﬁes number of elements from the origin of dst(src) in elements. The dst_dimensions 34
(src_dimensions ) parameter speciﬁes the length of each dimension of dst(src) 35
402 OpenMP API – Version 5.0 November 2018
C/C++ (cont.)
The routine returns zero if successful. If both dstandsrcareNULLpointers, the routine returns the 1
number of dimensions supported by the implementation for the speciﬁed device numbers. The host 2
device and host device data environment can be referenced with the device number returned by 3
omp_get_initial_device . Otherwise, it returns a non-zero value. The routine contains a 4
task scheduling point. 5
When called from within a target region the eﬀect of this routine is unspeciﬁed. 6
Execution Model Events 7
Thetarget-data-op event occurs when a thread transfers data on a target device. 8
Tool Callbacks 9
A thread invokes a registered ompt_callback_target_data_op callback for each 10
occurrence of a target-data-op event in that thread. The callback occurs in the context of the target 11
task and has type signature ompt_callback_target_data_op_t . 12
Cross References 13
target construct, see Section 2.12.5 on page 170. 14
omp_get_initial_device routine, see Section 3.2.41 on page 376 15
omp_target_alloc routine, see Section 3.6.1 on page 397. 16
ompt_callback_target_data_op_t , see Section 4.5.2.25 on page 488. 17
3.6.6 omp_target_associate_ptr 18
Summary 19
Theomp_target_associate_ptr routine maps a device pointer, which may be returned 20
fromomp_target_alloc or implementation-deﬁned runtime routines, to a host pointer. 21
CHAPTER 3. RUNTIME LIBRARY ROUTINES 403
C/C++ (cont.)
Format 1
int omp_target_associate_ptr( 2
const void *host_ptr , 3
const void *device_ptr , 4
size_t size, 5
size_t device_oﬀset , 6
intdevice_num 7
); 8
Constraints on Arguments 9
The value of device_ptr value must be a valid pointer to device memory for the device denoted by 10
the value of device_num . Thedevice_num argument must be greater than or equal to zero and less 11
than the result of omp_get_num_devices() or equal to the result of a call to 12
omp_get_initial_device() . 13
Effect 14
Theomp_target_associate_ptr routine associates a device pointer in the device data 15
environment of device device_num with a host pointer such that when the host pointer appears in a 16
subsequent mapclause, the associated device pointer is used as the target for data motion 17
associated with that host pointer. The device_oﬀset parameter speciﬁes the oﬀset into device_ptr 18
that is used as the base address for the device side of the mapping. The reference count of the 19
resulting mapping will be inﬁnite. After being successfully associated, the buﬀer to which the 20
device pointer points is invalidated and accessing data directly through the device pointer results in 21
unspeciﬁed behavior. The pointer can be retrieved for other uses by disassociating it. When called 22
from within a target region the eﬀect of this routine is unspeciﬁed. 23
The routine returns zero if successful. Otherwise it returns a non-zero value. 24
Only one device buﬀer can be associated with a given host pointer value and device number pair. 25
Attempting to associate a second buﬀer will return non-zero. Associating the same pair of pointers 26
on the same device with the same oﬀset has no eﬀect and returns zero. Associating pointers that 27
share underlying storage will result in unspeciﬁed behavior. The omp_target_is_present 28
function can be used to test whether a given host pointer has a corresponding variable in the device 29
data environment. 30
Execution Model Events 31
Thetarget-data-associate event occurs when a thread associates data on a target device. 32
Tool Callbacks 33
A thread invokes a registered ompt_callback_target_data_op callback for each 34
occurrence of a target-data-associate event in that thread. The callback occurs in the context of the 35
target task and has type signature ompt_callback_target_data_op_t . 36
404 OpenMP API – Version 5.0 November 2018
C/C++ (cont.)
Cross References 1
target construct, see Section 2.12.5 on page 170. 2
mapclause, see Section 2.19.7.1 on page 315. 3
omp_target_alloc routine, see Section 3.6.1 on page 397. 4
omp_target_disassociate_ptr routine, see Section 3.6.6 on page 403 5
ompt_callback_target_data_op_t , see Section 4.5.2.25 on page 488. 6
3.6.7 omp_target_disassociate_ptr 7
Summary 8
Theomp_target_disassociate_ptr removes the associated pointer for a given device 9
from a host pointer. 10
Format 11
int omp_target_disassociate_ptr(const void *ptr, intdevice_num ); 12
Constraints on Arguments 13
Thedevice_num must be greater than or equal to zero and less than the result of 14
omp_get_num_devices() or equal to the result of a call to 15
omp_get_initial_device() . 16
Effect 17
Theomp_target_disassociate_ptr removes the associated device data on device 18
device_num from the presence table for host pointer ptr. A call to this routine on a pointer that is 19
notNULLand does not have associated data on the given device results in unspeciﬁed behavior. 20
The reference count of the mapping is reduced to zero, regardless of its current value. 21
When called from within a target region the eﬀect of this routine is unspeciﬁed. 22
The routine returns zero if successful. Otherwise it returns a non-zero value. 23
After a call to omp_target_disassociate_ptr , the contents of the device buﬀer are 24
invalidated. 25
Execution Model Events 26
Thetarget-data-disassociate event occurs when a thread disassociates data on a target device. 27
CHAPTER 3. RUNTIME LIBRARY ROUTINES 405
Tool Callbacks 1
A thread invokes a registered ompt_callback_target_data_op callback for each 2
occurrence of a target-data-disassociate event in that thread. The callback occurs in the context of 3
the target task and has type signature ompt_callback_target_data_op_t . 4
Cross References 5
target construct, see Section 2.12.5 on page 170 6
omp_target_associate_ptr routine, see Section 3.6.6 on page 403 7
ompt_callback_target_data_op_t , see Section 4.5.2.25 on page 488. 8
C / C++
3.7 Memory Management Routines9
This section describes routines that support memory management on the current device. 10
Instances of memory management types must be accessed only through the routines described in 11
this section; programs that otherwise access instances of these types are non-conforming. 12
3.7.1 Memory Management Types 13
The following type deﬁnitions are used by the memory management routines: 14
C / C++
typedef enum omp_alloctrait_key_t { 15
omp_atk_sync_hint = 1, 16
omp_atk_alignment = 2, 17
omp_atk_access = 3, 18
omp_atk_pool_size = 4, 19
omp_atk_fallback = 5, 20
omp_atk_fb_data = 6, 21
omp_atk_pinned = 7, 22
omp_atk_partition = 8 23
} omp_alloctrait_key_t; 24
25
typedef enum omp_alloctrait_value_t { 26
406 OpenMP API – Version 5.0 November 2018
omp_atv_false = 0, 1
omp_atv_true = 1, 2
omp_atv_default = 2, 3
omp_atv_contended = 3, 4
omp_atv_uncontended = 4, 5
omp_atv_sequential = 5, 6
omp_atv_private = 6, 7
omp_atv_all = 7, 8
omp_atv_thread = 8, 9
omp_atv_pteam = 9, 10
omp_atv_cgroup = 10, 11
omp_atv_default_mem_fb = 11, 12
omp_atv_null_fb = 12, 13
omp_atv_abort_fb = 13, 14
omp_atv_allocator_fb = 14, 15
omp_atv_environment = 15, 16
omp_atv_nearest = 16, 17
omp_atv_blocked = 17, 18
omp_atv_interleaved = 18 19
} omp_alloctrait_value_t; 20
21
typedef struct omp_alloctrait_t { 22
omp_alloctrait_key_t key; 23
omp_uintptr_t value; 24
} omp_alloctrait_t; 25
C / C++
Fortran
26
integer(kind=omp_alloctrait_key_kind), & 27
parameter :: omp_atk_sync_hint = 1 28
integer(kind=omp_alloctrait_key_kind), & 29
parameter :: omp_atk_alignment = 2 30
integer(kind=omp_alloctrait_key_kind), & 31
parameter :: omp_atk_access = 3 32
integer(kind=omp_alloctrait_key_kind), & 33
parameter :: omp_atk_pool_size = 4 34
integer(kind=omp_alloctrait_key_kind), & 35
parameter :: omp_atk_fallback = 5 36
integer(kind=omp_alloctrait_key_kind), & 37
parameter :: omp_atk_fb_data = 6 38
integer(kind=omp_alloctrait_key_kind), & 39
parameter :: omp_atk_pinned = 7 40
integer(kind=omp_alloctrait_key_kind), & 41
CHAPTER 3. RUNTIME LIBRARY ROUTINES 407
Fortran (cont.)
parameter :: omp_atk_partition = 8 1
2
integer(kind=omp_alloctrait_val_kind), & 3
parameter :: omp_atv_false = 0 4
integer(kind=omp_alloctrait_val_kind), & 5
parameter :: omp_atv_true = 1 6
integer(kind=omp_alloctrait_val_kind), & 7
parameter :: omp_atv_default = 2 8
integer(kind=omp_alloctrait_val_kind), & 9
parameter :: omp_atv_contended = 3 10
integer(kind=omp_alloctrait_val_kind), & 11
parameter :: omp_atv_uncontended = 4 12
integer(kind=omp_alloctrait_val_kind), & 13
parameter :: omp_atv_sequential = 5 14
integer(kind=omp_alloctrait_val_kind), & 15
parameter :: omp_atv_private = 6 16
integer(kind=omp_alloctrait_val_kind), & 17
parameter :: omp_atv_all = 7 18
integer(kind=omp_alloctrait_val_kind), & 19
parameter :: omp_atv_thread = 8 20
integer(kind=omp_alloctrait_val_kind), & 21
parameter :: omp_atv_pteam = 9 22
integer(kind=omp_alloctrait_val_kind), & 23
parameter :: omp_atv_cgroup = 10 24
integer(kind=omp_alloctratit_val_kind), & 25
parameter :: omp_atv_default_mem_fb = 11 26
integer(kind=omp_alloctratit_val_kind), & 27
parameter :: omp_atv_null_fb = 12 28
integer(kind=omp_alloctratit_val_kind), & 29
parameter :: omp_atv_abort_fb = 13 30
integer(kind=omp_alloctratit_val_kind), & 31
parameter :: omp_atv_allocator_fb = 14 32
integer(kind=omp_alloctrait_val_kind), & 33
parameter :: omp_atv_environment = 15 34
integer(kind=omp_alloctrait_val_kind), & 35
parameter :: omp_atv_nearest = 16 36
integer(kind=omp_alloctrait_val_kind), & 37
parameter :: omp_atv_blocked = 17 38
integer(kind=omp_alloctrait_val_kind), & 39
parameter :: omp_atv_interleaved = 18 40
41
type omp_alloctrait 42
integer(kind=omp_alloctrait_key_kind) key 43
408 OpenMP API – Version 5.0 November 2018
integer(kind=omp_alloctrait_val_kind) value 1
end type omp_alloctrait 2
3
integer(kind=omp_allocator_handle_kind), & 4
parameter :: omp_null_allocator = 0 5
Fortran
3.7.2 omp_init_allocator 6
Summary 7
Theomp_init_allocator routine initializes an allocator and associates it with a memory 8
space. 9
Format 10
C / C++
omp_allocator_handle_t omp_init_allocator ( 11
omp_memspace_handle_t memspace , 12
intntraits , 13
const omp_alloctrait_t traits[] 14
); 15
C / C++
Fortran
integer(kind=omp_allocator_handle_kind) & 16
function omp_init_allocator ( memspace ,ntraits ,traits ) 17
integer(kind=omp_memspace_handle_kind),intent(in) :: memspace 18
integer,intent(in) :: ntraits 19
type(omp_alloctrait),intent(in) :: traits(*) 20
Fortran
Constraints on Arguments 21
Thememspace argument must be one of the predeﬁned memory spaces deﬁned in Table 2.8. 22
If thentraitsargument is greater than zero then the traitsargument must specify at least that many 23
traits. If it speciﬁes fewer than ntraitstraits the behavior is unspeciﬁed. 24
Unless a requires directive with the dynamic_allocators clause is present in the same 25
compilation unit, using this routine in a target region results in unspeciﬁed behavior. 26
CHAPTER 3. RUNTIME LIBRARY ROUTINES 409
Binding 1
The binding thread set for an omp_init_allocator region is all threads on a device. The 2
eﬀectofexecutingthisroutineisnotrelatedtoanyspeciﬁcregionthatcorrespondstoanyconstruct 3
or API routine. 4
Effect 5
Theomp_init_allocator routine creates a new allocator that is associated with the 6
memspace memory space and returns a handle to it. All allocations through the created allocator 7
will behave according to the allocator traits speciﬁed in the traitsargument. The number of traits in 8
thetraitsargument is speciﬁed by the ntraitsargument. Specifying the same allocator trait more 9
than once results in unspeciﬁed behavior. The routine returns a handle for the created allocator. If 10
the special omp_atv_default value is used for a given trait, then its value will be the default 11
value speciﬁed in Table 2.9 for that given trait. 12
Ifmemspace isomp_default_mem_space and the traits argument is an empty set this 13
routine will always return a handle to an allocator. Otherwise if an allocator based on the 14
requirements cannot be created then the special omp_null_allocator handle is returned. 15
The use of an allocator returned by this routine on a device other than the one on which it was 16
created results in unspeciﬁed behavior. 17
Cross References 18
Memory Spaces, see Section 2.11.1 on page 152. 19
Memory Allocators, see Section 2.11.2 on page 152. 20
3.7.3 omp_destroy_allocator 21
Summary 22
Theomp_destroy_allocator routine releases all resources used by the allocator handle. 23
Format 24
C / C++
void omp_destroy_allocator (omp_allocator_handle_t allocator ); 25
C / C++
Fortran
subroutine omp_destroy_allocator ( allocator ) 26
integer(kind=omp_allocator_handle_kind),intent(in) :: allocator 27
Fortran
410 OpenMP API – Version 5.0 November 2018
Constraints on Arguments 1
Theallocator argument must not represent a predeﬁned memory allocator. 2
Unless a requires directive with the dynamic_allocators clause is present in the same 3
compilation unit, using this routine in a target region results in unspeciﬁed behavior. 4
Binding 5
The binding thread set for an omp_destroy_allocator region is all threads on a device. The 6
eﬀectofexecutingthisroutineisnotrelatedtoanyspeciﬁcregionthatcorrespondstoanyconstruct 7
or API routine. 8
Effect 9
Theomp_destroy_allocator routine releases all resources used to implement the allocator 10
handle. Accessing any memory allocated by the allocator after this call results in unspeciﬁed 11
behavior. 12
Ifallocator isomp_null_allocator then this routine will have no eﬀect. 13
Cross References 14
Memory Allocators, see Section 2.11.2 on page 152. 15
3.7.4 omp_set_default_allocator 16
Summary 17
Theomp_set_default_allocator routine sets the default memory allocator to be used by 18
allocation calls, allocate directives and allocate clauses that do not specify an allocator. 19
Format 20
C / C++
void omp_set_default_allocator (omp_allocator_handle_t allocator ); 21
C / C++
Fortran
subroutine omp_set_default_allocator ( allocator ) 22
integer(kind=omp_allocator_handle_kind),intent(in) :: allocator 23
Fortran
CHAPTER 3. RUNTIME LIBRARY ROUTINES 411
Constraints on Arguments 1
Theallocator argument must be a valid memory allocator handle. 2
Binding 3
Thebindingtasksetforan omp_set_default_allocator regionisthebindingimplicittask. 4
Effect 5
Theeﬀect ofthisroutine isto setthevalue ofthe def-allocator-var ICVof thebindingimplicit task 6
to the value speciﬁed in the allocator argument. 7
Cross References 8
def-allocator-var ICV, see Section 2.5 on page 63. 9
Memory Allocators, see Section 2.11.2 on page 152. 10
omp_alloc routine, see Section 3.7.6 on page 413. 11
3.7.5 omp_get_default_allocator 12
Summary 13
Theomp_get_default_allocator routine returns a handle to the memory allocator to be 14
used by allocation calls, allocate directives and allocate clauses that do not specify an 15
allocator. 16
Format 17
C / C++
omp_allocator_handle_t omp_get_default_allocator (void); 18
C / C++
Fortran
integer(kind=omp_allocator_handle_kind)& 19
function omp_get_default_allocator () 20
Fortran
Binding 21
Thebindingtasksetforan omp_get_default_allocator regionisthebindingimplicittask. 22
412 OpenMP API – Version 5.0 November 2018
Effect 1
The eﬀect of this routine is to return the value of the def-allocator-var ICV of the binding implicit 2
task. 3
Cross References 4
def-allocator-var ICV, see Section 2.5 on page 63. 5
Memory Allocators, see Section 2.11.2 on page 152. 6
omp_alloc routine, see Section 3.7.6 on page 413. 7
C / C++
3.7.6 omp_alloc 8
Summary 9
Theomp_alloc routine requests a memory allocation from a memory allocator. 10
Format 11
C
void *omp_alloc (size_t size, omp_allocator_handle_t allocator ); 12
C
C++
void *omp_alloc( 13
size_t size, 14
omp_allocator_handle_t allocator =omp_null_allocator 15
); 16
C++
Constraints on Arguments 17
Unless dynamic_allocators appears on a requires directive in the same compilation unit, 18
omp_alloc invocations that appear in target regions must not pass omp_null_allocator 19
as theallocator argument, which must be a constant expression that evaluates to one of the 20
predeﬁned memory allocator values. 21
CHAPTER 3. RUNTIME LIBRARY ROUTINES 413
C/C++ (cont.)
Effect 1
Theomp_alloc routine requests a memory allocation of sizebytes from the speciﬁed memory 2
allocator. If the allocator argument is omp_null_allocator the memory allocator used by the 3
routine will be the one speciﬁed by the def-allocator-var ICV of the binding implicit task. Upon 4
success it returns a pointer to the allocated memory. Otherwise, the behavior speciﬁed by the 5
fallback trait will be followed. 6
Allocated memory will be byte aligned to at least the alignment required by malloc. 7
Cross References 8
Memory allocators, see Section 2.11.2 on page 152. 9
3.7.7 omp_free 10
Summary 11
Theomp_free routine deallocates previously allocated memory. 12
Format 13
C
void omp_free (void *ptr, omp_allocator_handle_t allocator ); 14
C
C++
void omp_free( 15
void *ptr, 16
omp_allocator_handle_t allocator =omp_null_allocator 17
); 18
C++
Effect 19
Theomp_free routine deallocates the memory to which ptrpoints. The ptrargument must point 20
to memory previously allocated with a memory allocator. If the allocator argument is speciﬁed it 21
must be the memory allocator to which the allocation request was made. If the allocator argument 22
isomp_null_allocator the implementation will determine that value automatically. Using 23
omp_free on memory that was already deallocated or that was allocated by an allocator that has 24
already been destroyed with omp_destroy_allocator results in unspeciﬁed behavior. 25
414 OpenMP API – Version 5.0 November 2018
Cross References 1
Memory allocators, see Section 2.11.2 on page 152. 2
C / C++
3.8 Tool Control Routine3
Summary 4
Theomp_control_tool routine enables a program to pass commands to an active tool. 5
Format 6
C / C++
int omp_control_tool(int command , intmodiﬁer , void *arg); 7
C / C++
Fortran
integer function omp_control_tool( command ,modiﬁer ) 8
integer (kind=omp_control_tool_kind) command 9
integer modiﬁer 10
Fortran
Description 11
An OpenMP program may use omp_control_tool to pass commands to a tool. An application 12
can use omp_control_tool to request that a tool starts or restarts data collection when a code 13
region of interest is encountered, that a tool pauses data collection when leaving the region of 14
interest, that a tool ﬂushes any data that it has collected so far, or that a tool ends data collection. 15
Additionally, omp_control_tool can be used to pass tool-speciﬁc commands to a particular 16
tool. 17
The following types correspond to return values from omp_control_tool : 18
C / C++
typedef enum omp_control_tool_result_t { 19
omp_control_tool_notool = -2, 20
omp_control_tool_nocallback = -1, 21
omp_control_tool_success = 0, 22
omp_control_tool_ignored = 1 23
} omp_control_tool_result_t; 24
C / C++
CHAPTER 3. RUNTIME LIBRARY ROUTINES 415
Fortran
integer (kind=omp_control_tool_result_kind), & 1
parameter :: omp_control_tool_notool = -2 2
integer (kind=omp_control_tool_result_kind), & 3
parameter :: omp_control_tool_nocallback = -1 4
integer (kind=omp_control_tool_result_kind), & 5
parameter :: omp_control_tool_success = 0 6
integer (kind=omp_control_tool_result_kind), & 7
parameter :: omp_control_tool_ignored = 1 8
Fortran
If the OMPT interface state is inactive, the OpenMP implementation returns 9
omp_control_tool_notool . If the OMPT interface state is active, but no callback is 10
registered for the tool-control event, the OpenMP implementation returns 11
omp_control_tool_nocallback . An OpenMP implementation may return other 12
implementation-deﬁned negative values strictly smaller than -64; an application may assume that 13
any negative return value indicates that a tool has not received the command. A return value of 14
omp_control_tool_success indicatesthatthetoolhasperformedthespeciﬁedcommand. A 15
return value of omp_control_tool_ignored indicates that the tool has ignored the speciﬁed 16
command. A tool may return other positive values strictly greater than 64 that are tool-deﬁned. 17
Constraints on Arguments 18
The following enumeration type deﬁnes four standard commands. Table 3.1 describes the actions 19
that these commands request from a tool. 20
C / C++
typedef enum omp_control_tool_t { 21
omp_control_tool_start = 1, 22
omp_control_tool_pause = 2, 23
omp_control_tool_flush = 3, 24
omp_control_tool_end = 4 25
} omp_control_tool_t; 26
C / C++
Fortran
integer (kind=omp_control_tool_kind), & 27
parameter :: omp_control_tool_start = 1 28
integer (kind=omp_control_tool_kind), & 29
parameter :: omp_control_tool_pause = 2 30
integer (kind=omp_control_tool_kind), & 31
parameter :: omp_control_tool_flush = 3 32
integer (kind=omp_control_tool_kind), & 33
parameter :: omp_control_tool_end = 4 34
Fortran
416 OpenMP API – Version 5.0 November 2018
Tool-speciﬁc values for command must be greater or equal to 64. Tools must ignore command 1
valuesthattheyarenotexplicitlydesignedtohandle. Othervaluesacceptedbyatoolfor command , 2
and any values for modiﬁerandargare tool-deﬁned. 3
TABLE 3.1:Standard Tool Control Commands
Command Action
omp_control_tool_start Start or restart monitoring if it is oﬀ. If monitoring
is already on, this command is idempotent. If
monitoring has already been turned oﬀ permanently,
this command will have no eﬀect.
omp_control_tool_pause Temporarily turn monitoring oﬀ. If monitoring is
already oﬀ, it is idempotent.
omp_control_tool_flush Flush any data buﬀered by a tool. This command may
be applied whether monitoring is on or oﬀ.
omp_control_tool_end Turn monitoring oﬀ permanently; the tool ﬁnalizes
itself and ﬂushes all output.
Execution Model Events 4
Thetool-control event occurs in the thread that encounters a call to omp_control_tool at a 5
point inside its corresponding OpenMP region. 6
Tool Callbacks 7
A thread dispatches a registered ompt_callback_control_tool callback for each 8
occurrenceofa tool-control event. Thecallbackexecutesinthecontextofthecallthatoccursinthe 9
user program and has type signature ompt_callback_control_tool_t . The callback may 10
return any non-negative value, which will be returned to the application by the OpenMP 11
implementation as the return value of the omp_control_tool call that triggered the callback. 12
Arguments passed to the callback are those passed by the user to omp_control_tool . If the 13
callismadeinFortran,thetoolwillbepassed NULLasthethirdargumenttothecallback. Ifanyof 14
the four standard commands is presented to a tool, the tool will ignore the modiﬁerandarg 15
argument values. 16
Cross References 17
OMPT Interface, see Chapter 4 on page 419 18
ompt_callback_control_tool_t , see Section 4.5.2.29 on page 495 19
CHAPTER 3. RUNTIME LIBRARY ROUTINES 417
This page intentionally left blank
CHAPTER 4
OMPT Interface 1
2
ThischapterdescribesOMPT,whichisaninterfacefor ﬁrst-party tools.First-party toolsarelinked 3
or loaded directly into the OpenMP program. OMPT deﬁnes mechanisms to initialize a tool, to 4
examineOpenMPstateassociatedwithanOpenMPthread,tointerpretthecallstackofanOpenMP 5
thread, to receive notiﬁcation about OpenMP events, to trace activity on OpenMP target devices, to 6
assess implementation-dependent details of an OpenMP implementation (such as supported states 7
and mutual exclusion implementations), and to control a tool from an OpenMP application. 8
4.1 OMPT Interfaces Deﬁnitions9
C / C++
A compliant implementation must supply a set of deﬁnitions for the OMPT runtime entry points, 10
OMPT callback signatures, and the special data types of their parameters and return values. These 11
deﬁnitions, which are listed throughout this chapter, and their associated declarations shall be 12
provided in a header ﬁle named omp-tools.h . In addition, the set of deﬁnitions may specify 13
other implementation-speciﬁc values. 14
Theompt_start_tool function is an external function with Clinkage. 15
C / C++
CHAPTER 4. OMPT INTERFACE 419
4.2 Activating a First-Party Tool1
To activate a tool, an OpenMP implementation ﬁrst determines whether the tool should be 2
initialized. If so, the OpenMP implementation invokes the initializer of the tool, which enables the 3
tool to prepare to monitor execution on the host. The tool may then also arrange to monitor 4
computation that executes on target devices. This section explains how the tool and an OpenMP 5
implementation interact to accomplish these tasks. 6
4.2.1 ompt_start_tool 7
Summary 8
InordertousetheOMPTinterfaceprovidedbyanOpenMPimplementation,atoolmustimplement 9
theompt_start_tool function,throughwhichtheOpenMPimplementationinitializesthetool. 10
Format 11
C
ompt_start_tool_result_t *ompt_start_tool( 12
unsigned int omp_version , 13
const char *runtime_version 14
); 15
C
Description 16
ForatooltousetheOMPTinterfacethatanOpenMPimplementationprovides,thetoolmustdeﬁne 17
a globally-visible implementation of the function ompt_start_tool . The tool indicates that it 18
will use the OMPT interface that an OpenMP implementation provides by returning a non-null 19
pointer to an ompt_start_tool_result_t structure from the ompt_start_tool 20
implementation that it provides. The ompt_start_tool_result_t structure contains 21
pointers to tool initialization and ﬁnalization callbacks as well as a tool data word that an OpenMP 22
implementation must pass by reference to these callbacks. A tool may return NULLfrom 23
ompt_start_tool to indicate that it will not use the OMPT interface in a particular execution. 24
A toolmay use the omp_version argument todetermine if itis compatible withthe OMPT interface 25
that the OpenMP implementation provides. 26
420 OpenMP API – Version 5.0 November 2018
Description of Arguments 1
The argument omp_version is the value of the _OPENMP version macro associated with the 2
OpenMP API implementation. This value identiﬁes the OpenMP API version that an OpenMP 3
implementation supports, which speciﬁes the version of the OMPT interface that it supports. 4
The argument runtime_version is a version string that unambiguously identiﬁes the OpenMP 5
implementation. 6
Constraints on Arguments 7
The argument runtime_version must be an immutable string that is deﬁned for the lifetime of a 8
program execution. 9
Effect 10
If a tool returns a non-null pointer to an ompt_start_tool_result_t structure, an OpenMP 11
implementation will call the tool initializer speciﬁed by the initialize ﬁeld in this structure before 12
beginning execution of any OpenMP construct or completing execution of any environment routine 13
invocation; the OpenMP implementation will call the tool ﬁnalizer speciﬁed by the ﬁnalizeﬁeld in 14
this structure when the OpenMP implementation shuts down. 15
Cross References 16
ompt_start_tool_result_t , see Section 4.4.1 on page 433. 17
4.2.2 Determining Whether a First-Party Tool Should be Initialized 18
An OpenMP implementation examines the tool-varICV as one of its ﬁrst initialization steps. If the 19
value oftool-varisdisabled, the initialization continues without a check for the presence of a tool 20
and the functionality of the OMPT interface will be unavailable as the program executes. In this 21
case, the OMPT interface state remains inactive. 22
Otherwise,theOMPTinterfacestatechangesto pendingandtheOpenMPimplementationactivates 23
any ﬁrst-party tool that it ﬁnds. A tool can provide a deﬁnition of ompt_start_tool to an 24
OpenMP implementation in three ways: 25
By statically-linking its deﬁnition of ompt_start_tool into an OpenMP application; 26
By introducing a dynamically-linked library that includes its deﬁnition of ompt_start_tool 27
into the application’s address space; or 28
CHAPTER 4. OMPT INTERFACE 421
InactiveRuntime
(re)starttool-var Pending
Find next tool
Return
value r
ActiveCall
ompt_start_toolFound? InactiveRuntime shutdown
or pause
Call
r->initializeReturn
valueenabled
disabled
r=non-nullr=NULL yesno
10FIGURE 4.1:First-Party Tool Activation Flow Chart
By providing, in the tool-libraries-var ICV, the name of a dynamically-linked library that is 1
appropriate for the architecture and operating system used by the application and that includes a 2
deﬁnition of ompt_start_tool . 3
If the value of tool-varisenabled, the OpenMP implementation must check if a tool has provided 4
an implementation of ompt_start_tool . The OpenMP implementation ﬁrst checks if a 5
tool-provided implementation of ompt_start_tool is available in the address space, either 6
statically-linked into the application or in a dynamically-linked library loaded in the address space. 7
If multiple implementations of ompt_start_tool are available, the OpenMP implementation 8
will use the ﬁrst tool-provided implementation of ompt_start_tool that it ﬁnds. 9
Iftheimplementationdoesnotﬁndatool-providedimplementationof ompt_start_tool inthe 10
address space, it consults the tool-libraries-var ICV, which contains a (possibly empty) list of 11
dynamically-linked libraries. As described in detail in Section 6.19 on page 617, the libraries in 12
tool-libraries-var are then searched for the ﬁrst usable implementation of ompt_start_tool 13
that one of the libraries in the list provides. 14
If the implementation ﬁnds a tool-provided deﬁnition of ompt_start_tool , it invokes that 15
method; if a NULLpointer is returned, the OMPT interface state remains pendingand the 16
422 OpenMP API – Version 5.0 November 2018
implementation continues to look for implementations of ompt_start_tool ; otherwise a 1
non-null pointer to an ompt_start_tool_result_t structure is returned, the OMPT 2
interface state changes to activeand the OpenMP implementation makes the OMPT interface 3
available as the program executes. In this case, as the OpenMP implementation completes its 4
initialization, it initializes the OMPT interface. 5
If no tool can be found, the OMPT interface state changes to inactive. 6
Cross References 7
tool-libraries-var ICV, see Section 2.5 on page 63. 8
tool-varICV, see Section 2.5 on page 63. 9
ompt_start_tool function, see Section 4.2.1 on page 420. 10
ompt_start_tool_result_t type, see Section 4.4.1 on page 433. 11
4.2.3 Initializing a First-Party Tool 12
To initialize the OMPT interface, the OpenMP implementation invokes the tool initializer that is 13
speciﬁed in the ompt_start_tool_result_t structure that is indicated by the non-null 14
pointer that ompt_start_tool returns. The initializer is invoked prior to the occurrence of any 15
OpenMP event. 16
A tool initializer, described in Section 4.5.1.1 on page 457, uses the function speciﬁed in its lookup 17
argument to look up pointers to OMPT interface runtime entry points that the OpenMP 18
implementation provides; this process is described in Section 4.2.3.1 on page 424. Typically, a tool 19
initializer obtains a pointer to the ompt_set_callback runtime entry point with type signature 20
ompt_set_callback_t and then uses this runtime entry point to register tool callbacks for 21
OpenMP events, as described in Section 4.2.4 on page 425. 22
A tool initializer may use the ompt_enumerate_states runtime entry point, which has type 23
signature ompt_enumerate_states_t , to determine the thread states that an OpenMP 24
implementation employs. Similarly, it may use the ompt_enumerate_mutex_impls runtime 25
entry point, which has type signature ompt_enumerate_mutex_impls_t , to determine the 26
mutual exclusion implementations that the OpenMP implementation employs. 27
If a tool initializer returns a non-zero value, the OMPT interface state remains activefor the 28
execution; otherwise, the OMPT interface state changes to inactive. 29
CHAPTER 4. OMPT INTERFACE 423
Cross References 1
ompt_start_tool function, see Section 4.2.1 on page 420. 2
ompt_start_tool_result_t type, see Section 4.4.1 on page 433. 3
ompt_initialize_t type, see Section 4.5.1.1 on page 457. 4
ompt_callback_thread_begin_t type, see Section 4.5.2.1 on page 459. 5
ompt_enumerate_states_t type, see Section 4.6.1.1 on page 498. 6
ompt_enumerate_mutex_impls_t type, see Section 4.6.1.2 on page 499. 7
ompt_set_callback_t type, see Section 4.6.1.3 on page 500. 8
ompt_function_lookup_t type, see Section 4.6.3 on page 531. 9
4.2.3.1 Binding Entry Points in the OMPT Callback Interface 10
Functions that an OpenMP implementation provides to support the OMPT interface are not deﬁned 11
as global function symbols. Instead, they are deﬁned as runtime entry points that a tool can only 12
identify through the lookupfunction that is provided as an argument with type signature 13
ompt_function_lookup_t to the tool initializer. A tool can use this function to obtain a 14
pointer to each of the runtime entry points that an OpenMP implementation provides to support the 15
OMPT interface. Once a tool has obtained a lookupfunction, it may employ it at any point in the 16
future. 17
For each runtime entry point in the OMPT interface for the host device, Table 4.1 provides the 18
string name by which it is known and its associated type signature. Implementations can provide 19
additional implementation-speciﬁc names and corresponding entry points. Any names that begin 20
withompt_are reserved names. 21
During initialization, a tool should look up each runtime entry point in the OMPT interface by 22
name and bind a pointer maintained by the tool that can later be used to invoke the entry point. The 23
entry points described in Table 4.1 enable a tool to assess the thread states and mutual exclusion 24
implementations that an OpenMP implementation supports, to register tool callbacks, to inspect 25
registered callbacks, to introspect OpenMP state associated with threads, and to use tracing to 26
monitor computations that execute on target devices. 27
Detailed information about each runtime entry point listed in Table 4.1 is included as part of the 28
description of its type signature. 29
Cross References 30
ompt_enumerate_states_t type, see Section 4.6.1.1 on page 498. 31
ompt_enumerate_mutex_impls_t type, see Section 4.6.1.2 on page 499. 32
424OpenMP API – Version 5.0 November 2018
ompt_set_callback_t type, see Section 4.6.1.3 on page 500. 1
ompt_get_callback_t type, see Section 4.6.1.4 on page 502. 2
ompt_get_thread_data_t type, see Section 4.6.1.5 on page 503. 3
ompt_get_num_procs_t type, see Section 4.6.1.6 on page 503. 4
ompt_get_num_places_t type, see Section 4.6.1.7 on page 504. 5
ompt_get_place_proc_ids_t type, see Section 4.6.1.8 on page 505. 6
ompt_get_place_num_t type, see Section 4.6.1.9 on page 506. 7
ompt_get_partition_place_nums_t type, see Section 4.6.1.10 on page 507. 8
ompt_get_proc_id_t type, see Section 4.6.1.11 on page 508. 9
ompt_get_state_t type, see Section 4.6.1.12 on page 508. 10
ompt_get_parallel_info_t type, see Section 4.6.1.13 on page 510. 11
ompt_get_task_info_t type, see Section 4.6.1.14 on page 512. 12
ompt_get_task_memory_t type, see Section 4.6.1.15 on page 514. 13
ompt_get_target_info_t type, see Section 4.6.1.16 on page 515. 14
ompt_get_num_devices_t type, see Section 4.6.1.17 on page 516. 15
ompt_get_unique_id_t type, see Section 4.6.1.18 on page 517. 16
ompt_finalize_tool_t type, see Section 4.6.1.19 on page 517. 17
ompt_function_lookup_t type, see Section 4.6.3 on page 531. 18
4.2.4 Monitoring Activity on the Host with OMPT 19
To monitor the execution of an OpenMP program on the host device, a tool initializer must register 20
to receive notiﬁcation of events that occur as an OpenMP program executes. A tool can use the 21
ompt_set_callback runtime entry point to register callbacks for OpenMP events. The return 22
codes for ompt_set_callback use the ompt_set_result_t enumeration type. If the 23
ompt_set_callback runtime entry point is called outside a tool initializer, registration of 24
supported callbacks may fail with a return value of ompt_set_error . 25
Allcallbacksregisteredwith ompt_set_callback orreturnedby ompt_get_callback use 26
the dummy type signature ompt_callback_t . 27
Table 4.2 shows the valid registration return codes of the ompt_set_callback runtime entry 28
point with speciﬁc values of its eventargument. For callbacks for which ompt_set_always is 29
CHAPTER 4. OMPT INTERFACE 425
TABLE 4.1:OMPT Callback Interface Runtime Entry Point Names and Their Type Signatures
Entry Point String Name Type signature
“ompt_enumerate_states ” ompt_enumerate_states_t
“ompt_enumerate_mutex_impls ” ompt_enumerate_mutex_impls_t
“ompt_set_callback ” ompt_set_callback_t
“ompt_get_callback ” ompt_get_callback_t
“ompt_get_thread_data ” ompt_get_thread_data_t
“ompt_get_num_places ” ompt_get_num_places_t
“ompt_get_place_proc_ids ” ompt_get_place_proc_ids_t
“ompt_get_place_num ” ompt_get_place_num_t
“ompt_get_partition_place_nums ”ompt_get_partition_place_nums_t
“ompt_get_proc_id ” ompt_get_proc_id_t
“ompt_get_state ” ompt_get_state_t
“ompt_get_parallel_info ” ompt_get_parallel_info_t
“ompt_get_task_info ” ompt_get_task_info_t
“ompt_get_task_memory ” ompt_get_task_memory_t
“ompt_get_num_devices ” ompt_get_num_devices_t
“ompt_get_num_procs ” ompt_get_num_procs_t
“ompt_get_target_info ” ompt_get_target_info_t
“ompt_get_unique_id ” ompt_get_unique_id_t
“ompt_finalize_tool ” ompt_finalize_tool_t
426 OpenMP API – Version 5.0 November 2018
the only registration return code that is allowed, an OpenMP implementation must guarantee that 1
the callback will be invoked every time that a runtime event that is associated with it occurs. 2
Support for such callbacks is required in a minimal implementation of the OMPT interface. For 3
callbacks for which the ompt_set_callback runtime entry may return values other than 4
ompt_set_always , whether an OpenMP implementation invokes a registered callback never, 5
sometimes, or always is implementation-deﬁned. If registration for a callback allows a return code 6
ofomp_set_never , support for invoking such a callback may not be present in a minimal 7
implementation of the OMPT interface. The return code from registering a callback indicates the 8
implementation-deﬁned level of support for the callback. 9
Two techniques reduce the size of the OMPT interface. First, in cases where events are naturally 10
paired,forexample,thebeginningandendofaregion,andtheargumentsneededbythecallbackat 11
each endpoint are identical, a tool registers a single callback for the pair of events, with 12
ompt_scope_begin orompt_scope_end provided as an argument to identify for which 13
endpoint the callback is invoked. Second, when a class of events is amenable to uniform treatment, 14
OMPT provides a single callback for that class of events, for example, an 15
ompt_callback_sync_region_wait callback is used for multiple kinds of synchronization 16
regions, such as barrier, taskwait, and taskgroup regions. Some events, for example, 17
ompt_callback_sync_region_wait , use both techniques. 18
Cross References 19
ompt_set_result_t type, see Section 4.4.4.2 on page 438. 20
ompt_set_callback_t type, see Section 4.6.1.3 on page 500. 21
ompt_get_callback_t type, see Section 4.6.1.4 on page 502. 22
4.2.5 Tracing Activity on Target Devices with OMPT 23
A target device may or may not initialize a full OpenMP runtime system. Unless it does, it may not 24
be possible to monitor activity on a device using a tool interface based on callbacks. To 25
accommodate such cases, the OMPT interface deﬁnes a monitoring interface for tracing activity on 26
target devices. Tracing activity on a target device involves the following steps: 27
To prepare to trace activity on a target device, a tool must register for an 28
ompt_callback_device_initialize callback. A tool may also register for an 29
ompt_callback_device_load callback to be notiﬁed when code is loaded onto a target 30
device or an ompt_callback_device_unload callback to be notiﬁed when code is 31
unloaded from a target device. A tool may also optionally register an 32
ompt_callback_device_finalize callback. 33
CHAPTER 4. OMPT INTERFACE 427
TABLE 4.2:Valid Return Codes of ompt_set_callback for Each Callback
Return code abbreviation N S/P A
ompt_callback_thread_begin *
ompt_callback_thread_end *
ompt_callback_parallel_begin *
ompt_callback_parallel_end *
ompt_callback_task_create *
ompt_callback_task_schedule *
ompt_callback_implicit_task *
ompt_callback_target *
ompt_callback_target_data_op *
ompt_callback_target_submit *
ompt_callback_control_tool *
ompt_callback_device_initialize *
ompt_callback_device_finalize *
ompt_callback_device_load *
ompt_callback_device_unload *
ompt_callback_sync_region_wait * * *
ompt_callback_mutex_released * * *
ompt_callback_dependences * * *
ompt_callback_task_dependence * * *
ompt_callback_work * * *
ompt_callback_master * * *
ompt_callback_target_map * * *
ompt_callback_sync_region * * *
ompt_callback_reduction * * *
ompt_callback_lock_init * * *
ompt_callback_lock_destroy * * *
ompt_callback_mutex_acquire * * *
ompt_callback_mutex_acquired * * *
ompt_callback_nest_lock * * *
ompt_callback_flush * * *
ompt_callback_cancel * * *
ompt_callback_dispatch * * *
N =ompt_set_never S =ompt_set_sometimes
P =ompt_set_sometimes_paired A =ompt_set_always
428 OpenMP API – Version 5.0 November 2018
When an OpenMP implementation initializes a target device, the OpenMP implementation 1
dispatches the device initialization callback of the tool on the host device. If the OpenMP 2
implementation or target device does not support tracing, the OpenMP implementation passes 3
NULLto the device initializer of the tool for its lookupargument; otherwise, the OpenMP 4
implementation passes a pointer to a device-speciﬁc runtime entry point with type signature 5
ompt_function_lookup_t to the device initializer of the tool. 6
If a non-null lookuppointer is provided to the device initializer of the tool, the tool may use it to 7
determine the runtime entry points in the tracing interface that are available for the device and 8
may bind the returned function pointers to tool variables. Table 4.3 indicates the names of 9
runtime entry points that may be available for a device; an implementations may provide 10
additional implementation-deﬁned names and corresponding entry points. The driver for the 11
deviceprovidestheruntimeentrypointsthatenableatooltocontrolthetracecollectioninterface 12
of the device. The nativetrace format that the interface uses may be device speciﬁc and the 13
available kinds of trace records are implementation-deﬁned. Some devices may allow a tool to 14
collect traces of records in a standard format known as OMPT trace records. Each OMPT trace 15
record serves as a substitute for an OMPT callback that cannot be made on the device. The ﬁelds 16
in each trace record type are deﬁned in the description of the callback that the record represents. 17
If this type of record is provided then the lookupfunction returns values for the runtime entry 18
points ompt_set_trace_ompt andompt_get_record_ompt , which support collecting 19
and decoding OMPT traces. If the native tracing format for a device is the OMPT format then 20
tracing can be controlled using the runtime entry points for native or OMPT tracing. 21
The tool uses the ompt_set_trace_native and/or the ompt_set_trace_ompt 22
runtime entry point to specify what types of events or activities to monitor on the device. The 23
return codes for ompt_set_trace_ompt andompt_set_trace_native use the 24
ompt_set_result_t enumeration type. If the ompt_set_trace_native /or the 25
ompt_set_trace_ompt runtime entry point is called outside a device initializer, registration 26
of supported callbacks may fail with a return code of ompt_set_error . 27
The tool initiates tracing on the device by invoking ompt_start_trace . Arguments to 28
ompt_start_trace include two tool callbacks through which the OpenMP implementation 29
can manage traces associated with the device. One allocates a buﬀer in which the device can 30
deposit trace events. The second callback processes a buﬀer of trace events from the device. 31
If the device requires a trace buﬀer, the OpenMP implementation invokes the tool-supplied 32
callback function on the host device to request a new buﬀer. 33
The OpenMP implementation monitors the execution of OpenMP constructs on the device and 34
records a trace of events or activities into a trace buﬀer. If possible, device trace records are 35
markedwitha host_op_id —anidentiﬁerthatassociatesdeviceactivitieswiththetargetoperation 36
that the host initiated to cause these activities. To correlate activities on the host with activities 37
on a device, a tool can register a ompt_callback_target_submit callback. Before the 38
host initiates each distinct activity associated with a structured block for a target construct on 39
a device, the OpenMP implementation dispatches the ompt_callback_target_submit 40
callbackonthehostinthethreadthatisexecutingthetaskthatencountersthe target construct. 41
CHAPTER 4. OMPT INTERFACE 429
TABLE 4.3:OMPT Tracing Interface Runtime Entry Point Names and Their Type Signatures
Entry Point String Name Type Signature
“ompt_get_device_num_procs ” ompt_get_device_num_procs_t
“ompt_get_device_time ” ompt_get_device_time_t
“ompt_translate_time ” ompt_translate_time_t
“ompt_set_trace_ompt ” ompt_set_trace_ompt_t
“ompt_set_trace_native ” ompt_set_trace_native_t
“ompt_start_trace ” ompt_start_trace_t
“ompt_pause_trace ” ompt_pause_trace_t
“ompt_flush_trace ” ompt_flush_trace_t
“ompt_stop_trace ” ompt_stop_trace_t
“ompt_advance_buffer_cursor ”ompt_advance_buffer_cursor_t
“ompt_get_record_type ” ompt_get_record_type_t
“ompt_get_record_ompt ” ompt_get_record_ompt_t
“ompt_get_record_native ” ompt_get_record_native_t
“ompt_get_record_abstract ” ompt_get_record_abstract_t
430 OpenMP API – Version 5.0 November 2018
Examples of activities that could cause an ompt_callback_target_submit callback to 1
be dispatched include an explicit data copy between a host and target device or execution of a 2
computation. This callback provides the tool with a pair of identiﬁers: one that identiﬁes the 3
target region and a second that uniquely identiﬁes an activity associated with that region. These 4
identiﬁers help the tool correlate activities on the target device with their target region. 5
When appropriate, for example, when a trace buﬀer ﬁlls or needs to be ﬂushed, the OpenMP 6
implementation invokes the tool-supplied buﬀer completion callback to process a non-empty 7
sequence of records in a trace buﬀer that is associated with the device. 8
The tool-supplied buﬀer completion callback may return immediately, ignoring records in the 9
trace buﬀer, or it may iterate through them using the ompt_advance_buffer_cursor 10
entry point to inspect each record. A tool may use the ompt_get_record_type runtime 11
entry point to inspect the type of the record at the current cursor position. Three runtime entry 12
points ( ompt_get_record_ompt ,ompt_get_record_native , and 13
ompt_get_record_abstract ) allow tools to inspect the contents of some or all records in 14
a trace buﬀer. The ompt_get_record_native runtime entry point uses the native trace 15
format of the device. The ompt_get_record_abstract runtime entry point decodes the 16
contents of a native trace record and summarizes them as an ompt_record_abstract_t 17
record. The ompt_get_record_ompt runtime entry point can only be used to retrieve 18
records in OMPT format. 19
Once tracing has been started on a device, a tool may pause or resume tracing on the device at 20
any time by invoking ompt_pause_trace with an appropriate ﬂag value as an argument. 21
A tool may invoke the ompt_flush_trace runtime entry point for a device at any time 22
between device initialization and ﬁnalization to cause the device to ﬂush pending trace records. 23
Atanytime,atoolmayusethe ompt_start_trace runtimeentrypointtostarttracingorthe 24
ompt_stop_trace runtime entry point to stop tracing on a device. When tracing is stopped 25
on a device, the OpenMP implementation eventually gathers all trace records already collected 26
on the device and presents them to the tool using the buﬀer completion callback. 27
An OpenMP implementation can be shut down while device tracing is in progress. 28
When an OpenMP implementation is shut down, it ﬁnalize each device. Device ﬁnalization 29
occurs in three steps. First, the OpenMP implementation halts any tracing in progress for the 30
device. Second, the OpenMP implementation ﬂushes all trace records collected for the device 31
and uses the buﬀer completion callback associated with that device to present them to the tool. 32
Finally, the OpenMP implementation dispatches any ompt_callback_device_finalize 33
callback registered for the device. 34
Restrictions 35
Tracing activity on devices has the following restriction: 36
Implementation-deﬁned names must not start with the preﬁx ompt_, which is reserved for the 37
OpenMP speciﬁcation. 38
CHAPTER 4. OMPT INTERFACE 431
Cross References 1
ompt_callback_device_initialize_t callback type, see Section 4.5.2.19 on 2
page 482. 3
ompt_callback_device_finalize_t callback type, see Section 4.5.2.20 on page 484. 4
ompt_get_device_num_procs runtime entry point, see Section 4.6.2.1 on page 518. 5
ompt_get_device_time runtime entry point, see Section 4.6.2.2 on page 519. 6
ompt_translate_time runtime entry point, see Section 4.6.2.3 on page 520. 7
ompt_set_trace_ompt runtime entry point, see Section 4.6.2.4 on page 521. 8
ompt_set_trace_native runtime entry point, see Section 4.6.2.5 on page 522. 9
ompt_start_trace runtime entry point, see Section 4.6.2.6 on page 523. 10
ompt_pause_trace runtime entry point, see Section 4.6.2.7 on page 524. 11
ompt_flush_trace runtime entry point, see Section 4.6.2.8 on page 525. 12
ompt_stop_trace runtime entry point, see Section 4.6.2.9 on page 526. 13
ompt_advance_buffer_cursor runtime entry point, see Section 4.6.2.10 on page 527. 14
ompt_get_record_type runtime entry point, see Section 4.6.2.11 on page 528. 15
ompt_get_record_ompt runtime entry point, see Section 4.6.2.12 on page 529. 16
ompt_get_record_native runtime entry point, see Section 4.6.2.13 on page 530. 17
ompt_get_record_abstract runtime entry point, see Section 4.6.2.14 on page 531. 18
4.3 Finalizing a First-Party Tool 19
If the OMPT interface state is active, the tool ﬁnalizer, which has type signature 20
ompt_finalize_t and is speciﬁed by the ﬁnalizeﬁeld in the 21
ompt_start_tool_result_t structure returned from the ompt_start_tool function, is 22
called when the OpenMP implementation shuts down. 23
Cross References 24
ompt_finalize_t callback type, see Section 4.5.1.2 on page 458 25
432 OpenMP API – Version 5.0 November 2018
4.4 OMPT Data Types1
The C/C++ header ﬁle (omp-tools.h) provides the deﬁnitions of the types that are speciﬁed 2
throughout this subsection. 3
4.4.1 Tool Initialization and Finalization4
Summary 5
A tool’s implementation of ompt_start_tool returns a pointer to an 6
ompt_start_tool_result_t structure, which contains pointers to the tool’s initialization 7
and ﬁnalization callbacks as well as an ompt_data_t object for use by the tool. 8
Format 9
C / C++
typedef struct ompt_start_tool_result_t { 10
ompt_initialize_t initialize ; 11
ompt_finalize_t ﬁnalize ; 12
ompt_data_t tool_data ; 13
} ompt_start_tool_result_t; 14
C / C++
Restrictions 15
Theompt_start_tool_result_t type has the following restriction: 16
Theinitialize andﬁnalizecallback pointer values in an ompt_start_tool_result_t 17
structure that ompt_start_tool returns must be non-null. 18
Cross References 19
ompt_start_tool function, see Section 4.2.1 on page 420. 20
ompt_data_t type, see Section 4.4.4.4 on page 440. 21
ompt_initialize_t callback type, see Section 4.5.1.1 on page 457. 22
ompt_finalize_t callback type, see Section 4.5.1.2 on page 458. 23
CHAPTER 4. OMPT INTERFACE 433
4.4.2 Callbacks1
Summary 2
Theompt_callbacks_t enumerationtypeindicatestheintegercodesusedtoidentifyOpenMP 3
callbacks when registering or querying them. 4
Format 5
C / C++
typedef enum ompt_callbacks_t { 6
ompt_callback_thread_begin = 1, 7
ompt_callback_thread_end = 2, 8
ompt_callback_parallel_begin = 3, 9
ompt_callback_parallel_end = 4, 10
ompt_callback_task_create = 5, 11
ompt_callback_task_schedule = 6, 12
ompt_callback_implicit_task = 7, 13
ompt_callback_target = 8, 14
ompt_callback_target_data_op = 9, 15
ompt_callback_target_submit = 10, 16
ompt_callback_control_tool = 11, 17
ompt_callback_device_initialize = 12, 18
ompt_callback_device_finalize = 13, 19
ompt_callback_device_load = 14, 20
ompt_callback_device_unload = 15, 21
ompt_callback_sync_region_wait = 16, 22
ompt_callback_mutex_released = 17, 23
ompt_callback_dependences = 18, 24
ompt_callback_task_dependence = 19, 25
ompt_callback_work = 20, 26
ompt_callback_master = 21, 27
ompt_callback_target_map = 22, 28
ompt_callback_sync_region = 23, 29
ompt_callback_lock_init = 24, 30
ompt_callback_lock_destroy = 25, 31
ompt_callback_mutex_acquire = 26, 32
ompt_callback_mutex_acquired = 27, 33
ompt_callback_nest_lock = 28, 34
ompt_callback_flush = 29, 35
ompt_callback_cancel = 30, 36
ompt_callback_reduction = 31, 37
ompt_callback_dispatch = 32 38
} ompt_callbacks_t; 39
C / C++
434 OpenMP API – Version 5.0 November 2018
4.4.3 Tracing1
OpenMP provides type deﬁnitions that support tracing with OMPT. 2
4.4.3.1 Record Type3
Summary 4
Theompt_record_t enumeration type indicates the integer codes used to identify OpenMP 5
trace record formats. 6
Format 7
C / C++
typedef enum ompt_record_t { 8
ompt_record_ompt = 1, 9
ompt_record_native = 2, 10
ompt_record_invalid = 3 11
} ompt_record_t; 12
C / C++
4.4.3.2 Native Record Kind 13
Summary 14
Theompt_record_native_t enumeration type indicates the integer codes used to identify 15
OpenMP native trace record contents. 16
Format 17
C / C++
typedef enum ompt_record_native_t { 18
ompt_record_native_info = 1, 19
ompt_record_native_event = 2 20
} ompt_record_native_t; 21
C / C++
CHAPTER 4. OMPT INTERFACE 435
4.4.3.3 Native Record Abstract Type1
Summary 2
Theompt_record_abstract_t type provides an abstract trace record format that is used to 3
summarize native device trace records. 4
Format 5
C / C++
typedef struct ompt_record_abstract_t { 6
ompt_record_native_t rclass ; 7
const char *type; 8
ompt_device_time_t start_time ; 9
ompt_device_time_t end_time ; 10
ompt_hwid_t hwid; 11
} ompt_record_abstract_t; 12
C / C++
Description 13
Anompt_record_abstract_t record contains information that a tool can use to process a 14
native record that it may not fully understand. The rclassﬁeld indicates that the record is 15
informational or that it represents an event; this information can help a tool determine how to 16
present the record. The record typeﬁeld points to a statically-allocated, immutable character string 17
that provides a meaningful name that a tool can use to describe the event to a user. The start_time 18
andend_time ﬁelds are used to place an event in time. The times are relative to the device clock. If 19
an event does not have an associated start_time (end_time), the value of the start_time (end_time) 20
ﬁeld is ompt_time_none . The hardware identiﬁer ﬁeld, hwid, indicates the location on the 21
device where the event occurred. A hwidmay represent a hardware abstraction such as a core or a 22
hardware thread identiﬁer. The meaning of a hwidvalue for a device is implementation deﬁned. If 23
nohardwareabstractionisassociatedwiththerecordthenthevalueof hwidisompt_hwid_none . 24
4.4.3.4 Record Type 25
Summary 26
Theompt_record_ompt_t type provides an standard complete trace record format. 27
436 OpenMP API – Version 5.0 November 2018
Format 1
C / C++
typedef struct ompt_record_ompt_t { 2
ompt_callbacks_t type; 3
ompt_device_time_t time; 4
ompt_id_t thread_id ; 5
ompt_id_t target_id ; 6
union { 7
ompt_record_thread_begin_t thread_begin ; 8
ompt_record_parallel_begin_t parallel_begin ; 9
ompt_record_parallel_end_t parallel_end ; 10
ompt_record_work_t work; 11
ompt_record_dispatch_t dispatch ; 12
ompt_record_task_create_t task_create ; 13
ompt_record_dependences_t dependences ; 14
ompt_record_task_dependence_t task_dependence ; 15
ompt_record_task_schedule_t task_schedule ; 16
ompt_record_implicit_task_t implicit_task ; 17
ompt_record_master_t master ; 18
ompt_record_sync_region_t sync_region ; 19
ompt_record_mutex_acquire_t mutex_acquire ; 20
ompt_record_mutex_t mutex ; 21
ompt_record_nest_lock_t nest_lock ; 22
ompt_record_flush_t ﬂush; 23
ompt_record_cancel_t cancel ; 24
ompt_record_target_t target ; 25
ompt_record_target_data_op_t target_data_op ; 26
ompt_record_target_map_t target_map ; 27
ompt_record_target_kernel_t target_kernel ; 28
ompt_record_control_tool_t control_tool ; 29
}record ; 30
} ompt_record_ompt_t; 31
C / C++
Description 32
The ﬁeld typespeciﬁes the type of record provided by this structure. According to the type, event 33
speciﬁc information is stored in the matching recordentry. 34
Restrictions 35
Theompt_record_ompt_t type has the following restriction: 36
Iftypeis set to ompt_callback_thread_end_t then the value of recordis undeﬁned. 37
CHAPTER 4. OMPT INTERFACE 437
4.4.4 Miscellaneous Type Deﬁnitions1
This section describes miscellaneous types and enumerations used by the tool interface. 2
4.4.4.1 ompt_callback_t 3
Summary 4
Pointers to tool callback functions with diﬀerent type signatures are passed to the 5
ompt_set_callback runtime entry point and returned by the ompt_get_callback 6
runtime entry point. For convenience, these runtime entry points expect all type signatures to be 7
cast to a dummy type ompt_callback_t . 8
Format 9
C / C++
typedef void ( *ompt_callback_t) (void); 10
C / C++
4.4.4.2 ompt_set_result_t 11
Summary 12
Theompt_result_t enumeration type corresponds to values that the ompt_set_callback , 13
ompt_set_trace_ompt andompt_set_trace_native runtime entry points return. 14
Format 15
C / C++
typedef enum ompt_set_result_t { 16
ompt_set_error = 0, 17
ompt_set_never = 1, 18
ompt_set_impossible = 2, 19
ompt_set_sometimes = 3, 20
ompt_set_sometimes_paired = 4, 21
ompt_set_always = 5 22
} ompt_set_result_t; 23
C / C++
438 OpenMP API – Version 5.0 November 2018
Description 1
Values of ompt_set_result_t , may indicate several possible outcomes. The 2
omp_set_error value indicates that the associated call failed. Otherwise, the value indicates 3
when an event may occur and, when appropriate, dispatching a callback event leads to the 4
invocation of the callback. The ompt_set_never value indicates that the event will never occur 5
or that the callback will never be invoked at runtime. The ompt_set_impossible value 6
indicates that the event may occur but that tracing of it is not possible. The 7
ompt_set_sometimes value indicates that the event may occur and, for an 8
implementation-deﬁned subset of associated event occurrences, will be traced or the callback will 9
be invoked at runtime. The ompt_set_sometimes_paired value indicates the same result as 10
ompt_set_sometimes and, in addition, that a callback with an endpoint value of 11
ompt_scope_begin will be invoked if and only if the same callback with an endpoint value of 12
ompt_scope_end will also be invoked sometime in the future. The ompt_set_always value 13
indicatesthat,wheneveranassociatedeventoccurs,itwillbetracedorthecallbackwillbeinvoked. 14
Cross References 15
Monitoring activity on the host with OMPT, see Section 4.2.4 on page 425. 16
Tracing activity on target devices with OMPT, see Section 4.2.5 on page 427. 17
ompt_set_callback runtime entry point, see Section 4.6.1.3 on page 500. 18
ompt_set_trace_ompt runtime entry point, see Section 4.6.2.4 on page 521. 19
ompt_set_trace_native runtime entry point, see Section 4.6.2.5 on page 522. 20
4.4.4.3 ompt_id_t 21
Summary 22
Theompt_id_t type is used to provide various identiﬁers to tools. 23
Format 24
C / C++
typedef uint64_t ompt_id_t; 25
C / C++
CHAPTER 4. OMPT INTERFACE 439
Description 1
When tracing asynchronous activity on devices, identiﬁers enable tools to correlate target regions 2
and operations that the host initiates with associated activities on a target device. In addition, 3
OMPT provides identiﬁers to refer to parallel regions and tasks that execute on a device. These 4
various identiﬁers are of type ompt_id_t . 5
ompt_id_none is deﬁned as an instance of type ompt_id_t with the value 0. 6
Restrictions 7
Theompt_id_t type has the following restriction: 8
Identiﬁers created on each device must be unique from the time an OpenMP implementation is 9
initialized until it is shut down. Identiﬁers for each target region and target operation instance 10
thatthehostdeviceinitiatesmustbeuniqueovertimeonthehost. Identiﬁersforparallelandtask 11
region instances that execute on a device must be unique over time within that device. 12
4.4.4.4 ompt_data_t 13
Summary 14
Theompt_data_t typerepresentsdataassociatedwiththreadsandwithparallelandtaskregions. 15
Format 16
C / C++
typedef union ompt_data_t { 17
uint64_t value; 18
void *ptr; 19
} ompt_data_t; 20
C / C++
Description 21
Theompt_data_t type represents data that is reserved for tool use and that is related to a thread 22
or to a parallel or task region. When an OpenMP implementation creates a thread or an instance of 23
a parallel or task region, it initializes the associated ompt_data_t object with the value 24
ompt_data_none , which is an instance of the type with the data and pointer ﬁelds equal to 0. 25
440 OpenMP API – Version 5.0 November 2018
4.4.4.5 ompt_device_t 1
Summary 2
Theompt_device_t opaque object type represents a device. 3
Format 4
C / C++
typedef void ompt_device_t; 5
C / C++
4.4.4.6 ompt_device_time_t 6
Summary 7
Theompt_device_time_t type represents raw device time values. 8
Format 9
C / C++
typedef uint64_t ompt_device_time_t; 10
C / C++
Description 11
Theompt_device_time_t opaque object type represents raw device time values. 12
ompt_time_none refers to an unknown or unspeciﬁed time and is deﬁned as an instance of type 13
ompt_device_time_t with the value 0. 14
4.4.4.7 ompt_buffer_t 15
Summary 16
Theompt_buffer_t opaque object type is a handle for a target buﬀer. 17
Format 18
C / C++
typedef void ompt_buffer_t; 19
C / C++
CHAPTER 4. OMPT INTERFACE 441
4.4.4.8 ompt_buffer_cursor_t 1
Summary 2
Theompt_buffer_cursor_t opaque type is a handle for a position in a target buﬀer. 3
Format 4
C / C++
typedef uint64_t ompt_buffer_cursor_t; 5
C / C++
4.4.4.9 ompt_dependence_t 6
Summary 7
Theompt_dependence_t type represents a task dependence. 8
Format 9
C / C++
typedef struct ompt_dependence_t { 10
ompt_data_t variable ; 11
ompt_dependence_type_t dependence_type ; 12
} ompt_dependence_t; 13
C / C++
Description 14
Theompt_dependence_t type is a structure that holds information about a depend clause. For 15
task dependences, the variableﬁeld points to the storage location of the dependence. For doacross 16
dependences, the variableﬁeld contains the value of a vector element that describes the 17
dependence. The dependence_type ﬁeld indicates the type of the dependence. 18
Cross References 19
ompt_dependence_type_t type, see Section 4.4.4.23 on page 450. 20
442 OpenMP API – Version 5.0 November 2018
4.4.4.10 ompt_thread_t 1
Summary 2
Theompt_thread_t enumeration type deﬁnes the valid thread type values. 3
Format 4
C / C++
typedef enum ompt_thread_t { 5
ompt_thread_initial = 1, 6
ompt_thread_worker = 2, 7
ompt_thread_other = 3, 8
ompt_thread_unknown = 4 9
} ompt_thread_t; 10
C / C++
Description 11
Anyinitial thread has thread type ompt_thread_initial . AllOpenMP threads that are not 12
initial threads have thread type ompt_thread_worker . A thread that an OpenMP 13
implementation uses but that does not execute user code has thread type ompt_thread_other . 14
Any thread that is created outside an OpenMP implementation and that is not an initial thread has 15
thread type ompt_thread_unknown . 16
4.4.4.11 ompt_scope_endpoint_t 17
Summary 18
Theompt_scope_endpoint_t enumeration type deﬁnes valid scope endpoint values. 19
Format 20
C / C++
typedef enum ompt_scope_endpoint_t { 21
ompt_scope_begin = 1, 22
ompt_scope_end = 2 23
} ompt_scope_endpoint_t; 24
C / C++
CHAPTER 4. OMPT INTERFACE 443
4.4.4.12 ompt_dispatch_t 1
Summary 2
Theompt_dispatch_t enumeration type deﬁnes the valid dispatch kind values. 3
Format 4
C / C++
typedef enum ompt_dispatch_t { 5
ompt_dispatch_iteration = 1, 6
ompt_dispatch_section = 2 7
} ompt_dispatch_t; 8
C / C++
4.4.4.13 ompt_sync_region_t 9
Summary 10
Theompt_sync_region_t enumeration type deﬁnes the valid synchronization region kind 11
values. 12
Format 13
C / C++
typedef enum ompt_sync_region_t { 14
ompt_sync_region_barrier = 1, 15
ompt_sync_region_barrier_implicit = 2, 16
ompt_sync_region_barrier_explicit = 3, 17
ompt_sync_region_barrier_implementation = 4, 18
ompt_sync_region_taskwait = 5, 19
ompt_sync_region_taskgroup = 6, 20
ompt_sync_region_reduction = 7 21
} ompt_sync_region_t; 22
C / C++
4.4.4.14 ompt_target_data_op_t 23
Summary 24
Theompt_target_data_op_t enumerationtypedeﬁnesthevalidtargetdataoperationvalues. 25
444 OpenMP API – Version 5.0 November 2018
Format 1
C / C++
typedef enum ompt_target_data_op_t { 2
ompt_target_data_alloc = 1, 3
ompt_target_data_transfer_to_device = 2, 4
ompt_target_data_transfer_from_device = 3, 5
ompt_target_data_delete = 4, 6
ompt_target_data_associate = 5, 7
ompt_target_data_disassociate = 6 8
} ompt_target_data_op_t; 9
C / C++
4.4.4.15 ompt_work_t 10
Summary 11
Theompt_work_t enumeration type deﬁnes the valid work type values. 12
Format 13
C / C++
typedef enum ompt_work_t { 14
ompt_work_loop = 1, 15
ompt_work_sections = 2, 16
ompt_work_single_executor = 3, 17
ompt_work_single_other = 4, 18
ompt_work_workshare = 5, 19
ompt_work_distribute = 6, 20
ompt_work_taskloop = 7 21
} ompt_work_t; 22
C / C++
4.4.4.16 ompt_mutex_t 23
Summary 24
Theompt_mutex_t enumeration type deﬁnes the valid mutex kind values. 25
CHAPTER 4. OMPT INTERFACE 445
Format 1
C / C++
typedef enum ompt_mutex_t { 2
ompt_mutex_lock = 1, 3
ompt_mutex_test_lock = 2, 4
ompt_mutex_nest_lock = 3, 5
ompt_mutex_test_nest_lock = 4, 6
ompt_mutex_critical = 5, 7
ompt_mutex_atomic = 6, 8
ompt_mutex_ordered = 7 9
} ompt_mutex_t; 10
C / C++
4.4.4.17 ompt_native_mon_flag_t 11
Summary 12
Theompt_native_mon_flag_t enumeration type deﬁnes the valid native monitoring ﬂag 13
values. 14
Format 15
C / C++
typedef enum ompt_native_mon_flag_t { 16
ompt_native_data_motion_explicit = 0x01, 17
ompt_native_data_motion_implicit = 0x02, 18
ompt_native_kernel_invocation = 0x04, 19
ompt_native_kernel_execution = 0x08, 20
ompt_native_driver = 0x10, 21
ompt_native_runtime = 0x20, 22
ompt_native_overhead = 0x40, 23
ompt_native_idleness = 0x80 24
} ompt_native_mon_flag_t; 25
C / C++
4.4.4.18 ompt_task_flag_t 26
Summary 27
Theompt_task_flag_t enumeration type deﬁnes valid task types. 28
446 OpenMP API – Version 5.0 November 2018
Format 1
C / C++
typedef enum ompt_task_flag_t { 2
ompt_task_initial = 0x00000001, 3
ompt_task_implicit = 0x00000002, 4
ompt_task_explicit = 0x00000004, 5
ompt_task_target = 0x00000008, 6
ompt_task_undeferred = 0x08000000, 7
ompt_task_untied = 0x10000000, 8
ompt_task_final = 0x20000000, 9
ompt_task_mergeable = 0x40000000, 10
ompt_task_merged = 0x80000000 11
} ompt_task_flag_t; 12
C / C++
Description 13
Theompt_task_flag_t enumeration type deﬁnes valid task type values. The least signiﬁcant 14
byte provides information about the general classiﬁcation of the task. The other bits represent 15
properties of the task. 16
4.4.4.19 ompt_task_status_t 17
Summary 18
Theompt_task_status_t enumeration type indicates the reason that a task was switched 19
when it reached a task scheduling point. 20
Format 21
C / C++
typedef enum ompt_task_status_t { 22
ompt_task_complete = 1, 23
ompt_task_yield = 2, 24
ompt_task_cancel = 3, 25
ompt_task_detach = 4, 26
ompt_task_early_fulfill = 5, 27
ompt_task_late_fulfill = 6, 28
ompt_task_switch = 7 29
} ompt_task_status_t; 30
C / C++
CHAPTER 4. OMPT INTERFACE 447
Description 1
The value ompt_task_complete of the ompt_task_status_t type indicates that the task 2
that encountered the task scheduling point completed execution of the associated structured-block 3
and an associated allow-completion-event was fulﬁlled. The value ompt_task_yield indicates 4
that the task encountered a taskyield construct. The value ompt_task_cancel indicates 5
that the task was canceled when it encountered an active cancellation point. The value 6
ompt_task_detach indicates that a task with detach clause completed execution of the 7
associated structured-block and is waiting for an allow-completion-event to be fulﬁlled. The value 8
ompt_task_early_fulfill indicates that the allow-completion-event of the task is fulﬁlled 9
before the task completed execution of the associated structured-block. The value 10
ompt_task_late_fulfill indicates that the allow-completion-event of the task is fulﬁlled 11
after the task completed execution of the associated structured-block. The value 12
ompt_task_switch is used for all other cases that a task was switched. 13
4.4.4.20 ompt_target_t 14
Summary 15
Theompt_target_t enumeration type deﬁnes the valid target type values. 16
Format 17
C / C++
typedef enum ompt_target_t { 18
ompt_target = 1, 19
ompt_target_enter_data = 2, 20
ompt_target_exit_data = 3, 21
ompt_target_update = 4 22
} ompt_target_t; 23
C / C++
4.4.4.21 ompt_parallel_flag_t 24
Summary 25
Theompt_parallel_flag_t enumeration type deﬁnes valid invoker values. 26
448 OpenMP API – Version 5.0 November 2018
Format 1
C / C++
typedef enum ompt_parallel_flag_t { 2
ompt_parallel_invoker_program = 0x00000001, 3
ompt_parallel_invoker_runtime = 0x00000002, 4
ompt_parallel_league = 0x40000000, 5
ompt_parallel_team = 0x80000000 6
} ompt_parallel_flag_t; 7
C / C++
Description 8
Theompt_parallel_flag_t enumeration type deﬁnes valid invoker values, which indicate 9
how an outlined function is invoked. 10
The value ompt_parallel_invoker_program indicates that the outlined function 11
associated with implicit tasks for the region is invoked directly by the application on the master 12
thread for a parallel region. 13
The value ompt_parallel_invoker_runtime indicates that the outlined function 14
associated with implicit tasks for the region is invoked by the runtime on the master thread for a 15
parallel region. 16
Thevalue ompt_parallel_league indicatesthatthecallbackisinvokedduetothecreationof 17
a league of teams by a teamsconstruct. 18
The value ompt_parallel_team indicates that the callback is invoked due to the creation of a 19
team of threads by a parallel construct. 20
4.4.4.22 ompt_target_map_flag_t 21
Summary 22
Theompt_target_map_flag_t enumeration type deﬁnes the valid target map ﬂag values. 23
CHAPTER 4. OMPT INTERFACE 449
Format 1
C / C++
typedef enum ompt_target_map_flag_t { 2
ompt_target_map_flag_to = 0x01, 3
ompt_target_map_flag_from = 0x02, 4
ompt_target_map_flag_alloc = 0x04, 5
ompt_target_map_flag_release = 0x08, 6
ompt_target_map_flag_delete = 0x10, 7
ompt_target_map_flag_implicit = 0x20 8
} ompt_target_map_flag_t; 9
C / C++
4.4.4.23 ompt_dependence_type_t 10
Summary 11
Theompt_dependence_type_t enumeration type deﬁnes the valid task dependence type 12
values. 13
Format 14
C / C++
typedef enum ompt_dependence_type_t { 15
ompt_dependence_type_in = 1, 16
ompt_dependence_type_out = 2, 17
ompt_dependence_type_inout = 3, 18
ompt_dependence_type_mutexinoutset = 4, 19
ompt_dependence_type_source = 5, 20
ompt_dependence_type_sink = 6 21
} ompt_dependence_type_t; 22
C / C++
4.4.4.24 ompt_cancel_flag_t 23
Summary 24
Theompt_cancel_flag_t enumeration type deﬁnes the valid cancel ﬂag values. 25
450 OpenMP API – Version 5.0 November 2018
Format 1
C / C++
typedef enum ompt_cancel_flag_t { 2
ompt_cancel_parallel = 0x01, 3
ompt_cancel_sections = 0x02, 4
ompt_cancel_loop = 0x04, 5
ompt_cancel_taskgroup = 0x08, 6
ompt_cancel_activated = 0x10, 7
ompt_cancel_detected = 0x20, 8
ompt_cancel_discarded_task = 0x40 9
} ompt_cancel_flag_t; 10
C / C++
4.4.4.25 ompt_hwid_t 11
Summary 12
Theompt_hwid_t opaque type is a handle for a hardware identiﬁer for a target device. 13
Format 14
C / C++
typedef uint64_t ompt_hwid_t; 15
C / C++
Description 16
Theompt_hwid_t opaque type is a handle for a hardware identiﬁer for a target device. 17
ompt_hwid_none is an instance of the type that refers to an unknown or unspeciﬁed hardware 18
identiﬁer and that has the value 0. If no hwidis associated with an 19
ompt_record_abstract_t then the value of hwidisompt_hwid_none . 20
Cross References 21
ompt_record_abstract_t type, see Section 4.4.3.3 on page 436. 22
CHAPTER 4. OMPT INTERFACE 451
4.4.4.26 ompt_state_t 1
Summary 2
If the OMPT interface is in the activestate then an OpenMP implementation must maintain thread 3
stateinformation for each thread. The thread state maintained is an approximation of the 4
instantaneous state of a thread. 5
Format 6
C / C++
A thread state must be one of the values of the enumeration type ompt_state_t or an 7
implementation-deﬁned state value of 512 or higher. 8
typedef enum ompt_state_t { 9
ompt_state_work_serial = 0x000, 10
ompt_state_work_parallel = 0x001, 11
ompt_state_work_reduction = 0x002, 12
13
ompt_state_wait_barrier = 0x010, 14
ompt_state_wait_barrier_implicit_parallel = 0x011, 15
ompt_state_wait_barrier_implicit_workshare = 0x012, 16
ompt_state_wait_barrier_implicit = 0x013, 17
ompt_state_wait_barrier_explicit = 0x014, 18
19
ompt_state_wait_taskwait = 0x020, 20
ompt_state_wait_taskgroup = 0x021, 21
22
ompt_state_wait_mutex = 0x040, 23
ompt_state_wait_lock = 0x041, 24
ompt_state_wait_critical = 0x042, 25
ompt_state_wait_atomic = 0x043, 26
ompt_state_wait_ordered = 0x044, 27
28
ompt_state_wait_target = 0x080, 29
ompt_state_wait_target_map = 0x081, 30
ompt_state_wait_target_update = 0x082, 31
32
ompt_state_idle = 0x100, 33
ompt_state_overhead = 0x101, 34
ompt_state_undefined = 0x102 35
} ompt_state_t; 36
C / C++
452 OpenMP API – Version 5.0 November 2018
Description 1
AtoolcanquerytheOpenMPstateofathreadatanytime. Ifatoolqueriesthestateofathreadthat 2
is not associated with OpenMP then the implementation reports the state as 3
ompt_state_undefined . 4
The value ompt_state_work_serial indicates that the thread is executing code outside all 5
parallel regions. 6
Thevalue ompt_state_work_parallel indicatesthatthethreadisexecutingcodewithinthe 7
scope of a parallel region. 8
The value ompt_state_work_reduction indicates that the thread is combining partial 9
reduction results from threads in its team. An OpenMP implementation may never report a thread 10
in this state; a thread that is combining partial reduction results may have its state reported as 11
ompt_state_work_parallel orompt_state_overhead . 12
The value ompt_state_wait_barrier indicates that the thread is waiting at either an 13
implicit or explicit barrier. An implementation may never report a thread in this state; instead, a 14
thread may have its state reported as ompt_state_wait_barrier_implicit or 15
ompt_state_wait_barrier_explicit , as appropriate. 16
The value ompt_state_wait_barrier_implicit indicates that the thread is waiting at an 17
implicit barrier in a parallel region. An OpenMP implementation may report 18
ompt_state_wait_barrier for implicit barriers. 19
The value ompt_state_wait_barrier_implicit_parallel indicates that the thread is 20
waiting at an implicit barrier at the end of a parallel region. An OpenMP implementation may 21
report ompt_state_wait_barrier orompt_state_wait_barrier_implicit for 22
these barriers. 23
The value ompt_state_wait_barrier_implicit_workshare indicates that the thread 24
is waiting at an implicit barrier at the end of a worksharing construct. An OpenMP implementation 25
may report ompt_state_wait_barrier orompt_state_wait_barrier_implicit 26
for these barriers. 27
The value ompt_state_wait_barrier_explicit indicates that the thread is waiting in a 28
barrier region. An OpenMP implementation may report ompt_state_wait_barrier for 29
these barriers. 30
The value ompt_state_wait_taskwait indicates that the thread is waiting at a taskwait 31
construct. 32
The value ompt_state_wait_taskgroup indicates that the thread is waiting at the end of a 33
taskgroup construct. 34
The value ompt_state_wait_mutex indicates that the thread is waiting for a mutex of an 35
unspeciﬁed type. 36
CHAPTER 4. OMPT INTERFACE 453
The value ompt_state_wait_lock indicates that the thread is waiting for a lock or nestable 1
lock. 2
The value ompt_state_wait_critical indicates that the thread is waiting to enter a 3
critical region. 4
The value ompt_state_wait_atomic indicates that the thread is waiting to enter an atomic 5
region. 6
The value ompt_state_wait_ordered indicates that the thread is waiting to enter an 7
ordered region. 8
The value ompt_state_wait_target indicates that the thread is waiting for a target 9
region to complete. 10
The value ompt_state_wait_target_map indicates that the thread is waiting for a target 11
data mapping operation to complete. An implementation may report 12
ompt_state_wait_target fortarget data constructs. 13
The value ompt_state_wait_target_update indicates that the thread is waiting for a 14
target update operation to complete. An implementation may report 15
ompt_state_wait_target fortarget update constructs. 16
The value ompt_state_idle indicates that the thread is idle, that is, it is not part of an 17
OpenMP team. 18
The value ompt_state_overhead indicates that the thread is in the overhead state at any point 19
while executing within the OpenMP runtime, except while waiting at a synchronization point. 20
The value ompt_state_undefined indicates that the native thread is not created by the 21
OpenMP implementation. 22
4.4.4.27 ompt_frame_t 23
Summary 24
Theompt_frame_t type describes procedure frame information for an OpenMP task. 25
Format 26
C / C++
typedef struct ompt_frame_t { 27
ompt_data_t exit_frame ; 28
ompt_data_t enter_frame ; 29
intexit_frame_ﬂags ; 30
intenter_frame_ﬂags ; 31
} ompt_frame_t; 32
C / C++
454 OpenMP API – Version 5.0 November 2018
Description 1
Eachompt_frame_t object is associated with the task to which the procedure frames belong. 2
Each non-merged initial, implicit, explicit, or target task with one or more frames on the stack of a 3
native thread has an associated ompt_frame_t object. 4
Theexit_frame ﬁeld of an ompt_frame_t object contains information to identify the ﬁrst 5
procedure frame executing the task region. The exit_frame for the ompt_frame_t object 6
associated with the initial task that is not nested inside any OpenMP construct is NULL. 7
Theenter_frame ﬁeld of an ompt_frame_t object contains information to identify the latest still 8
active procedure frame executing the task region before entering the OpenMP runtime 9
implementation or before executing a diﬀerent task. If a task with frames on the stack has not been 10
suspended, the value of enter_frame for the ompt_frame_t object associated with the task may 11
contain NULL. 12
Forexit_frame , theexit_frame_ﬂags and, forenter_frame , theenter_frame_ﬂags ﬁeld indicates that 13
the provided frame information points to a runtime or an application frame address. The same 14
ﬁelds also specify the kind of information that is provided to identify the frame, These ﬁelds are a 15
disjunction of values in the ompt_frame_flag_t enumeration type. 16
The lifetime of an ompt_frame_t object begins when a task is created and ends when the task is 17
destroyed. Tools should not assume that a frame structure remains at a constant location in memory 18
throughout the lifetime of the task. A pointer to an ompt_frame_t object is passed to some 19
callbacks; a pointer to the ompt_frame_t object of a task can also be retrieved by a tool at any 20
time, including in a signal handler, by invoking the ompt_get_task_info runtime entry point 21
(described in Section 4.6.1.14). A pointer to an ompt_frame_t object that a tool retrieved is 22
valid as long as the tool does not pass back control to the OpenMP implementation. 23
24
Note– A monitoring tool that uses asynchronous sampling can observe values of exit_frame and 25
enter_frame at inconvenient times. Tools must be prepared to handle ompt_frame_t objects 26
observed just prior to when their ﬁeld values will be set or cleared. 27
28
4.4.4.28 ompt_frame_flag_t 29
Summary 30
Theompt_frame_flag_t enumeration type deﬁnes valid frame information ﬂags. 31
CHAPTER 4. OMPT INTERFACE 455
Format 1
C / C++
typedef enum ompt_frame_flag_t { 2
ompt_frame_runtime = 0x00, 3
ompt_frame_application = 0x01, 4
ompt_frame_cfa = 0x10, 5
ompt_frame_framepointer = 0x20, 6
ompt_frame_stackaddress = 0x30 7
} ompt_frame_flag_t; 8
C / C++
Description 9
The value ompt_frame_runtime of the ompt_frame_flag_t type indicates that a frame 10
address is a procedure frame in the OpenMP runtime implementation. The value 11
ompt_frame_application of the ompt_frame_flag_t type indicates that an exit frame 12
address is a procedure frame in the OpenMP application. 13
Higher order bits indicate the kind of provided information that is unique for the particular frame 14
pointer. The value ompt_frame_cfa indicates that a frame address speciﬁes a canonical frame 15
address. The value ompt_frame_framepointer indicates that a frame address provides the 16
value of the frame pointer register. The value ompt_frame_stackaddress indicates that a 17
frame address speciﬁes a pointer address that is contained in the current stack frame. 18
4.4.4.29 ompt_wait_id_t 19
Summary 20
Theompt_wait_id_t type describes wait identiﬁers for an OpenMP thread. 21
Format 22
C / C++
typedef uint64_t ompt_wait_id_t; 23
C / C++
456 OpenMP API – Version 5.0 November 2018
Description 1
Each thread maintains a wait identiﬁer of type ompt_wait_id_t . When a task that a thread 2
executes is waiting for mutual exclusion, the wait identiﬁer of the thread indicates the reason that 3
the thread is waiting. A wait identiﬁer may represent a critical section name, a lock, a program 4
variable accessed in an atomic region, or a synchronization object that is internal to an OpenMP 5
implementation. When a thread is not in a wait state then the value of the wait identiﬁer of the 6
thread is undeﬁned. 7
ompt_wait_id_none is deﬁned as an instance of type ompt_wait_id_t with the value 0. 8
4.5 OMPT Tool Callback Signatures and Trace Records9
The C/C++ header ﬁle (omp-tools.h) provides the deﬁnitions of the types that are speciﬁed 10
throughout this subsection. 11
Restrictions 12
Tool callbacks may not use OpenMP directives or call any runtime library routines described in 13
Section 3. 14
4.5.1 Initialization and Finalization Callback Signature 15
4.5.1.1 ompt_initialize_t 16
Summary 17
A callback with type signature ompt_initialize_t initializes use of the OMPT interface. 18
Format 19
C / C++
typedef int ( *ompt_initialize_t) ( 20
ompt_function_lookup_t lookup , 21
intinitial_device_num , 22
ompt_data_t *tool_data 23
); 24
C / C++
CHAPTER 4. OMPT INTERFACE 457
Description 1
To use the OMPT interface, an implementation of ompt_start_tool must return a non-null 2
pointer to an ompt_start_tool_result_t structure that contains a non-null pointer to a tool 3
initializer with type signature ompt_initialize_t . An OpenMP implementation will call the 4
initializer after fully initializing itself but before beginning execution of any OpenMP construct or 5
completing execution of any environment routine invocation. 6
The initializer returns a non-zero value if it succeeds. 7
Description of Arguments 8
Thelookupargument is a callback to an OpenMP runtime routine that must be used to obtain a 9
pointer to each runtime entry point in the OMPT interface. The initial_device_num argument 10
provides the value of omp_get_initial_device() . Thetool_data argument is a pointer to 11
thetool_data ﬁeld in the ompt_start_tool_result_t structure that ompt_start_tool 12
returned. The expected actions of an initializer are described in Section 4.2.3. 13
Cross References 14
omp_get_initial_device routine, see Section 3.2.41 on page 376. 15
ompt_start_tool function, see Section 4.2.1 on page 420. 16
ompt_start_tool_result_t type, see Section 4.4.1 on page 433. 17
ompt_data_t type, see Section 4.4.4.4 on page 440. 18
ompt_function_lookup_t type, see Section 4.6.3 on page 531. 19
4.5.1.2 ompt_finalize_t 20
Summary 21
A tool implements a ﬁnalizer with the type signature ompt_finalize_t to ﬁnalize the tool’s 22
use of the OMPT interface. 23
Format 24
C / C++
typedef void ( *ompt_finalize_t) ( 25
ompt_data_t *tool_data 26
); 27
C / C++
458 OpenMP API – Version 5.0 November 2018
Description 1
To use the OMPT interface, an implementation of ompt_start_tool must return a non-null 2
pointer to an ompt_start_tool_result_t structure that contains a non-null pointer to a tool 3
ﬁnalizer with type signature ompt_finalize_t . An OpenMP implementation will call the tool 4
ﬁnalizer after the last OMPT eventas the OpenMP implementation shuts down. 5
Description of Arguments 6
Thetool_data argument is a pointer to the tool_data ﬁeld in the 7
ompt_start_tool_result_t structure returned by ompt_start_tool . 8
Cross References 9
ompt_start_tool function, see Section 4.2.1 on page 420. 10
ompt_start_tool_result_t type, see Section 4.4.1 on page 433. 11
ompt_data_t type, see Section 4.4.4.4 on page 440. 12
4.5.2 Event Callback Signatures and Trace Records 13
This section describes the signatures of tool callback functions that an OMPT tool may register and 14
thatarecalledduringruntimeofanOpenMPprogram. Animplementationmayalsoprovideatrace 15
ofeventsperdevice. Alongwiththecallbacks,thefollowingdeﬁnesstandardtracerecords. Forthe 16
trace records, tool data arguments are replaced by an ID, which must be initialized by the OpenMP 17
implementation. Each of parallel_id ,task_id, andthread_id must be unique per target region. Tool 18
implementations of callbacks are not required to be async signal safe . 19
Cross References 20
ompt_id_t type, see Section 4.4.4.3 on page 439. 21
ompt_data_t type, see Section 4.4.4.4 on page 440. 22
4.5.2.1 ompt_callback_thread_begin_t 23
Summary 24
Theompt_callback_thread_begin_t type is used for callbacks that are dispatched when 25
native threads are created. 26
CHAPTER 4. OMPT INTERFACE 459
Format 1
C / C++
typedef void ( *ompt_callback_thread_begin_t) ( 2
ompt_thread_t thread_type , 3
ompt_data_t *thread_data 4
); 5
C / C++
Trace Record 6
C / C++
typedef struct ompt_record_thread_begin_t { 7
ompt_thread_t thread_type ; 8
} ompt_record_thread_begin_t; 9
C / C++
Description of Arguments 10
Thethread_type argument indicates the type of the new thread: initial, worker, or other. The 11
binding of the thread_data argument is the new thread. 12
Cross References 13
parallel construct, see Section 2.6 on page 74. 14
teamsconstruct, see Section 2.7 on page 82. 15
Initial task, see Section 2.10.5 on page 148. 16
ompt_data_t type, see Section 4.4.4.4 on page 440. 17
ompt_thread_t type, see Section 4.4.4.10 on page 443. 18
4.5.2.2 ompt_callback_thread_end_t 19
Summary 20
Theompt_callback_thread_end_t type is used for callbacks that are dispatched when 21
native threads are destroyed. 22
460 OpenMP API – Version 5.0 November 2018
Format 1
C / C++
typedef void ( *ompt_callback_thread_end_t) ( 2
ompt_data_t *thread_data 3
); 4
C / C++
Description of Arguments 5
The binding of the thread_data argument is the thread that will be destroyed. 6
Cross References 7
parallel construct, see Section 2.6 on page 74. 8
teamsconstruct, see Section 2.7 on page 82. 9
Initial task, see Section 2.10.5 on page 148. 10
ompt_record_ompt_t type, see Section 4.4.3.4 on page 436. 11
ompt_data_t type, see Section 4.4.4.4 on page 440. 12
4.5.2.3 ompt_callback_parallel_begin_t 13
Summary 14
Theompt_callback_parallel_begin_t type is used for callbacks that are dispatched 15
when parallel andteamsregions start. 16
Format 17
C / C++
typedef void ( *ompt_callback_parallel_begin_t) ( 18
ompt_data_t *encountering_task_data , 19
const ompt_frame_t *encountering_task_frame , 20
ompt_data_t *parallel_data , 21
unsigned int requested_parallelism , 22
intﬂags, 23
const void *codeptr_ra 24
); 25
C / C++
CHAPTER 4. OMPT INTERFACE 461
Trace Record 1
C / C++
typedef struct ompt_record_parallel_begin_t { 2
ompt_id_t encountering_task_id ; 3
ompt_id_t parallel_id ; 4
unsigned int requested_parallelism ; 5
intﬂags; 6
const void *codeptr_ra ; 7
} ompt_record_parallel_begin_t; 8
C / C++
Description of Arguments 9
The binding of the encountering_task_data argument is the encountering task. 10
Theencountering_task_frame argument points to the frame object that is associated with the 11
encountering task. 12
The binding of the parallel_data argument is the parallel orteamsregion that is beginning. 13
Therequested_parallelism argument indicates the number of threads or teams that the user 14
requested. 15
Theﬂagsargument indicates whether the code for the region is inlined into the application or 16
invokedbytheruntimeandalsowhethertheregionisa parallel orteamsregion. Validvalues 17
forﬂagsare a disjunction of elements in the enum ompt_parallel_flag_t . 18
Thecodeptr_ra argument relates the implementation of an OpenMP region to its source code. If a 19
runtime routine implements the region associated with a callback that has type signature 20
ompt_callback_parallel_begin_t thencodeptr_ra containsthereturnaddressofthecall 21
to that runtime routine. If the implementation the region is inlined then codeptr_ra contains the 22
return address of the invocation of the callback. If attribution to source code is impossible or 23
inappropriate, codeptr_ra may be NULL. 24
Cross References 25
parallel construct, see Section 2.6 on page 74. 26
teamsconstruct, see Section 2.7 on page 82. 27
ompt_data_t type, see Section 4.4.4.4 on page 440. 28
ompt_parallel_flag_t type, see Section 4.4.4.21 on page 448. 29
ompt_frame_t type, see Section 4.4.4.27 on page 454. 30
462 OpenMP API – Version 5.0 November 2018
4.5.2.4 ompt_callback_parallel_end_t 1
Summary 2
Theompt_callback_parallel_end_t type is used for callbacks that are dispatched when 3
parallel andteamsregions ends. 4
Format 5
C / C++
typedef void ( *ompt_callback_parallel_end_t) ( 6
ompt_data_t *parallel_data , 7
ompt_data_t *encountering_task_data , 8
intﬂags, 9
const void *codeptr_ra 10
); 11
C / C++
Trace Record 12
C / C++
typedef struct ompt_record_parallel_end_t { 13
ompt_id_t parallel_id ; 14
ompt_id_t encountering_task_id ; 15
intﬂags; 16
const void *codeptr_ra ; 17
} ompt_record_parallel_end_t; 18
C / C++
Description of Arguments 19
The binding of the parallel_data argument is the parallel orteamsregion that is ending. 20
The binding of the encountering_task_data argument is the encountering task. 21
Theﬂagsargument indicates whether the execution of the region is inlined into the application or 22
invokedbytheruntimeandalsowhetheritisa parallel orteamsregion. Valuesfor ﬂagsarea 23
disjunction of elements in the enum ompt_parallel_flag_t . 24
Thecodeptr_ra argument relates the implementation of an OpenMP region to its source code. If a 25
runtime routine implements the region associated with a callback that has type signature 26
ompt_callback_parallel_end_t thencodeptr_ra contains the return address of the call to 27
that runtime routine. If the implementation of the region is inlined then codeptr_ra contains the 28
return address of the invocation of the callback. If attribution to source code is impossible or 29
inappropriate, codeptr_ra may be NULL. 30
CHAPTER 4. OMPT INTERFACE 463
Cross References 1
parallel construct, see Section 2.6 on page 74. 2
teamsconstruct, see Section 2.7 on page 82. 3
ompt_data_t type, see Section 4.4.4.4 on page 440. 4
ompt_parallel_flag_t type, see Section 4.4.4.21 on page 448. 5
4.5.2.5 ompt_callback_work_t 6
Summary 7
Theompt_callback_work_t type is used for callbacks that are dispatched when worksharing 8
regions, loop-related regions, and taskloop regions begin and end. 9
Format 10
C / C++
typedef void ( *ompt_callback_work_t) ( 11
ompt_work_t wstype , 12
ompt_scope_endpoint_t endpoint , 13
ompt_data_t *parallel_data , 14
ompt_data_t *task_data , 15
uint64_t count, 16
const void *codeptr_ra 17
); 18
C / C++
Trace Record 19
C / C++
typedef struct ompt_record_work_t { 20
ompt_work_t wstype ; 21
ompt_scope_endpoint_t endpoint ; 22
ompt_id_t parallel_id ; 23
ompt_id_t task_id ; 24
uint64_t count; 25
const void *codeptr_ra ; 26
} ompt_record_work_t; 27
C / C++
464 OpenMP API – Version 5.0 November 2018
Description of Arguments 1
Thewstypeargument indicates the kind of region. 2
Theendpoint argument indicates that the callback signals the beginning of a scope or the end of a 3
scope. 4
The binding of the parallel_data argument is the current parallel region. 5
The binding of the task_data argument is the current task. 6
Thecountargument is a measure of the quantity of work involved in the construct. For a 7
worksharing-loop construct, countrepresents the number of iterations of the loop. For a 8
taskloop construct, countrepresents the number of iterations in the iteration space, which may 9
be the result of collapsing several associated loops. For a sections construct, countrepresents 10
thenumberofsections. Fora workshare construct, countrepresentstheunitsofwork,asdeﬁned 11
by the workshare construct. For a single construct, countis always 1. When the endpoint 12
argument signals the end of a scope, a countvalue of 0 indicates that the actual countvalue is not 13
available. 14
Thecodeptr_ra argument relates the implementation of an OpenMP region to its source code. If a 15
runtime routine implements the region associated with a callback that has type signature 16
ompt_callback_work_t thencodeptr_ra contains the return address of the call to that 17
runtime routine. If the implementation of the region is inlined then codeptr_ra contains the return 18
address of the invocation of the callback. If attribution to source code is impossible or 19
inappropriate, codeptr_ra may be NULL. 20
Cross References 21
Worksharing constructs, see Section 2.8 on page 86 and Section 2.9.2 on page 101. 22
Loop-related constructs, see Section 2.9 on page 95. 23
taskloop construct, see Section 2.10.2 on page 140. 24
ompt_data_t type, see Section 4.4.4.4 on page 440. 25
ompt_scope_endpoint_t type, see Section 4.4.4.11 on page 443. 26
ompt_work_t type, see Section 4.4.4.15 on page 445. 27
4.5.2.6 ompt_callback_dispatch_t 28
Summary 29
Theompt_callback_dispatch_t type is used for callbacks that are dispatched when a 30
thread begins to execute a section or loop iteration. 31
CHAPTER 4. OMPT INTERFACE 465
Format 1
C / C++
typedef void ( *ompt_callback_dispatch_t) ( 2
ompt_data_t *parallel_data , 3
ompt_data_t *task_data , 4
ompt_dispatch_t kind, 5
ompt_data_t instance 6
); 7
C / C++
Trace Record 8
C / C++
typedef struct ompt_record_dispatch_t { 9
ompt_id_t parallel_id ; 10
ompt_id_t task_id ; 11
ompt_dispatch_t kind; 12
ompt_data_t instance ; 13
} ompt_record_dispatch_t; 14
C / C++
Description of Arguments 15
The binding of the parallel_data argument is the current parallel region. 16
The binding of the task_data argument is the implicit task that executes the structured block of the 17
parallel region. 18
Thekindargument indicates whether a loop iteration or a section is being dispatched. 19
For a loop iteration, the instance.value argument contains the iteration variable value. For a 20
structured block in the sections construct, instance.ptr contains a code address that identiﬁes 21
the structured block. In cases where a runtime routine implements the structured block associated 22
with this callback, instance.ptr contains the return address of the call to the runtime routine. In 23
cases where the implementation of the structured block is inlined, instance.ptr contains the return 24
address of the invocation of this callback. 25
466 OpenMP API – Version 5.0 November 2018
Cross References 1
sections andsection constructs, see Section 2.8.1 on page 86. 2
Worksharing-loop construct, see Section 2.9.2 on page 101. 3
taskloop construct, see Section 2.10.2 on page 140. 4
ompt_data_t type, see Section 4.4.4.4 on page 440. 5
ompt_dispatch_t type, see Section 4.4.4.12 on page 444. 6
4.5.2.7 ompt_callback_task_create_t 7
Summary 8
Theompt_callback_task_create_t type is used for callbacks that are dispatched when 9
taskregions or initial tasks are generated. 10
Format 11
C / C++
typedef void ( *ompt_callback_task_create_t) ( 12
ompt_data_t *encountering_task_data , 13
const ompt_frame_t *encountering_task_frame , 14
ompt_data_t *new_task_data , 15
intﬂags, 16
inthas_dependences , 17
const void *codeptr_ra 18
); 19
C / C++
Trace Record 20
C / C++
typedef struct ompt_record_task_create_t { 21
ompt_id_t encountering_task_id ; 22
ompt_id_t new_task_id ; 23
intﬂags; 24
inthas_dependences ; 25
const void *codeptr_ra ; 26
} ompt_record_task_create_t; 27
C / C++
CHAPTER 4. OMPT INTERFACE 467
Description of Arguments 1
The binding of the encountering_task_data argument is the encountering task. This argument is 2
NULLfor an initial task. 3
Theencountering_task_frame argumentpointstotheframeobjectassociatedwiththeencountering 4
task. This argument is NULLfor an initial task. 5
The binding of the new_task_data argument is the generated task. 6
Theﬂagsargument indicates the kind of the task (initial, explicit, or target) that is generated. 7
Values for ﬂagsare a disjunction of elements in the ompt_task_flag_t enumeration type. 8
Thehas_dependences argument is trueif the generated task has dependences and falseotherwise. 9
Thecodeptr_ra argument relates the implementation of an OpenMP region to its source code. If a 10
runtime routine implements the region associated with a callback that has type signature 11
ompt_callback_task_create_t thencodeptr_ra contains the return address of the call to 12
that runtime routine. If the implementation of the region is inlined then codeptr_ra contains the 13
return address of the invocation of the callback. If attribution to source code is impossible or 14
inappropriate, codeptr_ra may be NULL. 15
Cross References 16
taskconstruct, see Section 2.10.1 on page 135. 17
Initial task, see Section 2.10.5 on page 148. 18
ompt_data_t type, see Section 4.4.4.4 on page 440. 19
ompt_task_flag_t type, see Section 4.4.4.18 on page 446. 20
ompt_frame_t type, see Section 4.4.4.27 on page 454. 21
4.5.2.8 ompt_callback_dependences_t 22
Summary 23
Theompt_callback_dependences_t type is used for callbacks that are related to 24
dependences and that are dispatched when new tasks are generated and when ordered constructs 25
are encountered. 26
468 OpenMP API – Version 5.0 November 2018
Format 1
C / C++
typedef void ( *ompt_callback_dependences_t) ( 2
ompt_data_t *task_data , 3
const ompt_dependence_t *deps, 4
intndeps 5
); 6
C / C++
Trace Record 7
C / C++
typedef struct ompt_record_dependences_t { 8
ompt_id_t task_id ; 9
ompt_dependence_t dep; 10
intndeps ; 11
} ompt_record_dependences_t; 12
C / C++
Description of Arguments 13
The binding of the task_data argument is the generated task. 14
Thedepsargument lists dependences of the new task or the dependence vector of the ordered 15
construct. 16
Thendepsargument speciﬁes the length of the list passed by the depsargument. The memory for 17
depsis owned by the caller; the tool cannot rely on the data after the callback returns. 18
The performance monitor interface for tracing activity on target devices provides one record per 19
dependence. 20
Cross References 21
ordered construct, see Section 2.17.9 on page 250. 22
depend clause, see Section 2.17.11 on page 255. 23
ompt_data_t type, see Section 4.4.4.4 on page 440. 24
ompt_dependence_t type, see Section 4.4.4.9 on page 442. 25
CHAPTER 4. OMPT INTERFACE 469
4.5.2.9 ompt_callback_task_dependence_t 1
Summary 2
Theompt_callback_task_dependence_t type is used for callbacks that are dispatched 3
when unfulﬁlled task dependences are encountered. 4
Format 5
C / C++
typedef void ( *ompt_callback_task_dependence_t) ( 6
ompt_data_t *src_task_data , 7
ompt_data_t *sink_task_data 8
); 9
C / C++
Trace Record 10
C / C++
typedef struct ompt_record_task_dependence_t { 11
ompt_id_t src_task_id ; 12
ompt_id_t sink_task_id ; 13
} ompt_record_task_dependence_t; 14
C / C++
Description of Arguments 15
The binding of the src_task_data argument is a running task with an outgoing dependence. 16
The binding of the sink_task_data argument is a task with an unsatisﬁed incoming dependence. 17
Cross References 18
depend clause, see Section 2.17.11 on page 255. 19
ompt_data_t type, see Section 4.4.4.4 on page 440. 20
4.5.2.10 ompt_callback_task_schedule_t 21
Summary 22
Theompt_callback_task_schedule_t type is used for callbacks that are dispatched when 23
task scheduling decisions are made. 24
470 OpenMP API – Version 5.0 November 2018
Format 1
C / C++
typedef void ( *ompt_callback_task_schedule_t) ( 2
ompt_data_t *prior_task_data , 3
ompt_task_status_t prior_task_status , 4
ompt_data_t *next_task_data 5
); 6
C / C++
Trace Record 7
C / C++
typedef struct ompt_record_task_schedule_t { 8
ompt_id_t prior_task_id ; 9
ompt_task_status_t prior_task_status ; 10
ompt_id_t next_task_id ; 11
} ompt_record_task_schedule_t; 12
C / C++
Description of Arguments 13
Theprior_task_status argument indicates the status of the task that arrived at a task scheduling 14
point. 15
The binding of the prior_task_data argument is the task that arrived at the scheduling point. 16
The binding of the next_task_data argument is the task that is resumed at the scheduling point. 17
This argument is NULLif the callback is dispatched for a task-fulﬁll event. 18
Cross References 19
Task scheduling, see Section 2.10.6 on page 149. 20
ompt_data_t type, see Section 4.4.4.4 on page 440. 21
ompt_task_status_t type, see Section 4.4.4.19 on page 447. 22
4.5.2.11 ompt_callback_implicit_task_t 23
Summary 24
Theompt_callback_implicit_task_t type is used for callbacks that are dispatched when 25
initial tasks and implicit tasks are generated and completed. 26
CHAPTER 4. OMPT INTERFACE 471
Format 1
C / C++
typedef void ( *ompt_callback_implicit_task_t) ( 2
ompt_scope_endpoint_t endpoint , 3
ompt_data_t *parallel_data , 4
ompt_data_t *task_data , 5
unsigned int actual_parallelism , 6
unsigned int index, 7
intﬂags 8
); 9
C / C++
Trace Record 10
C / C++
typedef struct ompt_record_implicit_task_t { 11
ompt_scope_endpoint_t endpoint ; 12
ompt_id_t parallel_id ; 13
ompt_id_t task_id ; 14
unsigned int actual_parallelism ; 15
unsigned int index; 16
intﬂags; 17
} ompt_record_implicit_task_t; 18
C / C++
Description of Arguments 19
Theendpoint argument indicates that the callback signals the beginning of a scope or the end of a 20
scope. 21
The binding of the parallel_data argument is the current parallel region. For the implicit-task-end 22
event, this argument is NULL. 23
The binding of the task_data argument is the implicit task that executes the structured block of the 24
parallel region. 25
Theactual_parallelism argument indicates the number of threads in the parallel region or the 26
number of teams in the teamsregion. For initial tasks, that are not closely nested in a teams 27
construct, this argument is 1. For theimplicit-task-end and theinitial-task-end events, this 28
argument is 0. 29
Theindexargument indicates the thread number or team number of the calling thread, within the 30
team or league that is executing the parallel or teamsregion to which the implicit task region 31
binds. For initial tasks, that are not created by a teamsconstruct, this argument is 1. 32
Theﬂagsargument indicates the kind of the task (initial or implicit). 33
472 OpenMP API – Version 5.0 November 2018
Cross References 1
parallel construct, see Section 2.6 on page 74. 2
teamsconstruct, see Section 2.7 on page 82. 3
ompt_data_t type, see Section 4.4.4.4 on page 440. 4
ompt_scope_endpoint_t enumeration type, see Section 4.4.4.11 on page 443. 5
4.5.2.12 ompt_callback_master_t 6
Summary 7
Theompt_callback_master_t type is used for callbacks that are dispatched when master 8
regions start and end. 9
Format 10
C / C++
typedef void ( *ompt_callback_master_t) ( 11
ompt_scope_endpoint_t endpoint , 12
ompt_data_t *parallel_data , 13
ompt_data_t *task_data , 14
const void *codeptr_ra 15
); 16
C / C++
Trace Record 17
C / C++
typedef struct ompt_record_master_t { 18
ompt_scope_endpoint_t endpoint ; 19
ompt_id_t parallel_id ; 20
ompt_id_t task_id ; 21
const void *codeptr_ra ; 22
} ompt_record_master_t; 23
C / C++
CHAPTER 4. OMPT INTERFACE 473
Description of Arguments 1
Theendpoint argument indicates that the callback signals the beginning of a scope or the end of a 2
scope. 3
The binding of the parallel_data argument is the current parallel region. 4
The binding of the task_data argument is the encountering task. 5
Thecodeptr_ra argument relates the implementation of an OpenMP region to its source code. If a 6
runtime routine implements the region associated with a callback that has type signature 7
ompt_callback_master_t thencodeptr_ra contains the return address of the call to that 8
runtime routine. If the implementation of the region is inlined then codeptr_ra contains the return 9
address of the invocation of the callback. If attribution to source code is impossible or 10
inappropriate, codeptr_ra may be NULL. 11
Cross References 12
master construct, see Section 2.16 on page 221. 13
ompt_data_t type, see Section 4.4.4.4 on page 440. 14
ompt_scope_endpoint_t type, see Section 4.4.4.11 on page 443. 15
4.5.2.13 ompt_callback_sync_region_t 16
Summary 17
Theompt_callback_sync_region_t type is used for callbacks that are dispatched when 18
barrier regions, taskwait regions, and taskgroup regions begin and end and when waiting 19
begins and ends for them as well as for when reductions are performed. 20
Format 21
C / C++
typedef void ( *ompt_callback_sync_region_t) ( 22
ompt_sync_region_t kind, 23
ompt_scope_endpoint_t endpoint , 24
ompt_data_t *parallel_data , 25
ompt_data_t *task_data , 26
const void *codeptr_ra 27
); 28
C / C++
474 OpenMP API – Version 5.0 November 2018
Trace Record 1
C / C++
typedef struct ompt_record_sync_region_t { 2
ompt_sync_region_t kind; 3
ompt_scope_endpoint_t endpoint ; 4
ompt_id_t parallel_id ; 5
ompt_id_t task_id ; 6
const void *codeptr_ra ; 7
} ompt_record_sync_region_t; 8
C / C++
Description of Arguments 9
Thekindargument indicates the kind of synchronization. 10
Theendpoint argument indicates that the callback signals the beginning of a scope or the end of a 11
scope. 12
The binding of the parallel_data argument is the current parallel region. For the barrier-end event 13
at the end of a parallel region this argument is NULL. 14
The binding of the task_data argument is the current task. 15
Thecodeptr_ra argument relates the implementation of an OpenMP region to its source code. If a 16
runtime routine implements the region associated with a callback that has type signature 17
ompt_callback_sync_region_t thencodeptr_ra contains the return address of the call to 18
that runtime routine. If the implementation of the region is inlined then codeptr_ra contains the 19
return address of the invocation of the callback. If attribution to source code is impossible or 20
inappropriate, codeptr_ra may be NULL. 21
Cross References 22
barrier construct, see Section 2.17.2 on page 226. 23
Implicit barriers, see Section 2.17.3 on page 228. 24
taskwait construct, see Section 2.17.5 on page 230. 25
taskgroup construct, see Section 2.17.6 on page 232. 26
Properties common to all reduction clauses, see Section 2.19.5.1 on page 294. 27
ompt_data_t type, see Section 4.4.4.4 on page 440. 28
ompt_scope_endpoint_t type, see Section 4.4.4.11 on page 443. 29
ompt_sync_region_t type, see Section 4.4.4.13 on page 444. 30
CHAPTER 4. OMPT INTERFACE 475
4.5.2.14 ompt_callback_mutex_acquire_t 1
Summary 2
Theompt_callback_mutex_acquire_t type is used for callbacks that are dispatched when 3
locks are initialized, acquired and tested and when critical regions, atomic regions, and 4
ordered regions are begun. 5
Format 6
C / C++
typedef void ( *ompt_callback_mutex_acquire_t) ( 7
ompt_mutex_t kind, 8
unsigned int hint, 9
unsigned int impl, 10
ompt_wait_id_t wait_id , 11
const void *codeptr_ra 12
); 13
C / C++
Trace Record 14
C / C++
typedef struct ompt_record_mutex_acquire_t { 15
ompt_mutex_t kind; 16
unsigned int hint; 17
unsigned int impl; 18
ompt_wait_id_t wait_id ; 19
const void *codeptr_ra ; 20
} ompt_record_mutex_acquire_t; 21
C / C++
Description of Arguments 22
Thekindargument indicates the kind of the lock involved. 23
Thehintargument indicates the hint that was provided when initializing an implementation of 24
mutual exclusion. If no hint is available when a thread initiates acquisition of mutual exclusion, the 25
runtime may supply omp_sync_hint_none as the value for hint. 26
Theimplargument indicates the mechanism chosen by the runtime to implement the mutual 27
exclusion. 28
476 OpenMP API – Version 5.0 November 2018
Thewait_idargument indicates the object being awaited. 1
Thecodeptr_ra argument relates the implementation of an OpenMP region to its source code. If a 2
runtime routine implements the region associated with a callback that has type signature 3
ompt_callback_mutex_acquire_t thencodeptr_ra contains the return address of the call 4
to that runtime routine. If the implementation of the region is inlined then codeptr_ra contains the 5
return address of the invocation of the callback. If attribution to source code is impossible or 6
inappropriate, codeptr_ra may be NULL. 7
Cross References 8
critical construct, see Section 2.17.1 on page 223. 9
atomic construct, see Section 2.17.7 on page 234. 10
ordered construct, see Section 2.17.9 on page 250. 11
omp_init_lock andomp_init_nest_lock routines, see Section 3.3.1 on page 384. 12
ompt_mutex_t type, see Section 4.4.4.16 on page 445. 13
ompt_wait_id_t type, see Section 4.4.4.29 on page 456. 14
4.5.2.15 ompt_callback_mutex_t 15
Summary 16
Theompt_callback_mutex_t type is used for callbacks that indicate important 17
synchronization events. 18
Format 19
C / C++
typedef void ( *ompt_callback_mutex_t) ( 20
ompt_mutex_t kind, 21
ompt_wait_id_t wait_id , 22
const void *codeptr_ra 23
); 24
C / C++
CHAPTER 4. OMPT INTERFACE 477
Trace Record 1
C / C++
typedef struct ompt_record_mutex_t { 2
ompt_mutex_t kind; 3
ompt_wait_id_t wait_id ; 4
const void *codeptr_ra ; 5
} ompt_record_mutex_t; 6
C / C++
Description of Arguments 7
Thekindargument indicates the kind of mutual exclusion event. 8
Thewait_idargument indicates the object being awaited. 9
Thecodeptr_ra argument relates the implementation of an OpenMP region to its source code. If a 10
runtime routine implements the region associated with a callback that has type signature 11
ompt_callback_mutex_t thencodeptr_ra contains the return address of the call to that 12
runtime routine. If the implementation of the region is inlined then codeptr_ra contains the return 13
address of the invocation of the callback. If attribution to source code is impossible or 14
inappropriate, codeptr_ra may be NULL. 15
Cross References 16
critical construct, see Section 2.17.1 on page 223. 17
atomic construct, see Section 2.17.7 on page 234. 18
ordered construct, see Section 2.17.9 on page 250. 19
omp_destroy_lock andomp_destroy_nest_lock routines, see Section 3.3.3 on 20
page 387. 21
omp_set_lock andomp_set_nest_lock routines, see Section 3.3.4 on page 388. 22
omp_unset_lock andomp_unset_nest_lock routines, see Section 3.3.5 on page 390. 23
omp_test_lock andomp_test_nest_lock routines, see Section 3.3.6 on page 392. 24
ompt_mutex_t type, see Section 4.4.4.16 on page 445. 25
ompt_wait_id_t type, see Section 4.4.4.29 on page 456. 26
478OpenMP API – Version 5.0 November 2018
4.5.2.16 ompt_callback_nest_lock_t 1
Summary 2
Theompt_callback_nest_lock_t type is used for callbacks that indicate that a thread that 3
owns a nested lock has performed an action related to the lock but has not relinquished ownership 4
of it. 5
Format 6
C / C++
typedef void ( *ompt_callback_nest_lock_t) ( 7
ompt_scope_endpoint_t endpoint , 8
ompt_wait_id_t wait_id , 9
const void *codeptr_ra 10
); 11
C / C++
Trace Record 12
C / C++
typedef struct ompt_record_nest_lock_t { 13
ompt_scope_endpoint_t endpoint ; 14
ompt_wait_id_t wait_id ; 15
const void *codeptr_ra ; 16
} ompt_record_nest_lock_t; 17
C / C++
Description of Arguments 18
Theendpoint argument indicates that the callback signals the beginning of a scope or the end of a 19
scope. 20
Thewait_idargument indicates the object being awaited. 21
Thecodeptr_ra argument relates the implementation of an OpenMP region to its source code. If a 22
runtime routine implements the region associated with a callback that has type signature 23
ompt_callback_nest_lock_t thencodeptr_ra contains the return address of the call to that 24
runtime routine. If the implementation of the region is inlined then codeptr_ra contains the return 25
address of the invocation of the callback. If attribution to source code is impossible or 26
inappropriate, codeptr_ra may be NULL. 27
CHAPTER 4. OMPT INTERFACE 479
Cross References 1
omp_set_nest_lock routine, see Section 3.3.4 on page 388. 2
omp_unset_nest_lock routine, see Section 3.3.5 on page 390. 3
omp_test_nest_lock routine, see Section 3.3.6 on page 392. 4
ompt_scope_endpoint_t type, see Section 4.4.4.11 on page 443. 5
ompt_wait_id_t type, see Section 4.4.4.29 on page 456. 6
4.5.2.17 ompt_callback_flush_t 7
Summary 8
Theompt_callback_flush_t type is used for callbacks that are dispatched when flush 9
constructs are encountered. 10
Format 11
C / C++
typedef void ( *ompt_callback_flush_t) ( 12
ompt_data_t *thread_data , 13
const void *codeptr_ra 14
); 15
C / C++
Trace Record 16
C / C++
typedef struct ompt_record_flush_t { 17
const void *codeptr_ra ; 18
} ompt_record_flush_t; 19
C / C++
Description of Arguments 20
The binding of the thread_data argument is the executing thread. 21
Thecodeptr_ra argument relates the implementation of an OpenMP region to its source code. If a 22
runtime routine implements the region associated with a callback that has type signature 23
ompt_callback_flush_t thencodeptr_ra contains the return address of the call to that 24
runtime routine. If the implementation of the region is inlined then codeptr_ra contains the return 25
address of the invocation of the callback. If attribution to source code is impossible or 26
inappropriate, codeptr_ra may be NULL. 27
480 OpenMP API – Version 5.0 November 2018
Cross References 1
flushconstruct, see Section 2.17.8 on page 242. 2
ompt_data_t type, see Section 4.4.4.4 on page 440. 3
4.5.2.18 ompt_callback_cancel_t 4
Summary 5
Theompt_callback_cancel_t typeisusedforcallbacksthataredispatchedfor cancellation , 6
cancelanddiscarded-task events. 7
Format 8
C / C++
typedef void ( *ompt_callback_cancel_t) ( 9
ompt_data_t *task_data , 10
intﬂags, 11
const void *codeptr_ra 12
); 13
C / C++
Trace Record 14
C / C++
typedef struct ompt_record_cancel_t { 15
ompt_id_t task_id ; 16
intﬂags; 17
const void *codeptr_ra ; 18
} ompt_record_cancel_t; 19
C / C++
Description of Arguments 20
The binding of the task_data argument is the task that encounters a cancel construct, a 21
cancellation point construct, or a construct deﬁned as having an implicit cancellation 22
point. 23
Theﬂagsargument, deﬁned by the ompt_cancel_flag_t enumeration type, indicates whether 24
cancellation is activated by the current task, or detected as being activated by another task. The 25
constructthatisbeingcanceledisalsodescribedinthe ﬂagsargument. Whenseveralconstructsare 26
detected as being concurrently canceled, each corresponding bit in the argument will be set. 27
CHAPTER 4. OMPT INTERFACE 481
Thecodeptr_ra argument relates the implementation of an OpenMP region to its source code. If a 1
runtime routine implements the region associated with a callback that has type signature 2
ompt_callback_cancel_t thencodeptr_ra contains the return address of the call to that 3
runtime routine. If the implementation of the region is inlined then codeptr_ra contains the return 4
address of the invocation of the callback. If attribution to source code is impossible or 5
inappropriate, codeptr_ra may be NULL. 6
Cross References 7
omp_cancel_flag_t enumeration type, see Section 4.4.4.24 on page 450. 8
4.5.2.19 ompt_callback_device_initialize_t 9
Summary 10
Theompt_callback_device_initialize_t type is used for callbacks that initialize 11
device tracing interfaces. 12
Format 13
C / C++
typedef void ( *ompt_callback_device_initialize_t) ( 14
intdevice_num , 15
const char *type, 16
ompt_device_t *device , 17
ompt_function_lookup_t lookup , 18
const char *documentation 19
); 20
C / C++
Description 21
Registration of a callback with type signature ompt_callback_device_initialize_t for 22
theompt_callback_device_initialize event enables asynchronous collection of a trace 23
for a device. The OpenMP implementation invokes this callback after OpenMP is initialized for the 24
device but before execution of any OpenMP construct is started on the device. 25
482 OpenMP API – Version 5.0 November 2018
Description of Arguments 1
Thedevice_num argument identiﬁes the logical device that is being initialized. 2
Thetypeargument is a character string that indicates the type of the device. A device type string is 3
a semicolon separated character string that includes at a minimum the vendor and model name of 4
the device. These names may be followed by a semicolon-separated sequence of properties that 5
describe the hardware or software of the device. 6
Thedeviceargument is a pointer to an opaque object that represents the target device instance. 7
Functions in the device tracing interface use this pointer to identify the device that is being 8
addressed. 9
Thelookupargument points to a runtime callback that a tool must use to obtain pointers to runtime 10
entry points in the device’s OMPT tracing interface. If a device does not support tracing then 11
lookupisNULL. 12
Thedocumentation argumentisastringthatdescribeshowtouseanydevice-speciﬁcruntimeentry 13
points that can be obtained through the lookupargument. This documentation string may be a 14
pointer to external documentation, or it may be inline descriptions that include names and type 15
signatures for any device-speciﬁc interfaces that are available through the lookupargument along 16
with descriptions of how to use these interface functions to control monitoring and analysis of 17
device traces. 18
Constraints on Arguments 19
Thetypeanddocumentation arguments must be immutable strings that are deﬁned for the lifetime 20
of a program execution. 21
Effect 22
A device initializer must fulﬁll several duties. First, the typeargument should be used to determine 23
if any special knowledge about the hardware and/or software of a device is employed. Second, the 24
lookupargument should be used to look up pointers to runtime entry points in the OMPT tracing 25
interface for the device. Finally, these runtime entry points should be used to set up tracing for the 26
device. 27
Initialization of tracing for a target device is described in Section 4.2.5 on page 427. 28
Cross References 29
ompt_function_lookup_t type, see Section 4.6.3 on page 531. 30
CHAPTER 4. OMPT INTERFACE 483
4.5.2.20 ompt_callback_device_finalize_t 1
Summary 2
Theompt_callback_device_initialize_t type is used for callbacks that ﬁnalize device 3
tracing interfaces. 4
Format 5
C / C++
typedef void ( *ompt_callback_device_finalize_t) ( 6
intdevice_num 7
); 8
C / C++
Description of Arguments 9
Thedevice_num argument identiﬁes the logical device that is being ﬁnalized. 10
Description 11
A registered callback with type signature ompt_callback_device_finalize_t is 12
dispatchedforadeviceimmediatelypriortoﬁnalizingthedevice. Priortodispatchingaﬁnalization 13
callback for a device on which tracing is active, the OpenMP implementation stops tracing on the 14
device and synchronously ﬂushes all trace records for the device that have not yet been reported. 15
These trace records are ﬂushed through one or more buﬀer completion callbacks with type 16
signature ompt_callback_buffer_complete_t as needed prior to the dispatch of the 17
callback with type signature ompt_callback_device_finalize_t . 18
Cross References 19
ompt_callback_buffer_complete_t callback type, see Section 4.5.2.24 on page 487. 20
4.5.2.21 ompt_callback_device_load_t 21
Summary 22
Theompt_callback_device_load_t type is used for callbacks that the OpenMP runtime 23
invokes to indicate that it has just loaded code onto the speciﬁed device. 24
484 OpenMP API – Version 5.0 November 2018
Format 1
C / C++
typedef void ( *ompt_callback_device_load_t) ( 2
intdevice_num , 3
const char *ﬁlename , 4
int64_t oﬀset_in_ﬁle , 5
void *vma_in_ﬁle , 6
size_t bytes, 7
void *host_addr , 8
void *device_addr , 9
uint64_t module_id 10
); 11
C / C++
Description of Arguments 12
Thedevice_num argument speciﬁes the device. 13
Theﬁlenameargumentindicatesthenameofaﬁleinwhichthedevicecodecanbefound. ANULL 14
ﬁlenameindicates that the code is not available in a ﬁle in the ﬁle system. 15
Theoﬀset_in_ﬁle argument indicates an oﬀset into ﬁlenameat which the code can be found. A 16
value of -1 indicates that no oﬀset is provided. 17
ompt_addr_none is deﬁned as a pointer with the value ~0. 18
Thevma_in_ﬁle argument indicates an virtual address in ﬁlenameat which the code can be found. 19
A value of ompt_addr_none indicates that a virtual address in the ﬁle is not available. 20
Thebytesargument indicates the size of the device code object in bytes. 21
Thehost_addr argument indicates the address at which a copy of the device code is available in 22
host memory. A value of ompt_addr_none indicates that a host code address is not available. 23
Thedevice_addr argumentindicatestheaddressatwhichthedevicecodehasbeenloadedindevice 24
memory. A value of ompt_addr_none indicates that a device code address is not available. 25
Themodule_id argument is an identiﬁer that is associated with the device code object. 26
Cross References 27
Device directives, see Section 2.12 on page 160. 28
CHAPTER 4. OMPT INTERFACE 485
4.5.2.22 ompt_callback_device_unload_t 1
Summary 2
Theompt_callback_device_unload_t type is used for callbacks that the OpenMP 3
runtime invokes to indicate that it is about to unload code from the speciﬁed device. 4
Format 5
C / C++
typedef void ( *ompt_callback_device_unload_t) ( 6
intdevice_num , 7
uint64_t module_id 8
); 9
C / C++
Description of Arguments 10
Thedevice_num argument speciﬁes the device. 11
Themodule_id argument is an identiﬁer that is associated with the device code object. 12
Cross References 13
Device directives, see Section 2.12 on page 160. 14
4.5.2.23 ompt_callback_buffer_request_t 15
Summary 16
Theompt_callback_buffer_request_t type is used for callbacks that are dispatched 17
when a buﬀer to store event records for a device is requested. 18
Format 19
C / C++
typedef void ( *ompt_callback_buffer_request_t) ( 20
intdevice_num , 21
ompt_buffer_t **buﬀer , 22
size_t *bytes 23
); 24
C / C++
486 OpenMP API – Version 5.0 November 2018
Description 1
A callback with type signature ompt_callback_buffer_request_t requests a buﬀer to 2
store trace records for the speciﬁed device. A buﬀer request callback may set *bytesto 0 if it does 3
not provide a buﬀer. If a callback sets *bytesto 0, further recording of events for the device is 4
disabled until the next invocation of ompt_start_trace . This action causes the device to drop 5
future trace records until recording is restarted. 6
Description of Arguments 7
Thedevice_num argument speciﬁes the device. 8
The*buﬀerargumentpointstoabuﬀerwheredeviceeventsmayberecorded. The *bytesargument 9
indicates the length of that buﬀer. 10
Cross References 11
ompt_buffer_t type, see Section 4.4.4.7 on page 441. 12
4.5.2.24 ompt_callback_buffer_complete_t 13
Summary 14
Theompt_callback_buffer_complete_t type is used for callbacks that are dispatched 15
whendeviceswillnotrecordanymoretracerecordsinaneventbuﬀerandallrecordswrittentothe 16
buﬀer are valid. 17
Format 18
C / C++
typedef void ( *ompt_callback_buffer_complete_t) ( 19
intdevice_num , 20
ompt_buffer_t *buﬀer , 21
size_t bytes, 22
ompt_buffer_cursor_t begin, 23
intbuﬀer_owned 24
); 25
C / C++
CHAPTER 4. OMPT INTERFACE 487
Description 1
Acallbackwithtypesignature ompt_callback_buffer_complete_t providesabuﬀerthat 2
contains trace records for the speciﬁed device. Typically, a tool will iterate through the records in 3
the buﬀer and process them. 4
The OpenMP implementation makes these callbacks on a thread that is not an OpenMP master or 5
worker thread. 6
The callee may not delete the buﬀer if the buﬀer_owned argument is 0. 7
The buﬀer completion callback is not required to be async signal safe . 8
Description of Arguments 9
Thedevice_num argument indicates the device which the buﬀer contains events. 10
Thebuﬀerargument is the address of a buﬀer that was previously allocated by a buﬀer request 11
callback. 12
Thebytesargument indicates the full size of the buﬀer. 13
Thebeginargument is an opaque cursor that indicates the position of the beginning of the ﬁrst 14
record in the buﬀer. 15
Thebuﬀer_owned argumentis1ifthedatatowhichthebuﬀerpointscanbedeletedbythecallback 16
and 0 otherwise. If multiple devices accumulate trace events into a single buﬀer, this callback may 17
be invoked with a pointer to one or more trace records in a shared buﬀer with buﬀer_owned = 0. In 18
this case, the callback may not delete the buﬀer. 19
Cross References 20
ompt_buffer_t type, see Section 4.4.4.7 on page 441. 21
ompt_buffer_cursor_t type, see Section 4.4.4.8 on page 442. 22
4.5.2.25 ompt_callback_target_data_op_t 23
Summary 24
Theompt_callback_target_data_op_t type is used for callbacks that are dispatched 25
when a thread maps data to a device. 26
488OpenMP API – Version 5.0 November 2018
Format 1
C / C++
typedef void ( *ompt_callback_target_data_op_t) ( 2
ompt_id_t target_id , 3
ompt_id_t host_op_id , 4
ompt_target_data_op_t optype , 5
void *src_addr , 6
intsrc_device_num , 7
void *dest_addr , 8
intdest_device_num , 9
size_t bytes, 10
const void *codeptr_ra 11
); 12
C / C++
Trace Record 13
C / C++
typedef struct ompt_record_target_data_op_t { 14
ompt_id_t host_op_id ; 15
ompt_target_data_op_t optype ; 16
void *src_addr ; 17
intsrc_device_num ; 18
void *dest_addr ; 19
intdest_device_num ; 20
size_t bytes; 21
ompt_device_time_t end_time ; 22
const void *codeptr_ra ; 23
} ompt_record_target_data_op_t; 24
C / C++
Description 25
Aregistered ompt_callback_target_data_op callbackisdispatchedwhendevicememory 26
is allocated or freed, as well as when data is copied to or from a device. 27
28
Note– An OpenMP implementation may aggregate program variables and data operations upon 29
them. For instance, an OpenMP implementation may synthesize a composite to represent multiple 30
scalars and then allocate, free, or copy this composite as a whole rather than performing data 31
operations on each scalar individually. Thus, callbacks may not be dispatched as separate data 32
operations on each variable. 33
34
CHAPTER 4. OMPT INTERFACE 489
Description of Arguments 1
Thehost_op_id argument is a unique identiﬁer for a data operations on a target device. 2
Theoptypeargument indicates the kind of data mapping. 3
Thesrc_addr argument indicates the data address before the operation, where applicable. 4
Thesrc_device_num argument indicates the source device number for the data operation, where 5
applicable. 6
Thedest_addr argument indicates the data address after the operation. 7
Thedest_device_num argument indicates the destination device number for the data operation. 8
It is implementation deﬁned whether in some operations src_addr ordest_addr may point to an 9
intermediate buﬀer. 10
Thebytesargument indicates the size of data. 11
Thecodeptr_ra argument relates the implementation of an OpenMP region to its source code. If a 12
runtime routine implements the region associated with a callback that has type signature 13
ompt_callback_target_data_op_t thencodeptr_ra containsthereturnaddressofthecall 14
to that runtime routine. If the implementation of the region is inlined then codeptr_ra contains the 15
return address of the invocation of the callback. If attribution to source code is impossible or 16
inappropriate, codeptr_ra may be NULL. 17
Cross References 18
mapclause, see Section 2.19.7.1 on page 315. 19
ompt_id_t type, see Section 4.4.4.3 on page 439. 20
ompt_target_data_op_t type, see Section 4.4.4.14 on page 444. 21
4.5.2.26 ompt_callback_target_t 22
Summary 23
Theompt_callback_target_t type is used for callbacks that are dispatched when a thread 24
begins to execute a device construct. 25
490OpenMP API – Version 5.0 November 2018
Format 1
C / C++
typedef void ( *ompt_callback_target_t) ( 2
ompt_target_t kind, 3
ompt_scope_endpoint_t endpoint , 4
intdevice_num , 5
ompt_data_t *task_data , 6
ompt_id_t target_id , 7
const void *codeptr_ra 8
); 9
C / C++
Trace Record 10
C / C++
typedef struct ompt_record_target_t { 11
ompt_target_t kind; 12
ompt_scope_endpoint_t endpoint ; 13
intdevice_num ; 14
ompt_id_t task_id ; 15
ompt_id_t target_id ; 16
const void *codeptr_ra ; 17
} ompt_record_target_t; 18
C / C++
Description of Arguments 19
Thekindargument indicates the kind of target region. 20
Theendpoint argument indicates that the callback signals the beginning of a scope or the end of a 21
scope. 22
Thedevice_num argument indicates the id of the device that will execute the target region. 23
The binding of the task_data argument is the generating task. 24
The binding of the target_id argument is the target region. 25
Thecodeptr_ra argument relates the implementation of an OpenMP region to its source code. If a 26
runtime routine implements the region associated with a callback that has type signature 27
ompt_callback_target_t thencodeptr_ra contains the return address of the call to that 28
runtime routine. If the implementation of the region is inlined then codeptr_ra contains the return 29
address of the invocation of the callback. If attribution to source code is impossible or 30
inappropriate, codeptr_ra may be NULL. 31
CHAPTER 4. OMPT INTERFACE 491
Cross References 1
target data construct, see Section 2.12.2 on page 161. 2
target enter data construct, see Section 2.12.3 on page 164. 3
target exit data construct, see Section 2.12.4 on page 166. 4
target construct, see Section 2.12.5 on page 170. 5
target update construct, see Section 2.12.6 on page 176. 6
ompt_id_t type, see Section 4.4.4.3 on page 439. 7
ompt_data_t type, see Section 4.4.4.4 on page 440. 8
ompt_scope_endpoint_t type, see Section 4.4.4.11 on page 443. 9
ompt_target_t type, see Section 4.4.4.20 on page 448. 10
4.5.2.27 ompt_callback_target_map_t 11
Summary 12
Theompt_callback_target_map_t typeisusedforcallbacksthataredispatchedtoindicate 13
data mapping relationships. 14
Format 15
C / C++
typedef void ( *ompt_callback_target_map_t) ( 16
ompt_id_t target_id , 17
unsigned int nitems , 18
void **host_addr , 19
void **device_addr , 20
size_t *bytes, 21
unsigned int *mapping_ﬂags , 22
const void *codeptr_ra 23
); 24
C / C++
492 OpenMP API – Version 5.0 November 2018
Trace Record 1
C / C++
typedef struct ompt_record_target_map_t { 2
ompt_id_t target_id ; 3
unsigned int nitems ; 4
void **host_addr ; 5
void **device_addr ; 6
size_t *bytes; 7
unsigned int *mapping_ﬂags ; 8
const void *codeptr_ra ; 9
} ompt_record_target_map_t; 10
C / C++
Description 11
An instance of a target,target data ,target enter data , ortarget exit data 12
constructmaycontainoneormore mapclauses. AnOpenMPimplementationmayreportthesetof 13
mappings associated with mapclauses for a construct with a single 14
ompt_callback_target_map callback to report the eﬀect of all mappings or multiple 15
ompt_callback_target_map callbacks with each reporting a subset of the mappings. 16
Furthermore, an OpenMP implementation may omit mappings that it determines are unnecessary. 17
If an OpenMP implementation issues multiple ompt_callback_target_map callbacks, these 18
callbacks may be interleaved with ompt_callback_target_data_op callbacks used to 19
report data operations associated with the mappings. 20
Description of Arguments 21
The binding of the target_id argument is the target region. 22
Thenitemsargument indicates the number of data mappings that this callback reports. 23
Thehost_addr argument indicates an array of host data addresses. 24
Thedevice_addr argument indicates an array of device data addresses. 25
Thebytesargument indicates an array of size of data. 26
Themapping_ﬂags argument indicates the kind of data mapping. Flags for a mapping include one 27
or more values speciﬁed by the ompt_target_map_flag_t type. 28
Thecodeptr_ra argument relates the implementation of an OpenMP region to its source code. If a 29
runtime routine implements the region associated with a callback that has type signature 30
ompt_callback_target_map_t thencodeptr_ra contains the return address of the call to 31
that runtime routine. If the implementation of the region is inlined then codeptr_ra contains the 32
return address of the invocation of the callback. If attribution to source code is impossible or 33
inappropriate, codeptr_ra may be NULL. 34
CHAPTER 4. OMPT INTERFACE 493
Cross References 1
target data construct, see Section 2.12.2 on page 161. 2
target enter data construct, see Section 2.12.3 on page 164. 3
target exit data construct, see Section 2.12.4 on page 166. 4
target construct, see Section 2.12.5 on page 170. 5
ompt_id_t type, see Section 4.4.4.3 on page 439. 6
ompt_target_map_flag_t type, see Section 4.4.4.22 on page 449. 7
ompt_callback_target_data_op_t callback type, see Section 4.5.2.25 on page 488. 8
4.5.2.28 ompt_callback_target_submit_t 9
Summary 10
Theompt_callback_target_submit_t type is used for callbacks that are dispatched when 11
an initial task is created on a device. 12
Format 13
C / C++
typedef void ( *ompt_callback_target_submit_t) ( 14
ompt_id_t target_id , 15
ompt_id_t host_op_id , 16
unsigned int requested_num_teams 17
); 18
C / C++
Trace Record 19
C / C++
typedef struct ompt_record_target_kernel_t { 20
ompt_id_t host_op_id ; 21
unsigned int requested_num_teams ; 22
unsigned int granted_num_teams ; 23
ompt_device_time_t end_time ; 24
} ompt_record_target_kernel_t; 25
C / C++
494 OpenMP API – Version 5.0 November 2018
Description 1
Athreaddispatchesaregistered ompt_callback_target_submit callbackonthehostwhen 2
a target task creates an initial task on a target device. 3
Description of Arguments 4
Thetarget_id argument is a unique identiﬁer for the associated target region. 5
Thehost_op_id argument is a unique identiﬁer for the initial task on the target device. 6
Therequested_num_teams argument is the number of teams that the host requested to execute the 7
kernel. Theactualnumberofteamsthatexecutethekernelmaybesmallerandgenerallywillnotbe 8
known until the kernel begins to execute on the device. 9
Ifompt_set_trace_ompt has conﬁgured the device to trace kernel execution then the device 10
will log a ompt_record_target_kernel_t record in a trace. The ﬁelds in the record are as 11
follows: 12
Thehost_op_id ﬁeld contains a unique identiﬁer that can be used to correlate a 13
ompt_record_target_kernel_t record with its associated 14
ompt_callback_target_submit callback on the host; 15
Therequested_num_teams ﬁeld contains the number of teams that the host requested to execute 16
the kernel; 17
Thegranted_num_teams ﬁeld contains the number of teams that the device actually used to 18
execute the kernel; 19
The time when the initial task began execution on the device is recorded in the timeﬁeld of an 20
enclosing ompt_record_t structure; and 21
The time when the initial task completed execution on the device is recorded in the end_time 22
ﬁeld. 23
Cross References 24
target construct, see Section 2.12.5 on page 170. 25
ompt_id_t type, see Section 4.4.4.3 on page 439. 26
4.5.2.29 ompt_callback_control_tool_t 27
Summary 28
Theompt_callback_control_tool_t type is used for callbacks that dispatch tool-control 29
events. 30
CHAPTER 4. OMPT INTERFACE 495
Format 1
C / C++
typedef int ( *ompt_callback_control_tool_t) ( 2
uint64_t command , 3
uint64_t modiﬁer , 4
void *arg, 5
const void *codeptr_ra 6
); 7
C / C++
Trace Record 8
C / C++
typedef struct ompt_record_control_tool_t { 9
uint64_t command ; 10
uint64_t modiﬁer ; 11
const void *codeptr_ra ; 12
} ompt_record_control_tool_t; 13
C / C++
Description 14
Callbacks with type signature ompt_callback_control_tool_t may return any 15
non-negative value, which will be returned to the application as the return value of the 16
omp_control_tool call that triggered the callback. 17
Description of Arguments 18
Thecommand argument passes a command from an application to a tool. Standard values for 19
command are deﬁned by omp_control_tool_t in Section 3.8 on page 415. 20
Themodiﬁerargument passes a command modiﬁer from an application to a tool. 21
Thecommand andmodiﬁerarguments may have tool-speciﬁc values. Tools must ignore command 22
values that they are not designed to handle. 23
Theargargumentisavoidpointerthatenablesatoolandanapplicationtoexchangearbitrarystate. 24
Theargargument may be NULL. 25
Thecodeptr_ra argument relates the implementation of an OpenMP region to its source code. If a 26
runtime routine implements the region associated with a callback that has type signature 27
ompt_callback_control_tool_t thencodeptr_ra contains the return address of the call to 28
that runtime routine. If the implementation of the region is inlined then codeptr_ra contains the 29
return address of the invocation of the callback. If attribution to source code is impossible or 30
inappropriate, codeptr_ra may be NULL. 31
496 OpenMP API – Version 5.0 November 2018
Constraints on Arguments 1
Tool-speciﬁc values for command must be64. 2
Cross References 3
omp_control_tool_t enumeration type, see Section 3.8 on page 415. 4
4.6 OMPT Runtime Entry Points for Tools5
OMPTsupportstwoprincipalsetsofruntimeentrypointsfortools. Onesetofruntimeentrypoints 6
enablesatooltoregistercallbacksforOpenMPeventsandtoinspectthestateofanOpenMPthread 7
while executing in a tool callback or a signal handler. The second set of runtime entry points 8
enables a tool to trace activities on a device. When directed by the tracing interface, an OpenMP 9
implementation will trace activities on a device, collect buﬀers of trace records, and invoke 10
callbacks on the host to process these records. OMPT runtime entry points should not be global 11
symbols since tools cannot rely on the visibility of such symbols. 12
OMPT also supports runtime entry points for two classes of lookup routines. The ﬁrst class of 13
lookup routines contains a single member: a routine that returns runtime entry points in the OMPT 14
callback interface. The second class of lookup routines includes a unique lookup routine for each 15
kind of device that can return runtime entry points in a device’s OMPT tracing interface. 16
The C/C++ header ﬁle (omp-tools.h) provides the deﬁnitions of the types that are speciﬁed 17
throughout this subsection. 18
Restrictions 19
OMPT runtime entry points have the following restrictions: 20
OMPT runtime entry points must not be called from a signal handler on a native thread before a 21
native-thread-begin or after a native-thread-end event. 22
OMPTdeviceruntimeentrypointsmustnotbecalledaftera device-ﬁnalize eventforthatdevice. 23
4.6.1 Entry Points in the OMPT Callback Interface 24
Entry points in the OMPT callback interface enable a tool to register callbacks for OpenMP events 25
and to inspect the state of an OpenMP thread while executing in a tool callback or a signal handler. 26
Pointers to these runtime entry points are obtained through the lookup function that is provided 27
through the OMPT initializer. 28
CHAPTER 4. OMPT INTERFACE 497
4.6.1.1 ompt_enumerate_states_t 1
Summary 2
Theompt_enumerate_states_t type is the type signature of the 3
ompt_enumerate_states runtime entry point, which enumerates the thread states that an 4
OpenMP implementation supports. 5
Format 6
C / C++
typedef int ( *ompt_enumerate_states_t) ( 7
intcurrent_state , 8
int *next_state , 9
const char **next_state_name 10
); 11
C / C++
Description 12
An OpenMP implementation may support only a subset of the states deﬁned by the 13
ompt_state_t enumeration type. An OpenMP implementation may also support 14
implementation-speciﬁc states. The ompt_enumerate_states runtime entry point, which has 15
type signature ompt_enumerate_states_t , enables a tool to enumerate the supported thread 16
states. 17
When a supported thread state is passed as current_state , the runtime entry point assigns the next 18
thread state in the enumeration to the variable passed by reference in next_state and assigns the 19
name associated with that state to the character pointer passed by reference in next_state_name . 20
Whenever one or more states are left in the enumeration, the ompt_enumerate_states 21
runtime entry point returns 1. When the last state in the enumeration is passed as current_state , 22
ompt_enumerate_states returns 0, which indicates that the enumeration is complete. 23
Description of Arguments 24
Thecurrent_state argument must be a thread state that the OpenMP implementation supports. To 25
begin enumerating the supported states, a tool should pass ompt_state_undefined as 26
current_state . Subsequent invocations of ompt_enumerate_states should pass the value 27
assigned to the variable passed by reference in next_state to the previous call. 28
The value ompt_state_undefined is reserved to indicate an invalid thread state. 29
ompt_state_undefined is deﬁned as an integer with the value 0. 30
Thenext_state argument is a pointer to an integer in which ompt_enumerate_states returns 31
the value of the next state in the enumeration. 32
498 OpenMP API – Version 5.0 November 2018
Thenext_state_name argument is a pointer to a character string pointer through which 1
ompt_enumerate_states returns a string that describes the next state. 2
Constraints on Arguments 3
Any string returned through the next_state_name argument must be immutable and deﬁned for the 4
lifetime of a program execution. 5
Cross References 6
ompt_state_t type, see Section 4.4.4.26 on page 452. 7
4.6.1.2 ompt_enumerate_mutex_impls_t 8
Summary 9
Theompt_enumerate_mutex_impls_t type is the type signature of the 10
ompt_enumerate_mutex_impls runtime entry point, which enumerates the kinds of mutual 11
exclusion implementations that an OpenMP implementation employs. 12
Format 13
C / C++
typedef int ( *ompt_enumerate_mutex_impls_t) ( 14
intcurrent_impl , 15
int *next_impl , 16
const char **next_impl_name 17
); 18
C / C++
Description 19
Mutual exclusion for locks, critical sections, and atomic regions may be implemented in 20
several ways. The ompt_enumerate_mutex_impls runtime entry point, which has type 21
signature ompt_enumerate_mutex_impls_t , enables a tool to enumerate the supported 22
mutual exclusion implementations. 23
Whenasupportedmuteximplementationispassedas current_impl ,theruntimeentrypointassigns 24
the next mutex implementation in the enumeration to the variable passed by reference in next_impl 25
and assigns the name associated with that mutex implementation to the character pointer passed by 26
reference in next_impl_name . 27
CHAPTER 4. OMPT INTERFACE 499
Whenever one or more mutex implementations are left in the enumeration, the 1
ompt_enumerate_mutex_impls runtime entry point returns 1. When the last mutex 2
implementation in the enumeration is passed as current_impl , the runtime entry point returns 0, 3
which indicates that the enumeration is complete. 4
Description of Arguments 5
Thecurrent_impl argument must be a mutex implementation that an OpenMP implementation 6
supports. To begin enumerating the supported mutex implementations, a tool should pass 7
ompt_mutex_impl_none ascurrent_impl . Subsequent invocations of 8
ompt_enumerate_mutex_impls should pass the value assigned to the variable passed in 9
next_impl to the previous call. 10
The value ompt_mutex_impl_none is reserved to indicate an invalid mutex implementation. 11
ompt_mutex_impl_none is deﬁned as an integer with the value 0. 12
Thenext_impl argument is a pointer to an integer in which ompt_enumerate_mutex_impls 13
returns the value of the next mutex implementation in the enumeration. 14
Thenext_impl_name argument is a pointer to a character string pointer in which 15
ompt_enumerate_mutex_impls returns a string that describes the next mutex 16
implementation. 17
Constraints on Arguments 18
Any string returned through the next_impl_name argument must be immutable and deﬁned for the 19
lifetime of a program execution. 20
Cross References 21
ompt_mutex_t type, see Section 4.4.4.16 on page 445. 22
4.6.1.3 ompt_set_callback_t 23
Summary 24
Theompt_set_callback_t typeisthetypesignatureofthe ompt_set_callback runtime 25
entry point, which registers a pointer to a tool callback that an OpenMP implementation invokes 26
when a host OpenMP event occurs. 27
500 OpenMP API – Version 5.0 November 2018
Format 1
C / C++
typedef ompt_set_result_t ( *ompt_set_callback_t) ( 2
ompt_callbacks_t event, 3
ompt_callback_t callback 4
); 5
C / C++
Description 6
OpenMP implementations can use callbacks to indicate the occurrence of events during the 7
execution of an OpenMP program. The ompt_set_callback runtime entry point, which has 8
type signature ompt_set_callback_t , registers a callback for an OpenMP event on the 9
current device, The return value of ompt_set_callback indicates the outcome of registering 10
the callback. 11
Description of Arguments 12
Theeventargument indicates the event for which the callback is being registered. 13
Thecallbackargument is a tool callback function. If callbackisNULLthen callbacks associated 14
witheventare disabled. If callbacks are successfully disabled then ompt_set_always is 15
returned. 16
Constraints on Arguments 17
When a tool registers a callback for an event, the type signature for the callback must match the 18
type signature appropriate for the event. 19
Restrictions 20
Theompt_set_callback runtime entry point has the following restriction: 21
The entry point must not return ompt_set_impossible . 22
Cross References 23
Monitoring activity on the host with OMPT, see Section 4.2.4 on page 425. 24
ompt_callbacks_t enumeration type, see Section 4.4.2 on page 434. 25
ompt_callback_t type, see Section 4.4.4.1 on page 438. 26
ompt_set_result_t type, see Section 4.4.4.2 on page 438. 27
ompt_get_callback_t host callback type signature, see Section 4.6.1.4 on page 502. 28
CHAPTER 4. OMPT INTERFACE 501
4.6.1.4 ompt_get_callback_t 1
Summary 2
Theompt_get_callback_t typeisthetypesignatureofthe ompt_get_callback runtime 3
entry point, which retrieves a pointer to a registered tool callback routine (if any) that an OpenMP 4
implementation invokes when a host OpenMP event occurs. 5
Format 6
C / C++
typedef int ( *ompt_get_callback_t) ( 7
ompt_callbacks_t event, 8
ompt_callback_t *callback 9
); 10
C / C++
Description 11
Theompt_get_callback runtime entry point, which has type signature 12
ompt_get_callback_t , retrieves a pointer to the tool callback that an OpenMP 13
implementation may invoke when a host OpenMP event occurs. If a non-null tool callback is 14
registered for the speciﬁed event, the pointer to the tool callback is assigned to the variable passed 15
by reference in callbackandompt_get_callback returns 1; otherwise, it returns 0. If 16
ompt_get_callback returns 0, the value of the variable passed by reference as callbackis 17
undeﬁned. 18
Description of Arguments 19
Theeventargument indicates the event for which the callback would be invoked. 20
Thecallbackargument returns a pointer to the callback associated with event. 21
Constraints on Arguments 22
Thecallbackargument must be a reference to a variable of speciﬁed type. 23
Cross References 24
ompt_callbacks_t enumeration type, see Section 4.4.2 on page 434. 25
ompt_callback_t type, see Section 4.4.4.1 on page 438. 26
ompt_set_callback_t type signature, see Section 4.6.1.3 on page 500. 27
502 OpenMP API – Version 5.0 November 2018
4.6.1.5 ompt_get_thread_data_t 1
Summary 2
Theompt_get_thread_data_t type is the type signature of the 3
ompt_get_thread_data runtime entry point, which returns the address of the thread data 4
object for the current thread. 5
Format 6
C / C++
typedef ompt_data_t *(*ompt_get_thread_data_t) (void); 7
C / C++
Binding 8
The binding thread for the ompt_get_thread_data runtime entry point is the current thread. 9
Description 10
Each OpenMP thread can have an associated thread data object of type ompt_data_t . The 11
ompt_get_thread_data runtime entry point, which has type signature 12
ompt_get_thread_data_t , retrieves a pointer to the thread data object, if any, that is 13
associated with the current thread. A tool may use a pointer to an OpenMP thread’s data object that 14
ompt_get_thread_data retrieves to inspect or to modify the value of the data object. When 15
an OpenMP thread is created, its data object is initialized with value ompt_data_none . 16
This runtime entry point is async signal safe . 17
Cross References 18
ompt_data_t type, see Section 4.4.4.4 on page 440. 19
4.6.1.6 ompt_get_num_procs_t 20
Summary 21
Theompt_get_num_procs_t type is the type signature of the ompt_get_num_procs 22
runtime entry point, which returns the number of processors currently available to the execution 23
environment on the host device. 24
CHAPTER 4. OMPT INTERFACE 503
Format 1
C / C++
typedef int ( *ompt_get_num_procs_t) (void); 2
C / C++
Binding 3
The binding thread set for the ompt_get_num_procs runtime entry point is all threads on the 4
host device. 5
Description 6
Theompt_get_num_procs runtime entry point, which has type signature 7
ompt_get_num_procs_t , returns the number of processors that are available on the host 8
device at the time the routine is called. This value may change between the time that it is 9
determined and the time that it is read in the calling context due to system actions outside the 10
control of the OpenMP implementation. 11
This runtime entry point is async signal safe . 12
4.6.1.7 ompt_get_num_places_t 13
Summary 14
Theompt_get_num_places_t type is the type signature of the ompt_get_num_places 15
runtime entry point, which returns the number of places currently available to the execution 16
environment in the place list. 17
Format 18
C / C++
typedef int ( *ompt_get_num_places_t) (void); 19
C / C++
Binding 20
The binding thread set for the ompt_get_num_places runtime entry point is all threads on a 21
device. 22
504 OpenMP API – Version 5.0 November 2018
Description 1
Theompt_get_num_places runtime entry point, which has type signature 2
ompt_get_num_places_t , returns the number of places in the place list. This value is 3
equivalent to the number of places in the place-partition-var ICV in the execution environment of 4
the initial task. 5
This runtime entry point is async signal safe . 6
Cross References 7
place-partition-var ICV, see Section 2.5 on page 63. 8
OMP_PLACES environment variable, see Section 6.5 on page 605. 9
4.6.1.8 ompt_get_place_proc_ids_t 10
Summary 11
Theompt_get_place_procs_ids_t type is the type signature of the 12
ompt_get_num_place_procs_ids runtime entry point, which returns the numerical 13
identiﬁers of the processors that are available to the execution environment in the speciﬁed place. 14
Format 15
C / C++
typedef int ( *ompt_get_place_proc_ids_t) ( 16
intplace_num , 17
intids_size , 18
int *ids 19
); 20
C / C++
Binding 21
The binding thread set for the ompt_get_place_proc_ids runtime entry point is all threads 22
on a device. 23
Description 24
Theompt_get_place_proc_ids runtime entry point, which has type signature 25
ompt_get_place_proc_ids_t , returns the numerical identiﬁers of each processor that is 26
associated with the speciﬁed place. These numerical identiﬁers are non-negative and their meaning 27
is implementation deﬁned. 28
CHAPTER 4. OMPT INTERFACE 505
Description of Arguments 1
Theplace_num argument speciﬁes the place that is being queried. 2
Theidsargument is an array in which the routine can return a vector of processor identiﬁers in the 3
speciﬁed place. 4
Theids_sizeargument indicates the size of the result array that is speciﬁed by ids. 5
Effect 6
If theidsarray of size ids_sizeis large enough to contain all identiﬁers then they are returned in ids 7
and their order in the array is implementation deﬁned. Otherwise, if the idsarray is too small the 8
values in idswhen the function returns are unspeciﬁed. The routine always returns the number of 9
numerical identiﬁers of the processors that are available to the execution environment in the 10
speciﬁed place. 11
4.6.1.9 ompt_get_place_num_t 12
Summary 13
Theompt_get_place_num_t type is the type signature of the ompt_get_place_num 14
runtime entry point, which returns the place number of the place to which the current thread is 15
bound. 16
Format 17
C / C++
typedef int ( *ompt_get_place_num_t) (void); 18
C / C++
Binding 19
The binding thread set of the ompt_get_place_num runtime entry point is the current thread. 20
Description 21
When the current thread is bound to a place, ompt_get_place_num returns the place number 22
associated with the thread. The returned value is between 0 and one less than the value returned by 23
ompt_get_num_places ,inclusive. Whenthecurrentthreadisnotboundtoaplace,theroutine 24
returns -1. 25
This runtime entry point is async signal safe . 26
506 OpenMP API – Version 5.0 November 2018
4.6.1.10 ompt_get_partition_place_nums_t 1
Summary 2
Theompt_get_partition_place_nums_t type is the type signature of the 3
ompt_get_partition_place_nums runtime entry point, which returns a list of place 4
numbersthatcorrespondtotheplacesinthe place-partition-var ICVoftheinnermostimplicittask. 5
Format 6
C / C++
typedef int ( *ompt_get_partition_place_nums_t) ( 7
intplace_nums_size , 8
int *place_nums 9
); 10
C / C++
Binding 11
The binding task set for the ompt_get_partition_place_nums runtime entry point is the 12
current implicit task. 13
Description 14
Theompt_get_partition_place_nums runtime entry point, which has type signature 15
ompt_get_partition_place_nums_t , returns a list of place numbers that correspond to 16
the places in the place-partition-var ICV of the innermost implicit task. 17
This runtime entry point is async signal safe . 18
Description of Arguments 19
Theplace_nums argument is an array in which the routine can return a vector of place identiﬁers. 20
Theplace_nums_size argument indicates the size of the result array that the place_nums argument 21
speciﬁes. 22
Effect 23
If theplace_nums array of size place_nums_size is large enough to contain all identiﬁers then they 24
are returnedin place_nums and theirorder inthe arrayis implementation deﬁned. Otherwise,if the 25
place_nums array is too small, the values in place_nums when the function returns are unspeciﬁed. 26
The routine always returns the number of places in the place-partition-var ICV of the innermost 27
implicit task. 28
CHAPTER 4. OMPT INTERFACE 507
Cross References 1
place-partition-var ICV, see Section 2.5 on page 63. 2
OMP_PLACES environment variable, see Section 6.5 on page 605. 3
4.6.1.11 ompt_get_proc_id_t 4
Summary 5
Theompt_get_proc_id_t type is the type signature of the ompt_get_proc_id runtime 6
entry point, which returns the numerical identiﬁer of the processor of the current thread. 7
Format 8
C / C++
typedef int ( *ompt_get_proc_id_t) (void); 9
C / C++
Binding 10
The binding thread set for the ompt_get_proc_id runtime entry point is the current thread. 11
Description 12
Theompt_get_proc_id runtime entry point, which has type signature 13
ompt_get_proc_id_t , returns the numerical identiﬁer of the processor of the current thread. 14
A deﬁned numerical identiﬁer is non-negative and its meaning is implementation deﬁned. A 15
negative number indicates a failure to retrieve the numerical identiﬁer. 16
This runtime entry point is async signal safe . 17
4.6.1.12 ompt_get_state_t 18
Summary 19
Theompt_get_state_t type is the type signature of the ompt_get_state runtime entry 20
point, which returns the state and the wait identiﬁer of the current thread. 21
508 OpenMP API – Version 5.0 November 2018
Format 1
C / C++
typedef int ( *ompt_get_state_t) ( 2
ompt_wait_id_t *wait_id 3
); 4
C / C++
Binding 5
The binding thread for the ompt_get_state runtime entry point is the current thread. 6
Description 7
Each OpenMP thread has an associated state and a wait identiﬁer. If a thread’s state indicates that 8
the thread is waiting for mutual exclusion then its wait identiﬁer contains an opaque handle that 9
indicates the data object upon which the thread is waiting. The ompt_get_state runtime entry 10
point,whichhastypesignature ompt_get_state_t ,retrievesthestateandwaitidentiﬁerofthe 11
current thread. The returned value may be any one of the states predeﬁned by ompt_state_t or 12
a value that represents any implementation speciﬁc state. The tool may obtain a string 13
representation for each state with the ompt_enumerate_states function. 14
If the returned state indicates that the thread is waiting for a lock, nest lock, critical section, atomic 15
region, or ordered region then the value of the thread’s wait identiﬁer is assigned to a non-null wait 16
identiﬁer passed as the wait_idargument. 17
This runtime entry point is async signal safe . 18
Description of Arguments 19
Thewait_idargument is a pointer to an opaque handle that is available to receive the value of the 20
thread’s wait identiﬁer. If wait_idis not NULLthen the entry point assigns the value of the thread’s 21
wait identiﬁer to the object to which wait_idpoints. If the returned state is not one of the speciﬁed 22
wait states then the value of opaque object to which wait_idpoints is undeﬁned after the call. 23
Constraints on Arguments 24
The argument passed to the entry point must be a reference to a variable of the speciﬁed type or 25
NULL. 26
CHAPTER 4. OMPT INTERFACE 509
Cross References 1
ompt_state_t type, see Section 4.4.4.26 on page 452. 2
ompt_wait_id_t type, see Section 4.4.4.29 on page 456. 3
ompt_enumerate_states_t type, see Section 4.6.1.1 on page 498. 4
4.6.1.13 ompt_get_parallel_info_t 5
Summary 6
Theompt_get_parallel_info_t type is the type signature of the 7
ompt_get_parallel_info runtime entry point, which returns information about the parallel 8
region, if any, at the speciﬁed ancestor level for the current execution context. 9
Format 10
C / C++
typedef int ( *ompt_get_parallel_info_t) ( 11
intancestor_level , 12
ompt_data_t **parallel_data , 13
int *team_size 14
); 15
C / C++
Description 16
During execution, an OpenMP program may employ nested parallel regions. The 17
ompt_get_parallel_info runtime entry point known, which has type signature 18
ompt_get_parallel_info_t ,retrievesinformation,aboutthecurrentparallelregionandany 19
enclosing parallel regions for the current execution context. The entry point returns 2 if there is a 20
parallel region at the speciﬁed ancestor level and the information is available, 1 if there is a parallel 21
region at the speciﬁed ancestor level but the information is currently unavailable, and 0 otherwise. 22
A tool may use the pointer to a parallel region’s data object that it obtains from this runtime entry 23
point to inspect or to modify the value of the data object. When a parallel region is created, its data 24
object will be initialized with the value ompt_data_none . 25
This runtime entry point is async signal safe . 26
510 OpenMP API – Version 5.0 November 2018
Between a parallel-begin event and an implicit-task-begin event, a call to 1
ompt_get_parallel_info(0,...) may return information about the outer parallel team, 2
the new parallel team or an inconsistent state. 3
Ifathreadisinthestate ompt_state_wait_barrier_implicit_parallel thenacallto 4
ompt_get_parallel_info may return a pointer to a copy of the speciﬁed parallel region’s 5
parallel_data rather than a pointer to the data word for the region itself. This convention enables 6
the master thread for a parallel region to free storage for the region immediately after the region 7
ends, yet avoid having some other thread in the region’s team potentially reference the region’s 8
parallel_data object after it has been freed. 9
Description of Arguments 10
Theancestor_level argument speciﬁes the parallel region of interest by its ancestor level. Ancestor 11
level 0 refers to the innermost parallel region; information about enclosing parallel regions may be 12
obtained using larger values for ancestor_level . 13
Theparallel_data argument returns the parallel data if the argument is not NULL. 14
Theteam_size argument returns the team size if the argument is not NULL. 15
Effect 16
If the runtime entry point returns 0 or 1, no argument is modiﬁed. Otherwise, 17
ompt_get_parallel_info has the following eﬀects: 18
If a non-null value was passed for parallel_data , the value returned in parallel_data is a pointer 19
to a data word that is associated with the parallel region at the speciﬁed level; and 20
If a non-null value was passed for team_size , the value returned in the integer to which team_size 21
point is the number of threads in the team that is associated with the parallel region. 22
Constraints on Arguments 23
While argument ancestor_level is passed by value, all other arguments to the entry point must be 24
pointers to variables of the speciﬁed types or NULL. 25
Cross References 26
ompt_data_t type, see Section 4.4.4.4 on page 440. 27
CHAPTER 4. OMPT INTERFACE 511
4.6.1.14 ompt_get_task_info_t 1
Summary 2
Theompt_get_task_info_t type is the type signature of the ompt_get_task_info 3
runtime entry point, which returns information about the task, if any, at the speciﬁed ancestor level 4
in the current execution context. 5
Format 6
C / C++
typedef int ( *ompt_get_task_info_t) ( 7
intancestor_level , 8
int *ﬂags, 9
ompt_data_t **task_data , 10
ompt_frame_t **task_frame , 11
ompt_data_t **parallel_data , 12
int *thread_num 13
); 14
C / C++
Description 15
Duringexecution,anOpenMPthreadmaybeexecutinganOpenMPtask. Additionally,thethread’s 16
stack may contain procedure frames that are associated with suspended OpenMP tasks or OpenMP 17
runtime system routines. To obtain information about any task on the current thread’s stack, a tool 18
uses the ompt_get_task_info runtime entry point, which has type signature 19
ompt_get_task_info_t . 20
Ancestor level 0 refers to the active task; information about other tasks with associated frames 21
present on the stack in the current execution context may be queried at higher ancestor levels. 22
Theompt_get_task_info runtime entry point returns 2 if there is a task region at the 23
speciﬁed ancestor level and the information is available, 1 if there is a task region at the speciﬁed 24
ancestor level but the information is currently unavailable, and 0 otherwise. 25
If a task exists at the speciﬁed ancestor level and the information is available then information is 26
returned in the variables passed by reference to the entry point. If no task region exists at the 27
speciﬁed ancestor level or the information is unavailable then the values of variables passed by 28
reference to the entry point are undeﬁned when ompt_get_task_info returns. 29
A tool may use a pointer to a data object for a task or parallel region that it obtains from 30
ompt_get_task_info to inspect or to modify the value of the data object. When either a 31
parallel region or a task region is created, its data object will be initialized with the value 32
ompt_data_none . 33
This runtime entry point is async signal safe . 34
512 OpenMP API – Version 5.0 November 2018
Description of Arguments 1
Theancestor_level argument speciﬁes the task region of interest by its ancestor level. Ancestor 2
level 0 refers to the active task; information about ancestor tasks found in the current execution 3
context may be queried at higher ancestor levels. 4
Theﬂagsargument returns the task type if the argument is not NULL. 5
Thetask_data argument returns the task data if the argument is not NULL. 6
Thetask_frame argument returns the task frame pointer if the argument is not NULL. 7
Theparallel_data argument returns the parallel data if the argument is not NULL. 8
Thethread_num argument returns the thread number if the argument is not NULL. 9
Effect 10
If the runtime entry point returns 0 or 1, no argument is modiﬁed. Otherwise, 11
ompt_get_task_info has the following eﬀects: 12
If a non-null value was passed for ﬂagsthen the value returned in the integer to which ﬂags 13
points represents the type of the task at the speciﬁed level; possible task types include initial, 14
implicit, explicit, and target tasks; 15
If a non-null value was passed for task_data then the value that is returned in the object to which 16
it points is a pointer to a data word that is associated with the task at the speciﬁed level; 17
If a non-null value was passed for task_frame then the value that is returned in the object to 18
whichtask_frame points is a pointer to the ompt_frame_t structure that is associated with the 19
task at the speciﬁed level; 20
If a non-null value was passed for parallel_data then the value that is returned in the object to 21
whichparallel_data points is a pointer to a data word that is associated with the parallel region 22
that contains the task at the speciﬁed level or, if the task at the speciﬁed level is an initial task, 23
NULL; and 24
If a non-null value was passed for thread_num then the value that is returned in the object to 25
whichthread_num points indicates the number of the thread in the parallel region that is 26
executing the task at the speciﬁed level. 27
Constraints on Arguments 28
While argument ancestor_level is passed by value, all other arguments to 29
ompt_get_task_info must be pointers to variables of the speciﬁed types or NULL. 30
CHAPTER 4. OMPT INTERFACE 513
Cross References 1
ompt_data_t type, see Section 4.4.4.4 on page 440. 2
ompt_task_flag_t type, see Section 4.4.4.18 on page 446. 3
ompt_frame_t type, see Section 4.4.4.27 on page 454. 4
4.6.1.15 ompt_get_task_memory_t 5
Summary 6
Theompt_get_task_memory_t type is the type signature of the 7
ompt_get_task_memory runtimeentrypoint,whichreturnsinformationaboutmemoryranges 8
that are associated with the task. 9
Format 10
C / C++
typedef int ( *ompt_get_task_memory_t)( 11
void **addr, 12
size_t *size, 13
intblock 14
); 15
C / C++
Description 16
During execution, an OpenMP thread may be executing an OpenMP task. The OpenMP 17
implementation must preserve the data environment from the creation of the task for the execution 18
of the task. The ompt_get_task_memory runtime entry point, which has type signature 19
ompt_get_task_memory_t , provides information about the memory ranges used to store the 20
data environment for the current task. 21
Multiple memory ranges may be used to store these data. The blockargument supports iteration 22
over these memory ranges. 23
Theompt_get_task_memory runtime entry point returns 1 if there are more memory ranges 24
available, and 0 otherwise. If no memory is used for a task, sizeis set to 0. In this case, addr is 25
unspeciﬁed. 26
This runtime entry point is async signal safe . 27
514 OpenMP API – Version 5.0 November 2018
Description of Arguments 1
Theaddrargument is a pointer to a void pointer return value to provide the start address of a 2
memory block. 3
Thesizeargument is a pointer to a size type return value to provide the size of the memory block. 4
Theblockargument is an integer value to specify the memory block of interest. 5
4.6.1.16 ompt_get_target_info_t 6
Summary 7
Theompt_get_target_info_t type is the type signature of the 8
ompt_get_target_info runtime entry point, which returns identiﬁers that specify a thread’s 9
current target region and target operation ID, if any. 10
Format 11
C / C++
typedef int ( *ompt_get_target_info_t) ( 12
uint64_t *device_num , 13
ompt_id_t *target_id , 14
ompt_id_t *host_op_id 15
); 16
C / C++
Description 17
Theompt_get_target_info entry point, which has type signature 18
ompt_get_target_info_t , returns 1 if the current thread is in a target region and 0 19
otherwise. If the entry point returns 0 then the values of the variables passed by reference as its 20
arguments are undeﬁned. 21
If the current thread is in a target region then ompt_get_target_info returns information 22
about the current device, active target region, and active host operation, if any. 23
This runtime entry point is async signal safe . 24
CHAPTER 4. OMPT INTERFACE 515
Description of Arguments 1
Thedevice_num argument returns the device number if the current thread is in a target region. 2
Thtarget_id argument returns the target region identiﬁer if the current thread is in a target 3
region. 4
If the current thread is in the process of initiating an operation on a target device (for example, 5
copying data to or from an accelerator or launching a kernel) then host_op_id returns the identiﬁer 6
for the operation; otherwise, host_op_id returns ompt_id_none . 7
Constraints on Arguments 8
Arguments passed to the entry point must be valid references to variables of the speciﬁed types. 9
Cross References 10
ompt_id_t type, see Section 4.4.4.3 on page 439. 11
4.6.1.17 ompt_get_num_devices_t 12
Summary 13
Theompt_get_num_devices_t type is the type signature of the 14
ompt_get_num_devices runtime entry point, which returns the number of available devices. 15
Format 16
C / C++
typedef int ( *ompt_get_num_devices_t) (void); 17
C / C++
Description 18
Theompt_get_num_devices runtime entry point, which has type signature 19
ompt_get_num_devices_t , returns the number of devices available to an OpenMP program. 20
This runtime entry point is async signal safe . 21
516 OpenMP API – Version 5.0 November 2018
4.6.1.18 ompt_get_unique_id_t 1
Summary 2
Theompt_get_unique_id_t type is the type signature of the ompt_get_unique_id 3
runtime entry point, which returns a unique number. 4
Format 5
C / C++
typedef uint64_t ( *ompt_get_unique_id_t) (void); 6
C / C++
Description 7
Theompt_get_unique_id runtime entry point, which has type signature 8
ompt_get_unique_id_t , returns a number that is unique for the duration of an OpenMP 9
program. Successive invocations may not result in consecutive or even increasing numbers. 10
This runtime entry point is async signal safe . 11
4.6.1.19 ompt_finalize_tool_t 12
Summary 13
Theompt_finalize_tool_t type is the type signature of the ompt_finalize_tool 14
runtime entry point, which enables a tool to ﬁnalize itself. 15
Format 16
C / C++
typedef void ( *ompt_finalize_tool_t) (void); 17
C / C++
Description 18
A tool may detect that the execution of an OpenMP program is ending before the OpenMP 19
implementation does. To facilitate clean termination of the tool, the tool may invoke the 20
ompt_finalize_tool runtime entry point, which has type signature 21
ompt_finalize_tool_t . Upon completion of ompt_finalize_tool , no OMPT 22
callbacks are dispatched. 23
CHAPTER 4. OMPT INTERFACE 517
Effect 1
Theompt_finalize_tool routinedetachesthetoolfromtheruntime,unregistersallcallbacks 2
and invalidates all OMPT entry points passed to the tool in the lookup-function . Upon completion 3
ofompt_finalize_tool , no further callbacks will be issued on any thread. 4
Before the callbacks are unregistered, the OpenMP runtime should attempt to dispatch all 5
outstanding registered callbacks as well as the callbacks that would be encountered during 6
shutdown of the runtime, if possible in the current execution context. 7
4.6.2 Entry Points in the OMPT Device Tracing Interface8
The runtime entry points with type signatures of the types that are speciﬁed in this section enable a 9
tool to trace activities on a device. 10
4.6.2.1 ompt_get_device_num_procs_t 11
Summary 12
Theompt_get_device_num_procs_t type is the type signature of the 13
ompt_get_device_num_procs runtime entry point, which returns the number of processors 14
currently available to the execution environment on the speciﬁed device. 15
Format 16
C / C++
typedef int ( *ompt_get_device_num_procs_t) ( 17
ompt_device_t *device 18
); 19
C / C++
Description 20
Theompt_get_device_num_procs runtime entry point, which has type signature 21
ompt_get_device_num_procs_t , returns the number of processors that are available on the 22
device at the time the routine is called. This value may change between the time that it is 23
determined and the time that it is read in the calling context due to system actions outside the 24
control of the OpenMP implementation. 25
518 OpenMP API – Version 5.0 November 2018
Description of Arguments 1
Thedeviceargument is a pointer to an opaque object that represents the target device instance. The 2
pointer to the device instance object is used by functions in the device tracing interface to identify 3
the device being addressed. 4
Cross References 5
ompt_device_t type, see Section 4.4.4.5 on page 441. 6
4.6.2.2 ompt_get_device_time_t 7
Summary 8
Theompt_get_device_time_t type is the type signature of the 9
ompt_get_device_time runtime entry point, which returns the current time on the speciﬁed 10
device. 11
Format 12
C / C++
typedef ompt_device_time_t ( *ompt_get_device_time_t) ( 13
ompt_device_t *device 14
); 15
C / C++
Description 16
Host and target devices are typically distinct and run independently. If host and target devices are 17
diﬀerent hardware components, they may use diﬀerent clock generators. For this reason, a common 18
time base for ordering host-side and device-side events may not be available. 19
Theompt_get_device_time runtime entry point, which has type signature 20
ompt_get_device_time_t , returns the current time on the speciﬁed device. A tool can use 21
this information to align time stamps from diﬀerent devices. 22
Description of Arguments 23
Thedeviceargument is a pointer to an opaque object that represents the target device instance. The 24
pointer to the device instance object is used by functions in the device tracing interface to identify 25
the device being addressed. 26
CHAPTER 4. OMPT INTERFACE 519
Cross References 1
ompt_device_t type, see Section 4.4.4.5 on page 441. 2
ompt_device_time_t type, see Section 4.4.4.6 on page 441. 3
4.6.2.3 ompt_translate_time_t 4
Summary 5
Theompt_translate_time_t type is the type signature of the ompt_translate_time 6
runtime entry point, which translates a time value that is obtained from the speciﬁed device to a 7
corresponding time value on the host device. 8
Format 9
C / C++
typedef double ( *ompt_translate_time_t) ( 10
ompt_device_t *device , 11
ompt_device_time_t time 12
); 13
C / C++
Description 14
Theompt_translate_time runtime entry point, which has type signature 15
ompt_translate_time_t , translates a time value obtained from the speciﬁed device to a 16
corresponding time value on the host device. The returned value for the host time has the same 17
meaning as the value returned from omp_get_wtime . 18
19
Note– The accuracy of time translations may degrade if they are not performed promptly after a 20
device time value is received and if either the host or device vary their clock speeds. Prompt 21
translation of device times to host times is recommended. 22
23
Description of Arguments 24
Thedeviceargument is a pointer to an opaque object that represents the target device instance. The 25
pointer to the device instance object is used by functions in the device tracing interface to identify 26
the device being addressed. 27
Thetimeargument is a time from the speciﬁed device. 28
520 OpenMP API – Version 5.0 November 2018
Cross References 1
omp_get_wtime routine, see Section 3.4.1 on page 394. 2
ompt_device_t type, see Section 4.4.4.5 on page 441. 3
ompt_device_time_t type, see Section 4.4.4.6 on page 441. 4
4.6.2.4 ompt_set_trace_ompt_t 5
Summary 6
Theompt_set_trace_ompt_t type is the type signature of the ompt_set_trace_ompt 7
runtime entry point, which enables or disables the recording of trace records for one or more types 8
of OMPT events. 9
Format 10
C / C++
typedef ompt_set_result_t ( *ompt_set_trace_ompt_t) ( 11
ompt_device_t *device , 12
unsigned int enable , 13
unsigned int etype 14
); 15
C / C++
Description of Arguments 16
Thedeviceargumentpointstoanopaqueobjectthatrepresentsthetargetdeviceinstance. Functions 17
in the device tracing interface use this pointer to identify the device that is being addressed. 18
Theetypeargument indicates the events to which the invocation of ompt_set_trace_ompt 19
applies. If the value of etypeis 0 then the invocation applies to all events. If etypeis positive then it 20
applies to the event in ompt_callbacks_t that matches that value. 21
Theenableargumentindicateswhethertracingshouldbeenabledordisabledfortheeventorevents 22
that theetypeargument speciﬁes. A positive value for enableindicates that recording should be 23
enabled; a value of 0 for enableindicates that recording should be disabled. 24
Restrictions 25
Theompt_set_trace_ompt runtime entry point has the following restriction: 26
The entry point must not return ompt_set_sometimes_paired . 27
CHAPTER 4. OMPT INTERFACE 521
Cross References 1
Tracing activity on target devices with OMPT, see Section 4.2.5 on page 427. 2
ompt_callbacks_t type, see Section 4.4.2 on page 434. 3
ompt_set_result_t type, see Section 4.4.4.2 on page 438. 4
ompt_device_t type, see Section 4.4.4.5 on page 441. 5
4.6.2.5 ompt_set_trace_native_t 6
Summary 7
Theompt_set_trace_native_t type is the type signature of the 8
ompt_set_trace_native runtime entry point, which enables or disables the recording of 9
native trace records for a device. 10
Format 11
C / C++
typedef ompt_set_result_t ( *ompt_set_trace_native_t) ( 12
ompt_device_t *device , 13
intenable , 14
intﬂags 15
); 16
C / C++
Description 17
This interface is designed for use by a tool that cannot directly use native control functions for the 18
device. If a tool can directly use the native control functions then it can invoke native control 19
functions directly using pointers that the lookupfunction associated with the device provides and 20
that are described in the documentation string that is provided to the device initializer callback. 21
Description of Arguments 22
Thedeviceargumentpointstoanopaqueobjectthatrepresentsthetargetdeviceinstance. Functions 23
in the device tracing interface use this pointer to identify the device that is being addressed. 24
Theenableargumentindicateswhetherthisinvocationshouldenableordisablerecordingofevents. 25
522 OpenMP API – Version 5.0 November 2018
Theﬂagsargument speciﬁes the kinds of native device monitoring to enable or to disable. Each 1
kindofmonitoringisspeciﬁedbyaﬂagbit. Flagscanbecomposedbyusinglogical ortocombine 2
enumeration values from type ompt_native_mon_flag_t . 3
To start, to pause, to ﬂush, or to stop tracing for a speciﬁc target device associated with device, a 4
tool invokes the ompt_start_trace ,ompt_pause_trace ,ompt_flush_trace , or 5
ompt_stop_trace runtime entry point for the device. 6
Restrictions 7
Theompt_set_trace_native runtime entry point has the following restriction: 8
The entry point must not return ompt_set_sometimes_paired . 9
Cross References 10
Tracing activity on target devices with OMPT, see Section 4.2.5 on page 427. 11
ompt_set_result_t type, see Section 4.4.4.2 on page 438. 12
ompt_device_t type, see Section 4.4.4.5 on page 441. 13
4.6.2.6 ompt_start_trace_t 14
Summary 15
Theompt_start_trace_t type is the type signature of the ompt_start_trace runtime 16
entry point, which starts tracing of activity on a speciﬁc device. 17
Format 18
C / C++
typedef int ( *ompt_start_trace_t) ( 19
ompt_device_t *device , 20
ompt_callback_buffer_request_t request , 21
ompt_callback_buffer_complete_t complete 22
); 23
C / C++
CHAPTER 4. OMPT INTERFACE 523
Description 1
A device’s ompt_start_trace runtime entry point, which has type signature 2
ompt_start_trace_t , initiates tracing on the device. Under normal operating conditions, 3
every event buﬀer provided to a device by a tool callback is returned to the tool before the OpenMP 4
runtime shuts down. If an exceptional condition terminates execution of an OpenMP program, the 5
OpenMP runtime may not return buﬀers provided to the device. 6
An invocation of ompt_start_trace returns 1 if the command succeeds and 0 otherwise. 7
Description of Arguments 8
Thedeviceargumentpointstoanopaqueobjectthatrepresentsthetargetdeviceinstance. Functions 9
in the device tracing interface use this pointer to identify the device that is being addressed. 10
Therequestargumentspeciﬁesatoolcallbackthatsuppliesadevicewithabuﬀertodepositevents. 11
Thecomplete argument speciﬁes a tool callback that is invoked by the OpenMP implementation to 12
empty a buﬀer that contains event records. 13
Cross References 14
ompt_device_t type, see Section 4.4.4.5 on page 441. 15
ompt_callback_buffer_request_t callback type, see Section 4.5.2.23 on page 486. 16
ompt_callback_buffer_complete_t callback type, see Section 4.5.2.24 on page 487. 17
4.6.2.7 ompt_pause_trace_t 18
Summary 19
Theompt_pause_trace_t type is the type signature of the ompt_pause_trace runtime 20
entry point, which pauses or restarts activity tracing on a speciﬁc device. 21
Format 22
C / C++
typedef int ( *ompt_pause_trace_t) ( 23
ompt_device_t *device , 24
intbegin_pause 25
); 26
C / C++
524 OpenMP API – Version 5.0 November 2018
Description 1
A device’s ompt_pause_trace runtime entry point, which has type signature 2
ompt_pause_trace_t , pauses or resumes tracing on a device. An invocation of 3
ompt_pause_trace returns 1 if the command succeeds and 0 otherwise. Redundant pause or 4
resume commands are idempotent and will return the same value as the prior command. 5
Description of Arguments 6
Thedeviceargumentpointstoanopaqueobjectthatrepresentsthetargetdeviceinstance. Functions 7
in the device tracing interface use this pointer to identify the device that is being addressed. 8
Thebegin_pause argument indicates whether to pause or to resume tracing. To resume tracing, 9
zero should be supplied for begin_pause ; To pause tracing, any other value should be supplied. 10
Cross References 11
ompt_device_t type, see Section 4.4.4.5 on page 441. 12
4.6.2.8 ompt_flush_trace_t 13
Summary 14
Theompt_flush_trace_t type is the type signature of the ompt_flush_trace runtime 15
entry point, which causes all pending trace records for the speciﬁed device to be delivered. 16
Format 17
C / C++
typedef int ( *ompt_flush_trace_t) ( 18
ompt_device_t *device 19
); 20
C / C++
Description 21
A device’s ompt_flush_trace runtime entry point, which has type signature 22
ompt_flush_trace_t ,causestheOpenMPimplementationtoissueasequenceofzeroormore 23
buﬀer completion callbacks to deliver all trace records that have been collected prior to the ﬂush. 24
An invocation of ompt_flush_trace returns 1 if the command succeeds and 0 otherwise. 25
CHAPTER 4. OMPT INTERFACE 525
Description of Arguments 1
Thedeviceargumentpointstoanopaqueobjectthatrepresentsthetargetdeviceinstance. Functions 2
in the device tracing interface use this pointer to identify the device that is being addressed. 3
Cross References 4
ompt_device_t type, see Section 4.4.4.5 on page 441. 5
4.6.2.9 ompt_stop_trace_t 6
Summary 7
Theompt_stop_trace_t typeisthetypesignatureofthe ompt_stop_trace runtimeentry 8
point, which stops tracing for a device. 9
Format 10
C / C++
typedef int ( *ompt_stop_trace_t) ( 11
ompt_device_t *device 12
); 13
C / C++
Description 14
A device’s ompt_stop_trace runtime entry point, which has type signature 15
ompt_stop_trace_t , halts tracing on the device and requests that any pending trace records 16
are ﬂushed. An invocation of ompt_stop_trace returns 1 if the command succeeds and 0 17
otherwise. 18
Description of Arguments 19
Thedeviceargumentpointstoanopaqueobjectthatrepresentsthetargetdeviceinstance. Functions 20
in the device tracing interface use this pointer to identify the device that is being addressed. 21
Cross References 22
ompt_device_t type, see Section 4.4.4.5 on page 441. 23
526 OpenMP API – Version 5.0 November 2018
4.6.2.10 ompt_advance_buffer_cursor_t 1
Summary 2
Theompt_advance_buffer_cursor_t type is the type signature of the 3
ompt_advance_buffer_cursor runtime entry point, which advances a trace buﬀer cursor to 4
the next record. 5
Format 6
C / C++
typedef int ( *ompt_advance_buffer_cursor_t) ( 7
ompt_device_t *device , 8
ompt_buffer_t *buﬀer , 9
size_t size, 10
ompt_buffer_cursor_t current , 11
ompt_buffer_cursor_t *next 12
); 13
C / C++
Description 14
A device’s ompt_advance_buffer_cursor runtime entry point, which has type signature 15
ompt_advance_buffer_cursor_t , advances a trace buﬀer pointer to the next trace record. 16
An invocation of ompt_advance_buffer_cursor returnstrueif the advance is successful 17
and the next position in the buﬀer is valid. 18
Description of Arguments 19
Thedeviceargumentpointstoanopaqueobjectthatrepresentsthetargetdeviceinstance. Functions 20
in the device tracing interface use this pointer to identify the device that is being addressed. 21
Thebuﬀerargument indicates a trace buﬀer that is associated with the cursors. 22
The argument sizeindicates the size of buﬀerin bytes. 23
Thecurrentargument is an opaque buﬀer cursor. 24
Thenextargument returns the next value of an opaque buﬀer cursor. 25
Cross References 26
ompt_device_t type, see Section 4.4.4.5 on page 441. 27
ompt_buffer_cursor_t type, see Section 4.4.4.8 on page 442. 28
CHAPTER 4. OMPT INTERFACE 527
4.6.2.11 ompt_get_record_type_t 1
Summary 2
Theompt_get_record_type_t type is the type signature of the 3
ompt_get_record_type runtime entry point, which inspects the type of a trace record. 4
Format 5
C / C++
typedef ompt_record_t ( *ompt_get_record_type_t) ( 6
ompt_buffer_t *buﬀer , 7
ompt_buffer_cursor_t current 8
); 9
C / C++
Description 10
Trace records for a device may be in one of two forms: nativerecord format, which may be 11
device-speciﬁc, or OMPTrecord format, in which each trace record corresponds to an OpenMP 12
eventand most ﬁelds in the record structure are the arguments that would be passed to the OMPT 13
callback for the event. 14
A device’s ompt_get_record_type runtime entry point, which has type signature 15
ompt_get_record_type_t , inspects the type of a trace record and indicates whether the 16
record at the current position in the trace buﬀer is an OMPT record, a native record, or an invalid 17
record. An invalid record type is returned if the cursor is out of bounds. 18
Description of Arguments 19
Thebuﬀerargument indicates a trace buﬀer. 20
Thecurrentargument is an opaque buﬀer cursor. 21
Cross References 22
ompt_record_t type, see Section 4.4.3.1 on page 435. 23
ompt_buffer_t type, see Section 4.4.4.7 on page 441. 24
ompt_buffer_cursor_t type, see Section 4.4.4.8 on page 442. 25
528 OpenMP API – Version 5.0 November 2018
4.6.2.12 ompt_get_record_ompt_t 1
Summary 2
Theompt_get_record_ompt_t type is the type signature of the 3
ompt_get_record_ompt runtime entry point, which obtains a pointer to an OMPT trace 4
record from a trace buﬀer associated with a device. 5
Format 6
C / C++
typedef ompt_record_ompt_t *(*ompt_get_record_ompt_t) ( 7
ompt_buffer_t *buﬀer , 8
ompt_buffer_cursor_t current 9
); 10
C / C++
Description 11
A device’s ompt_get_record_ompt runtime entry point, which has type signature 12
ompt_get_record_ompt_t , returns a pointer that may point to a record in the trace buﬀer, or 13
itmaypointtoarecordinthreadlocalstorageinwhichtheinformationextractedfromarecordwas 14
assembled. The information available for an event depends upon its type. 15
The return value of the ompt_record_ompt_t type includes a ﬁeld of a union type that can 16
representinformationforanyOMPTeventrecordtype. Anothercalltotheruntimeentrypointmay 17
overwrite the contents of the ﬁelds in a record returned by a prior invocation. 18
Description of Arguments 19
Thebuﬀerargument indicates a trace buﬀer. 20
Thecurrentargument is an opaque buﬀer cursor. 21
Cross References 22
ompt_record_ompt_t type, see Section 4.4.3.4 on page 436. 23
ompt_device_t type, see Section 4.4.4.5 on page 441. 24
ompt_buffer_cursor_t type, see Section 4.4.4.8 on page 442. 25
CHAPTER 4. OMPT INTERFACE 529
4.6.2.13 ompt_get_record_native_t 1
Summary 2
Theompt_get_record_native_t type is the type signature of the 3
ompt_get_record_native runtime entry point, which obtains a pointer to a native trace 4
record from a trace buﬀer associated with a device. 5
Format 6
C / C++
typedef void *(*ompt_get_record_native_t) ( 7
ompt_buffer_t *buﬀer , 8
ompt_buffer_cursor_t current , 9
ompt_id_t *host_op_id 10
); 11
C / C++
Description 12
A device’s ompt_get_record_native runtime entry point, which has type signature 13
ompt_get_record_native_t , returns a pointer that may point may point into the speciﬁed 14
trace buﬀer, or into thread local storage in which the information extracted from a trace record was 15
assembled. The information available for a native event depends upon its type. If the function 16
returns a non-null result, it will also set the object to which host_op_id points to a host-side 17
identiﬁer for the operation that is associated with the record. A subsequent call to 18
ompt_get_record_native may overwrite the contents of the ﬁelds in a record returned by a 19
prior invocation. 20
Description of Arguments 21
Thebuﬀerargument indicates a trace buﬀer. 22
Thecurrentargument is an opaque buﬀer cursor. 23
Thehost_op_id argument is a pointer to an identiﬁer that is returned by the function. The entry 24
point sets the identiﬁer to which host_op_id points to the value of a host-side identiﬁer for an 25
operation on a target device that was created when the operation was initiated by the host. 26
Cross References 27
ompt_id_t type, see Section 4.4.4.3 on page 439. 28
ompt_buffer_t type, see Section 4.4.4.7 on page 441. 29
ompt_buffer_cursor_t type, see Section 4.4.4.8 on page 442. 30
530 OpenMP API – Version 5.0 November 2018
4.6.2.14 ompt_get_record_abstract_t 1
Summary 2
Theompt_get_record_abstract_t type is the type signature of the 3
ompt_get_record_abstract runtime entry point, which summarizes the context of a native 4
(device-speciﬁc) trace record. 5
Format 6
C / C++
typedef ompt_record_abstract_t * 7
(*ompt_get_record_abstract_t) ( 8
void *native_record 9
); 10
C / C++
Description 11
An OpenMP implementation may execute on a device that logs trace records in a native 12
(device-speciﬁc) format that a tool cannot interpret directly. A device’s 13
ompt_get_record_abstract runtime entry point, which has type signature 14
ompt_get_record_abstract_t , translates a native trace record into a standard form. 15
Description of Arguments 16
Thenative_record argument is a pointer to a native trace record. 17
Cross References 18
ompt_record_abstract_t type, see Section 4.4.3.3 on page 436. 19
4.6.3 Lookup Entry Points: ompt_function_lookup_t 20
Summary 21
Theompt_function_lookup_t type is the type signature of the lookup runtime entry points 22
that provide pointers to runtime entry points that are part of the OMPT interface. 23
CHAPTER 4. OMPT INTERFACE 531
Format 1
C / C++
typedef void ( *ompt_interface_fn_t) (void); 2
3
typedef ompt_interface_fn_t ( *ompt_function_lookup_t) ( 4
const char *interface_function_name 5
); 6
C / C++
Description 7
AnOpenMPimplementationprovidesapointertoalookuproutinethatprovidespointerstoOMPT 8
runtime entry points. When the implementation invokes a tool initializer to conﬁgure the OMPT 9
callback interface, it provides a lookup function that provides pointers to runtime entry points that 10
implement routines that are part of the OMPT callback interface. Alternatively, when it invokes a 11
tool initializer to conﬁgure the OMPT tracing interface for a device, it provides a lookup function 12
that provides pointers to runtime entry points that implement tracing control routines appropriate 13
for that device. 14
Description of Arguments 15
Theinterface_function_name argument is a C string that represents the name of a runtime entry 16
point. 17
Cross References 18
Tool initializer for a device’s OMPT tracing interface, see Section 4.2.5 on page 427. 19
Tool initializer for the OMPT callback interface, see Section 4.5.1.1 on page 457. 20
Entry points in the OMPT callback interface, see Table 4.1 on page 426 for a list and 21
Section 4.6.1 on page 497 for detailed deﬁnitions. 22
EntrypointsintheOMPTtracinginterface,seeTable4.3onpage430foralistandSection4.6.2 23
on page 518 for detailed deﬁnitions. 24
532OpenMP API – Version 5.0 November 2018
CHAPTER 5
OMPD Interface 1
2
This chapter describes OMPD, which is an interface for third-party tools.Third-party tools exist in 3
separate processes from the OpenMP program. To provide OMPD support, an OpenMP 4
implementation must provide an OMPD library to be loaded by the third-party tool. An OpenMP 5
implementation does not need to maintain any extra information to support OMPD inquiries from 6
third-party toolsunlessit is explicitly instructed to do so. 7
OMPD allows third-party tools such as a debuggers to inspect the OpenMP state of a live program 8
or core ﬁle in an implementation-agnostic manner. That is, a tool that uses OMPD should work 9
with any conforming OpenMP implementation. An OpenMP implementor provides a library for 10
OMPD that a third-party tool can dynamically load. Using the interface exported by the OMPD 11
library, the external tool can inspect the OpenMP state of a program. In order to satisfy requests 12
from the third-party tool, the OMPD library may need to read data from, or to ﬁnd the addresses of 13
symbolsintheOpenMPprogram. TheOMPDlibraryprovidesthisfunctionalitythroughacallback 14
interface that the third-party tool must instantiate for the OMPD library. 15
To use OMPD, the third-party tool loads the OMPD library. The OMPD library exports the API 16
that is deﬁned throughout this section and that the tool uses to determine OpenMP information 17
about the OpenMP program. The OMPD library must look up the symbols and read data out of the 18
program. Itdoesnotperformtheseoperationsdirectly, butinsteaditusesthecallbackinterface that 19
the tool exports to cause the tool to perform them. 20
The OMPD architecture insulates tools from the internal structure of the OpenMP runtime while 21
the OMPD library is insulated from the details of how to access the OpenMP program. This 22
decoupled design allows for ﬂexibility in how the OpenMP program and tool are deployed, so that, 23
for example, the tool and the OpenMP program are not required to execute on the same machine. 24
GenerallythetooldoesnotinteractdirectlywiththeOpenMPruntimeand,instead,interactswithit 25
through the OMPD library. However, a few cases require the tool to access the OpenMP runtime 26
directly. These cases fall into two broad categories. The ﬁrst is during initialization, where the tool 27
must look up symbols and read variables in the OpenMP runtime in order to identify the OMPD 28
library that it should use, which is discussed in Section 5.2.2 on page 535 and Section 5.2.3 on 29
page 536. The second category relates to arranging for the tool to be notiﬁed when certain events 30
533
occurduringtheexecutionoftheOpenMPprogram. Forthispurpose,theOpenMPimplementation 1
must deﬁne certain symbols in the runtime code, as is discussed in Section 5.6 on page 594. Each 2
ofthesesymbolscorrespondstoaneventtype. Theruntimemustensurethatcontrolpassesthrough 3
the appropriate named location when events occur. If the tool requires notiﬁcation of an event, it 4
canplantabreakpointatthematchinglocation. Thelocationcan,butmaynot,beafunction. Itcan, 5
for example, simply be a label. However, the names of the locations must have external Clinkage. 6
5.1 OMPD Interfaces Deﬁnitions7
C / C++
A compliant implementation must supply a set of deﬁnitions for the OMPD runtime entry points, 8
OMPD tool callback signatures, OMPD tool interface routines, and the special data types of their 9
parameters and return values. These deﬁnitions, which are listed throughout this chapter, and their 10
associated declarations shall be provided in a header ﬁle named omp-tools.h . In addition, the 11
set of deﬁnitions may specify other implementation-speciﬁc values. 12
Theompd_dll_locations function, all OMPD tool interface functions, and all OMPD 13
runtime entry points are external functions with Clinkage. 14
C / C++
5.2 Activating an OMPD Tool 15
The tool and the OpenMP program exist as separate processes. Thus, coordination is required 16
between the OpenMP runtime and the external tool for OMPD. 17
5.2.1 Enabling the Runtime for OMPD 18
In order to support third-party tools, the OpenMP runtime may need to collect and to maintain 19
information that it might not otherwise. The OpenMP runtime collects whatever information is 20
necessary to support OMPD if the environment variable OMP_DEBUG is set toenabled. 21
534 OpenMP API – Version 5.0 November 2018
Cross References 1
Activating an OMPT Tool, Section 4.2 on page 420 2
OMP_DEBUG , Section 6.20 on page 617 3
5.2.2 ompd_dll_locations 4
Summary 5
Theompd_dll_locations global variable indicates the location of OMPD libraries that are 6
compatible with the OpenMP implementation. 7
Format 8
C
const char **ompd_dll_locations; 9
C
Description 10
An OpenMP runtime may have more than one OMPD library. The tool must be able to locate the 11
right library to use for the OpenMP program that it is examining. The OpenMP runtime system 12
must provide a public variable ompd_dll_locations , which is an argv-style vector of 13
ﬁlename string pointers that provides the name(s) of any compatible OMPD library. This variable 14
must have Clinkage. The tool uses the name of the variable verbatim and, in particular, does not 15
apply any name mangling before performing the look up. 16
Theprogrammingmodelorarchitectureofthetooland,thus,thatofOMPDdoesnothavetomatch 17
that of the OpenMP program that is being examined. The tool must interpret the contents of 18
ompd_dll_locations to ﬁnd a suitable OMPD that matches its own architectural 19
characteristics. On platforms that support diﬀerent programming models (for example, 32-bit vs 20
64-bit), OpenMP implementations are encouraged to provide OMPD libraries for all models, and 21
that can handle OpenMP programs of any model. Thus, for example, a 32-bit debugger that uses 22
OMPD should be able to debug a 64-bit OpenMP program by loading a 32-bit OMPD 23
implementation that can manage a 64-bit OpenMP runtime. 24
ompd_dll_locations points to a NULL-terminated vector of zero or more NULL-terminated 25
pathname strings that do not have any ﬁlename conventions. This vector must be fully initialized 26
before ompd_dll_locations is set to a non-null value, such that if a tool, such as a debugger, 27
stops execution of the OpenMP program at any point at which ompd_dll_locations is 28
non-null, then the vector of strings to which it points is valid and complete. 29
CHAPTER 5. OMPD INTERFACE 535
Cross References 1
ompd_dll_locations_valid , see Section 5.2.3 on page 536 2
5.2.3 ompd_dll_locations_valid 3
Summary 4
The OpenMP runtime notiﬁes third-party tools that ompd_dll_locations is valid by allowing 5
execution to pass through a location that the symbol ompd_dll_locations_valid identiﬁes. 6
Format 7
C
void ompd_dll_locations_valid(void); 8
C
Description 9
Since ompd_dll_locations may not be a static variable, it may require runtime initialization. 10
The OpenMP runtime notiﬁes third-party tools that ompd_dll_locations is valid by having 11
execution pass through a location that the symbol ompd_dll_locations_valid identiﬁes. If 12
ompd_dll_locations is NULL, a third-party tool can place a breakpoint at 13
ompd_dll_locations_valid to be notiﬁed that ompd_dll_locations is initialized. In 14
practice,thesymbol ompd_dll_locations_valid maynotbeafunction;instead,itmaybea 15
labeled machine instruction through which execution passes once the vector is valid. 16
5.3 OMPD Data Types 17
This section deﬁnes the OMPD types. 18
5.3.1 Size Type 19
Summary 20
Theompd_size_t type speciﬁes the number of bytes in opaque data objects that are passed 21
across the OMPD API. 22
536 OpenMP API – Version 5.0 November 2018
Format 1
C / C++
typedef uint64_t ompd_size_t; 2
C / C++
5.3.2 Wait ID Type3
Summary 4
Thisompd_wait_id_t type identiﬁes the object on which a thread. 5
Format 6
C / C++
typedef uint64_t ompd_wait_id_t; 7
C / C++
5.3.3 Basic Value Types8
Summary 9
These deﬁnitions represent a word, address, and segment value types. 10
Format 11
C / C++
typedef uint64_t ompd_addr_t; 12
typedef int64_t ompd_word_t; 13
typedef uint64_t ompd_seg_t; 14
C / C++
Description 15
Theompd_addr_t type represents an unsigned integer address in an OpenMP process. The 16
ompd_word_t type represents a signed version of ompd_addr_t to hold a signed integer of the 17
OpenMP process. The ompd_seg_t type represents an unsigned integer segment value. 18
CHAPTER 5. OMPD INTERFACE 537
5.3.4 Address Type1
Summary 2
Theompd_address_t type is used to specify device addresses. 3
Format 4
C / C++
typedef struct ompd_address_t { 5
ompd_seg_t segment ; 6
ompd_addr_t address ; 7
} ompd_address_t; 8
C / C++
Description 9
Theompd_address_t type is a structure that OMPD uses to specify device addresses, which 10
may or may not be segmented. For non-segmented architectures, ompd_segment_none is used 11
inthesegmentﬁeldof ompd_address_t ;itisaninstanceofthe ompd_seg_t typethathasthe 12
value 0. 13
5.3.5 Frame Information Type 14
Summary 15
Theompd_frame_info_t type is used to specify frame information. 16
Format 17
C / C++
typedef struct ompd_frame_info_t { 18
ompd_address_t frame_address ; 19
ompd_word_t frame_ﬂag ; 20
} ompd_frame_info_t; 21
C / C++
538 OpenMP API – Version 5.0 November 2018
Description 1
Theompd_frame_info_t type is a structure that OMPD uses to specify frame information. 2
Theframe_address ﬁeld of ompd_frame_info_t identiﬁes a frame. The frame_ﬂag ﬁeld of 3
ompd_frame_info_t indicates what type of information is provided in frame_address . The 4
values and meaning is the same as deﬁned for the ompt_frame_t enumeration type. 5
Cross References 6
ompt_frame_t , see Section 4.4.4.27 on page 454 7
5.3.6 System Device Identiﬁers8
Summary 9
Theompd_device_t type provides information about OpenMP devices. 10
Format 11
C / C++
typedef uint64_t ompd_device_t; 12
C / C++
Description 13
Diﬀerent OpenMP runtimes may utilize diﬀerent underlying devices. The Device identiﬁers can 14
vary in size and format and, thus, are not explicitly represented in OMPD. Instead, device 15
identiﬁers are passed across the interface via the ompd_device_t type, which is a pointer to 16
where the device identiﬁer is stored, and the size of the device identiﬁer in bytes. The OMPD 17
library and a tool that uses it must agree on the format of the object that is passed. Each diﬀerent 18
kind of device identiﬁer uses a unique unsigned 64-bit integer value. 19
Recommended values of ompd_device_t are deﬁned in the ompd-types.h header ﬁle, 20
which is available on http://www.openmp.org/ . 21
5.3.7 Native Thread Identiﬁers 22
Summary 23
Theompd_thread_id_t type provides information about native threads. 24
CHAPTER 5. OMPD INTERFACE 539
Format 1
C / C++
typedef uint64_t ompd_thread_id_t; 2
C / C++
Description 3
Diﬀerent OpenMP runtimes may use diﬀerent native thread implementations. Native thread 4
identiﬁers can vary in size and format and, thus, are not explicitly represented in the OMPD API. 5
Instead, native thread identiﬁers are passed across the interface via the ompd_thread_id_t 6
type, which is a pointer to where the native thread identiﬁer is stored, and the size of the native 7
thread identiﬁer in bytes. The OMPD library and a tool that uses it must agree on the format of the 8
object that is passed. Each diﬀerent kind of native thread identiﬁer uses a unique unsigned 64-bit 9
integer value. 10
Recommended values of ompd_thread_id_t are deﬁned in the ompd-types.h header ﬁle, 11
which is available on http://www.openmp.org/ . 12
5.3.8 OMPD Handle Types 13
Summary 14
OMPD handle types are opaque types. 15
Format 16
C / C++
typedef struct _ompd_aspace_handle ompd_address_space_handle_t; 17
typedef struct _ompd_thread_handle ompd_thread_handle_t; 18
typedef struct _ompd_parallel_handle ompd_parallel_handle_t; 19
typedef struct _ompd_task_handle ompd_task_handle_t; 20
C / C++
540 OpenMP API – Version 5.0 November 2018
Description 1
OMPD uses handles for address spaces ( ompd_address_space_handle_t ), threads 2
(ompd_thread_handle_t ), parallel regions ( ompd_parallel_handle_t ), and tasks 3
(ompd_task_handle_t ). Each operation of the OMPD interface that applies to a particular 4
address space, thread, parallel region, or task must explicitly specify a corresponding handle. A 5
handle for an entity is constant while the entity itself is alive. Handles are deﬁned by the OMPD 6
library, and are opaque to the tool. 7
Deﬁning externally visible type names in this way introduces type safety to the interface, and helps 8
to catch instances where incorrect handles are passed by the tool to the OMPD library. The 9
structures do not need to be deﬁned; instead, the OMPD library must cast incoming (pointers to) 10
handles to the appropriate internal, private types. 11
5.3.9 OMPD Scope Types 12
Summary 13
Theompd_scope_t type identiﬁes OMPD scopes. 14
Format 15
C / C++
typedef enum ompd_scope_t { 16
ompd_scope_global = 1, 17
ompd_scope_address_space = 2, 18
ompd_scope_thread = 3, 19
ompd_scope_parallel = 4, 20
ompd_scope_implicit_task = 5, 21
ompd_scope_task = 6 22
} ompd_scope_t; 23
C / C++
Description 24
Theompd_scope_t type identiﬁes OpenMP scopes, including those related to parallel regions 25
and tasks. When used in an OMPD interface function call, the scope type and the ompd handle 26
must match according to Table 5.1. 27
CHAPTER 5. OMPD INTERFACE 541
TABLE 5.1:Mapping of Scope Type and OMPD Handles
Scope types Handles
ompd_scope_global Address space handle for the host device
ompd_scope_address_space Any address space handle
ompd_scope_thread Any thread handle
ompd_scope_parallel Any parallel handle
ompd_scope_implicit_task Task handle for an implicit task
ompd_scope_task Any task handle
5.3.10 ICV ID Type1
Summary 2
Theompd_icv_id_t type identiﬁes an OpenMP implementation ICV. 3
Format 4
C / C++
typedef uint64_t ompd_icv_id_t; 5
C / C++
Theompd_icv_id_t type identiﬁes OpenMP implementation ICVs. ompd_icv_undefined 6
is an instance of this type with the value 0. 7
5.3.11 Tool Context Types8
Summary 9
A third-party tool uses contexts to uniquely identify abstractions. These contexts are opaque to the 10
OMPD library and are deﬁned as follows: 11
Format 12
C / C++
typedef struct _ompd_aspace_cont ompd_address_space_context_t; 13
typedef struct _ompd_thread_cont ompd_thread_context_t; 14
C / C++
542 OpenMP API – Version 5.0 November 2018
5.3.12 Return Code Types1
Summary 2
Theompd_rc_t type is the return code type of OMPD operations 3
Format 4
C / C++
typedef enum ompd_rc_t { 5
ompd_rc_ok = 0, 6
ompd_rc_unavailable = 1, 7
ompd_rc_stale_handle = 2, 8
ompd_rc_bad_input = 3, 9
ompd_rc_error = 4, 10
ompd_rc_unsupported = 5, 11
ompd_rc_needs_state_tracking = 6, 12
ompd_rc_incompatible = 7, 13
ompd_rc_device_read_error = 8, 14
ompd_rc_device_write_error = 9, 15
ompd_rc_nomem = 10, 16
} ompd_rc_t; 17
C / C++
Description 18
Theompd_rc_t typeisusedforthereturncodesofOMPDoperations. Thereturncodetypesand 19
their semantics are deﬁned as follows: 20
ompd_rc_ok is returned when the operation is successful; 21
ompd_rc_unavailable is returned when information is not available for the speciﬁed 22
context; 23
ompd_rc_stale_handle is returned when the speciﬁed handle is no longer valid; 24
ompd_rc_bad_input is returned when the input parameters (other than handle) are invalid; 25
ompd_rc_error is returned when a fatal error occurred; 26
ompd_rc_unsupported is returned when the requested operation is not supported; 27
ompd_rc_needs_state_tracking is returned when the state tracking operation failed 28
because state tracking is not currently enabled; 29
ompd_rc_device_read_error is returned when a read operation failed on the device; 30
ompd_rc_device_write_error is returned when a write operation failed on the device; 31
CHAPTER 5. OMPD INTERFACE 543
ompd_rc_incompatible isreturnedwhenthisOMPDlibraryisincompatiblewith,orisnot 1
capable of handling, the OpenMP program; and 2
ompd_rc_nomem is returned when a memory allocation fails. 3
5.3.13 Primitive Type Sizes4
Summary 5
Theompd_device_type_sizes_t type provides the “sizeof” of primitive types in the 6
OpenMP architecture address space. 7
Format 8
C / C++
typedef struct ompd_device_type_sizes_t { 9
uint8_t sizeof_char ; 10
uint8_t sizeof_short ; 11
uint8_t sizeof_int ; 12
uint8_t sizeof_long ; 13
uint8_t sizeof_long_long ; 14
uint8_t sizeof_pointer ; 15
} ompd_device_type_sizes_t; 16
C / C++
Description 17
Theompd_device_type_sizes_t type is used in operations through which the OMPD 18
library can interrogate the tool about the “sizeof” of primitive types in the OpenMP architecture 19
address space. The ﬁelds of ompd_device_type_sizes_t give the sizes of the eponymous 20
basictypesusedbytheOpenMPruntime. AsthetoolandtheOMPDlibrary,bydeﬁnition,havethe 21
same architecture and programming model, the size of the ﬁelds can be given as uint8_t . 22
Cross References 23
ompd_callback_sizeof_fn_t , see Section 5.4.2.2 on page 549 24
544 OpenMP API – Version 5.0 November 2018
5.4 OMPD Tool Callback Interface1
For the OMPD library to provide information about the internal state of the OpenMP runtime 2
system in an OpenMP process or core ﬁle, it must have a means to extract information from the 3
OpenMP process that the tool is debugging. The OpenMP process on which the tool is operating 4
may be either a “live” process or a core ﬁle, and a thread may be either a “live” thread in an 5
OpenMPprocess,orathreadinacoreﬁle. ToenabletheOMPDlibrarytoextractstateinformation 6
from an OpenMP process or core ﬁle, the tool must supply the OMPD library with callback 7
functions to inquire about the size of primitive types in the device of the OpenMP process, to look 8
up the addresses of symbols, and to read and to write memory in the device. The OMPD library 9
uses these callbacks to implement its interface operations. The OMPD library only invokes the 10
callback functions in direct response to calls made by the tool to the OMPD library. 11
5.4.1 Memory Management of OMPD Library 12
The OMPD library must not access the heap manager directly. Instead, if it needs heap memory it 13
must use the memory allocation and deallocation callback functions that are described in this 14
section, ompd_callback_memory_alloc_fn_t (see Section 5.4.1.1 on page 546) and 15
ompd_callback_memory_free_fn_t (see Section 5.4.1.2 on page 546), which are provided 16
by the tool to obtain and to release heap memory. This mechanism ensures that the library does not 17
interfere with any custom memory management scheme that the tool may use. 18
If the OMPD library is implemented in C++, memory management operators like newand 19
delete inalltheirvariants, mustallbeoverloadedandimplementedintermsofthecallbacksthat 20
the tool provides. The OMPD library must be coded so that any of its deﬁnitions of newor 21
delete do not interfere with any that the tool deﬁnes. 22
In some cases, the OMPD library must allocate memory to return results to the tool. The tool then 23
owns this memory and has the responsibility to release it. Thus, the OMPD library and the tool 24
must use the same memory manager. 25
The OMPD library creates OMPD handles, which are opaque to the tool and may have a complex 26
internal structure. The tool cannot determine if the handle pointers that the API returns correspond 27
to discrete heap allocations. Thus, the tool must not simply deallocate a handle by passing an 28
address that it receives from the OMPD library to its own memory manager. Instead, the API 29
includes functions that the tool must use when it no longer needs a handle. 30
A tool creates contexts and passes them to the OMPD library. The OMPD library does not release 31
contexts; instead the tool release them after it releases any handles that may reference the contexts. 32
CHAPTER 5. OMPD INTERFACE 545
5.4.1.1 ompd_callback_memory_alloc_fn_t 1
Summary 2
Theompd_callback_memory_alloc_fn_t typeisthetypesignatureofthecallbackroutine 3
that the tool provides to the OMPD library to allocate memory. 4
Format 5
C
typedef ompd_rc_t ( *ompd_callback_memory_alloc_fn_t) ( 6
ompd_size_t nbytes , 7
void **ptr 8
); 9
C
Description 10
Theompd_callback_memory_alloc_fn_t type is the type signature of the memory 11
allocation callback routine that the tool provides. The OMPD library may call the 12
ompd_callback_memory_alloc_fn_t callback function to allocate memory. 13
Description of Arguments 14
Thenbytesargument is the size in bytes of the block of memory to allocate. 15
The address of the newly allocated block of memory is returned in the location to which the ptr 16
argument points. The newly allocated block is suitably aligned for any type of variable, and is not 17
guaranteed to be zeroed. 18
Cross References 19
ompd_size_t , see Section 5.3.1 on page 536. 20
ompd_rc_t , see Section 5.3.12 on page 543. 21
5.4.1.2 ompd_callback_memory_free_fn_t 22
Summary 23
Theompd_callback_memory_free_fn_t type is the type signature of the callback routine 24
that the tool provides to the OMPD library to deallocate memory. 25
546 OpenMP API – Version 5.0 November 2018
Format 1
C
typedef ompd_rc_t ( *ompd_callback_memory_free_fn_t) ( 2
void *ptr 3
); 4
C
Description 5
Theompd_callback_memory_free_fn_t type is the type signature of the memory 6
deallocation callback routine that the tool provides. The OMPD library may call the 7
ompd_callback_memory_free_fn_t callback function to deallocate memory that was 8
obtained from a prior call to the ompd_callback_memory_alloc_fn_t callback function. 9
Description of Arguments 10
Theptrargument is the address of the block to be deallocated. 11
Cross References 12
ompd_rc_t , see Section 5.3.12 on page 543. 13
ompd_callback_memory_alloc_fn_t , see Section 5.4.1.1 on page 546. 14
ompd_callbacks_t , see Section 5.4.6 on page 556. 15
5.4.2 Context Management and Navigation 16
Summary 17
ThetoolprovidestheOMPDlibrarywithcallbackstomanageandtonavigatecontextrelationships. 18
5.4.2.1 ompd_callback_get_thread_context_for_thread_id_fn_t 19
Summary 20
Theompd_callback_get_thread_context_for_thread_id_fn_t is the type 21
signature of the callback routine that the tool provides to the OMPD library to map a thread 22
identiﬁer to a tool thread context. 23
CHAPTER 5. OMPD INTERFACE 547
Format 1
C
typedef ompd_rc_t 2
(*ompd_callback_get_thread_context_for_thread_id_fn_t) ( 3
ompd_address_space_context_t *address_space_context , 4
ompd_thread_id_t kind, 5
ompd_size_t sizeof_thread_id , 6
const void *thread_id , 7
ompd_thread_context_t **thread_context 8
); 9
C
Description 10
Theompd_callback_get_thread_context_for_thread_id_fn_t is the type 11
signature of the context mapping callback routine that the tool provides. This callback maps a 12
thread identiﬁer to a tool thread context. The thread identiﬁer is within the address space that 13
address_space_context identiﬁes. The OMPD library can use the thread context, for example, to 14
access thread local storage. 15
Description of Arguments 16
Theaddress_space_context argument is an opaque handle that the tool provides to reference an 17
address space. The kind,sizeof_thread_id , andthread_id arguments represent a native thread 18
identiﬁer. On return, the thread_context argument provides an opaque handle that maps a native 19
thread identiﬁer to a tool thread context. 20
Restrictions 21
Routinesthatuse ompd_callback_get_thread_context_for_thread_id_fn_t have 22
the following restriction: 23
The provided thread_context must be valid until the OMPD library returns from the OMPD tool 24
interface routine. 25
Cross References 26
ompd_size_t , see Section 5.3.1 on page 536. 27
ompd_thread_id_t , see Section 5.3.7 on page 539. 28
ompd_address_space_context_t , see Section 5.3.11 on page 542. 29
ompd_thread_context_t , see Section 5.3.11 on page 542. 30
ompd_rc_t , see Section 5.3.12 on page 543. 31
548 OpenMP API – Version 5.0 November 2018
5.4.2.2 ompd_callback_sizeof_fn_t 1
Summary 2
Theompd_callback_sizeof_fn_t type is the type signature of the callback routine that the 3
toolprovidestothe OMPDlibrarytodeterminethesizesof theprimitivetypesinanaddress space. 4
Format 5
C
typedef ompd_rc_t ( *ompd_callback_sizeof_fn_t) ( 6
ompd_address_space_context_t *address_space_context , 7
ompd_device_type_sizes_t *sizes 8
); 9
C
Description 10
Theompd_callback_sizeof_fn_t is the type signature of the type-size query callback 11
routine that the tool provides. This callback provides the sizes of the basic primitive types for a 12
given address space. 13
Description of Arguments 14
Thecallbackreturnsthesizesofthebasicprimitivetypesusedbytheaddressspacecontextthatthe 15
address_space_context argument speciﬁes in the location to which the sizesargument points. 16
Cross References 17
ompd_address_space_context_t , see Section 5.3.11 on page 542. 18
ompd_rc_t , see Section 5.3.12 on page 543. 19
ompd_device_type_sizes_t , see Section 5.3.13 on page 544. 20
ompd_callbacks_t , see Section 5.4.6 on page 556. 21
5.4.3 Accessing Memory in the OpenMP Program or Runtime 22
The OMPD library may need to read from or to write to the OpenMP program. It cannot do this 23
directly. Instead the OMPD library must use callbacks that the tool provides so that the tool 24
performs the operation. 25
CHAPTER 5. OMPD INTERFACE 549
5.4.3.1 ompd_callback_symbol_addr_fn_t 1
Summary 2
Theompd_callback_symbol_addr_fn_t type is the type signature of the callback that the 3
tool provides to look up the addresses of symbols in an OpenMP program. 4
Format 5
C
typedef ompd_rc_t ( *ompd_callback_symbol_addr_fn_t) ( 6
ompd_address_space_context_t *address_space_context , 7
ompd_thread_context_t *thread_context , 8
const char *symbol_name , 9
ompd_address_t *symbol_addr , 10
const char *ﬁle_name 11
); 12
C
Description 13
Theompd_callback_symbol_addr_fn_t is the type signature of the symbol-address query 14
callback routine that the tool provides. This callback looks up addresses of symbols within a 15
speciﬁed address space. 16
Description of Arguments 17
This callback looks up the symbol provided in the symbol_name argument. 18
Theaddress_space_context argument is the tool’s representation of the address space of the 19
process, core ﬁle, or device. 20
Thethread_context argument is NULL for global memory access. If thread_context is not NULL, 21
thread_context gives the thread speciﬁc context for the symbol lookup, for the purpose of 22
calculating thread local storage addresses. If thread_context is non-null then the thread to which 23
thread_context refers must be associated with either the process or the device that corresponds to 24
theaddress_space_context argument. 25
The tool uses the symbol_name argument that the OMPD library supplies verbatim. In particular, 26
no name mangling, demangling or other transformations are performed prior to the lookup. The 27
symbol_name parameter must correspond to a statically allocated symbol within the speciﬁed 28
address space. The symbol can correspond to any type of object, such as a variable, thread local 29
storage variable, function, or untyped label. The symbol can have a local, global, or weak binding. 30
Theﬁle_name argument is an optional input parameter that indicates the name of the shared library 31
in which the symbol is deﬁned, and is intended to help the third party tool disambiguate symbols 32
550 OpenMP API – Version 5.0 November 2018
that are deﬁned multiple times across the executable or shared library ﬁles. The shared library 1
name may not be an exact match for the name seen by the tool. If ﬁle_name is NULL then the tool 2
ﬁrst tries to ﬁnd the symbol in the executable ﬁle, and, if the symbol is not found, the tool tries to 3
ﬁnd the symbol in the shared libraries in the order in which the shared libraries are loaded into the 4
address space. If ﬁle_name is non-null then the tool ﬁrst tries to ﬁnd the symbol in the libraries that 5
match the name in the ﬁle_name argument and, if the symbol is not found, the tool then uses the 6
same procedure as when ﬁle_name is NULL. 7
The callback does not support ﬁnding symbols that are dynamically allocated on the call stack, or 8
statically allocated symbols that are deﬁned within the scope of a function or subroutine. 9
The callback returns the symbol’s address in the location to which symbol_addr points. 10
Restrictions 11
Routines that use the ompd_callback_symbol_addr_fn_t type have the following 12
restrictions: 13
Theaddress_space_context argument must be non-null. 14
The symbol that the symbol_name argument speciﬁes must be deﬁned. 15
Cross References 16
ompd_address_t , see Section 5.3.4 on page 538. 17
ompd_address_space_context_t , see Section 5.3.11 on page 542. 18
ompd_thread_context_t , see Section 5.3.11 on page 542. 19
ompd_rc_t , see Section 5.3.12 on page 543. 20
ompd_callbacks_t , see Section 5.4.6 on page 556. 21
5.4.3.2 ompd_callback_memory_read_fn_t 22
Summary 23
Theompd_callback_memory_read_fn_t type is the type signature of the callback that the 24
tool provides to read data from an OpenMP program. 25
CHAPTER 5. OMPD INTERFACE 551
Format 1
C
typedef ompd_rc_t ( *ompd_callback_memory_read_fn_t) ( 2
ompd_address_space_context_t *address_space_context , 3
ompd_thread_context_t *thread_context , 4
const ompd_address_t *addr, 5
ompd_size_t nbytes , 6
void *buﬀer 7
); 8
C
Description 9
Theompd_callback_memory_read_fn_t is the type signature of the read callback routines 10
that the tool provides. 11
Theread_memory callback copies a block of data from addrwithin the address space to the tool 12
buﬀer. 13
Theread_string callback copies a string to which addrpoints, including the terminating null 14
byte( ’\0’),tothetool buﬀer. Atmost nbytesbytesarecopied. Ifanullbyteisnotamongtheﬁrst 15
nbytesbytes, the string placed in buﬀeris not null-terminated. 16
Description of Arguments 17
The address from which the data are to be read from the OpenMP program speciﬁed by 18
address_space_context is given by addr. whilenbytesgives the number of bytes to be transferred. 19
Thethread_context argument is optional for global memory access, and in this case should be 20
NULL. If it is non-null, thread_context identiﬁes the thread speciﬁc context for the memory access 21
for the purpose of accessing thread local storage. 22
The data are returned through buﬀer, which is allocated and owned by the OMPD library. The 23
contents of the buﬀer are unstructured, raw bytes. The OMPD library must arrange for any 24
transformations such as byte-swapping that may be necessary (see Section 5.4.4 on page 554) to 25
interpret the data. 26
552 OpenMP API – Version 5.0 November 2018
Cross References 1
ompd_size_t , see Section 5.3.1 on page 536. 2
ompd_address_t , see Section 5.3.4 on page 538. 3
ompd_address_space_context_t , see Section 5.3.11 on page 542. 4
ompd_thread_context_t , see Section 5.3.11 on page 542. 5
ompd_rc_t , see Section 5.3.12 on page 543. 6
ompd_callback_device_host_fn_t , see Section 5.4.4 on page 554. 7
ompd_callbacks_t , see Section 5.4.6 on page 556. 8
5.4.3.3 ompd_callback_memory_write_fn_t 9
Summary 10
Theompd_callback_memory_write_fn_t type is the type signature of the callback that 11
the tool provides to write data to an OpenMP program. 12
Format 13
C
typedef ompd_rc_t ( *ompd_callback_memory_write_fn_t) ( 14
ompd_address_space_context_t *address_space_context , 15
ompd_thread_context_t *thread_context , 16
const ompd_address_t *addr, 17
ompd_size_t nbytes , 18
const void *buﬀer 19
); 20
C
Description 21
Theompd_callback_memory_write_fn_t is the type signature of the write callback 22
routine that the tool provides. The OMPD library may call this callback to have the tool write a 23
block of data to a location within an address space from a provided buﬀer. 24
CHAPTER 5. OMPD INTERFACE 553
Description of Arguments 1
TheaddresstowhichthedataaretobewrittenintheOpenMPprogramthat address_space_context 2
speciﬁes is given by addr. Thenbytesargument is the number of bytes to be transferred. The 3
thread_context argument is optional for global memory access, and, in this case, should be NULL. 4
If it is non-null then thread_context identiﬁes the thread-speciﬁc context for the memory access for 5
the purpose of accessing thread local storage. 6
The data to be written are passed through buﬀer, which is allocated and owned by the OMPD 7
library. The contents of the buﬀer are unstructured, raw bytes. The OMPD library must arrange for 8
any transformations such as byte-swapping that may be necessary (see Section 5.4.4 on page 554) 9
to render the data into a form that is compatible with the OpenMP runtime. 10
Cross References 11
ompd_size_t , see Section 5.3.1 on page 536. 12
ompd_address_t , see Section 5.3.4 on page 538. 13
ompd_address_space_context_t , see Section 5.3.11 on page 542. 14
ompd_thread_context_t , see Section 5.3.11 on page 542. 15
ompd_rc_t , see Section 5.3.12 on page 543. 16
ompd_callback_device_host_fn_t , see Section 5.4.4 on page 554. 17
ompd_callbacks_t , see Section 5.4.6 on page 556. 18
5.4.4 Data Format Conversion: 19
ompd_callback_device_host_fn_t 20
Summary 21
Theompd_callback_device_host_fn_t type is the type signature of the callback that the 22
tool provides to convert data between the formats that the tool and the OMPD library use and that 23
the OpenMP program uses. 24
554OpenMP API – Version 5.0 November 2018
Format 1
C
typedef ompd_rc_t ( *ompd_callback_device_host_fn_t) ( 2
ompd_address_space_context_t *address_space_context , 3
const void *input, 4
ompd_size_t unit_size , 5
ompd_size_t count, 6
void *output 7
); 8
C
Description 9
The architecture and/or programming-model of the tool and the OMPD library may be diﬀerent 10
from that of the OpenMP program that is being examined. Thus, the conventions for representing 11
data may diﬀer. The callback interface includes operations to convert between the conventions, 12
such as the byte order (endianness), that the tool and OMPD library use and the one that the 13
OpenMP program uses. The callback with the ompd_callback_device_host_fn_t type 14
signature convert data between formats 15
Description of Arguments 16
Theaddress_space_context argument speciﬁes the OpenMP address space that is associated with 17
the data. The inputargument is the source buﬀer and the outputargument is the destination buﬀer. 18
Theunit_size argument is the size of each of the elements to be converted. The countargument is 19
the number of elements to be transformed. 20
The OMPD library allocates and owns the input and output buﬀers. It must ensure that the buﬀers 21
have the correct size, and are eventually deallocated when they are no longer needed. 22
Cross References 23
ompd_size_t , see Section 5.3.1 on page 536. 24
ompd_address_space_context_t , see Section 5.3.11 on page 542. 25
ompd_rc_t , see Section 5.3.12 on page 543. 26
ompd_callbacks_t , see Section 5.4.6 on page 556. 27
CHAPTER 5. OMPD INTERFACE 555
5.4.5 Output: ompd_callback_print_string_fn_t 1
Summary 2
Theompd_callback_print_string_fn_t type is the type signature of the callback that 3
tool provides so that the OMPD library can emit output. 4
Format 5
C
typedef ompd_rc_t ( *ompd_callback_print_string_fn_t) ( 6
const char *string , 7
intcategory 8
); 9
C
Description 10
TheOMPDlibrarymaycallthe ompd_callback_print_string_fn_t callbackfunctionto 11
emit output, such as logging or debug information. The tool may set the 12
ompd_callback_print_string_fn_t callback function to NULL to prevent the OMPD 13
library from emitting output; the OMPD may not write to ﬁle descriptors that it did not open. 14
Description of Arguments 15
Thestringargument is the null-terminated string to be printed. No conversion or formatting is 16
performed on the string. 17
Thecategory argument is the implementation-deﬁned category of the string to be printed. 18
Cross References 19
ompd_rc_t , see Section 5.3.12 on page 543. 20
ompd_callbacks_t , see Section 5.4.6 on page 556. 21
5.4.6 The Callback Interface 22
Summary 23
All OMPD library interactions with the OpenMP program must be through a set of callbacks that 24
the tool provides. These callbacks must also be used for allocating or releasing resources, such as 25
memory, that the library needs. 26
556 OpenMP API – Version 5.0 November 2018
Format 1
C
typedef struct ompd_callbacks_t { 2
ompd_callback_memory_alloc_fn_t alloc_memory ; 3
ompd_callback_memory_free_fn_t free_memory ; 4
ompd_callback_print_string_fn_t print_string ; 5
ompd_callback_sizeof_fn_t sizeof_type ; 6
ompd_callback_symbol_addr_fn_t symbol_addr_lookup ; 7
ompd_callback_memory_read_fn_t read_memory ; 8
ompd_callback_memory_write_fn_t write_memory ; 9
ompd_callback_memory_read_fn_t read_string ; 10
ompd_callback_device_host_fn_t device_to_host ; 11
ompd_callback_device_host_fn_t host_to_device ; 12
ompd_callback_get_thread_context_for_thread_id_fn_t 13
get_thread_context_for_thread_id ; 14
} ompd_callbacks_t; 15
C
Description 16
The set of callbacks that the OMPD library must use is collected in the ompd_callbacks_t 17
record structure. An instance of this type is passed to the OMPD library as a parameter to 18
ompd_initialize (see Section 5.5.1.1 on page 558). Each ﬁeld points to a function that the 19
OMPD library must use to interact with the OpenMP program or for memory operations. 20
Thealloc_memory andfree_memory ﬁelds are pointers to functions the OMPD library uses to 21
allocate and to release dynamic memory. 22
print_string points to a function that prints a string. 23
The architectures or programming models of the OMPD library and third party tool may be 24
diﬀerent from that of the OpenMP program that is being examined. sizeof_type points to function 25
that allows the OMPD library to determine the sizes of the basic integer and pointer types that the 26
OpenMP program uses. Because of the diﬀerences in architecture or programming model, the 27
conventions for representing data in the OMPD library and the OpenMP program may be diﬀerent. 28
Thedevice_to_host ﬁeld points to a function that translates data from the conventions that the 29
OpenMP program uses to those that the tool and OMPD library use. The reverse operation is 30
performed by the function to which the host_to_device ﬁeld points. 31
Thesymbol_addr_lookup ﬁeld points to a callback that the OMPD library can use to ﬁnd the 32
address of a global or thread local storage symbol. The read_memory ,read_string , and 33
write_memory ﬁelds are pointers to functions for reading from and writing to global memory or 34
thread local storage in the OpenMP program. 35
Theget_thread_context_for_thread_id ﬁeld is a pointer to a function that the OMPD library can 36
use to obtain a thread context that corresponds to a native thread identiﬁer. 37
CHAPTER 5. OMPD INTERFACE 557
Cross References 1
ompd_callback_memory_alloc_fn_t , see Section 5.4.1.1 on page 546. 2
ompd_callback_memory_free_fn_t , see Section 5.4.1.2 on page 546. 3
ompd_callback_get_thread_context_for_thread_id_fn_t , see Section 5.4.2.1 4
on page 547. 5
ompd_callback_sizeof_fn_t , see Section 5.4.2.2 on page 549. 6
ompd_callback_symbol_addr_fn_t , see Section 5.4.3.1 on page 550. 7
ompd_callback_memory_read_fn_t , see Section 5.4.3.2 on page 551. 8
ompd_callback_memory_write_fn_t , see Section 5.4.3.3 on page 553. 9
ompd_callback_device_host_fn_t , see Section 5.4.4 on page 554. 10
ompd_callback_print_string_fn_t , see Section 5.4.5 on page 556 11
5.5 OMPD Tool Interface Routines 12
5.5.1 Per OMPD Library Initialization and Finalization 13
The OMPD library must be initialized exactly once after it is loaded, and ﬁnalized exactly once 14
before it is unloaded. Per OpenMP process or core ﬁle initialization and ﬁnalization are also 15
required. 16
Once loaded, the tool can determine the version of the OMPD API that the library supports by 17
calling ompd_get_api_version (see Section 5.5.1.2 on page 559). If the tool supports the 18
version that ompd_get_api_version returns, the tool starts the initialization by calling 19
ompd_initialize (see Section 5.5.1.1 on page 558) using the version of the OMPD API that 20
the library supports. If the tool does not support the version that ompd_get_api_version 21
returns, it may attempt to call ompd_initialize with a diﬀerent version. 22
5.5.1.1 ompd_initialize 23
Summary 24
Theompd_initialize function initializes the OMPD library. 25
558 OpenMP API – Version 5.0 November 2018
Format 1
C
ompd_rc_t ompd_initialize( 2
ompd_word_t api_version , 3
const ompd_callbacks_t *callbacks 4
); 5
C
Description 6
A tool that uses OMPD calls ompd_initialize to initialize each OMPD library that it loads. 7
More than one library may be present in a third-party tool, such as a debugger, because the tool 8
may control multiple devices, which may use diﬀerent runtime systems that require diﬀerent 9
OMPD libraries. This initialization must be performed exactly once before the tool can begin to 10
operate on an OpenMP process or core ﬁle. 11
Description of Arguments 12
Theapi_version argumentistheOMPDAPI versionthatthetoolrequeststouse. Thetoolmaycall 13
ompd_get_api_version to obtain the latest version that the OMPD library supports. 14
The tool provides the OMPD library with a set of callback functions in the callbacks input 15
argument which enables the OMPD library to allocate and to deallocate memory in the tool’s 16
address space, to lookup the sizes of basic primitive types in the device, to lookup symbols in the 17
device, and to read and to write memory in the device. 18
Cross References 19
ompd_rc_t type, see Section 5.3.12 on page 543. 20
ompd_callbacks_t type, see Section 5.4.6 on page 556. 21
ompd_get_api_version call, see Section 5.5.1.2 on page 559. 22
5.5.1.2 ompd_get_api_version 23
Summary 24
Theompd_get_api_version function returns the OMPD API version. 25
CHAPTER 5. OMPD INTERFACE 559
Format 1
C
ompd_rc_t ompd_get_api_version(ompd_word_t *version ); 2
C
Description 3
The tool may call the ompd_get_api_version function to obtain the latest OMPD API 4
version number of the OMPD library. 5
Description of Arguments 6
The latest version number is returned into the location to which the versionargument points. 7
Cross References 8
ompd_rc_t type, see Section 5.3.12 on page 543. 9
5.5.1.3 ompd_get_version_string 10
Summary 11
Theompd_get_version_string function returns a descriptive string for the OMPD API 12
version. 13
Format 14
C
ompd_rc_t ompd_get_version_string(const char **string ); 15
C
Description 16
The tool may call this function to obtain a pointer to a descriptive version string of the OMPD API 17
version. 18
560 OpenMP API – Version 5.0 November 2018
Description of Arguments 1
A pointer to a descriptive version string is placed into the location to which stringoutput argument 2
points. The OMPD library owns the string that the OMPD library returns; the tool must not modify 3
or release this string. The string remains valid for as long as the library is loaded. The 4
ompd_get_version_string function may be called before ompd_initialize (see 5
Section 5.5.1.1 on page 558). Accordingly, the OMPD library must not use heap or stack memory 6
for the string. 7
The signatures of ompd_get_api_version (see Section 5.5.1.2 on page 559) and 8
ompd_get_version_string are guaranteed not to change in future versions of the API. In 9
contrast, the type deﬁnitions and prototypes in the rest of the API do not carry the same guarantee. 10
Therefore a tool that uses OMPD should check the version of the API of the loaded OMPD library 11
before it calls any other function of the API. 12
Cross References 13
ompd_rc_t type, see Section 5.3.12 on page 543. 14
5.5.1.4 ompd_finalize 15
Summary 16
When the tool is ﬁnished with the OMPD library it should call ompd_finalize before it 17
unloads the library. 18
Format 19
C
ompd_rc_t ompd_finalize(void); 20
C
Description 21
Thecallto ompd_finalize mustbethelastOMPDcallthatthetoolmakesbeforeitunloadsthe 22
library. This call allows the OMPD library to free any resources that it may be holding. 23
The OMPD library may implement a ﬁnalizersection, which executes as the library is unloaded 24
and therefore after the call to ompd_finalize . During ﬁnalization, the OMPD library may use 25
the callbacks that the tool earlier provided after the call to ompd_initialize . 26
CHAPTER 5. OMPD INTERFACE 561
Cross References 1
ompd_rc_t type, see Section 5.3.12 on page 543. 2
5.5.2 Per OpenMP Process Initialization and Finalization3
5.5.2.1 ompd_process_initialize 4
Summary 5
A tool calls ompd_process_initialize to obtain an address space handle when it initializes 6
a session on a live process or core ﬁle. 7
Format 8
C
ompd_rc_t ompd_process_initialize( 9
ompd_address_space_context_t *context , 10
ompd_address_space_handle_t **handle 11
); 12
C
Description 13
A tool calls ompd_process_initialize to obtain an address space handle when it initializes 14
a session on a live process or core ﬁle. On return from ompd_process_initialize , the tool 15
owns the address space handle, which it must release with 16
ompd_rel_address_space_handle . The initialization function must be called before any 17
OMPD operations are performed on the OpenMP process. This call allows the OMPD library to 18
conﬁrm that it can handle the OpenMP process or core ﬁle that the contextidentiﬁes. 19
Incompatibility is signaled by a return value of ompd_rc_incompatible . 20
Description of Arguments 21
Thecontextargument is an opaque handle that the tool provides to address an address space. On 22
return, the handleargument provides an opaque handle to the tool for this address space, which the 23
tool must release when it is no longer needed. 24
562 OpenMP API – Version 5.0 November 2018
Cross References 1
ompd_address_space_handle_t type, see Section 5.3.8 on page 540. 2
ompd_address_space_context_t type, see Section 5.3.11 on page 542. 3
ompd_rc_t type, see Section 5.3.12 on page 543. 4
ompd_rel_address_space_handle type, see Section 5.5.2.3 on page 564. 5
5.5.2.2 ompd_device_initialize 6
Summary 7
Atoolcalls ompd_device_initialize toobtainanaddressspacehandleforadevicethathas 8
at least one active target region. 9
Format 10
C
ompd_rc_t ompd_device_initialize( 11
ompd_address_space_handle_t *process_handle , 12
ompd_address_space_context_t *device_context , 13
ompd_device_t kind, 14
ompd_size_t sizeof_id , 15
void *id, 16
ompd_address_space_handle_t **device_handle 17
); 18
C
Description 19
Atoolcalls ompd_device_initialize toobtainanaddressspacehandleforadevicethathas 20
atleastoneactivetargetregion. Onreturnfrom ompd_device_initialize ,thetoolownsthe 21
address space handle. 22
Description of Arguments 23
Theprocess_handle argument is an opaque handle that the tool provides to reference the address 24
space of the OpenMP process. The device_context argument is an opaque handle that the tool 25
provides to reference a device address space. The kind,sizeof_id, andidarguments represent a 26
device identiﬁer. On return the device_handle argument provides an opaque handle to the tool for 27
this address space. 28
CHAPTER 5. OMPD INTERFACE 563
Cross References 1
ompd_size_t type, see Section 5.3.1 on page 536. 2
ompd_device_t type, see Section 5.3.6 on page 539. 3
ompd_address_space_handle_t type, see Section 5.3.8 on page 540. 4
ompd_address_space_context_t type, see Section 5.3.11 on page 542. 5
ompd_rc_t type, see Section 5.3.12 on page 543. 6
5.5.2.3 ompd_rel_address_space_handle 7
Summary 8
A tool calls ompd_rel_address_space_handle to release an address space handle. 9
Format 10
C
ompd_rc_t ompd_rel_address_space_handle( 11
ompd_address_space_handle_t *handle 12
); 13
C
Description 14
When the tool is ﬁnished with the OpenMP process address space handle it should call 15
ompd_rel_address_space_handle to release the handle, which allows the OMPD library 16
to release any resources that it has related to the address space. 17
Description of Arguments 18
Thehandleargument is an opaque handle for the address space to be released. 19
Restrictions 20
Theompd_rel_address_space_handle has the following restriction: 21
An address space context must not be used after the corresponding address space handle is 22
released. 23
564 OpenMP API – Version 5.0 November 2018
Cross References 1
ompd_address_space_handle_t type, see Section 5.3.8 on page 540. 2
ompd_rc_t type, see Section 5.3.12 on page 543. 3
5.5.3 Thread and Signal Safety4
The OMPD library does not need to be reentrant. The tool must ensure that only one thread enters 5
the OMPD library at a time. The OMPD library must not install signal handlers or otherwise 6
interfere with the tool’s signal conﬁguration. 7
5.5.4 Address Space Information8
5.5.4.1 ompd_get_omp_version 9
Summary 10
The tool may call the ompd_get_omp_version function to obtain the version of the OpenMP 11
API that is associated with an address space. 12
Format 13
C
ompd_rc_t ompd_get_omp_version( 14
ompd_address_space_handle_t *address_space , 15
ompd_word_t *omp_version 16
); 17
C
Description 18
The tool may call the ompd_get_omp_version function to obtain the version of the OpenMP 19
API that is associated with the address space. 20
CHAPTER 5. OMPD INTERFACE 565
Description of Arguments 1
Theaddress_space argument is an opaque handle that the tool provides to reference the address 2
space of the OpenMP process or device. 3
Upon return, the omp_version argument contains the version of the OpenMP runtime in the 4
_OPENMP version macro format. 5
Cross References 6
ompd_address_space_handle_t type, see Section 5.3.8 on page 540. 7
ompd_rc_t type, see Section 5.3.12 on page 543. 8
5.5.4.2 ompd_get_omp_version_string 9
Summary 10
Theompd_get_omp_version_string function returns a descriptive string for the OpenMP 11
API version that is associated with an address space. 12
Format 13
C
ompd_rc_t ompd_get_omp_version_string( 14
ompd_address_space_handle_t *address_space , 15
const char **string 16
); 17
C
Description 18
Afterinitialization,thetoolmaycallthe ompd_get_omp_version_string functiontoobtain 19
the version of the OpenMP API that is associated with an address space. 20
Description of Arguments 21
Theaddress_space argument is an opaque handle that the tool provides to reference the address 22
space of the OpenMP process or device. A pointer to a descriptive version string is placed into the 23
locationtowhichthe stringoutputargumentpoints. Afterreturningfromthecall,thetoolownsthe 24
string. The OMPD library must use the memory allocation callback that the tool provides to 25
allocate the string storage. The tool is responsible for releasing the memory. 26
566 OpenMP API – Version 5.0 November 2018
Cross References 1
ompd_address_space_handle_t type, see Section 5.3.8 on page 540. 2
ompd_rc_t type, see Section 5.3.12 on page 543. 3
5.5.5 Thread Handles4
5.5.5.1 ompd_get_thread_in_parallel 5
Summary 6
Theompd_get_thread_in_parallel function enables a tool to obtain handles for OpenMP 7
threads that are associated with a parallel region. 8
Format 9
C
ompd_rc_t ompd_get_thread_in_parallel( 10
ompd_parallel_handle_t *parallel_handle , 11
intthread_num , 12
ompd_thread_handle_t **thread_handle 13
); 14
C
Description 15
A successful invocation of ompd_get_thread_in_parallel returns a pointer to a thread 16
handle in the location to which thread_handle points. This call yields meaningful results only 17
if all OpenMP threads in the parallel region are stopped. 18
Description of Arguments 19
Theparallel_handle argument is an opaque handle for a parallel region and selects the parallel 20
regiononwhichtooperate. The thread_num argumentselectsthethreadoftheteamtobereturned. 21
On return, the thread_handle argument is an opaque handle for the selected thread. 22
Restrictions 23
Theompd_get_thread_in_parallel function has the following restriction: 24
The value of thread_num must be a non-negative integer smaller than the team size that was 25
provided as the ompd-team-size-var fromompd_get_icv_from_scope . 26
CHAPTER 5. OMPD INTERFACE 567
Cross References 1
ompd_parallel_handle_t type, see Section 5.3.8 on page 540. 2
ompd_thread_handle_t type, see Section 5.3.8 on page 540. 3
ompd_rc_t type, see Section 5.3.12 on page 543. 4
ompd_get_icv_from_scope call, see Section 5.5.9.2 on page 590. 5
5.5.5.2 ompd_get_thread_handle 6
Summary 7
Theompd_get_thread_handle function maps a native thread to an OMPD thread handle. 8
Format 9
C
ompd_rc_t ompd_get_thread_handle( 10
ompd_address_space_handle_t *handle , 11
ompd_thread_id_t kind, 12
ompd_size_t sizeof_thread_id , 13
const void *thread_id , 14
ompd_thread_handle_t **thread_handle 15
); 16
C
Description 17
Theompd_get_thread_handle function determines if the native thread identiﬁer to which 18
thread_id points represents an OpenMP thread. If so, the function returns ompd_rc_ok and the 19
location to which thread_handle points is set to the thread handle for the OpenMP thread. 20
Description of Arguments 21
Thehandleargument is an opaque handle that the tool provides to reference an address space. The 22
kind,sizeof_thread_id , andthread_id arguments represent a native thread identiﬁer. On return, the 23
thread_handle argumentprovidesanopaquehandletothethreadwithintheprovidedaddressspace. 24
The native thread identiﬁer to which thread_id points is guaranteed to be valid for the duration of 25
the call. If the OMPD library must retain the native thread identiﬁer, it must copy it. 26
568 OpenMP API – Version 5.0 November 2018
Cross References 1
ompd_size_t type, see Section 5.3.1 on page 536. 2
ompd_thread_id_t type, see Section 5.3.7 on page 539. 3
ompd_address_space_handle_t type, see Section 5.3.8 on page 540. 4
ompd_thread_handle_t type, see Section 5.3.8 on page 540. 5
ompd_rc_t type, see Section 5.3.12 on page 543. 6
5.5.5.3 ompd_rel_thread_handle 7
Summary 8
Theompd_rel_thread_handle function releases a thread handle. 9
Format 10
C
ompd_rc_t ompd_rel_thread_handle( 11
ompd_thread_handle_t *thread_handle 12
); 13
C
Description 14
Thread handles are opaque to tools, which therefore cannot release them directly. Instead, when the 15
tool is ﬁnished with a thread handle it must pass it to ompd_rel_thread_handle for disposal. 16
Description of Arguments 17
Thethread_handle argument is an opaque handle for a thread to be released. 18
Cross References 19
ompd_thread_handle_t type, see Section 5.3.8 on page 540. 20
ompd_rc_t type, see Section 5.3.12 on page 543. 21
CHAPTER 5. OMPD INTERFACE 569
5.5.5.4 ompd_thread_handle_compare 1
Summary 2
Theompd_thread_handle_compare function allows tools to compare two thread handles. 3
Format 4
C
ompd_rc_t ompd_thread_handle_compare( 5
ompd_thread_handle_t *thread_handle_1 , 6
ompd_thread_handle_t *thread_handle_2 , 7
int *cmp_value 8
); 9
C
Description 10
The internal structure of thread handles is opaque to a tool. While the tool can easily compare 11
pointers to thread handles, it cannot determine whether handles of two diﬀerent addresses refer to 12
the same underlying thread. The ompd_thread_handle_compare function compares thread 13
handles. 14
On success, ompd_thread_handle_compare returns in the location to which cmp_value 15
points a signed integer value that indicates how the underlying threads compare: a value less than, 16
equal to, or greater than 0 indicates that the thread corresponding to thread_handle_1 is, 17
respectively, less than, equal to, or greater than that corresponding to thread_handle_2 . 18
Description of Arguments 19
Thethread_handle_1 andthread_handle_2 arguments are opaque handles for threads. On return 20
thecmp_value argument is set to a signed integer value. 21
Cross References 22
ompd_thread_handle_t type, see Section 5.3.8 on page 540. 23
ompd_rc_t type, see Section 5.3.12 on page 543. 24
5.5.5.5 ompd_get_thread_id 25
Summary 26
Theompd_get_thread_id maps an OMPD thread handle to a native thread. 27
570 OpenMP API – Version 5.0 November 2018
Format 1
C
ompd_rc_t ompd_get_thread_id( 2
ompd_thread_handle_t *thread_handle , 3
ompd_thread_id_t kind, 4
ompd_size_t sizeof_thread_id , 5
void *thread_id 6
); 7
C
Description 8
Theompd_get_thread_id function maps an OMPD thread handle to a native thread identiﬁer. 9
Description of Arguments 10
Thethread_handle argument is an opaque thread handle. The kindargument represents the native 11
thread identiﬁer. The sizeof_thread_id argument represents the size of the native thread identiﬁer. 12
On return, the thread_id argument is a buﬀer that represents a native thread identiﬁer. 13
Cross References 14
ompd_size_t type, see Section 5.3.1 on page 536. 15
ompd_thread_id_t type, see Section 5.3.7 on page 539. 16
ompd_thread_handle_t type, see Section 5.3.8 on page 540. 17
ompd_rc_t type, see Section 5.3.12 on page 543. 18
5.5.6 Parallel Region Handles 19
5.5.6.1 ompd_get_curr_parallel_handle 20
Summary 21
Theompd_get_curr_parallel_handle function obtainsa pointerto theparallel handlefor 22
an OpenMP thread’s current parallel region. 23
CHAPTER 5. OMPD INTERFACE 571
Format 1
C
ompd_rc_t ompd_get_curr_parallel_handle( 2
ompd_thread_handle_t *thread_handle , 3
ompd_parallel_handle_t **parallel_handle 4
); 5
C
Description 6
Theompd_get_curr_parallel_handle function enables the tool to obtain a pointer to the 7
parallel handlefor thecurrent parallelregion that isassociated withan OpenMP thread. This call is 8
meaningful only if the associated thread is stopped. The parallel handle must be released by calling 9
ompd_rel_parallel_handle . 10
Description of Arguments 11
Thethread_handle argument is an opaque handle for a thread and selects the thread on which to 12
operate. On return, the parallel_handle argument is set to a handle for the parallel region that the 13
associated thread is currently executing, if any. 14
Cross References 15
ompd_thread_handle_t type, see Section 5.3.8 on page 540. 16
ompd_parallel_handle_t type, see Section 5.3.8 on page 540. 17
ompd_rc_t type, see Section 5.3.12 on page 543. 18
ompd_rel_parallel_handle call, see Section 5.5.6.4 on page 574. 19
5.5.6.2 ompd_get_enclosing_parallel_handle 20
Summary 21
Theompd_get_enclosing_parallel_handle function obtains a pointer to the parallel 22
handle for an enclosing parallel region. 23
572 OpenMP API – Version 5.0 November 2018
Format 1
C
ompd_rc_t ompd_get_enclosing_parallel_handle( 2
ompd_parallel_handle_t *parallel_handle , 3
ompd_parallel_handle_t **enclosing_parallel_handle 4
); 5
C
Description 6
Theompd_get_enclosing_parallel_handle function enables a tool to obtain a pointer 7
to the parallel handle for the parallel region that encloses the parallel region that 8
parallel_handle speciﬁes. This call is meaningful only if at least one thread in the parallel 9
region is stopped. A pointer to the parallel handle for the enclosing region is returned in the 10
location to which enclosing_parallel_handle points. After the call, the tool owns the handle; the 11
toolmustreleasethehandlewith ompd_rel_parallel_handle whenitisnolongerrequired. 12
Description of Arguments 13
Theparallel_handle argument is an opaque handle for a parallel region that selects the parallel 14
region on which to operate. On return, the enclosing_parallel_handle argument is set to a handle 15
for the parallel region that encloses the selected parallel region. 16
Cross References 17
ompd_parallel_handle_t type, see Section 5.3.8 on page 540. 18
ompd_rc_t type, see Section 5.3.12 on page 543. 19
ompd_rel_parallel_handle call, see Section 5.5.6.4 on page 574. 20
5.5.6.3 ompd_get_task_parallel_handle 21
Summary 22
Theompd_get_task_parallel_handle function obtainsa pointerto theparallel handlefor 23
the parallel region that encloses a task region. 24
CHAPTER 5. OMPD INTERFACE 573
Format 1
C
ompd_rc_t ompd_get_task_parallel_handle( 2
ompd_task_handle_t *task_handle , 3
ompd_parallel_handle_t **task_parallel_handle 4
); 5
C
Description 6
Theompd_get_task_parallel_handle function enables a tool to obtain a pointer to the 7
parallel handle for the parallel region that encloses the task region that task_handle speciﬁes. This 8
call is meaningful only if at least one thread in the parallel region is stopped. A pointer to the 9
parallel regions handle is returned in the location to which task_parallel_handle points. The tool 10
owns that parallel handle, which it must release with ompd_rel_parallel_handle . 11
Description of Arguments 12
Thetask_handle argument is an opaque handle that selects the task on which to operate. On return, 13
theparallel_handle argumentissettoahandlefortheparallelregionthatenclosestheselectedtask. 14
Cross References 15
ompd_task_handle_t type, see Section 5.3.8 on page 540. 16
ompd_parallel_handle_t type, see Section 5.3.8 on page 540. 17
ompd_rc_t type, see Section 5.3.12 on page 543. 18
ompd_rel_parallel_handle call, see Section 5.5.6.4 on page 574. 19
5.5.6.4 ompd_rel_parallel_handle 20
Summary 21
Theompd_rel_parallel_handle function releases a parallel region handle. 22
Format 23
C
ompd_rc_t ompd_rel_parallel_handle( 24
ompd_parallel_handle_t *parallel_handle 25
); 26
C
574 OpenMP API – Version 5.0 November 2018
Description 1
Parallel region handles are opaque so tools cannot release them directly. Instead, a tool must pass a 2
parallel region handle to the ompd_rel_parallel_handle function for disposal when 3
ﬁnished with it. 4
Description of Arguments 5
Theparallel_handle argument is an opaque handle to be released. 6
Cross References 7
ompd_parallel_handle_t type, see Section 5.3.8 on page 540. 8
ompd_rc_t type, see Section 5.3.12 on page 543. 9
5.5.6.5 ompd_parallel_handle_compare 10
Summary 11
Theompd_parallel_handle_compare function compares two parallel region handles. 12
Format 13
C
ompd_rc_t ompd_parallel_handle_compare( 14
ompd_parallel_handle_t *parallel_handle_1 , 15
ompd_parallel_handle_t *parallel_handle_2 , 16
int *cmp_value 17
); 18
C
Description 19
The internal structure of parallel region handles is opaque to tools. While tools can easily compare 20
pointers to parallel region handles, they cannot determine whether handles at two diﬀerent 21
addresses refer to the same underlying parallel region and, instead must use the 22
ompd_parallel_handle_compare function. 23
On success, ompd_parallel_handle_compare returns a signed integer value in the location 24
towhichcmp_value pointsthatindicateshowtheunderlyingparallelregionscompare. Avalueless 25
than, equal to, or greater than 0 indicates that the region corresponding to parallel_handle_1 is, 26
respectively, less than, equal to, or greater than that corresponding to parallel_handle_2 . This 27
function is provided since the means by which parallel region handles are ordered is 28
implementation deﬁned. 29
CHAPTER 5. OMPD INTERFACE 575
Description of Arguments 1
Theparallel_handle_1 andparallel_handle_2 arguments are opaque handles that correspond to 2
parallel regions. On return the cmp_value argument points to a signed integer value that indicates 3
how the underlying parallel regions compare. 4
Cross References 5
ompd_parallel_handle_t type, see Section 5.3.8 on page 540. 6
ompd_rc_t type, see Section 5.3.12 on page 543. 7
5.5.7 Task Handles8
5.5.7.1 ompd_get_curr_task_handle 9
Summary 10
Theompd_get_curr_task_handle function obtains a pointer to the task handle for the 11
current task region that is associated with an OpenMP thread. 12
Format 13
C
ompd_rc_t ompd_get_curr_task_handle( 14
ompd_thread_handle_t *thread_handle , 15
ompd_task_handle_t **task_handle 16
); 17
C
Description 18
Theompd_get_curr_task_handle function obtains a pointer to the task handle for the 19
current task region that is associated with an OpenMP thread. This call is meaningful only if the 20
thread for which the handle is provided is stopped. The task handle must be released with 21
ompd_rel_task_handle . 22
Description of Arguments 23
Thethread_handle argument is an opaque handle that selects the thread on which to operate. On 24
return, the task_handle argument points to a location that points to a handle for the task that the 25
thread is currently executing. 26
576 OpenMP API – Version 5.0 November 2018
Cross References 1
ompd_thread_handle_t type, see Section 5.3.8 on page 540. 2
ompd_task_handle_t type, see Section 5.3.8 on page 540. 3
ompd_rc_t type, see Section 5.3.12 on page 543. 4
ompd_rel_task_handle call, see Section 5.5.7.5 on page 580. 5
5.5.7.2 ompd_get_generating_task_handle 6
Summary 7
Theompd_get_generating_task_handle function obtains a pointer to the task handle of 8
the generating task region. 9
Format 10
C
ompd_rc_t ompd_get_generating_task_handle( 11
ompd_task_handle_t *task_handle , 12
ompd_task_handle_t **generating_task_handle 13
); 14
C
Description 15
Theompd_get_generating_task_handle function obtains a pointer to the task handle for 16
the task that encountered the OpenMP task construct that generated the task represented by 17
task_handle . The generating task is the OpenMP task that was active when the task speciﬁed by 18
task_handle was created. This call is meaningful only if the thread that is executing the task that 19
task_handle speciﬁes is stopped. The generating task handle must be released with 20
ompd_rel_task_handle . 21
Description of Arguments 22
Thetask_handle argument is an opaque handle that selects the task on which to operate. On return, 23
thegenerating_task_handle argument points to a location that points to a handle for the generating 24
task. 25
CHAPTER 5. OMPD INTERFACE 577
Cross References 1
ompd_task_handle_t type, see Section 5.3.8 on page 540. 2
ompd_rc_t type, see Section 5.3.12 on page 543. 3
ompd_rel_task_handle call, see Section 5.5.7.5 on page 580. 4
5.5.7.3 ompd_get_scheduling_task_handle 5
Summary 6
Theompd_get_scheduling_task_handle function obtains a task handle for the task that 7
was active at a task scheduling point. 8
Format 9
C
ompd_rc_t ompd_get_scheduling_task_handle( 10
ompd_task_handle_t *task_handle , 11
ompd_task_handle_t **scheduling_task_handle 12
); 13
C
Description 14
Theompd_get_scheduling_task_handle function obtains a task handle for the task that 15
was active when the task that task_handle represents was scheduled. This call is meaningful only if 16
the thread that is executing the task that task_handle speciﬁes is stopped. The scheduling task 17
handle must be released with ompd_rel_task_handle . 18
Description of Arguments 19
Thetask_handle argument is an opaque handle for a task and selects the task on which to operate. 20
On return, the scheduling_task_handle argument points to a location that points to a handle for the 21
task that is still on the stack of execution on the same thread and was deferred in favor of executing 22
the selected task. 23
Cross References 24
ompd_task_handle_t type, see Section 5.3.8 on page 540. 25
ompd_rc_t type, see Section 5.3.12 on page 543. 26
ompd_rel_task_handle call, see Section 5.5.7.5 on page 580. 27
578 OpenMP API – Version 5.0 November 2018
5.5.7.4 ompd_get_task_in_parallel 1
Summary 2
Theompd_get_task_in_parallel function obtains handles for the implicit tasks that are 3
associated with a parallel region. 4
Format 5
C
ompd_rc_t ompd_get_task_in_parallel( 6
ompd_parallel_handle_t *parallel_handle , 7
intthread_num , 8
ompd_task_handle_t **task_handle 9
); 10
C
Description 11
Theompd_get_task_in_parallel function obtains handles for the implicit tasks that are 12
associated with a parallel region. A successful invocation of ompd_get_task_in_parallel 13
returns a pointer to a task handle in the location to which task_handle points. This call yields 14
meaningful results only if all OpenMP threads in the parallel region are stopped. 15
Description of Arguments 16
Theparallel_handle argument is an opaque handle that selects the parallel region on which to 17
operate. The thread_num argument selects the implicit task of the team that is returned. The 18
selected implicit task would return thread_num from a call of the omp_get_thread_num() 19
routine. On return, the task_handle argument points to a location that points to an opaque handle 20
for the selected implicit task. 21
Restrictions 22
The following restriction applies to the ompd_get_task_in_parallel function: 23
The value of thread_num must be a non-negative integer that is smaller than the size of the team 24
size that is the value of the ompd-team-size-var thatompd_get_icv_from_scope returns. 25
CHAPTER 5. OMPD INTERFACE 579
Cross References 1
ompd_parallel_handle_t type, see Section 5.3.8 on page 540. 2
ompd_task_handle_t type, see Section 5.3.8 on page 540. 3
ompd_rc_t type, see Section 5.3.12 on page 543. 4
ompd_get_icv_from_scope call, see Section 5.5.9.2 on page 590. 5
5.5.7.5 ompd_rel_task_handle 6
Summary 7
Thisompd_rel_task_handle function releases a task handle. 8
Format 9
C
ompd_rc_t ompd_rel_task_handle( 10
ompd_task_handle_t *task_handle 11
); 12
C
Description 13
Task handles are opaque so tools cannot release them directly. Instead, when a tool is ﬁnished with 14
a task handle it must use the ompd_rel_task_handle function to release it. 15
Description of Arguments 16
Thetask_handle argument is an opaque task handle to be released. 17
Cross References 18
ompd_task_handle_t type, see Section 5.3.8 on page 540. 19
ompd_rc_t type, see Section 5.3.12 on page 543. 20
5.5.7.6 ompd_task_handle_compare 21
Summary 22
Theompd_task_handle_compare function compares task handles. 23
580 OpenMP API – Version 5.0 November 2018
Format 1
C
ompd_rc_t ompd_task_handle_compare( 2
ompd_task_handle_t *task_handle_1 , 3
ompd_task_handle_t *task_handle_2 , 4
int *cmp_value 5
); 6
C
Description 7
The internal structure of task handles is opaque so tools cannot directly determine if handles at two 8
diﬀerent addresses refer to the same underlying task. The ompd_task_handle_compare 9
function compares task handles. After a successful call to ompd_task_handle_compare , the 10
valueofthelocationtowhich cmp_value pointsisasignedintegerthatindicateshowtheunderlying 11
tasks compare: a value less than, equal to, or greater than 0 indicates that the task that corresponds 12
totask_handle_1 is, respectively, less than, equal to, or greater than the task that corresponds to 13
task_handle_2 . The means by which task handles are ordered is implementation deﬁned. 14
Description of Arguments 15
Thetask_handle_1 andtask_handle_2 arguments are opaque handles that correspond to tasks. On 16
return, the cmp_value argument points to a location in which a signed integer value indicates how 17
the underlying tasks compare. 18
Cross References 19
ompd_task_handle_t type, see Section 5.3.8 on page 540. 20
ompd_rc_t type, see Section 5.3.12 on page 543. 21
5.5.7.7 ompd_get_task_function 22
Summary 23
Thisompd_get_task_function function returns the entry point of the code that corresponds 24
to the body of a task. 25
CHAPTER 5. OMPD INTERFACE 581
Format 1
C
ompd_rc_t ompd_get_task_function ( 2
ompd_task_handle_t *task_handle , 3
ompd_address_t *entry_point 4
); 5
C
Description 6
Theompd_get_task_function function returns the entry point of the code that corresponds 7
to the body of code that the task executes. 8
Description of Arguments 9
Thetask_handle argument is an opaque handle that selects the task on which to operate. On return, 10
theentry_point argument is set to an address that describes the beginning of application code that 11
executes the task region. 12
Cross References 13
ompd_address_t type, see Section 5.3.4 on page 538. 14
ompd_task_handle_t type, see Section 5.3.8 on page 540. 15
ompd_rc_t type, see Section 5.3.12 on page 543. 16
5.5.7.8 ompd_get_task_frame 17
Summary 18
Theompd_get_task_frame function extracts the frame pointers of a task. 19
Format 20
C
ompd_rc_t ompd_get_task_frame ( 21
ompd_task_handle_t *task_handle , 22
ompd_frame_info_t *exit_frame , 23
ompd_frame_info_t *enter_frame 24
); 25
C
582 OpenMP API – Version 5.0 November 2018
Description 1
An OpenMP implementation maintains an ompt_frame_t object for every implicit or explicit 2
task. The ompd_get_task_frame function extracts the enter_frame andexit_frame ﬁelds of 3
theompt_frame_t object of the task that task_handle identiﬁes. 4
Description of Arguments 5
Thetask_handle argument speciﬁes an OpenMP task. On return, the exit_frame argument points to 6
anompd_frame_info_t object that has the frame information with the same semantics as the 7
exit_frame ﬁeldinthe ompt_frame_t objectthatisassociatedwiththespeciﬁedtask. Onreturn, 8
theenter_frame argument points to an ompd_frame_info_t object that has the frame 9
information with the same semantics as the enter_frame ﬁeld in the ompt_frame_t object that is 10
associated with the speciﬁed task. 11
Cross References 12
ompt_frame_t type, see Section 4.4.4.27 on page 454. 13
ompd_address_t type, see Section 5.3.4 on page 538. 14
ompd_frame_info_t type, see Section 5.3.5 on page 538. 15
ompd_task_handle_t type, see Section 5.3.8 on page 540. 16
ompd_rc_t type, see Section 5.3.12 on page 543. 17
5.5.7.9 ompd_enumerate_states 18
Summary 19
Theompd_enumerate_states function enumerates thread states that an OpenMP 20
implementation supports. 21
Format 22
C
ompd_rc_t ompd_enumerate_states ( 23
ompd_address_space_handle_t *address_space_handle , 24
ompd_word_t current_state , 25
ompd_word_t *next_state , 26
const char **next_state_name , 27
ompd_word_t *more_enums 28
); 29
C
CHAPTER 5. OMPD INTERFACE 583
Description 1
An OpenMP implementation may support only a subset of the states that the ompt_state_t 2
enumeration type deﬁnes. In addition, an OpenMP implementation may support 3
implementation-speciﬁc states. The ompd_enumerate_states call enables a tool to 4
enumerate the thread states that an OpenMP implementation supports. 5
When the current_state argument is a thread state that an OpenMP implementation supports, the 6
call assigns the value and string name of the next thread state in the enumeration to the locations to 7
which the next_state andnext_state_name arguments point. 8
On return, the third-party tool owns the next_state_name string. The OMPD library allocates 9
storage for the string with the memory allocation callback that the tool provides. The tool is 10
responsible for releasing the memory. 11
On return, the location to which the more_enums argument points has the value 1whenever one or 12
more states are left in the enumeration. On return, the location to which the more_enums argument 13
points has the value 0whencurrent_state is the last state in the enumeration. 14
Description of Arguments 15
Theaddress_space_handle argumentidentiﬁestheaddressspace. The current_state argumentmust 16
be a thread state that the OpenMP implementation supports. To begin enumerating the supported 17
states, a tool should pass ompt_state_undefined as the value of current_state . Subsequent 18
calls to ompd_enumerate_states by the tool should pass the value that the call returned in 19
thenext_state argument. On return, the next_state argument points to an integer with the value of 20
the next state in the enumeration. On return, the next_state_name argument points to a character 21
string that describes the next state. On return, the more_enums argument points to an integer with a 22
value of 1when more states are left to enumerate and a value of 0when no more states are left. 23
Constraints on Arguments 24
Any string that is returned through the next_state_name argument must be immutable and deﬁned 25
for the lifetime of program execution. 26
Cross References 27
ompt_state_t type, see Section 4.4.4.26 on page 452. 28
ompd_address_space_handle_t type, see Section 5.3.8 on page 540. 29
ompd_rc_t type, see Section 5.3.12 on page 543. 30
584OpenMP API – Version 5.0 November 2018
5.5.7.10 ompd_get_state 1
Summary 2
Theompd_get_state function obtains the state of a thread. 3
Format 4
C
ompd_rc_t ompd_get_state ( 5
ompd_thread_handle_t *thread_handle , 6
ompd_word_t *state, 7
ompt_wait_id_t *wait_id 8
); 9
C
Description 10
Theompd_get_state function returns the state of an OpenMP thread. 11
Description of Arguments 12
Thethread_handle argument identiﬁes the thread. The stateargument represents the state of that 13
thread as represented by a value that ompd_enumerate_states returns. On return, if the 14
wait_idargument is non-null then it points to a handle that corresponds to the wait_idwait 15
identiﬁer of the thread. If the thread state is not one of the speciﬁed wait states, the value to which 16
wait_idpoints is undeﬁned. 17
Cross References 18
ompd_wait_id_t type, see Section 5.3.2 on page 537. 19
ompd_thread_handle_t type, see Section 5.3.8 on page 540. 20
ompd_rc_t type, see Section 5.3.12 on page 543. 21
ompd_enumerate_states call, see Section 5.5.7.9 on page 583. 22
CHAPTER 5. OMPD INTERFACE 585
5.5.8 Display Control Variables1
5.5.8.1 ompd_get_display_control_vars 2
Summary 3
Theompd_get_display_control_vars function returns a list of name/value pairs for 4
OpenMP control variables. 5
Format 6
C
ompd_rc_t ompd_get_display_control_vars ( 7
ompd_address_space_handle_t *address_space_handle , 8
const char *const **control_vars 9
); 10
C
Description 11
Theompd_get_display_control_vars function returns a NULL-terminated vector of 12
NULL-terminated strings of name/value pairs of control variables that have user controllable 13
settings and are important to the operation or performance of an OpenMP runtime system. The 14
control variables that this interface exposes include all OpenMP environment variables, settings 15
that may come from vendor or platform-speciﬁc environment variables, and other settings that 16
aﬀect the operation or functioning of an OpenMP runtime. 17
The format of the strings is name=a string . 18
On return, the third-party tool owns the vector and the strings. The OMP library must satisfy the 19
terminationconstraints;itmayusestaticordynamicmemoryforthevectorand/orthestringsandis 20
unconstrained in how it arranges them in memory. If it uses dynamic memory then the OMPD 21
librarymustusetheallocatecallbackthatthetoolprovidesto ompd_initialize . Thetoolmust 22
useompd_rel_display_control_vars() to release the vector and the strings. 23
Description of Arguments 24
Theaddress_space_handle argument identiﬁes the address space. On return, the control_vars 25
argument points to the vector of display control variables. 26
586 OpenMP API – Version 5.0 November 2018
Cross References 1
ompd_address_space_handle_t type, see Section 5.3.8 on page 540. 2
ompd_rc_t type, see Section 5.3.12 on page 543. 3
ompd_initialize call, see Section 5.5.1.1 on page 558. 4
ompd_rel_display_control_vars type, see Section 5.5.8.2 on page 587. 5
5.5.8.2 ompd_rel_display_control_vars 6
Summary 7
Theompd_rel_display_control_vars releases a list of name/value pairs of OpenMP 8
control variables previously acquired with ompd_get_display_control_vars . 9
Format 10
C
ompd_rc_t ompd_rel_display_control_vars ( 11
const char *const **control_vars 12
); 13
C
Description 14
The third-party tool owns the vector and strings that ompd_get_display_control_vars 15
returns. The tool must call ompd_rel_display_control_vars to release the vector and the 16
strings. 17
Description of Arguments 18
Thecontrol_vars argument is the vector of display control variables to be released. 19
Cross References 20
ompd_rc_t type, see Section 5.3.12 on page 543. 21
ompd_get_display_control_vars call, see Section 5.5.8.1 on page 586. 22
CHAPTER 5. OMPD INTERFACE 587
5.5.9 Accessing Scope-Speciﬁc Information1
5.5.9.1 ompd_enumerate_icvs 2
Summary 3
Theompd_enumerate_icvs function enumerates ICVs. 4
Format 5
C
ompd_rc_t ompd_enumerate_icvs ( 6
ompd_address_space_handle_t *handle , 7
ompd_icv_id_t current , 8
ompd_icv_id_t *next_id , 9
const char **next_icv_name , 10
ompd_scope_t *next_scope , 11
int *more 12
); 13
C
Description 14
In addition to the ICVs listed in Table 2.1, an OpenMP implementation must support the OMPD 15
speciﬁc ICVs listed in Table 5.2. An OpenMP implementation may support additional 16
implementation speciﬁc variables. An implementation may store ICVs in a diﬀerent scope than 17
Table 2.3 indicates. The ompd_enumerate_icvs function enables a tool to enumerate the 18
ICVs that an OpenMP implementation supports and their related scopes. 19
When the currentargument is set to the identiﬁer of a supported ICV, ompd_enumerate_icvs 20
assigns the value, string name, and scope of the next ICV in the enumeration to the locations to 21
which the next_id,next_icv_name , andnext_scope arguments point. On return, the third-party tool 22
owns the next_icv_name string. The OMPD library uses the memory allocation callback that the 23
tool provides to allocate the string storage; the tool is responsible for releasing the memory. 24
On return, the location to which the moreargument points has the value of 1whenever one or more 25
ICV are left in the enumeration. on return, that location has the value 0whencurrentis the last 26
ICV in the enumeration. 27
588 OpenMP API – Version 5.0 November 2018
Description of Arguments 1
Theaddress_space_handle argument identiﬁes the address space. The currentargument must be 2
an ICV that the OpenMP implementation supports. To begin enumerating the ICVs, a tool should 3
passompd_icv_undefined as the value of current. Subsequent calls to 4
ompd_enumerate_icvs should pass the value returned by the call in the next_idoutput 5
argument. On return, the next_idargument points to an integer with the value of the ID of the next 6
ICV in the enumeration. On return, the next_icvargument points to a character string with the 7
name of the next ICV. On return, the next_scope argument points to the scope enum value of the 8
scope of the next ICV. On return, the more_enums argument points to an integer with the value of 1 9
when more ICVs are left to enumerate and the value of 0when no more ICVs are left. 10
Constraints on Arguments 11
Any string that next_icvreturns must be immutable and deﬁned for the lifetime of a program 12
execution. 13
TABLE 5.2:OMPD-speciﬁc ICVs
Variable Scope Meaning
ompd-num-procs-var device return value of omp_get_num_procs()
when executed on this device
ompd-thread-num-var task return value of omp_get_thread_num()
when executed in this task
ompd-ﬁnal-var task return value of omp_in_final() when
executed in this task
ompd-implicit-var task the task is an implicit task
ompd-team-size-var team return value of omp_get_num_threads()
when executed in this team
Cross References 14
ompd_address_space_handle_t type, see Section 5.3.8 on page 540. 15
ompd_scope_t type, see Section 5.3.9 on page 541. 16
ompd_icv_id_t type, see Section 5.3.10 on page 542. 17
ompd_rc_t type, see Section 5.3.12 on page 543. 18
CHAPTER 5. OMPD INTERFACE 589
5.5.9.2 ompd_get_icv_from_scope 1
Summary 2
Theompd_get_icv_from_scope function returns the value of an ICV. 3
Format 4
C
ompd_rc_t ompd_get_icv_from_scope ( 5
void *handle , 6
ompd_scope_t scope , 7
ompd_icv_id_t icv_id , 8
ompd_word_t *icv_value 9
); 10
C
Description 11
Theompd_get_icv_from_scope function provides access to the ICVs that 12
ompd_enumerate_icvs identiﬁes. 13
Description of Arguments 14
Thehandleargument provides an OpenMP scope handle. The scopeargument speciﬁes the kind of 15
scope provided in handle. Theicv_idargument speciﬁes the ID of the requested ICV. On return, 16
theicv_value argument points to a location with the value of the requested ICV. 17
Constraints on Arguments 18
If the ICV cannot be represented by an integer type value then the function returns 19
ompd_rc_incompatible . 20
The provided handlemust match the scopeas deﬁned in Section 5.3.10 on page 542. 21
The provided scopemust match the scope for icv_idas requested by ompd_enumerate_icvs . 22
590 OpenMP API – Version 5.0 November 2018
Cross References 1
ompd_address_space_handle_t type, see Section 5.3.8 on page 540. 2
ompd_thread_handle_t type, see Section 5.3.8 on page 540. 3
ompd_parallel_handle_t type, see Section 5.3.8 on page 540. 4
ompd_task_handle_t type, see Section 5.3.8 on page 540. 5
ompd_scope_t type, see Section 5.3.9 on page 541. 6
ompd_icv_id_t type, see Section 5.3.10 on page 542. 7
ompd_rc_t type, see Section 5.3.12 on page 543. 8
ompd_enumerate_icvs , see Section 5.5.9.1 on page 588. 9
5.5.9.3 ompd_get_icv_string_from_scope 10
Summary 11
Theompd_get_icv_string_from_scope function returns the value of an ICV. 12
Format 13
C
ompd_rc_t ompd_get_icv_string_from_scope ( 14
void *handle , 15
ompd_scope_t scope , 16
ompd_icv_id_t icv_id , 17
const char **icv_string 18
); 19
C
Description 20
Theompd_get_icv_string_from_scope function provides access to the ICVs that 21
ompd_enumerate_icvs identiﬁes. 22
CHAPTER 5. OMPD INTERFACE 591
Description of Arguments 1
Thehandleargument provides an OpenMP scope handle. The scopeargument speciﬁes the kind of 2
scope provided in handle. Theicv_idargument speciﬁes the ID of the requested ICV. On return, 3
theicv_string argument points to a string representation of the requested ICV. 4
On return, the third-party tool owns the icv_string string. The OMPD library allocates the string 5
storage with the memory allocation callback that the tool provides. The tool is responsible for 6
releasing the memory. 7
Constraints on Arguments 8
The provided handlemust match the scopeas deﬁned in Section 5.3.10 on page 542. 9
The provided scopemust match the scope for icv_idas requested by ompd_enumerate_icvs . 10
Cross References 11
ompd_address_space_handle_t type, see Section 5.3.8 on page 540. 12
ompd_thread_handle_t type, see Section 5.3.8 on page 540. 13
ompd_parallel_handle_t type, see Section 5.3.8 on page 540. 14
ompd_task_handle_t type, see Section 5.3.8 on page 540. 15
ompd_scope_t type, see Section 5.3.9 on page 541. 16
ompd_icv_id_t type, see Section 5.3.10 on page 542. 17
ompd_rc_t type, see Section 5.3.12 on page 543. 18
ompd_enumerate_icvs , see Section 5.5.9.1 on page 588. 19
5.5.9.4 ompd_get_tool_data 20
Summary 21
Theompd_get_tool_data function provides access to the OMPT data variable stored for each 22
OpenMP scope. 23
592OpenMP API – Version 5.0 November 2018
Format 1
C
ompd_rc_t ompd_get_tool_data( 2
void *handle , 3
ompd_scope_t scope , 4
ompd_word_t *value, 5
ompd_address_t *ptr 6
); 7
C
Description 8
Theompd_get_tool_data function provides access to the OMPT tool data stored for each 9
scope. If the runtime library does not support OMPT then the function returns 10
ompd_rc_unsupported . 11
Description of Arguments 12
Thehandleargument provides an OpenMP scope handle. The scopeargument speciﬁes the kind of 13
scope provided in handle. On return, the valueargument points to the valueﬁeld of the 14
ompt_data_t union stored for the selected scope. On return, the ptrargument points to the ptr 15
ﬁeld of the ompt_data_t union stored for the selected scope. 16
Cross References 17
ompt_data_t type, see Section 4.4.4.4 on page 440. 18
ompd_address_space_handle_t type, see Section 5.3.8 on page 540. 19
ompd_thread_handle_t type, see Section 5.3.8 on page 540. 20
ompd_parallel_handle_t type, see Section 5.3.8 on page 540. 21
ompd_task_handle_t type, see Section 5.3.8 on page 540. 22
ompd_scope_t type, see Section 5.3.9 on page 541. 23
ompd_rc_t type, see Section 5.3.12 on page 543. 24
CHAPTER 5. OMPD INTERFACE 593
5.6 Runtime Entry Points for OMPD1
The OpenMP implementation must deﬁne several entry point symbols through which execution 2
mustpasswhenparticulareventsoccur anddatacollectionforOMPDisenabled. Atoolcanenable 3
notiﬁcation of an event by setting a breakpoint at the address of the entry point symbol. 4
Entry point symbols have external Clinkage and do not require demangling or other 5
transformations to look up their names to obtain the address in the OpenMP program. While each 6
entry point symbol conceptually has a function type signature, it may not be a function. It may be a 7
labeled location 8
5.6.1 Beginning Parallel Regions9
Summary 10
Before starting the execution of an OpenMP parallel region, the implementation executes 11
ompd_bp_parallel_begin . 12
Format 13
C
void ompd_bp_parallel_begin(void); 14
C
Description 15
The OpenMP implementation must execute ompd_bp_parallel_begin at every 16
parallel-begin event. At the point that the implementation reaches 17
ompd_bp_parallel_begin , the binding for ompd_get_curr_parallel_handle is the 18
parallel region that is beginning and the binding for ompd_get_curr_task_handle is the 19
task that encountered the parallel construct. 20
Cross References 21
parallel construct, see Section 2.6 on page 74. 22
ompd_get_curr_parallel_handle , see Section 5.5.6.1 on page 571. 23
ompd_get_curr_task_handle , see Section 5.5.7.1 on page 576. 24
594 OpenMP API – Version 5.0 November 2018
5.6.2 Ending Parallel Regions1
Summary 2
After ﬁnishing the execution of an OpenMP parallel region, the implementation executes 3
ompd_bp_parallel_end . 4
Format 5
C
void ompd_bp_parallel_end(void); 6
C
Description 7
The OpenMP implementation must execute ompd_bp_parallel_end at everyparallel-end 8
event. At the point that the implementation reaches ompd_bp_parallel_end , the binding for 9
ompd_get_curr_parallel_handle isthe parallel regionthatisendingandthebinding 10
forompd_get_curr_task_handle is the task that encountered the parallel construct. 11
After execution of ompd_bp_parallel_end , anyparallel_handle that was acquired for the 12
parallel region is invalid and should be released. 13
Cross References 14
parallel construct, see Section 2.6 on page 74. 15
ompd_get_curr_parallel_handle , see Section 5.5.6.1 on page 571. 16
ompd_rel_parallel_handle , see Section 5.5.6.4 on page 574. 17
ompd_get_curr_task_handle , see Section 5.5.7.1 on page 576. 18
5.6.3 Beginning Task Regions 19
Summary 20
Before starting the execution of an OpenMP task region, the implementation executes 21
ompd_bp_task_begin . 22
CHAPTER 5. OMPD INTERFACE 595
Format 1
C
void ompd_bp_task_begin(void); 2
C
Description 3
The OpenMP implementation must execute ompd_bp_task_begin immediately before starting 4
execution of a structured-block that is associated with a non-merged task. At the point that the 5
implementation reaches ompd_bp_task_begin , the binding for 6
ompd_get_curr_task_handle is the task that is scheduled to execute. 7
Cross References 8
ompd_get_curr_task_handle , see Section 5.5.7.1 on page 576. 9
5.6.4 Ending Task Regions 10
Summary 11
After ﬁnishing the execution of an OpenMP task region, the implementation executes 12
ompd_bp_task_end . 13
Format 14
C
void ompd_bp_task_end(void); 15
C
Description 16
The OpenMP implementation must execute ompd_bp_task_end immediately after completion 17
ofastructured-block thatisassociatedwithanon-mergedtask. Atthepointthattheimplementation 18
reaches ompd_bp_task_end , the binding for ompd_get_curr_task_handle is the task 19
that ﬁnished execution. After execution of ompd_bp_task_end , anytask_handle that was 20
acquired for the task region is invalid and should be released. 21
596 OpenMP API – Version 5.0 November 2018
Cross References 1
ompd_get_curr_task_handle , see Section 5.5.7.1 on page 576. 2
ompd_rel_task_handle , see Section 5.5.7.5 on page 580. 3
5.6.5 Beginning OpenMP Threads4
Summary 5
When starting an OpenMP thread, the implementation executes ompd_bp_thread_begin . 6
Format 7
C
void ompd_bp_thread_begin(void); 8
C
Description 9
The OpenMP implementation must execute ompd_bp_thread_begin at every 10
native-thread-begin andinitial-thread-begin event. This execution occurs before the thread starts 11
the execution of any OpenMP region. 12
Cross References 13
parallel construct, see Section 2.6 on page 74. 14
Initial task, see Section 2.10.5 on page 148. 15
5.6.6 Ending OpenMP Threads 16
Summary 17
When terminating an OpenMP thread, the implementation executes ompd_bp_thread_end . 18
Format 19
C
void ompd_bp_thread_end(void); 20
C
CHAPTER 5. OMPD INTERFACE 597
Description 1
The OpenMP implementation must execute ompd_bp_thread_end at everynative-thread-end 2
and theinitial-thread-end event. This execution occurs after the thread completes the execution of 3
all OpenMP regions. After executing ompd_bp_thread_end , anythread_handle that was 4
acquired for this thread is invalid and should be released. 5
Cross References 6
parallel construct, see Section 2.6 on page 74. 7
Initial task, see Section 2.10.5 on page 148. 8
ompd_rel_thread_handle , see Section 5.5.5.3 on page 569. 9
5.6.7 Initializing OpenMP Devices 10
Summary 11
The OpenMP implementation must execute ompd_bp_device_begin at everydevice-initialize 12
event. 13
Format 14
C
void ompd_bp_device_begin(void); 15
C
Description 16
When initializing a device for execution of a target region, the implementation must execute 17
ompd_bp_device_begin . This execution occurs before the work associated with any OpenMP 18
region executes on the device. 19
Cross References 20
Device Initialization, see Section 2.12.1 on page 160. 21
598 OpenMP API – Version 5.0 November 2018
5.6.8 Finalizing OpenMP Devices1
Summary 2
When terminating an OpenMP thread, the implementation executes ompd_bp_device_end . 3
Format 4
C
void ompd_bp_device_end(void); 5
C
Description 6
The OpenMP implementation must execute ompd_bp_device_end at everydevice-ﬁnalize 7
event. This execution occurs after the thread executes all OpenMP regions. After execution of 8
ompd_bp_device_end , anyaddress_space_handle that was acquired for this device is invalid 9
and should be released. 10
Cross References 11
Device Initialization, see Section 2.12.1 on page 160. 12
ompd_rel_address_space_handle , see Section 5.5.2.3 on page 564. 13
CHAPTER 5. OMPD INTERFACE 599
This page intentionally left blank
CHAPTER 6
Environment Variables 1
2
This chapter describes the OpenMP environment variables that specify the settings of the ICVs that 3
aﬀect the execution of OpenMP programs (see Section 2.5 on page 63). The names of the 4
environment variables must be upper case. The values assigned to the environment variables are 5
case insensitive and may have leading and trailing white space. Modiﬁcations to the environment 6
variables after the program has started, even if modiﬁed by the program itself, are ignored by the 7
OpenMP implementation. However, the settings of some of the ICVs can be modiﬁed during the 8
execution of the OpenMP program by the use of the appropriate directive clauses or OpenMP API 9
routines. 10
The following examples demonstrate how the OpenMP environment variables can be set in 11
diﬀerent environments: 12
csh-like shells: 13
setenv OMP_SCHEDULE "dynamic" 14
bash-like shells: 15
export OMP_SCHEDULE="dynamic" 16
Windows Command Line: 17
set OMP_SCHEDULE=dynamic 18
6.1 OMP_SCHEDULE 19
TheOMP_SCHEDULE environment variable controls the schedule kind and chunk size of all loop 20
directives that have the schedule kind runtime , by setting the value of the run-sched-var ICV. 21
The value of this environment variable takes the form: 22
601
[modiﬁer :]kind[,chunk] 1
where 2
modiﬁeris one of monotonic ornonmonotonic ; 3
kindis one of static,dynamic ,guided, orauto; 4
chunkis an optional positive integer that speciﬁes the chunk size. 5
If themodiﬁeris not present, the modiﬁeris set to monotonic ifkindisstatic; for any other 6
kindit is set to nonmonotonic . 7
Ifchunkis present, white space may be on either side of the “ ,”. See Section 2.9.2 on page 101 for 8
a detailed description of the schedule kinds. 9
The behavior of the program is implementation deﬁned if the value of OMP_SCHEDULE does not 10
conform to the above format. 11
Implementation speciﬁc schedules cannot be speciﬁed in OMP_SCHEDULE . They can only be 12
speciﬁed by calling omp_set_schedule , described in Section 3.2.12 on page 345. 13
Examples: 14
setenv OMP_SCHEDULE "guided,4" 15
setenv OMP_SCHEDULE "dynamic" 16
setenv OMP_SCHEDULE "nonmonotonic:dynamic,4" 17
Cross References 18
run-sched-var ICV, see Section 2.5 on page 63. 19
Worksharing-Loop construct, see Section 2.9.2 on page 101. 20
Parallel worksharing-loop construct, see Section 2.13.1 on page 185. 21
omp_set_schedule routine, see Section 3.2.12 on page 345. 22
omp_get_schedule routine, see Section 3.2.13 on page 347. 23
6.2 OMP_NUM_THREADS 24
TheOMP_NUM_THREADS environment variable sets the number of threads to use for parallel 25
regions by setting the initial value of the nthreads-var ICV. See Section 2.5 on page 63 for a 26
comprehensive set of rules about the interaction between the OMP_NUM_THREADS environment 27
variable, the num_threads clause, the omp_set_num_threads library routine and dynamic 28
602 OpenMP API – Version 5.0 November 2018
adjustmentofthreads,andSection2.6.1onpage78foracompletealgorithmthatdescribeshowthe 1
number of threads for a parallel region is determined. 2
The value of this environment variable must be a list of positive integer values. The values of the 3
list set the number of threads to use for parallel regions at the corresponding nested levels. 4
The behavior of the program is implementation deﬁned if any value of the list speciﬁed in the 5
OMP_NUM_THREADS environment variable leads to a number of threads that is greater than an 6
implementation can support, or if any value is not a positive integer. 7
Example: 8
setenv OMP_NUM_THREADS 4,3,2 9
Cross References 10
nthreads-var ICV, see Section 2.5 on page 63. 11
num_threads clause, see Section 2.6 on page 74. 12
omp_set_num_threads routine, see Section 3.2.1 on page 334. 13
omp_get_num_threads routine, see Section 3.2.2 on page 335. 14
omp_get_max_threads routine, see Section 3.2.3 on page 336. 15
omp_get_team_size routine, see Section 3.2.20 on page 354. 16
6.3 OMP_DYNAMIC 17
TheOMP_DYNAMIC environment variable controls dynamic adjustment of the number of threads 18
to use for executing parallel regions by setting the initial value of the dyn-varICV. 19
The value of this environment variable must be one of the following: 20
true|false 21
If the environment variable is set to true, the OpenMP implementation may adjust the number of 22
threadsto useforexecuting parallel regionsin ordertooptimize theuseof systemresources. If 23
the environment variable is set to false, the dynamic adjustment of the number of threads is 24
disabled. The behavior of the program is implementation deﬁned if the value of OMP_DYNAMIC is 25
neither truenorfalse. 26
Example: 27
setenv OMP_DYNAMIC true 28
CHAPTER 6. ENVIRONMENT VARIABLES 603
Cross References 1
dyn-varICV, see Section 2.5 on page 63. 2
omp_set_dynamic routine, see Section 3.2.7 on page 340. 3
omp_get_dynamic routine, see Section 3.2.8 on page 341. 4
6.4 OMP_PROC_BIND 5
TheOMP_PROC_BIND environment variable sets the initial value of the bind-varICV. The value 6
of this environment variable is either true,false, or a comma separated list of master, 7
close, orspread. The values of the list set the thread aﬃnity policy to be used for parallel 8
regions at the corresponding nested level. 9
Iftheenvironmentvariableissetto false,theexecutionenvironmentmaymoveOpenMPthreads 10
between OpenMP places, thread aﬃnity is disabled, and proc_bind clauses on parallel 11
constructs are ignored. 12
Otherwise, the execution environment should not move OpenMP threads between OpenMP places, 13
thread aﬃnity is enabled, and the initial thread is bound to the ﬁrst place in the OpenMP place list 14
prior to the ﬁrst active parallel region. 15
The behavior of the program is implementation deﬁned if the value in the OMP_PROC_BIND 16
environment variable is not true,false, or a comma separated list of master,close, or 17
spread. The behavior is also implementation deﬁned if an initial thread cannot be bound to the 18
ﬁrst place in the OpenMP place list. 19
Examples: 20
setenv OMP_PROC_BIND false 21
setenv OMP_PROC_BIND "spread, spread, close" 22
Cross References 23
bind-varICV, see Section 2.5 on page 63. 24
proc_bind clause, see Section 2.6.2 on page 80. 25
omp_get_proc_bind routine, see Section 3.2.23 on page 357. 26
604 OpenMP API – Version 5.0 November 2018
6.5 OMP_PLACES 1
A list of places can be speciﬁed in the OMP_PLACES environment variable. The 2
place-partition-var ICV obtains its initial value from the OMP_PLACES value, and makes the list 3
available to the execution environment. The value of OMP_PLACES can be one of two types of 4
values: either an abstract name that describes a set of places or an explicit list of places described 5
by non-negative numbers. 6
TheOMP_PLACES environment variable can be deﬁned using an explicit ordered list of 7
comma-separated places. A place is deﬁned by an unordered set of comma-separated non-negative 8
numbers enclosed by braces. The meaning of the numbers and how the numbering is done are 9
implementationdeﬁned. Generally,thenumbersrepresentthesmallestunitofexecutionexposedby 10
the execution environment, typically a hardware thread. 11
Intervals may also be used to deﬁne places. Intervals can be speciﬁed using the < lower-bound > : 12
<length> : <stride> notation to represent the following list of numbers: “< lower-bound >, 13
<lower-bound > + <stride>, ..., <lower-bound > + (<length> - 1)*<stride>.” When < stride> is 14
omitted, a unit stride is assumed. Intervals can specify numbers within a place as well as sequences 15
of places. 16
An exclusion operator “ !” can also be used to exclude the number or place immediately following 17
the operator. 18
Alternatively, the abstract names listed in Table 6.1 should be understood by the execution and 19
runtimeenvironment. Theprecisedeﬁnitionsoftheabstractnamesareimplementationdeﬁned. An 20
implementation may also add abstract names as appropriate for the target platform. 21
TABLE 6.1:Deﬁned Abstract Names for OMP_PLACES
Abstract Name Meaning
threads Each place corresponds to a single hardware thread on the
target machine.
cores Each place corresponds to a single core (having one or more
hardware threads) on the target machine.
sockets Each place corresponds to a single socket (consisting of one or
more cores) on the target machine.
Theabstractnamemaybeappendedbyapositivenumberinparenthesestodenotethelengthofthe 22
place list to be created, that is abstract_name(num-places) . When requesting fewer places than 23
available on the system, the determination of which resources of type abstract_name are to be 24
included in the place list is implementation deﬁned. When requesting more resources than 25
available, the length of the place list is implementation deﬁned. 26
The behavior of the program is implementation deﬁned when the execution environment cannot 27
map a numerical value (either explicitly deﬁned or implicitly derived from an interval) within the 28
CHAPTER 6. ENVIRONMENT VARIABLES 605
OMP_PLACES list to a processor on the target platform, or if it maps to an unavailable processor. 1
The behavior is also implementation deﬁned when the OMP_PLACES environment variable is 2
deﬁned using an abstract name. 3
The following grammar describes the values accepted for the OMP_PLACES environment variable. 4
hlisti j=hp-listi j hanamei
hp-listi j=hp-intervali j hp-listi,hp-intervali
hp-intervali j=hplacei:hleni:hstridei j hplacei:hleni j hplacei j!hplacei
hplacei j={hres-listi}
hres-listi j=hres-intervali j hres-listi,hres-intervali
hres-intervali j=hresi:hnum-placesi:hstridei j hresi:hnum-placesi j hresi j!hresi
hanamei j=hwordi(hnum-placesi)j hwordi
hwordi j=socketsjcoresjthreadsj<implementation-deﬁned abstract name>
hresi j=non-negative integer
hnum-placesi j=positive integer
hstridei j=integer
hleni j=positive integer
Examples: 5
setenv OMP_PLACES threads 6
setenv OMP_PLACES "threads(4)" 7
setenv OMP_PLACES 8
"{0,1,2,3},{4,5,6,7},{8,9,10,11},{12,13,14,15}" 9
setenv OMP_PLACES "{0:4},{4:4},{8:4},{12:4}" 10
setenv OMP_PLACES "{0:4}:4:4" 11
where each of the last three deﬁnitions corresponds to the same 4 places including the smallest 12
units of execution exposed by the execution environment numbered, in turn, 0 to 3, 4 to 7, 8 to 11, 13
and 12 to 15. 14
Cross References 15
place-partition-var , see Section 2.5 on page 63. 16
Controlling OpenMP thread aﬃnity, see Section 2.6.2 on page 80. 17
omp_get_num_places routine, see Section 3.2.24 on page 358. 18
omp_get_place_num_procs routine, see Section 3.2.25 on page 359. 19
606 OpenMP API – Version 5.0 November 2018
omp_get_place_proc_ids routine, see Section 3.2.26 on page 360. 1
omp_get_place_num routine, see Section 3.2.27 on page 362. 2
omp_get_partition_num_places routine, see Section 3.2.28 on page 362. 3
omp_get_partition_place_nums routine, see Section 3.2.29 on page 363. 4
6.6 OMP_STACKSIZE 5
TheOMP_STACKSIZE environment variable controls the size of the stack for threads created by 6
the OpenMP implementation, by setting the value of the stacksize-var ICV. The environment 7
variable does not control the size of the stack for an initial thread. 8
The value of this environment variable takes the form: 9
size|sizeB|sizeK|sizeM|sizeG 10
where: 11
sizeis a positive integer that speciﬁes the size of the stack for threads that are created by the 12
OpenMP implementation. 13
B,K,M, andGare letters that specify whether the given size is in Bytes, Kilobytes (1024 Bytes), 14
Megabytes (1024 Kilobytes), or Gigabytes (1024 Megabytes), respectively. If one of these letters 15
is present, there may be white space between sizeand the letter. 16
Ifonlysizeisspeciﬁedandnoneof B,K,M,orGisspeciﬁed,then sizeisassumedtobeinKilobytes. 17
The behavior of the program is implementation deﬁned if OMP_STACKSIZE does not conform to 18
the above format, or if the implementation cannot provide a stack with the requested size. 19
Examples: 20
setenv OMP_STACKSIZE 2000500B 21
setenv OMP_STACKSIZE "3000 k " 22
setenv OMP_STACKSIZE 10M 23
setenv OMP_STACKSIZE " 10 M " 24
setenv OMP_STACKSIZE "20 m " 25
setenv OMP_STACKSIZE " 1G" 26
setenv OMP_STACKSIZE 20000 27
Cross References 28
stacksize-var ICV, see Section 2.5 on page 63. 29
CHAPTER 6. ENVIRONMENT VARIABLES 607
6.7 OMP_WAIT_POLICY 1
TheOMP_WAIT_POLICY environment variable provides a hint to an OpenMP implementation 2
about the desired behavior of waiting threads by setting the wait-policy-var ICV. A compliant 3
OpenMP implementation may or may not abide by the setting of the environment variable. 4
The value of this environment variable must be one of the following: 5
ACTIVE |PASSIVE 6
TheACTIVE value speciﬁes that waiting threads should mostly be active, consuming processor 7
cycles, while waiting. An OpenMP implementation may, for example, make waiting threads spin. 8
ThePASSIVE value speciﬁes that waiting threads should mostly be passive, not consuming 9
processor cycles, while waiting. For example, an OpenMP implementation may make waiting 10
threads yield the processor to other threads or go to sleep. 11
The details of the ACTIVE andPASSIVE behaviors are implementation deﬁned. 12
The behavior of the program is implementation deﬁned if the value of OMP_WAIT_POLICY is 13
neither ACTIVE norPASSIVE . 14
Examples: 15
setenv OMP_WAIT_POLICY ACTIVE 16
setenv OMP_WAIT_POLICY active 17
setenv OMP_WAIT_POLICY PASSIVE 18
setenv OMP_WAIT_POLICY passive 19
Cross References 20
wait-policy-var ICV, see Section 2.5 on page 63. 21
6.8 OMP_MAX_ACTIVE_LEVELS 22
TheOMP_MAX_ACTIVE_LEVELS environment variable controls the maximum number of nested 23
active parallel regions by setting the initial value of the max-active-levels-var ICV. 24
The value of this environment variable must be a non-negative integer. The behavior of the 25
program is implementation deﬁned if the requested value of OMP_MAX_ACTIVE_LEVELS is 26
greater than the maximum number of nested active parallel levels an implementation can support, 27
or if the value is not a non-negative integer. 28
608 OpenMP API – Version 5.0 November 2018
Cross References 1
max-active-levels-var ICV, see Section 2.5 on page 63. 2
omp_set_max_active_levels routine, see Section 3.2.16 on page 350. 3
omp_get_max_active_levels routine, see Section 3.2.17 on page 351. 4
6.9 OMP_NESTED 5
TheOMP_NESTED environment variable controls nested parallelism by setting the initial value of 6
themax-active-levels-var ICV. If the environment variable is set to true, the initial value of 7
max-active-levels-var is set to the number of active levels of parallelism supported by the 8
implementation. If the environment variable is set to false, the initial value of 9
max-active-levels-var is set to 1. The behavior of the program is implementation deﬁned if the 10
value of OMP_NESTED is neither truenorfalse. 11
If both the OMP_NESTED andOMP_MAX_ACTIVE_LEVELS environment variables are set, the 12
value of OMP_NESTED isfalse, and the value of OMP_MAX_ACTIVE_LEVELS is greater than 13
1,thebehaviorisimplementationdeﬁned. Otherwise,ifbothenvironmentvariablesaresetthenthe 14
OMP_NESTED environment variable has no eﬀect. 15
TheOMP_NESTED environment variable has been deprecated. 16
Example: 17
setenv OMP_NESTED false 18
Cross References 19
max-active-levels-var ICV, see Section 2.5 on page 63. 20
omp_set_nested routine, see Section 3.2.10 on page 343. 21
omp_get_team_size routine, see Section 3.2.20 on page 354. 22
OMP_MAX_ACTIVE_LEVELS environment variable, see Section 6.8 on page 608. 23
CHAPTER 6. ENVIRONMENT VARIABLES 609
6.10 OMP_THREAD_LIMIT 1
TheOMP_THREAD_LIMIT environment variable sets the maximum number of OpenMP threads 2
to use in a contention group by setting the thread-limit-var ICV. 3
The value of this environment variable must be a positive integer. The behavior of the program is 4
implementation deﬁned if the requested value of OMP_THREAD_LIMIT is greater than the 5
number of threads an implementation can support, or if the value is not a positive integer. 6
Cross References 7
thread-limit-var ICV, see Section 2.5 on page 63. 8
omp_get_thread_limit routine, see Section 3.2.14 on page 348. 9
6.11 OMP_CANCELLATION 10
TheOMP_CANCELLATION environment variable sets the initial value of the cancel-var ICV. 11
The value of this environment variable must be one of the following: 12
true|false 13
If set to true, the eﬀects of the cancel construct and of cancellation points are enabled and 14
cancellation is activated. If set to false, cancellation is disabled and the cancel construct and 15
cancellation points are eﬀectively ignored. The behavior of the program is implementation deﬁned 16
ifOMP_CANCELLATION is set to neither truenorfalse. 17
Cross References 18
cancel-var , see Section 2.5.1 on page 64. 19
cancel construct, see Section 2.18.1 on page 263. 20
cancellation point construct, see Section 2.18.2 on page 267. 21
omp_get_cancellation routine, see Section 3.2.9 on page 342. 22
610OpenMP API – Version 5.0 November 2018
6.12 OMP_DISPLAY_ENV 1
TheOMP_DISPLAY_ENV environment variable instructs the runtime to display the OpenMP 2
version number and the value of the ICVs associated with the environment variables described in 3
Chapter 6, as name=valuepairs. The runtime displays this information once, after processing the 4
environment variables and before any user calls to change the ICV values by runtime routines 5
deﬁned in Chapter 3. 6
The value of the OMP_DISPLAY_ENV environment variable may be set to one of these values: 7
TRUE|FALSE|VERBOSE 8
TheTRUEvalue instructs the runtime to display the OpenMP version number deﬁned by the 9
_OPENMP version macro (or the openmp_version Fortran parameter) value and the initial ICV 10
values for the environment variables listed in Chapter 6. The VERBOSE value indicates that the 11
runtime may also display the values of runtime variables that may be modiﬁed by vendor-speciﬁc 12
environment variables. The runtime does not display any information when the 13
OMP_DISPLAY_ENV environment variable is FALSEor undeﬁned. For all values of the 14
environment variable other than TRUE,FALSE, andVERBOSE , the displayed information is 15
unspeciﬁed. 16
The display begins with "OPENMP DISPLAY ENVIRONMENT BEGIN" , followed by the 17
_OPENMP version macro (or the openmp_version Fortran parameter) value and ICV values, in 18
the format NAME’=’VALUE.NAMEcorresponds to the macro or environment variable name, 19
optionally prepended by a bracketed device-type .VALUEcorresponds to the value of the macro or 20
ICV associated with this environment variable. Values are enclosed in single quotes. The display is 21
terminated with "OPENMP DISPLAY ENVIRONMENT END" . 22
For the OMP_NESTED environment variable, the printed value is trueif themax-active-levels-var 23
ICV is initialized to a value greater than 1; otherwise the printed value is false. 24
Example: 25
% setenv OMP_DISPLAY_ENV TRUE 26
The above example causes an OpenMP implementation to generate output of the following form: 27
OPENMP DISPLAY ENVIRONMENT BEGIN 28
_OPENMP=’201811’ 29
[host] OMP_SCHEDULE=’GUIDED,4’ 30
[host] OMP_NUM_THREADS=’4,3,2’ 31
[device] OMP_NUM_THREADS=’2’ 32
[host,device] OMP_DYNAMIC=’TRUE’ 33
[host] OMP_PLACES=’{0:4},{4:4},{8:4},{12:4}’ 34
... 35
OPENMP DISPLAY ENVIRONMENT END 36
CHAPTER 6. ENVIRONMENT VARIABLES 611
6.13 OMP_DISPLAY_AFFINITY 1
TheOMP_DISPLAY_AFFINITY environment variable instructs the runtime to display formatted 2
aﬃnity information for all OpenMP threads in the parallel region upon entering the ﬁrst parallel 3
region and when any change occurs in the information accessible by the format speciﬁers listed in 4
Table 6.2. If aﬃnity of any thread in a parallel region changes then thread aﬃnity information for 5
all threads in that region is displayed. If the thread aﬃnity for each respective parallel region at 6
each nesting level has already been displayed and the thread aﬃnity has not changed, then the 7
information is not displayed again. There is no speciﬁc order in displaying thread aﬃnity 8
information for all threads in the same parallel region. 9
The value of the OMP_DISPLAY_AFFINITY environment variable may be set to one of these 10
values: 11
TRUE|FALSE 12
TheTRUEvalue instructs the runtime to display the OpenMP thread aﬃnity information, and uses 13
the format setting deﬁned in the aﬃnity-format-var ICV. 14
The runtime does not display the OpenMP thread aﬃnity information when the value of the 15
OMP_DISPLAY_AFFINITY environment variable is FALSEor undeﬁned. For all values of the 16
environment variable other than TRUEorFALSE, the display action is implementation deﬁned. 17
Example: 18
setenv OMP_DISPLAY_AFFINITY TRUE 19
The above example causes an OpenMP implementation to display OpenMP thread aﬃnity 20
information during execution of the program, in a format given by the aﬃnity-format-var ICV. The 21
following is a sample output: 22
nesting_level= 1, thread_num= 0, thread_affinity= 0,1 23
nesting_level= 1, thread_num= 1, thread_affinity= 2,3 24
Cross References 25
Controlling OpenMP thread aﬃnity, see Section 2.6.2 on page 80. 26
omp_set_affinity_format routine, see Section 3.2.30 on page 364. 27
omp_get_affinity_format routine, see Section 3.2.31 on page 366. 28
omp_display_affinity routine, see Section 3.2.32 on page 367. 29
omp_capture_affinity routine, see Section 3.2.33 on page 368. 30
OMP_AFFINITY_FORMAT environment variable, see Section 6.14 on page 613. 31
612 OpenMP API – Version 5.0 November 2018
6.14 OMP_AFFINITY_FORMAT 1
TheOMP_AFFINITY_FORMAT environment variable sets the initial value of the 2
aﬃnity-format-var ICV which deﬁnes the format when displaying OpenMP thread aﬃnity 3
information. 4
The value of this environment variable is a character string that may contain as substrings one or 5
more ﬁeld speciﬁers, in addition to other characters. The format of each ﬁeld speciﬁer is 6
%[[[0].] size ] type 7
where an individual ﬁeld speciﬁer must contain the percent symbol ( %) and a type. The type can be 8
a single character short name or its corresponding long name delimited with curly braces, such as 9
%nor%{thread_num} . A literal percent is speciﬁed as %%. Field speciﬁers can be provided in 10
any order. 11
The0modiﬁer indicates whether or not to add leading zeros to the output, following any indication 12
of sign or base. The .modiﬁer indicates the output should be right justiﬁed when sizeis speciﬁed. 13
By default, output is left justiﬁed. The minimum ﬁeld length is size, which is a decimal digit string 14
with a non-zero ﬁrst digit. If no sizeis speciﬁed, the actual length needed to print the ﬁeld will be 15
used. If the 0modiﬁer is used with typeofA,{thread_affinity} ,H,{host}, or a type that 16
is not printed as a number, the result is unspeciﬁed. Any other characters in the format string that 17
are not part of a ﬁeld speciﬁer will be included literally in the output. 18
TABLE 6.2:Available Field Types for Formatting OpenMP Thread Aﬃnity Information
Short
NameLong Name Meaning
t team_num The value returned by omp_get_team_num() .
T num_teams The value returned by omp_get_num_teams() .
L nesting_level The value returned by omp_get_level() .
n thread_num The value returned by omp_get_thread_num() .
N num_threads The value returned by omp_get_num_threads() .
a ancestor_tnum The value returned by
omp_get_ancestor_thread_num( level),
wherelevelisomp_get_level() minus 1.
table continued on next page
CHAPTER 6. ENVIRONMENT VARIABLES 613
table continued from previous page
Short
NameLong Name Meaning
H host The name for the host machine on which the OpenMP
program is running.
P process_id The process identiﬁer used by the implementation.
i native_thread_id The native thread identiﬁer used by the implementation.
A thread_affinity The list of numerical identiﬁers, in the format of a comma-
separated list of integers or integer ranges, that represent
processors on which a thread may execute, subject to
OpenMP thread aﬃnity control and/or other external
aﬃnity mechanisms.
Implementations may deﬁne additional ﬁeld types. If an implementation does not have information 1
for a ﬁeld type, "undeﬁned" is printed for this ﬁeld when displaying the OpenMP thread aﬃnity 2
information. 3
Example: 4
setenv OMP_AFFINITY_FORMAT 5
"Thread Affinity: %0.3L %.8n %.15{thread_affinity} %.12H" 6
The above example causes an OpenMP implementation to display OpenMP thread aﬃnity 7
information in the following form: 8
Thread Affinity: 001 0 0-1,16-17 nid003 9
Thread Affinity: 001 1 2-3,18-19 nid003 10
Cross References 11
Controlling OpenMP thread aﬃnity, see Section 2.6.2 on page 80. 12
omp_set_affinity_format routine, see Section 3.2.30 on page 364. 13
omp_get_affinity_format routine, see Section 3.2.31 on page 366. 14
omp_display_affinity routine, see Section 3.2.32 on page 367. 15
omp_capture_affinity routine, see Section 3.2.33 on page 368. 16
OMP_DISPLAY_AFFINITY environment variable, see Section 6.13 on page 612. 17
614 OpenMP API – Version 5.0 November 2018
6.15 OMP_DEFAULT_DEVICE 1
TheOMP_DEFAULT_DEVICE environment variable sets the device number to use in device 2
constructs by setting the initial value of the default-device-var ICV. 3
The value of this environment variable must be a non-negative integer value. 4
Cross References 5
default-device-var ICV, see Section 2.5 on page 63. 6
device directives, Section 2.12 on page 160. 7
6.16 OMP_MAX_TASK_PRIORITY 8
TheOMP_MAX_TASK_PRIORITY environment variable controls the use of task priorities by 9
setting the initial value of the max-task-priority-var ICV. The value of this environment variable 10
must be a non-negative integer. 11
Example: 12
% setenv OMP_MAX_TASK_PRIORITY 20 13
Cross References 14
max-task-priority-var ICV, see Section 2.5 on page 63. 15
Tasking Constructs, see Section 2.10 on page 135. 16
omp_get_max_task_priority routine, see Section 3.2.42 on page 377. 17
6.17 OMP_TARGET_OFFLOAD 18
TheOMP_TARGET_OFFLOAD environment variable sets the initial value of the target-oﬄoad-var 19
ICV. The value of the OMP_TARGET_OFFLOAD environment variable must be one of the 20
following: 21
MANDATORY |DISABLED |DEFAULT 22
CHAPTER 6. ENVIRONMENT VARIABLES 615
TheMANDATORY value speciﬁes that program execution is terminated if a device construct or 1
device memory routine is encountered and the device is not available or is not supported by the 2
implementation. Support for the DISABLED value is implementation deﬁned. If an 3
implementation supports it, the behavior is as if the only device is the host device. 4
TheDEFAULT value speciﬁes the default behavior as described in Section 1.3 on page 20. 5
Example: 6
% setenv OMP_TARGET_OFFLOAD MANDATORY 7
Cross References 8
target-oﬄoad-var ICV, see Section 2.5 on page 63. 9
Device Directives, see Section 2.12 on page 160. 10
Device Memory Routines, see Section 3.6 on page 397. 11
6.18 OMP_TOOL 12
TheOMP_TOOL environment variable sets the tool-varICV, which controls whether an OpenMP 13
runtime will try to register a ﬁrst party tool. 14
The value of this environment variable must be one of the following: 15
enabled |disabled 16
IfOMP_TOOL is set to any value other than enabled ordisabled , the behavior is unspeciﬁed. 17
IfOMP_TOOL is not deﬁned, the default value for tool-varisenabled . 18
Example: 19
% setenv OMP_TOOL enabled 20
Cross References 21
tool-varICV, see Section 2.5 on page 63. 22
OMPT Interface, see Chapter 4 on page 419. 23
616 OpenMP API – Version 5.0 November 2018
6.19 OMP_TOOL_LIBRARIES 1
TheOMP_TOOL_LIBRARIES environmentvariablesetsthe tool-libraries-var ICVtoalistoftool 2
libraries that are considered for use on a device on which an OpenMP implementation is being 3
initialized. The value of this environment variable must be a list of names of dynamically-loadable 4
libraries, separated by an implementation speciﬁc, platform typical separator. 5
If thetool-varICV is not enabled, the value of tool-libraries-var is ignored. Otherwise, if 6
ompt_start_tool is not visible in the address space on a device where OpenMP is being 7
initialized or if ompt_start_tool returns NULL, an OpenMP implementation will consider 8
libraries in the tool-libraries-var list in a left to right order. The OpenMP implementation will 9
search the list for a library that meets two criteria: it can be dynamically loaded on the current 10
device and it deﬁnes the symbol ompt_start_tool . If an OpenMP implementation ﬁnds a 11
suitable library, no further libraries in the list will be considered. 12
Example: 13
% setenv OMP_TOOL_LIBRARIES libtoolXY64.so:/usr/local/lib/ 14
libtoolXY32.so 15
Cross References 16
tool-libraries-var ICV, see Section 2.5 on page 63. 17
OMPT Interface, see Chapter 4 on page 419. 18
ompt_start_tool routine, see Section 4.2.1 on page 420. 19
6.20 OMP_DEBUG 20
TheOMP_DEBUG environment variable sets the debug-var ICV, which controls whether an 21
OpenMP runtime collects information that an OMPD library may need to support a tool. 22
The value of this environment variable must be one of the following: 23
enabled |disabled 24
IfOMP_DEBUG is set to any value other than enabled ordisabled then the behavior is 25
implementation deﬁned. 26
Example: 27
% setenv OMP_DEBUG enabled 28
CHAPTER 6. ENVIRONMENT VARIABLES 617
Cross References 1
debug-var ICV, see Section 2.5 on page 63. 2
OMPD Interface, see Chapter 5 on page 533. 3
Enabling the Runtime for OMPD, see Section 5.2.1 on page 534. 4
6.21 OMP_ALLOCATOR 5
OMP_ALLOCATOR sets thedef-allocator-var ICV that speciﬁes the default allocator for allocation 6
calls, directives and clauses that do not specify an allocator. The value of this environment variable 7
isapredeﬁnedallocatorfromTable2.10onpage155. Thevalueofthisenvironmentvariableisnot 8
case sensitive. 9
Cross References 10
def-allocator-var ICV, see Section 2.5 on page 63. 11
Memory allocators, see Section 2.11.2 on page 152. 12
omp_set_default_allocator routine, see Section 3.7.4 on page 411. 13
omp_get_default_allocator routine, see Section 3.7.5 on page 412. 14
618OpenMP API – Version 5.0 November 2018
APPENDIX A
OpenMP Implementation-Deﬁned 1
Behaviors 2
3
This appendix summarizes the behaviors that are described as implementation deﬁned in this API. 4
Each behavior is cross-referenced back to its description in the main speciﬁcation. An 5
implementation is required to deﬁne and to document its behavior in these cases. 6
Processor : a hardware unit that is implementation deﬁned (see Section 1.2.1 on page 2). 7
Device: an implementation deﬁned logical execution engine (see Section 1.2.1 on page 2). 8
Device address : reference to an address in a device data environment (see Section 1.2.6 on 9
page 12). 10
Memory model : the minimum size at which a memory update may also read and write back 11
adjacent variables that are part of another variable (as array or structure elements) is 12
implementation deﬁned but is no larger than required by the base language (see Section 1.4.1 on 13
page 23). 14
requires directive: support of requirements is implementation deﬁned. All 15
implementation-deﬁned requirements should begin with ext_(see Section 2.4 on page 60). 16
Requires directive : Support for any feature speciﬁed by a requirement clause on a requires 17
directive is implementation deﬁned (see Section 2.4 on page 60). 18
Internal control variables : the initial values of dyn-var,nthreads-var ,run-sched-var , 19
def-sched-var ,bind-var,stacksize-var ,wait-policy-var ,thread-limit-var ,max-active-levels-var , 20
place-partition-var ,aﬃnity-format-var ,default-device-var anddef-allocator-var are 21
implementation deﬁned. The method for initializing a target device’s internal control variable is 22
implementation deﬁned (see Section 2.5.2 on page 66). 23
OpenMP context : the accepted isa-name values for the isatrait, the accepted arch-name values 24
for thearchtrait, and the accepted extension-name values for the extension trait are 25
implementation deﬁned (see Section 2.3.1 on page 51). 26
619
declare variant directive: whether, for some speciﬁc OpenMP context, the prototype of 1
the variant should diﬀer from that of the base function, and if so how it should diﬀer, is 2
implementation deﬁned (see Section 2.3.5 on page 58). 3
Dynamic adjustment of threads : providing the ability to adjust the number of threads 4
dynamically is implementation deﬁned. Implementations are allowed to deliver fewer threads 5
(but at least one) than indicated in Algorithm 2.1 even if dynamic adjustment is disabled (see 6
Section 2.6.1 on page 78). 7
Thread aﬃnity : For the closethread aﬃnity policy, if T > PandPdoes not divide Tevenly, 8
the exact number of threads in a particular place is implementation deﬁned. For the spread 9
thread aﬃnity, if T > PandPdoes not divide Tevenly, the exact number of threads in a 10
particular subpartition is implementation deﬁned. The determination of whether the aﬃnity 11
request can be fulﬁlled is implementation deﬁned. If not, the mapping of threads in the team to 12
places is implementation deﬁned (see Section 2.6.2 on page 80). 13
teamsconstruct : the number of teams that are created is implementation deﬁned but less than 14
or equal to the value of the num_teams clause if speciﬁed. The maximum number of threads 15
thatparticipateinthecontentiongroupthateachteaminitiatesisimplementationdeﬁnedbutless 16
than or equal to the value of the thread_limit clause if speciﬁed. The assignment of the 17
initial threads to places and the values of the place-partition-var anddefault-device-var ICVs for 18
each initial thread are implementation deﬁned (see Section 2.7 on page 82). 19
sections construct : the method of scheduling the structured blocks among threads in the 20
team is implementation deﬁned (see Section 2.8.1 on page 86). 21
single construct : the method of choosing a thread to execute the structured block is 22
implementation deﬁned (see Section 2.8.2 on page 89) 23
Worksharing-Loop directive : the integer type (or kind, for Fortran) used to compute the 24
iteration count of a collapsed loop is implementation deﬁned. The eﬀect of the 25
schedule(runtime) clause when the run-sched-var ICV is set to autois implementation 26
deﬁned. Thevalueof simd_width forthe simdschedulemodiﬁerisimplementationdeﬁned(see 27
Section 2.9.2 on page 101). 28
simdconstruct : the integer type (or kind, for Fortran) used to compute the iteration count for 29
the collapsed loop is implementation deﬁned. The number of iterations that are executed 30
concurrently at any given time is implementation deﬁned. If the alignment parameter is not 31
speciﬁed in the aligned clause, the default alignments for the SIMD instructions are 32
implementation deﬁned (see Section 2.9.3.1 on page 110). 33
declare simd directive: if the parameter of the simdlen clause is not a constant positive 34
integer expression, the number of concurrent arguments for the function is implementation 35
deﬁned. If the alignment parameter of the aligned clause is not speciﬁed, the default 36
alignments for SIMD instructions are implementation deﬁned (see Section 2.9.3.3 on page 116). 37
distribute construct : the integer type (or kind, for Fortran) used to compute the iteration 38
count for the collapsed loop is implementation deﬁned. If no dist_schedule clause is 39
620 OpenMP API – Version 5.0 November 2018
speciﬁed then the schedule for the distribute construct is implementation deﬁned (see 1
Section 2.9.4.1 on page 120). 2
taskloop construct : The number of loop iterations assigned to a task created from a 3
taskloop construct is implementation deﬁned, unless the grainsize ornum_tasks 4
clause is speciﬁed. The integer type (or kind, for Fortran) used to compute the iteration count for 5
the collapsed loop is implementation deﬁned (see Section 2.10.2 on page 140). 6
C++
taskloop construct : For firstprivate variables of class type, the number of invocations 7
of copy constructors to perform the initialization is implementation deﬁned (see Section 2.10.2 8
on page 140). 9
C++
Memory spaces : The actual storage resource that each memory space deﬁned in Table 2.8 on 10
page 152 represents is implementation deﬁned. 11
Memory allocators : The minimum partitioning size for partitioning of allocated memory over 12
the storage resources is implementation deﬁned (see Section 2.11.2 on page 152). The default 13
value for the pool_size allocator trait is implementation deﬁned (see Table 2.9 on page 153). 14
The associated memory space for each of the predeﬁned omp_cgroup_mem_alloc , 15
omp_pteam_mem_alloc andomp_thread_mem_alloc allocators is implementation 16
deﬁned (see Table 2.10 on page 155). 17
is_device_ptr clause: Support for pointers created outside of the OpenMP device data 18
management routines is implementation deﬁned (see Section 2.12.5 on page 170). 19
target construct : the eﬀect of invoking a virtual member function of an object on a device 20
other than the device on which the object was constructed is implementation deﬁned (see 21
Section 2.12.5 on page 170). 22
atomic construct : a compliant implementation may enforce exclusive access between 23
atomic regions that update diﬀerent storage locations. The circumstances under which this 24
occurs are implementation deﬁned. If the storage location designated by xis not size-aligned 25
(that is, if the byte alignment of xis not a multiple of the size of x), then the behavior of the 26
atomic region is implementation deﬁned (see Section 2.17.7 on page 234). 27
Fortran
Data-sharing attributes : The data-sharing attributes of dummy arguments without the VALUE 28
attribute are implementation-deﬁned if the associated actual argument is shared, except for the 29
conditions speciﬁed (see Section 2.19.1.2 on page 273). 30
threadprivate directive: if the conditions for values of data in the threadprivate objects of 31
threads (other than an initial thread) to persist between two consecutive active parallel regions do 32
not all hold, the allocation status of an allocatable variable in the second region is 33
implementation deﬁned (see Section 2.19.2 on page 274). 34
APPENDIX A. OPENMP IMPLEMENTATION-DEFINED BEHAVIORS 621
Runtimelibrarydeﬁnitions : itisimplementationdeﬁnedwhethertheincludeﬁle omp_lib.h 1
or the module omp_lib (or both) is provided. It is implementation deﬁned whether any of the 2
OpenMP runtime library routines that take an argument are extended with a generic interface so 3
arguments of diﬀerent KINDtype can be accommodated (see Section 3.1 on page 332). 4
Fortran
omp_set_num_threads routine: if the argument is not a positive integer the behavior is 5
implementation deﬁned (see Section 3.2.1 on page 334). 6
omp_set_schedule routine: for implementation speciﬁc schedule kinds, the values and 7
associated meanings of the second argument are implementation deﬁned (see Section 3.2.12 on 8
page 345). 9
omp_get_supported_active_levels routine: the number of active levels of 10
parallelism supported by the implementation is implementation deﬁned, but must be greater than 11
0 (see Section 3.2.15 on page 349). 12
omp_set_max_active_levels routine: when called from within any explicit parallel 13
region the binding thread set (and binding region, if required) for the 14
omp_set_max_active_levels region is implementation deﬁned and the behavior is 15
implementation deﬁned. If the argument is not a non-negative integer then the behavior is 16
implementation deﬁned (see Section 3.2.16 on page 350). 17
omp_get_max_active_levels routine: when called from within any explicit parallel 18
region the binding thread set (and binding region, if required) for the 19
omp_get_max_active_levels region is implementation deﬁned (see Section 3.2.17 on 20
page 351). 21
omp_get_place_proc_ids routine: the meaning of the non-negative numerical identiﬁers 22
returnedbythe omp_get_place_proc_ids routineisimplementationdeﬁned. Theorderof 23
the numerical identiﬁers returned in the array idsis implementation deﬁned (see Section 3.2.26 24
on page 360). 25
omp_set_affinity_format routine: when called from within any explicit parallel 26
region, the binding thread set (and binding region, if required) for the 27
omp_set_affinity_format region is implementation deﬁned and the behavior is 28
implementation deﬁned. If the argument does not conform to the speciﬁed format then the result 29
is implementation deﬁned (see Section 3.2.30 on page 364). 30
omp_get_affinity_format routine: when called from within any explicit parallel 31
region the binding thread set (and binding region, if required) for the 32
omp_get_affinity_format region is implementation deﬁned (see Section 3.2.31 on 33
page 366). 34
omp_display_affinity routine: if the argument does not conform to the speciﬁed format 35
then the result is implementation deﬁned (see Section 3.2.32 on page 367). 36
622 OpenMP API – Version 5.0 November 2018
omp_capture_affinity routine: if theformatargument does not conform to the speciﬁed 1
format then the result is implementation deﬁned (see Section 3.2.33 on page 368). 2
omp_get_initial_device routine: the value of the device number of the host device is 3
implementation deﬁned (see Section 3.2.41 on page 376). 4
omp_target_memcpy_rect routine: the maximum number of dimensions supported is 5
implementation deﬁned, but must be at least three (see Section 3.6.5 on page 402). 6
ompt_callback_sync_region_wait ,ompt_callback_mutex_released , 7
ompt_callback_dependences ,ompt_callback_task_dependence , 8
ompt_callback_work ,ompt_callback_master ,ompt_callback_target_map , 9
ompt_callback_sync_region ,ompt_callback_lock_init , 10
ompt_callback_lock_destroy ,ompt_callback_mutex_acquire , 11
ompt_callback_mutex_acquired ,ompt_callback_nest_lock , 12
ompt_callback_flush ,ompt_callback_cancel and 13
ompt_callback_dispatch tool callbacks : if a tool attempts to register a callback with the 14
stringnameusingtheruntimeentrypoint ompt_set_callback ,itisimplementationdeﬁned 15
whether the registered callback may never or sometimes invoke this callback for the associated 16
events (see Table 4.2 on page 428) 17
Device tracing : Whether a target device supports tracing or not is implementation deﬁned; if a 18
target device does not support tracing, a NULLmay be supplied for the lookupfunction to a 19
tool’s device initializer (see Section 4.2.5 on page 427). 20
ompt_set_trace_ompt andompt_buffer_get_record_ompt runtime entry 21
points: it is implementation deﬁned whether a device-speciﬁc tracing interface will deﬁne this 22
runtime entry point, indicating that it can collect traces in OMPT format. The kinds of trace 23
records available for a device is implementation deﬁned (see Section 4.2.5 on page 427). 24
ompt_callback_target_data_op_t callback type : it is implementation deﬁned 25
whether in some operations src_addr ordest_addr might point to an intermediate buﬀer (see 26
Section 4.5.2.25 on page 488). 27
ompt_set_callback_t entry point type : the subset of the associated event in which the 28
callback is invoked is implementation deﬁned (see Section 4.6.1.3 on page 500). 29
ompt_get_place_proc_ids_t entry point type : the meaning of the numerical identiﬁers 30
returned is implementation deﬁned. The order of idsreturned in the array is implementation 31
deﬁned (see Section 4.6.1.8 on page 505). 32
ompt_get_partition_place_nums_t entry point type : the order of the identiﬁers 33
returned in the array place_nums is implementation deﬁned (see Section 4.6.1.10 on page 507). 34
ompt_get_proc_id_t entry point type : the meaning of the numerical identiﬁer returned is 35
implementation deﬁned (see Section 4.6.1.11 on page 508). 36
ompd_callback_print_string_fn_t callback function : the value of catergory is 37
implementation deﬁned (see Section 5.4.5 on page 556). 38
APPENDIX A. OPENMP IMPLEMENTATION-DEFINED BEHAVIORS 623
ompd_parallel_handle_compare operation : the means by which parallel region 1
handles are ordered is implementation deﬁned (see Section 5.5.6.5 on page 575). 2
ompd_task_handle_compare operation : the means by which task handles are ordered is 3
implementation deﬁned (see Section 5.5.7.6 on page 580). 4
OMPT thread states : The set of OMPT thread states supported is implementation deﬁned (see 5
Section 4.4.4.26 on page 452). 6
OMP_SCHEDULE environment variable : if the value does not conform to the speciﬁed format 7
then the result is implementation deﬁned (see Section 6.1 on page 601). 8
OMP_NUM_THREADS environmentvariable : ifanyvalueofthelistspeciﬁedleadstoanumber 9
of threads that is greater than the implementation can support, or if any value is not a positive 10
integer, then the result is implementation deﬁned (see Section 6.2 on page 602). 11
OMP_DYNAMIC environment variable : if the value is neither truenorfalsethe behavior is 12
implementation deﬁned (see Section 6.3 on page 603). 13
OMP_PROC_BIND environment variable : if the value is not true,false, or a comma 14
separated list of master,close, orspread, the behavior is implementation deﬁned. The 15
behavior is also implementation deﬁned if an initial thread cannot be bound to the ﬁrst place in 16
the OpenMP place list (see Section 6.4 on page 604). 17
OMP_PLACES environment variable : the meaning of the numbers speciﬁed in the environment 18
variable and how the numbering is done are implementation deﬁned. The precise deﬁnitions of 19
the abstract names are implementation deﬁned. An implementation may add 20
implementation-deﬁned abstract names as appropriate for the target platform. When creating a 21
place list of n elements by appending the number nto an abstract name, the determination of 22
which resources to include in the place list is implementation deﬁned. When requesting more 23
resourcesthan available, thelength ofthe placelist isalso implementationdeﬁned. The behavior 24
of the program is implementation deﬁned when the execution environment cannot map a 25
numerical value (either explicitly deﬁned or implicitly derived from an interval) within the 26
OMP_PLACES listtoaprocessoronthetargetplatform,orifitmapstoanunavailableprocessor. 27
The behavior is also implementation deﬁned when the OMP_PLACES environment variable is 28
deﬁned using an abstract name (see Section 6.5 on page 605). 29
OMP_STACKSIZE environment variable : if the value does not conform to the speciﬁed format 30
or the implementation cannot provide a stack of the speciﬁed size then the behavior is 31
implementation deﬁned (see Section 6.6 on page 607). 32
OMP_WAIT_POLICY environment variable : the details of the ACTIVE andPASSIVE 33
behaviors are implementation deﬁned (see Section 6.7 on page 608). 34
OMP_MAX_ACTIVE_LEVELS environment variable : if the value is not a non-negative integer 35
or is greater than the number of parallel levels an implementation can support then the behavior 36
is implementation deﬁned (see Section 6.8 on page 608). 37
624 OpenMP API – Version 5.0 November 2018
OMP_NESTED environment variable : if the value is neither truenorfalsethe behavior is 1
implementation deﬁned (see Section 6.9 on page 609). 2
Conﬂicting OMP_NESTED andOMP_MAX_ACTIVE_LEVELS environment variables : if 3
both environment variables are set, the value of OMP_NESTED isfalse, and the value of 4
OMP_MAX_ACTIVE_LEVELS is greater than 1, the behavior is implementation deﬁned (see 5
Section 6.9 on page 609). 6
OMP_THREAD_LIMIT environmentvariable : iftherequestedvalueisgreaterthanthenumber 7
of threads an implementation can support, or if the value is not a positive integer, the behavior of 8
the program is implementation deﬁned (see Section 6.10 on page 610). 9
OMP_DISPLAY_AFFINITY environmentvariable : forallvaluesoftheenvironmentvariables 10
other than TRUEorFALSE, the display action is implementation deﬁned (see Section 6.13 on 11
page 612). 12
OMP_AFFINITY_FORMAT environment variable : if the value does not conform to the 13
speciﬁed format then the result is implementation deﬁned (see Section 6.14 on page 613). 14
OMP_TARGET_OFFLOAD environment variable : the support of disabled is 15
implementation deﬁned (see Section 6.17 on page 615). 16
OMP_DEBUG environment variable : if the value is neither disabled norenabled the 17
behavior is implementation deﬁned (see Section 6.20 on page 617). 18
APPENDIX A. OPENMP IMPLEMENTATION-DEFINED BEHAVIORS 625
This page intentionally left blank
APPENDIX B
Features History 1
2
This appendix summarizes the major changes between OpenMP API versions since version 2.5. 3
B.1 Deprecated Features4
The following features have been deprecated in Version 5.0. 5
Thenest-varICV, the OMP_NESTED environment variable, and the omp_set_nested and 6
omp_get_nested routines were deprecated. 7
Lock hints were renamed to synchronization hints. The following lock hint type and constants 8
were deprecated: 9
–the C/C++ type omp_lock_hint_t and the Fortran kind omp_lock_hint_kind ; 10
–the constants omp_lock_hint_none ,omp_lock_hint_uncontended , 11
omp_lock_hint_contended ,omp_lock_hint_nonspeculative , and 12
omp_lock_hint_speculative . 13
B.2 Version 4.5 to 5.0 Differences 14
The memory model was extended to distinguish diﬀerent types of ﬂush operations according to 15
speciﬁed ﬂush properties (see Section 1.4.4 on page 25) and to deﬁne a happens before order 16
based on synchronizing ﬂush operations (see Section 1.4.5 on page 27). 17
627
Various changes throughout the speciﬁcation were made to provide initial support of C11, 1
C++11, C++14, C++17 and Fortran 2008 (see Section 1.7 on page 31). 2
Fortran 2003 is now fully supported (see Section 1.7 on page 31). 3
Therequires directive (see Section 2.4 on page 60) was added to support applications that 4
require implementation-speciﬁc features. 5
Thetarget-oﬄoad-var internal control variable (see Section 2.5 on page 63) and the 6
OMP_TARGET_OFFLOAD environment variable (see Section 6.17 on page 615) were added to 7
support runtime control of the execution of device constructs. 8
Control over whether nested parallelism is enabled or disabled was integrated into the 9
max-active-levels-var internal control variable (see Section 2.5.2 on page 66), the default value 10
of which is now implementation deﬁned, unless determined according to the values of the 11
OMP_NUM_THREADS (see Section 6.2 on page 602) or OMP_PROC_BIND (see Section 6.4 on 12
page 604) environment variables. 13
Support for array shaping (see Section 2.1.4 on page 43) and for array sections with non-unit 14
strides in C and C++ (see Section 2.1.5 on page 44) was added to facilitate speciﬁcation of 15
discontiguous storage and the target update construct (see Section 2.12.6 on page 176) and 16
thedepend clause (see Section 2.17.11 on page 255) were extended to allow the use of 17
shape-operators (see Section 2.1.4 on page 43). 18
Iterators (see Section 2.1.6 on page 47) were added to support expressions in a list that expand to 19
multiple expressions. 20
Themetadirective directive (see Section 2.3.4 on page 56) and declare variant 21
directive (see Section 2.3.5 on page 58) were added to support selection of directive variants and 22
declaredfunctionvariantsatacallsite,respectively,basedoncompile-timetraitsoftheenclosing 23
context. 24
Theteamsconstruct(seeSection2.7onpage82)wasextendedtosupportexecutiononthehost 25
device without an enclosing target construct (see Section 2.12.5 on page 170). 26
The canonical loop form was deﬁned for Fortran and, for all base languages, extended to permit 27
non-rectangular loop nests (see Section 2.9.1 on page 95). 28
Therelational-op in thecanonical loop form for C/C++ was extended to include !=(see 29
Section 2.9.1 on page 95). 30
The default loop schedule modiﬁer for worksharing-loop constructs without the static 31
schedule and the ordered clause was changed to nonmonotonic (see Section 2.9.2 on 32
page 101). 33
The collapse of associated loops that are imperfectly nested loops was deﬁned for the 34
worksharing-loop (see Section 2.9.2 on page 101), simd(see Section 2.9.3.1 on page 110), 35
taskloop (see Section 2.10.2 on page 140) and distribute (see Section 2.9.4.2 on 36
page 123) constructs. 37
628 OpenMP API – Version 5.0 November 2018
Thesimdconstruct (see Section 2.9.3.1 on page 110) was extended to accept the if, 1
nontemporal andorder(concurrent) clauses and to allow the use of atomic 2
constructs within it. 3
Theloopconstruct and the order(concurrent) clause were added to support compiler 4
optimization and parallelization of loops for which iterations may execute in any order, including 5
concurrently (see Section 2.9.5 on page 128). 6
Thescandirective (see Section 2.9.6 on page 132) and the inscan modiﬁer for the 7
reduction clause (see Section 2.19.5.4 on page 300) were added to support inclusive and 8
exclusive scan computations. 9
To support task reductions, the task(see Section 2.10.1 on page 135) and target (see 10
Section2.12.5onpage170)constructswereextendedtoacceptthe in_reduction clause(see 11
Section 2.19.5.6 on page 303), the taskgroup construct (see Section 2.17.6 on page 232) was 12
extended to accept the task_reduction clause Section 2.19.5.5 on page 303), and the task 13
modiﬁer was added to the reduction clause (see Section 2.19.5.4 on page 300). 14
Theaffinity clause was added to the taskconstruct (see Section 2.10.1 on page 135) to 15
support hints that indicate data aﬃnity of explicit tasks. 16
Thedetach clause for the taskconstruct (see Section 2.10.1 on page 135) and the 17
omp_fulfill_event runtime routine (see Section 3.5.1 on page 396) were added to support 18
execution of detachable tasks. 19
To support taskloop reductions, the taskloop (see Section 2.10.2 on page 140) and 20
taskloop simd (see Section 2.10.3 on page 146) constructs were extended to accept the 21
reduction (see Section 2.19.5.4 on page 300) and in_reduction (see Section 2.19.5.6 on 22
page 303) clauses. 23
Thetaskloop construct (see Section 2.10.2 on page 140) was added to the list of constructs 24
that can be canceled by the cancel construct (see Section 2.18.1 on page 263)). 25
To support mutually exclusive inout sets, a mutexinoutset dependence-type was added to 26
thedepend clause (see Section 2.10.6 on page 149 and Section 2.17.11 on page 255). 27
Predeﬁned memory spaces (see Section 2.11.1 on page 152), predeﬁned memory allocators and 28
allocator traits (see Section 2.11.2 on page 152) and directives, clauses (see Section 2.11 on 29
page 152 and API routines (see Section 3.7 on page 406) to use them were added to support 30
diﬀerent kinds of memories. 31
The semantics of the use_device_ptr clause for pointer variables was clariﬁed and the 32
use_device_addr clause for using the device address of non-pointer variables inside the 33
target data construct was added (see Section 2.12.2 on page 161). 34
To support reverse oﬄoad, the ancestor modiﬁer was added to the device clause for 35
target constructs (see Section 2.12.5 on page 170). 36
APPENDIX B. FEATURES HISTORY 629
To reduce programmer eﬀort implicit declare target directives for some functions (C, C++, 1
Fortran) and subroutines (Fortran) were added (see Section 2.12.5 on page 170 and 2
Section 2.12.7 on page 180). 3
Thetarget update construct (see Section 2.12.6 on page 176) was modiﬁed to allow array 4
sections that specify discontiguous storage. 5
Thetoandfromclauses on the target update construct (see Section 2.12.6 on page 176), 6
thedepend clause on task generating constructs (see Section 2.17.11 on page 255), and the 7
mapclause (see Section 2.19.7.1 on page 315) were extended to allow any lvalue expression as a 8
list item for C/C++. 9
Support for nested declare target directives was added (see Section 2.12.7 on page 180). 10
New combined constructs master taskloop (see Section 2.13.7 on page 192), 11
parallel master (see Section 2.13.6 on page 191), parallel master taskloop (see 12
Section 2.13.9 on page 195), master taskloop simd (see Section 2.13.8 on page 194), 13
parallel master taskloop simd (see Section 2.13.10 on page 196) were added. 14
Thedepend clause was added to the taskwait construct (see Section 2.17.5 on page 230). 15
To support acquire and release semantics with weak memory ordering, the acq_rel , 16
acquire , andrelease clauses were added to the atomic construct (see Section 2.17.7 on 17
page 234) and flushconstruct (see Section 2.17.8 on page 242), and the memory ordering 18
semantics of implicit ﬂushes on various constructs and runtime routines were clariﬁed (see 19
Section 2.17.8.1 on page 246). 20
Theatomic construct was extended with the hintclause (see Section 2.17.7 on page 234). 21
Thedepend clause (see Section 2.17.11 on page 255) was extended to support iterators and to 22
support depend objects that can be created with the new depobj construct. 23
Lock hints were renamed to synchronization hints, and the old names were deprecated (see 24
Section 2.17.12 on page 260). 25
To support conditional assignment to lastprivate variables, the conditional modiﬁer was 26
added to the lastprivate clause (see Section 2.19.4.5 on page 288). 27
The description of the mapclause was modiﬁed to clarify the mapping order when multiple 28
map-types are speciﬁed for a variable or structure members of a variable on the same construct. 29
Theclosemap-type-modiﬁer was added as a hint for the runtime to allocate memory close to 30
the target device (see Section 2.19.7.1 on page 315). 31
The capability to map C/C++ pointer variables and to assign the address of device memory that 32
is mapped by an array section to them was added. Support for mapping of Fortran pointer and 33
allocatable variables, including pointer and allocatable components of variables, was added (see 34
Section 2.19.7.1 on page 315). 35
Thedefaultmap clause (see Section 2.19.7.2 on page 324) was extended to allow selecting 36
thedata-mappingordata-sharingattributesforanyofthescalar,aggregate,pointerorallocatable 37
630 OpenMP API – Version 5.0 November 2018
classes on a per-region basis. Additionally it accepts the noneparameter to support the 1
requirementthatallvariablesreferencedintheconstructmustbeexplicitlymappedorprivatized. 2
Thedeclare mapper directive was added to support mapping of data types with direct and 3
indirect members (see Section 2.19.7.3 on page 326). 4
Theomp_set_nested (see Section 3.2.10 on page 343) and omp_get_nested (see 5
Section 3.2.11 on page 344) routines and the OMP_NESTED environment variable (see 6
Section 6.9 on page 609) were deprecated. 7
Theomp_get_supported_active_levels routine was added to query the number of 8
active levels of parallelism supported by the implementation (see Section 3.2.15 on page 349). 9
Runtime routines omp_set_affinity_format (see Section 3.2.30 on page 364), 10
omp_get_affinity_format (see Section 3.2.31 on page 366), omp_set_affinity 11
(see Section 3.2.32 on page 367), and omp_capture_affinity (see Section 3.2.33 on 12
page 368) and environment variables OMP_DISPLAY_AFFINITY (see Section 6.13 on 13
page 612) and OMP_AFFINITY_FORMAT (see Section 6.14 on page 613) were added to 14
provide OpenMP runtime thread aﬃnity information. 15
Theomp_get_device_num runtime routine (see Section 3.2.37 on page 372) was added to 16
support determination of the device on which a thread is executing. 17
Theomp_pause_resource andomp_pause_resource_all runtime routines were 18
added to allow the runtime to relinquish resources used by OpenMP (see Section 3.2.43 on 19
page 378 and Section 3.2.44 on page 380). 20
Support for a ﬁrst-party tool interface (see Section 4 on page 419) was added. 21
Support for a third-party tool interface (see Section 5 on page 533) was added. 22
Support for controlling oﬄoading behavior with the OMP_TARGET_OFFLOAD environment 23
variable was added (see Section 6.17 on page 615). 24
StubsforRuntimeLibraryRoutines(previouslyAppendixA)weremovedtoaseparatedocument. 25
Interface Declarations (previously Appendix B) were moved to a separate document. 26
B.3 Version 4.0 to 4.5 Differences 27
Support for several features of Fortran 2003 was added (see Section 1.7 on page 31 for features 28
that are still not supported). 29
A parameter was added to the ordered clause of the worksharing-loop construct (see 30
Section 2.9.2 on page 101) and clauses were added to the ordered construct (see 31
APPENDIX B. FEATURES HISTORY 631
Section 2.17.9 on page 250) to support doacross loop nests and use of the simdconstruct on 1
loops with loop-carried backward dependences. 2
Thelinear clause was added to the worksharing-loop construct (see Section 2.9.2 on 3
page 101). 4
Thesimdlen clause was added to the simdconstruct (see Section 2.9.3.1 on page 110) to 5
support speciﬁcation of the exact number of iterations desired per SIMD chunk. 6
Thepriority clause was added to the taskconstruct (see Section 2.10.1 on page 135) to 7
support hints that specify the relative execution priority of explicit tasks. The 8
omp_get_max_task_priority routine was added to return the maximum supported 9
priority value (see Section 3.2.42 on page 377) and the OMP_MAX_TASK_PRIORITY 10
environment variable was added to control the maximum priority value allowed (see 11
Section 6.16 on page 615). 12
Taskloopconstructs(seeSection2.10.2onpage140andSection2.10.3onpage146)wereadded 13
to support nestable parallel loops that create OpenMP tasks. 14
To support interaction with native device implementations, the use_device_ptr clause was 15
added to the target data construct (see Section 2.12.2 on page 161) and the 16
is_device_ptr clausewasaddedtothe target construct(seeSection2.12.5onpage170). 17
Thenowait anddepend clauses were added to the target construct (see Section 2.12.5 on 18
page 170) to improve support for asynchronous execution of target regions. 19
Theprivate ,firstprivate anddefaultmap clauses were added to the target 20
construct (see Section 2.12.5 on page 170). 21
Thedeclare target directive was extended to allow mapping of global variables to be 22
deferred to speciﬁc device executions and to allow an extended-list to be speciﬁed in C/C++ (see 23
Section 2.12.7 on page 180). 24
To support unstructured data mapping for devices, the target enter data (see 25
Section 2.12.3 on page 164) and target exit data (see Section 2.12.4 on page 166) 26
constructs were added and the mapclause (see Section 2.19.7.1 on page 315) was updated. 27
To support a more complete set of device construct shortcuts, the target parallel (see 28
Section 2.13.16 on page 203), target parallel worksharing-loop (see Section 2.13.17 on 29
page 205), target parallel worksharing-loop SIMD (see Section 2.13.18 on page 206), and 30
target simd (see Section 2.13.20 on page 209), combined constructs were added. 31
Theifclausewasextendedtotakea directive-name-modiﬁer thatallowsittoapplytocombined 32
constructs (see Section 2.15 on page 220). 33
Thehintclause was addded to the critical construct (see Section 2.17.1 on page 223). 34
Thesource andsinkdependence types were added to the depend clause (see 35
Section 2.17.11 on page 255) to support doacross loop nests. 36
632OpenMP API – Version 5.0 November 2018
The implicit data-sharing attribute for scalar variables in target regions was changed to 1
firstprivate (see Section 2.19.1.1 on page 270). 2
Use of some C++ reference types was allowed in some data sharing attribute clauses (see 3
Section 2.19.4 on page 282). 4
Semantics for reductions on C/C++ array sections were added and restrictions on the use of 5
arrays and pointers in reductions were removed (see Section 2.19.5.4 on page 300). 6
Theref,val, anduvalmodiﬁers were added to the linear clause (see Section 2.19.4.6 on 7
page 290). 8
Support was added to the map clauses to handle structure elements (see Section 2.19.7.1 on 9
page 315). 10
Query functions for OpenMP thread aﬃnity were added (see Section 3.2.24 on page 358 to 11
Section 3.2.29 on page 363). 12
The lock API was extended with lock routines that support storing a hint with a lock to select a 13
desired lock implementation for a lock’s intended usage by the application code (see 14
Section 3.3.2 on page 385). 15
Device memory routines were added to allow explicit allocation, deallocation, memory transfers 16
and memory associations (see Section 3.6 on page 397). 17
C/C++ Grammar (previously Appendix B) was moved to a separate document. 18
B.4 Version 3.1 to 4.0 Differences 19
Various changes throughout the speciﬁcation were made to provide initial support of Fortran 20
2003 (see Section 1.7 on page 31). 21
C/C++ array syntax was extended to support array sections (see Section 2.1.5 on page 44). 22
Theproc_bind clause (see Section 2.6.2 on page 80), the OMP_PLACES environment 23
variable (see Section 6.5 on page 605), and the omp_get_proc_bind runtime routine (see 24
Section 3.2.23 on page 357) were added to support thread aﬃnity policies. 25
SIMD directives were added to support SIMD parallelism (see Section 2.9.3 on page 110). 26
Implementation deﬁned task scheduling points for untied tasks were removed (see Section 2.10.6 27
on page 149). 28
Device directives (see Section 2.12 on page 160), the OMP_DEFAULT_DEVICE environment 29
variable (see Section 6.15 on page 615), and the omp_set_default_device , 30
omp_get_default_device ,omp_get_num_devices ,omp_get_num_teams , 31
APPENDIX B. FEATURES HISTORY 633
omp_get_team_num , andomp_is_initial_device routines were added to support 1
execution on devices. 2
Thetaskgroup construct (see Section 2.17.6 on page 232) was added to support more ﬂexible 3
deep task synchronization. 4
Theatomic construct (see Section 2.17.7 on page 234) was extended to support atomic swap 5
with the capture clause, to allow new atomic update and capture forms, and to support 6
sequentially consistent atomic operations with a new seq_cst clause. 7
Thedepend clause (see Section 2.17.11 on page 255) was added to support task dependences. 8
Thecancel construct (see Section 2.18.1 on page 263), the cancellation point 9
construct (see Section 2.18.2 on page 267), the omp_get_cancellation runtime routine 10
(see Section 3.2.9 on page 342) and the OMP_CANCELLATION environment variable (see 11
Section 6.11 on page 610) were added to support the concept of cancellation. 12
Thereduction clause (see Section 2.19.5.4 on page 300) was extended and the 13
declare reduction construct (see Section 2.19.5.7 on page 304) was added to support user 14
deﬁned reductions. 15
TheOMP_DISPLAY_ENV environment variable (see Section 6.12 on page 611) was added to 16
display the value of ICVs associated with the OpenMP environment variables. 17
Examples (previously Appendix A) were moved to a separate document. 18
B.5 Version 3.0 to 3.1 Differences 19
Thebind-varICVhasbeenadded,whichcontrolswhetherornotthreadsareboundtoprocessors 20
(see Section 2.5.1 on page 64). The value of this ICV can be set with the OMP_PROC_BIND 21
environment variable (see Section 6.4 on page 604). 22
Thenthreads-var ICV has been modiﬁed to be a list of the number of threads to use at each 23
nested parallel region level and the algorithm for determining the number of threads used in a 24
parallel region has been modiﬁed to handle a list (see Section 2.6.1 on page 78). 25
Thefinalandmergeable clauses (see Section 2.10.1 on page 135) were added to the task 26
construct to support optimization of task data environments. 27
Thetaskyield construct (see Section 2.10.4 on page 147) was added to allow user-deﬁned 28
task scheduling points. 29
Theatomic construct(seeSection2.17.7onpage234)wasextendedtoinclude read,write, 30
andcapture forms,andan update clausewasaddedtoapplythealreadyexistingformofthe 31
atomic construct. 32
634 OpenMP API – Version 5.0 November 2018
Data environment restrictions were changed to allow intent(in) andconst-qualiﬁed types 1
for the firstprivate clause (see Section 2.19.4.4 on page 286). 2
Data environment restrictions were changed to allow Fortran pointers in firstprivate (see 3
Section 2.19.4.4 on page 286) and lastprivate (see Section 2.19.4.5 on page 288). 4
New reduction operators minandmaxwere added for C and C++ (see Section 2.19.5 on 5
page 293). 6
The nesting restrictions in Section 2.20 on page 328 were clariﬁed to disallow closely-nested 7
OpenMP regions within an atomic region. This allows an atomic region to be consistently 8
deﬁned with other OpenMP regions so that they include all code in the atomic construct. 9
Theomp_in_final runtime library routine (see Section 3.2.22 on page 356) was added to 10
support specialization of ﬁnal task regions. 11
Descriptions of examples (previously Appendix A) were expanded and clariﬁed. 12
Replaced incorrect use of omp_integer_kind in Fortran interfaces with 13
selected_int_kind(8) . 14
B.6 Version 2.5 to 3.0 Differences 15
The deﬁnition of active parallel region has been changed: in Version 3.0 a parallel 16
region is active if it is executed by a team consisting of more than one thread (see Section 1.2.2 17
on page 2). 18
The concept of tasks has been added to the OpenMP execution model (see Section 1.2.5 on 19
page 10 and Section 1.3 on page 20). 20
The OpenMP memory model now covers atomicity of memory accesses (see Section 1.4.1 on 21
page 23). The description of the behavior of volatile in terms of flushwas removed. 22
In Version 2.5, there was a single copy of the nest-var,dyn-var,nthreads-var andrun-sched-var 23
internal control variables (ICVs) for the whole program. In Version 3.0, there is one copy of 24
these ICVs per task (see Section 2.5 on page 63). As a result, the omp_set_num_threads , 25
omp_set_nested andomp_set_dynamic runtime library routines now have speciﬁed 26
eﬀects when called from inside a parallel region (see Section 3.2.1 on page 334, 27
Section 3.2.7 on page 340 and Section 3.2.10 on page 343). 28
Thethread-limit-var ICV has been added, which controls the maximum number of threads 29
participating in the OpenMP program. The value of this ICV can be set with the 30
OMP_THREAD_LIMIT environment variable and retrieved with the 31
omp_get_thread_limit runtime library routine (see Section 2.5.1 on page 64, 32
Section 3.2.14 on page 348 and Section 6.10 on page 610). 33
APPENDIX B. FEATURES HISTORY 635
Themax-active-levels-var ICV has been added, which controls the number of nested active 1
parallel regions. The value of this ICV can be set with the OMP_MAX_ACTIVE_LEVELS 2
environment variable and the omp_set_max_active_levels runtime library routine, and 3
it can be retrieved with the omp_get_max_active_levels runtime library routine (see 4
Section 2.5.1 on page 64, Section 3.2.16 on page 350, Section 3.2.17 on page 351 and 5
Section 6.8 on page 608). 6
Thestacksize-var ICVhasbeenadded,whichcontrolsthestacksizeforthreadsthattheOpenMP 7
implementation creates. The value of this ICV can be set with the OMP_STACKSIZE 8
environment variable (see Section 2.5.1 on page 64 and Section 6.6 on page 607). 9
Thewait-policy-var ICV has been added, which controls the desired behavior of waiting threads. 10
The value of this ICV can be set with the OMP_WAIT_POLICY environment variable (see 11
Section 2.5.1 on page 64 and Section 6.7 on page 608). 12
Therulesfordeterminingthenumberofthreadsusedina parallel regionhavebeenmodiﬁed 13
(see Section 2.6.1 on page 78). 14
In Version 3.0, the assignment of iterations to threads in a loop construct with a static 15
schedule kind is deterministic (see Section 2.9.2 on page 101). 16
InVersion3.0,aloopconstructmaybeassociatedwithmorethanoneperfectlynestedloop. The 17
number of associated loops is controlled by the collapse clause (see Section 2.9.2 on 18
page 101). 19
Random access iterators, and variables of unsigned integer type, may now be used as loop 20
iterators in loops associated with a loop construct (see Section 2.9.2 on page 101). 21
The schedule kind autohas been added, which gives the implementation the freedom to choose 22
anypossiblemappingofiterationsinaloopconstructtothreadsintheteam(seeSection2.9.2on 23
page 101). 24
Thetaskconstruct (see Section 2.10 on page 135) has been added, which provides a 25
mechanism for creating tasks explicitly. 26
Thetaskwait construct (see Section 2.17.5 on page 230) has been added, which causes a task 27
to wait for all its child tasks to complete. 28
Fortran assumed-size arrays now have predetermined data-sharing attributes (see 29
Section 2.19.1.1 on page 270). 30
In Version 3.0, static class members variables may appear in a threadprivate directive (see 31
Section 2.19.2 on page 274). 32
Version 3.0 makes clear where, and with which arguments, constructors and destructors of 33
private and threadprivate class type variables are called (see Section 2.19.2 on page 274, 34
Section 2.19.4.3 on page 285, Section 2.19.4.4 on page 286, Section 2.19.6.1 on page 310 and 35
Section 2.19.6.2 on page 312). 36
636 OpenMP API – Version 5.0 November 2018
In Version 3.0, Fortran allocatable arrays may appear in private ,firstprivate , 1
lastprivate ,reduction ,copyin andcopyprivate clauses (see Section 2.19.2 on 2
page 274, Section 2.19.4.3 on page 285, Section 2.19.4.4 on page 286, Section 2.19.4.5 on 3
page 288, Section 2.19.5.4 on page 300, Section 2.19.6.1 on page 310 and Section 2.19.6.2 on 4
page 312). 5
In Fortran, firstprivate is now permitted as an argument to the default clause (see 6
Section 2.19.4.1 on page 282). 7
Forlistitemsinthe private clause,implementationsarenolongerpermittedtousethestorage 8
of the original list item to hold the new list item on the master thread. If no attempt is made to 9
reference the original list item inside the parallel region, its value is well deﬁned on exit 10
from the parallel region (see Section 2.19.4.3 on page 285). 11
The runtime library routines omp_set_schedule andomp_get_schedule have been 12
added; these routines respectively set and retrieve the value of the run-sched-var ICV (see 13
Section 3.2.12 on page 345 and Section 3.2.13 on page 347). 14
Theomp_get_level runtime library routine has been added, which returns the number of 15
nested parallel regions enclosing the task that contains the call (see Section 3.2.18 on 16
page 352). 17
Theomp_get_ancestor_thread_num runtime library routine has been added, which 18
returns, for a given nested level of the current thread, the thread number of the ancestor (see 19
Section 3.2.19 on page 353). 20
Theomp_get_team_size runtime library routine has been added, which returns, for a given 21
nested level of the current thread, the size of the thread team to which the ancestor belongs (see 22
Section 3.2.20 on page 354). 23
Theomp_get_active_level runtime library routine has been added, which returns the 24
number of nested active parallel regions enclosing the task that contains the call (see 25
Section 3.2.21 on page 355). 26
In Version 3.0, locks are owned by tasks, not by threads (see Section 3.3 on page 381). 27
APPENDIX B. FEATURES HISTORY 637
This page intentionally left blank
Index
Symbols
_OPENMP macro, 49, 611–613
A
acquire ﬂush, 27
aﬃnity, 80
allocate , 156, 158
array sections, 44
array shaping, 43
atomic, 234
atomic construct, 621
attribute clauses, 282
attributes, data-mapping, 314
attributes, data-sharing, 269
auto, 105
B
barrier , 226
barrier, implicit, 228
C
cancel, 263
cancellation constructs, 263
cancel, 263
cancellation point , 267
cancellation point , 267
canonical loop form, 95
capture, atomic , 234
clauses
allocate , 158
attribute data-sharing, 282collapse , 101, 102
copyin, 310
copyprivate , 312
data copying, 309
data-sharing, 282
default , 282
defaultmap , 324
depend, 255
firstprivate , 286
hint, 260
ifClause, 220
in_reduction , 303
lastprivate , 288
linear, 290
map, 315
private , 285
reduction , 300
schedule , 103
shared, 283
task_reduction , 303
combined constructs, 185
master taskloop , 192
master taskloop simd , 194
parallel loop , 186
parallel master , 191
parallel master taskloop , 195
parallel master taskloop simd ,
196
parallel sections , 188
parallel workshare , 189
639
parallel worksharing-loop
construct, 185
parallel worksharing-loop SIMD
construct, 190
target parallel , 203
target parallel loop , 208
target parallel worksharing-loop
construct, 205
target parallel worksharing-loop SIMD
construct, 206
target simd , 209
target teams , 210
target teams distribute , 211
target teams distribute parallel
worksharing-loop construct, 215
target teams distribute parallel
worksharing-loop SIMD
construct, 216
target teams distribute simd ,
213
target teams loop construct, 214
teams distribute , 197
teams distribute parallel
worksharing-loop construct, 200
teams distribute parallel
worksharing-loop SIMD
construct, 201
teams distribute simd , 198
teams loop , 202
compilation sentinels, 50
compliance, 31
conditional compilation, 49
constructs
atomic, 234
barrier , 226
cancel, 263
cancellation constructs, 263
cancellation point , 267
combined constructs, 185
critical , 223
declare mapper , 326
declare target , 180
depobj, 254device constructs, 160
distribute , 120
distribute parallel do , 125
distribute parallel do simd ,
126
distribute parallel for , 125
distribute parallel for simd ,
126
distribute parallel worksharing-loop
construct, 125
distribute parallel worksharing-loop
SIMD construct, 126
distribute simd , 123
doFortran, 101
flush, 242
for,C/C++, 101
loop, 128
master, 221
master taskloop , 192
master taskloop simd , 194
ordered , 250
parallel , 74
parallel do Fortran, 185
parallel for C/C++, 185
parallel loop , 186
parallel master , 191
parallel master taskloop , 195
parallel master taskloop simd ,
196
parallel sections , 188
parallel workshare , 189
parallel worksharing-loop
construct, 185
parallel worksharing-loop SIMD
construct, 190
sections , 86
simd, 110
single, 89
target, 170
target data , 161
target enter data , 164
target exit data , 166
target parallel , 203
640OpenMP API – Version 5.0 November 2018
target parallel do , 205
target parallel do simd , 206
target parallel for , 205
target parallel for simd , 206
target parallel loop , 208
target parallel worksharing-loop
construct, 205
target parallel worksharing-loop SIMD
construct, 206
target simd , 209
target teams , 210
target teams distribute , 211
target teams distribute parallel
worksharing-loop construct, 215
target teams distribute parallel
worksharing-loop SIMD
construct, 216
target teams distribute simd ,
213
target teams loop , 214
target update , 176
task, 135
taskgroup , 232
tasking constructs, 135
taskloop , 140
taskloop simd , 146
taskwait , 230
taskyield , 147
teams, 82
teams distribute , 197
teams distribute parallel
worksharing-loop construct, 200
teams distribute parallel
worksharing-loop SIMD
construct, 201
teams distribute simd , 198
teams loop , 202
workshare , 92
worksharing, 86
worksharing-loop construct, 101
worksharing-loop SIMD construct, 114
controlling OpenMP thread aﬃnity, 80
copyin, 310copyprivate , 312
critical , 223
D
data copying clauses, 309
data environment, 269
data terminology, 12
data-mapping rules and clauses, 314
data-sharing attribute clauses, 282
data-sharing attribute rules, 269
declare mapper , 326
declare reduction , 304
declare simd , 116
declare target , 180
declare variant , 58
default , 282
defaultmap , 324
depend, 255
depend object, 254
depobj, 254
deprecated features, 627
device constructs
declare mapper , 326
declare target , 180
device constructs, 160
distribute , 120
distribute parallel worksharing-loop
construct, 125
distribute parallel worksharing-loop
SIMD construct, 126
distribute simd , 123
target, 170
target update , 176
teams, 82
device data environments, 24, 164, 166
device directives, 160
device memory routines, 397
directive format, 38
directives, 37
allocate , 156
declare mapper , 326
declare reduction , 304
declare simd , 116
declare target , 180
Index 641
declare variant , 58
memory management directives, 152
metadirective , 56
requires , 60
scanDirective, 132
threadprivate , 274
variant directives, 51
distribute , 120
distribute parallel worksharing-loop
construct, 125
distribute parallel worksharing-loop SIMD
construct, 126
distribute simd , 123
do,Fortran, 101
do simd , 114
dynamic , 105
dynamic thread adjustment, 620
E
environment variables, 601
OMP_AFFINITY_FORMAT , 613
OMP_ALLOCATOR , 618
OMP_CANCELLATION , 610
OMP_DEBUG , 617
OMP_DEFAULT_DEVICE , 615
OMP_DISPLAY_AFFINITY , 612
OMP_DISPLAY_ENV , 611
OMP_DYNAMIC , 603
OMP_MAX_ACTIVE_LEVELS , 608
OMP_MAX_TASK_PRIORITY , 615
OMP_NESTED , 609
OMP_NUM_THREADS , 602
OMP_PLACES , 605
OMP_PROC_BIND , 604
OMP_SCHEDULE , 601
OMP_STACKSIZE , 607
OMP_TARGET_OFFLOAD , 615
OMP_THREAD_LIMIT , 610
OMP_TOOL , 616
OMP_TOOL_LIBRARIES , 617
OMP_WAIT_POLICY , 608
event, 396
event callback registration, 425
event callback signatures, 459event routines, 396
execution environment routines, 334
execution model, 20
F
features history, 627
firstprivate , 286
ﬁxed source form conditional compilation
sentinels, 50
ﬁxed source form directives, 41
flush, 242
ﬂush operation, 25
ﬂush synchronization, 27
ﬂush-set, 25
for,C/C++, 101
for simd , 114
frames, 454
free source form conditional compilation
sentinel, 50
free source form directives, 41
G
glossary, 2
guided, 105
H
happens before, 27
header ﬁles, 332
history of features, 627
I
ICVs (internal control variables), 63
ifClause, 220
implementation, 619
implementation terminology, 16
implicit barrier, 228
implicit ﬂushes, 246
in_reduction , 303
include ﬁles, 332
internal control variables, 619
internal control variables (ICVs), 63
introduction, 1
iterators, 47
642 OpenMP API – Version 5.0 November 2018
L
lastprivate , 288
linear, 290
list item privatization, 279
lock routines, 381
loop, 128
loop terminology, 8
M
map, 315
master, 221
master taskloop , 192
master taskloop simd , 194
memory allocators, 152
memory management, 152
memory management directives
memory management directives, 152
memory management routines, 406
memory model, 23
memory spaces, 152
metadirective, 56
modifying and retrieving ICV values, 68
modifying ICVs, 66
N
nesting of regions, 328
normative references, 31
O
OMP_AFFINITY_FORMAT , 613
omp_alloc , 413
OMP_ALLOCATOR , 618
OMP_CANCELLATION , 610
omp_capture_affinity , 368
OMP_DEBUG , 617
OMP_DEFAULT_DEVICE , 615
omp_destroy_allocator , 410
omp_destroy_lock , 387
omp_destroy_nest_lock , 387
OMP_DISPLAY_AFFINITY , 612
omp_display_affinity , 367
OMP_DISPLAY_ENV , 611
OMP_DYNAMIC , 603
omp_free , 414omp_fulfill_event , 396
omp_get_active_level , 355
omp_get_affinity_format , 366
omp_get_ancestor_thread_num ,353
omp_get_cancellation , 342
omp_get_default_allocator , 412
omp_get_default_device , 370
omp_get_device_num , 372
omp_get_dynamic , 341
omp_get_initial_device , 376
omp_get_level , 352
omp_get_max_active_levels , 351
omp_get_max_task_priority , 377
omp_get_max_threads , 336
omp_get_nested , 344
omp_get_num_devices , 371
omp_get_num_places , 358
omp_get_num_procs , 338
omp_get_num_teams , 373
omp_get_num_threads , 335
omp_get_partition_num_places ,
362
omp_get_partition_place_nums ,
363
omp_get_place_num , 362
omp_get_place_num_procs , 359
omp_get_place_proc_ids , 360
omp_get_proc_bind , 357
omp_get_schedule , 347
omp_get_supported_active
_levels , 349
omp_get_team_num , 374
omp_get_team_size , 354
omp_get_thread_limit , 348
omp_get_thread_num , 337
omp_get_wtick , 395
omp_get_wtime , 394
omp_in_final , 356
omp_in_parallel , 339
omp_init_allocator , 409
omp_init_lock , 384, 385
omp_init_nest_lock , 384, 385
omp_is_initial_device , 375
Index 643
OMP_MAX_ACTIVE_LEVELS , 608
OMP_MAX_TASK_PRIORITY , 615
OMP_NESTED , 609
OMP_NUM_THREADS , 602
omp_pause_resource , 378
omp_pause_resource_all , 380
OMP_PLACES , 605
OMP_PROC_BIND , 604
OMP_SCHEDULE , 601
omp_set_affinity_format , 364
omp_set_default_allocator , 411
omp_set_default_device , 369
omp_set_dynamic , 340
omp_set_lock , 388
omp_set_max_active_levels , 350
omp_set_nest_lock , 388
omp_set_nested , 343
omp_set_num_threads , 334
omp_set_schedule , 345
OMP_STACKSIZE , 607
omp_target_alloc , 397
omp_target_associate_ptr , 403
omp_target_disassociate_ptr ,405
omp_target_free , 399
omp_target_is_present , 400
omp_target_memcpy , 400
omp_target_memcpy_rect , 402
OMP_TARGET_OFFLOAD , 615
omp_test_lock , 392
omp_test_nest_lock , 392
OMP_THREAD_LIMIT , 610
OMP_TOOL , 616
OMP_TOOL_LIBRARIES , 617
omp_unset_lock , 390
omp_unset_nest_lock , 390
OMP_WAIT_POLICY , 608
ompd_bp_device_begin , 598
ompd_bp_device_end , 599
ompd_bp_parallel_begin , 594
ompd_bp_parallel_end , 595
ompd_bp_task_begin , 595
ompd_bp_task_end , 596
ompd_bp_thread_begin , 597ompd_bp_thread_end , 597
ompd_callback_device_host
_fn_t, 554
ompd_callback_get_thread
_context_for_thread_id
_fn_t, 547
ompd_callback_memory_alloc
_fn_t, 546
ompd_callback_memory_free
_fn_t, 546
ompd_callback_memory_read
_fn_t, 551
ompd_callback_memory_write
_fn_t, 553
ompd_callback_print_string
_fn_t, 556
ompd_callback_sizeof_fn_t , 549
ompd_callback_symbol_addr
_fn_t, 550
ompd_callbacks_t , 556
ompd_dll_locations_valid , 536
ompd_dll_locations , 535
ompt_callback_buffer
_complete_t , 487
ompt_callback_buffer
_request_t , 486
ompt_callback_cancel_t , 481
ompt_callback_control
_tool_t , 495
ompt_callback_dependences_t ,468
ompt_callback_dispatch_t , 465
ompt_callback_device
_finalize_t , 484
ompt_callback_device
_initialize_t , 482
ompt_callback_flush_t , 480
ompt_callback_implicit
_task_t , 471
ompt_callback_master_t , 473
ompt_callback_mutex
_acquire_t , 476
ompt_callback_mutex_t , 477
ompt_callback_nest_lock_t , 479
644 OpenMP API – Version 5.0 November 2018
ompt_callback_parallel
_begin_t , 461
ompt_callback_parallel
_end_t, 463
ompt_callback_sync_region_t ,474
ompt_callback_device_load_t ,484
ompt_callback_device
_unload_t , 486
ompt_callback_target_data
_op_t, 488
ompt_callback_target_map_t , 492
ompt_callback_target
_submit_t , 494
ompt_callback_target_t , 490
ompt_callback_task_create_t ,467
ompt_callback_task
_dependence_t , 470
ompt_callback_task
_schedule_t , 470
ompt_callback_thread
_begin_t , 459
ompt_callback_thread_end_t , 460
ompt_callback_work_t , 464
OpenMP compliance, 31
ordered , 250
P
parallel , 74
parallel loop , 186
parallel master construct , 191
parallel master taskloop , 195
parallel master taskloop simd ,196
parallel sections , 188
parallel workshare , 189
parallel worksharing-loop construct, 185
parallel worksharing-loop SIMD
construct, 190
private , 285
R
read, atomic , 234
reduction , 300
reduction clauses, 293
release ﬂush, 27requires , 60
runtime , 105
runtime library deﬁnitions, 332
runtime library routines, 331
S
scanDirective, 132
scheduling, 149
sections , 86
shared, 283
simd, 110
SIMD Directives, 110
Simple Lock Routines, 382
single, 89
stand-alone directives, 42
static, 104
strong ﬂush, 25
synchronization constructs, 223
synchronization constructs and clauses, 223
synchronization hints, 260
synchronization terminology, 9
T
target, 170
target data , 161
target memory routines, 397
target parallel , 203
target parallel loop , 208
target parallel worksharing-loop construct
construct, 205
target parallel worksharing-loop SIMD
construct, 206
target simd , 209
target teams , 210
target teams distribute , 211
target teams distribute parallel
worksharing-loop construct, 215
target teams distribute parallel
worksharing-loop SIMD
construct, 216
target teams distribute simd , 213
target teams loop , 214
target update , 176
task, 135
Index 645
task scheduling, 149
task_reduction , 303
taskgroup , 232
tasking constructs, 135
tasking terminology, 10
taskloop , 140
taskloop simd , 146
taskwait , 230
taskyield , 147
teams, 82
teams distribute , 197
teams distribute parallel worksharing-loop
construct, 200
teams distribute parallel worksharing-loop
SIMD construct, 201
teams distribute simd , 198
teams loop , 202
thread aﬃnity, 80
threadprivate , 274
timer, 394
timing routines, 394
tool control, 415
tool initialization, 423
tool interfaces deﬁnitions, 419, 534
tools header ﬁles, 419, 534
tracing device activity, 427
U
update, atomic , 234
V
variables, environment, 601
variant directives, 51
W
wait identiﬁer, 456
wall clock timer, 394
workshare , 92
worksharing
constructs, 86
parallel, 185
scheduling, 109
worksharing constructs, 86
worksharing-loop construct, 101worksharing-loop SIMD construct, 114
write, atomic , 234
646 OpenMP API – Version 5.0 November 2018
